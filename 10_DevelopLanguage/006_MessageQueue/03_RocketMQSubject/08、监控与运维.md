###### 1. RocketMQ 如何进行监控？有哪些关键指标？
RocketMQ 的监控体系旨在实现**全链路可观测性**，核心涵盖**指标监控、消息追踪和日志分析**三大支柱 。构建完善的监控体系首先需要部署数据采集组件（如 RocketMQ Exporter），并配置可视化仪表盘（如 Grafana）和告警规则 。
**监控体系搭建与核心指标**

|**监控维度**​|**核心指标**​|**监控目标与阈值建议**​|**数据获取方式**​|
|---|---|---|---|
|**Broker 服务端**​|**消息生产/消费 TPS**​|反映集群吞吐能力，消费 TPS 持续低于生产 TPS 是堆积的直接信号 。|通过 Exporter 采集 Broker 的 `msgPutTotalTps`和 `msgGetTotalTps`指标 。|
||**消息堆积量**​ (`consumer lag`)|`consumer lag = 处理中消息 (inflight) + 已就绪消息 (ready)`。需设置阈值告警（如 >10,000） 。|通过 `admin.examineConsumeStats(consumerGroup)`计算 或 Exporter 采集。|
||**CommitLog 磁盘使用率**​|水位线阈值建议 ≤80%，超过后 Broker 可能拒绝对新消息的写入 。|通过 Broker 暴露的度量指标获取。|
||**刷盘延迟**​ (`flushCommitLogTimediff`)|同步刷盘应接近 0ms，异步刷盘建议 ≤10ms，否则宕机时有数据丢失风险 。|通过 Broker 暴露的度量指标获取。|
|**生产者**​|**发送失败次数**​|监控网络异常、Broker 负载过高或客户端配置问题。|客户端 SDK 内置计数器或通过可观测框架采集。|
||**发送平均耗时**​|耗时突增可能意味着 Broker 压力大或网络瓶颈。|客户端 SDK 内置指标。|
|**消费者**​|**消费成功率**​|直接反映消费端业务逻辑健康度，降低需立即排查。|通过控制台或 `examineConsumeStats`接口获取 。|
||**处理中消息量**​ (`inflight messages`)|持续高位可能表示消费线程被阻塞或业务处理耗时过长 。|计算公式：`最晚拉取位点 - 最晚提交位点`。|
||**重试次数**​ & **死信队列消息数**​|消息重复失败并进入死信队列，意味着消费逻辑可能存在需要修复的缺陷 。|通过 `examineConsumeStats`接口或监控死信 Topic `%DLQ%{consumerGroup}`。|
**监控平台集成实践**
企业级监控通常采用 **Prometheus + Grafana**​ 组合 。通过部署 RocketMQ Exporter，将 RocketMQ 的内部指标转换为 Prometheus 可抓取的格式 。在 Grafana 中导入或配置相应的监控大盘，即可实现可视化 。告警规则（如基于 PromQL 表达式）可通过 Alertmanager 配置，实现钉钉、短信等通知 。
###### 2. 如何排查 RocketMQ 的消息丢失问题？
消息丢失是严重故障，需遵循**全链路排查**原则，从生产者、Broker 到消费者逐一分析 。
- **生产者发送阶段**
    - **排查点**：是否使用了不可靠的**单向发送**模式；同步/异步发送下，**重试机制**是否生效；客户端日志是否有 `send message failed`等相关异常 。
    - **解决方案与源码级保障**：
        - **同步发送**：务必使用 `DefaultMQProducer.send(msg)`并处理异常，其内部会进行重试（默认2次） 。
        - **事务消息**：对于需要与数据库操作保持原子性的场景，采用事务消息。其核心是“**半消息**”机制：生产者先发送一条对消费者不可见的消息，待本地事务执行成功后再向 Broker 确认提交，确保消息必达 。
- **Broker 存储阶段**
    - **排查点**：Broker 是否配置了**异步刷盘**​ (`flushDiskType=ASYNC_FLUSH`) 且在刷盘前宕机；主从架构下，是否采用**异步复制**​ (`brokerRole=ASYNC_MASTER`) 且主节点在数据同步到从节点前宕机 。
    - **解决方案与源码视角**：
        - **同步刷盘**：在 `broker.conf`中设置 `flushDiskType=SYNC_FLUSH`。这将迫使 Broker 在 `CommitLog`的 `MappedByteBuffer.force()`刷盘操作完成后，才向生产者返回成功响应，代价是性能降低 。
        - **同步复制**：设置 `brokerRole=SYNC_MASTER`。这要求主节点必须等待至少一个从节点 (`haSyncReplicas=1`) 成功复制消息后，才确认写入，从根本上避免主节点宕机导致数据丢失 。
        - **DLedger 模式**：基于 Raft 协议实现多副本数据强一致性，是解决存储阶段高可用和数据不丢的终极方案。
- **消费者消费阶段**
    - **排查点**：是否错误地使用了**自动确认**模式；在手动确认下，业务逻辑失败后是否未正确返回 `RECONSUME_LATER`。
    - **解决方案**：
        - **强制手动确认**：消费者监听器内，必须在业务逻辑成功执行后，再返回 `ConsumeConcurrentlyStatus.CONSUME_SUCCESS`或调用 `ackMessage()`。
        - **异常处理**：在 `catch`块中返回 `RECONSUME_LATER`，利用 RocketMQ 的重试机制（默认最多16次）确保消息最终被成功处理 。
###### 3. 如何排查 RocketMQ 的消息积压问题？
消息积压的本质是**消费速度跟不上生产速度**。排查是一个系统工程 。
1. **定位堆积环节**：首先通过监控面板或命令查看 `inflight messages`（处理中）和 `ready messages`（已就绪）的数量 。
    - **`inflight`过高**：问题在**消费端**。表示消息已被客户端拉取但业务代码处理缓慢或卡住 。
    - **`ready`过高**：问题可能在**Broker 端或消费端的拉取环节**。表示消息在 Broker 端堆积，未被消费者及时拉取。
2. **消费端深度排查**：
    - **检查消费线程堆栈**：使用 `jstack`命令导出消费者 JVM 线程信息，重点查看 `ConsumeMessageThread`线程的状态 。如果线程阻塞在 I/O 调用、锁竞争或耗时操作上，就能定位瓶颈 。
    - **评估消费耗时**：通过控制台的消息轨迹功能或业务埋点，监控单条消息的平均处理时间。如果耗时过长，需优化业务逻辑，如优化数据库查询、缓存、异步化处理等 。
    - **调整消费并发度**：确保消费者线程数 (`consumeThreadMin/Max`) 与订阅 Topic 的队列数匹配甚至略多，以充分利用并行消费能力 。
3. **Broker 端与架构优化**：
    - **增加队列数**：Topic 的队列数是并发消费的并行度上限。如果队列数太少，即使增加消费者实例也无法提升消费能力。但修改队列数需重建 Topic，需谨慎规划。
    - **监控 Broker 负载**：检查 Broker 节点的 CPU、磁盘 IO 和网络流量，排除服务端性能瓶颈 。
    - **紧急处理**：若积压消息可跳过，可通过 `mqadmin`命令**重置消费位点**，让消费者从最新位置开始消费，快速恢复业务，事后再处理积压数据 。
###### 4. RocketMQ 如何进行消息追踪？
消息追踪用于**复现单条消息的完整生命周期**，是排查消息丢失、延迟和乱序的利器。
- **实现方式**：
    - **开源版**：可通过继承 `org.apache.rocketmq.client.hook.ConsumeMessageHook`和 `SendMessageHook`接口，自定义拦截器，在消息发送和消费的关键节点打印包含 `MsgId`、`Topic`、`QueueId`等信息的日志，然后通过日志系统串联 。
    - **5.x 版本与商业版**：RocketMQ 5.x 开始支持 **OpenTelemetry**​ 标准，提供了更强大的分布式追踪能力，可以无缝集成到 APM 系统中，实现端到端的链路跟踪 。
- **追踪信息**：一条消息的轨迹通常包括：生产者发送时间、消息到达 Broker 的存储时间、消息被消费者拉取的时间、消费者消费成功的时间等 。
###### 5. 如何查看 RocketMQ 的消费进度？
消费进度（`Consumer Offset`）是监控消费滞后和积压的核心。
- **命令行工具**：使用 `mqadmin`命令是直接的方式。
    ```bash
    # 查看指定消费组的消费进度和堆积情况
    mqadmin consumerProgress -g <你的消费者组名>
    ```
- **监控平台**：在 RocketMQ Console 或 Grafana 等监控仪表盘中，`consumer lag`（消费滞后）图表直观展示了 `maxOffset`（Broker 最大位点）与 `consumerOffset`（消费位点）之间的差距，即堆积消息量 。
- **API 方式**：通过 `DefaultMQAdminExt`的 `examineConsumeStats`方法，可以编程获取消费进度详情，包括每个 Message Queue 的位点信息 。
###### 6. RocketMQ 的死信队列有什么作用？如何处理死信消息？
- **作用**：死信队列是 RocketMQ 的**安全网机制**。当一个消息经过**最大重试次数**（默认 16 次）消费仍然失败后，为避免无限次重试浪费资源，该消息会被自动转移至一个特殊的队列，即死信队列 。其命名格式为 `%DLQ%<ConsumerGroupName>`。
- **处理流程**：
    1. **监控**：务必为死信队列 Topic 设置监控告警。一旦有消息进入，立即触发告警 。
    2. **排查**：消费组收到告警后，需要查询死信消息的内容和失败原因，修复消费端的业务逻辑缺陷 。
    3. **处理**：修复代码后，可以通过 **`mqadmin`命令**或 **RocketMQ Console**​ 将死信消息重新发送回原 Topic，让其被正常的消费逻辑重新处理 。
###### 7. 如何重置 RocketMQ 的消费位点？
重置消费位点是一项**高风险操作**，主要用于灾难恢复，例如在消息严重堆积且业务允许丢失部分历史消息时，快速让消费者追赶上最新进度。
- **操作步骤**：
    ```bash
    # 跳过积压，从最新位置开始消费
    mqadmin resetOffsetByTime -g <ConsumerGroup> -t <Topic> -s <时间戳> -f false
    ```
- **关键参数**：
    - `-s`：指定时间戳。`-1`表示重置到最新位点，`-2`表示重置到最小位点（即最早），也可指定具体时间。
    - `-f`：是否强制重置。务必在清楚后果的情况下使用。
- **注意事项**：重置操作是**不可逆**的。执行前必须确认该消费组下**所有消费者实例已停止**，否则会导致位点混乱。重置完成后，原先位点之后未被消费的消息将**永久丢失**。