###### 1. 如何保证消息不丢失？
保证消息不丢失需要在**生产者、Broker、消费者**三个层面共同保障。
**生产者端保证消息可靠性**
- **确认机制（ACK）**：生产者发送消息后等待Broker的确认响应。RabbitMQ提供`Publisher Confirms`机制，Kafka可通过配置`acks`参数实现。
- **事务消息**：使用事务机制确保消息发送的原子性。
- **失败重试**：为生产者配置合理的重试机制，以应对网络波动等临时性故障。
**Broker端保证消息可靠性**
- **消息持久化**：将消息保存到磁盘。在RabbitMQ中，创建队列时设置`durable`为`true`可将队列声明为持久化队列，发布消息时设置`deliveryMode`为`2`可将消息标记为持久化。Kafka通过分区副本机制和消息日志的持久化存储来保证消息不丢失。
- **高可用部署**：采用集群部署模式。RabbitMQ可使用镜像队列，Kafka则通过多副本机制（Replication）和ISR（In-Sync Replicas）列表来避免单点故障。
**消费者端保证消息可靠性**
- **手动确认（ACK）**：关闭自动提交，在消息被业务逻辑成功处理后再手动向Broker发送确认信号。在RabbitMQ中使用`channel.basicAck`，在Kafka中手动提交偏移量（offset）。
###### 2. 如何保证消息不被重复消费？
解决重复消费问题的核心是**幂等性设计**。
**幂等性解决方案**
- **唯一标识符**：为每条消息分配全局唯一ID（如UUID），消费者在处理前先检查该ID是否已被处理。可利用Redis的`SETNX`命令或数据库唯一索引进行校验。
- **数据库唯一约束**：利用数据库的唯一索引防止重复数据插入。例如，订单表可设置订单号的唯一索引，重复插入时捕获`DataIntegrityViolationException`异常即可。
- **状态机机制**：对于有状态流转的业务（如订单状态），在处理消息前先查询当前状态，仅当处于预期状态时才进行处理，通常结合乐观锁（如`version`字段）实现。
- **版本号控制**：在消息中携带数据版本号，消费者处理时校验版本号，仅处理更新的数据。
**消息队列配置优化**
- 通过配置最大重试次数和死信队列，防止消息无限次重试。
###### 3. 如何保证消息的顺序性？
**RabbitMQ保证顺序性**
- 将需要保证顺序的消息发送到**同一个队列**，并由**单个消费者**处理。要避免使用消费者集群，因为多个消费者会打乱顺序。
**Kafka保证顺序性**
- Kafka在一个分区（Partition）内保证消息的顺序性。确保需要顺序处理的消息被发送到同一分区，通常通过为这些消息设置相同的Key来实现自定义分区策略。
**业务层保证**
- 在消费者端，有时需通过状态机或分布式锁等机制，在业务逻辑层面保证操作的顺序性。
###### 4. 什么是消息的幂等性？如何实现？
**幂等性概念**
幂等性是指**同一操作执行一次或多次所产生的影响均相同**。在消息队列中，即无论消息被消费多少次，结果都与消费一次一致。
**实现方案**
- **唯一ID去重**：为消息分配唯一ID，使用Redis或数据库存储已处理ID。
- **数据库唯一约束**：通过数据库的唯一索引天然保证幂等性。
- **乐观锁机制**：通过版本号控制，只有版本号匹配时才更新数据。
- **状态机设计**：根据业务状态决定是否处理消息。
###### 5. 什么是分布式事务消息？如何实现？
分布式事务消息用于解决消息队列与本地数据库操作之间的数据一致性问题。
**本地消息表方案**
- 在业务数据库中创建消息表，将消息写入与业务操作放在同一数据库事务中。之后由定时任务轮询消息表，将未发送的消息发送到消息队列，并更新消息状态。这可确保业务操作成功时消息一定能发出。
**最大努力通知**
- 适用于最终一致性场景。服务A先完成本地操作并发送消息，服务B消费消息完成操作。若服务B处理失败，服务A通过定时任务等机制进行重试，直至成功或达到最大重试次数。
**TCC模式**
- 针对分布式事务的Try-Confirm-Cancel模式。在消息处理场景中，可让业务操作支持两阶段：先尝试执行（预留资源），根据结果再提交确认或取消回滚。
**框架支持**
- 可使用如Seata等分布式事务框架，通过`@GlobalTransactional`注解管理跨服务的事务。
###### 6. 如何处理消息堆积问题？
消息积压指消费速度低于生产速度，导致消息在队列中大量滞留。
**应急处理**
- **增加消费者实例**：通过增加消费者数量来提升整体消费能力。对于RabbitMQ，可启动多个消费者共同消费一个队列；对于Kafka，需保证消费者数量不超过分区数，因为一个分区只能被一个消费者组内的一个消费者消费。
- **临时扩容**：临时增加服务节点和队列的分区数，以应对流量洪峰。
**优化消费能力**
- **优化消费逻辑**：检查并优化消费者的业务处理代码，提升单条消息的处理速度。可考虑将同步调用改为异步处理，利用`CompletableFuture`等并行处理技术。
- **批量消费**：如业务允许，可配置消费者批量拉取并处理消息，减少网络交互开销。
**长期治理**
- **队列拆分**：根据业务优先级或类型拆分单一队列为多个队列，并进行隔离处理，避免相互影响。
- **监控告警**：建立完善的监控体系，对消息堆积量、消费延迟等关键指标进行监控和告警，以便提前发现潜在风险。
###### 7. 什么是死信队列（DLQ）？如何使用？
**死信队列概念**
死信队列（Dead-Letter Queue）是一个用于存放处理失败或成为"死信"（无法被正常消费的消息）的特殊队列。
**消息成为死信的常见原因**
- 消息被消费者否定确认（NACK）且设置为不重新入队，或重试次数超过上限。
- 消息在队列中的存活时间（TTL）过期。
- 队列长度达到限制。
**死信队列的应用**
- **异常处理与诊断**：将处理失败的消息转入DLQ，便于后续集中分析原因（如逻辑错误、数据格式问题）。
- **延迟重试**：结合TTL和死信交换机，可实现延迟重试功能。即消息先发到带TTL的队列，过期后成为死信，再被路由到真正的处理队列进行重试
###### 8. 消息队列如何保证数据一致性？
消息队列通常通过**最终一致性**来保证数据在分布式系统中的一致性。
**生产端一致性**
- **事务消息**：如Kafka和RocketMQ支持分布式事务消息，确保本地事务与消息发送的原子性。
- **本地消息表**：将消息与业务数据保存在同一数据库中，利用本地事务保证二者一致性，再通过定时任务补偿发送消息。
**消费端一致性**
- **幂等消费**：保证即使收到重复消息，也不会导致数据错乱，是实现最终一致性的关键。
- **手动提交偏移量**：消费者在处理完业务逻辑后再提交偏移量，避免消费后业务处理失败导致的数据不一致。
**Broker端一致性**
- **高可用机制**：通过集群和副本机制确保Broker自身数据的可靠性与一致性。
- **持久化机制**：防止节点宕机导致数据丢失。