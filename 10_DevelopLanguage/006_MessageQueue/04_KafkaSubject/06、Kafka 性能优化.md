###### 1. 如何提高 Kafka 的吞吐量？
提升 Kafka 吞吐量需要从**生产者、Broker、消费者**三个层面进行系统优化。

|**优化层面**​|**核心策略**​|**关键配置与原理**​|
|---|---|---|
|**生产者**​|**批处理与压缩**​|通过 `batch.size`（如32KB）和 `linger.ms`（如10-100ms）将多条消息合并为一个批次发送，大幅减少网络请求次数。同时，设置 `compression.type`为 `lz4`或 `zstd`，用 CPU 资源换取网络和磁盘 I/O 资源，减少数据传输量 。|
|**Broker**​|**分区扩展与硬件升级**​|**分区是并行操作的最小单元**。增加分区数可以将负载分散到更多 Broker 上。同时，使用 SSD 磁盘提升顺序 I/O 性能，并保证充足的网络带宽（如万兆网卡）。|
|**消费者**​|**并行消费**​|确保**消费者组内的消费者实例数不超过分区总数**，并调整 `fetch.min.bytes`和 `max.poll.records`以批量拉取消息，提升处理效率 。|
**源码视角**：生产者的 `Sender`线程会收集 `RecordAccumulator`中满足条件的批次（大小或时间达到阈值），通过 `ProducerBatch`进行网络传输。增大批次大小和等待时间，本质上是让 `Sender`线程一次发送更多数据，降低了网络往返的开销 。
###### 2. 如何降低 Kafka 的延迟？
降低延迟与提升吞吐量的策略有时需要权衡，核心在于减少消息路径上的等待。

|**优化层面**​|**核心策略**​|**关键配置与原理**​|
|---|---|---|
|**生产者**​|**减少批处理等待**​|将 `linger.ms`设置为较小的值（如 1-5ms），让消息更快发出。但会牺牲部分吞吐量。对于低延迟高可靠性场景，可设置 `acks=1`。|
|**Broker**​|**优化磁盘与副本同步**​|使用高性能 SSD 降低写入延迟。调整副本同步参数，如 `replica.fetch.wait.max.ms`，控制 Follower 副本的拉取等待时间 。|
|**消费者**​|**减少拉取间隔**​|将 `fetch.max.wait.ms`调小（如 100ms），让消费者更频繁地获取新消息。同时，确保消费者处理逻辑高效，避免阻塞 。|
**设计权衡**：`linger.ms`参数是吞吐量与延迟的**直接权衡**。设置为 0 追求最低延迟，但吞吐量可能下降；增大该值可提升吞吐量，但会增加延迟 。
###### 3. Kafka 的分区数应该如何设置？
分区数是 Kafka 最重要的调优参数之一，直接影响并发能力。
**核心计算公式**：
`分区数 ≈ 目标吞吐量 / min(单个分区生产吞吐量， 单个分区消费吞吐量)`
例如，目标吞吐量为 100MB/s，单个分区生产吞吐量为 20MB/s，消费吞吐量为 50MB/s，则分区数至少为 5（100 / 20）。
**考量因素与最佳实践**：
1. **并发上限**：一个分区只能被**同一个消费者组内的一个消费者线程**消费。因此，**消费者组的最大并行度由分区数决定**。若要实现 10 个消费者并行消费，分区数至少为 10 。
2. 分区数并非越多越好。过多的分区会导致：
    - **元数据膨胀**：Broker 需要维护更多元数据，增加内存开销，可能延长 Leader 选举时间 。
    - **资源开销**：每个分区都会占用文件句柄和内存。建议单个 Broker 上的分区数控制在 2000-4000 以内，集群总分区的经验值为 `100 * Broker数量 * 复制因子`。
3. **顺序性保证**：Kafka 只保证**单个分区内**的消息顺序。若业务要求消息全局有序，则只能设置 1 个分区，但这会牺牲并发性。通常按业务键（如订单ID）分区来保证局部有序 。
###### 4. Kafka 的副本数应该如何设置？
副本因子（Replication Factor）主要影响**数据可靠性**和**可用性**。

|**副本因子**​|**优点**​|**缺点**​|**适用场景**​|
|---|---|---|---|
|**1**​|存储开销最小，写入延迟最低。|无冗余，Broker 宕机导致数据丢失和服务中断。|测试环境，或可丢失的日志收集。|
|**2**​|提供基本冗余，存储开销适中。|一个副本故障时，系统可用但处于风险中（只剩一个副本）。|对可靠性要求不极高的业务场景 。|
|**3（推荐）**​|**高可靠性**。可容忍两个 Broker 同时宕机。|存储开销增加，写入延迟略有上升（需等待更多副本确认）。|**生产环境的标准配置**，尤其适用于金融、交易等核心业务 。|
**关联配置**：设置 `acks=all`和 `min.insync.replicas=2`（通常小于副本因子）。这意味着生产者需要等待至少 2 个副本（包括 Leader）同步成功后才确认写入，即使一个副本短暂离线，写入也能成功，实现了可靠性与可用性的平衡 。
###### 5. 如何优化 Kafka 的磁盘 I/O？
Kafka 重度依赖磁盘，I/O 优化是性能基础。
1. **使用高性能 SSD**：SSD 的随机 I/O 和顺序 I/O 性能远优于 HDD，能显著提升消息写入和读取速度，是解决 I/O 瓶颈最有效的手段 。
2. **利用顺序写入**：Kafka 将消息**持久化到追加写入的日志文件**，这种顺序写盘的方式充分利用了磁盘的高效特性。无需过度优化磁盘读写策略 。
3. **充分利用 Page Cache**：让操作系统将频繁访问的日志数据缓存到内存中，后续的读请求可直接从内存命中，极大减少磁盘 I/O 次数。因此，应为 Broker 预留足够的内存给操作系统使用 。
4. **调整刷盘策略**：`log.flush.interval.messages`和 `log.flush.interval.ms`参数控制强制刷盘频率。**生产环境通常依赖底层操作系统异步刷盘**，而非 Kafka 强制刷盘，以获取最佳性能 。
###### 6. 如何优化 Kafka 的网络传输？
网络是集群节点和客户端通信的桥梁。
1. **提升硬件带宽**：为 Broker 配置万兆网卡，确保交换机有足够带宽，避免网络成为瓶颈 。
2. **调整 Socket 缓冲区**：适当增大 `socket.send.buffer.bytes`和 `socket.receive.buffer.bytes`，允许更大的网络数据包传输，减少网络往返次数 。
3. **优化 TCP 参数**：在 Linux 系统层面，可启用 `tcp_nodelay`以减少小包的延迟，或调整 `tcp_nopush`等参数，优化 TCP 栈的行为 。
4. **减少网络跳数**：规划集群网络拓扑，尽量保证 Broker 节点之间以及客户端与 Broker 之间的网络路径最短，降低延迟 。
###### 7. Kafka 的消息压缩如何选择？
压缩在生产者端进行，是 CPU 计算与网络/磁盘 I/O 的权衡。

|**压缩算法**​|**压缩率**​|**CPU 开销**​|**速度**​|**推荐场景**​|
|---|---|---|---|---|
|**gzip**​|高|高|慢|网络带宽极其受限，可接受较高延迟。|
|**snappy**​|中等|低|快|**追求低延迟**的实时场景。|
|**lz4**​|中等|很低|非常快|**通用场景的平衡之选**，性能表现均衡 。|
|**zstd**​|很高|中等|快|追求高压缩比且 CPU 资源尚可，如数据归档 。|
**配置**：在生产者端设置 `compression.type=lz4`。Broker 端会保持消息的压缩状态存储和传输，直到消费者端解压，从而节省全程的带宽和存储。
###### 8. 如何监控 Kafka 的性能指标？
完善的监控是发现瓶颈和保障稳定的前提。
1. **核心监控指标**：
    - **吞吐量**：`messages-in/bytes-in`（写入），`messages-out/bytes-out`（读取）。
    - **延迟**：`Request latency`（Broker 处理请求时间），`Records-lag`（消费者滞后消息数）。
    - **Broker 指标**：CPU 使用率、磁盘使用率、网络流量、Under Replicated Partitions（未完全同步的分区数）。
    - **JVM 指标**：堆内存使用率、GC 频率和时长 。
2. **常用监控工具**：
    - **JMX**：Kafka 将大量指标通过 JMX 暴露，是监控数据的基础来源。
    - **Prometheus + Grafana**：行业标准方案。使用 `JMX Exporter`采集 JMX 指标，由 Prometheus 抓取和存储，最后在 Grafana 上构建可视化仪表盘 。
    - **Kafka 自带工具**：如 `kafka-consumer-groups.sh`脚本可查看消费组滞后情况。
###### 9. Kafka 的日志清理策略有哪些？
日志清理策略针对的是 Kafka 的存储日志文件（非应用日志）。

|**策略**​|**机制**​|**适用场景**​|
|---|---|---|
|**delete（默认）**​|基于时间（`log.retention.hours`）或大小（`log.retention.bytes`）删除旧的日志段文件。|大多数消息流场景，如日志收集、事件流。|
|**compact**​|为每个消息 Key 保留最新版本的值。删除过期的旧版本，只保留当前状态。|用于保存**可变数据的最新状态**，如数据库变更记录、用户会话状态 。|
**配置**：通过 `log.cleanup.policy`参数设置。
###### 10. 如何设置 Kafka 的数据保留时间？
数据保留时间由 `delete`清理策略控制。
- **基于时间**：通过 `log.retention.hours`设置（默认 168 小时，即 7 天）。也可使用 `log.retention.minutes`或 `log.retention.ms`进行更精细的控制 。
- **基于大小**：通过 `log.retention.bytes`设置 Topic 所有分区保留的总字节数。此为全局限制，会优先被触发。
    **最佳实践**：保留策略应根据业务需求设定。例如，用于实时计算的流数据可能只需保留几小时，而用于审计或回溯的数据可能需要保留数天甚至数周。同时要确保磁盘容量足以支撑保留期内的数据总量 。