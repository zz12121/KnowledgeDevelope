###### 1. 如何提高 RabbitMQ 的性能？
提升 RabbitMQ 性能需要从**架构设计、资源配置、消息流控制**等多个层面进行系统优化。
- **队列设计与规划**
    - **多队列利用多核**：RabbitMQ 中，**一个队列由单个 Erlang 进程处理**。通过创建多个队列，可以将负载分布到不同的 CPU 核心上，从而显著提升集群的整体吞吐量。
    - **控制队列数量与长度**：虽然多队列能提升并发，但过多的队列会对 CPU 和内存造成压力，并影响管理接口的响应速度。同时，应避免队列中堆积过多消息，因为当内存达到阈值时，RabbitMQ 会进行 `paging`（将内存中的消息刷到磁盘），这个过程会严重阻塞队列，导致性能骤降。
- **连接与信道管理**
    - 建立 TCP 连接是高开销操作（至少 7 个 TCP 包）。**最佳实践是一个应用进程只维护一个持久化的 Connection**。
    - 在 Connection 上创建多个轻量的 **Channel**​ 供不同线程使用（但信道本身不应跨线程共享）。避免为每条消息创建和关闭信道。
- **消息传递优化**
    - **批量发布**：将多条消息合并为一个批次发送，可以有效减少网络往返次数。
    - **消息大小权衡**：极端化的小消息或大消息都可能成为瓶颈。一种折中方案是生产者将多条小消息封装成一条大消息，由消费者解包处理，但需权衡失败重传的成本。
    - **慎用持久化与确认**：消息持久化（写入磁盘）和 Publisher Confirm/Consumer ACK 机制都会带来性能开销。在追求极致吞吐且可容忍消息丢失的场景下，可考虑禁用它们。
- **系统层面调优**
    - **Erlang 虚拟机优化**：对于多核机器，增加 Erlang 异步线程池大小（如 `+A 100`）有助于提升 I/O 性能。启用 HiPE 编译也能带来显著性能提升。
    - **资源限制监控**：合理设置内存水位线（`vm_memory_high_watermark`）和磁盘空间阈值（`disk_free_limit`），并通过 Prometheus 等工具持续监控，避免服务因资源耗尽而阻塞或中断。
###### 2. 说说 RabbitMQ 优先级队列
优先级队列允许**高优先级的消息优先被消费**，适用于需要区分消息处理紧急程度的业务场景。
- **工作原理**：RabbitMQ 的优先级队列内部使用多个子队列（或类似有序结构）实现。当消息到达时，会根据其优先级属性被放入对应的子队列。消费者获取消息时，Broker 会优先从最高优先级的非空子队列中取出消息。**注意，这并非完全的严格排序，尤其是在高并发或多消费者场景下可能有细微偏差，但能保证高优先级消息总体上先于低优先级消息被处理**。
- **配置与使用**
    1. **声明优先级队列**：在创建队列时，必须通过 `x-max-priority`参数指定队列支持的最大优先级。**该值建议设置在 1 到 10 之间**，过高的最大值会增加不必要的排序开销。
        ```java
        Map<String, Object> args = new HashMap<>();
        args.put("x-max-priority", 10); // 启用优先级，支持 0-10 共11个级别
        channel.queueDeclare("priority_queue", true, false, false, args);
        ```
    2. **发送优先级消息**：在发布消息时，通过 `priority`属性设置本条消息的优先级。
        ```java
        AMQP.BasicProperties props = new AMQP.BasicProperties.Builder()
            .priority(5) // 设置优先级为5
            .build();
        channel.basicPublish("", "priority_queue", props, message.getBytes());
        ```
- **使用场景与最佳实践**
    - **典型场景**：VIP 用户订单优先处理、系统告警消息即时响应、关键任务插队执行。
    - **注意事项**：
        - **`x-max-priority`不可动态修改**，需删除队列后重新设置。
        - 优先级队列会带来额外的 **CPU 和内存开销**。
        - **Quorum 队列暂不支持优先级**功能。
        - 避免过度使用高优先级，否则会失去“优先”的意义。建议制定明确的优先级定义规范（如 P0=紧急告警，P5=普通订单）。
###### 3. 什么是消息批量发送？如何实现？
消息批量发送是指**生产者将多条消息累积起来，合并成一次网络请求发送给 Broker**，以此减少网络调用次数，显著提升发布吞吐量。
- **实现方式**
    - **客户端批量**：在生产者应用层维护一个缓冲区，当消息数量达到一定阈值或等待时间超时时，将缓冲区的所有消息通过一个 Channel 一次性发送。这种方式灵活，但需要自行实现缓冲和重试逻辑。
    - **框架批量**：一些高级客户端或框架（如 Spring AMQP 的 `BatchingRabbitTemplate`）提供了内置的批量支持，简化了操作。
- **Java 代码示例（模拟客户端批量）**
    ```java
    public class BatchProducer {
        private Channel channel;
        private List<String> messageBatch = new ArrayList<>();
        private final int BATCH_SIZE = 50;
        private final long MAX_DELAY = 100; // 毫秒
    
        public void sendMessage(String message) throws Exception {
            messageBatch.add(message);
            // 如果达到批次大小或超时，则发送
            if (messageBatch.size() >= BATCH_SIZE || 
                System.currentTimeMillis() - lastSendTime > MAX_DELAY) {
                publishBatch();
            }
        }
    
        private void publishBatch() throws Exception {
            if (messageBatch.isEmpty()) return;
            // 开启事务或使用 Publisher Confirm 确保批量发送的可靠性
            channel.txSelect();
            for (String msg : messageBatch) {
                channel.basicPublish("exchange", "routingKey", null, msg.getBytes());
            }
            channel.txCommit(); // 或等待所有消息的 Confirm 确认
            messageBatch.clear();
        }
    }
    ```
- **权衡与优化**
    - **优点**：大幅减少网络 IO，提升生产者吞吐量。
    - **缺点**：**增加了延迟**，因为要等待凑够一批消息。如果某条消息发送失败，可能需要整个批次重试。需要根据业务对实时性和可靠性的要求，调整 `BATCH_SIZE`和 `MAX_DELAY`参数。
###### 4. 如何避免消息积压？
消息积压的根本原因是**消费速度跟不上生产速度**。解决之道在于“开源节流”。
- **提升消费能力（开源）**
    - **增加消费者**：最直接的方法。可以启动多个消费者实例，形成竞争消费模式。确保**消费者实例数不超过队列数**，否则会有空闲消费者。
    - **优化消费者逻辑**：检查并优化消费端的业务代码，避免耗时的同步操作（如复杂的计算、同步的数据库或 RPC 调用）。考虑使用异步处理或并行处理。
    - **批量消费**：如果业务允许，配置消费者一次拉取多条消息进行处理（如设置 `prefetchCount`> 1 并进行批量数据库写入），可以减少网络交互和设备 IO 次数。
- **控制生产流量（节流）**
    - **队列长度限制**：通过设置队列的 `x-max-length`（最大消息数）或 `x-max-length-bytes`（最大容量），当队列满时，新的消息会被拒绝或成为死信，从而从源头抑制生产速度，保护 Broker。
    - **生产端限流**：在生产者端实现速率限制，平滑发送流量，避免突发流量冲垮队列。
- **使用惰性队列**：对于可能产生大量积压且对消费实时性要求不高的场景，将队列设置为惰性队列（Lazy Queue），可以让消息直接存储在磁盘，极大减轻内存压力，避免 `paging`操作对性能的冲击。
###### 5. 惰性队列（Lazy Queue）是什么？
惰性队列是 RabbitMQ 的一种队列模式，其核心特征是**消息在进入队列时，立即被写入磁盘，而不是尽量保留在内存中**。
- **工作模式对比**
    - **默认队列**：消息优先保存在内存中，只有在内存压力达到阈值时，才会将一部分老消息刷到磁盘（`paging`）。
    - **惰性队列**：消息直接持久化到磁盘，消费时才会被加载到内存。这相当于绕开了 `paging`过程。
- **优缺点与适用场景**
    - **优点**：**极大地降低了内存使用率**，使队列能够稳定地处理海量消息堆积，避免了因 `paging`引起的性能抖动。
    - **缺点**：**吞吐量会下降**，因为每次读写都涉及磁盘 I/O（尽管有优化）。
    - **适用场景**：**需要处理可能产生大量积压的消息**，例如日志收集、离线任务、审计日志等对消费延迟不敏感的场景。
- **如何设置**
    - **策略方式（推荐）**：通过设置 Policy，将 `queue-mode`设置为 `lazy`。
        ```bash
        rabbitmqctl set_policy Lazy "^lazy-queue$" '{"queue-mode":"lazy"}' --apply-to queues
        ```
    - **声明参数**：在代码中声明队列时指定。
        ```java
        Map<String, Object> args = new HashMap<>();
        args.put("x-queue-mode", "lazy");
        channel.queueDeclare("lazy.queue", true, false, false, args);
        ```
###### 6. 如何优化内存使用？
RabbitMQ 的内存优化是保证其稳定运行的关键。
- **核心机制：内存水位线与 Paging**
    RabbitMQ 通过 `vm_memory_high_watermark`设置内存警戒线。当使用量超过此阈值，它会触发流控，阻塞生产者，并开始 **`paging`**：将内存中的消息（`alpha`状态）持久化到磁盘（转为 `beta`或 `gamma`状态）。频繁的 `paging`会严重影响性能。
- **优化策略**
    1. **控制消息堆积**：保持较短的队列长度是减少内存使用的根本办法。设置 `x-max-length`或消息 TTL 自动清理旧消息。
    2. **使用惰性队列**：对于允许消息积压的场景，使用惰性队列可从根本上避免内存压力和 `paging`。
    3. **限制未确认消息**：所有已发送给消费者但未被确认（ACK）的消息都暂存在内存中。通过设置合理的 `prefetchCount`来限制每个消费者未确认消息的数量，防止消费者故障导致内存溢出。
    4. **调整水位线**：根据服务器总内存和业务负载，合理设置 `vm_memory_high_watermark`（如 0.6-0.7），为系统和其他进程预留足够空间。在资源受限环境中，可使用绝对值配置。
    5. **监控与告警**：密切监控 `rabbitmq_memory_usage`等指标，提前发现内存增长趋势并干预。
###### 7. 流量控制（Flow Control）是什么？
RabbitMQ 的流量控制是一种**防止生产者压垮 Broker 或消费者的内部背压机制**。
- **源码与原理：基于信用证的算法**
    - 在 RabbitMQ 内部，如 `rabbit_channel`和 `rabbit_amqqueue_process`等核心进程之间，通信并非直接进行，而是采用了一种类似 TCP 流控的“信用证”机制。
    - 每个消息处理进程（如队列进程）会赋予消息发送进程（如信道进程）一个初始信用（`InitialCredit`）。发送进程每发送一条消息，信用减 1。当信用为 0 时，发送进程会被阻塞。接收进程每处理完一定数量的消息（`MoreCreditAfter`），会向发送进程返还信用，使其能够继续发送。
    - 这个机制从内部链路层面确保了消息的处理速度能够反向制约消息的流入速度，最终将压力传递到生产者，使其放慢发送速率，从而保障系统的稳定性。
###### 8. 如何设置合理的 Prefetch Count？
`prefetchCount`是**消费者端最重要的流量控制参数**，它定义了信道级别上，消费者最多能同时接收多少条未被确认的消息。
- **设置原则**
    1. **公平分发**：如果所有消费者的处理能力相近，且消息处理是 CPU 密集型或需要独占资源，将 `prefetchCount`设为 `1`。这能保证每个消费者一次只处理一条消息，实现严格的轮询（round-robin）式公平分发。
    2. **提高吞吐**：如果消息处理涉及大量 I/O 等待（如网络调用、数据库查询），可以设置一个较大的 `prefetchCount`（如 50-300）。这样消费者可以在等待一条消息的 I/O 响应时，去处理其他已预取的消息，提高资源利用率和吞吐量。一个简单的估算公式是：`吞吐量 * 网络往返耗时（RTT）`。
    3. **避免内存溢出**：过大的 `prefetchCount`会导致大量消息堆积在消费者客户端，可能引起客户端内存溢出（OOM）。
- **Java 代码配置**
    ```java
    Channel channel = ...;
    // 设置每个消费者最多同时预取 10 条消息
    channel.basicQos(10);
    // 或者设置为信道级别（该信道下所有消费者共享10个消息的配额）
    // channel.basicQos(10, true);
    ```