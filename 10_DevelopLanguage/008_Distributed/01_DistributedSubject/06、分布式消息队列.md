###### 1. 什么是消息队列？有什么作用？
消息队列是**分布式系统中实现应用间异步通信的中间件技术**，其核心是在消息传输过程中提供临时存储的容器。它采用生产者-消费者模型，生产者发送消息到队列，消费者从队列获取并处理消息，二者在时间上解耦。
**核心作用**：
- **异步处理**：生产者发送消息后无需等待消费者立即处理，提升系统响应速度。
- **系统解耦**：通过消息队列连接不同系统，降低系统间直接依赖，例如订单系统与库存系统通过队列通信，避免接口级耦合。
- **流量削峰**：在高并发场景下（如秒杀），消息队列作为缓冲区暂存请求，平滑流量峰值，防止系统过载。
- **消息通讯**：支持点对点或发布订阅模式，实现应用间数据传递。
###### 2. 消息队列的应用场景有哪些？
- **异步处理场景**：用户注册后，发送邮件和短信通知可通过消息队列异步执行，缩短主流程响应时间。
- **应用解耦场景**：电商系统中，订单服务完成下单后，将消息写入队列，库存服务异步消费，避免服务间直接调用导致的耦合与故障传递。
- **流量削锋场景**：秒杀活动中，瞬时高并发请求先写入消息队列，后端服务按处理能力消费，避免系统崩溃。
- **日志处理**：使用Kafka接收分布式系统日志，供流处理平台（如Storm）或日志分析系统（如ELK）消费。
- **消息通讯**：实现点对点通信或聊天室等实时交互场景。
###### 3. 如何保证消息不丢失？
消息不丢失需在**生产者、Broker、消费者**三个层面协同保障：
- **生产者层面**：
    - **确认机制**：RabbitMQ提供`publisher confirm`机制，Kafka可配置`acks=all`，确保消息成功写入Broker并复制到多数副本。
    - **事务消息**：如Kafka的事务消息机制，保证发送操作原子性。
    - **本地存储与重试**：重要消息先持久化到本地数据库或文件，配合定时任务重试。
- **Broker层面**：
    - **持久化机制**：RabbitMQ将队列和消息设置为持久化（`deliveryMode=2`），Kafka通过日志分段存储消息并同步刷盘。
    - **集群与副本**：RabbitMQ镜像队列、Kafka多副本机制确保单点故障时数据不丢失。
- **消费者层面**：
    - **手动确认**：关闭自动提交，处理完成后手动ACK。以RabbitMQ为例：
        ```java
        channel.basicConsume(queueName, false, (consumerTag, delivery) -> {
            try {
                processMessage(delivery.getBody());
                channel.basicAck(delivery.getEnvelope().getDeliveryTag(), false);
            } catch (Exception e) {
                channel.basicNack(delivery.getEnvelope().getDeliveryTag(), false, true);
            }
        });
        ```
    - **幂等性与重试**：消费者设计幂等逻辑，避免重复消费导致数据错乱。
###### 4. 如何保证消息不重复消费？
**重复消费的根源**：网络重传、消费者重启或负载均衡导致消息重复投递。
**解决方案**：
- **幂等性设计**：
    - **唯一标识**：为每条消息分配唯一ID（如业务主键），消费前检查数据库或Redis中是否存在记录。
    - **数据库约束**：利用数据库唯一索引防重。
    - **乐观锁**：通过版本号控制并发更新。
- **消息去重**：
    - **Broker端去重**：RocketMQ支持服务端去重，基于消息Key过滤重复消息。
    - **消费者端去重**：使用Redis Set或布隆过滤器判断消息是否已处理。
- **事务消息**：如RocketMQ的二次确认机制，确保本地事务与消息发送原子性。
###### 5. 如何保证消息的顺序性？
**顺序性场景**：订单创建、支付、发货等操作需严格顺序执行。
- **RabbitMQ**：单队列单消费者保证顺序，但吞吐量低。可通过业务字段（如订单ID）哈希路由到同一队列。
- **Kafka**：
    - **分区内有序**：同一分区内消息按偏移量顺序存储，需将顺序消息发送到同一分区（通过指定Key实现）。
    - **单分区单消费者**：一个分区仅由一个消费者处理，避免多消费者并发乱序。
- **RocketMQ**：通过`MessageQueueSelector`将顺序消息投递到同一队列。
**源码角度**：Kafka生产者通过`Partitioner`计算目标分区，默认策略是对Key进行哈希，相同Key的消息落入同一分区。
###### 6. 消息积压怎么处理？
消息积压指**消费速度跟不上生产速度**，导致队列中消息堆积。
**应急处理**：
- **扩容消费者**：增加消费者实例或分区数，提升并发处理能力。
- **批量消费**：优化消费者逻辑，支持批量处理消息（如Kafka的`max.poll.records`配置）。
- **降级处理**：非核心消息可跳过或异步处理，优先保障核心业务。
- **临时存储**：将积压消息转存至高速存储（如Redis）后异步消化。
**根因治理**：
- **优化消费逻辑**：避免耗时操作（如复杂计算、同步DB写入），改用异步或批量处理。
- **监控告警**：设定积压阈值，及时触发告警。
###### 7. 什么是消息的持久化？
消息持久化是**将消息保存到磁盘**，防止Broker重启或崩溃时数据丢失。
- **RabbitMQ**：
    - **队列持久化**：声明队列时设置`durable=true`。
    - **消息持久化**：发送消息时设置`deliveryMode=2`。
    - **日志持久化**：通过事务日志保证操作原子性。
- **Kafka**：所有消息持久化到磁盘日志文件，通过分段（Segment）和索引机制优化读写性能。
- **性能权衡**：持久化降低写入速度，可通过批量刷盘（如Kafka的`flush.interval.ms`）平衡性能与可靠性。
###### 8. RabbitMQ 的工作模式有哪些？
- **简单模式**：单生产者、单队列、单消费者，无路由逻辑。
- **工作队列模式**：单队列多消费者，通过轮询或公平分发实现负载均衡。
- **发布订阅模式**：通过交换机（Exchange）广播消息到所有绑定队列。
- **路由模式**：使用`Direct`交换机，基于路由键精确匹配队列。
- **主题模式**：使用`Topic`交换机，支持通配符（`*`、`#`）匹配路由键。
- **RPC模式**：利用回调队列实现远程过程调用。
###### 9. Kafka 的架构是怎样的？
Kafka采用**分布式提交日志架构**，核心组件包括：
- **Producer**：消息生产者，通过`Partitioner`选择分区。
- **Broker**：Kafka服务实例，负责消息存储和转发。
- **Topic**：逻辑消息类别，分为多个分区（Partition）。
- **Partition**：分区是物理存储单元，每个分区内消息有序，支持并行处理。
- **Consumer**：消费者，以组（Group）形式协作，组内消费者分摊分区。
- **ZooKeeper**：管理集群元数据（如Broker列表、分区领导者选举）。
- **数据流**：生产者向Topic发送消息，根据分区策略写入特定分区；消费者组订阅Topic，每个消费者分配若干分区，从分区拉取消息处理。
###### 10. Kafka 如何保证高吞吐量？
- **顺序读写**：利用磁盘顺序访问特性，避免随机I/O瓶颈。
- **页缓存**：通过操作系统页缓存减少磁盘直接访问。
- **批量处理**：生产者批量发送消息（`linger.ms`、`batch.size`），消费者批量拉取。
- **零拷贝**：使用`sendfile`系统调用，减少内核态与用户态数据拷贝。
- **分区并行**：多分区设计支持生产与消费并行化。
- **压缩传输**：支持Snappy、GZIP等压缩算法减少网络开销。
###### 11. 什么是 Kafka 的 ISR 机制？
ISR（In-Sync Replicas）是**与领导者副本保持同步的副本集合**，用于平衡一致性可用性。
- **机制原理**：
    1. 每个分区有一个领导者副本和多个追随者副本。
    2. 追随者定期从领导者拉取消息更新自身日志。
    3. 追随者与领导者差距在阈值内（`replica.lag.time.max.ms`）时，加入ISR。
    4. 消息提交需被ISR中所有副本确认，确保数据一致性。
- **容错处理**：若追随者滞后或失效，被移出ISR；恢复后重新追赶，达标后重新加入。
###### 12. RocketMQ 的事务消息如何实现？
RocketMQ通过**二阶段提交**保证分布式事务最终一致性：
1. **半消息阶段**：生产者发送半消息（对消费者不可见），RocketMQ持久化并返回发送结果。
2. **本地事务执行**：生产者执行本地事务（如更新数据库），并记录事务状态。
3. **事务状态回查**：
    - 若生产者未提交或回滚事务，RocketMQ定时回查生产者确认状态。
    - 生产者根据本地事务结果回复提交或回滚指令。
4. **消息投递**：若提交，消息对消费者可见；若回滚，消息丢弃。
**Java示例**：
```java
TransactionMQProducer producer = new TransactionMQProducer("group");
producer.setTransactionListener(new TransactionListener() {
    @Override
    public LocalTransactionState executeLocalTransaction(Message msg, Object arg) {
        // 执行本地事务
        return LocalTransactionState.COMMIT_MESSAGE;
    }
    @Override
    public LocalTransactionState checkLocalTransaction(MessageExt msg) {
        // 回查本地事务状态
        return LocalTransactionState.COMMIT_MESSAGE;
    }
});
```
###### 13. 什么是死信队列？
死信队列是**用于存储处理失败或过期消息的特殊队列**。
- **触发条件**：
    - 消息被消费者拒绝且未重新入队。
    - 消息过期（TTL超时）。
    - 队列达到最大长度。
- **作用**：
    - **故障隔离**：避免异常消息阻塞正常队列。
    - **重试机制**：结合重试策略实现延迟重试。
    - **审计分析**：记录失败消息供后续排查。
**RabbitMQ配置示例**：
```java
// 声明死信交换器与队列
channel.exchangeDeclare("dlx_exchange", "direct");
channel.queueDeclare("dead_letter_queue", true, false, false, null);
channel.queueBind("dead_letter_queue", "dlx_exchange", "dead_letter");

// 主队列绑定死信交换器
Map<String, Object> args = new HashMap<>();
args.put("x-dead-letter-exchange", "dlx_exchange");
args.put("x-dead-letter-routing-key", "dead_letter");
channel.queueDeclare("main_queue", true, false, false, args);
```