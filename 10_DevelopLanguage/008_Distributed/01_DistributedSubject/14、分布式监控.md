###### 1. 分布式系统监控的指标有哪些？
一个完善的分布式系统监控体系需要覆盖从基础设施到业务逻辑的多个层面，指标主要分为以下几类：
**1. 系统资源指标**：
- **CPU**：使用率、负载（Load Average）、上下文切换次数。
- **内存**：使用量、剩余量、Swap使用情况、页错误率。
- **磁盘**：I/O吞吐量、读写延迟、使用率、inode使用情况。
- **网络**：带宽使用率、TCP连接数（ESTABLISHED, TIME_WAIT）、丢包率、重传率、网络延迟。
**2. 应用运行时指标（以JVM为例）**：
- **堆内存**：Eden、Survivor、Old Gen的使用情况。
- **垃圾回收**：GC次数、GC耗时（Young GC, Full GC）、回收效率。
- **线程**：活跃线程数、阻塞线程数、死锁检测。
- **类加载**：已加载类数量、卸载类数量。
**3. 微服务与中间件指标**：
- **服务可用性**：实例健康状态（UP/DOWN）。
- **流量与吞吐**：QPS（每秒请求数）、TPS（每秒事务数）。
- **响应性能**：平均响应时间、分位值响应时间（P95, P99）、最大响应时间。
- **错误与异常**：错误率（HTTP 5xx比例）、异常抛出次数、超时次数。
- **依赖服务**：对下游服务（如数据库、缓存、其他微服务）调用的成功率、延迟。
- **中间件**：数据库连接池活跃连接数、Redis缓存命中率、消息队列堆积数。
**4. 业务指标**：
- **核心流程**：订单创建成功率、支付成功率、登录UV/PV。
- **业务量**：每秒订单数、新增用户数、活跃用户数（DAU/MAU）。
- **用户体验**：关键页面加载时间、API成功率（从用户端感知）。
**5. 分布式系统特有指标**：
- **一致性**：副本同步延迟（如MySQL主从延迟、Redis主从偏移量）。
- **分布式协调**：ZooKeeper/etcd的请求延迟、Watch数量。
- **数据分片**：Elasticsearch分片状态、Kafka分区Leader切换次数。
这些指标共同构成了系统的可观测性基础，通过它们可以快速定位瓶颈、预测容量和诊断故障。
###### 2. Prometheus 的工作原理是什么？
Prometheus 是一个基于**拉取模型**的开源系统监控和告警工具包。其核心架构和工作原理如下：
**1. 数据模型**：
- 所有数据都存储为**时间序列**，即带有时间戳的数值流。
- 每个时间序列由**指标名称**和一组**键值对标签**唯一标识。例如：`http_requests_total{method="POST", handler="/api/users", status="200"}`。这种多维数据模型是其强大查询能力的基础。
**2. 核心组件与工作流程**：
- **目标发现与抓取**：Prometheus Server 周期性地（通过 `scrape_interval`配置）根据配置（静态文件或动态服务发现，如Kubernetes, Consul）中的目标列表，主动发起HTTP请求（默认为 `/metrics`端点）来**拉取**指标数据。
- **指标暴露**：被监控目标需要运行一个 **HTTP服务**​ 来暴露符合Prometheus格式的指标。这通常通过客户端库（如 `prometheus/client_java`）在应用中集成，或通过导出器（如 `node_exporter`用于机器指标）实现。
- **存储**：抓取到的样本（时间戳-数值对）首先存储在内存中，并定期以块的形式持久化到磁盘。其自研的本地时序数据库（TSDB）采用自定义格式，针对高吞吐写入和按时间范围查询进行了优化。
- **查询**：通过强大的查询语言 **PromQL**，用户可以实时查询、聚合和分析这些时间序列数据。
- **告警**：`Alertmanager`组件负责处理由Prometheus Server根据 `alerting rules`触发的告警，进行去重、分组、抑制，并通过邮件、钉钉、Webhook等路由发送。
**源码角度**：
- 抓取器的核心逻辑在 `scrape.Manager`和 `scrape.Scraper`中。`Scraper`的 `scrape`方法会发起HTTP请求，并通过 `textParser`解析返回的文本指标。
- TSDB的核心是 `tsdb`包。数据在内存中存储在 `headBlock`里，其结构是一个包含所有序列的Map和一系列用于样本的 `memSeries`对象。持久化时，数据被写入按时间分片的块中，每个块包含索引文件和数据文件。索引使用倒排索引来根据标签快速定位序列，数据文件使用内存映射（mmap）进行高效读取。
###### 3. Grafana 是如何与 Prometheus 配合使用的？
Grafana 是一个开源的数据可视化和监控平台，它与 Prometheus 形成了经典的监控组合：**Prometheus 负责数据的采集与存储，Grafana 负责数据的展示与告警可视化**。
**配合工作流程**：
1. **数据源配置**：在 Grafana 的 Web UI 中，添加 Prometheus 作为一个数据源。需要配置 Prometheus Server 的 HTTP 地址（如 `http://prometheus:9090`）。
2. **创建仪表盘**：用户可以在 Grafana 中创建仪表盘，每个仪表盘由多个**面板**组成。
3. **面板查询**：在每个面板的编辑器中，通过编写 **PromQL**​ 查询语句，从已配置的 Prometheus 数据源中提取特定的时间序列数据。例如，绘制所有实例的CPU使用率：`100 - (avg by (instance) (rate(node_cpu_seconds_total{mode="idle"}[5m])) * 100)`。
4. **可视化渲染**：Grafana 将 Prometheus 返回的时序数据，以用户选择的图形（如图表、仪表、表格、热图等）渲染出来，并支持灵活的时间范围选择、自动刷新和模板变量。
5. **告警集成**：
    - **方式一（旧）**：在 Grafana 面板上直接定义告警规则，当数据满足条件时，Grafana 会发送通知。
    - **方式二（推荐）**：告警规则在 **Prometheus**​ 端定义，由 `Alertmanager`负责发送。Grafana 可以配置 `Alertmanager`为数据源，在其“警报”页面集中管理和查看所有告警的状态，提供更统一的视图。
**优势**：这种解耦设计让两者各司其职。Prometheus 专注于成为强大、可靠的数据引擎，而 Grafana 则提供了无与伦比的图表美观度和灵活的仪表盘管理能力，并可以同时连接多种数据源（如 MySQL、Elasticsearch、Loki），实现数据关联分析。
###### 4. 什么是 APM（应用性能监控）？
APM 是指对软件应用程序及其底层基础设施的性能、可用性、用户体验进行监控、管理和诊断的实践与技术体系。它超越了基础资源监控（CPU、内存），深入到**应用代码内部**，旨在回答“为什么我的应用慢了？”或“错误发生在哪一行代码？”。
**APM 的核心支柱（三大维度）**：
1. **指标**：量化应用性能的数值，如吞吐量（TPS/QPS）、响应时间（平均、P95）、错误率、JVM GC次数、数据库连接池使用率等。这些是判断系统是否健康的“体温计”。
2. **链路追踪**：记录一个**端到端的用户请求**（例如，从手机APP点击到后端数据库查询）在分布式系统中流经的所有服务和服务内部组件的完整路径。通过 **TraceId**​ 和 **SpanId**​ 还原调用拓扑，精确定位慢调用或故障点。
3. **日志**：应用程序运行时产生的结构化或非结构化文本事件记录。现代APM强调**日志与链路追踪的关联**，通过将 TraceId 注入到日志中，可以快速从错误日志定位到具体的请求链路。
**APM 与基础监控的区别**：
- **基础监控**：关注“机器是否活着”、“资源是否够用”。（What：CPU高了）
- **APM**：关注“业务交易是否成功”、“用户体验是否良好”、“代码哪里慢了”。（Why：因为订单服务的某个DAO方法执行了慢SQL，导致CPU高）
**主流APM工具**：包括之前提到的 SkyWalking、Pinpoint，以及商业版的 New Relic、AppDynamics、Dynatrace。它们通常通过**字节码增强**（无侵入）或**SDK埋点**（侵入式）的方式自动收集指标和链路数据。
###### 5. 如何设计一个分布式监控系统？
设计一个生产级的分布式监控系统，需要遵循可观测性理念，并平衡功能性、性能、可靠性和可维护性。其核心架构通常分为五层：
**1. 数据采集层**：
- **代理模式**：在被监控主机或容器内部署轻量级代理（如 `Prometheus Node Exporter`, `Telegraf`），负责收集系统、应用和自定义指标。
- **无侵入探针**：对于应用性能监控，采用 Java Agent（如SkyWalking Agent）进行字节码增强，自动收集JVM指标和调用链。
- **日志收集器**：使用 Filebeat、Fluentd 或 Logstash 从应用日志文件中采集、解析和结构化日志。
- **关键设计**：采集端应尽量轻量，支持批量和压缩上报，具备本地缓存和断点续传能力。
**2. 数据传输与聚合层**：
- **推 vs 拉模型**：指标监控常用**拉模型**（Prometheus）以简化客户端，但超大规模时可采用**推模型**，通过消息队列（如 Kafka）进行削峰填谷和异步传输。日志和追踪数据通常采用推模型。
- **聚合与采样**：对于高基数或高频率数据（如全量访问日志），需要在传输前进行聚合或采样，以降低后端存储压力。
**3. 数据存储层**：
- **时序数据**：使用专门的时序数据库，如 Prometheus TSDB（短期）、VictoriaMetrics、InfluxDB 或 TimescaleDB。它们对时间范围查询、数据压缩和过期策略有深度优化。
- **链路追踪数据**：通常存储在 Elasticsearch（支持全文搜索和复杂过滤）或 Jaeger 的 Cassandra/Elasticsearch 后端。
- **日志数据**：存储在 Elasticsearch 或 Loki（索引少、成本低）。
- **关键设计**：根据数据热度（热、温、冷）设计分层存储策略，将历史数据转移到对象存储（如 S3）以降低成本。
**4. 计算分析与查询层**：
- **实时计算**：对流入的指标流进行实时聚合、计算（如5分钟错误率）和异常检测。
- **查询引擎**：提供统一的查询接口或语言（如 PromQL），支持跨数据源关联查询（例如，通过 TraceId 同时查询链路和日志）。
**5. 可视化与告警层**：
- **可视化**：使用 Grafana 等工具，基于存储层的数据创建业务、技术全景仪表盘。
- **告警管理**：
    - **告警规则定义**：在数据层面（如Prometheus）定义基于指标的告警规则。
    - **告警处理中心**：使用独立的告警管理器（如 `Alertmanager`），负责告警的**去重**（避免重复通知）、**分组**（将相关告警合并为一条）、**抑制**（高级别告警触发时，抑制低级别告警）和**静默**。
    - **多渠道通知**：集成邮件、钉钉、企业微信、短信、电话、Webhook等。
- **自愈与联动**：高级系统中，告警可以自动触发预定义的修复动作（如重启Pod、扩容节点）。
**非功能性设计**：
- **可扩展性**：各层组件都应支持水平扩展。
- **高可用性**：关键组件无单点故障，存储有副本。
- **安全性**：数据传输加密，访问控制（RBAC）。
- **多租户**：支持按业务线或团队隔离数据和权限。