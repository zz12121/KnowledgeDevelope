```
技术自由圈
```
# 牛逼的职业发展之路

40 岁老架构尼恩用一张图揭秘: Java 工程师的高端职业发展路径，走向食物链顶端的之路

链接：https://www.processon.com/view/link/618a2b62e0b34d73f7eb3cd


```
技术自由圈^
```
# 史上最全：价值 10 W 的架构师知识图谱

此图梳理于尼恩的多个 3 高生产项目：多个亿级人民币的大型 SAAS 平台和智慧城市项目

链接：https://www.processon.com/view/link/60fb9421637689719d


```
技术自由圈
```
# 牛逼的架构师哲学

40 岁老架构师尼恩对自己的 20 年的开发、架构经验总结

链接：https://www.processon.com/view/link/616f801963768961e9d9aec


```
技术自由圈
```
# 牛逼的 3 高架构知识宇宙

尼恩 3 高架构知识宇宙，帮助大家穿透 3 高架构，走向技术自由，远离中年危机

链接：https://www.processon.com/view/link/635097d2e0b34d40be778ab


```
技术自由圈
```
# 尼恩 Java 面试宝典

40 个专题（卷王专供+ 史上最全 + 2023 面试必备）
详情：https://www.cnblogs.com/crazymakercircle/p/13917138.html


```
技术自由圈^
```
# 未来职业，如何突围：三栖架构师


## 专题 29 ：多线程面试题（史上最全、定期更

## 新）

#### 本文版本说明：V

```
此文的格式，由markdown 通过程序转成而来，由于很多表格，没有来的及调整，出现一个格式
问题，尼恩在此给大家道歉啦。
```
```
由于社群很多小伙伴，在面试，不断的交流最新的面试难题，所以，《尼恩Java面试宝典》， 后
面会不断升级，迭代。
```
```
本专题，作为 《尼恩Java面试宝典》专题之一， 《尼恩Java面试宝典》一共 41 个面试专题，后
续还会增加
```
###### 《Java 面试红宝书》升级的规划为：

后续基本上， **每一个月，都会发布一次** ，最新版本，可以扫描扫架构师尼恩微信，发送 “领取电子书”
获取。

尼恩的微信二维码在哪里呢 ？

具体可以百度搜索 **疯狂创客圈总目录**

###### V 66 版本

美团一面：Spring Cloud 如何构建动态线程池？

###### V 62 版本

网易一面：如何设计线程池？请手写一个简单线程池？

###### V 61 版本

美团一面：如何实现一个 100 W 级 ops 生产者、消费者程序？

###### V 60 版本

有赞一面：还有任务没执行，线程池被关闭怎么办？

###### V 40 版本

JD 一面：实现异步的 20 种方式，你知道几个？

###### 面试问题交流说明：

如果遇到面试难题，或者职业发展问题，或者中年危机问题，都可以来疯狂创客圈社群交流，

加入交流群，加尼恩微信即可，


**入交流群** ，加尼恩微信即可，发送 **“入群”**

#### 一：多线程基础题

###### 1 、什么是线程？

线程是操作系统能够进行运算调度的最小单位，它被包含在进程之中，是进程中的实际运作单位。

程序员可以通过它进行多处理器编程，你可以使用多线程对运算密集型任务提速。

比如，如果一个线程完成一个任务要 100 毫秒，那么用十个线程完成该任务只需 10 毫秒。

###### 2 、线程和进程有什么区别？

一个进程是一个独立 (self contained) 的运行环境，它可以被看作一个程序或者一个应用。而线程是在
进程中执行的一个任务。

线程是进程的子集，一个进程可以有很多线程，每条线程并行执行不同的任务。

不同的进程使用不同的内存空间，而所有的线程共享一片相同的内存空间。

每个线程都拥有单独的栈内存用来存储本地数据。

###### 3 、如何在 Java 中实现线程？

**（ 1 ）. 继承 Thread 类实现多线程**

继承 Thread 类, 然后重写 run 方法.（由于 Java 单继承的特性，这种方式用的比较少）

```
public class MyThread extends Thread {
public MyThread() {
```
```
}
public void run() {
for(int i=0;i<10;i++) {
System.out.println(Thread.currentThread()+":"+i);
}
}
public static void main(String[] args) {
MyThread mThread1=new MyThread();
MyThread mThread2=new MyThread();
MyThread myThread3=new MyThread();
mThread1.start();
mThread2.start();
myThread3.start();
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
```

**（ 2 ）. 实现 Runnable () 接口定制执行目标（target）类，实现其 run () 方法**

推荐此方式。两个特点：

```
a.覆写Runnable接口实现多线程可以避免单继承局限
b.实现Runnable()可以更好的体现共享的概念
c.当执行目标类实现Runnable接口，此时执行目标（target）类和Thread是代理模式（子类负责
真是业务的操作，thread负责资源调度与线程创建辅助真实业务。
```
**（ 3 ）. 实现 Callable 接口创建多线程（JDK 1.5）**

```
public class MyTarget implements Runnable{
public static int count=20;
public void run() {
while(count>0) {
try {
Thread.sleep(200);
} catch (InterruptedException e) {
e.printStackTrace();
}
System.out.println(Thread.currentThread().getName()+"-当前剩余票
数:"+count--);
}
}
public static void main(String[] args) {
MyThread target=new MyTarget();
Thread mThread1=new Thread(target,"线程1");
Thread mThread2=new Thread(target,"线程2");
Thread mThread3=new Thread(target,"线程3");
mThread1.start();
mThread2.start();
myThread3.start();
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
```
```
11
12
13
14
15
16
17
18
19
20
21
22
```
```
a.执行目标核心方法叫call()方法
b.有返回值
```
```
1
2
```
```
import java.util.concurrent.Callable;
import java.util.concurrent.ExecutionException;
import java.util.concurrent.FutureTask;
```
```
public class MyTarget implements Callable<String> {
private int count = 20;
```
```
@Override
public String call() throws Exception {
for (int i = count; i > 0; i--) {
// Thread.yield();
System.out.println(Thread.currentThread().getName()+"当前票数："
+ i);
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
```
```
13
```

**（ 4 ）. 通过线程池创建多线程**

请参见后面线程池的面试题。

###### 4 、继承 Thread 类或者实现 Runnable 接口来创建线程，有何区别？

这个问题是上题的后续，大家都知道我们可以通过继承 Thread 类或者调用 Runnable 接口来实现线程，
问题是，那个方法更好呢？什么情况下使用它？

```
提示：这个问题很容易回答。Java不支持类的多重继承，但允许你调用多个接口。所以如果你要
继承其他类，当然是调用Runnable接口好了。
```
参考答案，有两点：

```
a.覆写Runnable接口实现多线程可以避免单继承局限
b.实现Runnable()可以更好的体现共享的概念
```
###### 5 、 Thread 类中的 start () 和 run () 方法有什么区别？

start () 方法被用来启动新创建的线程，使该被创建的线程状态变为可运行状态。

当你直接调用 run () 方法的时候，只会是在原来的线程中调用，没有新的线程启动。只有调用 start () 方法
才会启动新线程。

如果我们调用了 Thread 的 run () 方法，它的行为就会和普通的方法一样，直接运行 run（）方法。为了在
新的线程中执行我们的代码，必须使用 Thread.start () 方法。

###### 6 、Java 中 Runnable 和 Callable 有什么不同？

Runnable 和 Callable 都代表那些要在不同的线程中执行的任务目标 target。

Runnable 从 JDK 1.0 开始就有了，Callable 是在 JDK 1.5 增加的。它们的主要区别是 Callable 的 call () 方法
可以返回值和抛出异常，而 Runnable 的 run () 方法没有这些功能。

```
return "sale out";
}
```
```
public static void main(String[] args) throws InterruptedException,
ExecutionException {
Callable<String> callable =new MyTarget();
FutureTask <String>futureTask=new FutureTask<>(callable);
Thread mThread=new Thread(futureTask);
Thread mThread2=new Thread(futureTask);
Thread mThread3=new Thread(futureTask);
// mThread.setName("hhh");
mThread.start();
mThread2.start();
mThread3.start();
System.out.println(futureTask.get());
```
```
}
}
```
```
14
15
16
17
```
```
18
19
20
21
22
23
24
25
26
27
28
29
30
```

###### 7 、线程的常用方法有哪些

```
1. Thread.sleep(long millis)，一定是当前线程调用此方法，当前线程进入TIMED_WAITING状态，但
不释放对象锁，millis后线程自动苏醒进入就绪状态。作用：给其它线程执行机会的最佳方式。
2. Thread.yield()，一定是当前线程调用此方法，当前线程放弃获取的CPU时间片，但不释放锁资
源，由运行状态变为就绪状态，让OS再次选择线程。作用：让相同优先级的线程轮流执行，但并
不保证一定会轮流执行。实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调
度程序再次选中。Thread.yield()不会导致阻塞。该方法与sleep()类似，只是不能由用户指定暂停
多长时间。
3. thread.join()/thread.join(long millis)，当前线程里调用其它线程t的join方法，当前线程进入
WAITING/TIMED_WAITING状态，当前线程不会释放已经持有的对象锁。线程t执行完毕或者millis
时间到，当前线程一般情况下进入RUNNABLE状态，也有可能进入BLOCKED状态（因为join是基
于wait实现的）。
4. obj.wait()，当前线程调用对象的wait()方法，当前线程释放对象锁，进入等待队列。依靠
notify()/notifyAll()唤醒或者wait(long timeout) timeout时间到自动唤醒。
5. obj.notify()唤醒在此对象监视器上等待的单个线程，选择是任意性的。notifyAll()唤醒在此对象监
视器上等待的所有线程。
6. LockSupport.park()/LockSupport.parkNanos(long nanos),LockSupport.parkUntil(long
deadlines), 当前线程进入WAITING/TIMED_WAITING状态。对比wait方法,不需要获得锁就可以让
线程进入WAITING/TIMED_WAITING状态，需要通过LockSupport.unpark(Thread thread)唤
醒。
```
###### 8) Java 内存模型是什么？

Java 内存模型规定和指引 Java 程序在不同的内存架构、CPU 和操作系统间有确定性地行为。它在多线程
的情况下尤其重要。Java 内存模型对一个线程所做的变动能被其它线程可见提供了保证，它们之间是先
行发生关系。这个关系定义了一些规则让程序员在并发编程时思路更清晰。比如，先行发生关系确保
了：

```
线程内的代码能够按先后顺序执行，这被称为程序次序规则。
对于同一个锁，一个解锁操作一定要发生在时间上后发生的另一个锁定操作之前，也叫做管程锁定
规则。
前一个对volatile的写操作在后一个volatile的读操作之前，也叫volatile变量规则。
一个线程内的任何操作必需在这个线程的start()调用之后，也叫作线程启动规则。
一个线程的所有操作都会在线程终止之前，线程终止规则。
一个对象的终结操作必需在这个对象构造完成之后，也叫对象终结规则。
可传递性
```
```
强烈建议大家阅读《Java高并发核心编程（卷 2 ）：多线程、锁、JMM、JUC、高并发设计模式》,
来加深对Java内存模型的理解。
```
###### 9) Java 中的 volatile 变量是什么？


volatile 是一个特殊的修饰符，只有成员变量才能使用它。在 Java 并发程序缺少同步类的情况下，多线程
对成员变量的操作对其它线程是透明的。volatile 变量可以保证下一个读取操作会在前一个写操作之后
发生。线程都会直接从内存中读取该变量并且不缓存它。这就确保了线程读取到的变量是同内存中是一
致的。

###### 11) 什么是线程安全？Vector 是一个线程安全类吗？

如果你的代码所在的进程中有多个线程在同时运行，而这些线程可能会同时运行这段代码。如果每次运
行结果和单线程运行的结果是一样的，而且其他的变量的值也和预期的是一样的，就是线程安全的。一
个线程安全的计数器类的同一个实例对象在被多个线程使用的情况下也不会出现计算失误。很显然你可
以将集合类分成两组，线程安全和非线程安全的。Vector 是用同步方法来实现线程安全的, 而和它相似
的 ArrayList 不是线程安全的。

###### 12) Java 中什么是竞态条件？

在大多数实际的多线程应用中，两个或两个以上的线程需要共享对同一数据的存取。如果 i 线程存取相同
的对象，并且每一个线程都调用了一个修改该对象状态的方法，将会发生什么呢？可以想象，线程彼此
踩了对方的脚。根据线程访问数据的次序，可能会产生讹误的对象。这样的情况通常称为竞争条件。

###### 13) Java 中如何停止一个线程？

Java 提供了很丰富的 API 但没有为停止线程提供 API。JDK 1.0 本来有一些像 stop (), suspend () 和
resume () 的控制方法，但是由于潜在的死锁威胁。因此在后续的 JDK 版本中他们被弃用了，之后 Java
API 的设计者就没有提供一个兼容且线程安全的方法来停止一个线程。当 run () 或者 call () 方法执行完的
时候线程会自动结束，如果要手动结束一个线程，可以用 volatile 布尔变量来退出 run () 方法的循环或者
是取消任务来中断线程。

###### 14) 一个线程运行时发生异常会怎样？

如果异常没有被捕获该线程将会停止执行。Thread. UncaughtExceptionHandler 是用于处理未捕获异常
造成线程突然中断情况的一个内嵌接口。

当一个未捕获异常将造成线程中断的时候，JVM 会使用 Thread.getUncaughtExceptionHandler () 来查询
线程的 UncaughtExceptionHandler 并将线程和异常作为参数传递给 handler 的 uncaughtException () 方
法进行处理。

###### 19) 什么是 FutureTask？

在 Java 并发程序中 FutureTask 表示一个可以取消的异步运算。它有启动和取消运算、查询运算是否完成
和取回运算结果等方法。只有当运算完成的时候结果才能取回，如果运算尚未完成 get 方法将会阻塞。
一个 FutureTask 对象可以对调用了 Callable 和 Runnable 的对象进行包装，由于 FutureTask 也是调用了
Runnable 接口所以它可以提交给 Executor 来执行。

###### 20) Java 中 interrupted 和 isInterruptedd 方法的区别？

interrupted () 和 isInterrupted () 的主要区别是前者会将中断状态清除而后者不会。Java 多线程的中断
机制是用内部标识来实现的，调用 Thread.interrupt () 来中断一个线程就会设置中断标识为 true。当中断
线程调用静态方法 Thread.interrupted () 来检查中断状态时，中断状态会被清零。而非静态方法
isInterrupted () 用来查询其它线程的中断状态且不会改变中断状态标识。简单的说就是任何抛出
InterruptedException 异常的方法都会将中断状态清零。无论如何，一个线程的中断状态有有可能被其
它线程调用中断来改变。


###### 23) Java 中的同步集合与并发集合有什么区别？

同步集合与并发集合都为多线程和并发提供了合适的线程安全的集合，不过并发集合的可扩展性更高。
在 Java 1.5 之前程序员们只有同步集合来用且在多线程并发的时候会导致争用，阻碍了系统的扩展性。
Java 5 介绍了并发集合像 ConcurrentHashMap，不仅提供线程安全还用锁分离和内部分区等现代技术提
高了可扩展性。更多内容详见答案。

###### 24 ） Java 中堆和栈有什么不同？

为什么把这个问题归类在多线程和并发面试题里？因为栈是一块和线程紧密相关的内存区域。每个线程
都有自己的栈内存，用于存储本地变量，方法参数和栈调用，一个线程中存储的变量对其它线程是不可
见的。而堆是所有线程共享的一片公用内存区域。对象都在堆里创建，为了提升效率线程会从堆中弄一
个缓存到自己的栈，如果多个线程使用该变量就可能引发问题，这时 volatile 变量就可以发挥作用了，
它要求线程从主存中读取变量的值。

###### 26 ） 如何写代码来解决生产者消费者问题？

在现实中你解决的许多线程问题都属于生产者消费者模型，就是一个线程生产任务供其它线程进行消
费，你必须知道怎么进行线程间通信来解决这个问题。比较低级的办法是用 wait 和 notify 来解决这个问
题，比较赞的办法是用 Semaphore 或者 BlockingQueue 来实现生产者消费者模型。

###### 27 ） 如何避免死锁？

Java 多线程中的死锁

死锁是指两个或两个以上的进程在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作
用，它们都将无法推进下去。这是一个严重的问题，因为死锁会让你的程序挂起无法完成任务，死锁的
发生必须满足以下四个条件：

```
互斥条件：一个资源每次只能被一个进程使用。
请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。
不剥夺条件：进程已获得的资源，在末使用完之前，不能强行剥夺。
循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系。
```
避免死锁最简单的方法就是阻止循环等待条件，将系统中所有的资源设置标志位、排序，规定所有的进
程申请资源必须以一定的顺序（升序或降序）做操作来避免死锁。

###### 28) Java 中活锁和死锁有什么区别？

这是上题的扩展，活锁和死锁类似，不同之处在于处于活锁的线程或进程的状态是不断改变的，活锁可
以认为是一种特殊的饥饿。一个现实的活锁例子是两个人在狭小的走廊碰到，两个人都试着避让对方好
让彼此通过，但是因为避让的方向都一样导致最后谁都不能通过走廊。简单的说就是，活锁和死锁的主
要区别是前者进程的状态可以改变但是却不能继续执行。

###### 29 ） 怎么检测一个线程是否拥有锁？

在 java. lang. Thread 中有一个方法叫 holdsLock ()，它返回 true 如果当且仅当当前线程拥有某个具体对象
的锁。

###### 30) 你如何在 Java 中获取线程堆栈？


对于不同的操作系统，有多种方法来获得 Java 进程的线程堆栈。当你获取线程堆栈时，JVM 会把所有线
程的状态存到日志文件或者输出到控制台。在 Windows 你可以使用 Ctrl + Break 组合键来获取线程堆
栈，Linux 下用 kill -3 命令。你也可以用 jstack 这个工具来获取，它对线程 id 进行操作，你可以用 jps 这个
工具找到 id。

###### 31) JVM 中哪个参数是用来控制线程的栈堆栈小的

这个问题很简单， -Xss 参数用来控制线程的堆栈大小。你可以查看 JVM 配置列表来了解这个参数的更多
信息。

###### 32 ） Java 中 synchronized 和 ReentrantLock 有什么不同？

Java 在过去很长一段时间只能通过 synchronized 关键字来实现互斥，它有一些缺点。比如你不能扩展锁
之外的方法或者块边界，尝试获取锁时不能中途取消等。Java 5 通过 Lock 接口提供了更复杂的控制来
解决这些问题。 ReentrantLock 类实现了 Lock，它拥有与 synchronized 相同的并发性和内存语义且
它还具有可扩展性。

###### 33 ） 有三个线程 T 1，T 2，T 3，怎么确保它们按顺序执行（确保

###### main () 方法所在的线程是 Java 程序最后结束的线程）？

在多线程中有多种方法让线程按特定顺序执行，你可以用线程类的 join () 方法在一个线程中启动另一个
线程，另外一个线程完成该线程继续执行。为了确保三个线程的顺序你应该先启动最后一个 (T 3 调用
T 2，T 2 调用 T 1)，这样 T 1 就会先完成而 T 3 最后完成。

###### 34) Thread 类中的 yield 方法有什么作用？

yield 方法可以暂停当前正在执行的线程对象，让其它有相同优先级的线程执行。它是一个静态方法而且
只保证当前线程放弃 CPU 占用而不能保证使其它线程一定能占用 CPU，执行 yield () 的线程有可能在进入
到暂停状态后马上又被执行。点击这里查看更多 yield 方法的相关内容。

###### 35 ） Java 中 ConcurrentHashMap 的并发度是什么？

ConcurrentHashMap 把实际 map 划分成若干部分来实现它的可扩展性和线程安全。这种划分是使用并
发度获得的，它是 ConcurrentHashMap 类构造函数的一个可选参数，默认值为 16 ，这样在多线程情况
下就能避免争用。

###### 36 ） Java 中 Semaphore 是什么？

Java 中的 Semaphore 是一种新的同步类，它是一个计数信号。从概念上讲，从概念上讲，信号量维护了
一个许可集合。如有必要，在许可可用前会阻塞每一个 acquire ()，然后再获取该许可。每个 release ()
添加一个许可，从而可能释放一个正在阻塞的获取者。但是，不使用实际的许可对象，Semaphore 只
对可用许可的号码进行计数，并采取相应的行动。信号量常常用于多线程的代码中，比如数据库连接
池。更多详细信息请点击这里。

###### 37 ）如果你提交任务时，线程池队列已满。会时发会生什么？

这个问题问得很狡猾，许多程序员会认为该任务会阻塞直到线程池队列有空位。事实上如果一个任务不
能被调度执行那么 ThreadPoolExecutor’s submit () 方法将会抛出一个 RejectedExecutionException 异
常。

###### 38) Java 线程池中 submit () 和 execute () 方法有什么区别？


两个方法都可以向线程池提交任务，execute () 方法的返回类型是 void，它定义在 Executor 接口中, 而
submit () 方法可以返回持有计算结果的 Future 对象，它定义在 ExecutorService 接口中，它扩展了
Executor 接口，其它线程池类像 ThreadPoolExecutor 和 ScheduledThreadPoolExecutor 都有这些方
法。更多详细信息请点击这里。

###### 39) 什么是阻塞式方法？

阻塞式方法是指程序会一直等待该方法完成期间不做其他事情，ServerSocket 的 accept () 方法就是一直
等待客户端连接。这里的阻塞是指调用结果返回之前，当前线程会被挂起，直到得到结果之后才会返
回。此外，还有异步和非阻塞式方法在任务完成前就返回。更多详细信息请点击这里。

###### 40 ） 你对线程优先级的理解是什么？

每一个线程都是有优先级的，一般来说，高优先级的线程在运行时会具有优先权，但这依赖于线程调度
的实现，这个实现是和操作系统相关的 (OS dependent)。我们可以定义线程的优先级，但是这并不能
保证高优先级的线程会在低优先级的线程前执行。线程优先级是一个 int 变量 (从 1-10)， 1 代表最低优先
级， 10 代表最高优先级。

###### 41 ） 什么是线程调度器 (Thread Scheduler) 和时间分片 (Time

###### Slicing)？

线程调度器是一个操作系统服务，它负责为 Runnable 状态的线程分配 CPU 时间。一旦我们创建一个线
程并启动它，它的执行便依赖于线程调度器的实现。时间分片是指将可用的 CPU 时间分配给可用的
Runnable 线程的过程。分配 CPU 时间可以基于线程优先级或者线程等待的时间。线程调度并不受到 Java
虚拟机控制，所以由应用程序来控制它是更好的选择（也就是说不要让你的程序依赖于线程的优先
级）。

###### 42 ） 在多线程中，什么是上下文切换 (context-switching)？

上下文切换是存储和恢复 CPU 状态的过程，它使得线程执行能够从中断点恢复执行。上下文切换是多任
务操作系统和多线程环境的基本特征。

###### 43) 如何在 Java 中创建 Immutable 对象？

Immutable 对象可以在没有同步的情况下共享，降低了对该对象进行并发访问时的同步化开销。要创建
不可变类，要实现下面几个步骤：通过构造方法初始化所有成员、对变量不要提供 setter 方法、将所有
的成员声明为私有的，这样就不允许直接访问这些成员、在 getter 方法中，不要直接返回对象本身，而
是克隆对象，并返回对象的拷贝。

###### 44 ） Java 中的 ReadWriteLock 是什么？

一般而言，读写锁是用来提升并发程序性能的锁分离技术的成果。Java 中的 ReadWriteLock 是 Java 5
中新增的一个接口，一个 ReadWriteLock 维护一对关联的锁，一个用于只读操作一个用于写。在没有写
线程的情况下一个读锁可能会同时被多个读线程持有。写锁是独占的，你可以使用 JDK 中的
ReentrantReadWriteLock 来实现这个规则，它最多支持 65535 个写锁和 65535 个读锁。

###### 45) 多线程中的忙循环是什么?

忙循环就是程序员用循环让一个线程等待，不像传统方法 wait (), sleep () 或 yield () 它们都放弃了 CPU 控
制，而忙循环不会放弃 CPU，它就是在运行一个空循环。这么做的目的是为了保留 CPU 缓存，在多核系
统中，一个等待线程醒来的时候可能会在另一个内核运行，这样会重建缓存。为了避免重建缓存和减少
等待重建的时间就可以使用它了。

###### 46 ）volatile 变量和 atomic 变量有什么不同？


这是个有趣的问题。首先，volatile 变量和 atomic 变量看起来很像，但功能却不一样。Volatile 变量可
以确保先行关系，即写操作会发生在后续的读操作之前, 但它并不能保证原子性。例如用 volatile 修饰
count 变量那么 count++ 操作就不是原子性的。而 AtomicInteger 类提供的 atomic 方法可以让这种操作
具有原子性如 getAndIncrement () 方法会原子性的进行增量操作把当前值加一，其它数据类型和引用变
量也可以进行相似操作。

###### 47) 如果同步块内的线程抛出异常会发生什么？

这个问题坑了很多 Java 程序员，若你能想到锁是否释放这条线索来回答还有点希望答对。无论你的同步
块是正常还是异常退出的，里面的线程都会释放锁，所以对比锁接口我们更喜欢同步块，因为它不用花
费精力去释放锁，该功能可以在 finally block 里释放锁实现。

###### 48 ） 单例模式的双检锁是什么？

这个问题在 Java 面试中经常被问到，但是面试官对回答此问题的满意度仅为 50%。一半的人写不出双检
锁还有一半的人说不出它的隐患和 Java 1.5 是如何对它修正的。它其实是一个用来创建线程安全的单例的
老方法，当单例实例第一次被创建时它试图用单个锁进行性能优化，但是由于太过于复杂在 JDK 1.4 中它
是失败的。

###### 49 ） 如何在 Java 中创建线程安全的 Singleton？

这是上面那个问题的后续，如果你不喜欢双检锁而面试官问了创建 Singleton 类的替代方法，你可以利
用 JVM 的类加载和静态变量初始化特征来创建 Singleton 实例，或者是利用枚举类型来创建 Singleton。

###### 50) 写出 3 条你遵循的多线程最佳实践

以下三条最佳实践大多数 Java 程序员都应该遵循：

```
给你的线程起个有意义的名字。
```
这样可以方便找 bug 或追踪。OrderProcessor, QuoteProcessor or TradeProcessor 这种名字比
Thread-1. Thread-2 and Thread-3 好多了，给线程起一个和它要完成的任务相关的名字，所有的主要
框架甚至 JDK 都遵循这个最佳实践。

```
避免锁定和缩小同步的范围
```
锁花费的代价高昂且上下文切换更耗费时间空间，试试最低限度的使用同步和锁，缩小临界区。因此相
对于同步方法我更喜欢同步块，它给我拥有对锁的绝对控制权。

```
多用同步类少用wait 和 notify
```
首先，CountDownLatch, Semaphore, CyclicBarrier 和 Exchanger 这些同步类简化了编码操作，而
用 wait 和 notify 很难实现对复杂控制流的控制。其次，这些类是由最好的企业编写和维护在后续的 JDK 中
它们还会不断优化和完善，使用这些更高等级的同步工具你的程序可以不费吹灰之力获得优化。

```
多用并发集合少用同步集合
```
这是另外一个容易遵循且受益巨大的最佳实践，并发集合比同步集合的可扩展性更好，所以在并发编程
时使用并发集合效果更好。如果下一次你需要用到 map，你应该首先想到用 ConcurrentHashMap。

###### 51) 如何强制启动一个线程？

这个问题就像是如何强制进行 Java 垃圾回收，目前还没有觉得方法，虽然你可以使用 System.gc () 来进行
垃圾回收，但是不保证能成功。在 Java 里面没有办法强制启动一个线程，它是被线程调度器控制着且
Java 没有公布相关的 API。

###### 52) Java 中的 fork join 框架是什么？


fork join 框架是 JDK 7 中出现的一款高效的工具，Java 开发人员可以通过它充分利用现代服务器上的多
处理器。它是专门为了那些可以递归划分成许多子模块设计的，目的是将所有可用的处理能力用来提升
程序的性能。fork join 框架一个巨大的优势是它使用了工作窃取算法，可以完成更多任务的工作线程可
以从其它线程中窃取任务来执行。

###### 53 ） Java 多线程中调用 wait () 和 sleep () 方法有什么不同？

Java 程序中 wait 和 sleep 都会造成某种形式的暂停，它们可以满足不同的需要。wait () 方法用于线程间
通信，如果等待条件为真且其它线程被唤醒时它会释放锁，而 sleep () 方法仅仅释放 CPU 资源或者让当前
线程停止执行一段时间，但不会释放锁。需要注意的是，sleep（）并不会让线程终止，一旦从休眠中
唤醒线程，线程的状态将会被改变为 Runnable，并且根据线程调度，它将得到执行。

###### 54 ） 什么是 Thread Group？为什么不建议使用它？

ThreadGroup 是一个类，它的目的是提供关于线程组的信息。

ThreadGroup API 比较薄弱，它并没有比 Thread 提供了更多的功能。它有两个主要的功能：一是获取
线程组中处于活跃状态线程的列表；二是设置为线程设置未捕获异常处理器 (ncaught exception
handler)。但在 Java 1.5 中 Thread 类也添加了
setUncaughtExceptionHandler (UncaughtExceptionHandler eh) 方法，所以 ThreadGroup 是已经过
时的，不建议继续使用。

###### 55) 什么是 Java 线程转储 (Thread Dump)，如何得到它？

线程转储是一个 JVM 活动线程的列表，它对于分析系统瓶颈和死锁非常有用。有很多方法可以获取线程
转储——使用 Profiler，Kill -3 命令，jstack 工具等等。我们更喜欢 jstack 工具，因为它容易使用并且是
JDK 自带的。由于它是一个基于终端的工具，所以我们可以编写一些脚本去定时的产生线程转储以待分
析。

###### 56) 什么是 Java Timer 类？如何创建一个有特定时间间隔的任务？

java. util. Timer 是一个工具类，可以用于安排一个线程在未来的某个特定时间执行。Timer 类可以用安排
一次性任务或者周期任务。

java. util. TimerTask 是一个实现了 Runnable 接口的抽象类，我们需要去继承这个类来创建我们自己的定
时任务并使用 Timer 去安排它的执行。

###### 57) 什么是原子操作？在 Java Concurrency API 中有哪些原子类

###### (atomic classes)？

原子操作是指一个不受其他操作影响的操作任务单元。原子操作是在多线程环境下避免数据不一致必须
的手段。

int++并不是一个原子操作，所以当一个线程读取它的值并加 1 时，另外一个线程有可能会读到之前的
值，这就会引发错误。

在 java. util. concurrent. atomic 包中添加原子变量类之后，这种情况才发生了改变。所有原子变量类
都公开比较并设置原语（与比较并交换类似），这些原语都是使用平台上可用的最快本机结构（比较并
交换、加载链接/条件存储，最坏的情况下是旋转锁）来实现的。 java. util. concurrent. atomic 包中提
供了原子变量的 9 种风格（ AtomicInteger； AtomicLong； AtomicReference； AtomicBoolean；
原子整型；长型；引用；及原子标记引用和戳记引用类的数组形式，其原子地更新一对值）。

###### 58 ） Java Concurrency API 中的 Lock 接口 (Lock interface) 是什

###### 么？对比同步它有什么优势？


Lock 接口比同步方法和同步块提供了更具扩展性的锁操作。他们允许更灵活的结构，可以具有完全不同
的性质，并且可以支持多个相关类的条件对象。

它的优势有：

```
可以使锁更公平
可以使线程在等待锁的时候响应中断
可以让线程尝试获取锁，并在无法获取锁的时候立即返回或者等待一段时间
可以在不同的范围，以不同的顺序获取和释放锁
```
###### 62 ）什么是 Callable 和 Future?

Java 5 在 concurrency 包中引入了 java. util. concurrent. Callable 接口，它和 Runnable 接口很相似，但它
可以返回一个对象或者抛出一个异常。

Callable 接口使用泛型去定义它的返回类型。Executors 类提供了一些有用的方法去在线程池中执行
Callable 内的任务。由于 Callable 任务是并行的，我们必须等待它返回的结果。
java. util. concurrent. Future 对象为我们解决了这个问题。在线程池提交 Callable 任务后返回了一个
Future 对象，使用它我们可以知道 Callable 任务的状态和得到 Callable 返回的执行结果。Future 提供了
get () 方法让我们可以等待 Callable 结束并获取它的执行结果。

###### 63 ） 什么是 FutureTask?

FutureTask 包装器是一种非常便利的机制，可将 Callable 转换成 Future 和 Runnable，它同时实现两者的
接口。

FutureTask 类是 Future 的一个实现，并实现了 Runnable，所以可通过 Excutor (线程池) 来执行。也可
传递给 Thread 对象执行。如果在主线程中需要执行比较耗时的操作时，但又不想阻塞主线程时，可以把
这些作业交给 Future 对象在后台完成，当主线程将来需要时，就可以通过 Future 对象获得后台作业的计
算结果或者执行状态。

###### 64 ） 什么是并发容器的实现？

Java 集合类都是快速失败的，这就意味着当集合被改变且一个线程在使用迭代器遍历集合的时候，迭代
器的 next () 方法将抛出 ConcurrentModificationException 异常。

并发容器：并发容器是针对多个线程并发访问设计的，在 jdk 5.0 引入了 concurrent 包，其中提供了很多
并发容器，如 ConcurrentHashMap，CopyOnWriteArrayList 等。并发容器使用了与同步容器完全不同
的加锁策略来提供更高的并发性和伸缩性，例如在 ConcurrentHashMap 中采用了一种粒度更细的加锁
机制，可以称为分段锁，在这种锁机制下，允许任意数量的读线程并发地访问 map，并且执行读操作的
线程和写操作的线程也可以并发的访问 map，同时允许一定数量的写操作线程并发地修改 map，所以它
可以在并发环境下实现更高的吞吐量。

###### 65 、如何创建守护线程？

使用 Thread 类的 setDaemon (true) 方法可以将线程设置为守护线程，需要注意的是，需要在调用 start ()
方法前调用这个方法，否则会抛出 IllegalThreadStateException 异常。

###### 65 ）用户线程和守护线程有什么区别？


当我们在 Java 程序中创建一个线程，它就被称为用户线程。一个守护线程是在后台执行并且不会阻止
JVM 终止的线程。当没有用户线程在运行的时候，JVM 关闭程序并且退出。一个守护线程创建的子线程
依然是守护线程。

###### 66 ）有哪些不同的线程生命周期？

当我们在 Java 程序中新建一个线程时，它的状态是 New。当我们调用线程的 start () 方法时，状态被改变
为 Runnable。线程调度器会为 Runnable 线程池中的线程分配 CPU 时间并且讲它们的状态改变为
Running。其他的线程状态还有 Waiting，Blocked 和 Dead。

###### 67 ）线程之间是如何通信的？

当线程间是可以共享资源时，线程间通信是协调它们的重要的手段。Object 类中
wait ()\notify ()\notifyAll () 方法可以用于线程间通信关于资源的锁的状态。

###### 68 ）为什么 Thread 类的 sleep () 和 yield () 方法是静态的？

Thread 类的 sleep () 和 yield () 方法将在当前正在执行的线程上运行。所以在其他处于等待状态的线程上调
用这些方法是没有意义的。这就是为什么这些方法是静态的。它们可以在当前正在执行的线程中工作，
并避免程序员错误的认为可以在其他非运行线程调用这些方法。

###### 69 、如何确保线程安全？

在 Java 中可以有很多方法来保证线程安全——

```
同步，
使用原子类(atomic concurrent classes)，
使用显示锁，
使用volatile关键字，
使用不变类
```
###### 72 、线程调度策略？

(1) 抢占式调度策略

Java 运行时系统的线程调度算法是抢占式的 (preemptive)。Java 运行时系统支持一种简单的固定优先
级的调度算法。如果一个优先级比其他任何处于可运行状态的线程都高的线程进入就绪状态，那么运行
时系统就会选择该线程运行。新的优先级较高的线程抢占 (preempt) 了其他线程。但是 Java 运行时系统
并不抢占同优先级的线程。换句话说，Java 运行时系统不是分时的 (time-slice)。然而，基于 Java
Thread 类的实现系统可能是支持分时的，因此编写代码时不要依赖分时。当系统中的处于就绪状态的线
程都具有相同优先级时，线程调度程序采用一种简单的、非抢占式的轮转的调度顺序。

(2) 时间片轮转调度策略

有些系统的线程调度采用时间片轮转 (round-robin) 调度策略。这种调度策略是从所有处于就绪状态的线
程中选择优先级最高的线程分配一定的 CPU 时间运行。该时间过后再选择其他线程运行。只有当线程运
行结束、放弃 (yield) CPU 或由于某种原因进入阻塞状态，低优先级的线程才有机会执行。如果有两个优
先级相同的线程都在等待 CPU，则调度程序以轮转的方式选择运行的线程。

###### 73 、在线程中你怎么处理不可捕捉异常？

Thread. UncaughtExceptionHandler 是 java SE 5 中的新接口，它允许我们在每一个 Thread 对象上添加
一个异常处理器。


#### 二：Java 线程的 6 种状态及切换

###### 1 、Java 中线程的状态有哪些？

Java 中线程的状态分为 6 种。

```
1. 初始(NEW) ：新创建了一个线程对象，但还没有调用start()方法。
2. 运行(RUNNABLE) ：Java线程中将就绪（ready）和运行中（running）两种状态笼统的称为
“运行”。
线程对象创建后，其他线程(比如main线程）调用了该对象的start()方法。该状态的线程位
于可运行线程池中，等待被线程调度选中，获取CPU的使用权，此时处于就绪状态
（ready）。就绪状态的线程在获得CPU时间片后变为运行中状态（running）。
3. 阻塞(BLOCKED) ：表示线程阻塞于锁。
4. 等待(WAITING) ：进入该状态的线程需要等待其他线程做出一些特定动作（通知或中断）。
5. 超时等待(TIMED_WAITING) ：该状态不同于WAITING，它可以在指定的时间后自行返回。
6. 终止(TERMINATED) ：表示该线程已经执行完毕。
```
这 6 种状态定义在 Thread 类的 State 枚举中，可查看源码进行一一对应。

**线程的状态图**

**状态详细说明**

**1. 初始状态 (NEW)**

实现 Runnable 接口和继承 Thread 可以得到一个线程类，new 一个实例出来，线程就进入了初始状态。

**2. 执行 Thread #start之后 ，线程进行 RUNNABLE 可运行状态**

**2.1. 就绪状态 (RUNNABLE 之 READY)**

```
1. 就绪状态只是说你资格运行，调度程序没有挑选到你，你就永远是就绪状态。
2. 调用线程的start()方法，此线程进入就绪状态。
```

```
3. 当前线程sleep()方法结束，其他线程join()结束，等待用户输入完毕，某个线程拿到对象锁，这些
线程也将进入就绪状态。
4. 当前线程时间片用完了，调用当前线程的yield()方法，当前线程进入就绪状态。
5. 锁池里的线程拿到对象锁后，进入就绪状态。
```
**2.2. 运行中状态 (RUNNABLE 之 RUNNING)**

线程调度程序从可运行池中选择一个线程作为当前线程时线程所处的状态。这也是线程进入运行状态的
唯一的一种方式。

**3. 阻塞状态 (BLOCKED)**

阻塞状态是线程阻塞在进入 synchronized 关键字修饰的方法或代码块 (获取锁) 时的状态。

**4. 等待 (WAITING)**

处于这种状态的线程不会被分配 CPU 执行时间，它们要等待被显式地唤醒，否则会处于无限期等待的状
态。

**5. 超时等待 (TIMED_WAITING)**

处于这种状态的线程不会被分配 CPU 执行时间，不过无须无限期等待被其他线程显示地唤醒，在达到一
定时间后它们会自动唤醒。

**6. 终止状态 (TERMINATED)**

```
1. 当线程的run()方法完成时，或者主线程的main()方法完成时，我们就认为它终止了。这个线程对
象也许是活的，但是它已经不是一个单独执行的线程。线程一旦终止了，就不能复生。
2. 在一个终止的线程上调用start()方法，会抛出java.lang.IllegalThreadStateException异常。
```
#### 三：synchronized 同步面试题

###### 1. synchronized 的简介

```
synchronized 要理解为 加锁 ，而不是锁，这个思维有助于你更好的理解线程同步。
```
**1.1 synchronized 的使用及各自的锁对象**

这里简要介绍一下，为以后的内容做一下铺垫：

```
1. 普通方法 ：锁对象是this，所谓的 方法锁 （本质上属于对象锁)
```
```
1. 同步代码块( 方法中 )：锁对象是synchronized(obj)的对象，所谓的 对象锁
```
```
1. 同步静态方法：锁对象是当前类的Class对象,即(XXX.class)，所谓的 类锁
```
```
public synchronized void say(){
System.out.println("Hello,everyone...");
}
```
```
1
2
3
```
```
public void say(boolean isYou){
synchronized (obj){
System.out.println("Hello");
}
}
```
```
1
2
3
4
5
```

希望大家再遇到 **对象锁** , **类锁** 而不知所措... 有时候遇到面试官把问题描述的不够清楚时，要勇于及时和面
试官沟通。虽然找工作时总会遇到奇葩面试官，但是如果你遇到的几率太高时，请自觉地审视一下自
己...

**1.2 synchronized 的关于代码块的疑问**

```
看到上面synchronized的用法，你会有这样的疑问吗？synchronized能修饰 类级别(静态)代码块
吗？(PS: 这个话题是我临时想起的,改天在面试中问一下看看效果...)
```
结论：synchronized 不能用在 **类级别的 (静态) 代码块**

如果在面试中不给你编译器，大多数人估计都是要 mountain 泰吧。这里直接给出我的理解：

```
这个要从加载顺序上考虑。
类级别的代码块在加载顺序上是要优先于任何方法的，其执行顺序只跟代码位置先后有关。没人
跟你抢，自然不需要同步。
```
###### 2. 涉及 synchronized 的面试题

这里通过一个常见的面试题- **单例模式** 来展开，这篇文章主要内容是考察 synchronized 关键字的，就直
奔主题进入 **DCL (Double Check Lock) 双重校验锁** 的单例。

**2.1 围绕着 DCL 展开的话题**

**2.1.1 实现 DCL**

```
如果DCL不懂，就尴尬无止境啦...。感兴趣的可以去看一下《Java高并发核心编程（卷 2 ）》
```
**2.1.2 谈一下 synchronized 的作用**

```
synchronized 关键字主要用来解决的是多线程同步问题，其可以保证在被其修饰的代码任意时
刻只有一个线程执行。视情况而定，（主动)说出它的用法及底层实现原理(使用的是
moniterenter 和 moniterexit指令...)，PS：synchronized的底层实现原理会单独展开...
```
**2.1.3 这里 (DCL) 的 volatile 的作用**

```
public static synchronized void work(){
System.out.println("Work hard...");
}
```
```
1
2
3
```
```
public class SingleInstance {
private volatile static SingleInstance instance = null;
private SingleInstance(){ }
public static SingleInstance getInstance(){
if (instance == null){
synchronized (SingleInstance.class){
if (instance == null){
instance = new SingleInstance();
}
}
}
return instance;
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
```

volatile 只能保证变量的可见性，并不能保证对 volatile 修饰的变量的操作的原子性。

```
volatile的主要作用：
```
```
1. 保持内存可见性；使所有线程都能看到共享内存的最新状态。
2. 防止指令重排的问题；
```
通过设置 **内存屏障** 实现的。感兴趣的可以去看一下《Java 高并发核心编程（卷 2 ）》

```
个人拙见，能答出来上面的内容即可，更深入的绝大部分都是在SHOW或者就是压薪资...
```
**2.2 基础面试点**

为了节约各位看官的时间，先把结论给出来：

```
1. 若是对象锁，则每个对象都持有一把自己的独一无二的锁，且对象之间的锁互不影响 。若是
类锁，所有该类的对象共用这把锁。
2. 一个线程获取一把锁，没有得到锁的线程只能排队等待；
3. synchronized 是可重入锁，避免很多情况下的死锁发生。
4. synchronized 方法若发生异常，则JVM会自动释放锁。
5. 锁对象不能为空，否则抛出NPE(NullPointerException)
6. 同步本身是不具备继承性的：即父类的synchronized 方法，子类重写该方法,分情况讨论：
没有synchonized修饰，则该子类方法不是线程同步的。(PS ：涉及同步继承性的问题要分
情况)
7. synchronized本身修饰的范围越小越好。毕竟是同步阻塞。跑不快还占着超车道...
```
**2.2.1 同时访问 synchronized 的静态和非静态方法，能保证线程安全吗？**

```
结论：不能，两者的锁对象不一样。前者是类锁(XXX.class),后者是this
```
**2.2.2 同时访问 synchronized 方法和非同步方法，能保证线程安全吗？**

```
结论：不能，因为synchronized只会对被修饰的方法起作用。
```
**2.2.3 两个线程同时访问两个对象的非静态同步方法能保证线程安全吗？**

```
结论：不能，每个对象都拥有一把锁。两个对象相当于有两把锁，导致锁对象不一致。(PS：如果
是类锁，则所有对象共用一把锁)
```
**2.2.4 若 synchronized 方法抛出异常，会导致死锁吗？**

```
JVM会自动释放锁，不会导致死锁问题
```
**2.2.5 若 synchronized 的锁对象能为空吗？会出现什么情况？**

```
锁对象不能为空，否则抛出NPE(NullPointerException)
```
**2.2.6 若 synchronized 的锁对象能为空吗？会出现什么情况？**

```
锁对象不能为空，否则抛出NPE(NullPointerException)
```
**2.3 关于继承性的面试点**

**2.3.1 synchronized 涉及的继承性问题**

重写父类的 synchronized 的方法，主要分为两种情况：

```
1. 子类的方法没有被synchronized修饰：
```
```
synchronized的不具备继承性。所以子类方法是线程不安全的。
```

```
1. 子类的方法被synchronized修饰(这里面试点主要考察锁对象的归属问题)：
```
```
两个锁对象其实是一把锁，而且是 子类对象作为锁 。这也证明了: synchronized的锁是可重入
锁。否则将出现死锁问题。
```
**2.4 实战经验的面试点**

**2.4.1 在开发过程中，你经常使用 synchronized 方法多还是 synchronized 代码块？and why?**

关于 synchronized 的内容部分，我在面试过程中经常问且只问这一道题。

本人认为这个能很好的考察面试者的综合素质。(PS：毕竟是要拧螺丝的...)

```
synchronized同步的范围是越小越好。
```
```
因为若该方法耗时很久，那其它线程必须等到该持锁线程执行完才能运行。(黄花菜都凉了都...)
```
```
而synchronized代码块部分只有这一部分是同步的，其它的照样可以异步执行，提高运行效率。
```
###### 3 、对象锁的同步队列

```
当前线程想调用对象A的同步方法时，发现对象A的锁被别的线程占有，此时当前线程进入对象锁
的同步队列。简言之，同步队列里面放的都是想争夺对象锁的线程。
当一个线程 1 被另外一个线程 2 唤醒时， 1 线程进入同步队列，去争夺对象锁。
同步队列是在同步的环境下才有的概念，一个对象对应一个同步队列。
线程等待时间到了或被notify/notifyAll唤醒后，会进入同步队列竞争锁，如果获得锁，进入
RUNNABLE状态，否则进入BLOCKED状态等待获取锁。
```
###### 4 、如何在两个线程间共享数据？

你可以通过共享对象来实现这个目的，或者是使用像阻塞队列这样并发的数据结构。这篇教程《Java 线
程间通信》(涉及到在两个线程间共享对象) 用 wait 和 notify 方法实现了生产者消费者模型。

###### 5 、 Java 中 notify 和 notifyAll 有什么区别？

这又是一个刁钻的问题，因为多线程可以等待单监控锁，Java API 的设计人员提供了一些方法当等待
条件改变的时候通知它们，但是这些方法没有完全实现。notify () 方法不能唤醒某个具体的线程，所以只
有一个线程在等待的时候它才有用武之地。而 notifyAll () 唤醒所有线程并允许他们争夺锁确保了至少有
一个线程能继续运行。

###### 6) 为什么 wait, notify 和 notifyAll 这些方法不在 thread 类里面？

一个很明显的原因是 JAVA 提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果
线程需要等待某些锁那么调用对象中的 wait () 方法就有意义了。如果 wait () 方法定义在 Thread 类中，线
程正在等待的是哪个锁就不明显了。简单的说，由于 wait，notify 和 notifyAll 都是锁级别的操作，所以
把他们定义在 Object 类中因为锁属于对象。

###### 7) 为什么 wait 和 notify 方法要在同步块中调用？


当一个线程需要调用对象的 wait () 方法的时候，这个线程必须拥有该对象的锁，接着它就会释放这个对
象锁并进入等待状态直到其他线程调用这个对象上的 notify () 方法。同样的，当一个线程需要调用对象的
notify () 方法时，它会释放这个对象的锁，以便其他在等待的线程就可以得到这个对象锁。由于所有的这
些方法都需要线程持有对象的锁，这样就只能通过同步来实现，所以他们只能在同步方法或者同步块中
被调用。如果你不这么做，代码会抛出 IllegalMonitorStateException 异常。

###### 8) 为什么应该在循环中检查等待条件?

处于等待状态的线程可能会收到错误警报和伪唤醒，如果不在循环中检查等待条件，程序就会在没有满
足结束条件的情况下退出。因此，当一个等待线程醒来时，不能认为它原来的等待状态仍然是有效的，
在 notify () 方法调用之后和等待线程醒来之前这段时间它可能会改变。这就是在循环中使用 wait () 方法效
果更好的原因，你可以在 Eclipse 中创建模板调用 wait 和 notify 试一试。如果你想了解更多关于这个问题
的内容，推荐你阅读《Effective Java》这本书中的线程和同步章节。

###### 9 、对象锁的等待队列

```
调用obj的wait(), notify()方法前，必须获得obj锁，也就是必须写在synchronized(obj) 代码段内。
与等待队列相关的步骤和图
```
```
1. 线程 1 获取对象A的锁，正在使用对象A。
2. 线程 1 调用对象A的wait()方法。
3. 线程 1 释放对象A的锁，并马上进入等待队列。
4. 锁池里面的对象争抢对象A的锁。
5. 线程 5 获得对象A的锁，进入synchronized块，使用对象A。
6. 线程 5 调用对象A的notifyAll()方法，唤醒所有线程，所有线程进入同步队列。若线程 5 调用对象A的
notify()方法，则唤醒一个线程，不知道会唤醒谁，被唤醒的那个线程进入同步队列。
7. notifyAll()方法所在synchronized结束，线程 5 释放对象A的锁。
8. 同步队列的线程争抢对象锁，但线程 1 什么时候能抢到就不知道了。
```

###### 聊聊：如何写代码来解决生产者消费者问题？

在现实中你解决的许多线程问题都属于生产者消费者模型，就是一个线程生产任务供其它线程进行消
费，你必须知道怎么进行线程间通信来解决这个问题。

比较低级的办法是用 wait 和 notify 来解决这个问题，比较赞的办法是用 Semaphore 或者
BlockingQueue 来实现生产者消费者模型。

###### 聊聊：什么是竟态条件？

在大多数实际的多线程应用中，两个或两个以上的线程需要共享对同一数据的存取。

如果 i 线程存取相同的对象，并且每一个线程都调用了一个修改该对象状态的方法，将会发生什么呢？

可以想象，线程彼此踩了对方的脚。

根据线程访问数据的次序，可能会产生讹误的对象。这样的情况通常称为竞争条件。

###### 聊聊：Java 中 Semaphore 是什么？

Java 中的 Semaphore 是一种新的同步类，它是一个计数信号。

从概念上讲，从概念上讲，信号量维护了一个许可集合。

如有必要，在许可可用前会阻塞每一个 acquire ()，然后再获取该许可。

每个 release () 添加一个许可，从而可能释放一个正在阻塞的获取者。

但是，不使用实际的许可对象，Semaphore 只对可用许可的号码进行计数，并采取相应的行动。

信号量常常用于多线程的代码中，比如数据库连接池。

###### 聊聊：java 中 wait () 的核心原理是什么？

1 ）当线程调用了 locko（某个同步锁对象）的 wait () 方法后，JVM 会将当前线程加入 locko 监视器的
WaitSet（等待集），等待被其他线程唤醒。
2 ）当前线程会释放 locko 对象监视器的 Owner 权利，让其他线程可以抢夺 locko 对象的监视器。
3 ）让当前线程等待，其状态变成 WAITING。

###### 聊聊：java 中的 notify () 的核心原理是什么？

1 ）当线程调用了 locko（某个同步锁对象）的 notify () 方法后，JVM 会唤醒 locko 监视器 WaitSet 中的第一
个等待线程。

2 ）当线程调用了 locko 的 notifyAll () 方法后，JVM 会唤醒 locko 监视器 WaitSet 中的所有等待线程。

3 ）等待线程被唤醒后，会从监视器的 WaitSet 移动到 EntryList，线程具备了排队抢夺监视器 Owner 权利
的资格，其状态从 WAITING 变成 BLOCKED。

4 ）EntryList 中的线程抢夺到监视器 Owner 权利之后，线程的状态从 BLOCKED 变成 Runnable，具备重
新执行的资格。

###### 聊聊：谈一下 synchronized 的作用

synchronized 关键字主要用来解决的是多线程同步问题，其可以保证在被其修饰的代码任意时
刻只有一个线程执行。


视情况而定，（主动) 说出它的用法及底层实现原理 (使用的是
moniterenter 和 moniterexit 指令...)。

###### 聊聊：同时访问 synchronized 的静态和非静态方法，能保证线程安

###### 全吗？

不能，两者的锁对象不一样。

前者是类锁 (XXX. class), 后者是 this

###### 聊聊：同时访问 synchronized 方法和非同步方法，能保证线程安全

###### 吗？

不能，因为 synchronized 只会对被修饰的方法起作用。

###### 聊聊：两个线程同时访问两个对象的非静态同步方法能保证线程安全

###### 吗？

不能，每个对象都拥有一把锁。两个对象相当于有两把锁，导致锁对象不一致。(PS：如果
是类锁，则所有对象共用一把锁)

###### 聊聊：若 synchronized 方法抛出异常，会导致死锁吗？

JVM 会自动释放锁，不会导致死锁问题。

###### 聊聊：若 synchronized 的锁对象能为空吗？会出现什么情况？

锁对象不能为空，否则抛出 NPE (NullPointerException)

###### 聊聊：synchronized 的继承性问题

重写父类的 synchronized 的方法，主要分为两种情况：

（ 1 ）子类的方法没有被 synchronized 修饰：

synchronized 的不具备继承性。所以子类方法是线程不安全的。

（ 2 ）子类的方法被 synchronized 修饰

两个锁对象其实是一把锁，而且是子类对象作为锁。

这也证明了: synchronized 的锁是可重入锁。否则将出现死锁问题。

###### 聊聊：如何在两个线程间共享数据？

可以通过共享对象来实现这个目的，或者是使用像阻塞队列这样并发的数据结构。

###### 聊聊：Java 中 notify 和 notifyAll 有什么区别？

因为多线程可以等待单监控锁，Java API 的设计人员提供了一些方法当等待
条件改变的时候通知它们，但是这些方法没有完全实现。notify () 方法不能唤醒某个具体的线程，所以只
有一个线程在等待的时候它才有用武之地。而 notifyAll () 唤醒所有线程并允许他们争夺锁确保了至少有
一个线程能继续运行。

###### 聊聊：为什么 wait, notify 和 notifyAll 这些方法不在 thread 类里

###### 面？


一个很明显的原因是 JAVA 提供的锁是对象级的而不是线程级的，每个对象都有锁，通过线程获得。如果
线程需要等待某些锁那么调用对象中的 wait () 方法就有意义了。如果 wait () 方法定义在 Thread 类中，线
程正在等待的是哪个锁就不明显了。简单的说，由于 wait，notify 和 notifyAll 都是锁级别的操作，所以
把他们定义在 Object 类中因为锁属于对象。

###### 聊聊：为什么 wait 和 notify 方法要在同步块中调用？

当一个线程需要调用对象的 wait () 方法的时候，这个线程必须拥有该对象的锁，接着它就会释放这个对
象锁并进入等待状态直到其他线程调用这个对象上的 notify () 方法。同样的，当一个线程需要调用对象的
notify () 方法时，它会释放这个对象的锁，以便其他在等待的线程就可以得到这个对象锁。由于所有的这
些方法都需要线程持有对象的锁，这样就只能通过同步来实现，所以他们只能在同步方法或者同步块中
被调用。如果你不这么做，代码会抛出 IllegalMonitorStateException 异常。

#### 四、深入分析 Synchronized 原理 (阿里面试题)

记得开始学习 Java 的时候，一遇到多线程情况就使用 synchronized，相对于当时的我们来说
synchronized 是这么的神奇而又强大，那个时候我们赋予它一个名字“同步”，也成为了我们解决多线程
情况的百试不爽的良药。但是，随着学习的进行我们知道在 JDK 1.5 之前 synchronized 是一个重量级锁，
相对于j.u.c.Lock，它会显得那么笨重，以至于我们认为它不是那么的高效而慢慢摒弃它。

不过，随着 Javs SE 1.6 对 synchronized 进行的各种优化后，synchronized 并不会显得那么重了。下面来
一起探索 synchronized 的基本使用、实现机制、Java 是如何对它进行了优化、锁优化机制、锁的存储结
构等升级过程。

###### 1 基本使用

Synchronized 是 Java 中解决并发问题的一种最常用的方法，也是最简单的一种方法。Synchronized 的
作用主要有三个：

```
1. 原子性：确保线程互斥的访问同步代码；
2. 可见性：保证共享变量的修改能够及时可见，其实是通过Java内存模型中的 “ 对一个变量
unlock操作之前，必须要同步到主内存中；如果对一个变量进行lock操作，则将会清空工
作内存中此变量的值，在执行引擎使用此变量前，需要重新从主内存中load操作或assign操
作初始化变量值 ” 来保证的；
3. 有序性：有效解决重排序问题，即 “一个unlock操作先行发生(happen-before)于后面对同一
个锁的lock操作”；
```
从语法上讲，Synchronized 可以把任何一个非 null 对象作为"锁"，在 HotSpot JVM 实现中， **锁有个专门
的名字：对象监视器（Object Monitor）** 。

Synchronized 总共有三种用法：

```
1. 当synchronized作用在实例方法时，监视器锁（monitor）便是对象实例（this）；
2. 当synchronized作用在静态方法时，监视器锁（monitor）便是对象的Class实例，因为
Class数据存在于永久代，因此静态方法锁相当于该类的一个全局锁；
3. 当synchronized作用在某一个对象实例时，监视器锁（monitor）便是括号括起来的对象实
例；
```
注意，synchronized 内置锁是一种对象锁（锁的是对象而非引用变量）， **作用粒度是对象，可以用来
实现对临界资源的同步互斥访问，是可重入的。其可重入最大的作用是避免死锁** ，如：

```
子类同步方法调用了父类同步方法，如没有可重入的特性，则会发生死锁；
```
###### 2 同步原理


数据同步需要依赖锁，那锁的同步又依赖谁？ **synchronized 给出的答案是在软件层面依赖 JVM，而
j.u.c.Lock 给出的答案是在硬件层面依赖特殊的 CPU 指令。**

当一个线程访问同步代码块时，首先是需要得到锁才能执行同步代码，当退出或者抛出异常时必须要释
放锁，那么它是如何来实现这个机制的呢？我们先看一段简单的代码：

查看反编译后结果：

反编译结果

```
1. monitorenter ：每个对象都是一个监视器锁（monitor）。当monitor被占用时就会处于锁定状
态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下：
```
```
1. 如果monitor的进入数为 0 ，则该线程进入monitor，然后将进入数设置为 1 ，该线程即
为monitor的所有者；
2. 如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加 1 ；
3. 如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为
0 ，再重新尝试获取monitor的所有权；
```
```
2. monitorexit：执行monitorexit的线程必须是objectref所对应的monitor的所有者。指令执行时，
monitor的进入数减 1 ，如果减 1 后进入数为 0 ，那线程退出monitor，不再是这个monitor的所有
者。其他被这个monitor阻塞的线程可以尝试去获取这个 monitor 的所有权。
```
```
monitorexit指令出现了两次，第 1 次为同步正常退出释放锁；第 2 次为发生异步退出释放
锁；
```
```
package com.paddx.test.concurrent;
public class SynchronizedDemo {
public void method() {
synchronized (this) {
System.out.println("Method 1 start");
}
}
}
```
```
1 2 3 4 5 6 7 8 9
```

通过上面两段描述，我们应该能很清楚的看出 Synchronized 的实现原理， **Synchronized 的语义底层是
通过一个 monitor 的对象来完成，其实 wait/notify 等方法也依赖于 monitor 对象，这就是为什么只有
在同步的块或者方法中才能调用 wait/notify 等方法，否则会抛出
java. lang. IllegalMonitorStateException 的异常的原因。**

再来看一下同步方法：

查看反编译后结果：

反编译结果

从编译的结果来看，方法的同步并没有通过指令 monitorenter 和 monitorexit 来完成（理论上其

实也可以通过这两条指令来实现），不过相对于普通方法，其常量池中多了 ACC_SYNCHRONIZED 标示
符。JVM 就是根据该标示符来实现方法的同步的：

```
当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置
了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。
在方法执行期间，其他任何线程都无法再获得同一个monitor对象。
```
两种同步方式本质上没有区别，只是方法的同步是一种隐式的方式来实现，无需通过字节码来完成。两
个指令的执行是 JVM 通过调用操作系统的互斥原语 mutex 来实现，被阻塞的线程会被挂起、等待重新调
度，会导致“用户态和内核态”两个态之间来回切换，对性能有较大影响。

###### 3 同步概念

**3.1 Java 对象头**

在 JVM 中 **，对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充。** 如下图所示：

```
package com.paddx.test.concurrent;
```
```
public class SynchronizedMethod {
public synchronized void method() {
System.out.println("Hello World!");
}
}
```
```
1 2 3 4 5 6 7
```

```
1. 实例数据：存放类的属性数据信息，包括父类的属性信息；
2. 对齐填充：由于虚拟机要求 对象起始地址必须是 8 字节的整数倍。填充数据不是必须存在的，仅仅
是为了字节对齐；
3. 对象头：Java对象头一般占有 2 个机器码（在 32 位虚拟机中， 1 个机器码等于 4 字节，也就是
32bit，在 64 位虚拟机中， 1 个机器码是 8 个字节，也就是64bit），但是 如果对象是数组类型，则
需要 3 个机器码，因为JVM虚拟机可以通过Java对象的元数据信息确定Java对象的大小，但是无法
从数组的元数据来确认数组的大小，所以用一块来记录数组长度。
```
Synchronized 用的锁就是存在 Java 对象头里的，那么什么是 Java 对象头呢？Hotspot 虚拟机的对象头主
要包括两部分数据： **Mark Word（标记字段）、** Class Pointer（类型指针）。其中 Class Pointer 是
对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例，Mark Word 用
于存储对象自身的运行时数据，它是实现轻量级锁和偏向锁的关键。 Java 对象头具体结构描述如下：

Java 对象头结构组成

Mark Word 用于存储对象自身的运行时数据，如：哈希码（HashCode）、GC 分代年龄、 **锁状态标
志** 、线程持有的锁、偏向线程 ID、偏向时间戳等。比如锁膨胀就是借助 Mark Word 的偏向的线程 ID 参
考：JAVA 锁的膨胀过程和优化 (阿里) 阿里也经常问的问题

下图是 Java 对象头无锁状态下 Mark Word 部分的存储结构（ 32 位虚拟机）：

Mark Word 存储结构


对象头信息是与对象自身定义的数据无关的额外存储成本，但是考虑到虚拟机的空间效率，Mark
Word 被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据，它会根据对象的状态
复用自己的存储空间，也就是说，Mark Word 会随着程序的运行发生变化，可能变化为存储以下 4 种数
据：

Mark Word 可能存储 4 种数据

在 64 位虚拟机下，Mark Word 是 64 bit 大小的，其存储结构如下：

64 位 Mark Word 存储结构

对象头的最后两位存储了锁的标志位， 01 是初始状态，未加锁，其对象头里存储的是对象本身的哈希
码，随着锁级别的不同，对象头里会存储不同的内容。偏向锁存储的是当前占用此对象的线程 ID；而轻
量级则存储指向线程栈中锁记录的指针。从这里我们可以看到，“锁”这个东西，可能是个锁记录+对象头
里的引用指针（判断线程是否拥有锁时将线程的锁记录地址和对象头里的指针地址比较)，也可能是对象
头里的线程 ID（判断线程是否拥有锁时将线程的 ID 和对象头里存储的线程 ID 比较）。

HotSpot 虚拟机对象头 Mark Word


```
Lock
Record
描述
```
```
Owner
初始时为NULL表示当前没有任何线程拥有该monitor record，当线程成功拥有该
锁后保存线程唯一标识，当锁被释放时又设置为NULL；
```
```
EntryQ
关联一个系统互斥锁（semaphore），阻塞所有试图锁住monitor record失败的
线程；
```
```
RcThis 表示blocked或waiting在该monitor record上的所有线程的个数；
```
```
Nest 用来实现 重入锁的计数；
```
```
HashCode 保存从对象头拷贝过来的HashCode值（可能还包含GC age）。
```
```
Candidate
```
```
用来避免不必要的阻塞或等待线程唤醒，因为每一次只有一个线程能够成功拥有
锁，如果每次前一个释放锁的线程唤醒所有正在阻塞或等待的线程，会引起不必要
的上下文切换（从阻塞到就绪然后因为竞争锁失败又被阻塞）从而导致性能严重下
降。Candidate只有两种可能的值 0 表示没有需要唤醒的线程 1 表示要唤醒一个继任
线程来竞争锁。
```
**3.2 对象头中 Mark Word 与线程中 Lock Record**

在线程进入同步代码块的时候，如果此同步对象没有被锁定，即它的锁标志位是 01 ，则虚拟机首先在当
前线程的栈中创建我们称之为“锁记录（Lock Record）”的空间，用于存储锁对象的 Mark Word 的拷
贝，官方把这个拷贝称为 Displaced Mark Word。整个 Mark Word 及其拷贝至关重要。

**Lock Record 是线程私有的数据结构** ，每一个线程都有一个可用 Lock Record 列表，同时还有一个全局
的可用列表。每一个被锁住的对象 Mark Word 都会和一个 Lock Record 关联（对象头的 MarkWord 中的
Lock Word 指向 Lock Record 的起始地址），同时 Lock Record 中有一个 Owner 字段存放拥有该锁的线
程的唯一标识（或者 object mark word），表示该锁被这个线程占用。如下图所示为 Lock Record 的

内部结构：

**3.3 监视器（Monitor）**

任何一个对象都有一个 Monitor 与之关联，当且一个 Monitor 被持有后，它将处于锁定状态。
Synchronized 在 JVM 里的实现都是基于进入和退出 Monitor 对象来实现方法同步和代码块同步，虽然具
体实现细节不一样，但是都可以通过成对的 MonitorEnter 和 MonitorExit 指令来实现。

```
1. MonitorEnter指令：插入在同步代码块的开始位置，当代码执行到该指令时，将会尝试获取该对
象Monitor的所有权，即尝试获得该对象的锁；
2. MonitorExit指令：插入在方法结束处和异常处，JVM保证每个MonitorEnter必须有对应的
MonitorExit；
```
那什么是 Monitor？可以把它理解为一个同步工具，也可以描述为一种同步机制，它通常被描述为一
个对象。

与一切皆对象一样，所有的 Java 对象是天生的 Monitor，每一个 Java 对象都有成为 Monitor 的潜质，因为
在 Java 的设计中， **每一个 Java 对象自打娘胎里出来就带了一把看不见的锁，它叫做内部锁或者 Monitor
锁** 。

也就是通常说 Synchronized 的对象锁，MarkWord 锁标识位为 10 ，其中指针指向的是 Monitor 对象的起
始地址。在 Java 虚拟机（HotSpot）中，Monitor 是由 ObjectMonitor 实现的，其主要数据结构如下（位
于 HotSpot 虚拟机源码 ObjectMonitor. hpp 文件，C++实现的）：

```
1 ObjectMonitor() {
```

ObjectMonitor 中有两个队列， _WaitSet_ 和 __EntryList_ ，用来保存 _ObjectWaiter_ 对象列表（ 每个等待锁的
线程都会被封装成 _ObjectWaiter_ 对象 ），owner 指向持有 ObjectMonitor 对象的线程，当多个线程同时
访问一段同步代码时：

```
1. 首先会进入 _EntryList 集合，当线程获取到对象的monitor后，进入 _Owner区域并把
monitor中的owner变量设置为当前线程，同时monitor中的计数器count加 1 ；
2. 若线程调用 wait() 方法，将释放当前持有的monitor，owner变量恢复为null，count自减
1 ，同时该线程进入 WaitSet集合中等待被唤醒；
3. 若当前线程执行完毕，也将释放monitor（锁）并复位count的值，以便其他线程进入获取
monitor(锁)；
```
同时 **，Monitor 对象存在于每个 Java 对象的对象头 Mark Word 中（存储的指针的指向），
Synchronized 锁便是通过这种方式获取锁的，也是为什么 Java 中任意对象可以作为锁的原因，同时
notify/notifyAll/wait 等方法会使用到 Monitor 锁对象，所以必须在同步代码块中使用。**

监视器 Monitor 有两种同步方式：互斥与协作。多线程环境下线程之间如果需要共享数据，需要解决互
斥访问数据的问题，监视器可以确保监视器上的数据在同一时刻只会有一个线程在访问。

什么时候需要协作？ 比如：

```
一个线程向缓冲区写数据，另一个线程从缓冲区读数据，如果读线程发现缓冲区为空就会等待，
当写线程向缓冲区写入数据，就会唤醒读线程，这里读线程和写线程就是一个合作关系。JVM通
过Object类的wait方法来使自己等待，在调用wait方法后，该线程会释放它持有的监视器，直到
其他线程通知它才有执行的机会。一个线程调用notify方法通知在等待的线程，这个等待的线程并
不会马上执行，而是要通知线程释放监视器后，它重新获取监视器才有执行的机会。如果刚好唤
醒的这个线程需要的监视器被其他线程抢占，那么这个线程会继续等待。Object类中的notifyAll
方法可以解决这个问题，它可以唤醒所有等待的线程，总有一个线程执行。
```
```
_header = NULL;
_count = 0 ; // 记录个数
_waiters = 0 ,
_recursions = 0 ;
_object = NULL;
_owner = NULL;
_WaitSet = NULL; // 处于wait状态的线程，会被加入到_WaitSet
_WaitSetLock = 0 ;
_Responsible = NULL ;
_succ = NULL ;
_cxq = NULL ;
FreeNext = NULL ;
_EntryList = NULL ; // 处于等待锁block状态的线程，会被加入到该列表
_SpinFreq = 0 ;
_SpinClock = 0 ;
OwnerIsThread = 0 ;
}
```
```
2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
```
```
1
```

如上图所示，一个线程通过 1 号门进入 Entry Set (入口区)，如果在入口区没有线程等待，那么这个线程
就会获取监视器成为监视器的 Owner，然后执行监视区域的代码。如果在入口区中有其它线程在等待，
那么新来的线程也会和这些线程一起等待。线程在持有监视器的过程中，有两个选择，一个是正常执行
监视器区域的代码，释放监视器，通过 5 号门退出监视器；还有可能等待某个条件的出现，于是它会通
过 3 号门到 Wait Set（等待区）休息，直到相应的条件满足后再通过 4 号门进入重新获取监视器再执行。

注意：

```
当一个线程释放监视器时，在入口区和等待区的等待线程都会去竞争监视器，如果入口区的线程
赢了，会从 2 号门进入；如果等待区的线程赢了会从 4 号门进入。只有通过 3 号门才能进入等待
区，在等待区中的线程只有通过 4 号门才能退出等待区，也就是说一个线程只有在持有监视器时才
能执行wait操作，处于等待的线程只有再次获得监视器才能退出等待状态。
```
###### 4 锁的优化

从 JDK 5 引入了现代操作系统新增加的 CAS 原子操作（ JDK 5 中并没有对 synchronized 关键字做优化，而
是体现在J.U.C 中，所以在该版本 concurrent 包有更好的性能 ），从 JDK 6 开始，就对 synchronized 的实
现机制进行了较大调整，包括使用 JDK 5 引进的 CAS 自旋之外，还增加了自适应的 CAS 自旋、锁消除、锁
膨胀、偏向锁、轻量级锁这些优化策略。由于此关键字的优化使得性能极大提高，同时语义清晰、操作
简单、无需手动关闭，所以推荐在允许的情况下尽量使用此关键字，同时在性能上此关键字还有优化的
空间。

锁主要存在四种状态，依次是 **：无锁状态、偏向锁状态、轻量级锁状态、重量级锁状态** ，锁可以从偏向
锁升级到轻量级锁，再升级的重量级锁。但是锁的升级是单向的，也就是说只能从低到高升级，不会出
现锁的降级。

在 JDK 1.6 中默认是开启偏向锁和轻量级锁的，可以通过-XX:-UseBiasedLocking 来禁用偏向锁。

**4.1 自旋锁**

线程的阻塞和唤醒需要 CPU 从用户态转为核心态，频繁的阻塞和唤醒对 CPU 来说是一件负担很重的工
作，势必会给系统的并发性能带来很大的压力。同时我们发现在许多应用上面，对象锁的锁状态只会持
续很短一段时间，为了这一段很短的时间频繁地阻塞和唤醒线程是非常不值得的。

所以引入自旋锁，何谓自旋锁？


所谓自旋锁，就是指当一个线程尝试获取某个锁时，如果该锁已被其他线程占用，就一直循环检测锁是
否被释放，而不是进入线程挂起或睡眠状态。

自旋锁适用于锁保护的临界区很小的情况，临界区很小的话，锁占用的时间就很短。自旋等待不能替代
阻塞，虽然它可以避免线程切换带来的开销，但是它占用了 CPU 处理器的时间。如果持有锁的线程很快
就释放了锁，那么自旋的效率就非常好，反之，自旋的线程就会白白消耗掉处理的资源，它不会做任何
有意义的工作，典型的占着茅坑不拉屎，这样反而会带来性能上的浪费。所以说，自旋等待的时间（自
旋的次数）必须要有一个限度，如果自旋超过了定义的时间仍然没有获取到锁，则应该被挂起。

自旋锁在 JDK 1.4.2 中引入，默认关闭，但是可以使用-XX:+UseSpinning 开开启，在 JDK 1.6 中默认开启。
同时自旋的默认次数为 10 次，可以通过参数-XX: PreBlockSpin 来调整。

如果通过参数-XX: PreBlockSpin 来调整自旋锁的自旋次数，会带来诸多不便。假如将参数调整为 10 ，但
是系统很多线程都是等你刚刚退出的时候就释放了锁（假如多自旋一两次就可以获取锁），是不是很尴
尬。于是 JDK 1.6 引入自适应的自旋锁，让虚拟机会变得越来越聪明。

**4.2 适应性自旋锁**

JDK 1.6 引入了更加聪明的自旋锁，即自适应自旋锁。所谓自适应就意味着自旋的次数不再是固定的，它
是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。那它如何进行适应性自旋呢？

**线程如果自旋成功了，那么下次自旋的次数会更加多，因为虚拟机认为既然上次成功了，那么此次自旋
也很有可能会再次成功，那么它就会允许自旋等待持续的次数更多。反之，如果对于某个锁，很少有自
旋能够成功，那么在以后要或者这个锁的时候自旋的次数会减少甚至省略掉自旋过程，以免浪费处理器
资源。**

有了自适应自旋锁，随着程序运行和性能监控信息的不断完善，虚拟机对程序锁的状况预测会越来越准

确，虚拟机会变得越来越聪明。

**4.3 锁消除**

为了保证数据的完整性，在进行操作时需要对这部分操作进行同步控制，但是在有些情况下，JVM 检测
到不可能存在共享数据竞争，这是 JVM 会对这些同步锁进行锁消除。

```
锁消除的依据是逃逸分析的数据支持
```
如果不存在竞争，为什么还需要加锁呢？所以锁消除可以节省毫无意义的请求锁的时间。变量是否逃
逸，对于虚拟机来说需要使用数据流分析来确定，但是对于程序员来说这还不清楚么？在明明知道不存
在数据竞争的代码块前加上同步吗？但是有时候程序并不是我们所想的那样？虽然没有显示使用锁，但
是在使用一些 JDK 的内置 API 时，如 StringBuffer、Vector、HashTable 等，这个时候会存在隐形的加锁
操作。比如 StringBuffer 的 append () 方法，Vector 的 add () 方法：

在运行这段代码时，JVM 可以明显检测到变量 vector 没有逃逸出方法 vectorTest () 之外，所以 JVM 可以大
胆地将 vector 内部的加锁操作消除。

**4.4 锁膨胀**

```
public void vectorTest(){
Vector<String> vector = new Vector<String>();
for(int i = 0 ; i < 10 ; i++){
vector.add(i + "");
}
```
```
System.out.println(vector);
}
```
```
1 2 3 4 5 6 7 8
```

在使用同步锁的时候，需要让同步块的作用范围尽可能小—仅在共享数据的实际作用域中才进行同步，
这样做的目的是为了使需要同步的操作数量尽可能缩小，如果存在锁竞争，那么等待锁的线程也能尽快
拿到锁。

在大多数的情况下，上述观点是正确的。但是如果一系列的连续加锁解锁操作，可能会导致不必要的性
能损耗，所以引入锁粗话的概念。

锁粗话概念比较好理解，就是将多个连续的加锁、解锁操作连接在一起，扩展成一个范围更大的锁

如上面实例：

```
vector每次add的时候都需要加锁操作，JVM检测到对同一个对象（vector）连续加锁、解锁操
作，会合并一个更大范围的加锁、解锁操作，即加锁解锁操作会移到for循环之外。
```
**4.5 偏向锁**

偏向锁是 JDK 6 中的重要引进，因为 HotSpot 作者经过研究实践发现，在大多数情况下，锁不仅不存在多
线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低，引进了偏向锁。

偏向锁是在单线程执行代码块时使用的机制，如果在多线程并发的环境下（即线程 A 尚未执行完同步代
码块，线程 B 发起了申请锁的申请），则一定会转化为轻量级锁或者重量级锁。

在 JDK 5 中偏向锁默认是关闭的，而到了 JDK 6 中偏向锁已经默认开启。如果并发数较大同时同步代码块
执行时间较长，则被多个线程同时访问的概率就很大，就可以使用参数-XX:-UseBiasedLocking 来禁止
偏向锁 (但这是个 JVM 参数，不能针对某个对象锁来单独设置)。

引入偏向锁主要目的是：为了在没有多线程竞争的情况下尽量减少不必要的轻量级锁执行路径。因为轻
量级锁的加锁解锁操作是需要依赖多次 CAS 原子指令的，而偏向锁只需要在置换 ThreadID 的时候依赖一
次 CAS 原子指令（由于一旦出现多线程竞争的情况就必须撤销偏向锁，所以偏向锁的撤销操作的性能损
耗也必须小于节省下来的 CAS 原子指令的性能消耗）。

```
轻量级锁是为了在线程交替执行同步块时提高性能，而偏向锁则是在只有一个线程执行同步块时
进一步提高性能。
```
那么偏向锁是如何来减少不必要的 CAS 操作呢？首先我们看下无竞争下锁存在什么问题：

```
现在几乎所有的锁都是可重入的，即已经获得锁的线程可以多次锁住/解锁监视对象，按照之前的
HotSpot设计，每次加锁/解锁都会涉及到一些CAS操作（比如对等待队列的CAS操作），CAS操
作会延迟本地调用，因此偏向锁的想法是 一旦线程第一次获得了监视对象，之后让监视对象“偏
向”这个线程，之后的多次调用则可以避免CAS操作，说白了就是置个变量，如果发现为true则无
需再走各种加锁/解锁流程。
```
CAS 为什么会引入本地延迟？这要从 SMP（对称多处理器）架构说起，下图大概表明了 SMP 的结构：

SMP（对称多处理器）架构


```
其意思是 所有的CPU会共享一条系统总线（BUS），靠此总线连接主存。每个核都有自己的一级
缓存，各核相对于BUS对称分布，因此这种结构称为“对称多处理器”。
```
而 CAS 的全称为 Compare-And-Swap，是一条 CPU 的原子指令，其作用是让 CPU 比较后原子地更新某个
位置的值，经过调查发现，其实现方式是基于硬件平台的汇编指令，就是说 CAS 是靠硬件实现的，JVM
只是封装了汇编调用，那些 AtomicInteger 类便是使用了这些封装后的接口。

例如：Core 1 和 Core 2 可能会同时把主存中某个位置的值 Load 到自己的 L 1 Cache 中，当 Core 1 在自己的
L 1 Cache 中修改这个位置的值时，会通过总线，使 Core 2 中 L 1 Cache 对应的值“失效”，而 Core 2 一旦发
现自己 L 1 Cache 中的值失效（称为 Cache 命中缺失）则会通过总线从内存中加载该地址最新的值，大家
通过总线的来回通信称为“Cache 一致性流量”，因为总线被设计为固定的“通信能力”，如果 Cache 一致性
流量过大，总线将成为瓶颈。而当 Core 1 和 Core 2 中的值再次一致时，称为“Cache 一致性”，从这个层面
来说，锁设计的终极目标便是减少 Cache 一致性流量。

而 CAS 恰好会导致 Cache 一致性流量，如果有很多线程都共享同一个对象，当某个 Core CAS 成功时必然
会引起总线风暴，这就是所谓的本地延迟，本质上偏向锁就是为了消除 CAS，降低 Cache 一致性流量。

_Cache_ 一致性：

```
上面提到Cache一致性，其实是有协议支持的，现在通用的协议是MESI（最早由Intel开始支
持），具体参考：http://en.wikipedia.org/wiki/MESI_protocol。
```
_Cache_ 一致性流量的例外情况：

```
其实也不是所有的CAS都会导致总线风暴，这跟Cache一致性协议有关，具体参考：http://blogs.
oracle.com/dave/entry/biased_locking_in_hotspot
```
_NUMA (Non Uniform Memory Access Achitecture_ ）架构：

```
与SMP对应还有非对称多处理器架构，现在主要应用在一些高端处理器上，主要特点是没有总
线，没有公用主存，每个Core有自己的内存，针对这种结构此处不做讨论。
```
所以，当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程 ID，以后
该线程进入和退出同步块时不需要花费 CAS 操作来争夺锁资源，只需要检查是否为偏向锁、锁标识为以
及 ThreadID 即可，处理流程如下：

```
1. 检测Mark Word是否为可偏向状态，即是否为偏向锁 1 ，锁标识位为 01 ；
2. 若为可偏向状态，则测试线程ID是否为当前线程ID，如果是，则执行步骤（ 5 ），否则执行
步骤（ 3 ）；
3. 如果测试线程ID不为当前线程ID，则通过CAS操作竞争锁，竞争成功，则将Mark Word的线
程ID替换为当前线程ID，否则执行线程（ 4 ）；
4. 通过CAS竞争锁失败，证明当前存在多线程竞争情况，当到达全局安全点，获得偏向锁的线
程被挂起，偏向锁升级为轻量级锁，然后被阻塞在安全点的线程继续往下执行同步代码块；
5. 执行同步代码块；
```
偏向锁的释放采用了一种只有竞争才会释放锁的机制，线程是不会主动去释放偏向锁，需要等待其他线
程来竞争。偏向锁的撤销需要等待全局安全点（这个时间点是上没有正在执行的代码）。其步骤如下：

```
1. 暂停拥有偏向锁的线程；
2. 判断锁对象是否还处于被锁定状态，否，则恢复到无锁状态（ 01 ），以允许其余线程竞争。
是，则挂起持有锁的当前线程，并将指向当前线程的锁记录地址的指针放入对象头Mark
Word，升级为轻量级锁状态（ 00 ），然后恢复持有锁的当前线程，进入轻量级锁的竞争模
式；
```
```
注意：此处将 当前线程挂起再恢复的过程中并没有发生锁的转移，仍然在当前线程手中，只是穿
插了个 “将对象头中的线程ID变更为指向锁记录地址的指针” 这么个事。
```

偏向锁的获取和释放过程

**4.6 轻量级锁**

引入轻量级锁的主要目的是在没有多线程竞争的前提下，减少传统的重量级锁使用操作系统互斥量产生
的性能消耗。当关闭偏向锁功能或者多个线程竞争偏向锁导致偏向锁升级为轻量级锁，则会尝试获取轻
量级锁，其步骤如下：

```
1. 在线程进入同步块时，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为
“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存
储锁对象目前的Mark Word的拷贝，官方称之为 Displaced Mark Word。此时线程堆栈与对象头
的状态如下图所示：
```

```
轻量级锁CAS操作之前线程堆栈与对象的状态
2. 拷贝对象头中的Mark Word复制到锁记录（Lock Record）中；
3. 拷贝成功后，虚拟机将使用CAS操作尝试将对象Mark Word中的Lock Word更新为指向当前线程
Lock Record的指针，并将Lock record里的owner指针指向object mark word。如果更新成功，
则执行步骤（ 4 ），否则执行步骤（ 5 ）；
4. 如果这个更新动作成功了，那么当前线程就拥有了该对象的锁，并且对象Mark Word的锁标志位
设置为“00”，即表示此对象处于轻量级锁定状态，此时线程堆栈与对象头的状态如下图所示：
```
```
轻量级锁CAS操作之后线程堆栈与对象的状态
5. 如果这个更新操作失败了，虚拟机首先会检查对象Mark Word中的Lock Word是否指向当前线程
的栈帧，如果是，就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行。
否则说明多个线程竞争锁，进入自旋执行（ 3 ），若自旋结束时仍未获得锁，轻量级锁就要膨胀为
重量级锁，锁标志的状态值变为“10”，Mark Word中存储的就是指向重量级锁（互斥量）的指
针，当前线程以及后面等待锁的线程也要进入阻塞状态。
```
轻量级锁的释放也是通过 CAS 操作来进行的，主要步骤如下：

```
1. 通过CAS操作尝试把线程中复制的Displaced Mark Word对象替换当前的Mark Word；
```

```
2. 如果替换成功，整个同步过程就完成了，恢复到无锁状态（ 01 ）；
3. 如果替换失败，说明有其他线程尝试过获取该锁（此时锁已膨胀），那就要在释放锁的同
时，唤醒被挂起的线程；
```
对于轻量级锁，其性能提升的依据是 “对于绝大部分的锁，在整个生命周期内都是不会存在竞争的”，如
果打破这个依据则除了互斥的开销外，还有额外的 CAS 操作，因此在有多线程竞争的情况下，轻量级锁
比重量级锁更慢。

轻量级锁的获取和释放过程

```
1. 为什么升级为轻量锁时要把对象头里的Mark Word复制到线程栈的锁记录中呢？
```
```
因为在申请对象锁时 需要以该值作为CAS的比较条件，同时在升级到重量级锁的时候，能通
过这个比较判定是否在持有锁的过程中此锁被其他线程申请过，如果被其他线程申请了，则
在释放锁的时候要唤醒被挂起的线程。
```
```
2. 为什么会尝试CAS不成功以及什么情况下会不成功？
```
```
CAS本身是不带锁机制的，其是通过比较而来。假设如下场景：线程A和线程B都在对象头里
的锁标识为无锁状态进入，那么如线程A先更新对象头为其锁记录指针成功之后，线程B再用
CAS去更新，就会发现此时的对象头已经不是其操作前的对象HashCode了，所以CAS会失
败。也就是说，只有两个线程并发申请锁的时候会发生CAS失败。
```

```
然后线程B进行CAS自旋，等待对象头的锁标识重新变回无锁状态或对象头内容等于对象
HashCode（因为这是线程B做CAS操作前的值），这也就意味着线程A执行结束（参见后面
轻量级锁的撤销，只有线程A执行完毕撤销锁了才会重置对象头），此时线程B的CAS操作终
于成功了，于是线程B获得了锁以及执行同步代码的权限。如果线程A的执行时间较长，线程
B经过若干次CAS时钟没有成功，则锁膨胀为重量级锁，即线程B被挂起阻塞、等待重新调
度。
```
此处，如何理解“轻量级”？“轻量级”是相对于使用操作系统互斥量来实现的传统锁而言的。但是，首先
需要强调一点的是，轻量级锁并不是用来代替重量级锁的，它的本意是在没有多线程竞争的前提下，减
少传统的重量级锁使用产生的性能消耗。

```
轻量级锁所适应的场景是线程交替执行同步块的情况，如果存在同一时间访问同一锁的情况，必
然就会导致轻量级锁膨胀为重量级锁。
```
**4.7 重量级锁**

Synchronized 是通过对象内部的一个叫做监视器锁（Monitor）来实现的。但是监视器锁本质又是依赖
于底层的操作系统的 Mutex Lock 来实现的。而操作系统实现线程之间的切换这就需要从用户态转换到
核心态，这个成本非常高，状态之间的转换需要相对比较长的时间，这就是为什么 Synchronized 效率低
的原因。因此，这种依赖于操作系统 Mutex Lock 所实现的锁我们称之为 “重量级锁”。

**4.8 重量级锁、轻量级锁和偏向锁之间转换**

**重量级锁、轻量级锁和偏向锁之间转换**


Synchronized 偏向锁、轻量级锁及重量级锁转换流程

###### 5 锁的优劣

各种锁并不是相互代替的，而是在不同场景下的不同选择，绝对不是说重量级锁就是不合适的。每种锁
是只能升级，不能降级，即由偏向锁->轻量级锁->重量级锁，而这个过程就是开销逐渐加大的过程。

```
1. 如果是单线程使用，那偏向锁毫无疑问代价最小，并且它就能解决问题，连CAS都不用做，
仅仅在内存中比较下对象头就可以了；
2. 如果出现了其他线程竞争，则偏向锁就会升级为轻量级锁；
3. 如果其他线程通过一定次数的CAS尝试没有成功，则进入重量级锁；
```
在第 3 种情况下进入同步代码块就要做偏向锁建立、偏向锁撤销、轻量级锁建立、升级到重量级锁，最
终还是得靠重量级锁来解决问题，那这样的代价就比直接用重量级锁要大不少了。所以使用哪种技术，
一定要看其所处的环境及场景，在绝大多数的情况下，偏向锁是有效的，这是基于 HotSpot 作者发现的
“大多数锁只会由同一线程并发申请”的经验规律。


###### 6. Synchronized 原理的推荐学习书籍

Synchronized 原理非常复杂，如果上面的问题不清楚，请前往阅读：

《Java 高并发核心编程（卷 2 加强版）：多线程、锁、JMM、JUC、高并发设计模式》。


#### 五、穿透 volatile 可见性

###### 聊聊：volatile 的作用？

volatile 的作用就是，核心是两个：

```
「保证变量对所有线程可见性」 。
「禁止指令重排」
但是
「不保证原子性」 。
```
所以当面试官问你 **「volatile 的作用或者特性」** ，都可以这么回答：

```
保证变量对所有线程可见性;
禁止指令重排序
不保证原子性
```
关于： 重排序，可见性的底层原理，请参见：

《Java 高并发核心编程（卷 2 ）：多线程、锁、JMM、JUC、高并发设计模式》。


###### 聊聊：volatile 的典型场景

通常来说，使用 volatile 必须具备以下 2 个条件：

```
1 ）对变量的写操作不依赖于当前值
2 ）该变量没有包含在具有其他变量的不变式中
```
实际上，volatile 场景一般就是

```
状态标志 ，
DCL单例模式
CAS 轻量级乐观锁场景
```
**场景 1 ：状态标志场景**

深入理解 Java 虚拟机，书中的例子：

```
Map configOptions;
char[] configText;
// 此变量必须定义为 volatile
volatile boolean initialized = false;
```
```
// 假设以下代码在线程 A 中运行
// 模拟读取配置信息, 当读取完成后将 initialized 设置为 true 以告知其他线程配置可用
configOptions = new HashMap();
configText = readConfigFile(fileName);
processConfigOptions(configText, configOptions);
initialized = true;
```
```
// 假设以下代码在线程 B 中运行
// 等待 initialized 为 true, 代表线程 A 已经把配置信息初始化完成
while(!initialized) {
sleep();
}
// 使用线程 A 中初始化好的配置信息
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
```

**场景 2 ：DCL 单例模式**

**场景 3 ：CAS 轻量级乐观锁场景**

JUC AQS 源码中，其核心的成员 state （同步状态）、head （头指针）、tail （尾部指针），都是通过
CAS 进行乐观锁修改的，都需要进行 volatile 保证可见性。

```
19 doSomethingWithConfig();
```
```
class Singleton{
private volatile static Singleton instance = null;
```
```
private Singleton() {
}
```
```
public static Singleton getInstance() {
if(instance==null) {
synchronized (Singleton.class) {
if(instance==null)
instance = new Singleton();
}
}
return instance;
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
```

同样，在高性能组件 caffeine 、 disruptor 源码中，都是 CAS + volatile 配合使用的

```
caffeine 、 disruptor 源码, 请参见 第 24 章、 第 25 章 视频。
```
###### 聊聊：volatile 的内存语义

```
当写一个 volatile 变量时，JMM 会把该线程对应的本地内存中的共享变量值刷新到主内存。
当读一个 volatile 变量时，JMM 会把该线程对应的本地内存置为无效。线程接下来将从主内存中
读取共享变量。
```
###### 聊聊：什么是内存可见性，什么是指令重排序？

```
可见性就是指当一个线程修改了共享变量的值时，其他线程能够立即得知这个修改。
指令重排是指JVM在编译Java代码的时候，或者CPU在执行JVM字节码的时候，对现有的指令顺序
进行重新排序。
```

###### 聊聊：volatile 重排序规则

volatile 禁止重排序场景：

```
第二个操作是volatile写，不管第一个操作是什么都不会重排序。
第一个操作是volatile读，不管第二个操作是什么都不会重排序。
第一个操作时volatile写，第二个操作时volatile读，也不会发生重排序。
```
###### 聊聊：并发编程的 3 大特性

```
原子性
可见性
有序性
```
###### 聊聊：volatile 是如何解决 java 并发中可见性的问题

底层是通过内存屏障实现的哦，

volatile 能保证修饰的变量后，可以立即同步回主内存，每次使用前立即先从主内存刷新最新的值。

###### 聊聊：volatile 底层的实现机制

volatile 如何保证可见性和禁止指令重排，

底层是通过内存屏障实现的哦，

###### 聊聊：volatile 如何防止指令重排

底层是通过内存屏障实现防止指令重排的哦，

跟面试官讲下 Java 内存的保守策略：

```
1 、在每个volatile写操作的前面插入一个StoreStore屏障。
2 、在每个volatile写操作的后面插入一个StoreLoad屏障。
3 、在每个volatile读操作的后面插入一个LoadLoad屏障。
4 、在每个volatile读操作的后面插入一个LoadStore屏障。
```

###### 聊聊：你对内存屏障理解？

分为两个层面：

```
JVM层面的内存屏障
硬件层面内存屏障
```
**JVM 层面的内存屏障**

```
LoadLoad屏障：（指令Load1；LoadLoad；Load2），在Load2及后续 读取操作要读取的数据
访问前，保障Load1要读取的数据被读取完毕。
LoadStore屏障：（指令Load1；LoadStore；Store2），在Store2及后续写入操作被刷出前，保
障Load1要读取的数据被读取完毕。
StoreStore屏障：（指令Store1；StoreStore；Store2），在Store2及后续写入操作执行前，保障
Store1的写入操作对其他处理器可见；
StoreLoad屏障：（指令Store1；StoreLoad；Load2），在Load2及后续所有读取操作执行前保
障Store1的写入对所有处理器可见。它的开销时四种屏障中最大的。在大多数处理器的实现中，
这个屏障是个万能屏障；间距其他三种内存屏障的功能。
```
**硬件层面内存屏障**

硬件层提供了一系列的内存屏障 memory barrier/memory fence 来提供一致性的能力，拿 X 86 平
台来说，有以下几种内存屏障：

```
lfence，是一种Load Barrier读屏障，在读指令前插入读屏障，可以让高速缓存中的数据失效，重
新从主内存加载数据。
sfence，是一种Store Barrier写屏障，在写指令之后插入写屏障，能让写入缓存的最新数据写回到
主内存。
mfence，是一种全能型的屏障，具备lfence和sfence的能力
Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线或高
速缓存加锁，可以理解为CPU指令级的一种锁。它先对高速缓存加锁，然后执行后面的指令，最后
释放锁后会把高速缓存中的数据刷新回主内存。在Lock锁总线的时候，其他CPU的读写请求斗会
被阻塞，直到锁释放。
```
不同硬件实现内存屏障的方式不同，Java 内存模型屏蔽了这种底层硬件平台的差异，由 JVM 来为不
同的平台生成相应的机器码。

###### 聊聊：内存屏障的作用？

两个作用：


```
阻止屏障两边的指令重排序
刷新处理器缓存
```
###### 聊聊： volatile 可以解决原子性嘛？为什么？

不可以，可以直接举 i++那个例子，原子性需要 synchronzied 或者 lock 保证

###### 聊聊：volatile 和 synchronized 的区别？

```
volatile修饰的是变量，synchronized一般修饰代码块或者方法
volatile保证可见性、禁止指令重排，但是不保证原子性；synchronized可以保证原子性
volatile不会造成线程阻塞，synchronized可能会造成线程的阻塞，所以后面才有锁优化那么多故
事~
```
#### 六：穿透线程池

###### 1 、什么是线程池？ 为什么要使用它？

创建线程要花费昂贵的资源和时间，如果任务来了才创建线程那么响应时间会变长，而且一个进程能创
建的线程数有限。

```
public class Test {
public volatile int race = 0 ;
```
```
public void increase() {
race++;
}
```
```
public static void main(String[] args) {
final Test test = new Test();
for(int i= 0 ;i< 10 ;i++){
new Thread(){
public void run() {
for(int j= 0 ;j< 100 ;j++)
test.increase();
};
}.start();
}
```
```
//等待所有累加线程结束
while(Thread.activeCount()> 1 )
Thread.yield();
System.out.println(test.race);
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
```

多线程技术主要解决处理器单元内多个线程执行的问题，它可以显著减少处理器单元的闲置时间，增加
处理器单元的吞吐能力。
假设一个服务器完成一项任务所需时间为：T 1 创建线程时间，T 2 在线程中执行任务的时间，T 3 销毁
线程时间。

如果：T 1 + T 3 远大于 T 2，则可以采用线程池，以提高服务器性能。

```
一个线程池包括以下四个基本组成部分：
1 、线程池管理器（ThreadPool）：用于创建并管理线程池，包括 创建线程池，销毁线程池，添
加新任务；
2 、工作线程（PoolWorker）：线程池中线程，在没有任务时处于等待状态，可以循环的执行任
务；
3 、任务接口（Task）：每个任务必须实现的接口，以供工作线程调度任务的执行，它主要规定了
任务的入口，任务执行完后的收尾工作，任务的执行状态等；
4 、任务队列（taskQueue）：用于存放没有处理的任务。提供一种缓冲机制。
```
线程池技术正是关注如何缩短或调整 T 1, T 3 时间的技术，从而提高服务器程序性能的。它把 T 1，T 3 分别
安排在服务器程序的启动和结束的时间段或者一些空闲的时间段，这样在服务器程序处理客户请求时，
不会有 T 1，T 3 的开销了。
线程池不仅调整 T 1, T 3 产生的时间段，而且它还显著减少了创建线程的数目，看一个例子：
假设一个服务器一天要处理 50000 个请求，并且每个请求需要一个单独的线程完成。在线程池中，线
程数一般是固定的，所以产生线程总数不会超过线程池中线程的数目，而如果服务器不利用线程池来处
理这些请求则线程总数为 50000 。一般线程池大小是远小于 50000 。所以利用线程池的服务器程序不会
为了创建 50000 而在处理请求时浪费时间，从而提高效率。

为了避免这些问题，在程序启动的时候就创建若干线程来响应处理，它们被称为线程池，里面的线程叫
工作线程。从 JDK 1.5 开始，Java API 提供了 Executor 框架让你可以创建不同的线程池。比如单线程池，
每次处理一个任务；数目固定的线程池或者是缓存线程池（一个适合很多生存期短的任务的程序的可扩
展线程池）。

###### 2 ） 什么是 Executor 框架？

Executor 框架同 java. util. concurrent. Executor 接口在 Java 5 中被引入。Executor 框架是一个根据一组
执行策略调用，调度，执行和控制的异步任务的框架。

无限制的创建线程会引起应用程序内存溢出。所以创建一个线程池是个更好的的解决方案，因为可以限
制线程的数量并且可以回收再利用这些线程。利用 Executor 框架可以非常方便的创建一个线程池。

60 ） Executors 类是什么？

Executors 为 Executor，ExecutorService，ScheduledExecutorService，ThreadFactory 和 Callable 类
提供了一些工具方法。

Executors 可以用于方便的创建线程池。

###### 3 ） 什么是阻塞队列？如何使用阻塞队列来实现生产者-消费者模型？

java. util. concurrent. BlockingQueue 的特性是：当队列是空的时，从队列中获取或删除元素的操作将会
被阻塞，或者当队列是满时，往队列里添加元素的操作会被阻塞。

阻塞队列不接受空值，当你尝试向队列中添加空值的时候，它会抛出 NullPointerException。

阻塞队列的实现都是线程安全的，所有的查询方法都是原子的并且使用了内部锁或者其他形式的并发控
制。


BlockingQueue 接口是 java collections 框架的一部分，它主要用于实现生产者-消费者问题。

###### 4. 常见线程池的快捷创建方式

① **newSingleThreadExecutor**
单个线程的线程池，即线程池中每次只有一个线程工作，单线程串行执行任务
② **newFixedThreadExecutor** (n)
固定数量的线程池，没提交一个任务就是一个线程，直到达到线程池的最大数量，然后后面进入等待队
列直到前面的任务完成才继续执行
③ **newCacheThreadExecutor** （推荐使用）
可缓存线程池，当线程池大小超过了处理任务所需的线程，那么就会回收部分空闲（一般是 60 秒无执
行）的线程，当有任务来时，又智能的添加新线程来执行。
④ **newScheduleThreadExecutor**
大小无限制的线程池，支持定时和周期性的执行线程

java 提供的线程池更加强大，相信理解线程池的工作原理，看类库中的线程池就不会感到陌生了。

要配置一个线程池是比较复杂的，尤其是对于线程池的原理不是很清楚的情况下，很有可能配置的线程
池不是较优的，因此在 Executors 类里面提供了一些静态工厂，生成一些常用的线程池。

**4.1 newSingleThreadExecutor**


创建一个单线程的线程池。这个线程池只有一个线程在工作，也就是相当于单线程串行执行所有任务。
如果这个唯一的线程因为异常结束，那么会有一个新的线程来替代它。此线程池保证所有任务的执行顺
序按照任务的提交顺序执行。

**4.2 newFixedThreadPool**

创建固定大小的线程池。每次提交一个任务就创建一个线程，直到线程达到线程池的最大大小。线程池
的大小一旦达到最大值就会保持不变，如果某个线程因为执行异常而结束，那么线程池会补充一个新线
程。

**4.3 newCachedThreadPool**

创建一个可缓存的线程池。如果线程池的大小超过了处理任务所需要的线程，

那么就会回收部分空闲（ 60 秒不执行任务）的线程，当任务数增加时，此线程池又可以智能的添加新线
程来处理任务。此线程池不会对线程池大小做限制，线程池大小完全依赖于操作系统（或者说 JVM）能
够创建的最大线程大小。

**4.4 newScheduledThreadPool**

创建一个大小无限的线程池。此线程池支持定时以及周期性执行任务的需求。

###### 5 、为什么不建议使用 Executors 静态工厂构建线程池

阿里巴巴 Java 开发手册，明确指出 **不允许** 使用 Executors 静态工厂构建线程池
原因如下：
线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式，这样的处理方式让写的同
学更加明确线程池的运行规则，规避资源耗尽的风险

说明：Executors 返回的线程池对象的弊端如下：

1 ：FixedThreadPool 和 SingleThreadPool：
允许的请求队列（底层实现是 LinkedBlockingQueue）长度为 Integer. MAX_VALUE，可能会堆积大量
的请求，从而导致 OOM
2 ：CachedThreadPool 和 ScheduledThreadPool
允许的创建线程数量为 Integer. MAX_VALUE，可能会创建大量的线程，从而导致 OOM。

创建线程池的正确姿势

避免使用 Executors 创建线程池，主要是避免使用其中的默认实现，那么我们可以自己直接调用
ThreadPoolExecutor 的构造函数来自己创建线程池。在创建的同时，给 BlockQueue 指定容量就可以
了。

或者是使用开源类库：开源类库，如 apache 和 guava 等。

```
private static ExecutorService executor = new ThreadPoolExecutor( 10 , 10 ,
60L, TimeUnit.SECONDS,
new ArrayBlockingQueue( 10 ));
```
```
1
2
3
```

###### 6 、线程池常用参数

corePoolSize：核心线程数量，会一直存在，除非 allowCoreThreadTimeOut 设置为 true
maximumPoolSize：线程池允许的最大线程池数量
keepAliveTime：线程数量超过 corePoolSize，空闲线程的最大超时时间
unit：超时时间的单位
workQueue：工作队列，保存未执行的 Runnable 任务
threadFactory：创建线程的工厂类
handler：当线程已满，工作队列也满了的时候，会被调用。被用来实现各种拒绝策略。

###### 7 、线程池的关闭

关闭线程池可以调用 shutdownNow 和 shutdown 两个方法来实现

shutdownNow：对正在执行的任务全部发出 interrupt ()，停止执行，对还未开始执行的任务全部取
消，并且返回还没开始的任务列表。

```
/**
* Creates a new {@code ThreadPoolExecutor} with the given initial
* parameters.
*
* @param corePoolSize the number of threads to keep in the pool, even
* if they are idle, unless {@code allowCoreThreadTimeOut} is
set
* @param maximumPoolSize the maximum number of threads to allow in the
* pool
* @param keepAliveTime when the number of threads is greater than
* the core, this is the maximum time that excess idle threads
* will wait for new tasks before terminating.
* @param unit the time unit for the {@code keepAliveTime} argument
* @param workQueue the queue to use for holding tasks before they are
* executed. This queue will hold only the {@code Runnable}
* tasks submitted by the {@code execute} method.
* @param threadFactory the factory to use when the executor
* creates a new thread
* @param handler the handler to use when execution is blocked
* because the thread bounds and queue capacities are reached
* @throws IllegalArgumentException if one of the following holds:<br>
* {@code corePoolSize < 0}<br>
* {@code keepAliveTime < 0}<br>
* {@code maximumPoolSize <= 0}<br>
* {@code maximumPoolSize < corePoolSize}
* @throws NullPointerException if {@code workQueue}
* or {@code threadFactory} or {@code handler} is null
*/
```
```
public ThreadPoolExecutor(int corePoolSize,
int maximumPoolSize,
long keepAliveTime,
TimeUnit unit,
BlockingQueue<Runnable> workQueue,
ThreadFactory threadFactory,
RejectedExecutionHandler handler) { }
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
```

shutdown：当我们调用 shutdown 后，线程池将不再接受新的任务，但也不会去强制终止已经提交或者
正在执行中的任务。

###### 8 、初始化线程池时线程数的选择

如果任务是 IO 密集型，一般线程数需要设置 2 倍 CPU 数以上，以此来尽量利用 CPU 资源。

如果任务是 CPU 密集型，一般线程数量只需要设置 CPU 数加 1 即可，更多的线程数也只能增加上下文切
换，不能增加 CPU 利用率。

如果任务是混合型，有一个公式，具体请参考：《Java 高并发核心编程（卷 2 ）》

###### 9 、线程池都有哪几种工作队列

1 、ArrayBlockingQueue

是一个基于数组结构的有界阻塞队列，此队列按 FIFO（先进先出）原则对元素进行排序。

2 、LinkedBlockingQueue

一个基于链表结构的阻塞队列，此队列按 FIFO （先进先出） 排序元素，吞吐量通常要高于
ArrayBlockingQueue。静态工厂方法 Executors.newFixedThreadPool () 使用了这个队列

3 、SynchronousQueue

一个不存储元素的阻塞队列。每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于
阻塞状态，吞吐量通常要高于 LinkedBlockingQueue，静态工厂方法
Executors. newCachedThreadPool 使用了这个队列。

4 、PriorityBlockingQueue

一个具有优先级的无限阻塞队列。

#### 七、threadlocal 面试题

###### 1) 什么是 ThreadLocal 变量？

ThreadLocal 是 Java 里一种特殊的变量。每个线程都有一个 ThreadLocal 就是每个线程都拥有了自己独立
的一个变量，竞争条件被彻底消除了。如果为每个线程提供一个自己独有的变量拷贝，将大大提高效
率。首先，通过复用减少了代价高昂的对象的创建个数。其次，你在没有使用高代价的同步或者不变性
的情况下获得了线程安全。

###### 2) ThreadLocal 用在什么地方？

讨论 ThreadLocal 用在什么地方前，我们先明确下，如果仅仅就一个线程，那么都不用谈 ThreadLocal
的， **ThreadLocal 是用在多线程的场景的！！！**

ThreadLocal 归纳下来就 2 类用途：

```
保存线程上下文信息，在任意需要的地方可以获取！！！
```

```
线程安全的，避免某些情况需要考虑线程安全必须同步带来的性能损失！！！
```
**保存线程上下文信息，在任意需要的地方可以获取！！！**

由于 ThreadLocal 的特性，同一线程在某地方进行设置，在随后的任意地方都可以获取到。从而可以用
来保存线程上下文信息。

常用的比如每个请求怎么把一串后续关联起来，就可以用 ThreadLocal 进行 set，在后续的任意需要记录
日志的方法里面进行 get 获取到请求 id，从而把整个请求串起来。

还有比如 Spring 的事务管理，用 ThreadLocal 存储 Connection，从而各个 DAO 可以获取同一
Connection，可以进行事务回滚，提交等操作。

```
备注： ThreadLocal的这种用处，很多时候是用在一些优秀的框架里面的，一般我们很少接触，
反而下面的场景我们接触的更多一些！
```
**线程安全的，避免某些情况需要考虑线程安全必须同步带来的性能损失！！！**

ThreadLocal 为解决多线程程序的并发问题提供了一种新的思路。但是 ThreadLocal 也有局限性，我们
来看看阿里规范：

每个线程往 ThreadLocal 中读写数据是线程隔离，互相之间不会影响的，所以 **ThreadLocal 无法解决共**

**享对象的更新问题！**

```
由于不需要共享信息，自然就不存在竞争问题了，从而保证了某些情况下线程的安全，以及避免
了某些情况需要考虑线程安全必须同步带来的性能损失！！！
```
**这类场景阿里规范里面也提到了：**

###### 3 、Thread、ThreadLocalMap、ThreadLocal 的关系


Thread 类有属性变量 threadLocals （类型是 ThreadLocal. ThreadLocalMap），也就是说每个线程有一
个自己的 ThreadLocalMap ，所以每个线程往这个 ThreadLocal 中读写隔离的，并且是互相不会影响
的。

**一个 ThreadLocal 只能存储一个 Object 对象，如果需要存储多个 Object 对象那么就需要多个
ThreadLocal！！！**

如图：


看到上面的几个图，大概思路应该都清晰了，我们 Entry 的 key 指向 ThreadLocal 用 **虚线** 表示弱引用，下
面我们来看看 ThreadLocalMap:

java 对象的引用包括 ： 强引用，软引用，弱引用，虚引用。

因为这里涉及到弱引用，简单说明下：

弱引用也是用来描述非必需对象的，当 JVM 进行垃圾回收时，无论内存是否充足， **该对象仅仅被弱引用
关联** ，那么就会被回收。

**当仅仅只有 ThreadLocalMap 中的 Entry 的 key 指向 ThreadLocal 的时候，ThreadLocal 会进行回收
的！！！**

ThreadLocal 被垃圾回收后，在 ThreadLocalMap 里对应的 Entry 的键值会变成 null，但是 Entry 是强引
用，那么 Entry 里面存储的 Object，并没有办法进行回收，所以 ThreadLocalMap 做了一些额外的回收
工作。


虽然做了但是也会存在内存泄漏风险（我没有遇到过，网上很多类似场景， **所以会提到后面的
ThreadLocal 最佳实践！！！** ）

###### 4 、为什么要调用 remove 方法进行清理?

ThreadLocal 被垃圾回收后，在 ThreadLocalMap 里对应的 Entry 的键值会变成 null，但是 Entry 是强引
用，那么 Entry 里面存储的 Object，并没有办法进行回收，所以 ThreadLocalMap 做了一些额外的回收
工作。

```
备注： 很多时候，我们都是用在线程池的场景，程序不停止，线程基本不会销毁！！！
```
由于线程的生命周期很长，如果我们往 ThreadLocal 里面 set 了很大很大的 Object 对象，虽然 set、get 等
等方法在特定的条件会调用进行额外的清理，但是 **ThreadLocal 被垃圾回收后，在 ThreadLocalMap
里对应的 Entry 的键值会变成 null，但是后续在也没有操作 set、get 等方法了。**

**所以最佳实践，应该在我们不使用的时候，主动调用 remove 方法进行清理。**

这里把 ThreadLocal 定义为 static 还有一个好处就是，由于 ThreadLocal 有强引用在，那么在
ThreadLocalMap 里对应的 Entry 的键会永远存在，那么执行 remove 的时候就可以正确进行定位到并且
删除！！！

**最佳实践做法应该为：**


###### 5 、下面的例子，输出结果是？

```
try {
// 其它业务逻辑
} finally {
threadLocal对象.remove();
}
```
```
1
2
3
4
5
```

```
答案： 100 个 5050
```
#### JD 一面：实现异步的 20 种方式，你知道几个？

异步，作为 **性能调优** 核心方式之一，经常被用于各种高并发场景。

很多场景多会使用到异步，比如：

场景 1 ： 超高并发批量写 mysql 、批量写 elasticSearch

场景 2 ： 超高并发批量 IO

场景 3 ： 超高并发发送短信、发邮件

场景 4 ： 超高并发发送消息


场景 5 ： 超高吞吐生产者、消费者场景

场景 6 ： 超高吞吐发布、订阅场景

场景 7 ： 分布式的通知场景

场景 8 ：异步回调场景

场景 9 ：其他的异步场景，不知道能列举出多少，总之非常多

**总之，异步，作为性能调优** 核心方式之一，经常被用于各种高并发场景。

所以， **异步** 是一个 **非常、非常核心的面试知识点** 。

在 40 岁老架构师尼恩的 **读者交流群 (50 个)** 中，其相关面试题，也是一个非常、非常高频的交流话题。其
大概的出题形式有：

```
形式 1 ：异步化作为应用调优的一个常用方式，你知道具体有几种方式实现吗？
```
```
形式 2 ：异步的实现方式有几种？
```
```
形式 3 ：异步调用，你知道哪些？
```
```
形式 4 ：异步调用，你用过哪些？
```
```
形式 5 ： 实现异步的 10 多种方式，你用过哪些？
```
```
形式 6 ： 实现异步的 10 多种方式，你知道几个？ （出自社群 美团一面）
```
```
形式 7 ： 请参考 《尼恩Java面试宝典》，还有很多变种........。
```
这里尼恩给大家做一下系统化、体系化的梳理，展示一下大家雄厚的 “技术肌肉”，让面试官爱到 “不能

自已、口水直流”。

###### 首先、什么是异步？

**同步：**

调用方在调用过程中，持续阻塞，一直到返回结果。

同步获取结果的方式是： 主动等待。

**异步：**

调用方在调用过程中，不会阻塞，不直接等待返回结果，而是执行其他任务。

异步获取结果的方式是 ： 被动通知或者被动回调。

###### 然后，梳理一下异步的 20 种实现方式

```
1. 新建线程Thread 实现异步
2. 线程池化 实现异步
3. Future 阻塞式异步
4. guava 回调式异步
5. Netty 回调式异步
6. Servlet 3.0 异步
7. CompletableFuture 回调式异步
8. JDK 9 Flow 响应式编程
9. RxJava 响应式 异步
10. Reactor 响应式 异步
11. Spring注解@Async 异步
12. EventBus 框架 发布订阅模式异步
```

```
13. Spring ApplicationEvent 事件 发布订阅模式
14. RocketMq 消息队列 分布式 发布订阅模式（Pub/Sub） 异步
15. Redis 消息队列 分布式 发布订阅模式（Pub/Sub） 异步
16. Distruptor 框架异步
17. ForkJoin 框架异步
18. RocketMQ源码中ServiceThread 能急能缓的高性能异步
19. Kotlin 协程 异步
20. Project Loom 协程 异步
```
###### 方式 1 ：新建线程 Thread 异步

在《Java 高并发核心编程卷 2 **加强版** 》 9.2.1 小节中，介绍了一个经典的异步案例《泡茶的案例》：

分别设计三条线程：泡茶线程（MainThread，主线程）、烧水线程（HotWarterThread）、清洗线程
（WashThread）。

```
泡茶线程的工作是：启动清洗线程、启动烧水线程，等清洗、烧水的工作完成后，泡茶喝；
清洗线程的工作是：洗茶壶、洗茶杯；
烧水线程的工作是：洗好水壶，灌上凉水，放在火上，一直等水烧开。
```
其中，负责烧水的线程 HotWarterThread、负责 WashThread 的线程，都是通过线程 Thread 异步的方
式，完成异步执行的。

具体的内容和示意图，来自于《Java 高并发核心编程卷 2 **加强版** 》 9.2.1 小节。示意图如下：

线程 Thread 异步的知识非常多，是 Java 高并发的基础知识，

具体请参见《Java 高并发核心编程卷 2 **加强版** 》1.3 节，示意图如下：


《Java 高并发核心编程卷 2 **加强版** 》电子版 PDF 是免费的，版本不断升级，提取最新版本可以找尼恩
即可。

###### 方式 2 ：线程池化异步

```
Thread线程和OS内核线程，是一一对应的关系，频繁的创建、销毁，浪费系统资源，并且涉及到进行
```
内核态和用户态的切换，这一切的一切，都是低性能的。

如何提升性能呢？可以将线程池化，就是线程池。

我们可以采用线程池，下面的代码，是来自于经历过双十一 100 Wqps 超高并发考验的 JD Hotkey 框架

的源码：

然后，可以将业务逻辑封装到 Runnable 或 Callable 中，交由线程池来执行。

下面的业务代码，是尼恩的第 26 章视频中基于 JD hotkey 源码二次定制的、用于实现三级缓存的数据
一致性的异步刷新代码：

```
public class AsyncPool {
private static ExecutorService threadPoolExecutor =
Executors.newCachedThreadPool();
```
```
public static void asyncDo(Runnable runnable) {
threadPoolExecutor.submit(runnable);
}
```
```
public static void shutDown() {
threadPoolExecutor.shutdown();
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
```
```
package com.jd.platform.hotkey.worker.netty.pusher;
....省略 import
/**
* 推送到各客户端服务器
*
* @author wuweifeng wrote on 2020-02-24
* @version 1.0
*/
@Component
```
```
1 2 3 4 5 6 7 8 9
```

```
public class RocketMqPusher implements IPusher {
/**
* 热key集中营
*/
private static LinkedBlockingQueue<HotKeyModel> hotKeyStoreQueue = new
LinkedBlockingQueue<>();
```
```
private static Logger logger =
LoggerFactory.getLogger(RocketMqPusher.class);
```
```
@Resource
MqSender mqSender;
public static class MqSender{
```
```
public DefaultMQProducer mqProducer;
public String topic;
```
```
public MqSender(DefaultMQProducer mqProducer, String topic) {
this.mqProducer = mqProducer;
this.topic = topic;
}
```
```
public void sendToMq(Command cmd) {
Message msg = new Message(topic, "", "",
cmd.json().getBytes());
try {
mqProducer.send(msg, 100000 );
} catch (Exception e) {
logger.error("Failed to publish {} to RocketMQ",
cmd.json(), e);
}
}
}
```
```
/**
* 给客户端推key信息
*/
@Override
public void push(HotKeyModel model) {
hotKeyStoreQueue.offer(model);
}
```
```
@Override
public void remove(HotKeyModel model) {
// push(model);
}
```
```
/**
* 和dashboard那边的推送主要区别在于，给app推送每10ms一次，dashboard那边1s一次
*/
@PostConstruct
public void batchPushToClient() {
AsyncPool.asyncDo(() -> {
while (true) {
try {
List<HotKeyModel> tempModels = new ArrayList<>();
//每10ms推送一次
```
10
11
12
13
14

15
16

17
18
19
20
21
22
23
24
25
26
27
28
29
30
31

32
33
34
35

36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62


线程 Thread 异步的知识非常多，是 Java 高并发的基础知识，

具体请参见《Java 高并发核心编程卷 2 **加强版** 》1.6 节，示意图如下：

《Java 高并发核心编程卷 2 **加强版** 》电子版 PDF 是免费的，版本不断升级，提取最新版本可以找尼恩
即可。

###### 方式 3 ：Future 阻塞式异步

为了获取异步线程的返回结果，以及更好的对异步线程的干预，Java 在 1.5 版本之后提供了一种新的多线
程的创建方式—— FutureTask 方式。

FutureTask 方式包含了一系列的 Java 相关的类，处于 java. util. concurrent 包中。

使用 FutureTask 方式进行异步调用时，所涉及的重要组件为 FutureTask 类和 Callable 接口。

Future 的调用方式，属于 **阻塞式异步**

主要原因在于，在获取异步线程处理结果时，需要主线程主动通过 Future.get () 去获取，

如果异步线程没有执行完，那么 Future.get () 会阻塞调用线程，一直到超时。

```
Queues.drain(hotKeyStoreQueue, tempModels, 10 , 10 ,
TimeUnit.MILLISECONDS);
if (CollectionUtil.isEmpty(tempModels)) {
continue;
}
String[] keys = tempModels.stream().map(m ->
m.getKey()).toArray(String[]::new);
mqSender.sendToMq(new Command(Command.OPT_HOT_KEY,
null, keys));
} catch (Exception e) {
e.printStackTrace();
}
}
});
}
}
```
```
63
```
```
64
65
66
67
```
```
68
```
```
69
70
71
72
73
74
75
```

参考的代码如下：

具体的内容和示意图，来自于《Java 高并发核心编程卷 2 **加强版** 》 9.2.1 小节。示意图如下：

**阻塞式异步 Future 的不足之处**

Future 的不足之处的包括以下几点：

```
无法被动接收异步任务的计算结果：
虽然我们可以主动将异步任务提交给线程池中的线程来执行，但是待异步任务执行结束之后，主线
程无法得到任务完成与否的通知，它需要通过get方法主动获取任务执行的结果。
Future件彼此孤立：
有时某一个耗时很长的异步任务执行结束之后，你想利用它返回的结果再做进一步的运算，该运算
也会是一个异步任务，两者之间的关系需要程序开发人员手动进行绑定赋予，Future并不能将其
形成一个任务流（pipeline），每一个Future都是彼此之间都是孤立的，所以才有了后面的
CompletableFuture，CompletableFuture就可以将多个Future串联起来形成任务流。
Futrue没有很好的错误处理机制：
截止目前，如果某个异步任务在执行发的过程中发生了异常，调用者无法被动感知，必须通过捕获
get方法的异常才知晓异步任务执行是否出现了错误，从而在做进一步的判断处理。
```
**伪异步与纯异步**

异步调用目的在于防止当前业务线程被阻塞。

但是 Future 阻塞式异步属于伪异步

**伪异步** 就是将任务包装为 Runnable/ Callable 作为 Biz 业务线程（被调用线程）的任务去执行，并调用
方阻塞等待，当前 Biz 线程不阻塞；

**纯异步** 为回调式异步。他们的区别不在于是否将请求放入另一个线程池执行，而在于是否有线程阻塞等
待 Response。

在前面的异步阻塞版本的泡茶喝的实现中：

```
泡茶线程是调用线程，
烧水（或者清洗）线程是被调用线程，
调用线程和被调用线程之间是一种主动关系，而不是被动关系。
```

```
泡茶线程需要主动获取烧水（或者清洗）线程的执行结果，二者协同的方式是调用方阻塞。
```
为什么说二者协同的方式是调用方阻塞？调用方线程需要通过 join () 或 Future.get () 阻塞式的干预异步操
作或者获取异步结果，这里，是阻塞模式的异步， **伪异步**

这种调用方线程的阻塞，是线程资源的一种浪费。

线程资源，是宝贵的。怎么充分的利用线程资源呢？

有效方式之一： **回调模式的异步** 。实现 **纯纯的异步**

###### 方式 4 ：guava 回调式异步

由于 JDK 在 1.8 之前没有 **回调式异步组件** ，于是出现了很多开源的 **回调式异步组件** 。

比较常用的是 guava 的回调式异步。

Guava 是 Google 提供的 Java 扩展包，它提供了一种异步回调的解决方案。

Guava 中与异步回调相关的源码处于 com. google. common. util. concurrent 包中。

包中的很多类都用于对 java. util. concurrent 的能力扩展和能力增强。

比如，Guava 的异步任务接口 ListenableFuture 扩展了 Java 的 Future 接口，实现了异步回调的的能力。

使用 Guava 组件实现异步回调模式的泡茶喝实例，具体的原理和代码请参见《Java 高并发核心编程
卷 2 **加强版** 》9.5.4 章, 示意图如下:

出于篇幅原因，这里不做赘述，请大家看 PDF 电子书 （可找尼恩面试获取最新版），书里非常细致。

###### 方式 5 ：Netty 回调式异步

由于 JDK 在 1.8 之前没有 **回调式异步组件** ，于是出现了很多开源的 **回调式异步组件** 。

Netty 也算其中之一。


Netty 是一个著名的高性能 NIO 王者框架，是 IO 的王者组件。具体，请参见尼恩梳理的四大王者组
件。

Netty 除了作为 NIO 框架之王，其子模也是可以单独使用的，比如说 **异步回调模块** 。

Netty 的 **回调式异步组件** 更加牛掰，为啥呢？

通过 Netty 源码可以知道： Netty 的 **回调式异步组件** 不光提供了外部的回调监听设置，而且可以在异步
代码中，通过 Promise 接口，可以对回调结果进行干预，比如说在进行回调之前，执行一些其他的操
作。

当然，Netty 的源码更加复杂，这部分内容，请参考尼恩的《第 21 章视频，彻底穿透 Netty 源码视
频》。

使用 Netty 的 **回调式异步组件** 实现异步回调模式的泡茶喝实例，具体的原理和代码请参见《Java 高
并发核心编程卷 2 **加强版** 》9.5.4 章, 示意图如下:

出于篇幅原因，这里不做赘述，请大家看 PDF 电子书 （可找尼恩面试获取最新版），书里非常细致。

###### Callback Hell（回调地狱）问题

无论是 Google Guava 包中的 ListenableFuture，还是 Netty 的 GenericFutureListener，都是需要设
置专门的 Callback 回调钩子

Guava 包中的 ListenableFuture，设置 Callback 回调钩子的实例如下：

```
ListenableFuture<Boolean> wFuture = gPool.submit(wJob);
```
```
Futures.addCallback(wFuture, new FutureCallback<Boolean>() {
public void onSuccess(Boolean r) {
if (!r) {
Print.tcfo("杯子洗不了，没有茶喝了");
} else {
```
```
countDownLatch.countDown();
```
```
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
```

调用方通过 Futures.addCallback () 添加处理结果的回调函数。

这样避免获取并处理异步任务执行结果阻塞调起线程的问题。

Callback 是将任务执行结果作为接口的入参，在任务完成时回调 Callback 接口，执行后续任务，从而
解决纯 Future 方案无法方便获得任务执行结果的问题。

但 Callback 产生了新的问题，那就是代码可读性的问题。

因为使用 Callback 之后，代码的字面形式和其所表达的业务含义不匹配，即业务的先后关系到了代码
层面变成了包含和被包含的关系。

**因此，如果大量使用 Callback 机制，将使大量的存在先后次序的业务逻辑，在代码形式上，转换成层
层嵌套，**

**从而导致：业务先后次序在代码维度被打乱，最终造成代码不可理解、可读性差、难以理解、难以维
护。**

**这便是所谓的 Callback Hell（回调地狱）问题。**

Callback Hell 问题可以从两个方向进行一定的解决：

```
一是链式调用
二是事件驱动机制。
```
前被 CompletableFuture、反应式编程等技术采用，后者被如 EventBus、Vert. x 所使用。

###### 方式 6 ：Servlet 3.0 异步

梳理一下： Callback 异步回调的使用场景。

Callback 真正体现价值，是它与 NIO 技术结合之后。

```
CPU 密集型场景，采用 Callback 回调没有太多意义；
IO 密集型场景，如果是使用 BIO模式，Callback 同样没有意义，因为一个连接一个线程，IO线程
是因为 IO 而阻塞。
IO 密集型场景，如果是使用 NIO 模式，使用Callback 才有意义。 NIO是少量IO线程负责大量IO
通道，IO线程需要避免线程阻塞，所以，也必须使用 Callback ，才能使应用得以被开发出来。
```
所以，高性能的 NIO 框架如 Netty ，都是基于 Callback 异步回调的。

但是，在微服务流行的今天，Netty 却没有在 WEB 服务器中占据统治地位。

微服务系统中，多级服务调用很常见，一个服务先调 A，再用结果 A 调 B，然后用结果 B 调用 C，等
等。

如果使用 Netty 作为底层服务器，IO 线程能大大降低，能处理的连接数（/请求数）也能大大增加，那
么，为啥 Netty 却没有在 WEB 服务器中占据统治地位呢？

这其中的难度来自两方面：

```
一是 NIO 和 Netty 本身的技术难度，
二是 Callback hell：Callback 风格所导致的代码理解和维护的困难。
```
因此，Netty 通常用于在基础架构层面，在业务系统中应用较少。

```
}
```
```
public void onFailure(Throwable t) {
Print.tcfo("杯子洗不了，没有茶喝了");
}
});
```
```
12
13
14
15
16
17
```

这也是大厂小伙人人要求精通 Netty，而中小厂小伙伴，不怎么认识 Netty 的原因。

当然，作为 IO 之王，学习 Netty 对应提升大家的内功，是至关重要的。

Netty 的知识，具体请参见《Java 高并发核心编程卷 1 加强版》, 很多小伙伴，靠此书入的门。

直接使用 Netty 开发 WEB 应用会遇到技术难度挑战、以及 Callback Hell 问题。

所以，Servlet 3.0 提供了一个异步解决方案。

**什么是 servlet 异步请求**

Servlet 3.0 之前，一个普通 Servlet 的主要工作流程大致如下：

（ 1 ）Servlet 接收到请求之后，可能需要对请求携带的数据进行一些预处理；

（ 2 ）调用业务接口的某些方法，以完成业务处理；

（ 3 ）根据处理的结果提交响应，Servlet 线程结束。

其中第二步处理业务逻辑时候很可以碰到比较耗时的任务，此时 servlet 主线程会阻塞等待完成业务处
理，

对于并发比较大的请求可能会产生性能瓶颈，则 servlet 3.0 之后再此处做了调整，引入了异步的概念。

（ 1 ）Servlet 接收到请求之后，可能需要对请求携带的数据进行一些预处理；

（ 2 ）调用业务接口的某些方法过程中 request.startAsync () 请求，获取一个 AsyncContext

（ 3 ）紧接着 servlet 线程退出 (回收到线程池)，但是响应 response 对象仍旧保持打开状态，新增线程会
使用 AsyncContext 处理并响应结果。

（ 4 ）AsyncContext 处理完成触发某些监听通知结果

Servlet 3.0 的出现，解决了在过去基于 Servlet 的 Web 应用中，接受请求和返回响应必须在同一个线
程的问题，实现了如下目标：

```
@WebServlet(urlPatterns = "/demo", asyncSupported = true)
public class AsyncDemoServlet extends HttpServlet {
@Override
public void doGet(HttpServletRequest req, HttpServletResponse resp)
throws IOException, ServletException {
// Do Something
```
```
AsyncContext ctx = req.startAsync();
startAsyncTask(ctx);
}
}
```
```
private void startAsyncTask(AsyncContext ctx) {
requestRpcService(result -> {
try {
PrintWriter out = ctx.getResponse().getWriter();
out.println(result);
out.flush();
ctx.complete();
} catch (Exception e) {
e.printStackTrace();
}
});
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
```

```
1. 可以避免了 Web 容器的线程被阻塞挂起
2. 使请求接收之后的任务处理可由专门线程完成
3. 不同任务可以实现线程池隔离
4. 结合 NIO 技术实现更高效的 Web 服务
```
除了直接使用 Servlet 3.0，也可以选择 Spring MVC 的 Deferred Result。

示例：Spring MVC DeferredResult

**Servlet 3.0 的技术局限**

Servlet 3.0 并不是用来解决前面提到的 Callback Hell 问题的，它只是降低了异步 Web 编程的技术门
槛。

对于 Callback Hell 问题，使用 Servlet 3.0 或类似技术时同样会遇到。

解决 Callback Hell 还需另寻他法。

###### 方式 7 ：回调式异步 CompletableFuture

JDK 1.8 之前并没有实现回调式的异步，CompletableFuture 是 JDK 1.8 引入的实现类，实现了 JDK 内置的
异步回调模式异步。

CompletableFuture 的创新是： **通过链式调用，解决 Callback Hell（回调地狱）问题** ，让代码变得
的可理解行更强，可读性更强。

CompletableFuture 该类实现了 Future 和 CompletionStage 两个接口。

该类的实例作为一个异步任务，可以在自己异步执行完成之后触发一些其他的异步任务，从而达到异步
回调的效果。

使用 CompletableFuture 实现泡茶喝实例的实现，参考如下：

```
@GetMapping("/async-deferredresult")
public DeferredResult<ResponseEntity<?>> handleReqDefResult(Model model) {
LOG.info("Received async-deferredresult request");
DeferredResult<ResponseEntity<?>> output = new DeferredResult<>();
```
```
ForkJoinPool.commonPool().submit(() -> {
LOG.info("Processing in separate thread");
try {
Thread.sleep( 6000 );
} catch (InterruptedException e) {
}
output.setResult(ResponseEntity.ok("ok"));
});
```
```
LOG.info("servlet thread freed");
return output;
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
```
```
package com.crazymakercircle.completableFutureDemo;
```
```
import com.crazymakercircle.util.Print;
```
```
import java.util.concurrent.CompletableFuture;
```
```
import static com.crazymakercircle.util.ThreadUtil.sleepSeconds;
```
```
1 2 3 4 5 6 7
```

具体的内容和示意图，来自于《Java 高并发核心编程卷 2 **加强版** 》 10 章。示意图如下：

```
public class DrinkTea {
private static final int SLEEP_GAP = 3 ;//等待 3 秒
```
```
public static void main(String[] args) {
```
```
// 任务 1
CompletableFuture<Boolean> washJob =
CompletableFuture.supplyAsync(() ->
{
Print.tcfo("洗茶杯");
//线程睡眠一段时间，代表清洗中
sleepSeconds(SLEEP_GAP);
Print.tcfo("洗完了");
```
```
return true;
});
```
```
// 任务 2
CompletableFuture<Boolean> hotJob =
CompletableFuture.supplyAsync(() ->
{
Print.tcfo("洗好水壶");
Print.tcfo("烧开水");
```
```
//线程睡眠一段时间，代表烧水中
sleepSeconds(SLEEP_GAP);
Print.tcfo("水开了");
return true;
```
```
});
```
```
// 任务 3 ：任务 1 和任务 2 完成后执行：泡茶
CompletableFuture<String> drinkJob =
washJob.thenCombine(hotJob, (hotOk, washOK) ->
{
if (hotOk && washOK) {
Print.tcfo("泡茶喝，茶喝完");
return "茶喝完了";
}
return "没有喝到茶";
});
```
```
// 等待任务 3 执行结果
Print.tco(drinkJob.join());
}
}
```
```
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
```

出于篇幅原因，这里不做赘述，请大家看 PDF 电子书 （可找尼恩面试获取最新版），书里非常细致。

###### 方式 8 ：JDK 9 Flow 响应式编程

但是 JDK 8 的 CompletableFuture 属于链式调用，它在形式上带有一些响应式编程的函数式代码风
格。

因为 Callback Hell 对代码可读性有很大杀伤力，从开发人员的角度来讲，反应式编程技术和链式调用
一样，使得代码可读性要比 Callback 提升了许多。

响应式流从 2013 年开始，作为提供非阻塞背压的异步流处理标准的倡议。

Reactive Stream 是一套基于发布/订阅模式的数据处理规范。

更确切地说，Reactive 流目的是“找到最小的一组接口，方法和协议，用来描述必要的操作和实体以实现
这样的目标：以非阻塞背压方式实现数据的异步流”。

**响应式流（Reactive Streams）** 是一个响应式编程的规范，用来为具有非阻塞背压（Back pressure）
的异步流处理提供标准，用最小的一组接口、方法和协议，用来描述必要的操作和实体。这里涉及到一
个关键概念叫 **Backpressure** ，国内大部分翻译为背压，我们先来了解这是什么。

响应式编程，其实就是对数据流的编程，而对流的处理对数据流的变化进行响应，是通过异步监听的方
式来处理的。既然是异步监听，就涉及到监听事件的发布者和订阅者，数据流其实就是由发布者生产，
再由一个或多个订阅者进行消费的元素（item）序列。

那么，如果发布者生产元素的速度和订阅者消费元素的速度不一样，是否会出现问题呢？其实就两种情
况：

```
发布者生产的速度比订阅者消费的速度慢，那生产的元素可以及时被处理，订阅者处理完只要等待
发布者发送下一元素即可，这不会产生什么问题。
发布者生产的速度比订阅者消费的速度快，那生产的元素无法被订阅者及时处理，就会产生堆积，
如果堆积的元素多了，订阅者就会承受巨大的资源压力(pressure)而有可能崩溃。
```
要应对第二种情况，就需要进行 **流控制** （flow control）。

流控制有多种方案，其中一种机制就是 Back pressure，即背压机制，其实就是下游能够向上游反馈流
量需求的机制。


如果生产者发出的数据比消费者能够处理的数据量大而且快时，消费者可能会被迫一直再获取或处理数
据，消耗越来越多的资源，从而埋下潜在的风险。为了防止这一点，消费者可以通知生产者降低生产数
据的速度。生产者可以通过多种方式来实现这一要求，这时候我们就会用到背压机制。

采用背压机制后，消费者告诉生产者降低生产数据速度并保存元素，知道消费者能够处理更多的元素。
使用背压可以有效地避免过快的生产者压制消费者。如果生产者要一直生产和保存元素，使用背压也可
能会要求其拥有无限制的缓冲区。生产者也可以实现有界缓冲区来保存有限数量的元素，如果缓冲区已
满可以选择放弃。

**背压的实现方式**

背压的实现方式有两种：

```
一种是阻塞式背压
另一种是非阻塞式背压。
```
**1 、阻塞式背压**

阻塞式背压是比较容易实现的，例如：当生产者和消费者在同一个线程中运行时，其中任何一方都将阻
塞其他线程的执行。这就意味着，当消费者被执行时，生产者就不能发出任何新的数据元素。因而也需
要一中自然地方式来平衡生产数据和消费数据的过程。

在有些情况下，阻塞式背压会出现不良的问题，比如：当生产者有多个消费者时，不是所有消费者都能
以同样的速度消费消息。当消费者和生产者在不同环境中运行时，这就达不到降压的目的了。

**2 、非阻塞式背压**

背压机制应该以非阻塞式的方式工作，实现非阻塞式背压的方法是放弃推策略，采用拉策略。生产者发
送消息给消费者等操作都可以保存在拉策略当中，消费者会要求生产者生成多少消息量，而且最多只能
发送这些量，然后等到更多消息的请求。

OK， **Backpressure** 解释完毕。其实，《Java 高并发核心编程卷 3 加强版》介绍得更加清楚，大家可
以系统化的去看看书。

JDK 8 的 CompletableFuture 不算是反应式编程，不遵守 Reactive Stream (响应式流/反应流) 规范。

JDK 9 Flow 是 JDK 对 Reactive Stream (响应式流/反应流) 的实现，

Java 9 中新增了反应式/响应式编程的 Api-Flow。

在 Flow 中存在 Publisher（发布者）、Subscriber（订阅者）、Subscription（订阅）和

`Processor（处理器）。

Flow `结构如下:


JDK 9 Flow 旨在解决处理元素流的问题——如何将元素流从发布者传递到订阅者，而不需要发布者阻
塞，或订阅者需要有无限制的缓冲区或丢弃。

当然，实施响应式编程，需要完整的解决方案，单靠 Flow 是不够的，还是需要 Netflix RxJava、
Project Reactor 这样的完整解决方案。

但是， JDK 层面的技术能提供统一的技术抽象和实现，在统一技术方面还是有积极意义的。

所以，这里不对 JDK 9 Flow 做介绍。

###### 方式 9 ：RxJava 响应式异步

在 JDK 9 Flow 之前，响应式编程的框架，早就存在。

比如说，席卷了 android 端编程的 RxJava 框架。RxJava 是一种响应式编程，来创建基于事件的异步操
作库。

这个组件，是 Netflix 的杰作，也叫作 Netflix RxJava。

这个框架，在 Java 后端的中间件中，也有广泛使用，比如在 Hystrix 源码中，就用大量用到。

总之，RxJava 框架很重要，具体请参见《Java 高并发核心编程卷 3 加强版》

使用 RxJava 基于事件流的链式调用、代码逻辑清晰简洁。

```
package com.crazymakercircle.completableFutureDemo;
```
```
import com.crazymakercircle.util.Print;
import io.reactivex.Observable;
import io.reactivex.schedulers.Schedulers;
import org.junit.Test;
```
```
import java.util.concurrent.CompletableFuture;
```
```
import static com.crazymakercircle.util.ThreadUtil.sleepMilliSeconds;
import static com.crazymakercircle.util.ThreadUtil.sleepSeconds;
```
```
public class IntegrityDemo {
/**
* 模拟模拟RPC调用 1
*/
public String rpc1() {
//睡眠400ms,模拟执行耗时
sleepMilliSeconds( 600 );
Print.tcfo("模拟RPC调用：服务器 server 1");
return "sth. from server 1";
}
```
```
/**
* 模拟模拟RPC调用 2
*/
public String rpc2() {
//睡眠400ms,模拟执行耗时
sleepMilliSeconds( 600 );
Print.tcfo("模拟RPC调用：服务器 server 2");
return "sth. from server 2";
}
```
```
@Test
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
```

如果需要从设计模式的高度理解 Rxjava、或者响应式编程，请参考《Java 高并发核心编程卷 3 **加强
版** 》 5 章。示意图如下：

```
public void rpcDemo() throws Exception {
CompletableFuture<String> future1 =
CompletableFuture.supplyAsync(() ->
{
return rpc1();
});
CompletableFuture<String> future2 =
CompletableFuture.supplyAsync(() -> rpc2());
CompletableFuture<String> future3 = future1.thenCombine(future2,
(out1, out2) ->
{
return out1 + " & " + out2;
});
String result = future3.get();
Print.tco("客户端合并最终的结果：" + result);
}
```
```
@Test
public void rxJavaDemo() throws Exception {
Observable<String> observable1 = Observable.fromCallable(() ->
{
return rpc1();
}).subscribeOn(Schedulers.newThread());
Observable<String> observable2 = Observable
.fromCallable(() ->
rpc2()).subscribeOn(Schedulers.newThread());
```
```
Observable.merge(observable1, observable2)
.observeOn(Schedulers.newThread())
.toList()
.subscribe((result) -> Print.tco("客户端合并最终的结果：" +
result));
```
```
sleepSeconds(Integer.MAX_VALUE);
}
}
```
```
35
36
```
```
37
38
39
40
```
```
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
```
```
58
59
60
61
62
```
```
63
64
65
66
```

###### 方式 10 ：Reactor 响应式异步

目前，在 Java 领域实现了反应式编程的技术除了 Netflix RxJava ，还有 Spring 的 Project Reactor。

Netflix 网飞的 RxJava 出现时间更早，在前端开发领域应用的比后端更要广泛一些。

Spring 的 Project Reactor 的 3.0 版本作为 Spring 5 的基础，在 17 年底发布，推动了后端领域反应式编
程的发展。

关于 Reactor 响应式异步的内容，请参考尼恩的另外一篇博客，

Flux、Mono、Reactor 实战（史上最全）

这篇文章，被小伙伴认为是全网介绍 Reactor 组件 **讲得最好的文章** ，

其实尼恩的其他文章，非常优质，大家都可以看看。

由于性能比较高，响应式编程越来越普及，建议大家及早掌握。

尼恩的 50 个群中，很多开始响应式编程的小伙伴反馈： 入手难、后面爽。


###### 方式 11 ：Spring 的@Async 异步

在 Spring 中，使用@Async 标注某方法，可以使该方法变成异步方法，这些方法在被调用的时候，将会
在独立的线程中进行执行，调用者不需等待该方法执行完成。

但在 Spring 中使用@Async 注解，需要使用@EnableAsync 来开启异步调用。

一个 AsyncService 参考代码如下：

@Async 注解，默认使用系统自定义线程池。

```
public interface AsyncService {
```
```
MessageResult sendSms(String callPrefix, String mobile, String
actionType, String content);
```
```
MessageResult sendEmail(String email, String subject, String content);
}
```
```
@Slf4j
@Service
public class AsyncServiceImpl implements AsyncService {
```
```
@Autowired
private IMessageHandler mesageHandler;
```
```
@Override
@Async("taskExecutor")
public MessageResult sendSms(String callPrefix, String mobile, String
actionType, String content) {
try {
```
```
Thread.sleep( 1000 );
mesageHandler.sendSms(callPrefix, mobile, actionType, content);
```
```
} catch (Exception e) {
log.error("发送短信异常 -> ", e)
}
}
```
```
@Override
@Async("taskExecutor")
public sendEmail(String email, String subject, String content) {
try {
```
```
Thread.sleep( 1000 );
mesageHandler.sendsendEmail(email, subject, content);
```
```
} catch (Exception e) {
log.error("发送email异常 -> ", e)
}
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
```
```
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
```

在实际项目中，推荐等方式是是使用自定义线程池的模式。

可在项目中设置多个线程池，在异步调用的时候，指明需要调用的线程池名称，比如：
@Async ("taskName")

自定义异步线程池的代码如下

###### 方式 12 ：EventBus 发布订阅模式异步

实际开发中，常常通过事件总线 EventBus/AsyncEventBus 进行 JAVA 模块解耦，

比如，在顶级开源组件 JD hotkey 的源码中，就多次用到 EventBus/AsyncEventBus 进行 JAVA 模块解耦

掌握了 EventBus ，在平时的开发中，多了一个神器

```
/**
* 线程池参数配置，多个线程池实现线程池隔离
@EnableAsync
@Configuration
public class TaskPoolConfig {
/**
* 自定义线程池
*
**/
@Bean("taskExecutor")
public Executor taskExecutor() {
//返回可用处理器的Java虚拟机的数量 12
int i = Runtime.getRuntime().availableProcessors();
System.out.println("系统最大线程数 ： " + i);
ThreadPoolTaskExecutor executor = new ThreadPoolTaskExecutor();
//核心线程池大小
executor.setCorePoolSize( 16 );
//最大线程数
executor.setMaxPoolSize( 20 );
//配置队列容量，默认值为Integer.MAX_VALUE
executor.setQueueCapacity( 99999 );
//活跃时间
executor.setKeepAliveSeconds( 60 );
//线程名字前缀
executor.setThreadNamePrefix("asyncServiceExecutor -");
//设置此执行程序应该在关闭时阻止的最大秒数，以便在容器的其余部分继续关闭之前等待
剩余的任务完成他们的执行
executor.setAwaitTerminationSeconds( 60 );
//等待所有的任务结束后再关闭线程池
executor.setWaitForTasksToCompleteOnShutdown(true);
return executor;
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
```
```
27
28
29
30
31
32
```

EventBus 是 Guava 的事件处理机制，是观察者模式（生产/消费模型）的一种实现。

EventBus 是 google 的 Guava 库中的一个处理组件间通信的事件总线，它基于发布/订阅模式，实现了多
组件之间通信的解耦合，事件产生方和事件消费方实现解耦分离，提升了通信的简洁性。

观察者模式在我们日常开发中使用非常广泛，

例如在订单系统中，订单状态或者物流信息的变更会向用户发送 APP 推送、短信、通知卖家、买家等
等；审批系统中，审批单的流程流转会通知发起审批用户、审批的领导等等。

Observer 模式也是 JDK 中自带就支持的，其在 1.0 版本就已经存在 Observer，

不过随着 Java 版本的飞速升级，其使用方式一直没有变化，许多程序库提供了更加简单的实现，例如
Guava EventBus、RxJava、EventBus 等

为什么要用 **EventBus** ，其优点 ？

**EventBus 优点**

```
相比 Observer 编程简单方便
通过自定义参数可实现同步、异步操作以及异常处理
单进程使用，无网络影响
```
**缺点**

```
只能单进程使用
项目异常重启或者退出不保证消息持久化
```
如果需要分布式使用还是需要使用 MQ

**使用事件总线的场景**

当一个事件的发生 (事件产生方)，需要触发很多事件 (事件消费方) 的时候，我们通常会在事件产生方中，
分别的去调用那些事件消费方，这样往往是很浪费资源。事件的产生方与事件的消费方，产生了极大的
耦合，如果我们要改动某一个事件消费方，我们很可能还要改动事件的产生方。

在工作中，经常会遇见使用异步的方式来发送事件，或者触发另外一个动作：经常用到的框架是
MQ（分布式方式通知）; 如果是同一个 jvm 里面通知的话，就可以使用 EventBus 事件总线。

由于 EventBus 使用起来简单、便捷，因此，工作中会经常用到。


EventBus 是线程安全的，分发事件到监听器，并提供相应的方式让监听器注册它们自己。

EventBus 允许组件之间进行 “发布-订阅” 式的通信，而不需要这些组件彼此知道对方。

EventBus 是专门设计用来替代传统的 Java 进程内的使用显示注册方式的事件发布模式。

EventBus 不是一个通用的发布-订阅系统，也不是用于进程间通信。

EventBus 有三个关键要素：

1 、事件（Event)

事件是 EventBus 之间相互通信的基本单位，一个 Event 可以是任何类型。

对，没错，就是 Object，只要你想将任意一个 Bean 作为事件，这个类不需要做任何改变，就可以作为
事件 Event。不过在项目中不会这么随便（除非对代码严谨度没什么要求。。）

，一般会定义特定的事件类，类名以 Event 作为后缀，里面定义一些变量或者函数等。

2 、事件发布者（Publisher）

事件发布者，就是发送事件到 EventBus 事件总线的一方，事件发布者调用 Post () 方法，将事件发给
EventBus。

你可以在程序的任何地方，调用 EventBus 的 post () 方法，发送事件给 EventBus，由 EventBus 发送给订
阅者们。

3 、事件订阅者（Subscriber）

事件订阅者，就是接收事件的一方，这些订阅者需要在自己的方法上，添加@Subscribe 注解声明自己
为事件订阅者。不过只声明是不够的，还需要将自己所在的类，注册到 EventBus 中，EventBus 才能扫
描到这个订阅者。

关于 EventBus 的原理和实操内容，请参考尼恩的另外一篇博客，

通过事件总线 EventBus/AsyncEventBus 进行 JAVA 模块解耦 （史上最全）

###### 方法 13 ：Spring ApplicationEvent 事件实现异步

Spring 内置了简便的事件机制，原理和 EventBus 差不多

通过 Spring ApplicationEvent 事件，可以非常方便的实现事件驱动，核心类包括

```
ApplicationEvent，具体事件内容，事件抽象基类，可继承该类自定义具体事件
ApplicationEventPublisher，事件发布器，可以发布ApplicationEvent，也可以发布普通的
Object对象
```

```
ApplicationListener，事件监听器，可以使用注解@EventListener
TransactionalEventListener，事务事件监听，可监听事务提交前、提交后、事务回滚、事务完成
（成功或失败）
```
**使用示例：不定义事件，直接发布 Object 对象，同步**

1 、定义发送事件对象

2 、定义事件监听器

可以添加条件 condition，限制监听具体的事件

3 、定义发送接口以及实现类

```
public class UserEntity {
private long id;
private String name;
private String msg;
}
```
```
1 2 3 4 5 6
```
```
@Slf4j
@Component
public class RegisterListener {
```
```
@EventListener(condition = "#entity.id != null and #entity.async==false
")
public void handlerEvent(UserEntity entity) {
```
```
try {
// 休眠 5 秒
TimeUnit.SECONDS.sleep( 5 );
} catch (InterruptedException e) {
e.printStackTrace();
}
log.info("handlerEvent: {}", entity);
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
```
```
public interface IRegisterService {
```
```
public void register(String name);
```
```
}
```
```
1
2
3
4
5
```
```
@Service
public class RegisterServiceImpl implements IRegisterService {
@Resource
private ApplicationEventPublisher applicationEventPublisher;
```
```
@Override
public void publish(String name) {
UserEntity entity = new UserEntity();
entity.setName(name);
entity.setId(1L);
```
```
1 2 3 4 5 6 7 8 9
```
```
10
```

4 、测试 Controller 类，进行测试

在浏览器中输入地址：http://localhost/test?name=nik

控制台输出：

但是，上面的案例是同步事件，如果需要编程异步事件，还需要加上额外的注解：

1 、在启动类添加异步注解 @EnableAsync

2 、在监听方法上添加注解 @Async

###### 方法 14 ： RocketMq 消息队列分布式发布订阅模式异步

上游系统对下游系统的调用若为同步调用，则会大大降低系统的吞吐量与并发度，且系统耦合度太高。

而异步调用则会解决这些问题。

```
entity.setMsg("新用户注册同步调用");
applicationEventPublisher.publishEvent(entity);
}
}
```
```
11
12
13
14
```
```
@Slf4j
@Controller
public class TestController {
```
```
@Resource
private IRegisterService registerService;
```
```
@RequestMapping("test")
@ResponseBody
public void test1(String name) {
registerService.publish(name);
log.info("执行同步调用结束");
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
```
```
handlerEvent: UserEntity(id=1, name=nik, msg=新用户注册同步调用)
执行同步调用结束
```
```
1
2
3
```
```
@Async
@EventListener(condition = "#entity.name != null and #entity.async ")
public void handlerEventAsync(UserEntity entity) {
```
```
try {
TimeUnit.SECONDS.sleep(5);
} catch (InterruptedException e) {
e.printStackTrace();
}
log.info("handlerEventAsync: {}", entity);
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
```

所以两层之间若要实现由同步到异步的转化，一般性做法就是，在这两层间添加一个 MQ 层。

RocketMq 消息队列分布式发布订阅模式（Pub/Sub） ，

基于事件的系统中，Pub/Sub 是目前广泛使用的通信模型，它采用事件作为基本的通信机制，提供大规
模系统所要求的松散耦合的交互模式：订阅者 (如客户端) 以事件订阅的方式表达出它有兴趣接收的一个
事件或一类事件；发布者 (如服务器) 可将订阅者感兴趣的事件随时通知相关订阅者。

**上游生产者参考**

```
1. 创建producer组
2. 设置NameServer地址 ： 如果实在安装不上，可以使用这个地址：115.159.88.63:9876
3. startr生产者
4. 发送消息获取结果
5. 结束producer
```
```
public class Producer {
```
```
public static void main(String[] args) throws Exception {
```
```
//1.创建生产者组
DefaultMQProducer producer = new DefaultMQProducer("producer-
hello");
```
```
//2.设置NameServer地址
producer.setNamesrvAddr("127.0.0.1:9876");
```
```
//3.启动producer实例
producer.start();
```
```
//4.创建消息
Message message = new Message("log-topic", "info-tag", "这是一个info
信息".getBytes(RemotingHelper.DEFAULT_CHARSET));
```
```
//5.发送消息
SendResult result = producer.send(message);
```
```
//6.关闭producer实例
System.out.println("发送完毕，结果: "+result);
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
```
```
16
17
18
19
20
21
22
23
24
```

**下游消费者参考**

```
1. 创建consumer组
2. 设置Name Server地址
3. 设置消费位置，从最开始销毁
4. 设置消息回调处理监听 -> 处理消息
5. Start consumer
```
```
DefaultMQPushConsumer ：消费者 ， 可以指定 consumerGroupName
consumer.setNamesrvAddr : 设置name server 地址
```
```
public class Consumer {
public static void main(String[] args) throws MQClientException {
//1.创建消费者组
DefaultMQPushConsumer consumer = new
DefaultMQPushConsumer("consumer-hello");
```
```
//2.设置NameServer地址
consumer.setNamesrvAddr("127.0.0.1:9876");
```
```
//3.订阅topic，指定tag标签
consumer.subscribe("log-topic","info-tag");
```
```
//4.注册消息监听器
consumer.registerMessageListener(new MessageListenerConcurrently(){
```
```
public ConsumeConcurrentlyStatus
consumeMessage(List<MessageExt> msgs, ConsumeConcurrentlyContext context) {
System.out.printf("%s 接收到新的消息: %n",
Thread.currentThread().getName());
msgs.stream().forEach(messageExt -> {
String body = null;
try {
body = new String(messageExt.getBody(),
RemotingHelper.DEFAULT_CHARSET);
} catch (UnsupportedEncodingException e) {
e.printStackTrace();
}
System.out.println(body);
});
//失败消费，稍后尝试消费,会进行多次重试
//return ConsumeConcurrentlyStatus.RECONSUME_LATER;
```
```
return ConsumeConcurrentlyStatus.CONSUME_SUCCESS;
}
});
```
```
//5.启动消费者
consumer.start();
```
```
System.out.println("消费者启动...");
```
```
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
```
```
16
```
```
17
18
19
20
```
```
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
```

```
consumer.setConsumeFromWhere(ConsumeFromWhere.CONSUME_FROM_FIRST_OFFSET)
：从什么位置开始消费
consumer.subscribe(“topic_log”, “tags_error”) ：订阅某个topic下的某个tags的消息
consumer.registerMessageListener ：注册消息监听器，拿到消息后，进行消息处理。
ConsumeConcurrentlyStatus ：消费者消费结果状态，
ConsumeConcurrentlyStatus.CONSUME_SUCCESS代表成
功,ConsumeConcurrentlyStatus.RECONSUME_LATER代表消费失败，稍后重试，会进行多次重
试
```
###### 方法 15 ：Redis 消息队列分布式发布订阅模式异步

在 springboot 项目中，一般分布式发布订阅模式异步，都是用 RocketMQ 的方式，

如果集成太麻烦了，而一般系统里面已经有了 redis，就用了 redis 做异步的功能

Redis 发布订阅 (pub/sub) 是一种消息通信模式：

```
发送者(pub)发送消息，
订阅者(sub)接收消息。
```
Redis 发布订阅 (pub/sub) 实现了消息系统，发送者 (在 redis 术语中称为发布者) 在接收者 (订阅者) 接收消
息时发送消息。传送消息的链路称为信道。

在 Redis 中，客户端可以订阅任意数量的信道。

```
消息发布
```
消息发布者，即 publish 客户端，无需独占链接，你可以在 publish 消息的同时，使用同一个 redis-client
链接进行其他操作（例如：INCR 等）

```
消息订阅
```

消息订阅者，即 subscribe 客户端，需要独占链接，即进行 subscribe 期间，redis-client 无法穿插其他
操作，此时 client 以阻塞的方式等待“publish 端”的消息；这一点很好理解，因此 subscribe 端需要使用单
独的链接，甚至需要在额外的线程中使用。

Redis 消息队列特点

```
发送者（发布者）不是计划发送消息给特定的接收者（订阅者）。而是发布的消息分到不同的频
道，不需要知道什么样的订阅者订阅。
订阅者对一个或多个频道感兴趣，只需接收感兴趣的消息，不需要知道什么样的发布者发布的。
```
这种发布者和订阅者的解耦合可以带来更大的扩展性和更加动态的网络拓扑。

发布及订阅功能通过 redis client 使用参考

Redis 发布订阅命令

```
# 订阅一个redisChat频道
```
```
redis 127 .0.0.1:6379> SUBSCRIBE redisChat
Reading messages... (press Ctrl-C to quit)
1 ) "subscribe"
2 ) "redisChat"
3 ) (integer) 1
```
```
#发布消息到redisChat频道，发布成功后，订阅者会收到信息
redis 127 .0.0.1:6379> PUBLISH redisChat "Redis is a great caching
technique"
(integer) 1
redis 127 .0.0.1:6379> PUBLISH redisChat "Learn redis by yiibai"
(integer) 1
1 ) "message"
2 ) "redisChat"
3 ) "Redis is a great caching technique"
1 ) "message"
2 ) "redisChat"
3 ) "Learn redis by yiibai"
```
```
1 2 3 4 5 6 7 8 9
```
```
10
```
```
11
12
13
14
15
16
17
18
19
```

关于 Java 的 API，使用封装的 Jedis API 或者 Redssion API 即可。

###### 方法 16: Distruptor 框架异步

Disruptor 是一个优秀的并发框架，使用无锁编程+环形队列架构，是高性能异步队列的王者组件

Disruptor 可以使用在 **非常多的生产者消费者异步场景**

```
单生产者多消费者场景
多生产者单消费者场景
单生产者多消费者场景
多个消费者串行消费场景
菱形方式执行场景
链式并行执行场景
多组消费者相互隔离场景
多组消费者航道执行模式
```
下面以单生产者多消费者并行场景为例，看看场景介绍。

在并发系统中提高性能最好的方式之一就是单一写者原则，对 Disruptor 也是适用的。

如果在生产者单消费者需求中仅仅有一个事件生产者，那么可以设置为单一生产者模式来提高系统的性
能。

其他场景，非常多，具体请参考

请参考尼恩的《Disruptor 框架红宝书》

```
PUBLISH channel message #将信息发送到指定的频道。
SUBSCRIBE channel [channel ...] #订阅给定的一个或多个频道的信息。
UNSUBSCRIBE [channel [channel ...]] #退订给定的频道。
```
```
PSUBSCRIBE pattern [pattern ...] #订阅一个或多个符合给定模式的频道。根据模式来订阅，可
以订阅许多频道
PUNSUBSCRIBE [pattern [pattern ...]] #退订所有给定模式的频道。
```
```
PUBSUB subcommand [argument [argument ...]] #查看订阅与发布系统状态。
```
```
1 2 3 4 5 6 7 8
```

###### 方法 17 ：ForkJoin 框架异步

Fork/Join 框架是 JDK 1.7 提供的一个并行任务执行框架，它可以把一个大任务分成多个可并行执行的子任
务，然后合并每个子任务的结果，得到的大任务的结果。

有点类似 Hadoop 的 MapReduce，Fork/Join 框架也可以分成两个核心操作：

```
Fork操作：将大任务分割成若干个可以并行执行的子任务
Join操作：合并子任务的执行结果
```
这里的内容，也是非常多，具体请参考《Java 高并发核心编程卷 2 **加强版** 》 8.3 小节。示意图如下：

**其工作窃取算法，非常有价值**

**尼恩在指导小伙伴写简历的时候，多次用到工作窃取算法**

###### 方法 18 ：RocketMQ 源码中 ServiceThread 能急能缓的高性能异步

RocketMQ 源码中, 实现了一种特殊的，高性能异步: **能急能缓 ServiceThread 异步** 。

能急能缓 ServiceThread 异步有两个特点：

```
既能周期性的执行异步任务
还能紧急的时候，执行应急性的任务
```
RocketMQ 的吞吐量达到 70 Wqps，ServiceThread 的异步框架，发挥了重要的价值。

尼恩在实现《10 WQps 推送中台实操》使用了 ServiceThread 异步框架，在实现《100 WQps 三级缓
存组件实操》, 实操时，也使用了 ServiceThread 异步框架。

总之， ServiceThread 异步框架是 RocketMq 的精华之一，性能非常高，也非常好用。


有关 _ServiceThread_ 异步框架的内容，请参见尼恩《穿透 _RocketMq_ 架构和源码》视频。

内容太多，还涉及到 _RocketMQ_ 源码对闭锁的改造，所以，在这里不做赘述。

###### 方式 19 ：Kotlin 协程异步

20 18 年，一种新的 JVM 编程语言开始流行：Kotlin。

Kotlin 首先流行在 Android 开发领域，因为它得到了 Google 的首肯和支持。

但对于后端开发领域，因为一项特性，使得 Kotlin 也非常值得注意。那就是 Kotlin Coroutine（后文称
Kotlin 协程）。

协程技术不是什么新技术，它在很多语言中都有实现，比如大家所熟悉的 Python、Lua、Go 都是支持
协程的。

在不同语言中，协程的实现方法各有不同。因为 Kotlin 的运行依赖于 JVM，不能对 JVM 进行修改，因
此，Kotlin 不能在底层支持协程。

同时，Kotlin 是一门编程语言，需要在语言层面支持协程，而不是像框架那样在语言层面之上支持。

因此，Kotlin 对协程支持最核心的部分是在编译器中。因为对这部分原理的解释在之前文章中都有涉
及，因此不在这里重复。

使用 Kotlin 协程之后最大的好处是异步代码的可读性大大提高。

如果上一个示例用 Kotlin 协程实现，那就是下面的样子：

这里的功能是：查询最近邮件数（Kotlin 协程版）

目前在 _Spring_ 应用中使用 _Kotlin_ 协程还有些小繁琐，但在 _Spring Boot 2.2_ 中，可以直接在 _Spring
WebFlux_ 方法上使用 _suspend_ 关键字。

Kotlin 协程最大的意义就是可以用看似指令式编程方式（Imperative Programming，即传统编程方
式）去写异步编程代码。并发和代码可读性似乎两全其美了。

```
@GetMapping("/coroutine/{personId}")
fun getNumberOfMessages(@PathVariable personId: String) = mono(Unconfined)
{
val person =
peopleRepository.findById(personId).awaitFirstOrDefault(null)
?: throw NoSuchElementException("No person can be found by
$personId")
```
```
val lastLoginDate =
auditRepository.findByEmail(person.email).awaitSingle().eventDate
```
```
val numberOfMessages =
```
```
messageRepository.countByMessageDateGreaterThanAndEmail(lastLoginDate,
person.email).awaitSingle()
```
```
"Hello ${person.name}, you have $numberOfMessages messages since
$lastLoginDate"
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
```
```
12
```

**Kotlin 协程的局限性**

Kotlin 协程依赖于各种基于 Callback 的技术

所以，只有当一段代码使用了 ListenableFuture、CompletableFuture、Project Reactor、RxJava 等
技术时，才能用 Kotlin 协程进行改造优化。

那对于其它的会阻塞线程的技术，如 Object. wait、Thread. sleep、Lock、BIO 等，Kotlin 协程就无能
为力了。

另外一个局限性源于 Kotlin 本身。

虽然 Kotlin 兼容 Java，但这种兼容并非完美。

因此，对于组件，尤其是基础组件的开发，并不推荐使用 Kotlin，而是更推荐使用 Java。这也导致
Kotlin 协程的使用范围被进一步地限制。

###### 方式 20 ：Project Loom

前面讲到，虽然 Kotlin 协程看上去很好，但在使用上还是有着种种限制。那有没有更好的选择呢？

答案是 Project Loom (https://openjdk.java.net/projects/loom/))。

这个项目在 18 年底的时候已经达到可初步演示的原型阶段。

**不同于之前的方案，Project Loom 是从 JVM 层面对多线程技术进行彻底的改变。**

下面这幅图很好地展示了目前 Java 并发编程方面的困境，简单的代码并发、伸缩能力差；并发、伸缩
能力强的代码复杂，难以与现有代码整合。

各种框架或其它 JVM 编程语言的解决方案，都在使用场景上有限制。

例如 Kotlin 协程必须基于各种 Callback 技术，而 Callback 技术有存在编写、调试困难的问题。为了使
Java 并发能力在更大范围上得到提升，从底层进行改进便是必然。

为了让简单和高并发这两个目标兼得，我们需要 Project Loom 这个项目。


Project Loom 设计思想与之前的一个开源 Java 协程技术非常相似。而现在 Project Loom 的主要设计
开发人员 Ron Pressler 就是来自 Quasar Fiber。

这个开源技术就是 Quasar Fiber https://docs.paralleluniverse.co/quasar/ 。

Project Loom 的被发起原因也很简单：长期以来，Java 的线程是与操作系统的线程一一对应的，这限
制了 Java 平台并发能力的提升。

**Project Loom 原理**

Project Loom 引入了虚拟线程作为 java. lang. Thread 的实例, 这是一种的 **轻量级用户模式线程** 。

虚拟线程可以理解为操作系统平台线程的一个任务。操作系统平台线程很庞大并且依赖于操作系
统。

Java 不能随意改进平台线程，操作系统直接将这些线程分配给处理器。

有了虚拟线程后，JDK 的调度程序将虚拟线程提交到平台线程，操作系统像往常一样将其分配给处理
器。

那么，虚拟线程如何工作？

我们都知道阻塞线程是邪恶的，会对应用程序的性能产生负面影响。

使用虚拟线程之后，当虚拟线程阻塞 I/O 或 JDK 中的某些阻塞操作时，平台线程就不会阻塞了。

怎么做的呢？ 当虚拟线程阻塞 I/O 或 JDK 中的某些阻塞操作时，例如 BlockingQueue.take ()，它会自

动从平台线程中卸载 （或者说解除合作关系）。JDK 的调度程序可以在这个空闲的平台线程上挂载和运
行其他虚拟线程。

当阻塞操作准备好完成时，它会将虚拟线程提交回调度程序，调度程序会将虚拟线程挂载到可用的平台
线程上以恢复执行。

当然，平台线程不必虚拟线程一一对应，更像是原始的线程和任务的关系。

因此，我们现在可以构建具有高吞吐量的高并发应用程序，而无需增加线程数量（默认情况下，虚拟线
程的 Executor 将使用与可用处理器数量一样多的平台线程）。

**使用方法**

在引入 Project Loom 之后，JDK 将引入一个新类：java. lang. Fiber。

此类与 java. lang. Thread 一起，都成为了 java. lang. Strand 的子类。

即线程变成了一个虚拟的概念，有两种实现方法：Fiber 所表示的轻量线程和 Thread 所表示的传统的
重量级线程。

对于应用开发人员，使用 Project Loom 很简单：


只需执行 Fiber.schedule (Runnable task) 就能在 Fiber 中执行任务。

最重要的是，上面例子中的 lock.lock () 操作将不再挂起底层线程。

除了 Lock 不再挂起线程以外，像 Socket BIO 操作也不再挂起线程。

但 synchronized，以及 Native 方法中线程挂起操作无法避免。

如上所示，Fiber 的使用非常简单。因此，让现有系统使用 Project Loom 很容易。

像 Tomcat、Jetty 这样的 Web 容器，只需将处理请求操作从使用 ThreadPoolExecutor execute 或
submit 改为使用 Fiber schedule 即可。

这个视频 https://www.youtube.com/watch?v=vbGbXUjlRyQ&t=1240s 中的 Demo 展示了 Jetty 使用
Project Loom 改造之后并发吞吐能力的大幅提升。

关于 Project Loom 的实操和性能对比，尼恩后面通过专题视频，给大家进行介绍。

## 有赞一面：还有任务没执行，线程池被关闭怎

## 么办？

###### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，最近有小伙伴拿到了一线互联网企业如极兔、有赞、希音
的面试资格，遇到一几个很重要的面试题：

```
还有线程池正在执行的任务和线程，如果线程池shutdown怎么怎么办
```
与之类似的、其他小伙伴遇到过的问题还有：

```
如果还有任务没执行，线程池被关闭了，怎么办？
```
```
Fiber f = Fiber.schedule(() -> {
println("Hello 1");
lock.lock(); // 等待锁不会挂起线程
try {
println("Hello 2");
} finally {
lock.unlock();
}
println("Hello 3");
})
```
```
1 2 3 4 5 6 7 8 9
```
```
10
```
```
synchronized (monitor) {
// 在 Fiber 中调用这条语句还是会挂起线程。
socket.getInputStream().read();
}
```
```
1
2
3
4
```

这里尼恩给大家做一下系统化、体系化的线程池梳理，使得大家可以充分展示一下大家雄厚的 “技术肌
肉”， **让面试官爱到 “不能自已、口水直流”** 。

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 60 版本，供后面的小伙伴参考，
提升大家的 3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，最新尼恩 架构笔记、面试题 的PDF文件，请从这里获取：[码云](）
```
#### 一：首先回顾线程池线程池的 5 种运行状态

ThreadPoolExecutor 使用 runState (运行状态) 变量，管理线程池的生命周期，

runState 一共有以下 5 种取值:

```
（ 1 ）RUNNING：接收新的任务，并对任务队列里的任务进行处理；
```
```
（ 2 ）SHUTDOWN：不再接收新的任务，但是会对任务队列中的任务进行处理；
```
```
（ 3 ）STOP：不接收新任务，也不再对任务队列中的任务进行处理，并中断正在处理的任务；
```
```
（ 4 ）TIDYING：所有任务都已终止，线程数为 0 ，在转向TIDYING状态的过程中，线程会执行
terminated()钩子方法，钩子方法是指在本类中是空方法，而在子类中进行具体实现的方法；
```
```
（ 5 ）TERMINATED：terminated()方法执行结束后会进入这一状态，表示线程池已关闭。
```
与线程池关闭有关的状态，不是 1 个，而是有 4 个：

状态（ 2 ）SHUTDOWN：不再接收新的任务，但是会对任务队列中的任务进行处理；

状态（ 3 ）STOP：不接收新任务，也不再对任务队列中的任务进行处理，并中断正在处理的任务；

状态（ 4 ）TIDYING：所有任务都已终止，线程数为 0 ，在转向 TIDYING 状态的过程中，线程会执行
terminated () 钩子方法，钩子方法是指在本类中是空方法，而在子类中进行具体实现的方法；

状态（ 5 ）TERMINATED：terminated () 方法执行结束后会进入这一状态，表示线程池已彻底关闭。

从这么多的状态可以知道，线程池的关闭，不是一个简单的问题了。


#### 二：线程池停止相关的五个方法

线程池停止相关的五个方法：

（ 1 ）shutdown 方法：柔和关闭线程池；

（ 2 ）shutdownNow 方法：暴力关闭线程池，无论线程池中是否有剩余任务，立刻彻底停止线程池

（ 3 ）isShutdown 方法：查看线程池是否已进入停止状态了

（ 4 ）isTerminated 方法：查看线程池是否已经彻底停止了

（ 5 ）awaitTermination 方法：判断在等待的时间内，线程池是否彻底停止

**其中终止线程池主要有 2 个：**

（ 1 ）shutdown 方法：柔和关闭线程池；

shutdown () 后线程池将变成 shutdown 状态，此时不接收新任务，但会处理完正在运行的和在
workQueue 阻塞队列中等待处理的任务。

（ 2 ）shutdownNow 方法：暴力关闭线程池

无论线程池中是否有剩余任务，shutdownNow () 立刻彻底停止线程池。shutdownNow () 后线程池将变
成 stop 状态，此时不接收新任务，不再处理在阻塞队列中等待的任务，还会尝试中断正在处理中的工作
线程。

**其中对线程池关闭状态进行检查的方法，主要有 3 个：**

（ 3 ）isShutdown 方法：查看线程池是否已进入停止状态了

（ 4 ）isTerminated 方法：查看线程池是否已经彻底停止了

（ 5 ）awaitTermination 方法：判断在等待的时间内，线程池是否彻底停止

###### （ 1 ）shutdown 柔和关闭线程池；

shutdown 柔和关闭线程池，有两个要点：

**（ 1 ）** shutdown 方法是关闭线程池；

**（ 2 ）** 但是，shutdown 只是初始化整个关闭过程, 执行完这个方法后，线程池不一定会立即停止；

所以，在我们调用了 shutdown 方法后，线程池就知道了停止线程池的意图；而并不是我们调用
shutdown 方法后，整个线程池就能停的。比如，线程池在执行到一半时，线程中有正在执行的任务，
队列中也可能有等待被执行的任务，线程池需要等这些任务执行完了，才能真正停止。

当然，在我们调用了 shutdown 方法后，如果还有新的任务过来，线程池就会拒绝。

演示案例，在尼恩的《Java 高并发核心编程卷 2 加强版》随时源码中，有大量的 shutdown 使用案
例。


在超级牛逼的 rocketmq 源码中，也是 shutdown 关闭线程池，具体如下：

**说明：**


**（ 1 ）** 还是强调一下：我们执行了 shutdown 方法，isShutdown 方法就会返回 true；isShutdown 方法返
回 true，仅仅代表线程池处于停止状态了，不代表线程池彻底停止了（因为，线程池进入停止状态后，
还要等待【正在执行的任务以及队列中等待的任务】都执行完后，才能彻底终止）；

**（ 2 ）** 那么怎么看，线程池是否彻底停止了呐？ 稍微晚点，要讲 isTerminated () 方法，可以实现这个需
求；

###### （ 2 ）shutdownNow 粗暴关闭线程

shutdownNow 方法：无论线程池中是否有剩余任务，立刻彻底停止线程池；

如何一个粗暴法呢？

(1) 正在执行任务的线程会被中断；

（ 2 ）队列中正在排队的任务，会返回；

来看一个例子：向 3 个线程的固定大小线程池，提交 10 个任务，每个任务 500 ms!

执行结果如下：


另外还有 7 个任务，没有来得及执行。

如果数据和任务都不重要，可以 shutdownNow 粗暴关闭线程，否则，这就太野蛮了。

###### （ 3 ）isShutdown 方法：查看线程池是否已进入停止状态了；

当调用 shutdown 方法关闭线程后，线程不是立即关闭，仅仅是启动了关闭流程，不再接收新的任务；

问题是，如何查看线程池是否已进入停止状态呢？ 难道，我们只有通过向线程池添加任务的方式才能
看到 shutdown 确确实实被执行了吗？

可以通过 isShutdown 方法查看线程池是否已进入停止状态了。只要开始执行了 shutdown 方法，
isShutdown 方法就会返回 true；

###### （ 4 ）isTerminated 方法：判停，注意是阻塞判停

threadPool. isTerminated 方法：查看线程池是否已经彻底停止了

threadPool.isTerminated () 常用来判断线程池是否结束，线程池 pool 的状态是否为 Terminated，如果
是，表示线程池 pool 彻底终止， threadPool.isTerminated () 返回为 TRUE


必须在 **shutdown () 方法关闭线程池之后才能使用** ，否则 isTerminated () 永不为 TRUE，而且线程将一直
阻塞在该判断的地方，导致程序最终崩溃。

###### （ 5 ）awaitTermination 等待停止

awaitTermination 方法：判断在等待的时间内，线程池是否彻底停止。awaitTermination 第一个参数是
long 类型的超时时间，第二个参数可以为该时间指定单位。

```
awaitTermination 的功能如下：
```
```
阻塞当前线程，等已提交和已执行的任务都执行完，解除阻塞
当等待超过设置的时间，检查线程池是否停止，如果停止返回 true，否则返回 false，并解除
阻塞
```
awaitTermination 一般与 shutdown () 方法结合使用，下面是一个例子：

```
当需要用到isTerminated()函数判断线程池中的所有线程是否执行完毕时候，不能直接使用该函
数，
```
```
1
```

执行结果如下：

例子中，线程池的有效执行时间为 20 S，20 S 之后不管子任务有没有执行完毕，都要关闭线程池。


**注意：**

与 shutdown () 方法结合使用时，尤其要注意的是 shutdown () 方法必须要在 awaitTermination () 方法之前
调用，该方法才会生效。否则会造成死锁。

###### 关闭线程池的正确姿势

关闭线程池的正确姿势= shutdown 方法 +awaitTermination 方法组合关闭。

（ 1 ）shutdown 方法：柔和的关闭 ExecutorService，

当此方法被调用时，pool 停止接收新的任务并且等待已经提交的任务（包含提交正在执行和提交未执
行）执行完成。当所有提交任务执行完毕，线程池即被关闭。

（ 2 ）awaitTermination 方法：

接收人 timeout 和 TimeUnit 两个参数，用于设定超时时间及单位。

当等待超过设定时间时，会监测 ExecutorService 是否已经关闭，若关闭则返回 true，否则返回 false。

#### 三：线程池关闭的源码分析

接下来，分析一下线程池关闭相关的方法的源码，包括各个方法之间的逻辑关系，调用关系和产生的效
果。

###### 再次回顾：线程池的 5 种运行状态

ThreadPoolExecutor 使用 runState (运行状态) 变量，管理线程池的生命周期，


线程池关闭过程中，会涉及到频繁的 runState 运行状态转化，

所以，首先需要了解线程池的各种 runState 运行状态及各种 runState 之间的转化关系，

runState 一共有以下 5 种取值:

```
（ 1 ）RUNNING：接收新的任务，并对任务队列里的任务进行处理；
```
```
（ 2 ）SHUTDOWN：不再接收新的任务，但是会对任务队列中的任务进行处理；
```
```
（ 3 ）STOP：不接收新任务，也不再对任务队列中的任务进行处理，并中断正在处理的任务；
```
```
（ 4 ）TIDYING：所有任务都已终止，线程数为 0 ，在转向TIDYING状态的过程中，线程会执行
terminated()钩子方法，钩子方法是指在本类中是空方法，而在子类中进行具体实现的方法；
```
```
（ 5 ）TERMINATED：terminated()方法执行结束后会进入这一状态，表示线程池已关闭。
```
运行状态的转化条件和转化关系如下所示：

shutdown 操作之后，经历三个状态：

（ 1 ）首先最重要的一点变化就是线程池状态变成了 SHUTDOWN。

该状态是开始关闭线程池之后，从 RUNNING 改变状态经过的第一个状态，

（ 1 ）等任务队列和线程数为 0 之后，进入 TIDYING 第 2 个状态，

（ 3 ）等内部调用的 terminated () 方法执行结束后，会进入 TERMINATED 状态，表示线程池已关闭

shutdownNow 操作之后，经历 3 个状态：

（ 1 ）直接进 STOP，不管任务队列里边是否还有任务要处理，尝试停止所有活动的正在执行的任务，停
止等待任务的处理，并排空任务列表
（ 2 ）等任务队列和线程数为 0 之后，进入 TIDYING 第 2 个状态，


（ 3 ）等内部调用的 terminated () 方法执行结束后，会进入 TERMINATED 状态，表示线程池已关闭

#### 源码分析 1 ：shutdown () 柔和终止线程池

shutdown () 柔和终止线程池的核心流程如下：

**step 1、抢占线程池的主锁**

线程池的主锁是 mainLock ，是可重入锁，

当要操作 workers set 这个保持线程的 HashSet 时，需要先获取 mainLock，

另外，当要处理 largestPoolSize、completedTaskCount 这类统计数据时需要先获取 mainLock

**step 2、权限校验**

java 安全管理器校验 , 判断调用者是否有权限 shutdown 线程池

**step 3、更新线程池状态为 shutdown**

使用 CAS 操作将线程池状态设置为 shutdown，

shutdown 之后将不再接收新任务

**step 4、中断所有空闲线程**

调用 interruptIdleWorkers () 打断所有的空闲工作线程，即 workerQueue.take () 阻塞的线程

**step 5、onShutdown ()，**

调用子类回调方法，基类默认为空方法

子类回调方法可以在 shutdown () 时做一些处理

子类 ScheduledThreadPoolExecutor 中实现了这个方法，

**step 6、解锁**

**step 7、尝试终止线程池 tryTerminate ()**

```
public void shutdown () {
final ReentrantLock mainLock = this. mainLock;
```
```
// step 1、抢占线程池的主锁
mainLock.lock ();
try {
// step 2、权限校验 java 安全管理器校验
checkShutdownAccess ();
//step 3、更新线程池状态为 shutdown
advanceRunState (SHUTDOWN);
// step 4、打断所有的空闲工作线程，即 workerQueue.take () 阻塞的线程
interruptIdleWorkers ();
// 调用子类回调方法，基类默认为空方法
onShutdown (); // hook for ScheduledThreadPoolExecutor
} finally {
//**step 6、解锁**
mainLock.unlock ();
}
//step 7、尝试终止线程池 tryTerminate ()
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
```

###### 最重要的 3 个步骤是：

step 3 更新线程池状态为 shutdown

step 4 中断所有空闲线程、

step 7 tryTerminated () 尝试终止线程池

接下来，介绍 step 4 、step 7 的核心源码

###### step 4： 中断所有空闲线程 interruptIdleWorkers ()

step 4 是调用 interruptIdleWorkers () 中断所有空闲线程完成的。有两个问题：

（ 1 ）什么是空闲线程？

（ 2 ）interruptIdleWorkers () 是怎么中断空闲线程的？

interruptIdleWorkers () 首先会获取 mainLock 锁，因为要迭代 workers 集合，

```
tryTerminate ();
}
```
```
20
21
```
```
/**
* 中断唤醒后，可以判断线程池状态是否变化来决定是否继续
*
* onlyOne 如果为 true，最多 interrupt 一个 worker
* 只有当终止流程已经开始，
* 但线程池还有 worker 线程时,tryTerminate () 方法会做调用 onlyOne 为 true 的调用
* （终止流程已经开始指的是：shutdown 状态且 workQueue 为空，或者 stop 状态）
* 在这种情况下，最多有一个 worker 被中断，为了传播 shutdown 信号，以免所有的线程都在等待
* 为保证线程池最终能终止，这个操作总是中断一个空闲 worker
* 而 shutdown () 中断所有空闲 worker，来保证空闲线程及时退出
*/
private void interruptIdleWorkers (boolean onlyOne) {
final ReentrantLock mainLock = this. mainLock;
mainLock.lock (); //上锁
try {
for (Worker w : workers) {
Thread t = w.thread;
if (!t.isInterrupted () && w.tryLock ()) {
try {
t.interrupt ();
} catch (SecurityException ignore) {
} finally {
w.unlock ();
}
}
if (onlyOne) break;
}
} finally {
mainLock.unlock (); //解锁
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
```

然后，中断在等待任务的线程 (没有上锁的)，在中断每个 worker 前，需要做两个判断：

1 、线程是否已经被中断，是就什么都不做

2 、worker.tryLock () 是否成功

第二个判断 worker.tryLock () 比较重要，因为 Worker 类除了实现了可执行的 Runnable，也继承了 AQS，

也就说，worker 本身也是一把锁.

```
尼恩提示，AQS 的知识，非常重要，具体请阅读《Java 高并发核心编程卷 2 加强版》。
```
```
该书对 AQS 作为浅显易懂的介绍，被很多小伙伴称之为最为易懂的版本，pdf 是免费获取的。
```
**worker.tryLock () 为什么要获取 worker 的锁呢？**

Woker 类在执行任务的工作线程，都是上了 worker 锁的。

在 runWorker () 方法中, worker 从 pool 中获取 task 并执行，但是执行的过程中，涉及到锁：

（ 1 ）一个 worker 每次通过 getTask () 方法从 pool 获取到 task 之后，在执行 task.run () 之前，都需要
worker.lock () 上锁，

（ 2 ）task 运行结束后 unlock 解锁，

所以说，只要是正在执行任务的工作线程，都是上了 worker 锁的

参考的源码如下：

```
final void runWorker (Worker w) {
Thread wt = Thread.currentThread ();
Runnable task = w.firstTask;
w.firstTask = null;
w.unlock (); // allow interrupts
boolean completedAbruptly = true;
try {
while (task != null || (task = getTask ()) != null) {
w.lock ();
```
```
1 2 3 4 5 6 7 8 9
```

回顾一下前面 interruptIdleWorkers 的代码，有一个核心要点：

```
interruptIdleWorkers 中断 work 线程之前，需要先 work.tryLock () 获取 worker 锁，
```
这就意味着正在执行 task 的 worker 线程，不能被中断。

为啥呢？ worker 锁比较特殊： 核心的要点是 worker 锁是不可重入的，所以不管是不是当前线程，
worker.tryLock () 都失败。

怎么证明 worker 锁是不可重入的，可以去看源码： worker 是线程池 ThreadPoolExecutor 的内部
类，继承了 AbstractQueuedSynchronizer 抽象队列同步器，核心的方法如下：

```
// If pool is stopping, ensure thread is interrupted;
// if not, ensure thread is not interrupted. This
// requires a recheck in second case to deal with
// shutdownNow race while clearing interrupt
if ((runStateAtLeast (ctl.get (), STOP) ||
(Thread.interrupted () &&
runStateAtLeast (ctl.get (), STOP))) &&
!wt.isInterrupted ())
wt.interrupt ();
try {
beforeExecute (wt, task);
Throwable thrown = null;
try {
task.run ();
} catch (RuntimeException x) {
thrown = x; throw x;
} catch (Error x) {
thrown = x; throw x;
} catch (Throwable x) {
thrown = x; throw new Error (x);
} finally {
afterExecute (task, thrown);
}
} finally {
task = null;
w.completedTasks++;
w.unlock ();
}
}
completedAbruptly = false;
} finally {
processWorkerExit (w, completedAbruptly);
}
}
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
```

```
尼恩提示，
```
```
这里关键的知识点，还是 AQS
```
```
所以 AQS 非常重要，具体请阅读《 Java 高并发核心编程卷 2 加强版》。
```
```
该书对 AQS 作为浅显易懂的介绍，被很多小伙伴称之为最为易懂的版本， pdf 是免费获取的。
```
所以说，shutdown () 只有对能获取到 worker 锁的空闲线程发送中断信号，对于忙的 worker 线程，要
等到拿到锁之后，才能去发中断信号。

由此可以将 worker 划分为：

1 、闲的 worker：没有执行任务的 worker，比如正在从 workQueue 阻塞队列中获取任务的 worker，

2 、忙的 worker：正在 task.run () 执行任务的 worker


###### 线程被中断之后，如何处理

还有一点需要注意： 对于闲着的但是正在被阻塞在 getTask () 的 worker，是可以被中断的，但是在被中
断后会抛出 InterruptedException，runWorker 的 while 循环被破坏，从而不再阻塞获取任务

worker 捕获中断异常后，将跳出 while 循环，进入 processWorkerExit 方法，

runWorker 的核心代码如下：

```
final void runWorker (Worker w) {
Thread wt = Thread.currentThread ();
Runnable task = w.firstTask;
w.firstTask = null;
w.unlock (); // allow interrupts
boolean completedAbruptly = true;
try {
while (task != null || (task = getTask ()) != null) {
w.lock ();
// If pool is stopping, ensure thread is interrupted;
// if not, ensure thread is not interrupted. This
// requires a recheck in second case to deal with
// shutdownNow race while clearing interrupt
if ((runStateAtLeast (ctl.get (), STOP) ||
(Thread.interrupted () &&
runStateAtLeast (ctl.get (), STOP))) &&
!wt.isInterrupted ())
wt.interrupt ();
try {
//...... 省略 n 行，这里执行拿到的任务，并处理任务异常
} finally {
task = null;
w.completedTasks++;
w.unlock ();
}
}
completedAbruptly = false;
} finally {
// InterruptedException 中断发生之后，走到这里
processWorkerExit (w, completedAbruptly);
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
```

这里特别注意，一旦出了那个 while 循环，这个 thread 的执行，即将结束了

换句话说，一旦 worker 捕获中断异常后，worker 所绑定的 thread 将跳出 while 循环，即将结束了

具体请参考下面：

虽然 worker 绑定的线程，即将结束了。但是在结束之前，还要执行一下 processWorkerExit 方法

**processWorkerExit 方法解析**

来看看 processWorkerExit (Worker w, boolean completedAbruptly) 方法解析

1. 参数说明：

```
Worker w ： 工作线程包装器。
boolean completedAbruptly ：默认值为 true，
```
```
只有调用 getTask () 方法，返回 null，线程正常退出，会将 completedAbruptly 设置为 false。
```
```
当 task.run () 任务运行过程中抛出异常，线程异常退出，completedAbruptly 还是默认值 true。
```
2. 执行过程：

```
统计执行完成的任务个数。
tryTerminate () 尝试调用 terminated () 方法。
RUNNING | SHUTDOWN 状态下，保证工作线程数量 >= corePoolSize，如果不满足，添加
新线程。
```
```
1 private void processWorkerExit (Worker w, boolean completedAbruptly) {
```

核心的工作为：

（ 1 ） 从 pool 的 workers 集合移除当前 worker

（ 2 ）尝试调用 pool 的 terminated () 方法

这个方法中，首先判断 pool 的状态，如果为 RUNNING || （线程池已经被关闭【TIDYING |
TERMINATED】） || （SHUTDOWN && 任务队列不为空），直接返回。

这个方法中，然后判断工作线程数，如果不为 0 （自己不是最后一个工作线程），随机打断一个空闲线
程，直接返回。

否则，这一个线程修改线程池状态为 TIDYING，修改线程状态为 TERMINATED，调用 terminated () 方
法，唤醒等待 pool 终止的线程，也就是 awaitTermination () 的线程。

```
// 线程异常退出，修改工作线程数量。
if (completedAbruptly) // If abrupt, then workerCount wasn't adjusted
decrementWorkerCount ();
```
```
final ReentrantLock mainLock = this. mainLock;
mainLock.lock ();
try {
// 统计执行完成任务个数
completedTaskCount += w.completedTasks;
// 移除当前 worker
workers.remove (w);
} finally {
mainLock.unlock ();
}
```
```
// 尝试调用 terminated () 方法
tryTerminate ();
```
```
int c = ctl.get ();
//如果线程为 RUNNING | SHUTDOWN 状态下 , 要保证最小工作线程数。
if (runStateLessThan (c, STOP)) {
// 线程正常退出，需要退出救急线程
// 线程异常退出，直接添加新线程
if (! completedAbruptly) {
// 判断最小线程数量，一般是核心线程数量。
int min = allowCoreThreadTimeOut? 0 : corePoolSize;
if (min == 0 &&! workQueue.isEmpty ())
// 最少一个线程
min = 1 ;
if (workerCountOf (c) >= min)
// 不需要添加新线程
return; // replacement not needed
}
// 添加新线程，在 RUNNING | SHUTDOWN 状态下, 不至于一个线程也没有了，要保证剩
余的任务干完
addWorker (null, false);
}
}
```
```
2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
```
```
36
37
38
```
```
//Set containing all worker threads in pool. Accessed only when holding
mainLock.
private final HashSet<Worker> workers = new HashSet<Worker>();
```
```
1
```
```
2
```

尼恩提示： _pool_ 的 _terminated ()_ 方法，稍微晚点介绍。

(3) 保证最小工作线程数

上面的代码中，使用 runStateLessThan (c, STOP) 判断线程的状态是否比 STOP 小，那么比 STOP 小的
是谁呢？

（ 1 ）RUNNING 状态

（ 2 ）SHUTDOWN 状态

ThreadPoolExecutor 用一个 AtomicInteger 字段保存了 2 个状态

```
1. workerCount （有效线程数） （占用 29 位）
2. runState （线程池运行状态） （占用高 3 位）
```
从上面的源码可以看出，比 STOP 小的是 RUNNING | SHUTDOWN

```
//标记线程数和状态的混合值
private final AtomicInteger ctl = new AtomicInteger (ctlOf (RUNNING, 0 ));
//线程位数
private static final int COUNT_BITS = Integer. SIZE - 3 ;
//线程最大个数 (低 29 位) 00011111111111111111111111111111
private static final int COUNT_MASK = ( 1 << COUNT_BITS) - 1 ;
```
```
//（高 3 位）： 11100000000000000000000000000000
private static final int RUNNING = - 1 << COUNT_BITS;
//（高 3 位）： 00000000000000000000000000000000
private static final int SHUTDOWN =  0 << COUNT_BITS;
//（高 3 位）： 00100000000000000000000000000000
private static final int STOP =  1 << COUNT_BITS;
//（高 3 位）： 01000000000000000000000000000000
private static final int TIDYING =  2 << COUNT_BITS;
//（高 3 位）： 01100000000000000000000000000000
private static final int TERMINATED =  3 << COUNT_BITS;
```
```
//获取线程池运行状态
private static int runStateOf (int c) { return c & ~COUNT_MASK; }
//获取线程个数
private static int workerCountOf (int c) { return c & COUNT_MASK; }
//计算 ctl 新值
private static int ctlOf (int rs, int wc) { return rs | wc; }
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
```

processWorkerExit 方法需要保证：如果 pool 在 RUNNING | SHUTDOWN 状态下, 不能一个线程也没有
了，要保证 workQueue 剩余的任务干完

所以，在 RUNNING | SHUTDOWN 状态下, 如果有必要，还要添加新线程，

###### step 7: 尝试终止线程池 tryTerminate ()

shutdown () 的最后也调用了 tryTerminated () 方法，下面看看这个方法的逻辑：

```
/**
* 在以下情况将线程池变为 TERMINATED 终止状态
* shutdown 且正在运行的 worker 和 workQueue 队列都 empty
* stop 且没有正在运行的 worker
*
* 这个方法必须在任何可能导致线程池终止的情况下被调用，如：
* 减少 worker 数量
* shutdown 时从 queue 中移除任务
*
* 这个方法不是私有的，所以允许子类 ScheduledThreadPoolExecutor 调用
*/
final void tryTerminate () {
//这个 for 循环主要是和进入关闭线程池操作的 CAS 判断结合使用的
for (;;) {
int c = ctl.get ();
```
```
/**
* 线程池是否需要终止
* 如果以下 3 中情况任一为 true，return，不进行终止
* 1、还在运行状态
* 2、状态是 TIDYING、或 TERMINATED，已经终止过了
* 3、SHUTDOWN 且 workQueue 不为空
*/
if (isRunning (c) ||
runStateAtLeast (c, TIDYING) ||
(runStateOf (c) == SHUTDOWN &&! workQueue.isEmpty ()))
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
```

tryTerminate () 执行流程：

1 、判断线程池是否需要进入终止流程（只有当 shutdown 状态+workQueue. isEmpty 或 stop 状态，才
需要）

2 、判断线程池中是否还有线程，有则 interruptIdleWorkers (ONLY_ONE) 尝试中断一个空闲线程

正是这个逻辑可以再次发出中断信号，中断阻塞在获取任务的线程

3 、如果状态是 SHUTDOWN，workQueue 也为空了，正在运行的 worker 也没有了，开始 terminated

```
return;
```
```
/**
* 只有 shutdown 状态且 workQueue 为空，或者 stop 状态能执行到这一步
* 如果此时线程池还有线程（正在运行任务，正在等待任务）
* 中断唤醒一个正在等任务的空闲 worker
* 唤醒后再次判断线程池状态，会 return null，进入 processWorkerExit () 流
程
*/
if (workerCountOf (c) != 0 ) { // Eligible to terminate 资格终止
interruptIdleWorkers (ONLY_ONE); //中断 workers 集合中的空闲任务，参数
为 true，只中断一个
return;
}
```
```
/**
* 如果状态是 SHUTDOWN，workQueue 也为空了，正在运行的 worker 也没有了，开
始 terminated
*/
final ReentrantLock mainLock = this. mainLock;
mainLock.lock ();
try {
//CAS：将线程池的 ctl 变成 TIDYING（所有的任务被终止，workCount 为 0 ，
// 为此状态时将会调用 terminated () 方法），期间 ctl 有变化就会失败，会再次
for 循环
if (ctl.compareAndSet (c, ctlOf (TIDYING, 0 ))) {
try {
terminated (); //需子类实现
}
finally {
ctl.set (ctlOf (TERMINATED, 0 )); //将线程池的 ctl 变成
TERMINATED
termination.signalAll (); //唤醒调用了等待线程池终止的线程
awaitTermination ()
}
return;
}
}
finally {
mainLock.unlock ();
}
// else retry on failed CAS
// 如果上面的 CAS 判断 false，再次循环
}
}
```
```
27
28
29
30
31
32
33
```
```
34
35
36
```
```
37
38
39
40
41
```
```
42
43
44
45
46
47
```
```
48
49
50
51
52
53
```
```
54
```
```
55
56
57
58
59
60
61
62
63
64
65
```

会先上锁，将线程池置为 tidying 状态，之后调用需子类实现的 terminated ()，最后线程池置为
terminated 状态，并唤醒所有等待线程池终止这个 Condition 的线程

#### 源码分析 2 ：shutdownNow () 粗暴终止线程池的核心流程

shutdownNow () 和 shutdown () 的大体流程相似，差别是：

1 、将线程池更新为 stop 状态

2 、调用 **interruptWorkers ()** 中断所有线程，包括正在运行的线程

3 、将 workQueue 中待处理的任务移到一个 List 中，并在方法最后返回，说明 shutdownNow () 后不会再
处理 workQueue 中的任务

###### interruptWorkers ()

```
/**
* 尝试停止所有活动的正在执行的任务，停止等待任务的处理，并返回正在等待被执行的任务列表
* 这个任务列表是从任务队列中排出（删除）的
* <p>
* 这个方法不用等到正在执行的任务结束，要等待线程池终止可使用 awaitTermination ()
* <p>
* 除了尽力尝试停止运行中的任务，没有任何保证
* 取消任务是通过 Thread.interrupt () 实现的，所以任何响应中断失败的任务可能永远不会结束
*/
public List <Runnable> shutdownNow () {
List <Runnable> tasks;
final ReentrantLock mainLock = this. mainLock;
mainLock.lock (); //上锁
```
```
try {
//判断调用者是否有权限 shutdown 线程池
checkShutdownAccess ();
```
```
//CAS+循环设置线程池状态为 stop
advanceRunState (STOP);
```
```
//中断所有线程，包括正在运行任务的
interruptWorkers ();
```
```
tasks = drainQueue ();
//将 workQueue 中的元素放入一个 List 并返回
} finally {
mainLock.unlock ();
//解锁
}
```
```
//尝试终止线程池
tryTerminate ();
```
```
return tasks;
//返回 workQueue 中未执行的任务
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
```

interruptWorkers () 很简单，循环对所有 worker 调用 interruptIfStarted ()，其中会判断 worker 的 AQS
state 是否大于 0 ，即 worker 是否已经开始运作，再调用 Thread.interrupt ()

**注意:**

对于运行中的线程调用 Thread.interrupt () 并不能保证线程被终止，为啥呢？

task.run () 内部执行的是业务代码，如果业务代码里边捕获了 InterruptException，没有上抛，导致这里
的结束机制失效。

改怎么办呢？其实也无所谓。

当 runWorker 执行下一次或者任务之后，里边会进行线程池状态的双重检查，如果线程池的状态变
了，变为结束，那么工作线程也会被中断了。

```
private void interruptWorkers () {
final ReentrantLock mainLock = this. mainLock;
mainLock.lock ();
try {
for (Worker w : workers)
w.interruptIfStarted ();
} finally {
mainLock.unlock ();
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
```
```
final void runWorker (Worker w) {
Thread wt = Thread.currentThread ();
Runnable task = w.firstTask;
w.firstTask = null;
w.unlock (); // allow interrupts
boolean completedAbruptly = true;
try {
while (task != null || (task = getTask ()) != null) {
w.lock ();
// If pool is stopping, ensure thread is interrupted;
// if not, ensure thread is not interrupted. This
// requires a recheck （线程池状态的双重检查） in second case to
deal with
// shutdownNow race while clearing interrupt
if ((runStateAtLeast (ctl.get (), STOP) ||
(Thread.interrupted () &&
runStateAtLeast (ctl.get (), STOP))) &&
!wt.isInterrupted ())
wt.interrupt ();
try {
beforeExecute (wt, task);
Throwable thrown = null;
try {
task.run ();
} catch (RuntimeException x) {
thrown = x; throw x;
} catch (Error x) {
thrown = x; throw x;
} catch (Throwable x) {
thrown = x; throw new Error (x);
} finally {
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
```
```
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
```

#### 源码分析 2 ：awaitTermination () 等待线程池终止的核心

#### 流程

这个方法，也比较重要，咱们顺便看看源码吧。

awaitTermination () 源码如下

在发出一个 shutdown 请求后，在以下 3 种情况发生之前，awaitTermination () 都会被阻塞

1 、所有任务完成执行

2 、到达超时时间

3 、当前线程被中断

这里用到一个锁条件 termination：

```
afterExecute (task, thrown);
}
} finally {
task = null;
w.completedTasks++;
w.unlock ();
}
}
completedAbruptly = false;
} finally {
processWorkerExit (w, completedAbruptly);
}
}
```
```
31
32
33
34
35
36
37
38
39
40
41
42
43
```
```
// 参数: timeout：超时时间 unit：timeout 超时时间的单位
//返回： true：线程池终止 , false：超过 timeout 指定时间
public boolean awaitTermination (long timeout, TimeUnit unit)
throws InterruptedException {
long nanos = unit.toNanos (timeout);
final ReentrantLock mainLock = this. mainLock;
mainLock.lock ();
try {
for (;;) {
// 线程池状态如果已经结束，立即返回，无需等待
if (runStateAtLeast (ctl.get (), TERMINATED))
return true;
if (nanos <= 0 )
return false;
//阻塞
nanos = termination.awaitNanos (nanos);
}
} finally {
mainLock.unlock ();
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
```

awaitTermination () 循环的判断线程池是否 terminated 终止或是否已经超过超时时间，然后通过
termination 这个 Condition 阻塞等待一段时间

termination 阻塞等待过程中发生以下具体情况会解除阻塞（对上面 3 种情况的解释）：

1 、如果发生了 termination.signalAll ()（内部实现是 LockSupport.unpark ()）会唤醒阻塞等待，且由
于 ThreadPoolExecutor 只有在 tryTerminated () 尝试终止线程池成功，将线程池更新为 terminated 状态
后才会 signalAll ()，故 awaitTermination () 再次判断状态会 return true 退出

2 、如果达到了超时时间 termination.awaitNanos () 也会返回，此时 nano==0，再次循环判断 return
false，等待线程池终止失败

3 、如果当前线程被 Thread.interrupt ()，termination.awaitNanos () 会上抛 InterruptException，
awaitTermination () 继续上抛给调用线程，会以异常的形式解除阻塞

故终止线程池并需要知道其是否终止，可以用如下方式：

## 美团一面：如何实现一个 100 W 级 ops 生产

## 者、消费者程序？

###### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，最近有小伙伴拿到了一线互联网企业如极兔、有赞、希
音、百度、网易的面试资格，遇到一几个很重要的面试题：

```
如何设计一个 100 W 级 ops 生产者、消费者程序？
```
与之类似的、其他小伙伴遇到过的问题还有：

```
手写一个生产者、消费者程序？
```
```
设计一个高性能的生产者、消费者程序？
```
这里尼恩给大家做一下系统化、体系化的线程池梳理，使得大家可以充分展示一下大家雄厚的 “技术肌
肉”， **让面试官爱到 “不能自已、口水直流”** 。

```
/**
* Wait condition to support awaitTermination
*/
private final Condition termination = mainLock.newCondition ();
```
```
1
2
3
4
```
```
executorService.shutdown ();
try{
while (! executorService.awaitTermination ( 500 , TimeUnit. MILLISECONDS)) {
LOGGER.debug ("Waiting for terminate");
}
} catch (InterruptedException e) {
//中断处理
}
```
```
1 2 3 4 5 6 7 8
```

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 61 版本，供后面的小伙伴参考，
提升大家的 3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，最新尼恩架构笔记、面试题的 PDF 文件，请从这里获取：[码云](）
```
#### 什么是生产者-消费者模式

###### 首先，来看什么是生产者-消费者问题？

生产者－消费者问题（Producer-Consumer Problem）也称有限缓冲问题（Bounded-Buffer
Problem），是一个多线程同步问题的经典案例。

生产者－消费者问题描述了两个访问共享缓冲区的线程，即生产者线程和消费者线程，在实际运行时会
发生的问题。生产者线程的主要功能是生成一定量的数据放到缓冲区中，然后重复此过程。消费者线程
的主要功能是从缓冲区提取（或消耗）数据。

生产者―消费者问题关键是：
1 ）保证生产者不会在缓冲区满时加入数据，消费者也不会在缓冲区中为空时消耗数据。
2 ）保证在生产者加入过程、消费者消耗过程中，不会产生错误的数据和行为。

生产者－消费者问题不仅仅是一个多线程同步问题的经典案例，而且业内已经将解决该问题的方案，抽
象成为了一种设计模式——“生产者－消费者”模式。

###### 现在，来看看什么是生产者-消费者模式？

生产者-消费者模式是一个经典的多线程设计模式，它为多线程间的协作提供了良好的解决方案。

在生产者－消费者模式中，通常由两类线程，即生产者线程（若干个）和消费者线程（若干个）。生产
者线程向数据缓冲区（DataBuffer）加入数据，消费者线程则从 DataBuffer 消耗数据。生产者和消费
者、内存缓冲区之间的关系结构图如下：

生产者-消费者模式中，有 4 个关键点：
（ 1 ）生产者与生产者之间、消费者与消费者之间，对数据缓冲区的操作是并发进行的。
（ 2 ）数据缓冲区是有容量上限的。数据缓冲区满后，生产者不能再加入数据；DataBuffer 空时，消费
者不能再取出数据。
（ 3 ）数据缓冲区是线程安全的。在并发操作数据区的过程中，不能出现数据不一致情况；或者在多个
线程并发更改共享数据后，不会造成出现脏数据的情况。
（ 4 ）生产者或者消费者线程在空闲时，需要尽可能阻塞而不是执行无效的空操作，尽量节约 CPU 资
源。

#### 面试题：如何实现一个 100 W 级 ops 生产者、消费者程序？


尼恩提示，遇到这样的面试题，我们可以从基础的版本开始，一步一步进行性能优化。

```
版本 1 ：不安全的生产者-消费者模式版本
版本 2 ：使用内置锁实现的生产者-消费者模式版本
顺便说说，锁的代价
版本 3 ：使用内置锁实现的生产者-消费者模式版本
```
#### 版本 1 ：不安全的生产者-消费者模式版本

根据生产者―消费者模式的结构图和描述先来实现一个非线程安全版本，包含了：

```
数据缓冲区（DataBuffer）类、
生产者（Producer）类、
消费者（Consumer）类。
```
首先定义其数据缓冲区类，具体的代码如下：

```
//共享数据区，类定义
class NotSafeDataBuffer<T> {
public static final int MAX_AMOUNT = 10 ;
//保存具体数据元素
private List<T> dataList = new LinkedList<>();
```
```
//保存元素数量
private AtomicInteger amount = new AtomicInteger ( 0 );
```
```
/**
* 向数据区增加一个元素
*/
public void add (T element) throws Exception {
if (amount.get () > MAX_AMOUNT) {
Print.tcfo ("队列已经满了！");
return;
}
dataList.add (element);
Print.tcfo (element + "");
amount.incrementAndGet ();
```
```
//如果数据不一致，抛出异常
if (amount.get () != dataList.size ()) {
throw new Exception (amount + "!=" + dataList.size ());
}
}
```
```
/**
* 从数据区取出一个元素
*/
public T fetch () throws Exception {
if (amount.get () <= 0 ) {
Print.tcfo ("队列已经空了！");
return null;
}
T element = dataList.remove ( 0 );
Print.tcfo (element + "");
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
```

上面的代码：

```
在 add () 实例方法中，加入元素之前首先会对 amount 是否达到上限进行判断，如果数据区满了，
则不能加入数据；
在 fetch () 实例方法中，消耗元素前首先会对 amount 是否大于零进行判断，如果数据区空了，就不
能取出数据。
```
生产者－消费者模式中，数据缓冲区（DataBuffer）类以及相应的生产、消费动作（Action）是可变
的，生产者类、消费者类的执行逻辑是不同的，

那本着“分离变与不变”的软件设计基本原则，可以将生产者类、消费者类与具体的生产、消费 Action 解
耦，

从而使得生产者类、消费者类的代码在后续可以复用，生产者、消费者逻辑与对应 Action 解耦后的类结
构图如下：

通用 Producer 类组合了一个 Callable 类型的成员 action 实例，代表了生产数据所需要执行的实际动作，
需要在构造 Producer 实例时传入。

通用生产者类的代码具体如下：

```
amount.decrementAndGet ();
//如果数据不一致，抛出异常
if (amount.get () != dataList.size ()) {
throw new Exception (amount + "!=" + dataList.size ());
}
return element;
}
}
```
```
38
39
40
41
42
43
44
45
```
```
/**
* 生产者任务的定义
* Created by 尼恩@疯狂创客圈. 源码来自《Java 高并发核心编程卷 2 加强版》
*/
public class Producer implements Runnable {
//生产的时间间隔，产一次等待的时间，默认为 200 ms
public static final int PRODUCE_GAP = 200 ;
```
```
//总次数
// 注意：
// 不是单个的次数
// 是所有生产者的总的生产次数
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
```

通用 Consumer 类也组合了一个 Callable 类型的成员 action 实例，代表了消费者所需要执行的实际消耗
动作，需要在构造 Consumer 实例时传入。

```
static final AtomicInteger TURN = new AtomicInteger ( 0 );
```
```
//生产者对象编号
static final AtomicInteger PRODUCER_NO = new AtomicInteger ( 1 );
```
```
//生产者名称
String name = null;
```
```
//生产的动作
Callable action = null;
```
```
int gap = PRODUCE_GAP;
```
```
public Producer (Callable action, int gap) {
this. action = action;
this. gap = gap;
if (this. gap <= 0 ) {
this. gap = PRODUCE_GAP;
}
name = "生产者-" + PRODUCER_NO.incrementAndGet ();
```
```
}
```
```
public Producer (Callable action) {
this. action = action;
this. gap = PRODUCE_GAP;
name = "生产者-" + PRODUCER_NO.incrementAndGet ();
```
```
}
```
```
@Override
public void run () {
while (true) {
```
```
try {
//执行生产动作
Object out = action.call ();
//输出生产的结果
if (null != out) {
Print.tcfo ("第" + TURN.get () + "轮生产：" + out);
}
//每一轮生产之后，稍微等待一下
sleepMilliSeconds (gap);
```
```
//增加生产轮次
TURN.incrementAndGet ();
```
```
} catch (Exception e) {
e.printStackTrace ();
}
}
}
}
```
```
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
```

通用 Consumer 类的代码具体如下：

```
/**
* 消费者任务的定义
* Created by 尼恩@疯狂创客圈. 源码来自《Java 高并发核心编程卷 2 加强版》
*/
public class Consumer implements Runnable {
```
```
//消费的时间间隔，默认等待 100 毫秒
public static final int CONSUME_GAP = 100 ;
```
```
//消费总次数
// 注意：
// 不是单个消费者的次数
// 是所有消费者的总的消费次数
static final AtomicInteger TURN = new AtomicInteger ( 0 );
```
```
//消费者对象编号
static final AtomicInteger CONSUMER_NO = new AtomicInteger ( 1 );
```
```
//消费者名称
String name;
```
```
//消费的动作
Callable action = null;
```
```
//消费一次等待的时间，默认为 1000 ms
int gap = CONSUME_GAP;
```
```
public Consumer (Callable action, int gap) {
this. action = action;
this. gap = gap;
name = "消费者-" + CONSUMER_NO.incrementAndGet ();
```
```
}
```
```
public Consumer (Callable action) {
this. action = action;
this. gap = gap;
this. gap = CONSUME_GAP;
name = "消费者-" + CONSUMER_NO.incrementAndGet ();
}
```
```
@Override
public void run () {
while (true) {
//增加消费次数
TURN.incrementAndGet ();
try {
//执行消费动作
Object out = action.call ();
if (null != out) {
Print.tcfo ("第" + TURN.get () + "轮消费：" + out);
}
//每一轮消费之后，稍微等待一下
sleepMilliSeconds (gap);
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
```

在完成了数据缓冲区类的定义、生产者类定义、消费者类的定义之后，

接下来定义一下数据缓冲区实例、生产动作和消费动作，具体的代码如下：

利用以上 NotSafePetStore 类所定义的三个静态成员，可以快速组装出一个简单的生产者－消费者模式
的 Java 实现版本，具体的代码如下：

```
} catch (Exception e) {
e.printStackTrace ();
}
}
}
}
```
```
56
57
58
59
60
61
```
```
// Created by 尼恩@疯狂创客圈. 源码来自《Java 高并发核心编程卷 2 加强版》
```
```
public class NotSafePetStore {
//共享数据区，实例对象
private static NotSafeDataBuffer<IGoods> notSafeDataBuffer = new
NotSafeDataBuffer ();
```
```
//生产者执行的动作
static Callable<IGoods> produceAction = () ->
{
//首先生成一个随机的商品
IGoods goods = Goods.produceOne ();
//将商品加上共享数据区
try {
notSafeDataBuffer.add (goods);
} catch (Exception e) {
e.printStackTrace ();
}
return goods;
};
//消费者执行的动作
static Callable<IGoods> consumerAction = () ->
{
// 从 PetStore 获取商品
IGoods goods = null;
try {
goods = notSafeDataBuffer.fetch ();
```
```
} catch (Exception e) {
e.printStackTrace ();
}
return goods;
};
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
```
```
// Created by 尼恩@疯狂创客圈. 源码来自《Java 高并发核心编程卷 2 加强版》
```
```
public static void main (String[] args) throws InterruptedException {
System.setErr (System. out);
```
```
// 同时并发执行的线程数
final int THREAD_TOTAL = 20 ;
```
```
1 2 3 4 5 6 7
```

在 NotSafePetStore 的 main () 方法中，利用 for 循环向线程池提交了 5 个生产者线程和 5 个消费者实例。

每个生产者实例生产一个商品间隔 500 毫秒；消费者实例每消费一个商品间隔 1500 毫秒；

也就是说，生产的速度大于消费的速度。

执行结果如下：

从以上异常可以看出，在向数据缓冲区进行元素的增加或者提取时，多个线程在并发执行对 amount、
dataList 两个成员操作时次序已经混乱，导致了数据不一致和线程安全问题。

#### 版本 2 ：使用内置锁实现的生产者-消费者模式版本

前面说了，为了实现线程安全的生产者-消费者模式实现，可以使用锁来实现。

```
比较低级的办法是用内置锁，也就是 synchronized+wait+notify 方式解决，
更加高级一点的版本，使用显示锁比如信号量（Semaphore）、Blockingqueue
当然，终极版本是无锁编程 disruptor 的方式来解决，
```
当然，咱们这个小节，仅仅关注 **有锁版本** ，后面的小节，再无锁编程。

咱们就挨个来看下。先看内置锁实现的生产者-消费者模式版本

###### synchronized+wait ()+notify () 的实现方式

使用 synchronized 解决生产者和消费者模式，首先我们需要找出临界区资源和临界区代码块。

首先，我们来看下什么是临界区资源。临界区资源表示一种可以被多个线程使用的公共资源或共享数
据，但是每一次只能有一个线程使用它。一旦临界区资源被占用，想使用该资源的其他线程则必须等
待。在并发情况下，临界区资源是受保护的对象。

```
//线程池，用于多线程模拟测试
ExecutorService threadPool =
Executors.newFixedThreadPool (THREAD_TOTAL);
for (int i = 0 ; i < 5 ; i++) {
//生产者线程每生产一个商品，间隔 500 ms
threadPool.submit (new Producer (produceAction, 500 ));
//消费者线程每消费一个商品，间隔 1500 ms
threadPool.submit (new Consumer (consumerAction, 1500 ));
}
}
```
```
8
9
```
```
10
11
12
13
14
15
16
```

接下来，我们再来看下什么是临界区代码块。临界区代码段（Critical Section）是每个线程中访问临界
资源的那段代码，多个线程必须互斥地对临界区资源进行访问。线程进入临界区代码段之前，必须在进
入区申请资源，申请成功之后进行临界区代码段，执行完成之后释放资源。临界区代码段的进入和退出
如下：

最后，我们来看下竟态条件（Race Conditions）可能是由于在访问临界区代码段时没有互斥地访问而
导致的特殊情况。

如果多个线程在临界区代码段的并发执行结果可能因为代码的执行顺序不同而出现不同的结果，我们就
说这时在临界区出现了竞态条件问题。

那咱们回过头来看生产者-消费者模式，这个模式中，生产者和消费者都需要操作 DataBuffer（数据缓
冲区）中，可以知道，临界区代码段在 DataBuffer（数据缓冲区）中。

在数据缓冲区中，主要是数据进行操作，那么由两个临界区资源，分别是 amount 和 dataList。

由生产者-消费者模式的关键点我们可知，生产者与生产者之间、消费者与消费者之间，对数据缓冲区
的操作是并发进行的。

那么添加数据和消耗数据是临界区代码，即其 add () 和 fetch () 两个方法。

那么创建建一个安全的数据缓存区类 SafeDataBuffer 类，在其 add () 和 fetch () 两个实例方法的 public 声明
后面加上 synchronized 关键字即可。那线程安全的 SafeDataBuffer 类代码如下：

```
// Created by 尼恩@疯狂创客圈. 源码来自《Java 高并发核心编程卷 2 加强版》
```
```
//共享数据区，类定义
class SafeDataBuffer<T> {
public static final int MAX_AMOUNT = 10 ;
private List<T> dataList = new LinkedList<>();
```
```
//保存数量
private AtomicInteger amount = new AtomicInteger ( 0 );
```
```
/**
* 向数据区增加一个元素
*/
public synchronized void add (T element) throws Exception {
if (amount.get () > MAX_AMOUNT) {
Print.tcfo ("队列已经满了！");
return;
}
dataList.add (element);
Print.tcfo (element + "");
amount.incrementAndGet ();
```
```
//如果数据不一致，抛出异常
if (amount.get () != dataList.size ()) {
throw new Exception (amount + "!=" + dataList.size ());
}
}
```
```
/**
* 从数据区取出一个元素
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
```

由于其他的代码没有发生变化，我们执行看下结果：

运行这个线程安全的生产者－消费者模式的实现版本，

等待一段时间，之前出现的 amount 数量和 dataList 的长度不相等的受检异常没有再抛出；

另外，之前出现的数据不一致情况以及线程安全问题也被完全解除。

目前的 SafeDataBuffer 类中，还存在一个性能的问题：消费者每一轮消费，不管数据区是否为空，都需
要进行数据区的询问和判断。

循环的代码如下：

```
*/
public synchronized T fetch () throws Exception {
if (amount.get () <= 0 ) {
Print.tcfo ("队列已经空了！");
return null;
}
T element = dataList.remove ( 0 );
Print.tcfo (element + "");
amount.decrementAndGet ();
//如果数据不一致，抛出异常
if (amount.get () != dataList.size ()) {
throw new Exception (amount + "!=" + dataList.size ());
}
return element;
}
}
```
```
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
```

当数据区空时（amount <= 0），消费者无法取出数据，但是仍然做一个无用的数据区询问工作，白白
耗费了 CPU 的时间片

对于生产者来说，也存在类似的无效轮询问题。

当数据区满时，生产者无法加入数据，这时候生产者执行 add (T element) 方法也白白耗费了 CPU 的时间
片。

在生产者或者消费者空闲时节约 CPU 时间片，免去巨大的 CPU 资源浪费的方法是使用“等待-通知”方式进
行生产者与消费者之间的线程通信。

具体实现：

（ 1 ）在数据区满（amount.get () > MAX_AMOUNT）时，可以让生产者等待，等到下次数据区中可以
加入数据时，给生产者发通知，让生产者唤醒。
（ 2 ）在数据区空（amount <= 0）时，可以让消费者等待，等到下次数据区中可以取出数据时，消费
者才能被唤醒。
（ 3 ）可以在消费者取出一个数据后，由消费者去唤醒等待的生产者。
（ 4 ）可以在生产者加入一个数据后，由生产者去唤醒等待的消费者。

Java 语言中“等待－通知”方式的线程间的通信使用对象的 wait ()、notify () 两类方法来实现。

每个 Java 对象都有 wait ()、notify () 两类实例方法，并且 wait ()、notify () 方法和对象的监视器是紧密相关
的。

Java 对象中的 wait ()、notify () 两类方法就如同信号开关，用来进行等待方和通知方之间的交互。

对象的 wait () 方法的主要作用是让当前线程阻塞并等待被唤醒。wait () 方法与对象监视器紧密相关，使用
wait () 方法时也一定需要放在同步块中。

wait () 方法的调用方法如下：

```
// Created by 尼恩@疯狂创客圈. 源码来自《Java 高并发核心编程卷 2 加强版》
```
```
/**
* 从数据区取出一个元素
*/
public synchronized T fetch () throws Exception {
if (amount.get () <= 0 ) {
Print.tcfo ("队列已经空了！");
return null;
}
....
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
```
```
// Created by 尼恩@疯狂创客圈. 源码来自《Java 高并发核心编程卷 2 加强版》
```
```
/**
* 向数据区增加一个元素
*/
public synchronized void add (T element) throws Exception {
if (amount.get () > MAX_AMOUNT) {
Print.tcfo ("队列已经满了！");
return;
}
....
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
```

对象的 notify () 方法的主要作用是唤醒在等待的线程。notify () 方法与对象监视器紧密相关，使用 notify ()
方法时也需要放在同步块中。notify () 方法的调用方法如下：

为了避免空轮询导致 CPU 时间片浪费，提高生产者－消费者实现版本的性能，接下来演示使用“等待－
通知”的方式在生产者与消费者之间进行线程间通信。

使用“等待－通知”机制通信的生产者－消费者实现版本定义三个同步对象，具体如下：
（ 1 ）LOCK_OBJECT：用于临界区同步，临界区资源为数据缓冲区的 dataList 变量和 amount 变量。

（ 2 ）NOT_FULL：用于数据缓冲区的未满条件等待和通知。生产者在添加元素前，需要判断数据区是
否已满，如果是，生产者进入 NOT_FULL 的同步区去等待被通知，只要消费者消耗一个元素，数据区就
是未满的，进入 NOT_FULL 的同步区发送通知。

（ 3 ）NOT_EMPTY：用于数据缓冲区的非空条件等待和通知。消费者在消耗元素前需要判断数据区是否
已空，如果是，消费者进入 NOT_EMPTY 的同步区等待被通知，只要生产者添加一个元素，数据区就是
非空的，生产者会进入 NOT_EMPTY 的同步区发送通知。

具体代码如下：

```
// Created by 尼恩@疯狂创客圈. 源码来自《Java 高并发核心编程卷 2 加强版》
```
```
synchronized (locko)
{
//同步保护的代码块
locko.wait ()；
...
}
```
```
1 2 3 4 5 6 7 8 9
```
```
// Created by 尼恩@疯狂创客圈. 源码来自《Java 高并发核心编程卷 2 加强版》
```
```
synchronized (locko)
{
//同步保护的代码块
locko.notify ()；
...
}
```
```
1 2 3 4 5 6 7 8 9
```
```
// Created by 尼恩@疯狂创客圈. 源码来自《Java 高并发核心编程卷 2 加强版》
```
```
public class CommunicatePetStore {
```
```
public static final int MAX_AMOUNT = 10 ; //数据区长度
```
```
//共享数据区，类定义
static class DateBuffer<T> {
//保存数据
private List<T> dataList = new LinkedList<>();
//保存数量
private volatile int amount = 0 ;
```
```
private final Object LOCK_OBJECT = new Object ();
private final Object NOT_FULL = new Object ();
private final Object NOT_EMPTY = new Object ();
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
```

那以上就是使用 synchronized+wait+notify 实现的线程安全的生产者-消费者模式。

```
// 向数据区增加一个元素
public void add (T element) throws Exception {
synchronized (NOT_FULL) {
while (amount >= MAX_AMOUNT) {
Print.tcfo ("队列已经满了！");
//等待未满通知
NOT_FULL.wait ();
}
}
synchronized (LOCK_OBJECT) {
```
```
if (amount < MAX_AMOUNT) { // 加上双重检查，模拟双检锁在单例模式中
应用
dataList.add (element);
amount++;
}
}
synchronized (NOT_EMPTY) {
//发送未空通知
NOT_EMPTY.notify ();
}
}
```
```
/**
* 从数据区取出一个商品
*/
public T fetch () throws Exception {
synchronized (NOT_EMPTY) {
while (amount <= 0 ) {
Print.tcfo ("队列已经空了！");
//等待未空通知
NOT_EMPTY.wait ();
}
}
```
```
T element = null;
synchronized (LOCK_OBJECT) {
if (amount > 0 ) {  // 加上双重检查，模拟双检锁在单例模式中应用
element = dataList.remove ( 0 );
amount--;
}
}
```
```
synchronized (NOT_FULL) {
//发送未满通知
NOT_FULL.notify ();
}
return element;
}
}
}
```
```
18
19
20
21
22
23
24
25
26
27
28
29
```
```
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
```

虽然线程安全问题顺利解决，但是以上的解决方式使用了 SafeDataBuffer 的实例的对象锁作为同步锁，
这样一来，所有的生产、消费动作在执行过程中都需要抢占同一个同步锁，最终的结果是所有的生产、
消费动作都被串行化了。

而且在锁竞争激烈的情况下，synchronized 锁会膨胀升级为重量级锁，严重的影响的程序的性能。

**尼恩提示：**

_synchronized_ 锁的膨胀底层原理，非常重要，这部分内容可以阅读《 _Java_ 高并发核心编程卷 _2_ 加强
版》。

这里不做赘述。

#### 版本 3 ：使用信号量实现（Semaphore）

为了实现线程安全的生产者-消费者模式实现，可以使用锁来实现。

```
比较低级的办法是用内置锁，也就是 synchronized+wait+notify 方式解决，
更加高级一点的版本，使用显示锁比如信号量（Semaphore）、Blockingqueue
当然，终极版本是无锁编程 disruptor 的方式来解决，
```
当然，咱们这个小节，仅仅关注 **有锁版本** ，后面的小节，再无锁编程。

咱们就挨个来看下。那接下我们看下显示锁的核心成员之一信号量（semaphore）实现线程安全的
生产者-消费者模式。

###### 什么是信号量？

信号量是 Dijkstra 在 1965 年提出的一种方法，它使用一个整型变量来累计唤醒次数，供以后使用。

在他的建议中引入了一个新的变量类型，称作信号量（semaphore）。

一个信号量的取值可以为 0 （表示没有保存下来的唤醒操作）或者正值（表示有一个或多个唤醒操
作）。

Dijkstra 建议设立两种操作：down 和 up（分别为一般化后的 sleep 和 wakeup）。

对一个信号量执行 down 操作，则是检查其值是否大于 0 。若该值大于 0 ，则将其减 1 （即用掉一个保存的
唤醒信号）并继续；若该值为 0 ，则进程将睡眠，而且此时 down 操作并未结束。

**原子操作：所谓原子操作，是指一组相关联的操作要么都不间断地执行，要么不执行。**

检查数值、修改变量值以及可能发生的睡眠操作，均作为一个单一的、不可分割的原子操作完成。保证
一旦一个信号量操作开始，则在该操作完成或阻塞之前，其他进程均不允许访问该信号量。

这种原子性对于解决同步问题和避免竞争条件是绝对必要的。

up 操作对信号量的值增 1 。

如果一个或多个进程在该信号量上睡眠，无法完成一个先前的 down 操作，则由系统选择其中的一个
（如随机挑选）并允许该进程完成它的 down 操作。

于是，对一个有进程在其上睡眠的信号量执行一次 up 操作后，该信号量的值仍旧是 0 ，但在其上睡眠的
进程却少了一个。信号量的值增加 1 和唤醒一个进程同样也是不可分割的，不会有某个进程因执行 up 而
阻塞，正如前面的模型中不会有进程因执行 wakeup 而阻塞一样。

**Dijkstra 论文中的信号量含义**


在 Dijkstra 原来的论文中，他分别使用名称 P 和 V 而不是 down 和 up，

荷兰语中，Proberen 的意思是尝试，Verhogen 的含义是增加或升高。

从物理上说明信号量的 P、V 操作的含义。

P (S) 表示申请一个资源，S.value>0 表示有资源可用，其值为资源的数目；S.value=0 表示无资源可用；
S.value<0, 则|S.value|表示 S 等待队列中的进程个数。

V (S) 表示释放一个资源，信号量的初值应该大于等于 0 。P 操作相当于“等待一个信号”，而 V 操作相当于
“发送一个信号”，在实现同步过程中，V 操作相当于发送一个信号说合作者已经完成了某项任务，在实现
互斥过程中，V 操作相当于发送一个信号说临界资源可用了。

实际上，在实现互斥时，P、V 操作相当于申请资源和释放资源。

Dijkstra 的解决方案使用了三个信号量：

一个称为 full，用来记录充满缓冲槽数目，

一个称为 empty，记录空的缓冲槽总数；

一个称为 mutex，用来确保生产者和消费者不会同时访问缓冲区。

full 的初值为 0 ，empty 的初值为缓冲区中槽的数目，mutex 的初值为 1 。供两个或多个进程使用的信号
量，其初值为 1 ，保证同时只有一个进程可以进入临界区，称作二元信号量。如果每个进程在进入临界
区前都执行 down 操作，并在刚刚退出时执行一个 up 操作，就能够实现互斥。

信号量的另一种用途是用于实现同步，信号量 full 和 empty 用来保证某种事件的顺序发生或不发生。在
本例中，它们保证当缓冲区满的时候生产者停止运行，以及当缓冲区空的时候消费者停止运行。

对于无界缓冲区的生产者—消费者问题，两个进程共享一个不限大小的公共缓冲区。

由于是无界缓冲区（仓库是无界限制的），即生产者不用关心仓库是否满，只管往里面生产东西，但是
消费者还是要关心仓库是否空。所以生产者不会因得不到缓冲区而被阻塞，不需要对空缓冲区进行管
理，可以去掉在有界缓冲区中用来管理空缓冲区的信号量及其 PV 操作。

**JUC 中的信号量 Semaphore**

在 JUC 中的信号量 Semaphore 属于共享锁。Semaphore 可以用来控制在同一时刻访问共享资源的线程
数量，通过协调各个线程以保证共享资源的合理使用。Semaphore 维护了一组虚拟许可，其数量可以
通过构造器的参数指定。线程在访问共享资源前必须使用 Semaphore 的 acquire () 方法获得许可，如果
许可数量为 0 ，该线程就一直阻塞。线程访问完成资源后，必须使用 Semaphore 的 release () 方法释放许
可。更形象的说法是：Semaphore 是一个是许可管理器。

JUC 包中 Semaphore 类的主要方法大致如下：

Semaphore 类的主要方法大致如下：

```
(1) Semaphore (permits)：构造一个 Semaphore 实例，初始化其管理的许可数量为 permits 参数
```
值。

```
(2) Semaphore (permits, fair)：构造一个 Semaphore 实例，初始化其管理的许可数量为 permits 参
```
数值，以及是否以公平模式（fair 参数是否为 true）进行许可的发放。

Semaphore 和 ReentrantLock 类似，Semaphore 发放许可时有两种模式：公平模式和非公平模式，默
认情况下使用非公平模式。

```
(3) availablePermits ()：获取 Semaphore 对象可用的许可数量。
```
(4) acquire ()：当前线程尝试获取 Semaphore 对象的一个许可。此过程是阻塞的，线程会一直等待
Semaphore 发放一个许可，直到发生以下任意一件事：

```
当前线程获取了一个可用的许可。
```

```
当前线程被中断，就会抛出 InterruptedException 异常，并停止等待，继续往下执行。
```
```
(5) acquire (permits)：当前线程尝试阻塞地获取 permits 个许可。此过程是阻塞的，线程会一直等
```
待 Semaphore 发放 permits 个许可。如果没有足够的许可而当前线程被中断，就会抛出
InterruptedException 异常并终止阻塞。

```
(6) acquireUninterruptibly ()：当前线程尝试阻塞地获取一个许可，阻塞的过程不可中断，直到
```
成功获取一个许可。

```
(7) acquireUninterruptibly (permits)：当前线程尝试阻塞地获取 permits 个许可，阻塞的过程不
```
可中断，直到成功获取 permits 个许可。

```
(8) tryAcquire ()：当前线程尝试获取一个许可。此过程是非阻塞的，它只是进行一次尝试，会立即
```
返回。如果当前线程成功获取了一个许可，就返回 true；如果当前线程没有获得许可，就返回 false

```
(9) tryAcquire (permits)：当前线程尝试获取 permits 个许可。此过程是非阻塞的，它只是进行一
```
次尝试，会立即返回。如果当前线程成功获取了 permits 个许可，就返回 true；如果当前线程没有获得
permits 个许可，就返回 false。

(10) tryAcquire (timeout, TimeUnit)：限时获取一个许可。此过程是阻塞的，会一直等待许可，
直到发生以下任意一件事：

```
当前线程获取了一个许可，则会停止等待，继续执行，并返回 true。
当前线程等待 timeout 后超时，则会停止等待，继续执行，并返回 false。
当前线程在 timeout 时间内被中断，则会抛出 InterruptedException 异常，并停止等待，继续执
行。
```
```
(11) tryAcquire (permits, timeout, TimeUnit)：与 tryAcquire (timeout, TimeUnit) 方法在逻辑上基
```
本相同，不同之处在于：在获取许可的数量上不同，此方法用于获取 permits 个许可。

```
(12) release ()：当前线程释放一个可用的许可。
```
```
(13) release (permits)：当前线程释放 permits 个可用的许可。
```
```
(14) drainPermits ()：当前线程获得剩余的所有可用许可。
```
```
(15) hasQueuedThreads ()：判断当前 Semaphore 对象上是否存在正在等待许可的线程。
```
```
(16) getQueueLength ()：获取当前 Semaphore 对象上正在等待许可的线程数量。
```
###### 使用 Semaphore 实现的生产者-消费者模式

那接下来我们就看下使用 Semaphore 实现的生产者-消费者模式的代码，主要是针对临界区资源和临界
区代码进行修改，具体修改如下：

```
// Created by 尼恩@疯狂创客圈. 源码来自《Java 高并发核心编程卷 2 加强版》
```
```
public class SemaphorePetStore {
public static final int MAX_AMOUNT = 10 ; //数据区长度
```
```
//共享数据区，类定义
static class DateBuffer<T> {
//保存数据
private LinkedBlockingDeque<T> dataList = new LinkedBlockingDeque<>
(MAX_AMOUNT);
```
```
//保存数量
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
```

```
private volatile int amount = 0 ;
// 每次处理的次数
private static final int times = 100 ;
```
```
//信号量标识
private static AtomicInteger signal = new AtomicInteger ( 0 );
```
```
// 向数据区增加一个元素
public void add (T element) throws Exception {
while (amount < times) {
if (signal.get () >= 0 && dataList.size () == 0 ) {
synchronized (signal) {
//生产者: P 操作 -1
Print.fo ("生产者: P 操作 -1 ");
signal.incrementAndGet ();
Print.fo ("生产者: 生产，放入一个对象");
dataList.add (element);
amount++;
//生产者: P 操作 -1
Print.fo ("生产者: V 操作 +1");
signal.decrementAndGet ();
Print.fo ("生产者: 通知消费者，生产者阻塞");
signal.notifyAll ();
// 阻塞
signal.wait ();
;
}
} else {
Thread.sleep ( 10 );
}
}
}
```
```
/**
* 从数据区取出一个商品
*/
public T fetch () throws Exception {
T element = null;
while (amount < times) {
if (signal.get () <= 0 && dataList.size() > 0 ) {
synchronized (signal) {
//消费者: P 操作 -1
Print.fo ("消费者: P 操作 -1 ");
signal.decrementAndGet ();
Print.fo ("消费者: 消费，取出一个对象");
element = dataList.take ();
amount--;
//生产者: P 操作 -1
Print.fo ("消费者: V 操作 +1");
signal.incrementAndGet ();
Print.fo ("消费者: 通知生产者，消费者阻塞");
signal.notifyAll ();
// 阻塞
signal.wait ();
;
}
} else {
```
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69


由于其他代码未做更改，小伙伴可参考前面的线程不安全的生产者类、消费者类以及组装生产者-消费
者模式的实现。

部分执行结果如下：

#### 版本四：使用 Blockingqueue 实现

回顾前面： 为了实现线程安全的生产者-消费者模式实现，可以使用锁来实现。

```
比较低级的办法是用内置锁，也就是 synchronized+wait+notify 方式解决，
更加高级一点的版本，使用显示锁比如信号量（Semaphore）、Blockingqueue
当然，终极版本是无锁编程 disruptor 的方式来解决，
```
当然，咱们这个小节，仅仅关注 **有锁版本** ，后面的小节，再无锁编程。

咱们就挨个来看下。那接下我们看下基于显示锁实现的核心结构 Blockingqueue 实现线程安全的生产
者-消费者模式。

在多线程环境中，通过 BlockingQueue（阻塞队列）可以很容易地实现多线程之间数据共享和通信。

```
Thread.sleep ( 10 );
}
}
return element;
}
}
}
```
```
70
71
72
73
74
75
76
77
```

阻塞队列与普通队列（ArrayDeque 等）之间的最大不同点在于阻塞队列提供了阻塞式的添加和删除方
法。
（ 1 ）阻塞添加
所谓的阻塞添加是指当阻塞队列元素已满时，队列会阻塞添加元素的线程，直队列元素不满时，才重新
唤醒线程执行元素添加操作。

（ 2 ）阻塞删除
阻塞删除是指在队列元素为空时，删除队列元素的线程将被阻塞，直到队列不为空时，才重新唤醒删除
线程再执行删除操作。

BlockingQueue 的实现类有 ArrayBlockingQueue、DelayQueue、LinkedBlockingDeque、
LinkedBlockingQueue、PriorityBlockingQueue、SynchronousQueue 等，具体如下：

ArrayBlockingQueue 是一个常用的阻塞队列，是基于数组实现的，其内部使用一个定长数组存储元
素。除了一个定长数组外，ArrayBlockingQueue 内部还保存着两个整型变量，分别标识队列的头部和
尾部在数组中的位置。ArrayBlockingQueue 的添加和删除操作都是共用同一个锁对象，由此意味着添
加和删除无法并行运行，这一点不同于 LinkedBlockingQueue。ArrayBlockingQueue 完全可以将添加
和删除的锁分离，从而添加和删除操作完全并行。Doug Lea 之所以没有这样去做，是因为

ArrayBlockingQueue 的数据写入和获取操作已经足够轻巧。

LinkedBlockingQueue 是基于链表的阻塞队列，其内部也维持着一个数据缓冲队列（该队列由一个链表
构成）。LinkedBlockingQueue 对于添加和删除元素分别采用了独立的锁来控制数据同步，这也意味着
在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列的并发性能。

DelayQueue 中的元素只有当其指定的延迟时间到了，才能从队列中获取到该元素。DelayQueue 是一
个没有大小限制的队列，因此往队列中添加数据的操作（生产者）永远不会被阻塞，而只有获取数据的
操作（消费者）才会被阻塞。DelayQueue 使用场景较少，但是相当巧妙，常见的例子比如使用一个
DelayQueue 来管理一个超时未响应的连接队列。

基于优先级的阻塞队列和 DelayQueue 类似，PriorityBlockingQueue 并不会阻塞数据生产者，而只会在
没有可消费的数据时，阻塞数据的消费者。在使用的时候要特别注意，生产者生产数据的速度绝对不能
快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。

相对于有缓冲的阻塞队列（如 LinkedBlockingQueue）来说，SynchronousQueue 少了中间缓冲区（如
仓库）的环节。如果有仓库，生产者直接把商品批发给仓库，不需要关心仓库最终会将这些商品发给哪
些消费者，由于仓库可以中转部分商品，总体来说有仓库进行生产和消费的吞吐量高一些。反过来说，
又因为仓库的引入，使得商品从生产者到消费者中间增加了额外的交易环节，单个商品的及时响应性能
可能会降低，所以对单个消息的响应要求高的场景可以使用 SynchronousQueue。声明一个
SynchronousQueue 有两种不同的方式：公平模式和非公平模式。公平模式的 SynchronousQueue 会
采用公平锁，并配合一个 FIFO 队列来阻塞多余的生产者和消费者，从而体系整体的公平策略。非公平模
式（默认情况）的 SynchronousQueue 采用非公平锁，同时配合一个 LIFO 堆栈（TransferStack 内部实
例）来管理多余的生产者和消费者。对于后一种模式，如果生产者和消费者的处理速度有差距，则很容
易出现线程饥渴的情况，即可能出现某些生产者或者消费者的数据永远都得不到处理。

了解完阻塞队列的基本方法、主要类型之后，下面通过 ArrayBlockingQueue 队列实现一个生产者－消
费者的案例。


具体的代码在前面的生产者和消费者实现基础上进行迭代——Consumer（消费者）和 Producer（生产
者）通过 ArrayBlockingQueue 队列获取和添加元素。其中，消费者调用了 take () 方法获取元素，当队列
没有元素就阻塞；生产者调用 put () 方法添加元素，当队列满时就阻塞。通过这种方式便实现生产者－消
费者模式，比直接使用等待唤醒机制或者 Condition 条件队列更加简单。基于 ArrayBlockingQueue 的生
产者和消费者实现版本具体的 UML 类图如下

出于“分离变与不变”的原则，此版本的 Producer（生产者）、Consumer（消费者）等的逻辑不用变
化，直接复用前面原的代码即可。此版本 DataBuffer（共享数据区）需要变化，使用一个
ArrayBlockingQueue 用于缓存数据，具体的代码如下：

运行程序，部分执行结果如下：

```
// Created by 尼恩@疯狂创客圈. 源码来自《Java 高并发核心编程卷 2 加强版》
```
```
public class ArrayBlockingQueuePetStore {
```
```
public static final int MAX_AMOUNT = 10 ; //数据区长度
```
```
//共享数据区，类定义
static class DateBuffer<T> {
//保存数据
private ArrayBlockingQueue<T> dataList = new ArrayBlockingQueue<>
(MAX_AMOUNT);
```
```
// 向数据区增加一个元素
public void add (T element) throws Exception {
dataList.put (element);
}
```
```
/**
* 从数据区取出一个商品
*/
public T fetch () throws Exception {
return dataList.take ();
}
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
```
```
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
```

```
Method Time (ms)
```
```
Single thread 300
```
```
Single thread with lock 10,000
```
```
Two threads with lock 224,000
```
```
Single thread with CAS 5,700
```
```
Two threads with CAS 30,000
```
```
Single thread with volatile write 4,700
```
#### 锁的代价

锁提供了互斥，并能够确保变化能够以一个确定的顺序让其它的线程看见。

锁其实是很昂贵的，因为他们在竞争的时候需要进行仲裁。这个仲裁会涉及到操作系统的上下文切换，
操作系统会挂起所有在等待这把锁的线程，直到锁持有者释放该锁。

上下文切换期间，执行线程会丧失对操作系统的控制，导致执行线程的执行上下文丢失之前缓存的数据
和指令集，这会给现代处理器带来严重的性能损耗。

当然效率更高的用户态锁是另一种选择，但用户锁只有在没有竞争的时候才真正会带来益处。

注：因为用户态的锁往往是通过自旋锁来实现（或者带休眠的自旋锁），而自旋在竞争激烈的时候开销
是很大的（一直在消耗 _CPU_ 资源）。

网上有小伙伴为了进行效果验证，写了一个很简单程序，就是调用一个循环 5 亿次递增操作的函数。

这个 java 函数在单线程，2.4 G Intel Westmere EP 的 CPU 上只需要 300 ms。

一旦引入锁，即使没有发生竞争，程序的执行时间也会发生显著的增加。

**循环 5 亿次递增操作实验结果如下：**


#### CAS 的代价

无锁编程场景中，线程之间的协调主要使用 CAS 的机制。但是从上面的实验看到， CAS 也是有代价
的。

**为啥呢？**

CAS 依赖于处理器的支持，当然大部分现代处理器都支持。

**CAS 相对于锁是非常高效的，因为它不需要涉及内核上下文切换进行仲裁。**

**但 cas 并不是免费的，处理器需要对 CPU 指令 pipeline 加锁以确保原子性，**

**并且 cas 只保证原子性，不保证可见性，所以 cas 一般和 volatile 内存屏障一起使用，以确保对其他线程
的可见性。**

尼恩备注： **_cas+ volatile_** **内存屏障的底层原理，非常重要** 。

如果大家对 _cas+ volatile_ 内存屏障的知识不清楚，请细致阅读尼恩《 _Java_ 高并发核心编程卷 _2_ 》，这
本书做了非常详细的介绍。

#### 版本五：无锁实现生产者-消费者模式版本

回顾前面： 为了实现线程安全的生产者-消费者模式实现，可以使用锁来实现。

```
比较低级的办法是用内置锁，也就是 synchronized+wait+notify 方式解决，
更加高级一点的版本，使用显示锁比如信号量（Semaphore）、Blockingqueue
当然，终极版本是无锁编程 disruptor 的方式来解决，
```
咱们就挨个来看下无锁版本。

为了提升性能，需要使用 CAS 实现生产者、消费者。

从实操的角度来说，CAS 的一个问题就是太复杂了，本来用锁进行并发编程就已经很头疼了，用 CAS 来
实现复杂逻辑就更头痛了。

但有一个好消息是，目前有一个现成的 Disruptor 框架，它已经帮助我们实现了这一个功能。

###### Disruptor 框架的简单介绍

Disruptor 框架有着 1000 W 级 ops 性能，非常复杂的底层原理，光介绍清楚这个框架，尼恩的
《Disruptor 红宝书》 PDF 电子书就有 100 多页。

具体的 Disruptor 框架底层原理，请参见尼恩的《Disruptor 红宝书》 PDF ，和《100 Wqps 日志平台实
操》视频。

这里仅仅对这个框架进行简单介绍。

Disruptor 框架是由 LMAX 公司开发的一款高效的无锁内存队列。


它使用无锁的方式实现了一个环形队列（RingBuffer），非常适合实现生产者-消费者模式，比如事件和
消息的发布。

目前，包括 Apache Storm、Camel、Log 4 j 2 在内的很多知名项目都应用了 Disruptor 以获取高性能。

Disruptor 框架别出心裁地使用了环形队列来代替普通线形队列，这个环形队列内部实现为一个普通的
数组。

对于一般的队列，势必要提供队列同步 head 和尾部 tail 两个指针，用于出队和入队，这样无疑增加了线
程协作的复杂度。但如果队列是环形的，则只需要对外提供一个当前位置 cursor，利用这个指针既可以
进行入队操作，也可以进行出队操作。由于环形队列的缘故，队列的总大小必须事先指定，不能动态扩
展。为了能够快速从一个序列（sequence）对应到数组的实际位置（每次有元素入队，序列就加 1 ），
Disruptor 框架要求我们必须将数组的大小设置为 2 的整数次方。这样通过 sequence ＆(queueSize-1) 就
能立即定位到实际的元素位置 index，这比取余（%）操作快得多。

如果 queueSize 是 2 的整数次幂，则这个数字的二进制表示必然是 10 、 100 、 1000 、 10000 等形式。因
此，queueSize-1 的二进制则是一个全 1 的数字。因此它可以将 sequence 限定在 queueSize-1 范围内，
并且不会有任何一位是浪费的。

RingBuffer 的结构如下：

其实质只是一个普通的数组，只是当放置数据填充满队列（即到达 2^n-1 位置）之后，再填充数据，就
会从 0 开始，覆盖之前的数据，于是就相当于一个环。

RingBuffer 的指针（Sequence）属于一个 volatile 变量，同时也是我们能够不用锁操作就能实现
Disruptor 的原因之一，而且通过缓存行补充，避免伪共享问题。该所谓指针是通过一直自增的方式来
获取下一个可写或者可读数据，该数据是 Long 类型，不用担心会爆掉。有人计算过： long 的范围最大
可以达到 9223372036854775807 ，一年 365 * 24 * 60 * 60 = 31536000 秒，每秒产生 1 W 条数据，也
可以使用 292 年。

Disruptor 不像传统的队列，分为一个队头指针和一个队尾指针，而是只有一个角标（上面的 seq），
在 Disruptor 中生产者分为单生产者和多生产者，在枚举类 ProducerType 中定义单生产（SINGLE）和
多生产（MULTI）。而消费者并没有区分。


单生产者情况下，就是普通的生产者向 RingBuffer 中放置数据，消费者获取最大可消费的位置，并进行
消费。单生产者线程写数据的流程比较简单, 具体如下:
（ 1 ）申请写入 m 个元素；
（ 2 ）若是有 m 个元素可以入，则返回最大的序列号。这儿主要判断是否会覆盖未读的元素；
（ 3 ）若是返回的正确，则生产者开始写入元素。

采用多生产者时，会遇到“如何防止多个线程重复写同一个元素”的问题。Disruptor 的解决方法是，每个
线程获取不同的一段数组空间进行操作。这个通过 CAS 很容易达到。只需要在分配元素的时候，通过
CAS 判断一下这段空间是否已经分配出去即可。

但是又会碰到新问题：如何防止读取的时候，读到还未写的元素。那么 Disruptor 引入了一个跟
RingBuffer 同样大小的 Buffer，称为 AvailableBuffer。当某个位置写入成功的时候，便把 availble
Buffer 相应的位置置位，标记为写入成功。读取的时候，会遍历 available Buffer，来判断元素是否已经
就绪。多生产者流程如下：
（ 1 ）申请写入 m 个元素；
（ 2 ）若是有 m 个元素可以写入，则返回最大的序列号。每个生产者会被分配一段独享的空间；
（ 3 ）生产者写入元素，写入元素的同时设置 available Buffer 里面相应的位置，以标记自己哪些位置是
已经写入成功的。


那么生产者和消费者模式在 RingBuffer 上的情况如下

生产者向缓冲区中写入数据，而消费者从中读取数据。生产者写入数据时，使用 CAS 操作，消费者读取
数据时，为了防止多个消费者处理同一个数据，也使用 CAS 操作进行数据保护。

###### ArrayBlockingQueue 和 Disruptor 的性能 PK

参考文献中，有小伙伴选取了 Doug Lea 的 ArrayBlockingQueue 的实现作为参考目标进行测试，
ArrayBlockingQueue 是所有有界队列中性能最好的，测试是按照阻塞的方式进行的。

。


```
Nehalem 2.8 Ghz –
Windows 7 SP 1 64-
bit
```
```
Sandy Bridge 2.2 Ghz
```
**- Linux 2.6.38 64-bit**

```
ABQ Disruptor ABQ Disruptor
```
```
Unicast: 1 P
```
- 1 C

```
5,339,256 25,998,336 4,057,453 22,381,378
```
```
Pipeline:
1 P – 3 C
2,128,918 16,806,157 2,006,903 15,857,913
```
```
Sequencer:
3 P – 1 C
5,539,531 13,403,268 2,056,118 14,540,519
```
```
Multicast:
1 P – 3 C
```
```
1,077,384 9,377,871 260,733 10,860,121
```
```
Diamond:
1 P – 3 C
```
```
2,113,941 16,143,613 2,082,725 15,295,197
```
下表展示了总共处理 5 亿条消息时每秒吞吐量的性能测试结果，

测试环境为：没有 HT 的 1.6.0_25 64-bit Sun JVM, Windows 7, Intel Core i 7 860 @ 2.8 GHz ，以及 Intel
Core i 7-2720 QM, Ubuntu 11.04。

我们取了最好的前三条结果，这个结果使用于任何 JVM 运行环境，表中显示的结果并不是我们发现最好
的结果。

无论在 linux 环境在是在 windows 环境，无论是多个生产者还是单个生产者， **Disruptor** 的性能稳稳
的都在 1000 W ops 以上。


###### 基于 Disruptor 的实现 100 W 级 ops+ 生产者和消费者设计

基于 Disruptor 的高性能生产者和消费者模式的类图如下：

MsgEven 是存放数据对象的载体，具体代码如下：

消费者的作用是读取数据进行处理。

这里，数据的读取已经由 Disruptor 框架进行封装了，onEvent () 方法为框架的回调方法。

因此，只需要简单地进行数据处理即可。

具体代码如下：

```
public class MsgEven {
```
```
private IGoods goods;
```
```
public IGoods getGoods () {
return goods;
}
```
```
public void setGoods (IGoods goods) {
this. goods = goods;
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
```
```
public class Consumer implements EventHandler<MsgEven> {
```
```
//消费的时间间隔，默认等待 100 毫秒
public static final int CONSUME_GAP = 100 ;
```
```
//消费者对象编号
static final AtomicInteger CONSUMER_NO = new AtomicInteger ( 1 );
```
```
//消费者名称
String name;
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
```

需要一个产生 MsgEven 对象的工厂类 GoodsFactory。

它会在 Disruptor 框架系统初始化时，构造所有的缓冲区中的对象实例, 具体代码如下：

生产者需要一个 RingBuffer 的引用，也就是环形缓冲区。

它有一个重要的方法 add () 将产生的数据推入缓冲区。方法 add () 接收一个 IGood 对象。

add () 方法的功能就是将传入的 IGood 对象中的数据提取出来，并装载到环形缓冲区中。

具体代码如下：

```
public Consumer () {
name = "消费者-" + CONSUMER_NO.incrementAndGet ();
}
```
```
@Override
public void onEvent (MsgEven msgEven, long sequence, boolean endOfBatch)
{
```
```
Print.tcfo ("消费者中："+sequence+"商品信息："+msgEven.getGoods ());
}
}
```
```
14
15
16
17
18
19
20
```
```
21
22
23
24
25
```
```
public class GoodsFactory implements EventFactory<MsgEven> {
@Override
public MsgEven newInstance () {
return new MsgEven ();
}
}
```
```
1 2 3 4 5 6 7
```
```
public class Produer {
```
```
//生产者对象编号
static final AtomicInteger PRODUCER_NO = new AtomicInteger ( 1 );
```
```
//生产者名称
String name = null;
```
```
private final RingBuffer<MsgEven> ringBuffer ;
```
```
public Produer (RingBuffer<MsgEven> ringBuffer) {
name = "生产者-" + PRODUCER_NO.incrementAndGet ();
this. ringBuffer = ringBuffer;
}
```
```
public void add (IGoods goods){
// 1. ringBuffer 事件队列下一个槽
long sequence = ringBuffer.next ();
try {
//2. 取出空的事件队列
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
```

我们的生产者、消费者和数据都已经准备就绪，只差一个统筹规划的主函数将所有的内容整合起来。具
体代码如下：

部分执行结果如下：

```
MsgEven msgEven= ringBuffer.get (sequence);
msgEven.setGoods (goods);
//3. 获取事件队列传递的数据
Print.cfo ("生产者名称："+name+"，生产商品："+goods.toString ());
}finally {
//4. 发布事件
ringBuffer.publish (sequence);
}
}
}
```
```
23
24
25
26
27
28
29
30
31
32
33
```
```
public class DisruptorPetStore {
public static void main (String[] args) throws InterruptedException {
// 1. 创建工厂
GoodsFactory dateBufferFactory= new GoodsFactory ();
//2. 创建 ringBuffer 大小, 大小一定要是 2 的 N 次方
int bufferSize= 1024 * 1024 ;
```
```
//3. 创建 Disruptor
Disruptor<MsgEven> disruptor = new Disruptor<MsgEven>
(dateBufferFactory, bufferSize,
Executors.defaultThreadFactory (), ProducerType. MULTI, new
BlockingWaitStrategy ());
//4. 设置事件处理器即消费者
disruptor.handleEventsWith (new Consumer ());
// 5. 启动
disruptor.start ();
```
```
// 6. 创建 RingBuffer 容器
RingBuffer<MsgEven> ringBuffer= disruptor.getRingBuffer ();
```
```
//7. 创建生产者
Produer produer = new Produer (ringBuffer);
```
```
for (int l= 0 ;true; l++){
IGoods goods = Goods.produceOne ();
produer.add (goods);
Thread.sleep ( 100 );
```
```
}
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
```

学习生产者-消费者模式学习的思想，消息队列、缓存中也有生产者-消费者模式的思想。

#### 尼恩总结

生产者、消费者，是一道高频的面试题，非常高频，也非常考验水平。

如果按照上面的套路去作答，无论是美团，还是华为，或者其他的大厂面试官，都会对你献上膝盖。

如果面试过程中，遇到什么问题，可以来《技术自由圈》社群交流。

#### 作者介绍：

本文 1 作： 唐欢，资深架构师，《Java 高并发核心编程加强版》作者之 1 。

本文 2 作： 尼恩， 40 岁资深老架构师，《Java 高并发核心编程加强版卷 1 、卷 2 、卷 3 》创世作者，
著名博主。《K 8 S 学习圣经》《Docker 学习圣经》等 11 个 PDF 圣经的作者。



## Disruptor 相关的面试题

尼恩再给大家来几道相关的面试题

###### 什么是 Disruptor？它有哪些特点？

Disruptor 是一个高性能的无锁并发框架，用于解决在多线程场景下的数据共享和通信问题。它采用了
环形缓冲区（RingBuffer）来存储事件，并通过控制序列（Sequence）来实现线程间的协作。
Disruptor 的特点包括：高性能、低延迟、可扩展、无锁化等。

###### Disruptor 如何实现无锁并发？它的核心原理是什么？

Disruptor 实现无锁并发的核心原理是使用了 CAS（Compare And Swap）算法以及 volatile 变量保证
数据的原子性和可见性。此外，Disruptor 还使用了基于序列的技术来实现线程间的协作。

###### Disruptor 的优缺点是什么？

Disruptor 的优点包括高性能、低延迟、可扩展、无锁化等。
缺点包括学习成本较高、应用场景相对局限等。

###### Disruptor 中的 RingBuffer 是什么？有哪些作用？

RingBuffer 是 Disruptor 中的核心组件之一，它是一个环形的缓冲区，用于存储事件。RingBuffer 的
作用包括存储数据、实现高并发以及提供线程间的协作。


###### Disruptor 中的 Sequence 是什么？有哪些作用？

Sequence 是 Disruptor 中的另一个核心组件，它是一个单调递增的序列，用于控制事件的发布和消
费。Sequence 的作用包括控制事件的发布和消费、实现线程间的协作等。

###### Disruptor 中的 EventProcessor 是什么？有哪些作用？

EventProcessor 是 Disruptor 中的一个概念，它主要负责处理事件，并将事件从 RingBuffer 中取出来
进行处理。EventProcessor 的作用包括实现事件的处理、实现线程间的协作等。

###### Disruptor 中的 WaitStrategy 是什么？有哪些类型？

WaitStrategy 是 Disruptor 中用于实现线程间协作的策略之一，它主要决定了消费者在没有可用事件时
如何等待。Disruptor 提供了多种 WaitStrategy，包括 BlockingWaitStrategy、
BusySpinWaitStrategy、LiteBlockingWaitStrategy 等。

###### Disruptor 的多生产者模型和多消费者模型分别是什么？如何实现？

Disruptor 支持多生产者和多消费者模型。多生产者模型指的是多个生产者往 RingBuffer 中写入数据，
多消费者模型指的是多个消费者从 RingBuffer 中读取数据。实现多生产者和多消费者模型需要使用不
同的序列来控制并发操作。

###### Disruptor 如何保证数据的顺序性？

Disruptor 通过使用控制序列（Sequence）来实现数据的顺序性。在生产者往 RingBuffer 中写入数据

时，会更新生产者的序列；在消费者从 RingBuffer 中读取数据时，会更新消费者的序列。通过对序列
的控制，可以保证事件的顺序性。

###### Disruptor 如何保证数据的可见性？

Disruptor 使用 volatile 变量和 CAS 算法来保证数据的可见性。

在生产者往 RingBuffer 中写入数据时，会使用 volatile 变量来确保数据的可见性；在消费者从
RingBuffer 中读取数据时，会使用 CAS 算法来保证对序列的原子性和可见性，从而保证数据的可见
性。

###### Disruptor 的实现原理是什么？

Disruptor 实现原理主要包括以下几个方面：

```
使用环形缓冲区（RingBuffer）存储事件
使用控制序列（Sequence）控制事件的发布和消费
使用多生产者和多消费者模型提高并发性能
使用无锁算法保证线程安全等。
```
###### Disruptor 与传统的线程池有什么区别？

Disruptor 和传统的线程池相比，具有更高的并发性能和更低的延迟。

这是因为 Disruptor 使用了 **无锁算法和基于序列的技术** 来实现数据共享和通信，避免了线程间的互斥和
同步操作，从而提高了并发性能，并且由于没有线程切换的开销，也可以降低延迟。

###### Disruptor 如何处理异常？

Disruptor 中的异常处理需要由应用程序自己实现。


一般来说，可以在 EventProcessor 中捕获异常，并进行相应的处理。如果不进行处理，异常可能会导
致整个系统崩溃。

###### 聊聊：Disruptor 适用于哪些场景？

Disruptor 适用于需要高性能、低延迟、大规模并发、对数据顺序有要求等场景，例如高频交易系统、
大规模数据处理系统、实时消息系统等。

###### 聊聊：Disruptor 如何进行性能测试？

Disruptor 的性能测试可以使用 JMH（Java Microbenchmark Harness）框架进行。

常见的性能测试包括吞吐量测试、延迟测试、竞争测试等。

**题外话：JMH 是什么？**

**JMH** ：即（Java Microbenchmark Harness），它是由 Java 官方团队开发的一款用于 Java 微基准测试
工具。

基准测试：是指通过设计科学的测试方法、测试工具和测试系统，实现对一类测试对象的某项性能指标
进行定量的和可对比的测试。

比如鲁大师、安兔兔，都是按一定的基准或者在特定条件下去测试某一对象的的性能，比如显卡、IO、
CPU 之类的。

```
JMH 官网：http://openjdk.java.net/projects/code-tools/jmh
```
**JMH 和 JMeter 的不同？**

JMeter 更多的是对 rest api 进行压测，而 JMH 关注的粒度更细，它更多的是发现某块性能槽点代码，
然后对优化方案进行基准测试对比。比如 json 序列化方案对比，bean copy 方案对比等。

###### 聊聊：Disruptor 如何保证线程安全？

Disruptor 使用了无锁算法和基于序列的技术来保证线程安全。

具体而言，它使用 CAS 算法和 volatile 变量来保证数据的原子性和可见性，使用控制序列来实现线程间
的协作，避免了线程间的互斥和同步操作，从而保证线程安全。

###### 聊聊：Disruptor 中的 Sequence Barrier 是什么？有哪些作用？

Sequence Barrier 是 Disruptor 中用于实现线程间协作的组件之一，它主要负责控制消费者的读取进
度，并阻塞消费者直到事件可用。

Sequence Barrier 的作用包括实现线程间的协作、控制消费者的读取进度、提高并发性能等。

###### 聊聊：Disruptor 中的 BatchEventProcessor 是什么？有哪些作

###### 用？

BatchEventProcessor 是 Disruptor 中的一个概念，它是一个高性能的事件处理器，可以批量地处理事
件。

BatchEventProcessor 的作用包括实现事件的处理、实现线程间的协作等。


###### 聊聊：Disruptor 如何解决数据竞争问题？

Disruptor 使用无锁算法和基于序列的技术来避免数据竞争问题。

具体而言，它使用 CAS 算法和 volatile 变量来保证数据的原子性和可见性，使用控制序列来实现线程间
的协作，从而避免了线程间的互斥和同步操作，避免了数据竞争问题。

###### 聊聊：Disruptor 中的 EventTranslator 是什么？有哪些作用？

EventTranslator 是 Disruptor 中实现事件发布的一种方式，它可以将用户定义的数据转换为 Disruptor
需要的事件格式，并发布到 RingBuffer 中。

EventTranslator 的作用包括简化事件发布的流程、提高代码的可读性等，同时还可以提高性能，因为
它可以避免在生产者线程和 RingBuffer 之间进行对象复制的操作。

通过 EventTranslator，用户可以自定义事件，并将其发布到 RingBuffer 中，让消费者线程进行处理。

###### 聊聊：Disruptor 如何处理高并发场景下的竞争问题？

Disruptor 通过使用 RingBuffer 的多个序号来实现消费者和生产者之间的解耦。

RingBuffer 的每个序号都对应着一个槽位，生产者将事件发布到槽位中，并更新序号。

消费者根据各自的需要获取槽位中的事件，并更新对应的序号。

这种方式避免了生产者和消费者之间的竞争，从而提高了系统性能。

###### 聊聊：Disruptor 中的 TimeoutBlockingWaitStrategy 是什么？

###### 有哪些作用？

TimeoutBlockingWaitStrategy 是一种等待策略，它会在一定的时间内进行等待，并且在超时后抛出异
常。

这种等待策略可以在需要限制等待时间的场景中使用，例如在生产者线程向 RingBuffer 发布事件时，
限制等待时间可以保证生产者不会一直阻塞在 RingBuffer 上，从而避免系统出现死锁等问题。

###### 聊聊：Disruptor 如何实现有界队列？

Disruptor 使用 RingBuffer 来实现有界队列，RingBuffer 的容量就是队列的大小。

当 RingBuffer 的可用空间被填满后，新的事件将无法继续发布，从而实现了对队列大小的控制。

###### 聊聊：Disruptor 在实际项目中的应用有哪些经验？

Disruptor 主要用于解决高性能的并发编程问题，例如在金融领域的交易系统、广告系统中的实时数据
处理等场景。

在实际应用中，需要根据具体的业务需求来选择相应的策略和配置参数。

###### 聊聊：Disruptor 的性能瓶颈在哪里？如何避免？

Disruptor 的性能瓶颈主要在于 RingBuffer 的读写操作和事件处理器的逻辑处理。

为了避免性能瓶颈，可以使用合适的等待策略、线程池大小和事件处理器数量等策略，并且尽可能避免
在事件处理器中进行复杂的计算或者 IO 操作。

###### 聊聊：Disruptor 和 Kafka 中的消息队列相比有哪些异同？

Disruptor 和 Kafka 都是高性能的消息队列，但是它们的设计目标和应用场景有所不同。


Disruptor 的设计目标是提供一个非常快速、可预测的内存消息传递机制，用于实现高性能的并发编
程。

而 Kafka 的设计目标是建立一个高可靠、可扩展、持久化的分布式消息队列，用于实现大规模数据的流
式处理。

###### 聊聊：Disruptor 是否适用于分布式系统？

Disruptor 是一种本地内存消息传递机制，不适用于分布式系统。

如果需要在分布式环境中使用 Disruptor，可以考虑使用类似于 Kafka 的分布式消息队列来代替。

###### 聊聊：Disruptor 是否适用于对数据一致性要求较高的场景？

Disruptor 是一种内存模型，在单个 JVM 中提供了高效且可预测的消息传递机制，因此适用于对数据一
致性要求较高的场景。

但是，如果需要实现跨进程或者跨机器的高一致性需求，需要考虑使用分布式锁等更为复杂的机制。

###### 聊聊：Disruptor 是否适用于内存受限的场景？

Disruptor 在内存使用上比较高效，但如果在内存受限的场景下，需要根据具体情况进行评估。

Disruptor 的内存消耗主要来自于 RingBuffer 和事件对象本身，可以通过减小 RingBuffer 大小和优化
事件对象等方式来降低内存消耗。

同时，也可以考虑使用压缩算法等方式来减小事件对象的大小。因此，在内存受限的场景下，需要结合
具体的业务需求和系统限制来进行评估。

###### 聊聊：Disruptor 是否适用于长时间阻塞的场景？

Disruptor 不适用于长时间阻塞的场景。

Disruptor 的设计初衷是为了解决高并发、低延迟的场景，即在处理速度和吞吐量方面具有优势。

在 Disruptor 中，生产者和消费者之间通过环形缓冲区进行数据交换，但如果某个消费者在处理某个事
件时出现了长时间阻塞，则会影响其他消费者的处理效率，降低整个系统的性能。

如果需要处理长时间阻塞的任务，可以考虑使用线程池等方式来解决。

同时，也可以对 Disruptor 进行扩展，实现类似于超时机制的功能，当某个消费者的处理时间超过一定
阈值时，自动放弃该事件的处理，避免长时间阻塞对整个系统的影响。

## 网易一面：如何设计线程池？请手写一个简单

## 线程池？

#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，最近有小伙伴拿到了一线互联网企业如极兔、有赞、希
音、百度、网易的面试资格，遇到一几个很重要的面试题：


```
如何设计线程池？
```
与之类似的、其他小伙伴遇到过的问题还有：

```
请手写一个简单线程池？
```
这个问题，很多小伙伴在社群里边反馈，都遇到过

**线程池的知识，既是面试的核心知识，又是开发的核心知识。**

所以，这里尼恩给大家做一下系统化、体系化的线程池梳理，使得大家可以充分展示一下大家雄厚的
“技术肌肉”， **让面试官爱到 “不能自已、口水直流”** 。

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 62 版本，供后面的小伙伴参考，
提升大家的 3 高架构、设计、开发水平。


```
注：本文以 PDF 持续更新，最新尼恩架构笔记、面试题的 PDF 文件，请从公众号 【技术自由
圈】获取。
```
#### 为什么要使用线程池？

多线程编程是在开发过程中非常基础且非常重要的一个环节，基本上任何一家软件公司或者项目中都会
使用多线程。主要有三个原因：

```
1. 降低资源的消耗。降低线程创建和销毁的资源消耗。
2. 提高响应速度：线程的创建时间为 T 1，执行时间 T 2，销毁时间 T 3，免去 T 1 和 T 3 的时间
3. 提高线程的可管理性
```
总之：线程池是一种常用的并发编程工具，它可以帮助我们更好地管理和复用线程资源，提高程序的性
能和稳定性。

线程池也是 3 高架构的基础技术。

#### JAVA 中的线程池组件

在 Java 中，我们可以使用 java. util. concurrent 包中提供的 ThreadPoolExecutor 类来创建和使用线程池。

ThreadPoolExecutor 是非常高频，非常常用的组件。

对于 ThreadPoolExecutor 的底层原理和源码，大家要做到非常深入的掌握。大家一定要深入看
ThreadPoolExecutor 线程池源码，了解其执行过程。

另外，看懂线程池执行流程和源码设计有助于提升我们多线程编程技术和解决工作中遇到的问题。

#### 手写线程池的重要性

很多小伙伴给尼恩反馈，说线程池的 **源码太难，看不懂** 。

怎么办呢？

大家可以先易后难。

可以手撸一个简单版的线程池加强一下对执行流程的理解。然后再深入源码去历险记。

或者说，如果我们想要更好地理解线程池的工作原理，那么自己动手实现一个简单的线程池是一个很好
的选择。

接下来，我将带领大家一步一步地实现一个简单的线程池。

我们将从最基本的功能开始，逐步添加更多的功能和优化，最终实现一个完整的线程池。

#### 线程池的实现原理

线程池是一个典型的生产者-消费者模型。下图所示为线程池的实现原理：

```
调用方不断向线程池中提交任务； （生产者）
```

```
线程池中有一组线程，不断地从队列中取任务，（消费者）
线程池管理一个任务队列，对异步任务进行缓冲 （缓冲区）
```
**要实现一个线程池，有几个问题需要考虑：**

```
1. 队列设置多长？
如果是无界的，调用方不断往队列中方任务，可能导致内存耗尽。如果是有界的，当队列满了之
后，调用方如何处理？
2. 线程池中的线程个数是固定的，还是动态变化的？
3. 每次提交新任务，是放入队列？还是开新线程
4. 当没有任务的时候，线程是睡眠一小段时间？还是进入阻塞？如果进入阻塞，如何唤醒？
```
**针对问题 4 ，有 3 种做法：**

```
1. 不使用阻塞队列，只使用一般的线程安全的队列，也无阻塞/唤醒机制。
当队列为空时，线程池中的线程只能睡眠一会儿，然后醒来去看队列中有没有新任务到来，如此不
断轮询。
2. 不使用阻塞队列，但在队列外部，线程池内部实现了阻塞/唤醒机制
3. 使用阻塞队列
```
很显然，做法 3 最完善，既避免了线程池内部自己实现阻塞/唤醒机制的麻烦，也避免了做法 1 的睡眠/轮
询带来的资源消耗和延迟。

现在来带大家手写一个简单的线程池，让大家更加理解线程池的工作原理

#### 手写一个简单线程池

###### 第一步：定义线程池接口

首先，我们需要定义一个线程池接口，用来表示线程池应该具备哪些功能。

一个简单的线程池应该至少具备以下几个功能：


```
添加任务并执行
关闭线程池
强制关闭线程池
```
因此，我们可以定义一个 ThreadPool 接口，它包含三个方法：execute、shutdown 和
shutdownNow。

其中：

```
execute 方法用来添加任务并执行；
shutdown 方法用来关闭线程池，它会等待已经提交到线程池中的任务都执行完毕后再关闭；
shutdownNow 方法用来强制关闭线程池，它会立即停止所有正在执行或等待执行的任务，并返回
未执行的任务列表。
```
###### 第二步：实现线程的池化管理

接下来，我们需要实现一个简单的线程池类，它实现了 ThreadPool 接口，并提供了基本的功能。

为了简化代码，先实现一个 v 1 版本，这是一个基础版本，一个简单的实现示例。

在 v 1 版本中，我们先不考虑拒绝策略、自动调节线程资源等高级功能。

下面是一个简单的实现示例：

**首先定义一个工作线程类：**

```
import java. util. List;
```
```
// 线程池接口
public interface ThreadPool {
```
```
// 提交任务到线程池
void execute (Runnable task);
```
```
// 优雅关闭
void shutdown ();
```
```
//立即关闭
List<Runnable> shutdownNow ();
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
```
```
// 定义一个工作线程类
public class WorkerThread extends Thread {
// 用于从任务队列中取出并执行任务
private BlockingQueue<Runnable> taskQueue;
```
```
// 构造方法，传入任务队列
public WorkerThread (BlockingQueue<Runnable> taskQueue) {
this. taskQueue = taskQueue;
}
```
```
// 重写 run 方法
@Override
public void run () {
// 循环执行，直到线程被中断
while (! Thread.currentThread (). isInterrupted () &&
!taskQueue.isEmpty ()) {
try {
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
```
```
16
```

然后, 基于一个线程池接口，实现一个简单的线程池,

```
// 从任务队列中取出一个任务，如果队列为空，则阻塞等待
Runnable task = taskQueue.take ();
// 执行任务
task.run ();
} catch (Exception e) {
e.printStackTrace ();
// 如果线程被中断，则退出循环
break;
}
}
}
}
```
```
17
18
19
20
21
22
23
24
25
26
27
28
```
```
// 简单的线程池实现
public class SimpleThreadPool implements ThreadPool {
// 线程池初始化时的线程数量
private int initialSize;
// 任务队列
private BlockingQueue<Runnable> taskQueue;
// 用于存放和管理工作线程的集合
private List<WorkerThread> threads;
// 是否已经被 shutdown 标志
private volatile boolean isShutdown = false;
```
```
public SimpleThreadPool (int initialSize) {
this. initialSize = initialSize;
taskQueue = new LinkedBlockingQueue<>();
threads = new ArrayList<>(initialSize);
// 初始化方法，创建一定数量的工作线程，并启动它们
for (int i = 0 ; i < initialSize; i++) {
WorkerThread workerThread = new WorkerThread (taskQueue);
workerThread.start ();
threads.add (workerThread);
}
}
```
```
// 实现 execute 方法，用于将任务加入到任务队列，并通知工作线程来执行
@Override
public void execute (Runnable task) {
if (isShutdown) {
throw new IllegalStateException ("ThreadPool is shutdown");
}
taskQueue.offer (task);
}
```
```
// 关闭线程池, 等待所有线程执行完毕
@Override
public void shutdown () {
// 修改状态
isShutdown = true;
for (WorkerThread thread : threads) {
// 中断线程
thread.interrupt ();
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
```

这个版本的线程池实现了基本的添加任务并执行、关闭线程池和强制关闭线程池等功能。

它在构造方法中接收一个初始化线程池大小参数，用于初始化任务队列和工作线程集合，并创建一定数
量的工作线程。

###### 第三步：自定义线程池的基本参数

在上一步中，我们实现了一个简单的线程池，它具备了基本的功能。

但是，它存在一个问题：任务队列没有指定容量大小，是个无界队列，其次只指定了初始的线程池大
小，应该要提供根据不同的应用场景来调整线程池的大小参数，以提高性能和资源利用率。

因此线程池实现类需要实现自定义初始大小、最大大小以及核心大小的功能。

```
初始大小是指线程池初始化时创建的工作线程数量
最大大小是指线程池能够容纳的最多的工作线程数量
核心大小是指线程池在没有任务时保持存活的工作线程数量。
```
这三个参数需要在基本的线程池实现类中定义为成员变量，并在构造方法中传入并赋值。

同时，还需要在 execute 方法中根据这三个参数来动态地调整工作线程的数量，例如：

```
当活跃的工作线程数量小于核心大小时，尝试创建并启动一个新的工作线程来执行任务；
当活跃的工作线程数量大于等于核心大小时，将任务加入到任务队列，等待空闲的工作线程来执
行；
当任务队列已满时，尝试创建并启动一个新的工作线程来执行任务，
当活跃的工作线程数量达到最大大小时，无法再创建新的工作线程。
```
我们还需要在构造方法里提供一个参数 **queueSize** ，用于限制队列大小。

下面我们就对类进行改造：

```
@Override
public List<Runnable> shutdownNow () {
// 修改状态
isShutdown = true;
// 清空队列
List<Runnable> remainingTasks = new ArrayList<>();
taskQueue.drainTo (remainingTasks);
```
```
// 中断所有线程
for (WorkerThread thread : threads) {
thread.interrupt ();
}
// 返回未执行任务集合
return remainingTasks;
}
}
```
```
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
```
```
import java. util. ArrayList;
import java. util. List;
import java. util. concurrent. BlockingQueue;
import java. util. concurrent. LinkedBlockingQueue;
import java. util. concurrent. TimeUnit;
```
```
public class SimpleThreadPool implements ThreadPool {
```
```
1 2 3 4 5 6 7
```

```
// 线程池初始化时的线程数量
private int initialSize;
// 线程池最大线程数量
private int maxSize;
// 线程池核心线程数量
private int coreSize;
// 队列大小
private int queueSize;
// 任务队列
private BlockingQueue<Runnable> taskQueue;
// 用于存放和管理工作线程的集合
private List<WorkerThread> threads;
// 是否已经被 shutdown 标志
private volatile boolean isShutdown = false;
```
```
public SimpleThreadPool (int initialSize, int maxSize, int coreSiz, int
queueSizee) {
// 初始化参数
this. initialSize = initialSize;
this. maxSize = maxSize;
this. coreSize = coreSize;
taskQueue = new LinkedBlockingQueue<>(queueSize);
threads = new ArrayList<>(initialSize);
```
```
// 初始化方法，创建一定数量的工作线程，并启动它们
for (int i = 0 ; i < initialSize; i++) {
WorkerThread workerThread = new WorkerThread ();
workerThread.start (taskQueue);
threads.add (workerThread);
}
}
```
```
@Override
public void execute (Runnable task) {
if (isShutdown) {
throw new IllegalStateException ("ThreadPool is shutdown");
}
// 当线程数量小于核心线程数时，创建新的线程
if (threads.size () < coreSize) {
addWorkerThread (task);
} else if (! taskQueue.offer (task)) {
// 当队列已满时，且线程数量小于最大线程数量时，创建新的线程
if (threads.size () < maxSize) {
addWorkerThread (task);
} else {
throw new IllegalStateException ("执行任务失败");
}
}
}
```
```
// 创建新的线程，并执行任务
private void addWorkerThread (Runnable task) {
WorkerThread workerThread = new WorkerThread ();
workerThread.start (taskQueue);
threads.add (workerThread);
// 任务放入队列
taskQueue.offer (task);
```
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23

24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64


这一步，我们在 **SimpleThreadPool** 里新增了 **initialSize** ， **maxSize** ， **coreSize** 三个变量，在构造方
法里传入对应三个参数，同时在 **execute** 方法里，当有任务进入时，先判断当前线程池数量是否满足不
同条件，进而执行不同的处理逻辑。

###### 第四步：设计饱和拒绝策略

这个功能是为了处理当任务队列已满且无法再创建新的工作线程时，也是就线程池的工作量饱和时，如
何处理被拒绝的任务。

不同的场景可能需要不同的拒绝策略，例如

```
直接抛出异常
忽略任务
阻塞当前线程
等等
```
为了让用户可以自定义拒绝策略，需要

```
1. 定义一个拒绝策略接口，声明一个方法，用于处理被拒绝的任务。
2. 然后需要在基本的线程池实现类中定义一个拒绝策略成员变量，并在构造方法中传入并赋值。
3. 最后，在 execute 方法中，在无法创建新的工作线程时，调用拒绝策略来处理该任务。
```
下面是一个简单的实现示例，

我们首先定义了一个 **RejectedExecutionHandler** 接口，用来表示拒绝策略。用户可以根据需要实现这
个接口，并在构造线程池时传入自己的拒绝策略。

我们再实现一个直接抛出异常的拒绝策略

我们也可以实现一个丢弃策略：

```
}
```
```
////省略其它代码
```
```
}
```
```
65
66
67
68
69
```
```
public interface RejectedExecutionHandler {
// 参数：r 代表被拒绝的任务，executor 代表线程池对象
void rejectedExecution (Runnable r, ThreadPool executor);
}
```
```
1
2
3
4
```
```
// 直接抛出异常的拒绝策略
public class AbortPolicy implements RejectedExecutionHandler {
public void rejectedExecution (Runnable r, ThreadPool executor) {
throw new RuntimeException ("The thread pool is full and the task
queue is full.");
}
}
```
```
1 2 3 4 5 6
```

接下来，我们再优化 **SimpleThreadPool** 类，

```
// 忽略任务的拒绝策略
public class DiscardPolicy implements RejectedExecutionHandler {
public void rejectedExecution (Runnable r, ThreadPool executor) {
// do nothing
System.out.println ("Task rejected: " + r);
}
}
```
```
1 2 3 4 5 6 7
```
```
public class SimpleThreadPool implements ThreadPool {
// 线程池初始化时的线程数量
private int initialSize;
// 线程池最大线程数量
private int maxSize;
// 线程池核心线程数量
private int coreSize;
// 队列大小
private int queueSize;
// 任务队列
private BlockingQueue<Runnable> taskQueue;
// 用于存放和管理工作线程的集合
private List<WorkerThread> threads;
// 是否已经被 shutdown 标志
private volatile boolean isShutdown = false;
// 默认的拒绝策略
private final static RejectedExecutionHandler DEFAULT_REJECT_HANDLER =
new AbortPolicy ();
// 拒绝策略成员变量
private final RejectedExecutionHandler rejectHandler;
```
```
public SimpleThreadPool (int initialSize, int maxSize, int coreSize, int
queueSize) {
this (initialSize, maxSize, coreSize, queueSize,
DEFAULT_REJECT_HANDLER);
}
```
```
public SimpleThreadPool (int initialSize, int maxSize, int coreSize ,
int queueSize, RejectedExecutionHandler rejectHandler) {
System.out.printf ("初始化线程池: initialSize: %d, maxSize: %d,
coreSize: %d%n", initialSize, maxSize, coreSize);
// 初始化参数
this. initialSize = initialSize;
this. maxSize = maxSize;
this. coreSize = coreSize;
taskQueue = new LinkedBlockingQueue<>(queueSize);
threads = new ArrayList<>(initialSize);
this. rejectHandler = rejectHandler;
```
```
// 初始化方法，创建一定数量的工作线程，并启动它们
for (int i = 0 ; i < initialSize; i++) {
WorkerThread workerThread = new WorkerThread (taskQueue);
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
```
```
18
19
20
21
22
```
```
23
```
```
24
25
26
```
```
27
```
```
28
29
30
31
32
33
34
35
36
37
38
```

这个版本的线程池在构造方法中新增了一个 handler 参数，用来表示拒绝策略。当任务队列已满时，它
会调用 handler 的 rejectedExecution 方法来处理被拒绝的任务。

###### 第五步：性能优化之：自动调节线程资源

到目前为止，我们已经实现了一个简单但功能完备的线程池。

**但是，它还有很多可以优化和扩展的地方。**

例如，可以添加自动调节线程资源的功能，为啥需要自动调节线程资源呢？

**因为线程资源，是非常昂贵的。**

自动调节线程资源功能是为了让线程池可以根据任务的变化，动态地增加或减少工作线程的数量，以提
高性能和资源利用率。

为了实现这个功能，需要在基本的线程池实现类中定义一个空闲时长成员变量，并在构造方法中传入并
赋值。

空闲时长是指当工作线程没有任务执行时，可以保持存活的时间。

如果超过这个时间还没有新的任务，那么工作线程就会自动退出。

同时，还需要在工作线程类中定义一个空闲开始时间成员变量，并在 run 方法中更新它。

空闲开始时间是指当工作线程从任务队列中取出一个任务后，上一次取出任务的时间。

如果当前时间减去空闲开始时间大于空闲时长，那么工作线程就会自动退出。

```
workerThread.start ();
threads.add (workerThread);
}
}
```
```
@Override
public void execute (Runnable task) {
System.out.printf ("添加任务: %s%n", task.toString ());
if (isShutdown) {
throw new IllegalStateException ("ThreadPool is shutdown");
}
// 当线程数量小于核心线程数时，创建新的线程
if (threads.size () < coreSize) {
addWorkerThread (task);
System.out.printf ("创建新的线程: thread count: %d, number of
queues: %d%n", threads.size (), taskQueue.size ());
} else if (! taskQueue.offer (task)) {
// 当队列已满时，且线程数量小于最大线程数量时，创建新的线程
if (threads.size () < maxSize) {
addWorkerThread (task);
System.out.printf ("创建新的线程: thread count: %d, number of
queues: %d%n", threads.size (), taskQueue.size ());
} else {
//使用拒绝策略
rejectHandler.rejectedExecution (task, this);
}
}
}
// 省略其它代码
}
```
```
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53
```
```
54
55
56
57
58
```
```
59
60
61
62
63
64
65
66
```

ok，那么我们继续改进线程池,

然后改造工作线程 **WorkerThread** ：

```
public class SimpleThreadPool implements ThreadPool {
// 省略其它代码
// 线程空闲时长
private long keepAliveTime;
```
```
public SimpleThreadPool (int initialSize, int maxSize, int coreSize, int
queueSize, long keepAliveTime) {
this (initialSize, maxSize, coreSize, queueSize, keepAliveTime,
DEFAULT_REJECT_HANDLER);
}
```
```
public SimpleThreadPool (int initialSize, int maxSize, int coreSize, int
queueSize, long keepAliveTime, RejectedExecutionHandler rejectHandler) {
System.out.printf ("初始化线程池: initialSize: %d, maxSize: %d,
coreSize: %d%n", initialSize, maxSize, coreSize);
// 初始化参数
this. initialSize = initialSize;
this. maxSize = maxSize;
this. coreSize = coreSize;
taskQueue = new LinkedBlockingQueue<>(queueSize);
threads = new ArrayList<>(initialSize);
this. rejectHandler = rejectHandler;
this. keepAliveTime = keepAliveTime;
// 初始化方法，创建一定数量的工作线程，并启动它们
for (int i = 0 ; i < initialSize; i++) {
// 传入相关参数到工作线程
WorkerThread workerThread = new WorkerThread (keepAliveTime,
taskQueue, threads);
workerThread.start ();
threads.add (workerThread);
}
}
```
```
// 省略其它代码
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
```
```
11
```
```
12
13
14
15
16
17
18
19
20
21
22
23
```
```
24
25
26
27
28
29
30
```
```
// 定义一个工作线程类
public class WorkerThread extends Thread {
private List<WorkerThread> threads;
// 空闲时长
private long keepAliveTime;
// 用于从任务队列中取出并执行任务
private BlockingQueue<Runnable> taskQueue;
// 构造方法，传入任务队列
public WorkerThread (long keepAliveTime, BlockingQueue<Runnable>
taskQueue, List<WorkerThread> threads) {
this. keepAliveTime = keepAliveTime;
this. taskQueue = taskQueue;
this. threads = threads;
}
```
```
// 重写 run 方法
@Override
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
```

在 **WorkerThread** 类 **run** 方法里，采用 taskQueue. poll 方法指定等待时长，这里是 **线程退出的关键。**

如果超时未获取到任务，则表明当前线程长时间未处理任务，可以正常退出，并从线程池里移除该线
程。

#### 手写一个简单线程池的完整代码

下面，我们给出完整的所有代码：

拒绝策略相关类：

```
public void run () {
long lastActiveTime = System.currentTimeMillis ();
// 循环执行，直到线程被中断
Runnable task;
while (! Thread.currentThread (). isInterrupted () &&
!taskQueue.isEmpty ()) {
try {
// 从任务队列中取出一个任务，如果队列为空，则阻塞等待
task = taskQueue.poll (keepAliveTime,
TimeUnit. MILLISECONDS);
if (task != null) {
task.run ();
System.out.printf ("WorkerThread %d, current task:
%s%n", Thread.currentThread (). getId (), task.toString ());
```
```
lastActiveTime = System.currentTimeMillis ();
} else if (System.currentTimeMillis () - lastActiveTime >=
keepAliveTime) {
// 从线程池中移除
threads.remove (this);
System.out.printf ("WorkerThread %d exit %n",
Thread.currentThread (). getId ());
break;
}
} catch (Exception e) {
// 从线程池中移除
threads.remove (this);
e.printStackTrace ();
// 如果线程被中断，则退出循环
break;
}
}
}
}
```
```
17
18
19
20
21
```
```
22
23
24
```
```
25
26
27
```
```
28
29
30
```
```
31
32
33
```
```
34
35
36
37
38
39
40
41
42
43
44
45
```
```
// 拒绝策略接口
public interface RejectedExecutionHandler {
// 参数：r 代表被拒绝的任务，executor 代表线程池对象
void rejectedExecution (Runnable r, ThreadPool executor);
}
```
```
1 2 3 4 5 6
```

为了通过输出日志，清晰的展现线程池中任务的运行流程，新增了 **RunnableWrapper** 用于记录
taskId，方便日志监控。

线程池接口

工作线程类：

```
// 忽略任务的拒绝策略
public class DiscardPolicy implements RejectedExecutionHandler {
public void rejectedExecution (Runnable r, ThreadPool executor) {
// do nothing
RunnableWrapper wrapper = (RunnableWrapper) r;
System.out.println ("Task rejected: " + wrapper.getTaskId ());
}
}
```
```
7
8
9
10
11
12
13
14
```
```
public class RunnableWrapper implements Runnable{
private final Integer taskId;
```
```
public RunnableWrapper (Integer taskId) {
this. taskId = taskId;
}
```
```
public Integer getTaskId () {
return this. taskId;
}
```
```
@Override
public void run () {
System.out.println ("Task " + taskId + " is running.");
try {
Thread.sleep ( 100 );
} catch (Exception e) {
e.printStackTrace ();
// ignore
}
System.out.println ("Task " + taskId + " is completed.");
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
```
```
// 线程池接口
public interface ThreadPool {
```
```
// 提交任务到线程池
void execute (Runnable task);
```
```
// 优雅关闭
void shutdown ();
```
```
//立即关闭
List<Runnable> shutdownNow ();
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
```
```
// 定义一个工作线程类
public class WorkerThread extends Thread {
```
```
1
2
```

简单线程池实现类

```
private List<WorkerThread> threads;
// 空闲时长
private long keepAliveTime;
// 用于从任务队列中取出并执行任务
private BlockingQueue<Runnable> taskQueue;
```
```
// 构造方法，传入任务队列
public WorkerThread (long keepAliveTime, BlockingQueue<Runnable>
taskQueue, List<WorkerThread> threads) {
this. keepAliveTime = keepAliveTime;
this. taskQueue = taskQueue;
this. threads = threads;
}
```
```
// 重写 run 方法
@Override
public void run () {
long lastActiveTime = System.currentTimeMillis ();
// 循环执行，直到线程被中断
Runnable task;
while (! Thread.currentThread (). isInterrupted () ||
!taskQueue.isEmpty ()) {
try {
// 从任务队列中取出一个任务，如果队列为空，则阻塞等待
task = taskQueue.poll (keepAliveTime,
TimeUnit. MILLISECONDS);
RunnableWrapper wrapper = (RunnableWrapper) task;
if (task != null) {
System.out.printf ("WorkerThread %s, poll current task:
%s%n", Thread.currentThread (). getName (), wrapper.getTaskId ());
task.run ();
lastActiveTime = System.currentTimeMillis ();
} else if (System.currentTimeMillis () - lastActiveTime >=
keepAliveTime) {
// 从线程池中移除
threads.remove (this);
System.out.printf ("WorkerThread %s exit %n",
Thread.currentThread (). getName ());
break;
}
} catch (Exception e) {
// 从线程池中移除
System.out.printf ("WorkerThread %s occur exception%n",
Thread.currentThread (). getName ());
threads.remove (this);
e.printStackTrace ();
// 如果线程被中断，则退出循环
break;
}
}
}
}
```
```
3 4 5 6 7 8 9
```
```
10
```
```
11
12
13
14
15
16
17
18
19
20
21
22
```
```
23
24
25
```
```
26
27
28
```
```
29
30
31
```
```
32
33
34
```
```
35
36
37
38
39
```
```
40
41
42
43
44
45
46
47
```
```
public class SimpleThreadPool implements ThreadPool {
// 线程池初始化时的线程数量
```
```
1
2
```

```
private int initialSize;
// 线程池最大线程数量
private int maxSize;
// 线程池核心线程数量
private int coreSize;
// 任务队列
private BlockingQueue<Runnable> taskQueue;
// 用于存放和管理工作线程的集合
private List<WorkerThread> threads;
// 是否已经被 shutdown 标志
private volatile boolean isShutdown = false;
// 默认的拒绝策略
private final static RejectedExecutionHandler DEFAULT_REJECT_HANDLER =
new AbortPolicy ();
// 拒绝策略成员变量
private final RejectedExecutionHandler rejectHandler;
// 线程空闲时长
private long keepAliveTime;
```
```
public SimpleThreadPool (int initialSize, int maxSize, int coreSize,
int queueSize, long keepAliveTime) {
this (initialSize, maxSize, coreSize, queueSize, keepAliveTime,
DEFAULT_REJECT_HANDLER);
}
```
```
public SimpleThreadPool (int initialSize, int maxSize, int coreSize,
int queueSize, long keepAliveTime, RejectedExecutionHandler rejectHandler)
{
System.out.printf ("初始化线程池: initialSize: %d, maxSize: %d,
coreSize: %d%n", initialSize, maxSize, coreSize);
// 初始化参数
this. initialSize = initialSize;
this. maxSize = maxSize;
this. coreSize = coreSize;
taskQueue = new LinkedBlockingQueue<>(queueSize);
threads = new ArrayList<>(initialSize);
this. rejectHandler = rejectHandler;
this. keepAliveTime = keepAliveTime;
// 初始化方法，创建一定数量的工作线程，并启动它们
for (int i = 0 ; i < initialSize; i++) {
WorkerThread workerThread = new WorkerThread (keepAliveTime,
taskQueue, threads);
workerThread.start ();
threads.add (workerThread);
}
}
```
```
@Override
public void execute (Runnable task) {
if (isShutdown) {
throw new IllegalStateException ("ThreadPool is shutdown");
}
RunnableWrapper wrapper = (RunnableWrapper) task;
System.out.printf ("put task: %s %n" , wrapper.getTaskId ());
```
```
// 当线程数量小于核心线程数时，创建新的线程
if (threads.size () < coreSize) {
addWorkerThread (task);
```
```
3 4 5 6 7 8 9
```
10
11
12
13
14
15

16
17
18
19
20
21

22

23
24
25

26

27
28
29
30
31
32
33
34
35
36
37

38
39
40
41
42
43
44
45
46
47
48
49
50
51
52
53


```
System.out.printf ("小于核心线程数，创建新的线程: thread count: %d,
queue remainingCapacity : %d%n", threads.size (),
taskQueue.remainingCapacity ());
} else if (! taskQueue.offer (task)) {
// 当队列已满时，且线程数量小于最大线程数量时，创建新的线程
if (threads.size () < maxSize) {
addWorkerThread (task);
System.out.printf ("队列已满, 创建新的线程: thread count: %d,
queue remainingCapacity : %d%n", threads.size (),
taskQueue.remainingCapacity ());
} else {
rejectHandler.rejectedExecution (task, this);
}
} else {
System.out.printf ("任务放入队列: thread count: %d, queue
remainingCapacity : %d%n", threads.size (), taskQueue.remainingCapacity ());
}
}
```
```
// 创建新的线程，并执行任务
private void addWorkerThread (Runnable task) {
WorkerThread workerThread = new WorkerThread (keepAliveTime,
taskQueue, threads);
workerThread.start ();
threads.add (workerThread);
// 任务放入队列
try {
taskQueue.put (task);
} catch (InterruptedException e) {
throw new RuntimeException (e);
}
}
```
```
// 关闭线程池, 等待所有线程执行完毕
@Override
public void shutdown () {
System.out.printf ("shutdown thread, count: %d, queue
remainingCapacity : %d%n", threads.size (), taskQueue.remainingCapacity ());
// 修改状态
isShutdown = true;
for (WorkerThread thread : threads) {
// 中断线程
thread.interrupt ();
}
}
```
```
@Override
public List<Runnable> shutdownNow () {
System.out.printf ("shutdown thread now, count: %d, queue
remainingCapacity : %d%n", threads.size (), taskQueue.remainingCapacity ());
```
```
// 修改状态
isShutdown = true;
// 清空队列
List<Runnable> remainingTasks = new ArrayList<>();
taskQueue.drainTo (remainingTasks);
```
```
54
```
```
55
56
57
58
59
```
```
60
61
62
63
64
```
```
65
66
67
68
69
70
71
```
```
72
73
74
75
76
77
78
79
80
81
82
83
84
85
86
```
```
87
88
89
90
91
92
93
94
95
96
97
```
98
99
100
101
102
103


#### 第六步：验证线程池

接下来，我们编写一个测试用例来验证我们的线程池是否能正常运行。

最后，我们编写了一个测试用例 **SimpleThreadPoolTest** ，

这个测试用例创建了一个拥有 1 个初始线程、最多 4 个线程、核心线程数为 2 、队列长度为 3 ，空闲线程保
留时间为 2000 毫秒的线程池。

它使用了一个简单的拒绝策略，当任务被拒绝时，它会打印一条消息。

然后，测试用例向线程池中提交了 10 个简单的任务，每个任务都会打印一条消息，然后睡眠 100 毫秒，
再打印一条消息。

最后，测试用例调用了 shutdown 方法来关闭线程池。

当我们运行这个测试用例时，会看到类似下面的输出：

```
// 中断所有线程
for (WorkerThread thread : threads) {
thread.interrupt ();
}
// 返回未执行任务集合
return remainingTasks;
}
}
```
```
104
105
106
107
108
109
110
111
112
```
```
// 定义一个测试用例类
public class SimpleThreadPoolTest {
public static void main (String[] args) throws InterruptedException {
SimpleThreadPool threadPool = new SimpleThreadPool ( 1 , 4 , 2 , 3 ,
2000 , new DiscardPolicy ());
for (int i = 0 ; i < 10 ; i++) {
threadPool.execute (new RunnableWrapper (i));
}
Thread.sleep (10_000);
threadPool.shutdown ();
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
```
```
初始化线程池: initialSize: 1, maxSize: 4, coreSize: 2
put task: 0
小于核心线程数，创建新的线程: thread count: 2, queue remainingCapacity : 2
put task: 1
WorkerThread Thread-1, poll current task: 0
WorkerThread Thread-0, poll current task: 1
Task 1 is running.
```
```
1 2 3 4 5 6 7
```

从输出中可以看出，线程池中最多有 4 个线程在同时运行。当有空闲线程时，新提交的任务会被立即执
行；否则，新提交的任务会被添加到任务队列中等待执行。

ok，到了这里，大家能够帮助大家更好地理解上文中实现的简单线程池。

接下来，大家可以去进一步技术深入，去研究线程池的源码了。

#### 实操总结

通过实操，我们一步一步地实现了一个简单的线程池。

我们从最基本的功能开始，逐步添加了拒绝策略、自动调节线程资源等高级功能，并对线程池进行了优
化。

```
任务放入队列: thread count: 2, queue remainingCapacity : 2
put task: 2
Task 0 is running.
任务放入队列: thread count: 2, queue remainingCapacity : 2
put task: 3
任务放入队列: thread count: 2, queue remainingCapacity : 1
put task: 4
任务放入队列: thread count: 2, queue remainingCapacity : 0
put task: 5
WorkerThread Thread-2, poll current task: 2
Task 2 is running.
队列已满, 创建新的线程: thread count: 3, queue remainingCapacity : 0
put task: 6
WorkerThread Thread-3, poll current task: 3
Task 3 is running.
队列已满, 创建新的线程: thread count: 4, queue remainingCapacity : 0
put task: 7
Task rejected: 7
put task: 8
Task rejected: 8
put task: 9
Task rejected: 9
Task 2 is completed.
Task 1 is completed.
WorkerThread Thread-2, poll current task: 4
Task 4 is running.
Task 0 is completed.
Task 3 is completed.
WorkerThread Thread-1, poll current task: 6
WorkerThread Thread-0, poll current task: 5
Task 6 is running.
Task 5 is running.
Task 5 is completed.
Task 6 is completed.
Task 4 is completed.
WorkerThread Thread-3 exit
WorkerThread Thread-1 exit
WorkerThread Thread-0 exit
WorkerThread Thread-2 exit
shutdown thread, count: 0, queue remainingCapacity : 3
```
```
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
```

通过这个过程，我们可以更好地理解线程池的工作原理和实现细节。

当然，这只是一个简单的示例，实际应用中的线程池可能会更加复杂和强大。与 Java 标准库中提供的线
程池相比，仍然存在一些不足之处。例如：

```
没有提供足够的构造参数和方法，让用户可以更好地控制和监控线程池的行为。
没有提供足够多的拒绝策略，让用户可以根据不同的场景选择不同的拒绝策略。
没有提供定时任务和周期性任务的执行功能。
没有提供足够完善的错误处理机制。
```
Java 标准库中提供的线程池实现（如 ThreadPoolExecutor 类），则在这些方面都做得更好。

它提供了丰富的构造参数和方法，让用户可以更好地控制和监控线程池的行为；

它提供了多种拒绝策略，让用户可以根据不同的场景选择不同的拒绝策略；

它还提供了 ScheduledThreadPoolExecutor 类，用来执行定时任务和周期性任务；

它还提供了完善的错误处理机制，可以帮助用户更好地处理异常情况。

如果你想要深入了解 Java 标准库中提供的线程池实现，可以参考以下清华大学出版社，所出版的尼恩
Java 高并发三部曲之二《Java 高并发核心编程卷 2 加强版》。

## 美团一面：Spring Cloud 如何构建动态线程

## 池？

#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，最近有小伙伴拿到了一线互联网企业如美团、极兔、有
赞、希音、百度、网易、滴滴的面试资格，遇到一几个很重要的面试题：

```
(1) Spring Cloud 如何构建动态线程池？
```
```
(2 ) 生产场景中，应该如何动态调整线程池的核心参数？
```
```
等等等等......
```
线程池、动态线程池，是面试的重点和高频点。

尼恩作为技术中台、数据中台的架构师，致力于为大家研究出一个 3 高架构知识宇宙，所以，这里，带
大家完成一个 Spring Cloud 如何构建动态线程池架构分析和实操。

当然，作为一篇文章，仅仅是抛砖引玉，后面有机会，带大家做一下这个高质量的实操，并且指导大家
写入简历。

**让面试官爱到 “不能自已、口水直流”** 。

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 66 版本，供后面的小伙伴参考，
提升大家的 3 高架构、设计、开发水平。


```
注：本文以 PDF 持续更新，最新尼恩架构笔记、面试题的 PDF 文件，请从公众号 【技术自由
圈】获取。
```
#### 业务场景分析

流量洪峰是互联网生产环境经常遇到的场景，例如某个时间点进行商品抢购活动，或者某个时间点集中
触发定时任务，这些场景都有可能引发流量洪峰，所以如何应对流量洪峰是我们必须面对的问题。

纵向维度我们可以从代理层、WEB 层、服务层、缓存层、数据层进行思考，横向维度我们可以从高频检
测、缓存前置、节点冗余、服务降级等方向进行思考。本文我们从服务层动态调节线程数这个角度进行
思考。

动态线程池是指我们可以根据流量的不同调节线程池某些参数，例如可以在业务低峰期调低线程数，在
业务高峰期调高线程数增加处理线程从而应对流量洪峰。

本文我们结合 SpringCloud 应用，彻底介绍如何构建一个动态线程池。

#### 为啥需要动态线程池？

线程池是 Java 并发编程中的一个重要工具，它可以有效地管理和复用线程，提高系统的性能和吞吐量。

但是，如果线程池的配置和使用不当，也会带来一些严重的问题，比如内存溢出、CPU 过载、响应延
迟、服务不可用等。

这些问题往往在生产环境中才会暴露出来，给系统带来巨大的风险和损失。

那么你是否想要更好地管理和监控你的线程池状态和性能？

你是否想要动态地调整你的线程池参数，而不需要重启你的应用？

你是否想要及时地收到你的线程池异常或风险的告警通知？

如果你的答案是肯定的，那么本文将教你如何在 SpirngCloud 微服务框架下，使用 Nacos、

```
Prometheus 和 Grafana 这三个强大的组件，来实现自定义线程池的指标暴露、动态参数调整、指标采
```
集和可视化监控、以及报警功能。

通过本文，你将学习到：

```
如何使用 Nacos 注册中心来存储和管理你的线程池参数，并实现动态刷新
如何使用 Micrometer 来创建和管理你的线程池指标，并将它们导出到 Prometheus 格式
如何使用 Prometheus 来从你的应用中拉取指标数据，并存储在它自己的时间序列数据库中
如何使用 Grafana 来从 Prometheus 中获取指标数据，并创建美观和实用的仪表盘，来展示你的指
标数据
如何使用 Prometheus 或 Grafana 的报警功能，为你的指标数据设置告警规则和通知渠道，当指
标达到某些条件时，及时收到告警通知，例如钉钉、邮件等。如果线程池出现问题或者完成修改
后，能够基于监控的信息，进行通知和告警。这样就需要考虑通知和告警的方式的多样性：比如基
于钉钉、微信、飞书、电子邮件等渠道进行通知和告警。
```
本文将为你提供详细的步骤和代码，让你可以轻松地跟随操作，并实现自己的线程池监控和管理系统。

###### 线程池监控和参数动态化的好处？


我们需要对线程池进行监控，来了解线程池的运行状态和性能指标，及时发现和解决问题，优化线程池
的配置和使用。

监控线程池有以下几个好处：

```
可以观察线程池的核心参数
比如核心线程数、最大线程数、队列容量、活跃线程数、任务数量等，判断线程池是否合理配置和
充分利用。
可以分析线程池的运行情况
比如任务执行时间、任务等待时间、任务拒绝率、任务失败率等，评估线程池的性能和稳定性。
可以设置线程池的预警机制
比如当线程池达到一定的阈值或发生异常时，及时通知相关人员，采取相应的措施，避免系统崩溃
或影响用户体验。
动态地调整你的线程池参数，而不需要重启你的应用
```
###### 如何获取线程池的一些指标数据？

要监控线程池的状态和性能，我们需要获取线程池的一些指标数据。

```
ThreadPoolExecutor 类提供了一些方法来获取这些数据，比如：
```
```
核心线程数：getCorePoolSize ()
最大线程数：getMaximumPoolSize ()
阻塞队列：getQueue ()，可以通过它获取队列长度、元素个数等信息
工作线程数：getPoolSize ()，包括核心线程和非核心线程
活跃线程数：getActiveCount ()，也就是正在执行任务的线程
最大工作线程数：getLargestPoolSize ()，也就是线程池曾经到过的最大值
任务数量：getTaskCount ()，包括历史已完成和正在执行的任务
```
除了这些方法，ThreadPoolExecutor 类还有一些钩子方法，它们没有具体的实现，但是我们可以重写

它们来获取更多的数据，比如：

```
beforeExecute：在 Worker 线程执行任务之前会调用的方法，我们可以在这里记录任务开始执行
的时间
afterExecute：在 Worker 线程执行任务之后会调用的方法，我们可以在这里计算任务执行的耗
时，并根据耗时计算最大耗时、最小耗时、平均耗时等
terminated：当线程池从状态变更到 TERMINATED 状态之前调用的方法，我们可以在这里做一些
清理或者统计工作
```
通过这些方法，我们就可以获取线程池的各种指标数据，为监控线程池提供基础。

#### SpringCloud 线程池监控管理方案

那么，如何实现线程池的监控呢？

我们可以采用以下几个步骤：

```
第一步，扩展 ThreadPoolExecutor 类，重写 beforeExecute、afterExecute 和 terminated
方法，获取更多的指标信息，比如最短执行时间、最长执行时间、平均执行耗时等。
```

```
第二步，结合 Nacos 注册中心实现线程池核心参数动态变更、实时生效。
第三步，使用 Spring Boot 提供的 Actuator 自定义一个 Endpoint 来发布线程池的指标数据，这样我
们就可以通过 HTTP 请求来获取线程池的监控信息。
第四步，使用一些开源组件来采集、存储、展示和预警线程池的指标数据，比如 Prometheus、
Grafana 和 AlertManager。这些组件可以帮助我们实现可视化的监控界面和灵活的预警策略。
```
接下来，我们根据以上步骤说明，一步步的实现一个完善的线程池监控管理方案。

#### 第一步：扩展线程池，获取线程池指标数据

首先，我们在 springboot 项目配置文件（例如：application. yml）里，新增以下示例配置，用于

后续根据该配置动态生成线程池。

根据以上配置，我们再编写对应的配置类，来读取配置文件里声明的线程池属性，代码如下：

```
monitor:
thread:
executors[0]:
thread-pool-name: first-monitor-thread-pool
core-pool-size: 4
max-pool-size: 8
queue-capacity: 1000
keep-alive-time: 1000
executors[1]:
thread-pool-name: second-monitor-thread-pool
core-pool-size: 2
max-pool-size: 4
queue-capacity: 2000
keep-alive-time: 2000
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
```
```
/**
* 获取线程池配置属性
*/
@ConfigurationProperties (prefix = "monitor. thread")
@Data
@Component
public class ThreadPoolConfigProperties {
private List<ThreadPoolProperties> executors = new ArrayList<>();
}
```
```
/**
* 线程池的核心属性声明。
*/
@Data
@NoArgsConstructor
@AllArgsConstructor
public class ThreadPoolProperties {
/**
* 线程池名称
*/
private String threadPoolName;
```
```
/**
* 核心线程数，默认为 Runtime.getRuntime (). availableProcessors ()
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
```

然后，我们需要扩展 ThreadPoolExecutor 类，重写 beforeExecute、afterExecute 和

```
terminated 方法，获取更多的指标信息，比如最短执行时间、最长执行时间、平均执行耗时等。
```
扩展关键点：

```
1. 在构造线程池的时候，在构造方法里传入线程池名称 poolName, 该名称可用做线程池里线程名称
前缀，方便日志跟踪。
2. 在 beforeExecute 方法里，通过 ThreadLocal 对象记录当前线程任务执行前的开始时间戳，用
于后续计算线程任务执行耗时。
3. 在 afterExecute 方法里，计算当前线程执行耗时，累加总耗时，并计算平均耗时、最大耗时、最
小耗时。
4. 在线程池生命明周期相关方法里，打印线程池相关指标信息，提供公共方法暴露指标信息。
5. 实现自定义线程工厂，在创建新的线程时，以线程池名称 poolName 为前缀拼接创建线程序号为线
程命名。
```
```
*/
private Integer corePoolSize =
Runtime.getRuntime (). availableProcessors ();
```
```
/**
* 最大线程数，默认为 Runtime.getRuntime (). availableProcessors ()* 2
*/
private Integer maxPoolSize =
Runtime.getRuntime (). availableProcessors () * 2 ;
```
```
/**
* 队列最大数量
*/
private Integer queueCapacity;
```
```
/**
* 空闲线程存活时间
*/
private Long keepAliveTime = 1 L;
```
```
/**
* 空闲线程存活时间单位
*/
private TimeUnit unit = TimeUnit. MILLISECONDS;
}
```
```
25
26
```
```
27
28
29
30
31
```
```
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
```
```
/**
* 线程池监控类
* <p>
* 计算线程执行每个任务处理的耗时，以及平均耗时、最大耗时、最小耗时，以及输出监控日志信息
等等
*/
public class MonitorThreadPool extends ThreadPoolExecutor {
private static final Logger LOGGER =
LoggerFactory.getLogger (MonitorThreadPool. class);
```
```
/**
* 默认拒绝策略
*/
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
```

```
private static final RejectedExecutionHandler DEFAULT_HANDLER = new
AbortPolicy ();
```
```
/**
* 线程池名称，一般以业务名称命名，方便区分
*/
private final String poolName;
```
```
/**
* 最短执行时间
*/
private Long minCostTime = 0 L;
```
```
/**
* 最长执行时间
*/
private Long maxCostTime = 0 L;
/**
* 总的耗时
*/
private AtomicLong totalCostTime = new AtomicLong ();
/**
* 用于暂存任务执行起始时间戳
*/
private ThreadLocal<Long> startTimeThreadLocal = new ThreadLocal<>();
```
```
/**
* 初始化
*/
public MonitorThreadPool (int corePoolSize, int maximumPoolSize, long
keepAliveTime, TimeUnit unit, BlockingQueue<Runnable> workQueue, String
poolName) {
super (corePoolSize, maximumPoolSize, keepAliveTime, unit,
workQueue, new MonitorThreadFactory (poolName), DEFAULT_HANDLER);
this. poolName = poolName;
}
```
```
/**
* 线程池延迟关闭时（等待线程池里的任务都执行完毕），统计线程池情况
*/
@Override
public void shutdown () {
// 统计已执行任务、正在执行任务、未执行任务数量
LOGGER.info ("{} 关闭线程池，已执行任务: {}, 正在执行任务: {}, 未执行任务
数量: {}",
this. poolName, this.getCompletedTaskCount (),
this.getActiveCount (), this.getQueue (). size ());
super.shutdown ();
}
```
```
/**
* 线程池立即关闭时，统计线程池情况
*/
@Override
public List<Runnable> shutdownNow () {
// 统计已执行任务、正在执行任务、未执行任务数量
LOGGER.info ("{} 立即关闭线程池，已执行任务: {}, 正在执行任务: {}, 未执行任
务数量: {}",
```
12

13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40

41

42
43
44
45
46
47
48
49
50
51

52

53
54
55
56
57
58
59
60
61
62


```
this. poolName, this.getCompletedTaskCount (),
this.getActiveCount (), this.getQueue (). size ());
return super.shutdownNow ();
}
```
```
/**
* 任务执行之前，记录任务开始时间
*/
@Override
protected void beforeExecute (Thread t, Runnable r) {
//记录任务开始时间
startTimeThreadLocal.set (System.currentTimeMillis ());
super.beforeExecute (t, r);
}
```
```
/**
* 任务执行之后，计算任务结束时间
*/
@Override
protected void afterExecute (Runnable r, Throwable t) {
// 当前任务耗时
long costTime = System.currentTimeMillis () -
startTimeThreadLocal.get ();
startTimeThreadLocal.remove ();
// 更新最大耗时时长
maxCostTime = maxCostTime > costTime? maxCostTime : costTime;
if (getCompletedTaskCount () == 0 ) {
minCostTime = costTime;
}
// 更新最小耗时时长
minCostTime = minCostTime < costTime? minCostTime : costTime;
// 统计总耗时
totalCostTime.addAndGet (costTime);
LOGGER.info ("{}-monitor: " +
"任务耗时: {} ms, 初始线程数: {}, 核心线程数: {}, 执行的
任务数量: {}, " +
"已完成任务数量: {}, 任务总数: {}, 队列里缓存的任务数量:
{}, 池中存在的最大线程数: {}, " +
"最大允许的线程数: {}, 线程空闲时间: {}, 线程池是否关闭:
{}, 线程池是否终止: {}",
this. poolName,
costTime, this.getPoolSize (), this.getCorePoolSize (),
this.getActiveCount (),
this.getCompletedTaskCount (), this.getTaskCount (),
this.getQueue (). size (), this.getLargestPoolSize (),
this.getMaximumPoolSize (),
this.getKeepAliveTime (TimeUnit. MILLISECONDS), this.isShutdown (),
this.isTerminated ());
super.afterExecute (r, t);
}
```
```
// 获取最小耗时时长
public Long getMinCostTime () {
return minCostTime;
}
```
```
// 获取最大耗时时长
public Long getMaxCostTime () {
```
```
63
```
```
64
65
66
67
68
69
70
71
72
73
74
75
76
77
78
79
80
81
82
83
```
```
84
85
86
87
88
89
90
91
92
93
94
95
```
```
96
```
```
97
```
```
98
99
```
100

101

102
103
104
105
106
107
108
109
110
111


最后我们实现线程池管理功能，

```
return maxCostTime;
}
```
```
// 计算平均耗时时长
public long getAverageCostTime () {
if (getCompletedTaskCount () == 0 || totalCostTime.get () == 0 ) {
return 0 ;
}
// 总完成耗时除以总完成任务数
return totalCostTime.get () / getCompletedTaskCount ();
}
```
```
/**
* 生成线程池所用的线程，改写了线程池默认的线程工厂，传入线程池名称，便于问题追踪
*/
static class MonitorThreadFactory implements ThreadFactory {
private static final AtomicInteger POOL_NUMBER = new
AtomicInteger ( 1 );
private final ThreadGroup group;
private final AtomicInteger threadNumber = new AtomicInteger ( 1 );
private final String namePrefix;
```
```
/**
* 初始化线程工厂
*
* @param poolName 线程池名称
*/
MonitorThreadFactory (String poolName) {
SecurityManager s = System.getSecurityManager ();
group = Objects.nonNull (s)? s.getThreadGroup () :
Thread.currentThread (). getThreadGroup ();
namePrefix = poolName + "-" + POOL_NUMBER.getAndIncrement () +
"-thread-";
}
```
```
/**
* 新增线程
* @param r a runnable to be executed by new thread instance
* @return
*/
@Override
public Thread newThread (Runnable r) {
Thread t = new Thread (group, r, namePrefix +
THREAD_NUMBER.getAndIncrement (), 0 );
if (t.isDaemon ()) {
t.setDaemon (false);
}
if (t.getPriority () != Thread. NORM_PRIORITY) {
t.setPriority (Thread. NORM_PRIORITY);
}
return t;
}
}
}
```
```
112
113
114
115
116
117
118
119
120
121
122
123
124
125
126
127
128
```
```
129
130
131
132
133
134
135
136
137
138
139
140
```
```
141
```
```
142
143
144
145
146
147
148
149
150
151
```
```
152
153
154
155
156
157
158
159
160
161
```

```
1. 通过 ThreadPoolConfigProperties 读取线程池配置信息，然后根据这些信息，生成对应的
MonitorThreadPool 线程池对象。
2. 通过线程池名称 poolName, 提供对应线程池实例。
```
```
/**
* 线程池管理上下文
*/
@Component
@Slf 4 j
public class ThreadPoolManager {
@Autowired
private ThreadPoolConfigProperties threadPoolConfigProperties;
/**
* 存储线程池对象
*/
public Map<String, MonitorThreadPool> threadPoolExecutorMap = new
HashMap<>();
```
```
/**
* 根据配置信息，初始化线程池
*/
@PostConstruct
public void init () {
createThreadPools (threadPoolConfigProperties);
}
```
```
/**
* 初始化线程池的创建
*
* @param threadPoolConfigProperties
*/
private void createThreadPools (ThreadPoolConfigProperties
threadPoolConfigProperties) {
threadPoolConfigProperties.getExecutors (). forEach (config -> {
if
(! threadPoolExecutorMap.containsKey (config.getThreadPoolName ())) {
MonitorThreadPool threadPoolMonitor = new
MonitorThreadPool (
config.getCorePoolSize (),
config.getMaxPoolSize (),
config.getKeepAliveTime (),
config.getUnit (),
new LinkedBlockingQueue<Runnable>
(config.getQueueCapacity ()),
config.getThreadPoolName ()
);
threadPoolExecutorMap.put (config.getThreadPoolName (),
threadPoolMonitor);
}
});
}
```
```
// 根据线程池名称，获取对应线程池实例
public MonitorThreadPool getThreadPoolExecutor (String poolName) {
MonitorThreadPool threadPoolExecutorForMonitor =
threadPoolExecutorMap.get (poolName);
if (threadPoolExecutorForMonitor == null) {
```
```
1 2 3 4 5 6 7 8 9
```
10
11
12

13
14
15
16
17
18
19
20
21
22
23
24
25
26
27

28
29

30

31
32
33
34
35

36
37
38
39
40
41
42
43
44
45
46

47


到这里，我们就实现了一个基本的线程池配置和监控功能，

```
1. 可以通过配置文件实例化对应线程池
2. 线程池运行时，会在相关生命周期方法里打印详细的指标信息，供开发人员参考。
```
为了验证上述实现的线程池功能是否满足要求，我们再编写一个测试接口，

该接口用于对每个线程池，提交 100 个任务。

接下来我们看下部分输出结果：

```
throw new RuntimeException ("找不到名字为" + poolName + "的线程池");
}
return threadPoolExecutorForMonitor;
}
```
```
// 获取线程池 Map
public Map<String, MonitorThreadPool> getThreadPoolExecutorMap () {
return threadPoolExecutorMap;
}
```
```
}
```
```
48
49
50
51
52
53
54
55
56
57
58
```
```
/**
* 线程池测试接口
*/
@RestController
@Slf 4 j
public class ThreadPoolController {
@Autowired
private ThreadPoolManager threadPoolManager;
```
```
@GetMapping ("/execute")
public String doExecute () {
threadPoolManager.getThreadPoolExecutorMap (). forEach ((poolName,
monitorThreadPool) -> {
for (int i = 0 ; i < 100 ; i++) {
int taskId = i;
monitorThreadPool.execute (() -> {
try {
log.info ("run task: " + taskId);
Thread.sleep (new Random (). nextInt ( 4000 ));
} catch (InterruptedException e) {
e.printStackTrace ();
}
});
}
});
return "success";
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
```
```
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
```
```
[ user-thread-pool-1-thread-1] LN:? user-thread-pool-monitor: 任务耗时:
2849 ms, 初始线程数: 4 , 核心线程数: 4 , 执行的任务数量: 4 , 已完成任务数量: 92 , 任务总
数: 100 , 队列里缓存的任务数量: 4 , 池中存在的最大线程数: 4 , 最大允许的线程数: 8 , 线程
空闲时间: 1000 , 线程池是否关闭: false, 线程池是否终止: false
[ user-thread-pool-1-thread-1] LN:? run task:96
```
```
1
```
```
2
```

#### 第二步: 动态配置线程池参数

线程池使用面临的核心的问题在于： **线程池的参数并不好配置** 。

一方面线程池的运行机制不是很好理解，配置合理需要强依赖开发人员的个人经验和知识；

另一方面，线程池执行的情况和任务类型相关性较大，IO 密集型和 CPU 密集型的任务运行起来的情况差
异非常大，这导致业界并没有一些成熟的经验策略帮助开发人员参考。

线程池参数设置不合理，比如核心线程数、最大线程数、任务队列容量、空闲线程存活时间等，可能导
致线程池无法有效地处理任务，或者消耗过多的系统资源，甚至引发内存溢出。

那么有没有固定的计算公式，能够让开发人员很简易地计算出某种场景中的线程池应该是什么参数呢？

下图是业界的一些主流线程池参数配置方案：

第 1 类线程数： IO 密集型任务确定线程数

```
[ user-thread-pool-1-thread-4] LN:? user-thread-pool-monitor: 任务耗时:
3407 ms, 初始线程数: 4 , 核心线程数: 4 , 执行的任务数量: 4 , 已完成任务数量: 93 , 任务总
数: 100 , 队列里缓存的任务数量: 3 , 池中存在的最大线程数: 4 , 最大允许的线程数: 8 , 线程
空闲时间: 1000 , 线程池是否关闭: false, 线程池是否终止: false
[ user-thread-pool-1-thread-4] LN:? run task:97
[ order-thread-pool-2-thread-2] LN:? order-thread-pool-monitor: 任务耗时:
2266 ms, 初始线程数: 2 , 核心线程数: 2 , 执行的任务数量: 2 , 已完成任务数量: 52 , 任务总
数: 100 , 队列里缓存的任务数量: 46 , 池中存在的最大线程数: 2 , 最大允许的线程数: 4 , 线程
空闲时间: 2000 , 线程池是否关闭: false, 线程池是否终止: false
[ order-thread-pool-2-thread-2] LN:? run task:54
[ user-thread-pool-1-thread-1] LN:? user-thread-pool-monitor: 任务耗时:
1553 ms, 初始线程数: 4 , 核心线程数: 4 , 执行的任务数量: 4 , 已完成任务数量: 94 , 任务总
数: 100 , 队列里缓存的任务数量: 2 , 池中存在的最大线程数: 4 , 最大允许的线程数: 8 , 线程
空闲时间: 1000 , 线程池是否关闭: false, 线程池是否终止: false
[ user-thread-pool-1-thread-1] LN:? run task:98
[ user-thread-pool-1-thread-3] LN:? user-thread-pool-monitor: 任务耗时:
2396 ms, 初始线程数: 4 , 核心线程数: 4 , 执行的任务数量: 4 , 已完成任务数量: 95 , 任务总
数: 100 , 队列里缓存的任务数量: 1 , 池中存在的最大线程数: 4 , 最大允许的线程数: 8 , 线程
空闲时间: 1000 , 线程池是否关闭: false, 线程池是否终止: false
[ user-thread-pool-1-thread-3] LN:? run task:99
[ user-thread-pool-1-thread-4] LN:? user-thread-pool-monitor: 任务耗时:
2017 ms, 初始线程数: 4 , 核心线程数: 4 , 执行的任务数量: 4 , 已完成任务数量: 96 , 任务总
数: 100 , 队列里缓存的任务数量: 0 , 池中存在的最大线程数: 4 , 最大允许的线程数: 8 , 线程
空闲时间: 1000 , 线程池是否关闭: false, 线程池是否终止: false
[ order-thread-pool-2-thread-1] LN:? order-thread-pool-monitor: 任务耗时:
2713 ms, 初始线程数: 2 , 核心线程数: 2 , 执行的任务数量: 2 , 已完成任务数量: 53 , 任务总
数: 100 , 队列里缓存的任务数量: 45 , 池中存在的最大线程数: 2 , 最大允许的线程数: 4 , 线程
空闲时间: 2000 , 线程池是否关闭: false, 线程池是否终止: false
[ order-thread-pool-2-thread-1] LN:? run task:55
[ user-thread-pool-1-thread-2] LN:? user-thread-pool-monitor: 任务耗时:
3932 ms, 初始线程数: 4 , 核心线程数: 4 , 执行的任务数量: 3 , 已完成任务数量: 97 , 任务总
数: 100 , 队列里缓存的任务数量: 0 , 池中存在的最大线程数: 4 , 最大允许的线程数: 8 , 线程
空闲时间: 1000 , 线程池是否关闭: false, 线程池是否终止: false
[ order-thread-pool-2-thread-1] LN:? order-thread-pool-monitor: 任务耗时:
467 ms, 初始线程数: 2 , 核心线程数: 2 , 执行的任务数量: 2 , 已完成任务数量: 54 , 任务总
数: 100 , 队列里缓存的任务数量: 44 , 池中存在的最大线程数: 2 , 最大允许的线程数: 4 , 线程
空闲时间: 2000 , 线程池是否关闭: false, 线程池是否终止: false
[ order-thread-pool-2-thread-1] LN:? run task:56
```
```
3 4 5 6 7 8 9
```
```
10
11
```
```
12
```
```
13
14
```
```
15
```
```
16
```

第 2 类线程数： CPU 密集型任务确定线程数

第 3 类线程数： 为混合型任务确定线程数

```
以上线程池计算公式。具体请参见清华大学出版社的尼恩《Java 高并发核心编程卷 2 加强版》
PDF。
```
实际上, 大部分的线程都是混合型线程，很难准确的去估算线程等待时间和线程 CPU 时间. 所以，一
种有效的办法是： 根据监控指标，动态的标准线程池的线程数。

**如何实现线程池参数的动态配置和即时生效呢？ 一个有效的方法是将线程池的参数从代码中迁移到分布
式配置中心上。**

动态化线程池的核心设计包括以下三个方面：

```
1. 简化线程池配置：
线程池构造参数有 8 个，但是最核心的是 3 个：corePoolSize、maximumPoolSize，
workQueue，它们决定了线程池的任务分配和线程分配策略。
实际应用中我们获取并发性的场景主要是两种：
（ 1 ）并行执行子任务，提高响应速度。这种情况下，应该使用同步队列，没有任务应该被缓存下
来，而是应该立即执行。
（ 2 ）并行执行大批次任务，提升吞吐量。这种情况下，应该使用有界队列，使用队列去缓冲大批
量的任务，队列容量必须声明，防止任务无限制堆积。
所以线程池只需要提供这三个关键参数的配置，并且提供两种队列的选择，就可以满足绝大多数的
业务需求。
2. 参数可动态修改：
为了解决参数不好配，修改参数成本高等问题。
我们需要封装线程池，让线程池能够监听外部的消息，并根据消息进行修改配置。
需要将线程池的配置放置在平台侧，让开发人员方便地查看、修改线程池配置。
3. 增加线程池监控 ：
没有状态观测就没有改进依据。
我们在线程池执行任务的生命周期添加了监控能力，帮助开发同学了解线程池状态。
```
以上这三个方面，我们先实现前两个方面的功能设计，在后续的步骤中我们再实现第三个方面功能。

具体的实现步骤如下：

```
1 CPU 核心数两倍的线程
```
```
1 线程数量应当等于 CPU 的核心数
```
```
1 最佳线程数目 =（线程等待时间与线程 CPU 时间之比 + 1）* CPU 核数
```

1 使用配置中台进行参数的集中化管理

将线程池属性配置从本地配置文件迁移到 Nacos 注册中心。

2 让 nacos 的配置动态生效

ThreadPoolConfigProperties 类加上@RefreshScope 注解, 用于在 nacos`上修改配置后，实时同步到

系统对象。

3 修改线程池的参数

ThreadPoolManager 监听 EnvironmentChangeEvent 事件，通过 ThreadPoolConfigProperties`实例

修改对应线程池属性。

###### 1 使用配置中台 nacos 进行参数的集中化管理

```
Nacos 配置示例如下图所示：
```
###### 2 让 nacos 的配置动态生效

ThreadPoolConfigProperties 类加上@RefreshScope 注解, 用于在 nacos 上修改配置后，实时同步到

系统对象。


修改了 ThreadPoolConfigProperties 后，接下来，springboot 会触发与之相关的
EnvironmentChangeEvent 环境变化事件。

**EnvironmentChangeEvent 事件** ：环境变化事件。

```
接收到此事件表示应用里的配置数据已经发生改变。
```
```
EnvironmentChangeEvent 事件里维护着一个配置项 keys 集合，当配置动态修改后，配置值
发生变化后的 key 会设置到事件的 keys 集合中。
```
ThreadPoolManager 监听 EnvironmentChangeEvent 事件，通过 ThreadPoolConfigProperties 实
例修改对应线程池属性。

###### 3 修改线程池的参数

这里我们在 changeThreadPools 方法里，只修改了线程池的 corePoolSize, maximumPoolSize,

```
keepAliveTime 三个属性。因为线程池核心类 ThreadPoolExecutor 支持动态修改这三个属性。
```
```
@RefreshScope
public class ThreadPoolConfigProperties
```
```
1
2
```
```
/**
* 调整线程池
*
* @param threadPoolConfigProperties
*/
private void changeThreadPools (ThreadPoolConfigProperties
threadPoolConfigProperties) {
threadPoolConfigProperties.getExecutors (). forEach (config -> {
ThreadPoolExecutor threadPoolExecutor =
threadPoolExecutorMap.get (config.getThreadPoolName ());
if (Objects.nonNull (threadPoolExecutor)) {
```
```
threadPoolExecutor.setCorePoolSize (config.getCorePoolSize ());
```
```
threadPoolExecutor.setMaximumPoolSize (config.getMaxPoolSize ());
```
```
threadPoolExecutor.setKeepAliveTime (config.getKeepAliveTime (),
config.getUnit ());
}
});
}
```
```
/**
* 监听事件
*/
@EventListener
public void envListener (EnvironmentChangeEvent event) {
log.info ("配置发生变更" + event);
changeThreadPools (threadPoolConfigProperties);
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
```
```
11
```
```
12
```
```
13
14
15
16
17
18
19
20
21
22
23
24
```

以 setCorePoolSize 方法为例，该方法用于设置线程的核心数。该方法将覆盖构造函数中设置的任何

值。

如果新值小于当前值，则多余的现有线程将在下次空闲时终止。

如果更大，如果需要，将启动新线程以执行任何排队的任务。

**麻烦的问题是：线程池核心类** ThreadPoolExecutor **不支持修改队列容量大小。所以，queue-
capacity 不好修改。**

至于为啥不支持修改队列容量大小，因为 BlockingQueue 接口相关实现类都不支持动态修改容量大

小。

以 ArrayBlockingQueue 和 LinkedBlockingQueue 为例，ArrayBlockingQueue 底层是数组，大小固

定。

而 LinkedBlockingQueue 的 capacity 则被 final 修饰，不可修改。

如果我们想基于 ArrayBlockingQueue 进行改造，但修改大小必然要涉及到重新创建数组，以及新旧数

组的数据迁移问题，有些复杂。

如果考虑基于 LinkedBlockingQueue 进行改造，我们只要将修饰 capacity 的 final 去掉即可实现动

态调整。

但有一个问题，LinkedBlockingQueue 具体实现中很多是基于 capacity 不变进行的设计，需要将涉及

的功能进行调整。

对该功能感兴趣的同学可以参考 elasticsearch 官方提供的 ResizableBlockingQueue 队列。

该队列支持通过 adjustCapacity 方法动态修改队列容量。

```
1 private final int capacity;
```
```
package org. elasticsearch. common. util. concurrent;
```
```
import java. util. concurrent. BlockingQueue;
```
```
/**
* Extends the {@code SizeBlockingQueue} to add the {@code adjustCapacity}
method, which will adjust
* the capacity by a certain amount towards a maximum or minimum.
*/
final class ResizableBlockingQueue<E> extends SizeBlockingQueue<E> {
```
```
private volatile int capacity;
```
```
ResizableBlockingQueue (BlockingQueue<E> queue, int initialCapacity) {
super (queue, initialCapacity);
this. capacity = initialCapacity;
}
```
```
@Override
public int capacity () {
return this. capacity;
}
```
```
@Override
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
```

现在，我们验证下通过 nacos 修改线程池属性后，配置是否实时生效。

项目启动后，修改配置如下：

```
public int remainingCapacity () {
return Math.max (0, this.capacity ());
}
```
```
/** Resize the limit for the queue, returning the new size limit */
public synchronized int adjustCapacity (int optimalCapacity, int
adjustmentAmount, int minCapacity, int maxCapacity) {
assert adjustmentAmount > 0 : "adjustment amount should be a
positive value";
assert optimalCapacity >= 0 : "desired capacity cannot be
negative";
assert minCapacity >= 0 : "cannot have min capacity smaller than
0";
assert maxCapacity >= minCapacity : "cannot have max capacity
smaller than min capacity";
```
```
if (optimalCapacity == capacity) {
// Yahtzee!
return this. capacity;
}
```
```
if (optimalCapacity > capacity + adjustmentAmount) {
// adjust up
final int newCapacity = Math.min (maxCapacity, capacity +
adjustmentAmount);
this. capacity = newCapacity;
return newCapacity;
} else if (optimalCapacity < capacity - adjustmentAmount) {
// adjust down
final int newCapacity = Math.max (minCapacity, capacity -
adjustmentAmount);
this. capacity = newCapacity;
return newCapacity;
} else {
return this. capacity;
}
}
}
```
```
24
25
26
27
28
29
```
```
30
```
```
31
```
```
32
```
```
33
```
```
34
35
36
37
38
39
40
41
42
```
```
43
44
45
46
47
```
```
48
49
50
51
52
53
54
```
```
monitor:
thread:
executors[0]:
thread-pool-name: user-thread-pool
core-pool-size: 6
max-pool-size: 8
queue-capacity: 1000
keep-alive-time: 1000
executors[1]:
thread-pool-name: order-thread-pool
core-pool-size: 3
max-pool-size: 4
queue-capacity: 2000
keep-alive-time: 2000
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
```

在控制台可以看到以下日志：

运行测试接口，部分日志如下：

#### 第三步，监控线程池

目前为止，我们已实现通过日志观察线程运行情况，以及通过和 Nacos 注册中心集合实现动态调整线程
池核心参数功能。

但是作为开发人员，你是否经常遇到这样的问题：

当你的应用出现异常或性能下降时，你需要花费大量的时间和精力去查看日志文件，分析问题的原因和
解决方案。日志文件往往分散在不同的服务器上，不易于集中管理和查询。

日志文件也可能过大或过多，导致磁盘空间不足或内存溢出。

日志文件的格式和内容也可能不统一或不清晰，给你带来阅读和理解的困难。

总之，通过日志进行监控是一种不方便和低效的方式，它会影响你的开发效率和应用质量。

有没有一种更好的方式来监控你的应用呢？答案是肯定的。

```
[ngPolling. fixed-127.0.0.1_8848] c.c.c.n.d.c.thread. ThreadPoolManager
LN:? 配置发生变更
org. springframework. cloud. context. environment. EnvironmentChangeEvent[source=o
rg. springframework. boot. web. servlet. context. AnnotationConfigServletWebServerA
pplicationContext@54534abf , started on Thu May 11 10:38:41 CST 2023, parent:
org.springframework.context.annotation.AnnotationConfigApplicationContext@aa5
49 e 5]
[ngPolling. fixed-127.0.0.1_8848] o.s.c.e.event. RefreshEventListener
LN:? Refresh keys changed: [monitor. thread. executors[1]. core-pool-size,
monitor. thread. executors[0]. core-pool-size]
```
```
1
```
```
2
```
```
[ user-thread-pool-1-thread-1] c.c.c.n.d.c.thread. MonitorThreadPool
LN:? user-thread-pool-monitor: 任务耗时: 2336 ms, 初始线程数: 6, 核心线程数: 6, 执
行的任务数量: 6, 已完成任务数量: 293, 任务总数: 300, 队列里缓存的任务数量: 1, 池中存在
的最大线程数: 6, 最大允许的线程数: 8, 线程空闲时间: 1000, 线程池是否关闭: false, 线程
池是否终止: false
[ user-thread-pool-1-thread-1] c.c.c.n.d.c.ThreadPoolController
LN:? run task:99
[ user-thread-pool-1-thread-6] c.c.c.n.d.c.thread. MonitorThreadPool
LN:? user-thread-pool-monitor: 任务耗时: 2175 ms, 初始线程数: 6, 核心线程数: 6, 执
行的任务数量: 6, 已完成任务数量: 294, 任务总数: 300, 队列里缓存的任务数量: 0, 池中存在
的最大线程数: 6, 最大允许的线程数: 8, 线程空闲时间: 1000, 线程池是否关闭: false, 线程
池是否终止: false
[ order-thread-pool-2-thread-2] c.c.c.n.d.c.thread. MonitorThreadPool
LN:? order-thread-pool-monitor: 任务耗时: 2019 ms, 初始线程数: 3, 核心线程数: 3,
执行的任务数量: 3, 已完成任务数量: 247, 任务总数: 300, 队列里缓存的任务数量: 50, 池中存
在的最大线程数: 3, 最大允许的线程数: 4, 线程空闲时间: 2000, 线程池是否关闭: false, 线
程池是否终止: false
[ order-thread-pool-2-thread-2] c.c.c.n.d.c.ThreadPoolController
LN:? run task:50
[ order-thread-pool-2-thread-3] c.c.c.n.d.c.thread. MonitorThreadPool
LN:? order-thread-pool-monitor: 任务耗时: 3586 ms, 初始线程数: 3, 核心线程数: 3,
执行的任务数量: 3, 已完成任务数量: 248, 任务总数: 300, 队列里缓存的任务数量: 49, 池中存
在的最大线程数: 3, 最大允许的线程数: 4, 线程空闲时间: 2000, 线程池是否关闭: false, 线
程池是否终止: false
```
```
1 2 3 4 5 6
```

Spring Boot Actuator 是 Spring Boot 的一个子项目，它可以为你的应用添加一些生产级的功能，而你只
需要很少的配置。

这些功能包括：

```
Endpoint：这是一些特殊的 URL，可以暴露你的应用的内部信息，例如健康状况、指标、环境变
量、日志等。你可以通过 HTTP 或 JMX 访问这些 Endpoint，或者通过一些工具来可视化地展示这些
信息。
Health：这是一个 Endpoint，可以显示你的应用的健康状况，包括应用本身和它依赖的组件（如
数据库、缓存、消息队列等）的状态。你可以自定义健康指标和细节。
Metrics：这是一个 Endpoint，可以显示你的应用的各种指标，包括内存、CPU、线程、HTTP 请
求等。你可以自定义指标和收集方式。
Auditing：这是一个功能，可以记录你的应用的重要事件，如认证、授权、失败等。你可以自定义
审计事件和存储方式。
Logging：这是一个功能，可以让你在运行时查看和修改你的应用的日志级别。你可以通过
Endpoint 或 JMX 来操作日志。
```
通过 Endpoint，你可以快速地了解你的应用是否正常运行，是否有潜在的问题或风险，以及如何优化你
的应用性能和资源利用率。

首先引入 actuator 依赖

下面我们自定义一个 Endpoint 类，暴露线程池相关指标信息。

```
<!--健康检查-->
<dependency>
<groupId>org. springframework. boot</groupId>
<artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
```
```
1
2
3
4
5
```
```
@Configuration
@Endpoint (id = "thread")
public class ThreadPoolEndpoint {
@Autowired
private ThreadPoolManager threadPoolManager;
```
```
@ReadOperation
public Map<String, Object> threadPoolsMetric () {
Map<String, Object> metricMap = new HashMap<>();
List<Map> threadPools = new ArrayList<>();
threadPoolManager.getThreadPoolExecutorMap (). forEach ((k, v) -> {
MonitorThreadPool tpe = (MonitorThreadPool) v;
Map<String, Object> poolInfo = new HashMap<>();
poolInfo.put ("thread. pool. name", k);
poolInfo.put ("thread. pool. core. size", tpe.getCorePoolSize ());
poolInfo.put ("thread. pool. largest. size",
tpe.getLargestPoolSize ());
poolInfo.put ("thread. pool. max. size", tpe.getMaximumPoolSize ());
poolInfo.put ("thread. pool. thread. count", tpe.getPoolSize ());
poolInfo.put ("thread. pool. max. costTime", tpe.getMaxCostTime ());
poolInfo.put ("thread. pool. average. costTime",
tpe.getAverageCostTime ());
poolInfo.put ("thread. pool. min. costTime", tpe.getMinCostTime ());
poolInfo.put ("thread. pool. active. count", tpe.getActiveCount ());
poolInfo.put ("thread. pool. completed. taskCount",
tpe.getCompletedTaskCount ());
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
```
```
17
18
19
20
```
```
21
22
23
```

在 application. yml 里暴露端口

通过 http 接口： /service-provider-demo/actuator/thread 访问该 endpoint 信息：

```
poolInfo.put ("thread. pool. queue. name",
tpe.getQueue (). getClass (). getName ());
poolInfo.put ("thread. pool. rejected. name",
tpe.getRejectedExecutionHandler (). getClass (). getName ());
poolInfo.put ("thread. pool. task. count", tpe.getTaskCount ());
threadPools.add (poolInfo);
});
metricMap.put ("threadPools", threadPools);
return metricMap;
}
}
```
```
24
```
```
25
```
```
26
27
28
29
30
31
32
```
```
#### 暴露端点
management:
endpoints:
web:
base-path: "/actuator" # 配置 Endpoint 的基础路径
exposure:
include: '*' #在yaml 文件属于关键字，所以需要加引号
```
```
1 2 3 4 5 6 7 {
```
```
"threadPools": [
{
"thread. pool. queue. name":
"java. util. concurrent. LinkedBlockingQueue",
"thread. pool. core. size": 6 ,
"thread. pool. min. costTime": 9 ,
"thread. pool. completed. taskCount": 300 ,
"thread. pool. max. costTime": 7185 ,
"thread. pool. task. count": 300 ,
"thread. pool. name": "user-thread-pool",
"thread. pool. largest. size": 6 ,
"thread. pool. rejected. name":
"java. util. concurrent. ThreadPoolExecutor$AbortPolicy",
"thread. pool. active. count": 0 ,
"thread. pool. thread. count": 6 ,
"thread. pool. average. costTime": 1918 ,
"thread. pool. max. size": 8
},
{
"thread. pool. queue. name":
"java. util. concurrent. LinkedBlockingQueue",
"thread. pool. core. size": 3 ,
"thread. pool. min. costTime": 61 ,
"thread. pool. completed. taskCount": 300 ,
"thread. pool. max. costTime": 3979 ,
"thread. pool. task. count": 300 ,
"thread. pool. name": "order-thread-pool",
"thread. pool. largest. size": 3 ,
"thread. pool. rejected. name":
"java. util. concurrent. ThreadPoolExecutor$AbortPolicy",
"thread. pool. active. count": 0 ,
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
```
```
13
14
15
16
17
18
19
```
```
20
21
22
23
24
25
26
27
```
```
28
```

#### 第四步，接入 Prometheus

Prometheus 是一个开源的监控和告警系统，它可以从应用的 Endpoint 拉取指标数据，并提供查询和可
视化的功能。使用 Prometheus 可以获得以下好处：

```
Prometheus 可以定期从应用的 Endpoint 拉取指标数据，并存储在它自己的时间序列数据库中。这
样就可以在任何时间点查看应用的历史数据，而不仅仅是当前的数据。我们也可以对数据进行聚
合、过滤、计算等操作，以得到更多的洞察。
Prometheus 可以为指标数据设置告警规则，当某些条件满足时，它可以向我们发送通知，例如邮
件、短信、Slack 等。这样，我们就可以及时发现和处理应用的异常或风险，而不需要人工监控。
Prometheus 可以与其他工具集成，例如 Grafana、Alertmanager 等，来提供更丰富的可视化和
告警管理功能。我们可以使用 Grafana 来创建美观和实用的仪表盘，来展示你的指标数据。我们
也可以使用 Alertmanager 来管理和分发你的告警通知。
```
总之，使用 Prometheus，可以更方便和高效地监控和管理我们的应用，提升我们的应用质量和用户满
意度。

```
Grafana 是一个开源的数据可视化和监控平台，它可以从多种数据源（如 Prometheus、InfluxDB、
Elasticsearch 等）获取数据，并创建美观和实用的仪表盘，来展示你的指标数据。
```
除了可视化功能，Grafana 还提供了报警功能，让你可以为你的指标数据设置告警规则，当某些条件满
足时，它可以向你发送通知，例如邮件、短信、Slack 等。

接下来，我们将展示如何将线程池的指标信息上报到 Prometheus, 并通过 Grafana 以图表的形式展示
指标数据。

###### 1. 安装和配置 prometheus 和 Grafana

为了方便演示，我们直接在本机采用 docker 安装，

首先创建相关文件夹, config 为配置文件夹，grafana-storage 用于存储 grafana 数据，prometheus-

data 存储 prometheus 数据，

```
"thread. pool. thread. count": 3 ,
"thread. pool. average. costTime": 1990 ,
"thread. pool. max. size": 4
}
]
}
```
```
29
30
31
32
33
34
```

在 config 文件夹下，新建 prometheus. yml 配置文件：

其中 10.23.48.43:28088 为 service-provider-demo 项目的 ip 和端口。

创建 prometheus. bat：

创建 grafana. bat:

```
global:
scrape_interval: 60 s
evaluation_interval: 60 s
```
```
scrape_configs:
```
- job_name: prometheus
static_configs:
- targets: ['10.23.48.43:9300']
labels:
instance: prometheus
- job_name: springboot
metrics_path: '/service-provider-demo/actuator/prometheus'
scrape_interval: 5 s
static_configs:
- targets: ['10.23.48.43:28088']
labels:
instance: service-provider-demo

```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
```
```
docker run  -d --name=prometheus  -p 9300 : 9090  -v
D:\program\docker\prometheus\config\prometheus. yml:/etc/prometheus/prometheus
.yml -v D:\program\docker\prometheus\prometheus-data:/prometheus
prom/prometheus
```
```
1
```
```
docker run -d -p 9400 : 3000 --name=grafana -v
D:\program\docker\prometheus\grafana-storage:/var/lib/grafana
grafana/grafana
```
```
1
```

分别点击 prometheus. bat 和 grafana. bat 脚本启动 prometheus 和 grafana，下图为启动后，

docker desktop 客户端界面：

下图为 prometheus 管理页面：Prometheus Time Series Collection and Processing Server

下图为 grafana 管理页面：Data sources - Your connections - Connections - Grafana

在 connections 界面，添加本机 Prometheus 数据源


在 Dashboards 界面，选择 JVM 仪表盘, 即可看到，Application 为 service-provider-demo 项目的相关
JVM 指标信息图表：


到这里，我们的环境就配置好了。

###### 2. 收集线程池指标信息

首先，在项目中引入 prometheus 相关依赖：

在 application. yml 文件中设置相关信息：

接下来，需要使用 Micrometer 来创建和管理我们的线程池指标数据。

Micrometer 是一个度量工具库，它提供了一套通用的 API，让项目可以在不同的监控系统中使用相同

的指标。

```
<!--健康检查-->
<dependency>
<groupId>org. springframework. boot</groupId>
<artifactId>spring-boot-starter-actuator</artifactId>
</dependency>
```
```
<dependency>
<groupId>io. micrometer</groupId>
<artifactId>micrometer-registry-prometheus</artifactId>
</dependency>
```
```
1 2 3 4 5 6 7 8 9
```
```
10
```
```
#### 暴露端点
management:
endpoints:
web:
base-path: "/actuator" # 配置 Endpoint 的基础路径
exposure:
include: '*' #在yaml 文件属于关键字，所以需要加引号
endpoint:
health:
show-details: always
metrics:
tags:
application: ${spring. application. name}
export:
prometheus:
enabled: true
step: 20 s
descriptions: true
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
```

我们需要注入一个 MeterRegistry 类型的 bean，它是 Micrometer 的核心接口，负责注册和管理各种

类型的指标。

Micrometer 支持多种类型的指标，例如 Counter（计数器）、Gauge（计量）、Timer（计时器）、
DistributionSummary（分布摘要）等。我们可以根据需求选择合适的类型，并为它们添加名称、标
签和描述。

在这里，我们会注册 4 个指标，分别是

```
1. threadPoolCompletedTaskCount: 已完成任务数, Counter 类型（递增)
2. threadPoolTotalCostTime: 已完成任务总耗时，Counter 类型（递增)
3. threadPoolActiveCount: 当前活跃任务数, Gauge 类型 （根据实际情况变化）
4. taskCostTimeHistogram: 直方图，任务耗时分布， Histogram 类型 （统计不同耗时下的累计任
务数量）
```
以下是用于初始化上述 4 个指标的代码：

```
@Configuration
public class PrometheusComponent implements ApplicationContextAware {
private static PrometheusComponent instance;
/**
* 已完成任务数
*/
private Counter threadPoolCompletedTaskCount;
/**
* 已完成任务总耗时
*/
private Counter threadPoolTotalCostTime;
/**
* 当前活跃任务数
*/
private Gauge threadPoolActiveCount;
/**
* 直方图，任务耗时分布
*/
private Histogram taskCostTimeHistogram;
/**
* 配置 MeterRegistry
* @param applicationName 应用名称
* @return
*/
@Bean
MeterRegistryCustomizer<MeterRegistry>
configurer (@Value ("${spring. application. name}") String applicationName)
{
return (registry) -> registry.config (). commonTags ("application",
applicationName);
}
```
```
/**
* 初始化指标对象
* @param applicationContext
* @throws BeansException
*/
@Override
public void setApplicationContext (ApplicationContext
applicationContext) throws BeansException {
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
```
```
27
```
```
28
29
30
31
32
33
34
35
36
```

改进 MonitorThreadPool 线程池类，在相关方法里添加相关指标设置：

```
instance = this;
CollectorRegistry collectorRegistry =
applicationContext.getBean (CollectorRegistry. class);
// 这里指定 SpringBoot 容器的 CollectorRegistry，如果使用默认的会导致无法收集
// 实例化指标，添加名称、标签和描述，注册到收集器里
threadPoolCompletedTaskCount =
Counter.build (). name ("thread_pool_task_completed_count"). labelNames ("poolNa
me")
.help ("线程池已完成任务数"). register (collectorRegistry);
threadPoolTotalCostTime =
Counter.build (). name ("thread_pool_total_cost_time"). labelNames ("poolName")
.help ("线程池已完成任务总耗时"). register (collectorRegistry);
```
```
threadPoolActiveCount = Gauge.build ()
```
```
.name ("thread_pool_task_active_count"). labelNames ("poolName")
.help ("线程池当前活跃任务数"). register (collectorRegistry);
```
```
taskCostTimeHistogram = Histogram.build (). labelNames ("poolName")
.name ("thread_pool_task_cost_time"). help ("请求耗时分布")
.register (collectorRegistry);
}
```
```
public static PrometheusComponent getInstance () {
return instance;
}
```
```
public Counter threadPoolCompletedTaskCount () {
return threadPoolCompletedTaskCount;
}
```
```
public Counter threadPoolTotalCostTime () {
return threadPoolTotalCostTime;
}
```
```
public Gauge threadPoolActiveCount () {
return threadPoolActiveCount;
}
```
```
public Histogram taskCostTimeHistogram () {
return taskCostTimeHistogram;
}
}
```
```
37
38
```
```
39
40
41
```
```
42
43
```
```
44
45
46
47
```
```
48
49
50
51
52
53
54
55
56
57
58
59
60
61
62
63
64
65
66
67
68
69
70
71
72
73
74
```
```
public class MonitorThreadPool extends ThreadPoolExecutor {
// 用于统计任务耗时, 在任务开始时启动计时，任务结束时关闭计时，获取执行时长
private ThreadLocal<Histogram.Timer> timerThreadLocal = new
ThreadLocal<>();
```
```
//// 省略其它代码
```
```
/**
* 线程池立即关闭时，统计线程池情况
*/
@Override
```
```
1 2 3 4 5 6 7 8 9
```
```
10
```

```
public List<Runnable> shutdownNow () {
// 统计已执行任务、正在执行任务、未执行任务数量
LOGGER.info ("{} 立即关闭线程池，已执行任务: {}, 正在执行任务: {}, 未执行任务
数量: {}",
this. poolName, this.getCompletedTaskCount (),
this.getActiveCount (), this.getQueue (). size ());
// 活跃任务数清零
```
```
PrometheusComponent.getInstance (). threadPoolActiveCount (). labels (this. pool
Name). set ( 0 );
return super.shutdownNow ();
}
```
```
/**
* 任务执行之前，记录任务开始时间
*/
@Override
protected void beforeExecute (Thread t, Runnable r) {
//记录任务开始时间
startTimeThreadLocal.set (System.currentTimeMillis ());
// 活跃任务数 +1
```
```
PrometheusComponent.getInstance (). threadPoolActiveCount (). labels (this. pool
Name). inc ();
// 开始计时
```
```
timerThreadLocal.set (PrometheusComponent.getInstance (). taskCostTimeHistogr
am ()
.labels (this. poolName)
.startTimer ());
super.beforeExecute (t, r);
}
```
```
/**
* 任务执行之后，计算任务结束时间
*/
@Override
protected void afterExecute (Runnable r, Throwable t) {
//// 省略其它代码
// 总耗时增加
```
```
PrometheusComponent.getInstance (). threadPoolTotalCostTime (). labels (this. po
olName). inc ((double) costTime);
// 完成任务数+1
```
```
PrometheusComponent.getInstance (). threadPoolCompletedTaskCount (). labels (th
is. poolName). inc ();
// 活跃任务数-1
```
```
PrometheusComponent.getInstance (). threadPoolActiveCount (). labels (this. pool
Name). dec ();
// 当前任务耗时直方图统计
Histogram. Timer timer = timerThreadLocal.get ();
if (timer != null) {
timer.observeDuration ();
timerThreadLocal.remove ();
}
```
11
12
13

14

15
16

17
18
19
20
21
22
23
24
25
26
27
28

29
30

31
32
33
34
35
36
37
38
39
40
41
42
43
44

45
46

47
48

49
50
51
52
53
54


###### 3. 可视化监控

```
1. 启动项目，发起接口请求
```
```
2. 通过 Endpoint 查看指标信息
10.23.48.43:28088/service-provider-demo/actuator/prometheus
```
```
3. prometheus 图表查看指标信息
```
```
super.afterExecute (r, t);
}
}
```
```
55
56
57
```
```
1 GET http://localhost:28088/service-provider-demo/execute
```
```
# HELP thread_pool_total_cost_time 线程池已完成任务总耗时
# TYPE thread_pool_total_cost_time counter
thread_pool_total_cost_time{poolName="order-thread-pool",} 203466 .0
thread_pool_total_cost_time{poolName="user-thread-pool",} 201892 .0
# HELP thread_pool_task_completed_count 线程池已完成任务数
# TYPE thread_pool_task_completed_count counter
thread_pool_task_completed_count{poolName="order-thread-pool",} 100 .0
thread_pool_task_completed_count{poolName="user-thread-pool",} 100 .0
# HELP thread_pool_task_active_count 线程池当前活跃任务数
# TYPE thread_pool_task_active_count gauge
thread_pool_task_active_count{poolName="order-thread-pool",} 0 .0
thread_pool_task_active_count{poolName="user-thread-pool",} 0 .0
# HELP thread_pool_task_cost_time 请求耗时分布
# TYPE thread_pool_task_cost_time histogram
thread_pool_task_cost_time_bucket{poolName="order-thread-
pool", le="0.005",} 0 .0
thread_pool_task_cost_time_bucket{poolName="order-thread-
pool", le="0.01",} 0 .0
thread_pool_task_cost_time_bucket{poolName="order-thread-
pool", le="0.025",} 1 .0
thread_pool_task_cost_time_bucket{poolName="order-thread-
pool", le="0.05",} 2 .0
thread_pool_task_cost_time_bucket{poolName="order-thread-
pool", le="0.075",} 2 .0
thread_pool_task_cost_time_bucket{poolName="order-thread-
pool", le="0.1",} 2 .0
thread_pool_task_cost_time_bucket{poolName="order-thread-
pool", le="0.25",} 6 .0
thread_pool_task_cost_time_bucket{poolName="order-thread-
pool", le="0.5",} 14 .0
thread_pool_task_cost_time_bucket{poolName="order-thread-
pool", le="0.75",} 19 .0
thread_pool_task_cost_time_bucket{poolName="order-thread-
pool", le="1.0",} 24 .0
thread_pool_task_cost_time_bucket{poolName="order-thread-
pool", le="2.5",} 60 .0
thread_pool_task_cost_time_bucket{poolName="order-thread-
pool", le="5.0",} 100 .0
thread_pool_task_cost_time_bucket{poolName="order-thread-
pool", le="7.5",} 100 .0
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
```
```
16
```
```
17
```
```
18
```
```
19
```
```
20
```
```
21
```
```
22
```
```
23
```
```
24
```
```
25
```
```
26
```
```
27
```

```
在 Graph 页，输入 thread_pool_task_cost_time_bucket ，点击 Execute 按钮：
```
4. Grafana 页面配置图表

```
首先还是进入 JVMdashboard, 我们就在当前页面，添加相关视图。
1. 配置任务总耗时，点击 Add -> Visualization,
```
```
按照上图配置，最后点击 Apply 按钮。
2. 配置任务耗时分布直方图，点击 Add -> Visualization,
```
```
3. 最后效果如下：
```

#### Nacos 注册中心的动态参数调整小结

通过上述步骤，我们实现了自定义线程池的指标暴露、Nacos 注册中心的动态参数调整、
Prometheus 和 Grafana 的指标采集和可视化监控。这样，我们就可以更方便和高效地管理和监控我们
的线程池状态和性能。

除了监控功能，我们还可以利用 Prometheus 或 Grafana 的报警功能，为我们的指标设置告警规则和通
知渠道，当指标达到某些条件时，例如线程平均耗时过长，大量线程执行异常，大量任务被拒绝时，及
时收到告警通知，例如钉钉、邮件等。Grafana 的报警功能还可以让我们直观地定义告警阈值，并在仪
表盘上显示告警状态。

由于篇幅有限，本文就不再演示报警功能的具体操作，有兴趣的小伙伴可以参考本文的代码和相关配
置，自行尝试添加报警功能，并优化相关功能。

#### 动态线程池的开源方案推荐

本文仅为你展示了在 SpringCloud 框架下实现线程池的管理、监控、报警功能的基本思路和方法，如

果你想要将它应用到实际的生产环境中，还需要对它进行更多的功能扩展和优化。

如果你觉得这个过程太复杂或太麻烦，那么有一个开源组件已经为你做好了这些工作，它就是
dynamic-tp。

dynamic-tp 是一个基于配置中心的轻量级动态可监控线程池组件，它可以帮助你：

```
动态地调整线程池参数，无需重启应用
实时地查看线程池状态和性能指标
可视化地展示线程池指标数据和趋势图
灵活地设置线程池告警规则和通知渠道
一键地恢复线程池异常或风险
首页 | dynamic-tp (dynamictp. cn)
```

#### SpringCloud 项目使用 dynamic-tp 动态线程池

###### dynamic-tp 动态线程池的思想思路

**1. AlarmCheckEvent 事件发布**

根据引入的 dynamic-tp-spring-cloud-starter-nacos 或者 dynamic-tp-spring-boot-starter-nacos 依赖

以 nacos 为例：

可以看到自动装配的文件：DtpAutoConfiguration 与 NacosRefresher. 在 DtpAutoConfiguration 中，
我们可以看到导入的配置信息：

基于这个注解，关注 BaseBeanAutoConfiguration 这个类：

这个类主要干了下面这几件事请

```
<dependency>
<groupId>cn. dynamictp</groupId>
<artifactId>dynamic-tp-spring-boot-starter-nacos</artifactId>
<version>1.0.9</version>
</dependency>
```
```
1
2
3
4
5
```
```
1 @ImportAutoConfiguration ({BaseBeanAutoConfiguration. class})
```

其中

1 ）dtpBanner 是做控制台启动项目时的 banner 打印操作。

2 ）dtpPostProcessor dtp 后置处理器处理所有相关 bean

如果 bean 是执行器，则注册 dtp，此时会注册到 DTP_REGISTRY 中，数据结构：Map

否则会基于 ApplicationHolder 拿到基于 DynamicTp 注解的 class，如果当前基于 DynamicTp 的
methodMetadata 为空，则返回 bean, 否则拿到 dtpAnnotationVal。poolName 也即
dtpAnnotationVal。

如果当前的 bean 属于线程池任务执行器，则注册 task 执行器。包装执行器，放入通知信息
notifyItems。registerCommon 执行注册。

3 ）dtpRegistry 注册 dtp DTP_REGISTRY 数据结构：Map

其中最为重要的方法是刷新方法：

获取 dtp 执行器，对执行器进行转换为 DtpMainProp。执行刷新。

4 ）dtp 监控 dtpMonitor 会执行监控发布：里面有有 2 个方法需要注意：检查监控 checkAlarm，collect
收集监控指标信息

其中：检查监控的时候，会基于当前的发送告警的信息：基于对应的渠道进行消息发送。

此时会发布两个事件：publishAlarmCheckEvent、publishCollectEvent

NacosRefresher 中存在的方法 Refresh: 刷新当监听到配置发生改变的时候, doNoticeAsync 执行异步通
知，通知业务方，此时发生了配置的变更。

刷新完成后，执行 RefreshEvent 刷新事件发布。

**2. AlarmCheckEvent 事件监听**

发布完成后，可以看到对应的监听是在

适配器公共自动装配中

```
DtpProperties 线程池相关配置
上下文 holder dtpApplicationContextHolder
dtpBanner 打印 dtpBannerPrinter
dtp 后置处理器 dtpPostProcessor
dtp 注册 dtpRegistry
dtp 监控 dtpMonitor
dtpEndpoint dtpEndpoint
```
```
1 2 3 4 5 6 7
```
```
1 com. dtp. starter. adapter. common. autoconfigure. AdapterCommonAutoConfiguration
```
```
@Override
public void onApplicationEvent (@NonNull ApplicationEvent event) {
try {
if (event instanceof RefreshEvent) {
doRefresh (((RefreshEvent) event). getDtpProperties ());
} else if (event instanceof CollectEvent) {
doCollect (((CollectEvent) event). getDtpProperties ());
} else if (event instanceof AlarmCheckEvent) {
doAlarmCheck (((AlarmCheckEvent) event). getDtpProperties ());
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
```

可以看到我们关心的三个发布事件，都在此进行了监听：doRefresh、doCollect、doAlarmCheck

其中

```
doRefresh 刷新事件会执行相关渠道的通知
doCollect 收集日志会执行对应的打印
doAlarmCheck 告警信息会执行告警
```
###### SpringCloud 中 dynamic-tp 使用

使用方式：以 nacos 为例，可以看到其基于@EnableDynamicTp 实现对 dtp 相关 bean 的注册。

DtpBeanDefinitionRegistrar 即是完成注册的类。其主要是创建 dtp 配置对象 DtpProperties，绑定 dtp
配置，获取执行器。拿到执行器后，遍历执行，绑定对应的信息，构建构造函数，注册 bean 信息。方
便后续对线程池的操作。

由此可以看到实现了两个最为主要的功能：对线程池进行动态变更和对线程池的监控告警。

```
} catch (Exception e) {
log.error ("DynamicTp adapter, event handle failed.", e);
}
}
```
```
11
12
13
14
```
```
@Resource
private ThreadPoolExecutor dtpExecutor 1;
```
```
@GetMapping ("/dtp-nacos-example/test")
public String test () throws InterruptedException {
task ();
return "success";
}
```
```
//获取 dtp 执行器
public void task () throws InterruptedException {
//获取 dtp 执行器
DtpExecutor dtpExecutor 2 = DtpRegistry.getDtpExecutor ("dtpExecutor 2");
for (int i = 0 ; i < 100 ; i++) {
Thread.sleep ( 100 );
dtpExecutor 1.execute (() -> {
log.info ("i am dynamic-tp-test-1 task");
});
dtpExecutor 2.execute (NamedRunnable.of (() -> {
try {
Thread.sleep ( 1000 );
} catch (InterruptedException e) {
e.printStackTrace ();
}
log.info ("i am dynamic-tp-test-2 task");
}, "task-" + i));
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
```

## 参考文献

https://tech.meituan.com/2020/04/02/java-pooling-pratice-in-meituan.html

https://www.cnblogs.com/mic112/p/15424574.html

https://dynamictp.cn/guide/introduction/background.html

https://cloud.tencent.com/developer/article/2228775)

https://www.cnblogs.com/daoqidelv/p/7043696.html

清华大学出版社《Java 高并发核心编程卷 2 加强版》

《队列之王 Disruptor 红宝书》

通过事件总线 EventBus/AsyncEventBus 进行 JAVA 模块解耦 （史上最全）

队列之王： Disruptor 原理、架构、源码一文穿透

https://blog.csdn.net/crazymakercircle/article/details/128264803

https://xie.infoq.cn/article/deba3305beba3838c2cf6c102


```
技术自由圈
```
## 未来职业，如何突围：三栖架构师


```
技术自由圈
```
### 成功案例： 2 年翻 3 倍， 35 岁卷王成功转型为架构师

详情：http://topcoder.cloud/forum.php?mod=forumdisplay&fid=43&page=1


技术自由圈


技术自由圈


技术自由圈


```
技术自由圈
```
### 硬核推荐：尼恩 Java 硬核架构班

详情：https://www.cnblogs.com/crazymakercircle/p/9904544.html


技术自由圈


```
技术自由圈
```
##### 架构班（社群 VIP）的起源：

最初的视频，主要是给读者加餐。很多的读者，需要一些高质量的实操、理论视频，所以，我就围绕书，和底层，做了几个
实操、理论视频，然后效果还不错，后面就做成迭代模式了。

##### 架构班（社群 VIP）的功能：^

提供高质量实操项目整刀真枪的架构指导、快速提升大家的:

⚫ 开发水平
⚫ 设计水平

⚫ 架构水平

弥补业务中 CRUD 开发短板，帮助大家尽早脱离具备 3 高能力，掌握：
⚫ 高性能

⚫ 高并发
⚫ 高可用

作为一个高质量的架构师成长、人脉社群，把所有的卷王聚焦起来，一起卷：

⚫ 卷高并发实操
⚫ 卷底层原理

⚫ 卷架构理论、架构哲学
⚫ 最终成为顶级架构师，实现人生理想，走向人生巅峰

##### 架构班（社群 VIP）的目的：^

⚫ 高质量的实操，大大提升简历的含金量，吸引力，增强面试的召唤率

⚫ 为大家提供九阳真经、葵花宝典，快速提升水平
⚫ 进大厂、拿高薪

⚫ 一路陪伴，提供助学视频和指导，辅导大家成为架构师
⚫ 自学为主，和其他卷王一起，卷高并发实操，卷底层原理、卷大厂面试题，争取狠卷 3 月成高手，狠卷 3 年成为顶级架

```
构师
```

```
技术自由圈
```
##### N 个超高并发实操项目：简历压轴、个顶个精彩


```
技术自由圈
```
【样章】第 17 章：横扫全网 Rocketmq 视频第 2 部曲: 工业级 rocketmq 高可用（HA）底层原
理和实操

工业级 rocketmq 高可用底层原理，包含：消息消费、同步消息、异步消息、单向消息等不同消息的底层原理和源码实现；
消息队列非常底层的主从复制、高可用、同步刷盘、异步刷盘等底层原理。

工业级 rocketmq 高可用底层原理和搭建实操，包含：高可用集群的搭建。
解决以下难题：

1 、技术难题：RocketMQ 如何最大限度的保证消息不丢失的呢？RocketMQ 消息如何做到高可靠投递？

2 、技术难题：基于消息的分布式事务，核心原理不理解
3 、选型难题： kafka or rocketmq ，该娶谁？

下图链接：https://www.processon.com/view/6178e8ae0e3e7416bde9da19


```
技术自由圈
```
### 简历优化后的成功涨薪案例（ VIP 含免费简历优化）


技术自由圈


技术自由圈


技术自由圈


技术自由圈


技术自由圈


技术自由圈


技术自由圈


```
技术自由圈
```
### 修改简历找尼恩（资深简历优化专家）

⚫ 如果面试表达不好，尼恩会提供简历优化指导

⚫ 如果项目没有亮点，尼恩会提供项目亮点指导

⚫ 如果面试表达不好，尼恩会提供面试表达指导

作为 40 岁老架构师，尼恩长期承担技术面试官的角色：

⚫ 从业以来，“阅历”无数，对简历有着点石成金、改头换面、脱胎换骨的指导能力。

⚫ 尼恩指导过刚刚就业的小白，也指导过 P 8 级的老专家，都指导他们上岸。

如何联系尼恩。尼恩微信，请参考下面的地址：

语雀：https://www.yuque.com/crazymakercircle/gkkw8s/khigna

码云：https://gitee.com/crazymaker/SimpleCrayIM/blob/master/疯狂创客圈总目录.md


