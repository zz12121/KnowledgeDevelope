```
技术自由圈
```
# 牛逼的职业发展之路

40 岁老架构尼恩用一张图揭秘: Java 工程师的高端职业发展路径，走向食物链顶端的之路

链接：https://www.processon.com/view/link/618a2b62e0b34d73f7eb3cd


```
技术自由圈^
```
# 史上最全：价值 10 W 的架构师知识图谱

此图梳理于尼恩的多个 3 高生产项目：多个亿级人民币的大型 SAAS 平台和智慧城市项目

链接：https://www.processon.com/view/link/60fb9421637689719d


```
技术自由圈
```
# 牛逼的架构师哲学

40 岁老架构师尼恩对自己的 20 年的开发、架构经验总结

链接：https://www.processon.com/view/link/616f801963768961e9d9aec


```
技术自由圈
```
# 牛逼的 3 高架构知识宇宙

尼恩 3 高架构知识宇宙，帮助大家穿透 3 高架构，走向技术自由，远离中年危机

链接：https://www.processon.com/view/link/635097d2e0b34d40be778ab


```
技术自由圈
```
# 尼恩 Java 面试宝典

40 个专题（卷王专供+ 史上最全 + 2023 面试必备）
详情：https://www.cnblogs.com/crazymakercircle/p/13917138.html


```
技术自由圈^
```
# 未来职业，如何突围：三栖架构师


## 专题 14 ：Redis 面试题（史上最全、定期更

## 新）

#### 本文版本说明：V

```
此文的格式，由markdown 通过程序转成而来，由于很多表格，没有来的及调整，出现一个格式
问题，尼恩在此给大家道歉啦。
由于社群很多小伙伴，在面试，不断的交流最新的面试难题，所以，《尼恩Java面试宝典》， 后
面会不断升级，迭代。
```
```
本专题，作为 《尼恩Java面试宝典》专题之一， 《尼恩Java面试宝典》一共 41 个面试专题，后
续还会增加
```
###### 面试问题交流说明：

如果遇到分布式事务的面试难题，或者其他的面试难题，都可以来疯狂创客圈社群交流，

加入交流群，加尼恩微信即可，

尼恩的微信二维码在哪里呢 ？ 请参见文末

###### 升级说明：

###### V 65 升级说明（2023-05-13）

有赞一面：亿级用户日活统计，有几种方案？

###### V 64 升级说明（2023-5-11）：

1000 W 用户 1 Wqps 高并发签到系统的架构和实操

###### V 62 升级说明（2023-05-03）

滴滴一面：BigKey 问题很致命，如何排查和处理？

###### V 37 升级说明（2023-02-03）

阿里二面： BigKey、HotKey 问题严重，该如何预防和解决


###### V 18 升级说明（2022-12-20）

说说：Redis 的过期策略有哪些？

说说：那么定期+惰性都没有删除过期的 key 怎么办？

聊聊：分布式锁有哪些实现方案？ 会有哪些问题？

###### V 5 升级说明（2022-6-21）

```
聊聊：什么是redis混合持久化？
聊聊：redis主从复制核心流程？
聊聊：数据分片（sharding）的基本类型？ 大致的原理？
聊聊：什么是缓存击穿、缓存穿透、缓存雪崩？
聊聊：详细介绍一下redis主从复制核心流程
聊聊：假如Redis里面有 1 亿个key，其中有10w个key是以某个固定的已知的前缀开头的，如何将
它们全部找出来？
聊聊：Redis 支持事务吗？
聊聊：字典是如何实现的？Rehash 了解吗？
聊聊：如何保证缓存和数据库数据的一致性？
聊聊：官方Redis cluster 集群的原理？
聊聊：Redis 集群模式的工作原理能说一下么？在集群模式下，Redis 的 key 是如何寻址的？分布
式寻址都有哪些算法？了解一致性 hash 算法吗？
聊聊：详细介绍一下redis主从复制核心流程
```
###### V 4 升级说明（2022-6-19），增加 redis 如何优化的试题答案：

```
问：redis如何优化? (来源，小伙伴的面试真题)
```
#### 聊聊：为什么使用 redis？

**分析** : 博主觉得在项目中使用 redis，主要是从两个角度去考虑: **性能** 和 **并发** 。当然，redis 还具备可以做分
布式锁等其他功能，但是如果只是为了分布式锁这些其他功能，完全还有其他中间件 (如 zookpeer 等) 代
替，并不是非要使用 redis。因此，这个问题主要从性能和并发两个角度去答。
**回答** : 如下所示，分为两点
**（一）性能**
我们在碰到需要执行耗时特别久，且结果不频繁变动的 SQL，就特别适合将运行结果放入缓存。这样，
后面的请求就去缓存中读取，使得请求能够 **迅速响应** 。

**（二）并发**
在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用 redis
做一个缓冲操作，让请求先访问到 redis，而不是直接访问数据库。


#### 聊聊：在项目中缓存是如何使用的？为什么要用缓存？缓

#### 存使用不当会造成什么后果？

**面试官心理分析**

这个问题，互联网公司必问，要是一个人连缓存都不太清楚，那确实比较尴尬。

只要问到缓存，上来第一个问题，肯定是先问问你项目哪里用了缓存？为啥要用？不用行不行？如果用
了以后可能会有什么不良的后果？

这就是看看你对缓存这个东西背后有没有思考，如果你就是傻乎乎的瞎用，没法给面试官一个合理的解
答，那面试官对你印象肯定不太好，觉得你平时思考太少，就知道干活儿。

**面试题剖析**

项目中缓存是如何使用的？

这个，需要结合自己项目的业务来。

为什么要用缓存？

用缓存，主要有两个用途：高性能、高并发。

**高性能**

假设这么个场景，你有个操作，一个请求过来，吭哧吭哧你各种乱七八糟操作 mysql，半天查出来一个
结果，耗时 600 ms。但是这个结果可能接下来几个小时都不会变了，或者变了也可以不用立即反馈给
用户。那么此时咋办？

缓存啊，折腾 600 ms 查出来的结果，扔缓存里，一个 key 对应一个 value，下次再有人查，别走
mysql 折腾 600 ms 了，直接从缓存里，通过一个 key 查出来一个 value，2 ms 搞定。性能提升 300
倍。

就是说对于一些需要复杂操作耗时查出来的结果，且确定后面不怎么变化，但是有很多读请求，那么直
接将查询出来的结果放在缓存中，后面直接读缓存就好。

**高并发**

所以要是你有个系统，高峰期一秒钟过来的请求有 1 万，那一个 mysql 单机绝对会死掉。你这个时候
就只能上缓存，把很多数据放缓存，别放 mysql。缓存功能简单，说白了就是 key-value 式操作，单机
支撑的并发量轻松一秒几万十几万，支撑高并发 so easy。单机承载并发量是 mysql 单机的几十倍。

缓存是走内存的，内存天然就支撑高并发。

用了缓存之后会有什么不良后果？

常见的缓存问题有以下几个：

缓存与数据库双写不一致、缓存雪崩、缓存穿透、缓存并发竞争后面再详细说明。


#### 聊聊：redis 都有哪些数据类型？分别在哪些场景下使用比

#### 较合适？

**面试官心理分析**

除非是面试官感觉看你简历，是工作 3 年以内的比较初级的同学，可能对技术没有很深入的研究，面试
官才会问这类问题。否则，在宝贵的面试时间里，面试官实在不想多问。

其实问这个问题，主要有两个原因：

```
看看你到底有没有全面的了解 redis 有哪些功能，一般怎么来用，啥场景用什么，就怕你别就会最
简单的 KV 操作；
看看你在实际项目里都怎么玩儿过 redis。
```
要是你回答的不好，没说出几种数据类型，也没说什么场景，你完了，面试官对你印象肯定不好，觉得
你平时就是做个简单的 set 和 get。

**面试题剖析**

redis 主要有以下几种数据类型：

```
string
hash
list
set
sorted set
```
###### string

这是最简单的类型，就是普通的 set 和 get，做简单的 KV 缓存。

###### hash

这个是类似 map 的一种结构，这个一般就是可以将结构化的数据，比如一个对象（前提是 **这个对象没
嵌套其他的对象** ）给缓存在 redis 里，然后每次读写缓存的时候，可以就操作 hash 里的 **某个字段** 。

###### list

list 是有序列表，这个可以玩儿出很多花样。

```
1 set college szu
```
```
hset person name bingo
hset person age 20
hset person id 1
hget person name
person = {
"name": "bingo",
"age": 20 ,
"id": 1
}
```
```
1 2 3 4 5 6 7 8 9
```

比如可以通过 list 存储一些列表型的数据结构，类似粉丝列表、文章的评论列表之类的东西。

比如可以通过 lrange 命令，读取某个闭区间内的元素，可以基于 list 实现分页查询，这个是很棒的一个
功能，基于 redis 实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高，就一页
一页走。

比如可以搞个简单的消息队列，从 list 头怼进去，从 list 尾巴那里弄出来。

###### set

set 是无序集合，自动去重。

直接基于 set 将系统里需要去重的数据扔进去，自动就给去重了，如果你需要对一些数据进行快速的全
局去重，你当然也可以基于 jvm 内存里的 HashSet 进行去重，但是如果你的某个系统部署在多台机器
上呢？得基于 redis 进行全局的 set 去重。

可以基于 set 玩儿交集、并集、差集的操作，比如交集吧，可以把两个人的粉丝列表整一个交集，看看
俩人的共同好友是谁？对吧。

把两个大 V 的粉丝都放在两个 set 中，对两个 set 做交集。

```
# 0开始位置，-1结束位置，结束位置为-1时，表示列表的最后一个位置，即查看所有。
lrange mylist 0 -
```
```
1
2
```
```
lpush mylist 1
lpush mylist 2
lpush mylist 3 4 5
```
```
# 1
rpop mylist
```
```
1 2 3 4 5 6
```
```
#-------操作一个set-------
# 添加元素
sadd mySet 1
```
```
# 查看全部元素
smembers mySet
```
```
# 判断是否包含某个值
sismember mySet 3
```
```
# 删除某个/些元素
srem mySet 1
srem mySet 2 4
```
```
# 查看元素个数
scard mySet
```
```
# 随机删除一个元素
spop mySet
```
```
#-------操作多个set-------
# 将一个set的元素移动到另外一个set
smove yourSet mySet 2
```
```
# 求两set的交集
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
```

###### sorted set

sorted set 是排序的 set，去重但可以排序，写进去的时候给一个分数，自动根据分数排序。

#### 说说：Redis 的过期策略有哪些？

**1 、两种过期策略：定期删除+惰性删除：**

（ 1 ）定期删除：

redis 默认每隔 100 ms 就随机抽取一些设置了过期时间的 key，检查其是否过期，如果有过期就删除。有
两个要点：

```
定期删除指的是Redis每隔一段时间对数据库做一次检查，删除里面的过期key。
由于不可能对所有key去做轮询来删除，所以Redis会每次随机取一些key去做检查和删除
```
注意这里是随机抽取的。

为什么要随机呢？

你想一想假如 redis 存了几十万个 key ，每隔 100 ms 就遍历所有的设置过期时间的 key 的话，就会给
CPU 带来很大的负载。

```
为什么不用单个key的到期删除策略呢？
```
```
定时删除，用一个定时器来负责监视key，过期则自动删除。
虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，
而不是删除key，因此没有采用这一策略。
```
（ 2 ）惰性删除：

惰性删除指的是当我们查询 key 的时候才对 key 进行检测，如果已经达到过期时间，则删除。显然，

他有一个缺点就是如果这些过期的 key 没有被访问，那么他就是一直无法被删除，而且一直占用内存。

```
sinter yourSet mySet
```
```
# 求两set的并集
sunion yourSet mySet
```
```
# 求在yourSet中而不在mySet中的元素
sdiff yourSet mySet
```
```
26
27
28
29
30
31
32
```
```
zadd board 85 zhangsan
zadd board 72 lisi
zadd board 96 wangwu
zadd board 63 zhaoliu
```
```
# 获取排名前三的用户（默认是升序，所以需要 rev 改为降序）
zrevrange board 0 3
```
```
# 获取某用户的排名
zrank board zhaoliu
```
```
1 2 3 4 5 6 7 8 9
```
```
10
```

为啥要惰性删除呢？

定期删除可能导致很多过期的 key 到了时间并没有被删除掉。这时就要使用到惰性删除。在你获取某个
key 的时候，redis 会检查一下，这个 key 如果设置了过期时间并且过期了，是的话就删除。

**2 、定期删除+惰性删除存在的问题：**

如果某个 key 过期后，定期删除没删除成功，然后也没再次去请求 key，也就是说惰性删除也没生效。

这时，如果大量过期的 key 堆积在内存中，redis 的内存会越来越高，导致 redis 的内存块耗尽。

那么就应该采用内存淘汰机制。

#### 说说：那么定期+惰性都没有删除过期的 key 怎么办？

假设 Redis 每次定期随机查询 key 的时候没有删除，这些 key 也没有做查询的话，就会导致这些 key 一直
保存在 Redis 里面, 无法被删除，

这时候就会走到 Redis 的内存淘汰机制。

Redis 共提供了 8 中缓存淘汰策略，其中 volatile-lfu 和 allkeys-lfu 是 Redis 4.0 版本新增的。

1 、noeviction：不进行淘汰数据。一旦缓存被写满，再有写请求进来，Redis 就不再提供服务，而是直
接返回错误。Redis 用作缓存时，实际的数据集通常都是大于缓存容量的，总会有新的数据要写入缓
存，这个策略本身不淘汰数据，也就不会腾出新的缓存空间，我们不把它用在 Redis 缓存中。

2 、volatile-ttl：在设置了过期时间的键值对中，移除即将过期的键值对。

3 、volatile-random：在设置了过期时间的键值对中，随机移除某个键值对。

4 、volatile-lru：在设置了过期时间的键值对中，移除最近最少使用（最近最久未使用）的键值对。

5 、volatile-lfu：在设置了过期时间的键值对中，移除最近最不频繁使用的键值对, 或者移除最不经常
使用的键值对

6 、allkeys-random：在所有键值对中，随机移除某些 key。

7 、allkeys-lru：在所有的键值对中，移除最近最少使用（最近最久未使用）的键值对。

8 、allkeys-lfu：在所有的键值对中，移除最近最不频繁使用的键值对, 或者移除最不经常使用的键值对

```
通常情况下推荐优先使用 allkeys-lru 策略。
```

```
这样可以充分利用 LRU 这一经典缓存算法的优势，把最近最常访问的数据留在缓存中，提升应用
的访问性能。
```
```
如果你的业务数据中有明显的局部周期性流量( 局部冷热数据区分明显)，建议使用 allkeys-lru 策
略。
```
#### 聊聊：redis 的过期策略都有哪些？内存淘汰机制都有哪

#### 些？手写一下 LRU 代码实现？

**面试官心理分析**

如果你连这个问题都不知道，上来就懵了，回答不出来，那线上你写代码的时候，想当然的认为写进
redis 的数据就一定会存在，后面导致系统各种 bug，谁来负责？

常见的有两个问题：

**（ 1 ）往 redis 写入的数据怎么没了？**

可能有同学会遇到，在生产环境的 redis 经常会丢掉一些数据，写进去了，过一会儿可能就没了。我的
天，同学，你问这个问题就说明 redis 你就没用对啊。redis 是缓存，你给当存储了是吧？

啥叫缓存？用内存当缓存。内存是无限的吗，内存是很宝贵而且是有限的，磁盘是廉价而且是大量的。
可能一台机器就几十个 G 的内存，但是可以有几个 T 的硬盘空间。redis 主要是基于内存来进行高性
能、高并发的读写操作的。

那既然内存是有限的，比如 redis 就只能用 10 G，你要是往里面写了 20 G 的数据，会咋办？当然会干
掉 10 G 的数据，然后就保留 10 G 的数据了。那干掉哪些数据？保留哪些数据？当然是干掉不常用的数
据，保留常用的数据了。

**（ 2 ）数据明明过期了，怎么还占用着内存？**

这是由 redis 的过期策略来决定。

**面试题剖析**

**redis 过期策略**

redis 过期策略是：定期删除+惰性删除。

所谓定期删除，指的是 redis 默认是每隔 100 ms 就随机抽取一些设置了过期时间的 key，检查其是否过
期，如果过期就删除。

假设 redis 里放了 10 w 个 key，都设置了过期时间，你每隔几百毫秒，就检查 10 w 个 key，那 redis 基
本上就死了，cpu 负载会很高的，消耗在你的检查过期 key 上了。注意，这里可不是每隔 100 ms 就遍
历所有的设置过期时间的 key，那样就是一场性能上的灾难。实际上 redis 是每隔 100 ms 随机抽取一些
key 来检查和删除的。

但是问题是，定期删除可能会导致很多过期 key 到了时间并没有被删除掉，那咋整呢？所以就是惰性删
除了。这就是说，在你获取某个 key 的时候，redis 会检查一下，这个 key 如果设置了过期时间那么是
否过期了？如果过期了此时就会删除，不会给你返回任何东西。

获取 key 的时候，如果此时 key 已经过期，就删除，不会返回任何东西。

答案是：走内存淘汰机制。


**内存淘汰机制**

redis 内存淘汰机制有以下几个：

```
noeviction: 当内存不足以容纳新写入数据时，新写入操作会报错，这个一般没人用吧，实在是太
恶心了。
allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的 key（这个是最
常用的）。
allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个 key，这个一般没
人用吧，为啥要随机，肯定是把最近最少使用的 key 给干掉啊。
volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用
的 key（这个一般不太合适）。
volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某
个 key。
volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的
key 优先移除。
```
**手写一个 LRU 算法**

你可以现场手写最原始的 LRU 算法，那个代码量太大了，似乎不太现实。

不求自己纯手工从底层开始打造出自己的 LRU，但是起码要知道如何利用已有的 JDK 数据结构实现一个
Java 版的 LRU。

父类的构造方法：LinkedHashMap (int initialCapacity, float loadFactor, boolean accessOrder);

```
initialCapacity:初始容量
```
```
import java.util.LinkedHashMap;
import java.util.Map;
```
```
public class LRUCache<K, V> extends LinkedHashMap<K, V> {
private final int CACHE_SIZE;
```
```
/**
* 传递进来最多能缓存多少数据
* @param cacheSize 缓存大小
*/
public LRUCache(int cacheSize) {
```
```
//true 表示让 linkedHashMap 按照访问顺序来进行排序，最近访问的放在头部，最老
访问的的放在尾部
super((int) Math.ceil(cacheSize / 0.75) + 1, 0.75f, true);
CACHE_SIZE = cacheSize;
}
```
```
@Override
protected boolean removeEldestEntry(Map.Entry<K, V> eldest) {
//当map中的数据量大于制定的缓存个数的时候，就自动删除最老的数据
return size() > CACHE_SIZE;
}
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
```
```
14
15
16
17
18
19
20
21
22
23
```

```
loadFactor:装载因子
accessOrder:访问顺序
```
问题 1 ：关于装载因子的为什么是 0.

```
请参见尼恩的 《HashMap - 图解 -秒懂》 博文和配套视频
```
问题 2 ：accessOrder 访问顺序的取值含义：

```
false，所有的Entry按照插入的顺序排列
true，所有的Entry按照访问的顺序排列
```
#### 聊聊：Redis 支持事务吗？

Redis 提供了简单的事务，但它对事务 ACID 的支持并不完备。

multi 命令代表事务开始，exec 命令代表事务结束，它们之间的命令是原子顺序执行的：

Redis 事务的原理，是所有的指令在 exec **之前不执行** ，而是缓存在服务器的一个事务队列中，

服务器一旦收到 exec 指令，才开执行整个事务队列，执行完毕后一次性返回所有指令的运行结果。

因为 Redis 执行命令是单线程的，所以这组命令顺序执行，而且不会被其它线程打断。

```
127.0.0.1:6379> multi
OK
127.0.0.1:6379> sadd user:a:follow user:b
QUEUED
127.0.0.1:6379> sadd user:b:fans user:a
QUEUED
127.0.0.1:6379> sismember user:a:follow user:b
(integer) 0
127.0.0.1:6379> exec 1) (integer) 1
2) (integer) 1
```
```
1 2 3 4 5 6 7 8 9
```
```
10
```

**Redis 事务的注意点有哪些？**

需要注意的点有：

```
Redis 事务是不支持回滚的，不像 MySQL 的事务一样，要么都执行要么都不执行；
Redis 服务端在执行事务的过程中，不会被其他客户端发送来的命令请求打断。直到事务命令全部
执行完毕才会执行其他客户端的命令。
```
**Redis 事务为什么不支持回滚？**

Redis 的事务不支持回滚。

如果执行的命令有语法错误，Redis 会执行失败，这些问题可以从程序层面捕获并解决。但是如果出现
其他问题，则依然会继续执行余下的命令。

这样做的原因是因为回滚需要增加很多工作，而不支持回滚则可以 **保持简单、快速的特性** 。

#### 请问：了解 Redis 事务机制吗？

Redis 通过 MULTI、EXEC、WATCH 等命令来实现事务机制，

Redis 事务执行过程将一系列多个命令按照顺序一次性执行，并且在执行期间，事务不会被中断，也不
会去执行客户端的其他请求，直到所有命令执行完毕。

事务的执行过程如下：

```
1. 服务端收到客户端请求，事务以MULTI开始
2. 如果客户端正处于事务状态，则会把事务放入队列同时返回给客户端 QUEUED，反之则直接执行
这个命令
3. 当收到客户端EXEC命令时，WATCH命令监视真个事务中的key是否被修改，如果有，则返回空回
复到客户端表示失败，否则Redis会遍历真个事务队列，执行队列中保存的所有命令，最后返回结
果给客户端
```
WATCH 的机制本身是一个 CAS 的机制，被监视的 key 会被保存到一个链表中，如果某一个 key 被修改，那
么 REDIS_DIRTY_CAS 标志将会被打开，这时服务器会拒绝执行事务

#### 问：Redis 如果大量的 key 设置同一时间过期，可能发生什

#### 么？

如果大量的 key 过期时间设置的过于集中，到过期的那个时间点，Redis 可能会出现短暂的卡顿现象。

严重的话会出现缓存雪崩，我们一般需要在时间上加一个随机值，使得过期时间分散一些

#### 聊聊：Redis 为什么快呢？

Redis 的速度非常的快，单机的 Redis 就可以支撑每秒十几万的并发，相对于 MySQL 来说，性能是
MySQL 的几十倍。速度快的原因主要有几点：

```
完全基于内存操作
```

我们都知道 Redis 是完全基于内存操作，这也是为什么 Redis 的访问速度要远远快于 MySQL 的主要原
因，

因为是使用内存存储数据，可以避免频繁的进行写盘操作，大大降低响应时间，我们仅仅知道因为它是
基于内存实现的，对于其它原因为什么快是一概不知。

```
使用单线程，避免了线程切换和竞态产生的消耗
基于非阻塞的IO多路复用机制
C语言实现，优化过的数据结构，基于几种基础的数据结构，redis做了大量的优化，性能极高
```
接下来就可以展开介绍：

**基于内存实现**

这点在上面就已经说过了，这里在简单说一下。

Redis 是基于内存的数据库，不可避免的要和磁盘数据库做对比，比如 MySQL 数据库。

MySQL 是关系型数据库，主要用于存放持久化数据，将数据存储在硬盘中，读取速度较慢，每次请求
访问数据库时，都存在着 I/O 操作，如果反复频繁的访问数据库，会在数据库中花费过多的时间，并且
反复访问数据库会导致数据库的负载过高。

而 Redis 是基于内存的缓存数据库，用于存储使用频繁的数据，这样减少访问数据库的次数，提高运行
效率。

**高效的数据结构**

我们都知道，MySQL 索引为了提高效率，选择了 B+ 树的数据结构，对于一个应用场景来说合理的数据
结构可以让你的应用或者程序更快。

接下来我们就说说 Redis 的底层数据结构，底层数据结构一共有 6 种，分别是，简单动态字符串，双向
链表，压缩列表，哈希表，跳表和整数数组，它们和数据类型的对应关系如下图所示：

下面我们来详细介绍一下 Redis 中 5 大数据结构的底层实现。

**SDS 简单动态字符串**

Redis 是用 C 语言开发完成的，但在 Redis 字符串中，并没有使用 C 语言中的字符串，而是用一种称为
SDS（Simple Dynamic String）的结构体来保存字符串。


例如：执行命令 set key value，key 和 value 都是一个 SDS 类型的结构存储在内存中。

SDS 与 C 字符串的区别：

**字符串长度**

C 字符串本身不记录长度信息，每次获取长度信息都需要遍历整个字符串，复杂度为 O (n)；C 字符串遍
历时遇到‘\0’时结束。

SDS 中 len 字段保存着字符串的长度，所以总能在常数时间内获取字符串长度，复杂度是 O (1)。

**拒绝缓冲区溢出**

当 SDS API 需要对 SDS 进行修改时，首先会检查空间是否足够，若不充足则会分配新空间，避免了缓
冲区溢出问题。

**减少字符串修改时带来的内存重新分配的次数**

在 C 中，当我们频繁的对一个字符串进行修改（append 或 trim）操作的时候，需要频繁的进行内存重
新分配的操作，十分影响性能。如果不小心忘记，有可能会导致内存溢出或内存泄漏，对于 Redis 来
说，本身就会很频繁的修改字符串，所以使用 C 字符串并不合适。而 SDS 实现了空间预分配和惰性空
间释放两种优化策略：

```
空间预分配： 字符串修改越频繁的话，内存分配就越频繁，就会很消费性能，而SDS修改和空间
扩充，会额外分配未使用的空间，减少性能损耗
惰性空间释放： SDS缩短时，不是回收多余的内存空间，而是free记录下多余的空间，后续有变
更，直接使用free中记录的空间，减少分配
```
**二进制安全**


在 Redis 中不仅可以存储 String 类型的数据，也可能存储一些二进制数据，但二进制数据并不是规则的
字符串格式，可能会包含一些特殊的字符，比如‘\0’等。

C 中字符串遇到‘\0’会结束，那‘\0’之后的数据就读取不上了。

但在 SDS 中，是根据 len 长度来判断字符串结束的。

**哈希表 (字典)**

Redis 作为 k-v 型内存数据库，所有的键值就是用字典来存储。字典就是哈希表，比如 HashMap，通
过 key 就可以直接获取到对应的 value。

而哈希表的特性，在 O（ 1 ）时间复杂度就可以获得对应的值。

**跳表**

作为 Redis 中特有的数据结构-跳跃表，其在链表的基础上增加了多级索引来提升查找效率。

这是跳跃表的简单原理图，每一层都有一条有序的链表，最底层的链表包含了所有的元素。

这样跳跃表就可以支持在 O (logN) 的时间复杂度里查找到对应的节点。

下面这张是跳表真实的存储结构图：

网上对跳表的各种理论讲解都比较多，, 其基本原理为添加多级索引来加快查找速度实现 O（logN) 的时
间复杂度，通过随机函数确定节点插入到几级索引中来防止跳表退化为单链表。

**双向链表**

列表 List 更多是被当作队列或栈来使用的。队列和栈的特性一个先进先出，一个先进后出。双向链表很
好的支持了这些特性。


以上是双端链表图结构。

链表里每个节点都带有两个指针，prev 指向前节点，next 指向后节点。这样在时间复杂度为 O (1) 内就
能获取到前后节点。

这里小伙伴可能注意到了，头节点里有 head 和 tail 两个参数，分别指向头节点和尾节点。这样设计能
对双向节点的处理时间复杂度降至 O (1)，对于队列和栈来说再适合不过。同时链表迭代时从两端都可以
进行。

而且，头节点里同时还有一个参数 len 3 ，和上边说到的 SDS 里类似，这里是用来记录链表长度的。因
此获取链表长度时不用再遍历整个链表，直接拿到 len 值就可以了，这个时间复杂度是 O (1)，我们可以
看出，这些特性都降低了 List 使用时的时间开销。

**压缩列表**


ziplist 是 Redis 为了节约内存而开发的，是由一系列特殊编码的连续内存块 (而不是像双端链表一样每个
节点是指针) 组成的顺序型数据结构，如下图：

压缩列表是经过特殊编码，专门为了提升内存使用效率设计的。

所有的操作都是通过指针与解码出来的偏移量进行的。并且压缩列表的内存是连续分配的，遍历的速度
很快。

**I/O 多路复用模型**

Redis 采用网络 IO 多路复用技术，来保证在多连接的时候系统的高吞吐量。多路-指的是多个 socket
网络连接，复用-指的是复用一个线程。多路复用主要有三种技术：select，poll，epoll。epoll 是最新
的、也是目前最好的多路复用技术。采用多路 I/O 复用技术, 可以让单个线程高效处理多个连接请求
（尽量减少网络 IO 的时间消耗）。并且 Redis 在内存中操作数据的速度非常快（因为 Redis 是基于内
存的操作，CPU 不是 Redis 的瓶颈）。主要以上两点造就了 Redis 具有很高的吞吐量。采用多路 I/O
复用技术可以让单个线程高效的处理多个连接请求。

**避免上下文切换**

那么单线程的 Redis 为什么会快呢？

因为多线程在执行过程中需要进行 CPU 的上下文切换，需要完成一系列工作，这是非常消耗资源的操
作，Redis 又是基于内存实现的，对于内存来说，没有上下文切换效率就是最高的。多次读写都在一个
CPU 上，对于内存来说就是最佳方案。

#### 聊聊：Redis 为什么最开始被设计成单线程的？

Redis 作为一个成熟的分布式缓存框架，

它由很多个模块组成，如网络请求模块、索引模块、存储模块、高可用集群支撑模块、数据操作模块
等。

**Redis 中只有网络请求模块和数据操作模块是单线程的** ，而其他的如持久化存储模块、集群支撑模块等
是多线程的。

单线程指的是网络请求模块使用了一个线程（所以不需考虑并发安全性），即一个线程处理所有网络请
求，其他模块仍用了多个线程。

那么，为什么网络操作模块和数据存储模块最初并没有使用多线程呢？

为什么没必要呢？我们先来说一下，什么情况下要使用多线程？

一个计算机程序在执行的过程中，主要需要进行两种操作分别是 **读写操作** 和 **计算操作** 。其中读写操作主
要是涉及到的就是 I/O 操作，其中包括网络 I/O 和磁盘 I/O。

计算操作主要涉及到 CPU。


而多线程的目的：就是通过并发的方式来提升 I/O 的利用率和 CPU 的利用率。

Redis 不需要提升 CPU 利用率，因为 Redis 的操作基本都是基于内存的，CPU 资源根本就不是 Redis 的性
能瓶颈。

所以，通过多线程技术来提升 Redis 的 CPU 利用率这一点是完全没必要的；采用多线程可以帮助我们提
升 I/O 的利用率，但是多线程带来的并发问题也给这些语言和框架带来了更多的复杂性。

而且，多个线程的互相切换也会带来一定的性能开销。所以，在提升 I/O 利用率这个方面上，Redis 并没
有采用多线程技术，而是选择了多路复用 I/O 技术。

官方解释如下：https://redis.io/topics/faq

官方 FAQ 表示，因为 Redis 是基于内存的操作，CPU 成为 Redis 的瓶颈的情况很少见，Redis 的瓶颈最有
可能是内存的大小或者网络限制。

如果想要最大程度利用 CPU，可以在一台机器上启动多个 Redis 实例。

同时 FAQ 里还提到了， Redis 4.0 之后开始变成多线程，除了主线程外，它也有后台线程在处理一些较
为缓慢的操作，例如清理脏数据、无用连接的释放、大 Key 的删除等等。

#### 聊聊：redis 和 memcached 有什么区别？redis 的线程

#### 模型是什么？为什么 redis 单线程却能支撑高并发？

**面试官心理分析**

这个是问 redis 的时候，最基本的问题吧，redis 最基本的一个内部原理和特点，就是 redis 实际上是个
单线程工作模型，你要是这个都不知道，那后面玩儿 redis 的时候，出了问题岂不是什么都不知道？

还有可能面试官会问问你 redis 和 memcached 的区别，但是 memcached 是早些年各大互联网公司常
用的缓存方案，但是现在近几年基本都是 redis，没什么公司用 memcached 了。

###### 面试题剖析

redis 和 memcached 有啥区别？

**redis 支持复杂的数据结构**

redis 相比 memcached 来说，拥有更多的数据结构，能支持更丰富的数据操作。如果需要缓存能够支
持更复杂的结构和操作， redis 会是不错的选择。


**redis 原生支持集群模式**

在 redis 3. x 版本中，便能支持 cluster 模式，而 memcached 没有原生的集群模式，需要依靠客户端来
实现往集群中分片写入数据。

**性能对比**

由于 redis 只使用单核，而 memcached 可以使用多核，所以平均每一个核上 redis 在存储小数据时比
memcached 性能更高。而在 100 k 以上的数据中，memcached 性能要高于 redis。虽然 redis 最近也
在存储大数据的性能上进行优化，但是比起 memcached，还是稍有逊色。

#### 说说：redis 的 IO 处理线程模型

redis 内部使用文件事件处理器 file event handler，这个文件事件处理器是单线程的，所以 redis 才叫
做单线程的模型。

这个模型，类似于 Netty 的 Reactor 反应器模型。

它采用 IO 多路复用机制同时监听多个 socket，将产生事件的 socket 压入内存队列中，事件分派器根据
socket 上的事件类型来选择对应的事件处理器进行处理。

文件事件处理器的结构包含 4 个部分：

```
多个 socket
IO 多路复用程序
文件事件分派器
事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）
```
多个 socket 可能会并发产生不同的操作，每个操作对应不同的文件事件，但是 IO 多路复用程序会监听
多个 socket，会将产生事件的 socket 放入队列中排队，事件分派器每次从队列中取出一个 socket，根
据 socket 的事件类型交给对应的事件处理器进行处理。

为啥 redis 单线程模型也能效率这么高？

```
纯内存操作
核心是基于非阻塞的 IO 多路复用机制
单线程反而避免了多线程的频繁上下文切换问题
```
#### 聊聊：为什么 Redis 6.0 引入多线程

Redis 不是说用单线程的吗？怎么 6.0 成了多线程的？

Redis 6.0 中的多线程，也只是针对处理 **网络请求过程采用了多线程，而数据的读写命令，仍然是单线程
处理的** 。

经过分析，限制 Redis 的性能的主要瓶颈出现在网络 IO 的处理上，虽然之前采用了多路复用技术。


多路复用的 IO 模型本质上仍然是同步阻塞型 IO 模型。

在多路复用的 IO 模型中，在处理网络请求时，调用 select （其他函数同理）的过程是阻塞的，也就是说
这个过程会阻塞线程，如果并发量很高，此处可能会成为瓶颈。

虽然现在很多服务器都是多个 CPU 核的，但是对于 Redis 来说，因为使用了单线程，在一次数据操作的
过程中，有大量的 CPU 时间片是耗费在了网络 IO 的同步处理上的，并没有充分的发挥出多核的优势。

如果能采用多线程，使得网络处理的请求并发进行，就可以大大的提升性能。多线程除了可以减少由于
网络 I/O 等待造成的影响，还可以充分利用 CPU 的多核优势。

Redis 6.0 只有在网络请求的接收和解析，以及请求后的数据通过网络返回给时，使用了多线程。

而数据读写操作还是由单线程来完成的，所以，这样就不会出现并发问题了。

Redis 6.0 的多线程是用多线程来处理数据的 **读写和协议解析** ，但是 Redis **执行命令** 还是单线程的。

这样做的目的是因为 Redis 的性能瓶颈在于网络 IO 而非 CPU，使用多线程能提升 IO 读写的效率，从而整
体提高 Redis 的性能。

#### 聊聊：Redis 有哪些数据结构？

字符串 String、字典 Hash、列表 List、集合 Set、有序集合 SortedSet。

如果你是 Redis 中高级用户，还需要加上下面几种数据结构 HyperLogLog、Geo、Pub/Sub。

如果你说还玩过 Redis Module，像 BloomFilter，RedisSearch，Redis-ML，面试官得眼睛就开始发亮
了。

#### 聊聊：使用过 Redis 分布式锁么，它是什么回事？


先拿 setnx 来争抢锁，抢到之后，再用 expire 给锁加一个过期时间防止锁忘记了释放。

这时候对方会告诉你说你回答得不错，然后接着问如果在 setnx 之后执行 expire 之前进程意外 crash 或者
要重启维护了，那会怎么样？

这时候你要给予惊讶的反馈：唉，是喔，这个锁就永远得不到释放了。

紧接着你需要抓一抓自己得脑袋，故作思考片刻，好像接下来的结果是你主动思考出来的，

然后回答：我记得 set 指令有非常复杂的参数，这个应该是可以同时把 setnx 和 expire 合成一条指令来用
的！

对方这时会显露笑容，心里开始默念：嗯，这小子还不错。

#### 聊聊：Redis 里面有 1 亿个 key，其中有 10 w 个 key 是以某个

#### 固定的已知的前缀开头的，如何将它们全部找出来？

使用 keys 指令可以扫出指定模式的 key 列表。

对方接着追问：

如果这个 redis 正在给线上的业务提供服务，那使用 keys 指令会有什么问题？

这个时候你要回答 redis 关键的一个特性：

redis 的单线程的。

keys 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢复。

这个时候可以使用 scan 指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定的重复
概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。

#### 聊聊：使用过 Redis 做异步队列么，你是怎么用的？

一般使用 list 结构作为队列，rpush 生产消息，lpop 消费消息。

当 lpop 没有消息的时候，要适当 sleep 一会再重试。

如果对方追问可不可以不用 sleep 呢？

list 还有个指令叫 blpop，在没有消息的时候，它会阻塞住直到消息到来。

如果对方追问能不能生产一次消费多次呢？

使用 pub/sub 主题订阅者模式，可以实现 1: N 的消息队列。

如果对方追问 pub/sub 有什么缺点？

在消费者下线的情况下，生产的消息会丢失，得使用专业的消息队列如 rabbitmq 等。

如果对方追问 redis 如何实现延时队列？

我估计现在你很想把面试官一棒打死如果你手上有一根棒球棍的话，怎么问的这么详细。

但是你很克制，然后神态自若的回答道：使用 sortedset，拿时间戳作为 score，消息内容作为 key 调用
zadd 来生产消息，

消费者用 zrangebyscore 指令获取 N 秒之前的数据轮询进行处理。


到这里，面试官暗地里已经对你竖起了大拇指。但是他不知道的是此刻你却竖起了中指，在椅子背后。

#### 聊聊：如果有大量的 key 需要设置同一时间过期，一般需要

#### 注意什么？

如果大量的 key 过期时间设置的过于集中，到过期的那个时间点，redis 可能会出现短暂的卡顿现象。

一般需要在时间上加一个随机值，使得过期时间分散一些。

#### 聊聊：Redis 如何做持久化的？

bgsave 做镜像 **全量持久化** ，

aof 做 **增量持久化** 。

因为 bgsave 会耗费较长时间，不够实时，在停机的时候会导致大量丢失数据，所以需要 AOF 来配合使
用。

在 redis 实例重启时，优先使用 AOF 来恢复内存的状态，如果没有 AOF 日志，就会使用 RDB 文件来恢复。

**bgsave 做全量持久化**

既然说 RDB 是 Redis 中数据集的时间点快照，在 Redis 内完成 RDB 持久化的方法有 rdbSave 和
rdbSaveBackground 两个函数方法（源码文件 rdb. c 中），先简单说下两者差别：

```
rdbSave：是同步执行的，方法调用后就会立刻启动持久化流程。由于Redis是单线程模型，持久
化过程中会阻塞，Redis无法对外提供服务；
rdbSaveBackground：是后台（异步）执行的，该方法会fork出子进程，真正的持久化过程是在
子进程中执行的（调用rdbSave），主进程会继续提供服务；
```
RDB 持久化的触发必然离不开以上两个方法，触发的方式分为手动和自动。

手动触发容易理解，是指我们通过 Redis 客户端人为的对 Redis 服务端发起持久化备份指令，然后 Redis
服务端开始执行持久化流程，

这里的指令有 save 和 **bgsave** 。

整个持久化的过程中，主进程不进行任何 io 操作，全程都有子进程来完成，这就确保了极高的性能。

如果需要进行大规模的数据恢复，且对数据恢复的完整性不是非常敏感，那么 rdb 方式要比 AOF 方式
更加的高效，rdb 的缺点是最后一次持久化的数据可能会丢失。


因为 bgsave 会耗费较长时间， **不够实时** ，在停机的时候会导致大量丢失数据，所以需要 aof 来配合使
用。

**aof 做增量持久化**

AOF 持久化全称 append only file，以日志形式记录每个写操作，将 redis 执行过得所有写操作指令记
录下来（读操作不记录）。

只许追加文件但不可以改写文件，redis 启动之初会读取该文件重新构建数据，换言之，redis 重启的话
就根据日志文件的内容将写操作指令从前到后执行一次以完成数据的恢复工作。

AOF 默认保存的是 appendonly. AOF 文件，此文件具有可读性。

AOF 的工作原理其实类似于 mysql 的 binlog 日志语句复制。是以日志的形式记录服务器所处理的每一
个写，删除操作，查询操作不会记录，以文本的方式进行记录，该文件具有可读性。

AOF 文件同步有三种同步策略：

修改同步、每秒同步、不主动调用 fsync 同步。

AOF 优缺点

AOF 利用 appendfsync 持久化机制，异步操作每秒记录，数据完整性要高于 rdb , 如果一秒宕机，有
可能丢失 1 秒数据。

相同的数据集而言 AOF 文件要远大于 rdb 文件。

恢复速度要慢于 rdb，AOF 运行效率要慢于 rdb。每秒同步策略效率较好，不同步效率和 rdb 相同。

在 redis 实例重启时，优先使用 aof 来恢复内存的状态，如果没有 aof 日志，就会使用 rdb 文件来恢复。

#### 聊聊：系统化的介绍一下，Redis 持久化的机制？

###### Redis 的持久化配置

**redis 的 rdb 和 aof 持久化的区别**

```
aof，rdb是两种 redis持久化的机制。用于crash后，redis的恢复。
```

redis 将数据保存在内存中，一旦 Redis 服务器被关闭，或者运行 Redis 服务的主机本身被关闭的话，储
存在内存里面的数据就会丢失

如果仅仅将 redis 用作缓存的话，那么这种数据丢失带来的问题并不是非常大，只需要重启机器，然后再
次将数据同步到缓存中就可以了

但如果将 redis 用作 DB 的话，那么因为一些原因导致数据丢失的情况就不能接受

Redis 的持久化就是将储存在内存里面的数据以文件形式保存硬盘里面，这样即使 Redis 服务端被关闭，
已经同步到硬盘里面的数据也不会丢失

除此之外，持久化也可以使 Redis 服务器重启时，通过载入同步的持久文件来还原之前的数据，或者使
用持久化文件来进行数据备份和数据迁移等工作

**RDB 持久化功能**

RDB 持久化功能可以将 Redis 中所有数据生成快照并以二进行文件的形式保存到硬盘里，文件名为. RDB
文件

在 Redis 启动时载入 RDB 文件，Redis 读取 RDB 文件内容，还原服务器原有的数据库数据

过程如下图所示：

Redis 服务端创建 RDB 文件，有三种方式

```
使用SAVE命令手动同步创建RDB文件
使用BGSAVE命令异步创建RDB文件
自动创建RDB文件
```
**使用 SAVE 命令手动同步创建 RDB 文件**

客户端向 Redis 服务端发送 SAVE 命令，服务端把当前所有的数据同步保存为一个 RDB 文件

**使用 BGSAVE 命令异步创建 RDB 文件**

执行 BGSAVE 命令也会创建一个新的 RDB 文件

BGSAVE 不会造成 redis 服务器阻塞：在执行 BGSAVE 命令的过程中，Redis 服务端仍然可以正常的处理其
他的命令请求

BGSAVE 命令执行步骤：

**自动创建 RDB 文件**

打开 Redis 的配置文件/etc/redis. conf


自动持久化配置解释：

```
save 900 1表示：如果距离上一次创建RDB文件已经过去的 900 秒时间内，Redis中的数据发生了 1
次改动，则自动执行BGSAVE命令
save 300 10表示：如果距离上一次创建RDB文件已经过去的 300 秒时间内，Redis中的数据发生了
10 次改动，则自动执行BGSAVE命令
save 60 10000表示：如果距离上一次创建RDB文件已经过去了 60 秒时间内，Redis中的数据发生
了 10000 次改动，则自动执行BGSAVE命令
当三个条件中的任意一个条件被满足时，Redis就会自动执行BGSAVE命令
```
**rdb 持久化的特性如下：**

fork 一个进程，遍历 hash table，利用 copy on write，把整个 db dump 保存下来。
save, shutdown, slave 命令会触发这个操作。
粒度比较大，如果 save, shutdown, slave 之前 crash 了，则中间的操作没办法恢复。

**AOF 的功能**

AOF 持久化保存数据库的方法是：每当有修改的数据库的命令被执行时，服务器就会将执行的命令写入
到 AOF 文件的末尾。

因为 AOF 文件里面储存了服务器执行过的所有数据库修改的命令，所以 Redis 只要重新执行一遍 AOF 文
件里面保存的命令，就可以达到还原数据库的目的

**AOF 安全性问题**

虽然服务器执行一次修改数据库的命令，执行的命令就会被写入到 AOF 文件，但这并不意味着 AOF 持久
化方式不会丢失任何数据

在 linux 系统中，系统调用 write 函数，将一些数据保存到某文件时，为了提高效率，系统通常不会直接
将内容写入硬盘里面，而是先把数据保存到硬盘的缓冲区之中。

等到缓冲区被填满，或者用户执行 fsync 调用和 fdatasync 调用时，操作系统才会将储存在缓冲区里的内
容真正的写入到硬盘里

对于 AOF 持久化来说，当一条命令真正的被写入到硬盘时，这条命令才不会因为停机而意外丢失

因此，AOF 持久化在遭遇停机时丢失命令的数量，取决于命令被写入硬盘的时间

越早将命令写入到硬盘，发生意外停机时丢失的数据就越少，而越迟将命令写入硬盘，发生意外停机时
丢失的数据就越多

**AOF 三种策略**

为了控制 Redis 服务器在遇到意外停机时丢失的数据量，Redis 为 AOF 持久化提供了 appendfsync 选项，
这个选项的值可以是 always, everysec 或者 no

```
appendfsync always：
总是写入aof文件，并通过事件循环磁盘同步，即使Redis遭遇意外停机时，最多只丢失一事件循
环内的执行的数据
appendfsync everysec：
每一秒写入aof文件，并完成磁盘同步，即使Redis遭遇意外停机时，最多只丢失一秒钟内的执行
的数据
```
```
1 save 900 1save 300 10save 60 10000
```

```
appendfsync no：
服务器不主动调用fdatasync,由操作系统决定任何将缓冲区里面的命令写入到硬盘里，这种模式
下，服务器遭遇意外停机时，丢失的命令的数量是不确定的
```
**AOF 三种方式比较**

运行速度：

```
always的速度慢，everysec和no都很快, always丢失的数据最少，但是硬盘IO开销很多，一般的
SATA硬盘一秒种只能写入几百次数据
everysec每秒同步一次数据，如果Redis发生故障，可能会丢失 1 秒钟的数据
no则系统控制，不可控，不知道会丢失多少数据
```
```
可见，从持久化角度讲，always是最安全的。
```
```
从效率上讲，no是最快的。而redis默认设置进行了折中，选择了everysec。合情合理。
```
**配置文件中 AOF 相关选项**

appendonly yes # 改为 yes，开启 AOF 功能
appendfilename "appendonly. aof" # 生成的 AOF 的文件名
appendfsync everysec # AOF 同步的策略
no-appendfsync-on-rewrite yes # AOF 重写时，是否做 append 的操作, yes 是不做，在 rewrite 期
间的 AOF 有丢失的风险。

**配置文件中 AOF 相关选项**

```
建议把appendfsync选项设定为everysec，进行持久化，这种情况下Redis宕机最多只会丢失一秒
钟的数据
如果使用Redis做为缓存时，即使数据丢失也不会造成任何影响，只需要在下次加载时重新从数据
源加载就可以了
不要占用100%的内存。一般分配服务器60%到70%的内存给Redis使用，剩余的内存分留给类似
fork的操作
```
**aof 与 rdb 持久化的区别：**

把写操作指令，持续的写到一个类似日志文件里。（类似于从 postgresql 等数据库导出 sql 一样，只记录
写操作）
粒度较小，crash 之后，只有 crash 之前没有来得及做日志的操作没办法恢复。

两种区别就是，

```
一个是持续的用日志记录写操作，crash后利用日志恢复；
一个是平时写操作的时候不触发写，只有手动提交save命令，或者是关闭命令时，才触发备份操
作。
```
选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），还是愿意写操作频繁
的时候，不启用备份来换取更高的性能，待手动运行 save 的时候，再做备份（rdb）。

rdb 这个就更有些 eventually consistent 的意思了。

#### 聊聊：Redis 持久化的方式


**1 、RDB（Redis DataBase）持久化**

RDB 是 Redis 中默认的持久化机制，按照一定的时间将内存中的数据以快照的方式保存到磁盘中，

它会产生一个特殊类型的文件 .rdb 文件，同时可以通过配置文件中的 save 参数来定义快照的周期

在 RDB 中有两个核心概念 fork 和 cow，在执行备份的流程如下：

在执行 bgsave 的时候，Redis 会 fork 主进程得到一个新的子进程，子进程是共享主进程内存数据的，
会将数据写到磁盘上的一个临时的 .rdb 文件中，当子进程写完临时文件后，会将原来的 .rdb 文件替
换掉，这个就是 fork 的概念。那 cow 全称是 copy-on-write ，当主进程执行读操作的时候是访问共享
内存的，而主进程执行写操作的时候，则会拷贝一份数据，执行写操作。

**优点**

```
1. 只有一个文件 dump.rdb ，方便持久化
2. 容错性好，一个文件可以保存到安全的磁盘
3. 实现了性能最大化，fork 单独子进程来完成持久化，让主进程继续处理命令，主进程不进行任何
I/O 操作，从而保证了Redis的高性能
4. RDB 是一个紧凑压缩的二进制文化，RDB重启时的加载效率比AOF持久化更高，在数据量大时更
明显
```
**缺点**

```
1. 可能出现数据丢失，在两次RDB持久化的时间间隔中，如果出现宕机，则会丢失这段时间中的数据
2. 由于RDB是通过fork子进程来协助完成数据持久化，如果当数据集较大时，可能会导致整个服务器
间歇性暂停服务
```
**2 、AOF（Append Only File）持久化**

AOF 全称是 Append Only File（追加文件）。

当 Redis 处理每一个写命令都会记录在 AOF 文件中，可以看做是命令日志文件。该方式需要设置 AOF
的同步选项，因为对文件进行写入并不会马上将内容同步到磁盘上，而是先存储到缓冲区中，

同步选项有三种配置项选择：

```
always：同步刷盘，可靠性高，但性能影响较大
everysec：每秒刷盘，性能适中，最多丢失 1 秒的数据
no：操作系统控制，性能最好，可靠性最差
```
为了解决 AOF 文件体检不断增大的问题，用户可以向 Redis 发送 bgrewriteaof 命令，可以将 AOF
文件进行压缩，也可以选择自动触发，在配置文件中配置

**优点**

```
1. 实现持久化，数据安全，AOF持久化可以配置 appendfsync 属性为 always，每进行一次命令操作
就记录到AOF文件中一次，数据最多丢失一次
2. 通过 append 模式写文件，即使中途服务器宕机，可以通过 Redis-check-aof 工具解决数据一致性
问题
3. AOF 机制的 rewrite 模式。AOF 文件的文件大小触碰到临界点时，rewrite 模式会被运行，重写内
存中的所有数据，从而缩小文件体积
```
**缺点**

```
1. AOF 文件大，通常比 RDB 文件大很多
```
```
auto-aof-rewrite-precentage 100
auto-aof-rewrite-min-zise 64mb
```
```
1
2
```

```
2. 比 RDB 持久化启动效率低，数据集大的时候较为明显
3. AOF 文件体积可能迅速变大，需要定期执行重写操作来降低文件体积
```
#### 聊聊：RDB 和 AOF 如何选择？

一般来说，如果想达到足以媲美数据库的 **数据安全性** ，应该 **同时使用两种持久化功能** 。

在这种情况下，当 Redis 重启的时候会优先载入 AOF 文件来恢复原始的数据，因为在通常情况下 AOF
文件保存的数据集要比 RDB 文件保存的数据集要完整。

如果 **可以接受数分钟以内的数据丢失** ，那么可以 **只使用 RDB 持久化** 。

有很多用户都只使用 AOF 持久化，但并不推荐这种方式，因为定时生成 RDB 快照（snapshot）非常便
于进行数据备份，

并且 RDB 恢复数据集的速度也要比 AOF 恢复的速度要快。

如果只需要数据在服务器运行的时候存在，也可以不使用任何持久化方式。

#### 聊聊：RDB 和 AOF 各自有什么优缺点？

**RDB 优点**

```
1. 只有一个紧凑的二进制文件 dump.rdb，非常适合备份、全量复制的场景。
2. 容灾性好 ，可以把RDB文件拷贝道远程机器或者文件系统张，用于容灾恢复。
3. 恢复速度快 ，RDB恢复数据的速度远远快于AOF的方式
```
**RDB 缺点**

```
1. 实时性低 ，RDB 是间隔一段时间进行持久化，没法做到实时持久化/秒级持久化。如果在这一间隔
事件发生故障，数据会丢失。
2. 存在兼容问题 ，Redis演进过程存在多个格式的RDB版本，存在老版本Redis无法兼容新版本RDB
的问题。
```
**AOF 优点**

```
1. 实时性好 ，aof 持久化可以配置 appendfsync 属性，有 always，每进行一次命令操作就记录到
aof 文件中一次。
2. 通过 append 模式写文件，即使中途服务器宕机，可以通过 redis-check-aof 工具解决数据一致性
问题。
```
**AOF 缺点**

```
1. AOF 文件比 RDB 文件大 ，且 恢复速度慢 。
2. 数据集大 的时候，比 RDB 启动效率低 。
```

#### 聊聊：redis 持久存储 RDB 和 AOF 的区别及优缺点

由于 Redis 的数据都存放在内存中，如果没有配置持久化，redis 重启后数据就全丢失了，

于是需要开启 redis 的持久化功能，将数据保存到磁盘上，当 redis 重启后，可以从磁盘中恢复数据。

redis 提供两种方式进行持久化，

一种是 RDB 持久化（原理是将 Reids 在内存中的数据库记录定时 dump 到磁盘上的 RDB 持久化），

另外一种是 AOF 持久化（原理是将 Reids 的操作日志以追加的方式写入文件）。

**二者的区别**

RDB 持久化是指在指定的时间间隔内将内存中的数据集快照写入磁盘，实际操作过程是 fork 一个子进
程，先将数据集写入临时文件，写入成功后，再替换之前的文件，用二进制压缩存储。

AOF 持久化以日志的形式记录服务器所处理的每一个写、删除操作，查询操作不会记录，以文本的方式
记录，可以打开文件看到详细的操作记录。

**二者优缺点**

RDB 存在哪些优势呢？

1). 一旦采用该方式，那么你的整个 Redis 数据库将只包含一个文件，这对于文件备份而言是非常完美
的。比如，你可能打算每个小时归档一次最近 24 小时的数据，同时还要每天归档一次最近 30 天的数据。
通过这样的备份策略，一旦系统出现灾难性故障，我们可以非常容易的进行恢复。

2). 对于灾难恢复而言，RDB 是非常不错的选择。因为我们可以非常轻松的将一个单独的文件压缩后再
转移到其它存储介质上。

3). 性能最大化。对于 Redis 的服务进程而言，在开始持久化时，它唯一需要做的只是 fork 出子进程，之
后再由子进程完成这些持久化的工作，这样就可以极大的避免服务进程执行 IO 操作了。

4). 相比于 AOF 机制，如果数据集很大，RDB 的启动效率会更高。

RDB 又存在哪些劣势呢？

1). 如果你想保证数据的高可用性，即最大限度的避免数据丢失，那么 RDB 将不是一个很好的选择。因
为系统一旦在定时持久化之前出现宕机现象，此前没有来得及写入磁盘的数据都将丢失。

2). 由于 RDB 是通过 fork 子进程来协助完成数据持久化工作的，因此，如果当数据集较大时，可能会导致
整个服务器停止服务几百毫秒，甚至是 1 秒钟。

AOF 的优势有哪些呢？

1). 该机制可以带来更高的数据安全性，即数据持久性。Redis 中提供了 3 中同步策略，即每秒同步、每
修改同步和不同步。事实上，每秒同步也是异步完成的，其效率也是非常高的，所差的是一旦系统出现
宕机现象，那么这一秒钟之内修改的数据将会丢失。而每修改同步，我们可以将其视为同步持久化，即
每次发生的数据变化都会被立即记录到磁盘中。可以预见，这种方式在效率上是最低的。至于无同步，
无需多言，我想大家都能正确的理解它。

2). 由于该机制对日志文件的写入操作采用的是 append 模式，因此在写入过程中即使出现宕机现象，也
不会破坏日志文件中已经存在的内容。然而如果我们本次操作只是写入了一半数据就出现了系统崩溃问
题，不用担心，在 Redis 下一次启动之前，我们可以通过 redis-check-aof 工具来帮助我们解决数据一致
性的问题。

3). 如果日志过大，Redis 可以自动启用 rewrite 机制。即 Redis 以 append 模式不断的将修改数据写入到老
的磁盘文件中，同时 Redis 还会创建一个新的文件用于记录此期间有哪些修改命令被执行。因此在进行
rewrite 切换时可以更好的保证数据安全性。


4). AOF 包含一个格式清晰、易于理解的日志文件用于记录所有的修改操作。事实上，我们也可以通过该
文件完成数据的重建。

**AOF 的劣势有哪些呢？**

1). 对于相同数量的数据集而言，AOF 文件通常要大于 RDB 文件。RDB 在恢复大数据集时的速度比 AOF
的恢复速度要快。

2). 根据同步策略的不同，AOF 在运行效率上往往会慢于 RDB。总之，每秒同步策略的效率是比较高的，
同步禁用策略的效率和 RDB 一样高效。

###### 二者选择的标准，

二者选择的标准，就是看系统是愿意牺牲一些性能，换取更高的缓存一致性（aof），

还是愿意写操作频繁的时候，不启用备份来换取更高的性能，待手动运行 save 的时候，再做备份
（rdb）。

rdb 这个就更有些 eventually consistent 的意思了。不过生产环境其实更多都是二者结合使用的。

###### 常用配置

**RDB 持久化配置**

Redis 会将数据集的快照 dump 到 dump. rdb 文件中。

此外，我们也可以通过配置文件来修改 Redis 服务器 dump 快照的频率，在打开 6379. conf 文件之后，我
们搜索 save，可以看到下面的配置信息：

**AOF 持久化配置**

在 Redis 的配置文件中存在三种同步方式，它们分别是：

#### 聊聊：如果突然机器掉电会怎样？

取决于 aof 日志 sync 属性的配置，如果不要求性能，在每条写指令时都 sync 一下磁盘，就不会丢失数
据。

```
save 900 1 #在 900 秒(15分钟)之后，如果至少有 1 个key发生变化，则dump内存快照。
```
```
save 300 10 #在 300 秒(5分钟)之后，如果至少有 10 个key发生变化，则dump内存快照。
```
```
save 60 10000 #在 60 秒(1分钟)之后，如果至少有 10000 个key发生变化，则dump内存快照。
```
```
1
2
3
4
5
```
```
appendfsync always #每次有数据修改发生时都会写入AOF文件。
```
```
appendfsync everysec #每秒钟同步一次，该策略为AOF的缺省策略。
```
```
appendfsync no #从不同步。高效但是数据不会被持久化。
```
```
1
2
3
4
5
```

但是在高性能的要求下每次都 sync 是不现实的，一般都使用定时 sync，比如 1 s 1 次，这个时候最多就会
丢失 1 s 的数据。

#### 聊聊：Redis 的数据恢复？

当 Redis 发生了故障，可以从 RDB 或者 AOF 中恢复数据。

恢复的过程也很简单，把 RDB 或者 AOF 文件拷贝到 Redis 的数据目录下，如果使用 AOF 恢复，配置文件
开启 AOF，然后启动 redis-server 即可。

**Redis 的数据恢复优先级**

```
1. 如果只配置 AOF ，重启时加载 AOF 文件恢复数据；
2. 如果同时配置了 RDB 和 AOF ，启动只加载 AOF 文件恢复数据；
3. 如果只配置 RDB，启动将加载 dump文件恢复数据。
```
**Redis** 启动时加载数据的流程：

```
1. AOF持久化开启且存在AOF文件时，优先加载AOF文件。
2. AOF关闭或者AOF文件不存在时，加载RDB文件。
3. 加载AOF/RDB文件成功后，Redis启动成功。
4. AOF/RDB文件存在错误时，Redis启动失败并打印错误信息。
```
**新型的混合型持久化**

RDB 和 AOF 都有各自的缺点：

```
1. RDB是每隔一段时间持久化一次, 故障时就会丢失宕机时刻与上一次持久化之间的数据，无法保证
数据完整性
2. AOF存储的是指令序列, 恢复重放时要花费很长时间并且文件更大
```
Redis 4.0 提供了更好的混合持久化选项：

创建出一个同时包含 RDB 数据和 AOF 数据的 AOF 文件，其中 RDB 数据位于 AOF 文件的开头，它们
储存了服务器开始执行重写操作时的数据库状态，

至于那些在重写操作执行之后执行的 Redis 命令，则会继续以 AOF 格式追加到 AOF 文件的末尾，也
即是 RDB 数据之后。


**持久化实战**

在实际使用中需要根据 Redis 作为主存还是缓存、数据完整性和缺失性的要求、CPU 和内存情况等诸多
因素来确定适合自己的持久化方案，一般来说稳妥的做法包括：

```
1. 最安全的做法是RDB与AOF同时使用，即使AOF损坏无法修复，还可以用RDB来恢复数据，当然在
持久化时对性能也会有影响。
2. Redis当简单缓存，没有缓存也不会造成缓存雪崩只使用RDB即可。
3. 不推荐单独使用AOF，因为AOF对于数据的恢复载入比RDB慢，所以使用AOF的时候，最好还是有
RDB作为备份。
4. 采用新版本Redis 4.0的持久化新方案。
```
#### 聊聊：为什么恢复的时候 RDB 比 AOF 快？

AOF，存放的指令日志，做数据恢复的时候，其实是要回放和执行所有的指令日志，来恢复出来内存中
的所有数据的；
RDB，就是一份数据文件，恢复的时候，直接加载到内存中即可；

RDB 持久化的时候，Redis 主进程只需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化
即可；

（ 1 ）RDB 对 Redis 对外提供的读写服务，影响非常小，可以让 Redis 保持高性能，因为 Redis 主进程只需
要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可;

RDB 每次写，都是直接写 Redis 内存，只是在一定的时候，才会将数据写入磁盘中；

AOF，每次都是要写文件的，虽然可以快速写入 os cache 中，但是还是有一定的时间开销的，速度肯定
比 RDB 略慢一些;

（ 2 ）RDB 使用单独子进程来进行持久化，主进程不会进行任何 IO 操作，保证了 Redis 的高性能；

#### 聊聊：RDB 的缺点

（ 1 ）如果想要在 Redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。


一般来说，RDB 数据快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 Redis
进程宕机，那么会丢失最近 5 分钟的数据；

这个问题，也是 RDB 最大的缺点，就是不适合做第一优先的恢复方案，如果你依赖 RDB 做第一优先恢复
方案，会导致数据丢失的比较多;

（ 2 ）RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导致
对客户端提供的服务暂停数毫秒，或者甚至数秒；

一般不要让 RDB 的间隔太长，否则每次生成的 RDB 文件太大了，对 Redis 本身的性能可能会有影响的；

（ 3 ）RDB 无法实现实时或者秒级持久化

RDB 是间隔一段时间进行持久化，如果持久化之间 Redis 发生故障，会发生数据丢失。

#### 聊聊：aof 文件过大恢复时间过长怎么办

如果再问 aof 文件过大恢复时间过长怎么办？

你告诉面试官，Redis 会定期做 aof 重写，压缩 aof 文件日志大小。

#### 聊聊：什么是 AOF 重写？AOF 重写为何会出现 Redis 主进程

#### 阻塞，应用端响应超时的问题？

###### 问题背景

```
某个业务线使用Redis集群保存用户session数据，数据量大约在 4 千万-5千万，每天发生3-4次
AOF重写，每次时间持续30-40秒，AOF重写期间出现Redis主进程阻塞，应用端响应超时的问
题。
```
环境：Redis 2.8，一主一从。


###### 什么是 AOF 重写

AOF 重写是 AOF 持久化的一个机制，用来压缩 AOF 文件。

```
随着服务器的不断运行，为了记录Redis中数据的变化，Redis会将越来越多的命令写入到AOF文
件中，使得AOF文件的体积来断增大
```
为了让 AOF 文件的大小控制在合理的范围，redis 提供了 AOF 重写功能，通过这个功能，服务器可以产生
一个新的 AOF 文件：

```
新的AOF文件记录的数据库数据和原有AOF文件记录的数据库数据完全一样
新的AOF文件会使用尽可能少的命令来记录数据库数据，因此新的AOF文件的体积通常会比原有
AOF文件的体积要小得多
AOF重写期间，服务器不会被阻塞，可以正常处理客户端发送的命令请求
```
AOF 重写功能就是把 Redis 中过期的，不再使用的，重复的以及一些可以优化的命令进行优化，重新生
成一个新的 AOF 文件，从而达到减少硬盘占用量和加速 Redis 恢复速度的目的

###### AOF 重写的目的

Redis 的 rewrite 策略，实现 AOF 文件的减肥，但是结果是幂等的

###### AOF 重写的流程

Redis 通过 fork 一个子进程，重新写一个新的 AOF 文件，该次重写不是读取旧的 AOF 文件进行复制，而是
读取内存中的 Redis 数据库，重写一份 AOF 文件，有点类似于 RDB 的快照方式。

在子进程进行 AOF 重写期间，Redis 主进程执行的命令会被保存在 AOF 重写缓冲区里面，这个缓冲区在
服务器创建子进程之后开始使用，当 Redis 执行完一个写命令之后，它会同时将这个写命令发送给 AOF
缓冲区和 AOF 重写缓冲区。如下图：


具体的步骤如下：

1. 无论是执行 bgrewriteaof 命令手动开启重写，还是自动进行 AOF 重写，实际上都是执行
BGREWRITEAOF 命令
2. 执行 bgrewriteaof 命令, Redis 会 fork 一个子进程，
3. 子进程对内存中的 Redis 数据进行回溯，生成新的 AOF 文件
4. Redis 主进程会处理正常的命令操作
5. 同时 Redis 把会新的命令写入到 aof_rewrite_buf 当中，当 bgrewriteaof 命令执行完成，新的 AOF 文件
生成完毕，Redis 主进程会把 aof_rewrite_buf 中的命令追加到新的 AOF 文件中
6. 用新生成的 AOF 文件替换旧的 AOF 文件


###### AOF 重写导致主进程阻塞原因分析

当 AOF 重写子进程完成 AOF 重写工作之后，它会向父进程发送一个信号，父进程在接收到该信号之后，
会调用一个信号处理函数，并执行以下工作：

```
将AOF重写缓冲区中的所有内容写入到新的AOF文件中，保证新 AOF文件保存的数据库状态和服务
器当前状态一致。
对新的AOF文件进行改名，原子地覆盖现有AOF文件，完成新旧文件的替换
继续处理客户端请求命令。
```
现在问题出现了，同时在执行 bgrewriteaof 操作和主进程写 aof 文件的操作，两者都会操作磁盘，

特别需要注意的是：

```
bgrewriteaof往往会涉及大量磁盘操作，这样就会造成主进程在写aof文件的时候，出现阻塞的情
形，导致主进程阻塞。
```
###### 根因分析与解决方案

这是当时的 Redis 配置：


从配置看，原因理论上就很清楚了：

```
我们的这个Redis实例使用AOF进行持久化(appendonly)
appendfsync策略采用的是everysec刷盘。
```
但是 AOF 随着时间推移，文件会越来越大，因此，Redis 自动启动一个 rewrite 策略，实现 AOF 文件的减
肥，但是结果是幂等的

```
no-appendfsync-on-rewrite的策略是 no，这就会导致在进行rewrite操作时，appendfsync会写
入aof文件而可能被阻塞。
```
这不是什么新问题，很多开启 AOF 的业务场景都会遇到这个问题。

解决的办法有这么几个：

```
将no-appendfsync-on-rewrite设置为yes.
```
yes 表示在日志 AOF 重写时，不进行 aof 文件命令追加操作，而只是将命令放在重写缓冲区里，避免与命
令的追加造成磁盘 IO 造成的阻塞。但是在 rewrite 期间的 AOF 有丢失的风险。

```
给当前Redis实例添加slave节点，当前节点设置为master, 然后master节点关闭AOF，slave节点
开启AOF。
```
```
这样的方式的风险是如果master挂掉，尚没有同步到slave的数据会丢失。
```
比较折中的方式：

```
在master节点设置将no-appendfsync-on-rewrite设置为yes，注意，还有后手，就是停止自动aof
重写，如何停止，将auto-aof-rewrite-percentage参数设置为 0 ，关闭主动重写
```
```
auto-aof-rewrite-percentage 参数说明
aof文件增长比例，指当前aof文件比上次重写的增长比例大小。aof重写即在aof文件在一定
大小之后，重新将整个内存写到aof文件当中，以反映最新的状态(相当于bgsave)。这样就避
免了，aof文件过大而实际内存数据小的问题(频繁修改数据问题).
```
```
为了防止AOF文件越来越大，在任务调度配置在凌晨低峰期定时手动执行bgrewriteaof命令完成每
日一次的AOF重写
在重写时为了避免硬盘空间不足或者IO使用率高影响重写功能添加了硬盘空间报警和IO使用率报
警保障重写的正常进行
```
#### 聊聊：Redis 4.0 的混合持久化了解吗？

重启 Redis 时，我们很少使用 RDB 来恢复内存状态，因为会丢失大量数据。

我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 RDB 来说要慢很多，这样在 Redis 实例很
大的情况下，启动需要花费很长的时间。

```
127.0.0.1:6379> config get *append*
1) "no-appendfsync-on-rewrite"
2) "no"
3) "appendonly"
4) "yes"
5) "appendfsync"
6) "everysec"
```
```
1 2 3 4 5 6 7
```

**Redis 4.0** 为了解决这个问题，带来了一个新的持久化选项—— **混合持久化** 。

将 rdb 文件的内容和增量的 AOF 日志文件存在一起。

这里的 AOF 日志不再是全量的日志，而是 **自持久化开始到持久化结束** 的这段时间发生的增量 AOF 日
志，通常这部分 AOF 日志很小：

于是在 Redis 重启的时候，可以先加载 rdb 的内容，然后再重放增量 AOF 日志就可以完全替代之前的
AOF 全量文件重放，重启效率因此大幅得到提升。

#### 聊聊：为什么 Redis 不能保证 100%数据不丢失？

Redis 能否保证 100%数据不丢失，答案是 no。

哪怕是在要求最高的持久化配置场景，将 appendfsync 值设置为 always，其实也会产生数据丢失。

```
尽管，很多博客都讲，将appendfsync值设置为always，Redis能保证100%数据不丢失，可能会
打脸了。
```
###### 图解：redis 的事件循环

```
void aeMain(aeEventLoop *eventLoop) {
eventLoop->stop = 0;
while (!eventLoop->stop) {
if (eventLoop->beforesleep != NULL)
eventLoop->beforesleep(eventLoop);
aeProcessEvents(eventLoop, AE_ALL_EVENTS);
}
}
```
```
1 2 3 4 5 6 7 8
```

###### flushAppendOnlyFile 的时机分析

一个 while 循环，我们把这个循环叫做事件循环，从写盘的角度来说：

```
第N+1轮循环的第一阶段，调用flushAppendOnlyFile 的，会将aof buffer写到磁盘上。
第N轮循环的第二阶段，将读取到的命令，写入aof buffer，而不是直接落盘
```
所以：

redis 即使在配制 appendfsync=always 的策略下，还是会可能丢失一个事件循环的 aof_buf 数据，

#### 聊聊： Pipeline 有什么好处，为什么要用 pipeline？

可以将多次 IO 往返的时间缩减为一次，前提是 pipeline 执行的指令之间没有因果相关性。

使用 redis-benchmark 进行压测的时候可以发现影响 redis 的 QPS 峰值的一个重要因素是 pipeline 批次指
令的数目。

#### 聊聊： Redis 的主从同步机制了解么？

Redis 可以使用主从同步，从从同步。

第一次同步时，主节点做一次 bgsave，并同时将后续修改操作记录到内存 buffer，待完成后将 RDB 文件
全量同步到复制节点，复制目标节点接受完成后将 RDB 镜像加载到内存。

加载完成后，再通知主节点将期间修改的操作记录同步到复制节点，进行重放就完成了同步过程。

后续的增量数据通过 AOF 日志同步即可，有点类似数据库的 binlog


#### 聊聊：说说主从数据同步的方式？

Redis 在 2.8 及以上版本使用 psync 命令完成主从数据同步，

主从数据同步的方式分为：全量复制和部分复制。

**全量复制** 一般用于初次复制场景，Redis 早期支持的复制功能只有全量复制，它会把主节点全部数据一
次性发送给从节点，当数据量较大时，会对主从节点和网络造成很大的开销。

全量复制的完整运行流程如下：


1. 发送 psync 命令进行数据同步，由于是第一次进行复制，从节点没有复制偏移量和主节点的运行
ID，所以发送 psync-1。
2. 主节点根据 psync-1 解析出当前为全量复制，回复+FULLRESYNC 响应。
3. 从节点接收主节点的响应数据保存运行 ID 和偏移量 offset
4. 主节点执行 bgsave 保存 RDB 文件到本地
5. 主节点发送 RDB 文件给从节点，从节点把接收的 RDB 文件保存在本地并直接作为从节点的数据文件
6. 对于从节点开始接收 RDB 快照到接收完成期间，主节点仍然响应读写命令，因此主节点会把这期间
写命令数据保存在复制客户端缓冲区内，当从节点加载完 RDB 文件后，主节点再把缓冲区内的数据
发送给从节点，保证主从之间数据一致性。
7. 从节点接收完主节点传送来的全部数据后会清空自身旧数据
8. 从节点清空数据后开始加载 RDB 文件
9. 从节点成功加载完 RDB 后，如果当前节点开启了 AOF 持久化功能，它会立刻做 bgrewriteaof 操
作，为了保证全量复制后 AOF 持久化文件立刻可用。


**部分复制** 部分复制主要是 Redis 针对全量复制的过高开销做出的一种优化措施，使用 psync{runId}
{offset}命令实现。当从节点（slave）正在复制主节点 （master）时，如果出现网络闪断或者命令丢
失等异常情况时，从节点会向主节点要求补发丢失的命令数据，如果主节点的复制积压缓冲区内存在这
部分数据则直接发送给从节点，这样就可以保持主从节点复制的一致性。

```
1. 当主从节点之间网络出现中断时，如果超过repl-timeout时间，主节点会认为从节点故障并中断复
制连接
2. 主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内
部存在的复制积压缓冲区，依然可以保存最近一段时间的写命令数据，默认最大缓存1MB。
3. 当主从节点网络恢复后，从节点会再次连上主节点
4. 当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行ID。因此会把它
们当作psync参数发送给主节点，要求进行部分复制操作。
5. 主节点接到psync命令后首先核对参数runId是否与自身一致，如果一 致，说明之前复制的是当前
主节点；之后根据参数offset在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，
则对从节点发送+CONTINUE响应，表示可以进行部分复制。
6. 主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。
```
下面的流程图，也是类似的。


#### 聊聊：详细介绍一下 redis 主从复制核心流程

```
主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。
```
```
what is 主从复制? ，是指将一台Redis服务器的数据，复制到其他的Redis服务器。
前者称为主节点(master)，后者称为从节点(slave)；
数据的复制是单向的，只能由主节点到从节点。
默认情况下，每台Redis服务器都是主节点；
且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。
```
###### 主从复制的作用

主从复制的作用主要包括：

```
1. 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。
2. 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服
务的冗余。
3. 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务
（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其
是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。
4. 高可用、高并发基石：主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用
的基础。
```
###### 开启主从复制的方式

需要注意， **主从复制的开启，完全是在从节点发起的；不需要我们在主节点做任何事情。**


从节点开启主从复制，有 3 种方式：

（ 1 ）配置文件

在从服务器的配置文件中加入：slaveof

（ 2 ）启动命令

redis-server 启动命令后加入 --slaveof

（ 3 ）客户端命令

Redis 服务器启动后，直接通过客户端执行命令：slaveof ，则该 Redis 实例成为从节点。

上述 3 种方式是等效的，下面以客户端命令的方式为例，看一下当执行了 slaveof 后，Redis 主节点和从
节点的变化。

###### 主从复制实例

**准备工作：启动两个节点**

实验所使用的主从节点是在一台机器上的不同 Redis 实例，其中：

```
主节点监听 6379 端口，
从节点监听 6380 端口；
从节点监听的端口号可以在配置文件中修改：
```
启动后可以看到：

两个 Redis 节点启动后（分别称为 6379 节点和 6380 节点），默认都是主节点。

**建立复制关系**

此时在 6380 节点执行 slaveof 命令，使之变为从节点：

**观察效果**

下面验证一下，在主从复制建立后，主节点的数据会复制到从节点中。

（ 1 ）首先在从节点查询一个不存在的 key：

（ 2 ）然后在主节点中增加这个 key：

（ 3 ）此时在从节点中再次查询这个 key，会发现主节点的操作已经同步至从节点：


（ 4 ）然后在主节点删除这个 key：

（ 5 ）此时在从节点中再次查询这个 key，会发现主节点的操作已经同步至从节点：

###### 断开复制

通过 slaveof 命令建立主从复制关系以后，可以通过 slaveof no one 断开。需要注意的是，从节点断开
复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。

从节点执行 slaveof no one 后，打印日志如下所示；

可以看出断开复制后，从节点又变回为主节点。

断开复制后，主节点打印日志如下：

###### 主从复制的核心原理

1 当启动一个 slave node 的时候，它会发送一个 PSYNC 命令给 master node。

2 如果这是 slave node 初次连接到 master node，那么会触发一次 full resynchronization 全量复制。

master node 怎么进行 full resynchronization 全量复制？

```
此时 master 会启动一个后台线程，开始生成一份 RDB 快照文件，同时还会将从客户端 client 新
收到的所有写命令缓存在内存中。
RDB 文件生成完毕后， master 会将这个 RDB 发送给 slave，
```
slave node 接收到 RDB ，干啥呢？

```
会先写入本地磁盘，然后再从本地磁盘加载到内存中，
```
3 数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段 master 将自己执行的写命令发送给
从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。

4 部分复制。如果 slave node 跟 master node 有网络故障，断开了连接，会自动重连，连接之后
master node 仅会复制给 slave 部分缺少的数据。


###### 主从复制的核心流程

主从复制过程大体可以分为 3 个阶段：

```
连接建立阶段（即准备阶段）
数据同步阶段
命令传播阶段
```
下面分别进行介绍。

###### phrase 1：连接建立阶段

该阶段的主要作用是在主从节点之间建立连接，为数据同步做好准备。

**步骤 1 ：保存主节点信息**

从节点服务器内部维护了两个字段，即 masterhost 和 masterport 字段，用于存储主节点的 ip 和 port 信
息。

```
需要注意的是， slaveof 是异步命令，从节点完成主节点 ip 和port 的保存后，向发送slaveof 命令
的客户端直接返回OK，实际的复制操作在这之后才开始进行。
```
这个过程中，可以看到从节点打印日志如下：

**步骤 2 ：建立 socket 连接**

slave 从节点每秒 1 次调用复制定时函数 replicationCron ()，如果发现了有主节点可以连接，便会根据主
节点的 ip 和 port，创建 socket 连接。

如果连接成功，则：

```
从节点:
```
为该 socket 建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收 RDB 文件、接
收命令传播等。

```
主节点：
```
接收到从节点的 socket 连接后（即 accept 之后），为该 socket 创建相应的客户端状态， **并将从节点看做
是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。**

这个过程中，从节点打印日志如下：


**步骤 3 ：发送 ping 命令**

从节点成为主节点的客户端之后，发送 ping 命令进行首次请求，目的是：检查 socket 连接是否可用，以
及主节点当前是否能够处理请求。

从节点发送 ping 命令后，可能出现 3 种情况：

（ 1 ）返回 pong：说明 socket 连接正常，且主节点当前可以处理请求，复制过程继续。

（ 2 ）超时：一定时间后从节点仍未收到主节点的回复，说明 socket 连接不可用，则从节点断开 socket
连接，并重连。

（ 3 ）返回 pong 以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前
无法处理命令，则从节点断开 socket 连接，并重连。

在主节点返回 pong 情况下，从节点打印日志如下：

**步骤 4 ：身份验证**

如果从节点中设置了 masterauth 选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不
需要验证。

从节点进行身份验证是通过向主节点发送 auth 命令进行的，auth 命令的参数即为配置文件中的 master
auth 的值。

```
则身份验证通过，复制过程继续；
如果不一致，则从节点断开socket连接，并重连。
```
**步骤 5 ：发送从节点端口信息**

身份验证之后，从节点会向主节点发送其监听的端口号（前述例子中为 6380 ），主节点将该信息保存到
该从节点对应的客户端的 slave_listening_port 字段中；

该端口信息除了在主节点中执行 info Replication 时显示以外，没有其他作用。

###### phrase 2：数据同步阶段

主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。

```
具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。
```
数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复
制。

在 Redis 2.8 以前，从节点向主节点发送 sync 命令请求同步数据，此时的同步方式是全量复制；

在 Redis 2.8 及以后，从节点可以发送 psync 命令请求同步数据，此时根据主从节点当前状态的不同，同
步方式可能是全量复制或部分复制。后文介绍以 Redis 2.8 及以后版本为例。


```
1. 全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节
点，是一个非常重型的操作。
2. 部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全
量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中
断期间执行的写命令，则无法进行部分复制，仍使用全量复制。
```
**全量复制的过程**

Redis 通过 psync 命令进行全量复制的过程如下：

（ 1 ）从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，
但主节点判断无法进行部分复制；

（ 2 ）主节点收到全量复制的命令后，执行 bgsave，在后台生成 RDB 文件，并使用一个缓冲区（称为复
制缓冲区）记录从现在开始执行的所有写命令

（ 3 ）主节点的 bgsave 执行完成后，将 RDB 文件发送给从节点； **从节点接收完成之后，首先清除自己的
旧数据，然后载入接收的 RDB** 文件，将数据库状态更新至主节点执行 bgsave 时的数据库状态

（ 4 ）主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态
更新至主节点的最新状态

（ 5 ）如果从节点开启了 AOF，则会触发 bgrewriteaof 的执行，从而保证 AOF 文件更新至主节点的最新
状态

下面是执行全量复制时，主从节点打印的日志；可以看出日志内容与上述步骤是完全对应的。

主节点的打印日志如下：

从节点打印日志如下图所示：

其中，有几点需要注意：

```
从节点接收了来自主节点的 89260 个字节的数据；
从节点在载入主节点的数据之前要先将老数据清除；
从节点在同步完数据后，调用了bgrewriteaof。
```

通过全量复制的过程可以看出，全量复制是非常重型的操作：

（ 1 ）性能损耗：主节点通过 bgsave 命令 fork 子进程进行 RDB 持久化，该过程是非常消耗 CPU、内存 (页
表复制)、硬盘 IO 的；

（ 2 ）带宽占用：主节点通过网络将 RDB 文件发送给从节点，对主从节点的带宽都会带来很大的消耗

（ 3 ）停服载入：从节点清空老数据、载入新 RDB 文件的过程是阻塞的，无法响应客户端的命令；如果
从节点执行 bgrewriteaof，也会带来额外的消耗

**题外话：什么是 Redis Bgrewriteaof ？**

Redis Bgrewriteaof 命令用于异步执行一个 AOF（AppendOnly File） 文件重写操作。

Bgrewriteaof 重写会创建一个当前 AOF 文件的体积优化版本。

即使 Bgrewriteaof 执行失败，也不会有任何数据丢失，因为旧的 AOF 文件在 Bgrewriteaof 成功之前
不会被修改。

**注意：** 从 Redis 2.4 开始， AOF 重写由 Redis 自行触发， BGREWRITEAOF 仅仅用于手动触发重写操
作。

redis Bgrewriteaof 命令基本语法如下：

**redis 2.8 版本之前主从复制流程**

redis 2.8 版本之前主从复制流程：

```
从服务器连接主服务器，发送SYNC命令；
```
```
1 redis 127.0.0.1:6379> BGREWRITEAOF
```

```
主服务器接收到SYNC命名后，开始执行BGSAVE命令生成RDB文件并使用缓冲区记录此后执行的
所有写命令；
主服务器BGSAVE执行完后，向所有从服务器发送快照文件，并在发送期间继续记录被执行的写命
令；
从服务器收到快照文件后丢弃所有旧数据，载入收到的快照；
主服务器快照发送完毕后开始向从服务器发送缓冲区中的写命令；
从服务器完成对快照的载入，开始接收命令请求，并执行来自主服务器缓冲区的写命令；
```
全量复制的弊端：

场景：(1) 新创建的 slave，从主机 master 同步数据。(2) 刚宕机一小会的 slave，从主机 master 同步数
据。

```
前者新建的slave则从主机master全量同步数据，这没啥问题。但是后者slave可能只与主机
master存在小量的数据差异，要是全量同步肯定没有只同步差异（部分复制）的那点数据性能高
```
**部分复制**

由于全量复制在主节点数据量较大时效率太低，因此 Redis 2.8 开始提供部分复制，用于处理网络中断时
的数据同步。

部分复制的实现，依赖于三个重要的概念：

**（ 1 ）offset 复制偏移量**

```
主节点和从节点分别维护一个复制偏移量（offset），代表的是 主节点向从节点传递的字节数 ；
主节点每次向从节点传播N个字节数据时，主节点的offset增加N；
从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。
```
**offset 复制偏移量的用途**

offset 用于判断主从节点的数据库状态是否一致：如果二者 offset 相同，则一致；如果 offset 不同，则不
一致，此时可以根据两个 offset 找出从节点缺少的那部分数据。

例如，如果主节点的 offset 是 1000 ，而从节点的 offset 是 500 ，那么部分复制就需要将 offset 为 501-
1000 的数据传递给从节点。

而 offset 为 501-1000 的数据存储的位置，就是下面要介绍的复制积压缓冲区。

**（ 2 ）复制积压缓冲区 ( repl-backlog-buffer )**

复制积压缓冲区是由主节点维护的、固定长度的、先进先出 (FIFO) 队列，默认大小 1 MB；

当主节点开始有从节点时, master 创建一个积压缓冲区，其作用是备份主节点最近收到的 redis 命令，后
续会发送给从节点的数据。

```
注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。
```
在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的
备份；

除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。


```
由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最复制积压缓冲区近执行的写命
令；时间较早的写命令会被挤出缓冲区。
```
由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点 offset 的差距过大超过缓冲
区长度时，将无法执行部分复制，只能执行全量复制。

反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小 (通过配
置 repl-backlog-size)；

例如如果网络中断的平均时间是 60 s，而主节点平均每秒产生的写命令 (特定协议格式) 所占的字节数为
100 KB，则复制积压缓冲区的平均需求为 6 MB，保险起见，可以设置为 12 MB，来保证绝大多数断线情
况都可以使用部分复制。

从节点将 offset 发送给主节点后，主节点根据 offset 和缓冲区大小决定能否执行部分复制：

```
如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制；
如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。
```
**（ 3 ）服务器运行 ID (runid)**

每个 Redis 节点 (无论主从)，在启动时都会自动生成一个随机 ID (每次启动都不一样)，由 40 个随机的十六
进制字符组成；runid 用来唯一识别一个 Redis 节点。

通过 info Server 命令，可以查看节点的 runid：

主从节点初次复制时，主节点将自己的 runid 发送给从节点，从节点将这个 runid 保存起来；当断线重连
时，从节点会将这个 runid 发送给主节点；主节点根据 runid 判断能否进行部分复制：

```
如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝
试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)；
如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是
当前的主节点，只能进行全量复制。
```
**slavof 命令的执行流程**

在了解了复制偏移量、复制积压缓冲区、节点运行 id 之后，


接下来，看看 slavof 命令的执行流程

从节点收到 slaveof 命令之后，首先决定是使用全量复制还是部分复制：

（ 1 ）首先，从节点根据当前状态，决定如何调用 psync 命令：

```
如果从节点之前未执行过slaveof或最近执行了slaveof no one，则从节点发送命令为psync? -1，
向主节点请求全量复制；
如果从节点之前执行了slaveof，则发送命令为psync {runid} {offset}，其中runid为上次复制的
主节点的runid，offset为上次复制截止时从节点保存的复制偏移量。
```
（ 2 ）主节点根据收到的 psync 命令，及当前服务器状态，决定执行全量复制还是部分复制：

```
如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制；
如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复
制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺
少的数据即可；
如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已
不在复制积压缓冲区中(在队列中被挤出了)，则回复+FULLRESYNC {runid} {offset}，表示要进行
全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两
个值，以备使用。
```
**重新连接之后的部分复制**


部分复制主要是 Redis 针对全量复制的过高开销做出的一种优化措施，使用 psync {runId} {offset} 命
令实现。

当从节点正在复制主节点时，如果出现网络闪断或者命令丢失等异常情况时，从节点会向主节点要求补
发丢失的命令数据，如果主节点的复制积压缓冲区存在这部分数据，则直接发送给从节点，这样就保证
了主从节点复制的一致性。

补发的这部分数据一般远远小于全量数据，所以开销很小。

1) 当主从节点之间网络出现中断时，如果超过了 repl-timeout 时间，主节点会认为从节点故障并中断
复制连接。

2) 主从连接中断期间主节点依然响应命令，但因复制连接中断命令无法发送给从节点，不过主节点内部
存在复制积压缓冲区 ( repl-backlog-buffer )，依然可以保存最近一段时间的写命令数据，默认最大缓存
1 MB。

3) 当主从节点网络恢复后，从节点会再次连上主节点。

4) 当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行 ID。因此会把它们作
为 psync 参数发送给主节点，要求进行补发复制操作。

5) 主节点接到 psync 命令后首先核对参数 runId 是否与自身一致，如果一致，说明之前复制的是当前
主节点；之后根据参数 offset 在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对
从节点发送 +CONTINUE 响应，表示可以进行部分复制。

6) 主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。

###### phrase 3：命令传播阶段

数据同步阶段完成后，主从节点进入命令传播阶段；


在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据
的一致性。

在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING 和 REPLCONF ACK。

心跳机制对于主从复制的超时判断、数据安全等有作用。

**1. 主->从：PING**

每隔指定的时间， **主节点会向从节点发送 PING 命令** ，这个 PING 命令的作用，主要是为了让从节点进行
超时判断。

PING 发送的频率由 repl-ping-slave-period 参数控制，单位是秒，默认值是 10 s。

关于该 PING 命令究竟是由主节点发给从节点，还是相反，有一些争议；

```
因为在Redis的官方文档中，对该参数的注释中说明是从节点向主节点发送PING命令，如下图所
示：
```
但是通过源码可以看到， PING 命令是主节点会向从节点发送.

```
可能的原因是：代码的迭代和注释的迭代，没有完全同步。 可能早期是 从发给主，后面改成了主
发从，而并没有配套修改注释， 就像尼恩的很多代码一样。
```
**2. 从->主：REPLCONF ACK**

在命令传播阶段， **从节点会向主节点发送 REPLCONF ACK 命令，** 频率是每秒 1 次；

命令格式为：REPLCONF ACK {offset}，其中 offset 指从节点保存的复制偏移量。

REPLCONF ACK 命令的作用包括：

（ 1 ）实时监测主从节点网络状态：该命令会被主节点用于复制超时的判断。此外，在主节点中使用
info Replication，可以看到其从节点的状态中的 lag 值，代表的是主节点上次收到该 REPLCONF ACK 命
令的时间间隔，在正常情况下，该值应该是 0 或 1 ，如下图所示：

（ 2 ）检测命令丢失：从节点发送了自身的 offset，主节点会与自己的 offset 对比，如果从节点数据缺失
（如网络丢包），主节点会推送缺失的数据（这里也会利用复制积压缓冲区）。

```
注意，offset和复制积压缓冲区，不仅可以用于部分复制，也可以用于处理命令丢失等情形；区别
在于前者是在断线重连后进行的，而后者是在主从节点没有断线的情况下进行的。
```
（ 3 ）辅助保证从节点的数量和延迟：Redis 主节点中使用 min-slaves-to-write 和 min-slaves-max-lag 参
数，来保证主节点在不安全的情况下不会执行写命令；所谓不安全，是指从节点数量太少，或延迟过
高。


```
例如min-slaves-to-write和min-slaves-max-lag分别是 3 和 10 ，含义是如果从节点数量小于 3 个，
或所有从节点的延迟值都大于10s，则主节点拒绝执行写命令。而这里从节点延迟值的获取，就是
通过主节点接收到REPLCONF ACK命令的时间来判断的，即前面所说的info Replication中的lag
值。
```
#### 聊聊：是否使用过 Redis 集群，集群的原理是什么？

Redis Sentinal 着眼于高可用，在 master 宕机时会自动将 slave 提升为 master，继续提供服务。

Redis Cluster 着眼于扩展性，在单个 redis 内存不足时，使用 Cluster 进行分片存储。

#### 聊聊：如何保证 redis 的高并发和高可用？redis 的主从复

#### 制原理能介绍一下么？redis 的哨兵原理能介绍一下么？

**面试官心理分析**

其实问这个问题，主要是考考你，redis 单机能承载多高并发？如果单机扛不住如何扩容扛更多的并
发？redis 会不会挂？既然 redis 会挂那怎么保证 redis 是高可用的？

其实针对的都是项目中你肯定要考虑的一些问题，如果你没考虑过，那确实你对生产系统中的问题思考
太少。

**面试题剖析**

如果你用 redis 缓存技术的话，肯定要考虑如何用 redis 来加多台机器，保证 redis 是高并发的，还有
就是如何让 redis 保证自己不是挂掉以后就直接死掉了，即 redis 高可用。

由于此节内容较多，因此，会分为两个小节进行讲解。- redis 主从架构 - redis 基于哨兵实现高可用
redis 实现高并发主要依靠主从架构，一主多从，一般来说，很多项目其实就足够了，单主用来写入数
据，单机几万 QPS，多从用来查询数据，多个从实例可以提供每秒 10 w 的 QPS。

如果想要在实现高并发的同时，容纳大量的数据，那么就需要 redis 集群，使用 redis 集群之后，可以
提供每秒几十万的读写并发。

redis 高可用，如果是做主从架构部署，那么加上哨兵就可以了，就可以实现，任何一个实例宕机，可
以进行主备切换。


#### 聊聊：redis 的持久化有哪几种方式？不同的持久化机制都

#### 有什么优缺点？持久化机制具体底层是如何实现的？

**面试官心理分析**

redis 如果仅仅只是将数据缓存在内存里面，如果 redis 宕机了再重启，内存里的数据就全部都弄丢了
啊。

你必须得用 redis 的持久化机制，将数据写入内存的同时，异步的慢慢的将数据写入磁盘文件里，进行
持久化。

如果 redis 宕机重启，自动从磁盘上加载之前持久化的一些数据就可以了，也许会丢失少许数据，但是
至少不会将所有数据都弄丢。

这个其实一样，针对的都是 redis 的生产环境可能遇到的一些问题，就是 redis 要是挂了再重启，内存
里的数据不就全丢了？能不能重启的时候把数据给恢复了？

**面试题剖析**

持久化主要是做灾难恢复、数据恢复，也可以归类到高可用的一个环节中去，比如你 redis 整个挂了，
然后 redis 就不可用了，你要做的事情就是让 redis 变得可用，尽快变得可用。

重启 redis，尽快让它对外提供服务，如果没做数据备份，这时候 redis 启动了，也不可用啊，数据都
没了。

很可能说，大量的请求过来，缓存全部无法命中，在 redis 里根本找不到数据，这个时候就死定了，出
现缓存雪崩问题。所有请求没有在 redis 命中，就会去 mysql 数据库这种数据源头中去找，一下子 mysql
承接高并发，然后就挂了...

如果你把 redis 持久化做好，备份和恢复方案做到企业级的程度，那么即使你的 redis 故障了，也可以
通过备份数据，快速恢复，一旦恢复立即对外提供服务。

redis 持久化的两种方式

```
RDB：RDB 持久化机制，是对 redis 中的数据执行周期性的持久化。
AOF：AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，在
redis重启的时候，可以通过回放 AOF 日志中的写入指令来重新构建整个数据集。
```
通过 RDB 或 AOF，都可以将 redis 内存中的数据给持久化到磁盘上面来，然后可以将这些数据备份到
别的地方去，比如说阿里云等云服务。

如果 redis 挂了，服务器上的内存和磁盘上的数据都丢了，可以从云服务上拷贝回来之前的数据，放到
指定的目录中，然后重新启动 redis，redis 就会自动根据持久化数据文件中的数据，去恢复内存中的数
据，继续对外提供服务。

如果同时使用 RDB 和 AOF 两种持久化机制，那么在 redis 重启的时候，会使用 AOF 来重新构建数据，
因为 AOF 中的数据更加完整。


**RDB 优缺点**

```
RDB 会生成多个数据文件，每个数据文件都代表了某一个时刻中 redis 的数据，这种多个数据文
件的方式，非常适合做冷备，可以将这种完整的数据文件发送到一些远程的安全存储上去，比如说
Amazon的 S3 云服务上去，在国内可以是阿里云的 ODPS 分布式存储上，以预定好的备份策略来
定期备份 redis中的数据。
RDB 对 redis 对外提供的读写服务，影响非常小，可以让 redis 保持高性能，因为 redis 主进程只
需要 fork 一个子进程，让子进程执行磁盘 IO 操作来进行 RDB 持久化即可。·
相对于 AOF 持久化机制来说，直接基于 RDB 数据文件来重启和恢复 redis 进程，更加快速。
如果想要在 redis 故障时，尽可能少的丢失数据，那么 RDB 没有 AOF 好。一般来说，RDB 数据
快照文件，都是每隔 5 分钟，或者更长时间生成一次，这个时候就得接受一旦 redis 进程宕机，那
么会丢失最近 5 分钟的数据。
RDB 每次在 fork 子进程来执行 RDB 快照数据文件生成的时候，如果数据文件特别大，可能会导
致对客户端提供的服务暂停数毫秒，或者甚至数秒。
```
**AOF 优缺点**

```
AOF 可以更好的保护数据不丢失，一般 AOF 会每隔 1 秒，通过一个后台线程执行一次 fsync 操
作，最多丢失 1 秒钟的数据。
AOF 日志文件以 append-only 模式写入，所以没有任何磁盘寻址的开销，写入性能非常高，而且
文件不容易破损，即使文件尾部破损，也很容易修复。
AOF 日志文件即使过大的时候，出现后台重写操作，也不会影响客户端的读写。因为在 rewrite
log的时候，会对其中的指令进行压缩，创建出一份需要恢复数据的最小日志出来。在创建新日志
文件的时候，老的日志文件还是照常写入。当新的merge后日志文件ready的时候，在交换新老日
志文件即可。
AOF 日志文件的命令通过非常可读的方式进行记录，这个特性非常适合做灾难性的误删除的紧急
恢复。比如某人不小心用 flushall 命令清空了所有数据，只要这个时候后台 rewrite 还没有发生，
那么就可以立即拷贝 AOF 文件，将最后一条 flushall 命令给删了，然后再将该 AOF 文件放回去，
就可以通过恢复机制，自动恢复所有数据。
对于同一份数据来说，AOF 日志文件通常比 RDB 数据快照文件更大。
AOF 开启后，支持的写 QPS 会比 RDB 支持的写 QPS 低，因为 AOF 一般会配置成每秒 fsync 一次
日志文件，当然，每秒一次 fsync，性能也还是很高的。（如果实时写入，那么 QPS 会大降，
redis 性 能会大大降低）
以前 AOF 发生过 bug，就是通过 AOF 记录的日志，进行数据恢复的时候，没有恢复一模一样的数
据出来。所以说，类似 AOF 这种较为复杂的基于命令日志 / merge / 回放的方式，比基于 RDB 每
次持久化一份完整的数据快照文件的方式，更加脆弱一些，容易有 bug。不过 AOF 就是为了避免
rewrite 过程导致的 bug，因此每次 rewrite 并不是基于旧的指令日志进行 merge 的，而是基于当
时内存中的数据进行指令的重新构建，这样健壮性会好很多。
```
**RDB 和 AOF 到底该如何选择**

```
不要仅仅使用 RDB，因为那样会导致你丢失很多数据；
也不要仅仅使用 AOF，因为那样有两个问题：第一，你通过 AOF 做冷备，没有 RDB 做冷备来的
恢复速度更快；第二，RDB 每次简单粗暴生成数据快照，更加健壮，可以避免 AOF 这种复杂的备
份和恢复机制的 bug；
```

#### 聊聊：如何保证缓存与数据库的双写一致性？

**面试官心理分析析**

你只要用缓存，就可能会涉及到缓存与数据库双存储双写，你只要是双写，就一定会有数据一致性的问
题，那么你如何解决一致性问题？

**面试题剖析试题剖析**

一般来说，如果允许缓存可以稍微的跟数据库偶尔有不一致的情况，也就是说如果你的系统不是严格要
求“缓存+数据库” 必须保持一致性的话，最好不要做这个方案，即：读请求和写请求串行化，串到一个
内存队列里去。

串行化可以保证一定不会出现不一致的情况，但是它也会导致系统的吞吐量大幅度降低，用比正常情况
下多几倍的机器去支撑线上的一个请求。

**Cache Aside Pattern**

最经典的缓存+数据库读写的模式，就是 Cache Aside Pattern。- 读的时候，先读缓存，缓存没有的
话，就读数据库，然后取出数据后放入缓存，同时返回响应。- 更新的时候，先更新数据库，然后再删
除缓存。

**为什么是删除缓存，而不是更新缓存？**

原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。

比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才
能计算出缓存最新的值的。

另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更
新一份？也许有的场景是这样，但是对于比较复杂的缓存数据计算的场景，就不是这样了。如果你频繁
修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，这个缓存到底会不会被频繁访问到？

举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20
次、 100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有大量的冷数据。实际上，如果你只是删除缓
存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度降低。用到缓存才去算缓
存。

其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会
不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。查
询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都里面的 1000 个员工的数据也同
时查出来啊。80%的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要访
问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员工。

**最初级的缓存不一致问题及解决方案**


问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧
数据，数据就出现了不一致。

解决思路：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空
的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存
中。

**比较复杂的数据不一致问题分析**

数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发
现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据
库的修改。完了，数据库和缓存中的数据不一样了...

**为什么上亿流量高并发场景下，缓存会出现这个问题？**

只有在对一个数据在并发的进行读写的时候，才可能会出现这种问题。其实如果说你的并发量很低的
话，特别是读并发很低，每天访问量就 1 万次，那么很少的情况下，会出现刚才描述的那种不一致的场
景。但是问题是，如果每天的是上亿的流量，每秒并发读是几万，每秒只要有数据更新的请求，就可能
会出现上述的数据库 **+** 缓存不一致的情况。

**解决方案如下：**

更新数据的时候，根据数据的唯一标识，将操作路由之后，发送到一个 jvm 内部队列中。读取数据的时
候，如果发现数据不在缓存中，那么将重新读取数据+更新缓存的操作，根据唯一标识路由之后，也发
送同一个 jvm 内部队列中。


一个队列对应一个工作线程，每个工作线程串行拿到对应的操作，然后一条一条的执行。这样的话一个
数据变更的操作，先删除缓存，然后再去更新数据库，但是还没完成更新。此时如果一个读请求过来，
没有读到缓存，那么可以先将缓存更新的请求发送到队列中，此时会在队列中积压，然后同步等待缓存
更新完成。

这里有一个优化点，一个队列中，其实多个更新缓存请求串在一起是没意义的，因此可以做过滤，如果
发现队列中已经有一个更新缓存的请求了，那么就不用再放个更新请求操作进去了，直接等待前面的更
新操作请求完成即可。

待那个队列对应的工作线程完成了上一个操作的数据库的修改之后，才会去执行下一个操作，也就是缓
存更新的操作，此时会从数据库中读取最新的值，然后写入缓存中。

如果请求还在等待时间范围内，不断轮询发现可以取到值了，那么就直接返回；如果请求等待的时间超
过一定时长，那么这一次直接从数据库中读取当前的旧值。

**高并发的场景下，该解决方案要注意的问题：**

**（ 1 ）读请求长时阻塞**

由于读请求进行了非常轻度的异步化，所以一定要注意读超时的问题，每个读请求必须在超时时间范围
内返回。该解决方案，最大的风险点在于说，可能数据更新很频繁，导致队列中积压了大量更新操作在
里面，然后读请求会发生大量的超时，最后导致大量的请求直接走数据库。务必通过一些模拟真实的测
试，看看更新数据的频率是怎样的。

另外一点，因为一个队列中，可能会积压针对多个数据项的更新操作，因此需要根据自己的业务情况进
行测试，可能需要部署多个服务，每个服务分摊一些数据的更新操作。如果一个内存队列里居然会挤压
100 个商品的库存修改操作，每隔库存修改操作要耗费 10 ms 去完成，那么最后一个商品的读请求，可
能等待 10 *100 = 1000 ms = 1 s 后，才能得到数据，这个时候就导致读请求的长时阻塞。

一定要做根据实际业务系统的运行情况，去进行一些压力测试，和模拟线上环境，去看看最繁忙的时
候，内存队列可能会挤压多少更新操作，可能会导致最后一个更新操作对应的读请求，会 hang 多少时
间，如果读请求在 200 ms 返回，如果你计算过后，哪怕是最繁忙的时候，积压 10 个更新操作，最多等
待 200 ms，那还可以的。

如果一个内存队列中可能积压的更新操作特别多，那么你就要加机器，让每个机器上部署的服务实例处
理更少的数据，那么每个内存队列中积压的更新操作就会越少。

其实根据之前的项目经验，一般来说，数据的写频率是很低的，因此实际上正常来说，在队列中积压的
更新操作应该是很少的。像这种针对读高并发、读缓存架构的项目，一般来说写请求是非常少的，每秒
的 QPS 能到几百就不错了。

我们来实际粗略测算一下。

如果一秒有 500 的写操作，如果分成 5 个时间片，每 200 ms 就 100 个写操作，放到 20 个内存队列
中，每个内存队列，可能就积压 5 个写操作。每个写操作性能测试后，一般是在 20 ms 左右就完成，那
么针对每个内存队列的数据的读请求，也就最多 hang 一会儿，200 ms 以内肯定能返回了。

经过刚才简单的测算，我们知道，单机支撑的写 QPS 在几百是没问题的，如果写 QPS 扩大了 10 倍，
那么就扩容机器，扩容 10 倍的机器，每个机器 20 个队列。

**（ 2 ）读请求并发量过高**

这里还必须做好压力测试，确保恰巧碰上上述情况的时候，还有一个风险，就是突然间大量读请求会在
几十毫秒的延时 hang 在服务上，看服务能不能扛的住，需要多少机器才能扛住最大的极限情况的峰
值。


但是因为并不是所有的数据都在同一时间更新，缓存也不会同一时间失效，所以每次可能也就是少数数
据的缓存失效了，然后那些数据对应的读请求过来，并发量应该也不会特别大。

**（ 3 ）多服务实例部署的请求路由**

可能这个服务部署了多个实例，那么必须保证说，执行数据更新操作，以及执行缓存更新操作的请求，
都通过 Nginx 服务器路由到相同的服务实例上。

比如说，对同一个商品的读写请求，全部路由到同一台机器上。可以自己去做服务间的按照某个请求参
数的 hash 路由，也可以用 Nginx 的 hash 路由功能等等。

**（ 4 ）热点商品的路由问题，导致请求的倾斜**

万一某个商品的读写请求特别高，全部打到相同的机器的相同的队列里面去了，可能会造成某台机器的
压力过大。就是说，因为只有在商品数据更新的时候才会清空缓存，然后才会导致读写并发，所以其实
要根据业务系统去看，如果更新频率不是太高的话，这个问题的影响并不是特别大，但是的确可能某些
机器的负载会高一些。

#### 聊聊： 为什么是删除缓存，而不是更新缓存？

原因很简单，很多时候，在复杂点的缓存场景，缓存不单单是数据库中直接取出来的值。

比如可能更新了某个表的一个字段，然后其对应的缓存，是需要查询另外两个表的数据并进行运算，才
能计算出缓存最新的值的。

另外更新缓存的代价有时候是很高的。是不是说，每次修改数据库的时候，都一定要将其对应的缓存更
新一份？也许有的场景是这样，但是对于比较复杂的缓存数据计算的场景，就不是这样了。
如果你频繁修改一个缓存涉及的多个表，缓存也频繁更新。但是问题在于，这个缓存到底会不会被频繁
访问到？

举个栗子，一个缓存涉及的表的字段，在 1 分钟内就修改了 20 次，或者是 100 次，那么缓存更新 20
次、 100 次；但是这个缓存在 1 分钟内只被读取了 1 次，有大量的冷数据。
实际上，如果你只是删除缓存的话，那么在 1 分钟内，这个缓存不过就重新计算一次而已，开销大幅度
降低。用到缓存才去算缓存。

其实删除缓存，而不是更新缓存，就是一个 lazy 计算的思想，不要每次都重新做复杂的计算，不管它会
不会用到，而是让它到需要被使用的时候再重新计算。像 mybatis，hibernate，都有懒加载思想。
查询一个部门，部门带了一个员工的 list，没有必要说每次查询部门，都里面的 1000 个员工的数据也
同时查出来啊。80%的情况，查这个部门，就只是要访问这个部门的信息就可以了。先查部门，同时要
访问里面的员工，那么这个时候只有在你要访问里面的员工的时候，才会去数据库里面查询 1000 个员
工。

2 ）最初级的缓存不一致问题及解决方案
问题：先更新数据库，再删除缓存。如果删除缓存失败了，那么会导致数据库中是新数据，缓存中是旧
数据，数据就出现了不一致。


解决思路：先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空
的，那么数据不会不一致。因为读的时候缓存没有，所以去读了数据库中的旧数据，然后更新到缓存
中。

3 ）比较复杂的数据不一致问题分析
数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。一个请求过来，去读缓存，发
现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。随后数据变更的程序完成了数据
库的修改。
完了，数据库和缓存中的数据不一样了...

#### 聊聊：redis 的并发竞争问题是什么？如何解决这个问题？

#### 了解 redis 事务的 CAS 方案吗？

**面试官心理分析**

这个也是线上非常常见的一个问题，就是多客户端同时并发写一个 key，可能本来应该先到的数据后到
了，导致数据版本错了；或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数
据就错了。

而且 redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案。

###### Optimistic locking using check-and-set (乐观锁)

**乐观锁介绍：**

watch 指令在 redis 事物中提供了 CAS 的行为。为了检测被 watch 的 keys 在是否有多个 clients 同时改变引
起冲突，这些 keys 将会被监控。如果至少有一个被监控的 key 在执行 exec 命令前被修改，整个事物将会
回滚，不执行任何动作，从而保证原子性操作，并且执行 exec 会得到 null 的回复。

**乐观锁工作机制：**


watch 命令会监视给定的每一个 key，当 exec 时如果监视的任一个 key 自从调用 watch 后发生过变化，则
整个事务会回滚，不执行任何动作。注意 watch 的 key 是对整个连接有效的，事务也一样。如果连接断
开，监视和事务都会被自动清除。当然 exec，discard，unwatch 命令，及客户端连接关闭都会清除连
接中的所有监视。还有，如果 watch 一个不稳定 (有生命周期) 的 key 并且此 key 自然过期，exec 仍然会执
行事务队列的指令。

**redis 的 Watch 机制是什么？**

```
Redis Watch 命令用于监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令
所改动，那么事务将被打断。注意使用multi 开始事务，exec 提交事务。
```
```
语法， redis Watch 命令基本语法如下：
WATCH key [key ...]
```
验证：首先开启两个 redis 客户端，客户端 1 和客户端 2.


```
1 、客户端 1 中，先set一个值
```
```
2 、客户端 1 开启Watch 此值。
```
```
3 、客户端 1 开启事务，修改此值
```
注意此时先不要 exec 执行

```
4 、客户端 2 ，去修改此值
```
```
5 、客户端 1 ，执行exec执行
```
发现为 nil, 执行未成功，获取的值为客户端 2 修改后的值。

#### 聊聊：生产环境中的 redis 是怎么部署的？

###### 面试官心理分析析

看看你了解不了解你们公司的 redis 生产集群的部署架构，如果你不了解，那么确实你就很失职了，你
的 redis 是主从架构？集群架构？用了哪种集群方案？有没有做高可用保证？有没有开启持久化机制确
保可以进行数据恢复？线上 redis 给几个 G 的内存？设置了哪些参数？压测后你们 redis 集群承载多少
QPS？

兄弟，这些你必须是门儿清的，否则你确实是没好好思考过。

**面试题剖析**

```
redis 127.0.0.1:6379> set number 10
OK
```
```
1
2
```
```
redis 127.0.0.1:6379> watch number
OK
```
```
1
2
```
```
redis 127.0.0.1:6379> multi
OK
redis 127.0.0.1:6379> set number 100
QUEUED
redis 127.0.0.1:6379> get number
QUEUED
redis 127.0.0.1:6379>
```
```
1 2 3 4 5 6 7
```
```
redis 127.0.0.1:6379> set number 500
OK
```
```
1
2
```
```
redis 127.0.0.1:6379> exec
(nil)
redis 127.0.0.1:6379> get number
"500"
```
```
1
2
3
4
```

redis cluster， 10 台机器， 5 台机器部署了 redis 主实例，另外 5 台机器部署了 redis 的从实例，每个
主实例挂了一个从实例， 5 个节点对外提供读写服务，每个节点的读写高峰 qps 可能可以达到每秒 5
万， 5 台机器最多是 25 万读写请求/s。

机器是什么配置？32 G 内存+ 8 核 CPU + 1 T 磁盘，但是分配给 redis 进程的是 10 g 内存，一般线上生
产环境，redis 的内存尽量不要超过 10 g，超过 10 g 可能会有问题。

5 台机器对外提供读写，一共有 50 g 内存。

因为每个主实例都挂了一个从实例，所以是高可用的，任何一个主实例宕机，都会自动故障迁移，redis
从实例会自动变成主实例继续提供读写服务。

你往内存里写的是什么数据？每条数据的大小是多少？商品数据，每条数据是 10 kb。 100 条数据是
1 mb， 10 万条数据是 1 g。常驻内存的是 200 万条商品数据，占用内存是 20 g，仅仅不到总内存的
50%。目前高峰期每秒就是 3500 左右的请求量。

其实大型的公司，会有基础架构的 team 负责缓存集群的运维。

#### 聊聊：什么是缓存击穿、缓存穿透、缓存雪崩？

尼恩备注：这里是，面试重点

尼恩给 vip 小伙伴改简历时，基本每问一个小伙伴，都说不清楚。问了 N 多人，很少表达清楚的。

下面重点的介绍一下

###### 缓存穿透

缓存穿透指的查询缓存和数据库中都不存在的数据，这样每次请求直接打到数据库，就好像缓存不存在
一样。

对于系统 A，假设一秒 5000 个请求，结果其中 4000 个请求是黑客发出的恶意攻击。

黑客发出的那 4000 个攻击，缓存中查不到，每次你去数据库里查，也查不到。

举个栗子。

数据库 id 是从 1 开始的，结果黑客发过来的请求 id 全部都是负数。

这样的话，缓存中不会有，请求每次都“ **绕过缓存** ”，直接查询数据库。

这种恶意攻击场景的缓存穿透就会直接把数据库给打死。


缓存穿透将导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。

缓存穿透可能会使后端存储负载加大，如果发现大量存储层空命中，可能就是出现了缓存穿透问题。

缓存穿透可能有两种原因：

```
1. 自身业务代码问题
2. 恶意攻击，爬虫造成空命中
```
**缓存穿透解决办法：**

①对空值缓存：如果一个查询数据为空（不管数据是否存在），都对该空结果进行缓存，其过期时间会
设置非常短。

②采用布隆过滤器：布隆过滤器可以判断元素是否存在集合中，他的优点是空间效率和查询时间都比一
般算法快，缺点是有一定的误识别率和删除困难。

③设置可以访问名单：使用 bitmaps 类型定义一个可以访问名单，名单 id 作为 bitmaps 的偏移量，每次
访问时与 bitmaps 中的 id 进行比较，如果访问 id 不在 bitmaps 中，则进行拦截，不给其访问。

④进行实时监控：对于 redis 缓存中命中率急速下降时，迅速排查访问对象和访问数据，将其设置为黑名
单。

**缓存空值/默认值**

一种方式是在数据库不命中之后，把一个空对象或者默认值保存到缓存，之后再访问这个数据，就会从
缓存中获取，这样就保护了数据库。


```
缓存空值/默认值
```
缓存空值有两大问题：

```
1. 空值做了缓存，意味着缓存层中存了更多的键，需要更多的内存空间（如果是攻击，问题更严
重），比较有效的方法是针对这类数据设置一个较短的过期时间，让其自动剔除。
2. 缓存层和存储层的数据会有一段时间窗口的不一致，可能会对业务有一定影响。例如过期时间设置
为 5 分钟，如果此时存储层添加了这个数据，那此段时间就会出现缓存层和存储层数据的不一致。
这时候可以利用消息队列或者其它异步方式清理缓存中的空对象。
```
**布隆过滤器**

除了缓存空对象，我们还可以在存储和缓存之前，加一个布隆过滤器，做一层过滤。


布隆过滤器里会保存数据是否存在，如果判断数据不不能再，就不会访问存储。

两种解决方案的对比：

###### 缓存击穿

一个并发访问量比较大的 key 在某个时间过期，导致所有的请求直接打在 DB 上。

具体来是，就是说某个 key 非常热点，访问非常频繁，处于集中式高并发访问的情况，

当这个 key 在失效的瞬间，大量的请求就击穿了缓存，直接请求数据库，就像是在一道屏障上凿开了一
个洞。

结果是：

请求会直接访问数据库，并回设到缓存中，高并发访问数据库会导致数据库崩溃。


**缓存击穿解决方案：**

（ 1 ）预先设置热门数据：

在 redis 高峰访问时期，提前设置热门数据到缓存中，或适当延长缓存中 key 过期时间。

（ 2 ）实时调整：

实时监控哪些数据热门，实时调整 key 过期时间。

（ 3 ）对于热点 key 设置永不过期。

（ 4 ）加锁更新

比如请求查询 A，发现缓存中没有，对 A 这个 key 加锁，同时去数据库查询数据，写入缓存，再返回给用
户，这样后面的请求就可以从缓存中拿到数据了。


###### 缓存雪崩

某一时刻发生大规模的缓存失效的情况，例如缓存服务宕机、大量 key 在同一时间过期，这样的后果就
是大量的请求进来直接打到 DB 上，db 无响应，最后可能导致整个系统的崩溃，称为雪崩。

对于系统 A，假设每天高峰期每秒 5000 个请求，本来缓存在高峰期可以扛住每秒 4000 个请求，

但是缓存机器意外发生了：

```
缓存全盘宕机，缓存挂了，
大量key在同一时间过期
```
此时 1 秒 5000 个请求全部落数据库，数据库必然扛不住，它会报一下警，然后 db 无响应，最后导致整
个系统的崩溃。

此时，如果没有采用什么特别的方案来处理这个故障，DBA 很着急，重启数据库，但是数据库立马又被
新的流量给打死了。


**缓存雪崩解决方案：**

缓存雪崩是三大缓存问题里最严重的一种，我们来看看怎么预防和处理。

```
提高缓存可用性
```
```
1. 集群部署：通过集群来提升缓存的可用性，可以利用Redis本身的Redis Cluster或者第三方集群方
案如Codis等。
2. 多级缓存：设置多级缓存，设置一级缓存本地 guava 缓存，第一级缓存失效的基础上再访问二级
缓存 redis，每一级缓存的失效时间都不同。
```
```
过期时间
```
```
1. 均匀过期：为了避免大量的缓存在同一时间过期，可以把不同的 key 过期时间随机生成，避免过
期时间太过集中。
2. 热点数据永不过期。
熔断降级
```
```
1. 服务熔断：当缓存服务器宕机或超时响应时，为了防止整个系统出现雪崩，可以使用hystrix 类似
的熔断，暂时停止业务服务访问db, 或者其他被依赖的服务，避免 MySQL 被打死。
2. 服务降级：当出现大量缓存失效，而且处在高并发高负荷的情况下，在业务系统内部暂时舍弃对一
些非核心的接口和数据的请求，而直接返回一个提前准备好的 fallback（退路）错误处理信息。
```
#### 14 、Redis 常见的问题

**问题 1 ：缓存穿透**

```
缓存穿透是指缓存和数据库上都没有的数据，导致所有请求都落到数据库上，造成数据库短时间
内承受大量的请求而导致宕机
```
解决：

```
1. 使用布隆过滤器：将查询的参数都存储到一个 bitmap 中，在查询缓存前，如果 bitmap 存在则进
行底层缓存的数据查询，如果不存在则进行拦截，不再进行缓存的数据查询
```

```
2. 缓存空对象：如果数据库查询的为空，则依然把这个数据缓存并设置过期时间，当多次访问的时候
可以直接返回结果，避免造成多次访问数据库，但要保证当数据库有数据时及时更新缓存。
```
**问题 2 ：缓存击穿**

```
缓存击穿是指缓存中没有但数据库中有的数据（一般是缓存时间到期），就会导致所有请求都落
到数据库上，造成数据库段时间内承受大量的请求而宕机
```
解决：

```
1. 设置热点数据永不过期
2. 可以使用互斥锁更新，保证同一进程中针对同一个数据不会并发请求到 DB，减小DB的压力
3. 使用随机退避方式，失效时随机 sleep 一个很短的时间，再次查询，如果失败再执行更新
```
**问题 3 ：缓存雪崩**

```
缓存雪崩是指大量缓存同一时间内大面积失效，后面的请求都会落到数据库上，造成数据库段时
间无法承受大量的请求而宕掉
```
解决：

```
1. 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个Key只允许一个
线程查询和写缓存，其他线程等待
2. 通过缓存 reload 机制，预先去更新缓存，在即将发生高并发访问前手动触发加载缓存
3. 对于不同的key设置不同的过期时间，让缓存失效的时间点尽量均匀，比如我们可以在原有的失效
时间基础上增加一个随机值，比如1~5分钟随机，这样每一个缓存的过期时间的重复率就会降低。
4. 设置二级缓存，或者双缓存策略。
```
#### 聊聊：如何使用 Redis 布隆过滤器防恶意流量击穿缓存

**什么是恶意流量穿透**

假设我们的 Redis 里存有一组用户的注册 email，以 email 作为 Key 存在，同时它对应着 DB 里的 User 表的
部分字段。

一般来说，一个合理的请求过来我们会先在 Redis 里判断这个用户是否是会员，因为从缓存里读数据返
回快。如果这个会员在缓存中不存在那么我们会去 DB 中查询一下。

现在试想，有千万个不同 IP 的请求（不要以为没有，我们就在 2018 年和 2019 年碰到了，因为攻击的成
本很低）带着 Redis 里根本不存在的 key 来访问你的网站，这时我们来设想一下：

```
1. 请求到达Web服务器；
2. 请求派发到应用层->微服务层；
3. 请求去Redis捞数据，Redis内不存在这个Key；
4. 于是请求到达DB层，在DB建立connection后进行一次查询
```
千万乃至上亿的 DB 连接请求，先不说 Redis 是否撑的住 DB 也会被瞬间打爆。这就是“Redis 穿透”，它会
打爆你的缓存或者是连 DB 一起打爆进而引起一系列的“雪崩效应”。


**怎么防**

那就是使用布隆过滤器，可以把所有的 user 表里的关键查询字段放于 Redis 的 bloom 过滤器内。

有人会说，这不疯了，我有 4000 万会员？

你把 4000 会员放在 Redis 里是比较夸张，有些网站有 8000 万、 1 亿会员呢？

```
因此我没让你直接放在Redis里，而是放在布隆过滤器内！
```
布隆过滤器内不是直接把 key, value 这样放进去的，它存放的内容是这么一个 **bitmap** 中。

**bitmap**

所谓的 Bit-map 就是用一个 bit 位来标记某个元素对应的 Value，

通过 Bit 为单位来存储数据，可以大大节省存储空间.

所以我们可以通过一个 int 型的整数的 32 比特位来存储 32 个 10 进制的数字，

那么这样所带来的好处是内存占用少、效率很高（不需要比较和位移）

比如我们要存储 5 (101)、3 (11) 四个数字，那么我们申请 int 型的内存空间，会有 32 个比特位。

这四个数字的二进制分别对应从右往左开始数，比如第一个数字是 5 ，对应的二进制数据是 101, 那么从
右往左数到第 5 位，把对应的二进制数据存储到 32 个比特位上。

第一个 5 就是 00000000000000000000000000101000
输入 3 时候 00000000000000000000000000001100


**Bloom Filte 介绍**

**1. 含义**

(1). 布隆过滤器（Bloom Filter）是由 Howard Bloom 在 1970 年提出的一种比较巧妙的概率型数据结
构，它实际上是由一个很长的二进制 (0 或 1) 向量和一系列随机映射函数组成。

(2). 布隆过滤器可以用于检索一个元素是否在一个集合中。它可以告诉你某种东西 **一定不存在** 或者 **可能
存在** 。当布隆过滤器说，某种东西存在时，这种东西可能不存在；当布隆过滤器说，某种东西不存在
时，那么这种东西一定不存在。

(3). 布隆过滤器优点：A. 空间效率高，占用空间少 B. 查询时间短

缺点：A. 有一定的误判率 B. 元素不能删除

**2. 原理**

当一个元素被加入集合时，通过 K 个散列函数将这个元素映射成一个位数组中的 K 个点（使用多个哈希
函数对 **元素 key (bloom 中不存 value)** 进行哈希，算出一个整数索引值，然后对位数组长度进行取模运
算得到一个位置，每个无偏哈希函数都会得到一个不同的位置），把它们置为 1 。

检索时，我们只要看看这些点是不是都是 1 就（大约）知道集合中有没有它了：① 如果这些点有任何
一个为 0 （如下图的 e），则被检元素一定不在；如果都是 1 （如下图的 d），并不能完全说明这个元素
就一定存在其中，有可能这些位置为 1 是因为其他元素的存在，这就是布隆过滤器会出现误判的原因。

如下图：

补充：

Bloom Filter 跟 **‘’单哈希函数 BitMap‘’** 不同之处在于：Bloom Filter 使用了 k 个哈希函数，每个字符
串跟 k 个 bit 对应，从而降低了冲突的概率。

**3. 实现**

(1). Redis 的 bitmap

基于 redis 的 bitmap 数据结构的相关指令来执行。

(2). RedisBloom （推荐）

布隆过滤器可以使用 Redis 中的位图 (bitmap) 操作实现，直到 Redis 4.0 版本提供了插件功能，Redis 官
方提供的布隆过滤器才正式登场，布隆过滤器作为一个插件加载到 Redis Server 中，官网推荐了一个
RedisBloom 作为 Redis 布隆过滤器的 Module。


详细安装、指令操作参考：https://github.com/RedisBloom/RedisBloom

文档地址：https://oss.redislabs.com/redisbloom/

(3). PyreBloom

pyreBloom 是 Python 中 Redis + BloomFilter 模块，是 c 语言实现。如果觉得 Redis module 的形式
部署很麻烦或者线上环境 Redis 版本不是 4.0 及以上，则可以采用这个，但是它是在 hiredis 基础上，需
要安装 hiredis，且不支持重连和重试。

(4). Lua 脚本实现

详见：https://github.com/erikdubbelboer/redis-lua-scaling-bloom-filter

(5). guvua 包自带的布隆过滤器

**Bloom Filte 应用场景**

**1. 解决缓存穿透**

(1). 含义

业务请求中数据缓存中没有，DB 中也没有，导致类似请求直接跨过缓存，反复在 DB 中查询，与此同
时缓存也 **不会** 得到更新。（详见：https://www.cnblogs.com/yaopengfei/p/13878124.html）

(2). 解决思路

事先把存在的 key 都放到 redis 的 **Bloom Filter** 中，他的用途就是存在性检测，如果 BloomFilter 中不
存在，那么数据一定不存在；如果 BloomFilter 中存在，实际数据也有可能会不存在。

**剖析：*** *布隆过滤器可能会误判，放过部分请求，当不影响整体，所以目前该方案是处理此类问题最佳
方案。**

**2. 黑名单校验**

识别垃圾邮件，只要发送者在黑名单中的，就识别为垃圾邮件。假设黑名单的数量是数以亿计的，存
放起来就是非常耗费存储空间的，布隆过滤器则是一个较好的解决方案。把所有黑名单都放在布隆过滤
器中，再收到邮件时，判断邮件地址是否在布隆过滤器中即可。

ps：

如果用哈希表，每存储一亿个 email 地址，就需要 1.6 GB 的内存（用哈希表实现的具体办法是将每
一个 email 地址对应成一个八字节的信息指纹，然后将这些信息指纹存入哈希表，由于哈希表的存储效
率一般只有 50%，因此一个 email 地址需要占用十六个字节。一亿个地址大约要 1.6 GB，即十六亿字节
的内存）。因此存贮几十亿个邮件地址可能需要上百 GB 的内存。而 Bloom Filter 只需要哈希表 1/8 到
1/4 的大小就能解决同样的问题。

**3. Web 拦截器**

(1). 含义

如果相同请求则拦截，防止重复被攻击。

(2). 解决思路

用户第一次请求，将请求参数放入布隆过滤器中，当第二次请求时，先判断请求参数是否被布隆过滤
器命中，从而提高缓存命中率。

**布隆过滤器其他场景**

比如有如下几个需求：


1 、原本有 10 亿个号码，现在又来了 10 万个号码，要快速准确判断这 10 万个号码是否在 10 亿个号码
库中？

解决办法一：将 10 亿个号码存入数据库中，进行数据库查询，准确性有了，但是速度会比较慢。

解决办法二：将 10 亿号码放入内存中，比如 Redis 缓存中，这里我们算一下占用内存大小： 10 亿*8
字节=8 GB，通过内存查询，准确性和速度都有了，但是大约 8 gb 的内存空间，挺浪费内存空间的。

2 、接触过爬虫的，应该有这么一个需求，需要爬虫的网站千千万万，对于一个新的网站 url，我们
如何判断这个 url 我们是否已经爬过了？

解决办法还是上面的两种，很显然，都不太好。

3 、同理还有垃圾邮箱的过滤。

那么对于类似这种，大数据量集合，如何准确快速的判断某个数据是否在大数据量集合中，并且不
占用内存， **布隆过滤器** 应运而生了。

**给 Redis 安装 Bloom Filter**

Redis 从 4.0 才开始支持 bloom filter，因此本例中我们使用的是 Redis 5.4。

Redis 的 bloom filter 下载地址在这：https://github.com/RedisLabsModules/redisbloom.git

让 Redis 启动时可以加载 bloom filter 有两种方式：

**手工加载式：**

**每次启动自加载：**

编辑 Redis 的 redis. conf 文件，加入：

Like this:

```
1 4 、假设我用python爬虫爬了 4 亿条url，需要去重？
```
```
git clone https://github.com/RedisLabsModules/redisbloom.git
cd redisbloom
make # 编译
```
```
1
2
3
```
```
1 redis-server --loadmodule ./redisbloom/rebloom.so
```
```
1 loadmodule /soft/redisbloom/redisbloom.so
```

**在 Redis 里使用 Bloom Filter**

基本指令：

bf. reserve {key} {error_rate} {size}

上面这条命令就是：创建一个空的布隆过滤器，并设置一个期望的错误率和初始大小。{error_rate}过
滤器的错误率在 0-1 之间，如果要设置 0.1%，则应该是 0.001。 **该数值越接近 0 ，内存消耗越大，对 cpu
利用率越高** 。

bf. add {key} {item}

上面这条命令就是：往过滤器中添加元素。如果 key 不存在，过滤器会自动创建。

bf. exists {key} {item}

上面这条命令就是：判断指定 key 的 value 是否在 bloomfilter 里存在。存在：返回 1 ，不存在：返回 0 。

**引入 Redis 布隆过滤器防止缓存穿透**

缓存穿透（大量查询一个不存在的 key）定义：

```
缓存穿透，是指查询一个数据库中不一定存在的数据；
```
正常使用缓存查询数据的流程是，依据 key 去查询 value，数据查询先进行缓存查询，如果 key 不存在或
者 key 已经过期，再对数据库进行查询，并把查询到的对象，放进缓存。如果数据库查询对象为空，则
不放进缓存。

如果每次都查询一个不存在 value 的 key，由于缓存中没有数据，所以每次都会去查询数据库；当对 key
查询的并发请求量很大时，每次都访问 DB，很可能对 DB 造成影响；并且由于缓存不命中，每次都查询
持久层，那么也失去了缓存的意义。

**缓存穿透** 解决方法

**第一种是缓存层缓存空值**

将数据库中的空值也缓存到缓存层中，这样查询该空值就不会再访问 DB，而是直接在缓存层访问就
行。

但是这样有个弊端就是缓存太多空值占用了更多的空间，可以通过给缓存层空值设立一个较短的过期时
间来解决，例如 60 s。

**第二种是布隆过滤器**

将数据库中所有的查询条件，放入布隆过滤器中，

```
127.0.0.1:6379> bf.reserve userid 0.01 100000
OK
```
```
1
2
```
```
127.0.0.1:6379> bf.add userid '181920'
(integer) 1
```
```
1
2
```
```
127.0.0.1:6379> bf.exists userid '101310299'
(integer) 1
```
```
1
2
```

当一个查询请求过来时，先经过布隆过滤器进行查，如果判断请求查询值存在，则继续查；如果判断请
求查询不存在，直接丢弃。

这里看 **Bloom Filter。**

我们先看看一般业务缓存流程：

先查询缓存，缓存不命中再查询数据库。然后将查询结果放在缓存中即使数据不存在，也需要创建一个
缓存，用来防止穿库。这里需要区分一下数据是否存在。如果数据不存在，缓存时间可以设置相对较
短，防止因为主从同步等问题，导致问题被放大。

这个流程中存在薄弱的问题是，当用户量太大时，我们会缓存大量数据空数据，并且一旦来一波冷用
户，会造成雪崩效应。对于这种情况，我们产生第二个版本流程: redis 过滤冷用户缓存流程


我们将数据库里面，命中的用户放在 redis 的 set 类型中，设置不过期。这样相当把 redis 当作数据库的索
引，只要查询 redis，就可以知道是否数据存在。 redis 中不存在就可以直接返回结果。如果存在就按照
上面提到一般业务缓存流程处理。

聪明的你肯定会想到更多的问题：

```
1. redis本身可以做缓存，为什么不直接返回数据呢？
2. 如果数据量比较大，单个set，会有性能问题？
3. 业务不重要，将全量数据放在redis中，占用服务器大量内存。投入产出不成比例？
```

问题 1 需要区分业务场景，结果数据少，我们是可以直接使用 redis 作为缓存，直接返回数据。结果比较
大就不太适合用 redis 存放了。比如 ugc 内容，一个评论里面可能存在上万字，业务字段多。

redis 使用有很多技巧。bigkey 危害比较大，无论是扩容或缩容带来的内存申请释放，还是查询命令使
用不当导致大量数据返回，都会影响 redis 的稳定。这里就不细谈原因及危害了。解决 bigkey 方法很简
单。我们可以使用 hash 函数来分桶，将数据分散到多个 key 中。减少单个 key 的大小，同时不影响查询
效率。

问题 3 是 redis 存储占用内存太大。因此我们需要减少内存使用。重新思考一下引入 redis 的目的。 redis
像一个集合，整个业务就是验证请求的参数是否在集合中。

这个结构就像洗澡的时候用的双向阀门：左边热水，右边冷水。大部分的编程语言都内置了 filter。拿
python 举例，filter 函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的列表。

#### 聊聊：Redis 的并发竞争问题是什么？如何解决这个问

#### 题？了解 Redis 事务的 CAS 方案吗？

简单的讲：就是 **多客户端同时并发写** 一个 key，可能本来应该先到的数据后到了，导致数据版本错了；
或者是多客户端同时获取一个 key，修改值之后再写回去，只要顺序错了，数据就错了。

而且 Redis 自己就有天然解决这个问题的 CAS 类的乐观锁方案，使用版本号进行控制，cas 的思想这里
就不详细说了。

#### 聊聊：Redis 集群模式的工作原理能说一下么？在集群模

#### 式下，Redis 的 key 是如何寻址的？分布式寻址都有哪些

#### 算法？了解一致性 hash 算法吗？

**Redis cluster 介绍**


```
自动将数据进行分片，每个 master 上放一部分数据
提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的
```
在 Redis cluster 架构下，每个 Redis 要放开两个端口号，比如一个是 6379 ，另外一个就是加 1 w 的端
口号，比如 16379 。

16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故
障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议， gossip 协议，用于节
点间进行高效的数据交换，占用更少的网络带宽和处理时间。

**集群节点间的内部通信机制**

**基本通信原理**

集群元数据的维护有两种方式：集中式、Gossip 协议。Redis cluster 节点间采用 gossip 协议进行通
信。

**集中式** 是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个
典型代表，就是大数据领域的 storm 。它是分布式的大数据实时计算引擎，是集中式的元数据存储的
结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。

Redis 维护集群元数据采用另一个方式， gossip 协议，所有节点都持有一份元数据，不同的节点如果
出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。


**集中式** 的 **好处** 在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中
式的存储中，其它节点读取的时候就可以感知到； **不好** 在于，所有的元数据的更新压力全部集中在一个
地方，可能会导致元数据的存储有压力。

gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续打到所有节点上
去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。

```
10000 端口：每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号
+10000，比如 7001 ，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另
外几个节点发送 ping 消息，同时其它几个节点接收到 ping 之后返回 pong 。
交换的信息：信息包括故障信息，节点的增加和删除，hash slot 信息等等。
```
**gossip 协议**

gossip 协议包含多种消息，包含 ping , pong , meet , fail 等等。

```
meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它
节点进行通信。
```
其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群。

```
ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数
据，互相通过 ping 交换元数据。
pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。
fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕
机啦。
```
**ping 消息深入**

ping 时要携带一些元数据，如果很频繁，可能会加重网络负担。

每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。当然如果发现某个节点通
信延时达到了 cluster_node_timeout / 2 ，那么立即发送 ping，避免数据交换延时过长，落后的时
间太长了。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致
的情况，就会有问题。所以 cluster_node_timeout 可以调节，如果调得比较大，那么会降低 ping
的频率。

每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少
包含 3 个其它节点的信息，最多包含总节点数减 2 个其它节点的信息。

**分布式寻址算法**

```
hash 算法（大量缓存重建）
一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）
Redis cluster 的 hash slot 算法
```
**hash 算法**

来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个
master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会
导致 **大部分的请求过来，全部无法拿到有效的缓存** ，导致大量的流量涌入数据库。

```
Redis-trib.rb add-node
1
```
```
1
2
```

**一致性 hash 算法**

一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将
各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位
置。

来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环 **顺时针“行走”** ，遇到的
第一个 master 节点就是 key 所在位置。

在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时
针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。

燃鹅，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成 **缓存热点** 的问题。为了解决这种
热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置
都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。


**Redis cluster 的 hash slot 算法**

Redis cluster 有固定的 16384 个 hash slot，对每个 key 计算 CRC 16 值，然后对 16384 取模，可
以获取 key 对应的 hash slot。

Redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有
5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master
的 hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动
hash slot 的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过
hash tag 来实现。

任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。


#### 聊聊：Redis cluster 的高可用与主备切换原理

Redis cluster 的高可用的原理，几乎跟哨兵是类似的。

**判断节点宕机**

如果一个节点认为另外一个节点宕机，那么就是 pfail ， **主观宕机** 。如果多个节点都认为另外一个节
点宕机了，那么就是 fail ， **客观宕机** ，跟哨兵的原理几乎一样，sdown，odown。

在 cluster-node-timeout 内，某个节点一直没有返回 pong ，那么就被认为 pfail 。

如果一个节点认为某个节点 pfail 了，那么会在 gossip ping 消息中， ping 给其他节点，如果 **超
过半数** 的节点都认为 pfail 了，那么就会变成 fail 。

**从节点过滤**

对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。

检查每个 slave node 与 master node 断开连接的时间，如果超过了 cluster-node-timeout *
cluster-slave-validity-factor ，那么就 **没有资格** 切换成 master 。

**从节点选举**

每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据
越多）的从节点，选举时间越靠前，优先进行选举。

所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master
node （N/2 + 1） 都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。

从节点执行主备切换，从节点切换为主节点。

**与哨兵比较**

整个流程跟哨兵相比，非常类似，所以说，Redis cluster 功能强大，直接集成了 replication 和
sentinel 的功能。

#### 聊聊：如何进行 Redis 优化？

```
来自于小伙伴的真题，他面试挂在这里了。
```
谈优化前我们首先要对 Redis 要有一个全局的认识，

Redis 是单线程，Redis 作为 KV 数据库包括访问框架，操作模块，索引模块，存储模块；

Redis 的访问方式包括 UNIX 套接字和 TCP；

操作模块和数据结构相关, 包括 string，list，set，Hash，Sorted Set;

索引模块是为了更迅速的通过 key 定位到 value，Redis 采用的索引方式是哈希表（其它常用的索引方式
还包括 B+树，字典树，跳表等)；

存储模块主要是负责分配及持久化，Redis 支持的持久化方式包括 RDB (快照) 以及 AOF (日志)；

###### 尽量使用短的 key

降低内存，减少哈希表的算法执行时间;


当然在精简的同时，不要完了 key 的“见名知意”。对于 value 有些也可精简，比如性别使用 0 、 1 。

###### 不要存过大的数据;

过大的数据存取和删除都会更为耗时；

###### 避免使用 keys *

keys 会导致查找的时间复杂度为 0 (n);

其它复杂度命令也要少用；Redis 命令参考 — Redis 命令参考有给出每个命令的时间复杂度;

```
keys *, 这个命令是阻塞的，即操作执行期间，其它任何命令在你的实例中都无法执行。
```
当 redis 中 key 数据量小时到无所谓，数据量大就很糟糕了。所以我们应该避免去使用这个命令。可以去
使用 SCAN, 来代替。

###### 在存到 Redis 之前先把你的数据压缩下

redis 为每种数据类型都提供了两种内部编码方式，在不同的情况下 redis 会自动调整合适的编码方式。

###### 设置 key 有效期

我们应该尽可能的利用 key 有效期。比如一些临时数据（短信校验码），过了有效期 Redis 就会自动为你
清除！

设置过期时间，减少 redis 中的数据量，但要注意避免大量数据同时失效;

###### 选择回收策略 (maxmemory-policy)

**当 Redis 的实例空间被填满了之后，将会尝试回收一部分 key** 。

根据你的使用方式，强烈建议使用 **volatile-lru（默认）** 策略——前提是你对 key 已经设置了超时。

但如果你运行的是一些类似于 cache 的东西，并且没有对 key 设置超时机制，可以考虑使用 **allkeys-
lru** 回收机制。

maxmemory-samples 3 是说每次进行淘汰的时候会随机抽取 3 个 key 从里面淘汰最不经常使用的
（默认选项）

```
maxmemory-policy 六种方式 :
volatile-lru：只对设置了过期时间的key进行LRU（默认值）
allkeys-lru ： 是从所有key里 删除 不经常使用的key
volatile-random：随机删除即将过期key
allkeys-random：随机删除
volatile-ttl ： 删除即将过期的
noeviction ： 永不过期，返回错误
```
###### 减少不必要的连接；

能用连接池的情况下使用连接池；


###### 使用 bit 位级别操作和 byte 字节级别操作来减少不必要的内存使用。

```
bit位级别操作 ：GETRANGE, SETRANGE, GETBIT and SETBIT
byte字节级别操作 ：GETRANGE and SETRANGE
```
尽可能地使用 hashes 哈希存储。

当业务场景不需要数据持久化时，关闭所有的持久化方式可以获得最佳的性能。

想要一次添加多条数据的时候可以使用管道。

###### 限制 redis 的内存大小（ 64 位系统不限制内存， 32 位系统默认最多使

###### 用 3 GB 内存）

数据量不可预估，并且内存也有限的话，尽量限制下 redis 使用的内存大小，这样可以避免 redis 使用
swap 分区或者出现 OOM 错误。（使用 swap 分区，性能较低，如果限制了内存，当到达指定内存之后就
不能添加数据了，否则会报 OOM 错误。可以设置 maxmemory-policy，内存不足时删除数据。）

###### SLOWLOG [get/reset/len]

```
slowlog-log-slower-than 它决定要对执行时间大于多少微秒(microsecond， 1 秒 = 1,000,000 微
秒)的命令进行记录。
slowlog-max-len 它决定 slowlog 最多能保存多少条日志，当发现redis性能下降的时候可以查看
下是哪些命令导致的。
```
###### 使用 pipline 批量操作数据，进行性能优化

**redis 的管道功能在命令行中没有，但是 redis 是支持管道的，在 java 的客户端 (jedis) 中是可以使用的** ：

示例代码


###### Instagram 内存优化

```
Instagram可能大家都已熟悉，当前火热的拍照App，月活跃用户 3 亿。
```
Instagram 所存图片 3 亿多时需要解决一个问题：

想知道每一张照片的作者是谁（通过图片 ID 反查用户 UID），并且要求查询速度要相当的块，如果把它
放到内存中使用 String 结构做 key-value:

**测试** ： 1 百万数据会用掉 70 MB 内存， 3 亿张照片就会用掉 21 GB 的内存。

最好是一台 EC 2 的 high-memory 机型就能存储（17 GB 或者 34 GB 的，68 GB 的太浪费了）, 想把它放到
16 G 机型中还是不行的。

Instagram 的开发者向 Redis 的开发者之一 Pieter Noordhuis 询问优化方案，得到的回复是使用 Hash 结
构。具体的做法就是将数据分段，每一段使用一个 Hash 结构存储.

```
//注：具体耗时，和自身电脑有关(博主是在虚拟机中运行的数据)
/**
* 不使用管道初始化1W条数据
* 耗时： 3079 毫秒
* @throws Exception
*/
@Test
public void NOTUsePipeline() throws Exception {
Jedis jedis = JedisUtil.getJedis();
long start_time = System.currentTimeMillis();
for (int i = 0 ; i < 10000 ; i++) {
jedis.set("aa_"+i, i+"");
}
System.out.println(System.currentTimeMillis()-start_time);
}
```
```
/**
* 使用管道初始化1W条数据
* 耗时： 255 毫秒
* @throws Exception
*/
@Test
public void usePipeline() throws Exception {
Jedis jedis = JedisUtil.getJedis();
```
```
long start_time = System.currentTimeMillis();
Pipeline pipelined = jedis.pipelined();
for (int i = 0 ; i < 10000 ; i++) {
pipelined.set("cc_"+i, i+"");
}
pipelined.sync();//执行管道中的命令
System.out.println(System.currentTimeMillis()-start_time);
}
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
```
```
HSET "mediabucket:1155" "1155315" "939"
HGET "mediabucket:1155" "1155315"
"939"
```
```
1
2
3
```

由于 Hash 结构会在单个 Hash 元素在不足一定数量时进行压缩存储，所以可以大量节约内存。

这一点在上面的 String 结构里是不存在的。而这个一定数量是由配置文件中的 hash-zipmap-max-
entries 参数来控制的。

经过实验，将 hash-zipmap-max-entries 设置为 1000 时，性能比较好，超过 1000 后 HSET 命令就会导致
CPU 消耗变得非常大。

**测试** ：

1 百万消耗 16 MB 的内存。总内存使用也降到了 5 GB。

当然我们还可以优化，去掉 mediabucket: key 前缀之后，长度减少了 12 个字节。

###### hash 的应用

**示例** ：我们要存储一个用户信息对象数据，包含以下信息：
key 为用户 ID，value 为用户对象（姓名，年龄，生日等）如果用普通的 key/value 结构来存储，

主要有以下 2 种存储方式：

```
1. 将用户ID作为查找key,把其他信息封装成一个对象以 序列化的方式存储
缺点：增加了序列化/反序列化的开销，引入复杂适应系统（Complex adaptive system，简称
CAS）修改其中一项信息时，需要把整个对象取回，并且修改操作需要对并发进行保护。
```
```
2. 用户信息 对象有多少成员就存成多少个key-value对
虽然省去了序列化开销和并发问题，但是用户ID为重复存储。
```
```
HSET "mediabucket:1155" "1155315" "939"
HGET "mediabucket:1155" "1155315"
"939"
```
```
1
2
3
```
```
HSET "1155" "315" "939"
HGET "1155" "315"
"939"
```
```
1
2
3
```

Redis 提供的 Hash 很好的解决了这个问题，

提供了直接存取这个 Map 成员的接口。Key 仍然是用户 ID, value 是一个 Map，这个 Map 的 key 是成员的
属性名，value 是属性值

**内部实现** ：

Redis Hashd 的 Value 内部有 2 种不同实现，

Hash 的成员比较少时，Redis 为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的
HashMap 结构，对应的 value redisObject 的 encoding 为 zipmap, 当成员数量增大时会自动转成真正的
HashMap, 此时 encoding 为 ht)。

###### 启动时 WARNING 优化

在我们启动 redis 时，默认会出现如下三个警告：


**一、修改 linux 中 TCP 监听的最大容纳数量**

**在高并发环境下你需要一个高 backlog 值来避免慢客户端连接问题** 。

注意 Linux 内核默默地将这个值减小到/proc/sys/net/core/somaxconn 的值，所以需要确认增大
somaxconn 和 tcp_max_syn_backlog 两个值来达到想要的效果。
echo 511 > /proc/sys/net/core/somaxconn

**注意** ：这个参数并不是限制 redis 的最大链接数。如果想限制 redis 的最大连接数需要修改 maxclients，
默认最大连接数为 10000

**二、修改 linux 内核内存分配策略**

原因：

**redis 在备份数据的时候，会 fork 出一个子进程，理论上 child 进程所占用的内存和 parent 是一样的，比
如 parent 占用的内存为 8 G，这个时候也要同样分配 8 G 的内存给 child, 如果内存无法负担，往往会造成
redis 服务器的 down 机或者 IO 负载过高，效率下降** 。

```
WARNING: The TCP backlog setting of 511 cannot be enforced because
/proc/sys/net/core/somaxconn is set to the lower value of 128.
```
```
1
2
```
```
错误日志：WARNING overcommit_memory is set to 0! Background save may fail
under low memory condition.
To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then
reboot or
run the command 'sysctl vm.overcommit_memory=1'
```
```
1
```
```
2
```
```
3
```

所以内存分配策略应该设置为 1 （表示内核允许分配所有的物理内存，而不管当前的内存状态如何）。
内存分配策略有三种
可选值： 0 、 1 、 2 。
0 ，表示内核将检查是否有足够的可用内存供应用进程使用；如果有足够的可用内存，内存申请允许；
否则，内存申请失败，并把错误返回给应用进程。
1 ，不管需要多少内存，都允许申请。
2 ，只允许分配物理内存和交换内存的大小 (交换内存一般是物理内存的一半)。

**三、关闭 Transparent Huge Pages (THP)**

THP 会造成内存锁影响 redis 性能，建议关闭

```
Transparent HugePages ：用来提高内存管理的性能
Transparent Huge Pages在 32 位的RHEL 6中是不支持的
执行命令 echo never > /sys/kernel/mm/transparent_hugepage/enabled
把这条命令添加到这个文件中/etc/rc.local
```
###### 性能分析方法:

1. 慢操作日志:

CONFIG SET slowlog-log-slower-than 0 单位是微秒, 若设置为 0 则相当于记录了所有的操作

CONFIG SET slowlog-max-len 10000000 最大慢日志长度

slowlog get 10 查看 redis 操作的执行耗时；

2. 基准测试

redis-cli --intrinsic-latency 120 (120 是测试时间)

基准测试要在系统无压力下进行，是为了排除硬件网络等本身就有较大的延迟，当执行延迟达到基准测
试时间 2 倍及以上可以认为 redis 是变慢了;

###### 记录一份 checklist:

1. 获取当前环境的基线性能

2. 是否使用了慢查询?

用其它命令代替慢查询命令
3. 是否对过期 key 设置了相同的过期时间?

4. 是否使用了 bigkey?

采用异步删除

5. AOF 的配置级别是什么？是否符合业务场景?

避免 IO 影响性能, 关于 IO 这块看是否可以使用 SSD 磁盘

6. Redis 内存是否占用过大? 使用 swap 了吗?


7. Redis 运行环境中是否启用了大页机制？

启用了则需要关闭，对持久化不友好，持久化是有了修改就需要大量复制

8. 是否使用了主从集群?

启用了主从集群需要控制数据量大小为 2 G-4 G，避免主从复制带来大量的开销;

9. 是否使用了多核心 CPU？

可以给 Redis 绑定物理核

#### 聊聊：Redis 集群了解吗？

前面说到了主从存在高可用和高扩展的问题，哨兵解决了高可用的问题，

而集群就是终极方案，一举解决 **高可用和高扩展** 问题。

**数据分区：**

数据分区 _(_ 或称数据分片 _)_ 是集群最核心的功能。

集群将数据分散到多个节点，一方面突破了 Redis 单机内存大小的限制， **存储容量大大增加** ； **另一方面**
每个主节点都可以对外提供读服务和写服务， **大大提高了集群的响应能力** 。

```
1 如果使用了swap可能就需要考虑增加系统内存了
```

数据分片是高扩展的基础。

**高可用：** 集群支持主从复制和主节点的 **自动故障转移** （与哨兵类似），当任一节点发生故障时，集群
仍然可以对外提供服务。

#### 聊聊：数据分片（sharding）的基本类型？ 大致的原理？

数据分片（sharding）的基本类型，大致有：

```
范围分片
key（id）取模分片
哈希取余分片
一致性哈希分片
虚拟槽分片
```
###### 什么是数据分片?

**名词说明：**

```
数据分片（sharding）也叫数据分区
```
**为什么要做数据分片？**

全量数据较大的场景下，单节点无法满足要求，需要数据分片

**什么是数据分片?**

按照分片规则把数据分到若干个 shard、partition 当中


###### range 分片

一种是按照 range 来分，就是每个片，一段连续的数据，这个一般是按比如 **时间范围/数据范围** 来的，
但是这种一般较少用，因为很容易发生 **数据倾斜** ，大量的流量都打在 **最新的数据** 上了。

比如，安装数据范围分片，把 1 到 100 个数字，要保存在 3 个节点上

按照顺序分片，把数据平均分配三个节点上

```
1 号到 33 号数据保存到节点 1 上
34 号到 66 号数据保存到节点 2 上
67 号到 100 号数据保存到节点 3 上
```

###### ID（或者 key）取模分片

此种分片规则将数据分成 n 份（通常 dn 节点也为 n），从而将数据均匀的分布于各个表中，或者各节点
上。

```
ID（或者key）取模分片常用在关系型数据库的设计
```
具体请参见秒杀视频的亿级库表架构设计

###### hash 哈希分布

使用 hash 算法，获取 key 的哈希结果，再按照规则进行分片，这样可以保证数据被打散，同时保证数据
分布的比较均匀

哈希分布方式分为三个分片方式：

```
哈希取余分片
一致性哈希分片
虚拟槽分片
```
###### 哈希取余模分片

例如 1 到 100 个数字，对每个数字进行哈希运算，然后对每个数的哈希结果除以节点数进行取余，余数为
1 则保存在第 1 个节点上，余数为 2 则保存在第 2 个节点上，余数为 0 则保存在第 3 个节点，这样可以保证
数据被打散，同时保证数据分布的比较均匀

比如有 100 个数据，对每个数据进行 hash 运算之后，与节点数进行取余运算，根据余数不同保存在不同
的节点上

哈希取余分片是非常简单的一种分片方式


**哈希取模分片有一个问题**

```
即当增加或减少节点时，原来节点中的80%的数据会进行迁移操作，对所有数据重新进行分布
```
哈希取余分片，建议使用多倍扩容的方式，例如以前用 3 个节点保存数据，扩容为比以前多一倍的节点
即 6 个节点来保存数据，这样只需要适移 50%的数据。

数据迁移之后，第一次无法从缓存中读取数据，必须先从数据库中读取数据，然后回写到缓存中，然后
才能从缓存中读取迁移之后的数据

哈希取余分片优点：

```
配置简单：对数据进行哈希，然后取余
```
哈希取余分片缺点：

```
数据节点伸缩时，导致数据迁移
迁移数量和添加节点数据有关，建议翻倍扩容
```
**一致性哈希分片**

一致性哈希原理：

```
将所有的数据当做一个token环，
```
```
token环中的数据范围是 0 到 2 的 32 次方。
```
```
然后为每一个数据节点分配一个token范围值，这个节点就负责保存这个范围内的数据。
```

对每一个 key 进行 hash 运算，被哈希后的结果在哪个 token 的范围内，则按顺时针去找最近的节点，这
个 key 将会被保存在这个节点上。

**一致性哈希分片的节点扩容**

在下面的图中：

```
有 4 个key被hash之后的值在在n1节点和n2节点之间，按照顺时针规则，这 4 个key都会被保存在
n2节点上
如果在n1节点和n2节点之间添加n5节点，当下次有key被hash之后的值在n1节点和n5节点之间，
这些key就会被保存在n5节点上面了
```

下图的例子里，添加 n 5 节点之后：

```
数据迁移会在n1节点和n2节点之间进行
n3节点和n4节点不受影响
数据迁移范围被缩小很多
```
同理，如果有 1000 个节点，此时添加一个节点，受影响的节点范围最多只有千分之 2 。所以，一致性哈
希一般用在节点比较多的时候，节点越多，扩容时受影响的节点范围越少

分片方式：哈希 + 顺时针 (优化取余)

一致性哈希分片优点：

```
一致性哈希算法解决了分布式下数据分布问题。比如在缓存系统中，通过一致性哈希算法把缓存键
映射到不同的节点上，由于算法中虚拟节点的存在，哈希结果一般情况下比较均匀。
节点伸缩时，只影响邻近节点，但是还是有数据迁移
```
```
“但没有一种解决方案是银弹，能适用于任何场景。所以实践中一致性哈希算法有哪些缺陷，或者
有哪些场景不适用呢？”
```
一致性哈希分片缺点：


```
一致性哈希在大批量的数据场景下负载更加均衡，但是在数据规模小的场景下，会出现单位时间
内某个节点完全空闲的情况出现。
```
###### 虚拟槽分片 (范围分片的变种)

```
Redis Cluster在设计中没有使用一致性哈希（Consistency Hashing），而是使用数据分片引入
哈希槽（hash slot）来实现；
```
虚拟槽分片是 Redis Cluster 采用的分片方式.

虚拟槽分片，可以理解为范围分片的变种， hash 取模分片+范围分片，把 hash 值取余数分为 n 段，一
个段给一个节点负责

在该分片方式中：

```
首先 预设虚拟槽，每个槽为一个hash值，每个node负责一定槽范围。
每一个值都是key的hash值取余，每个槽映射一个数据子集，一般比节点数大
```
```
Redis Cluster中预设虚拟槽的范围为 0 到 16383
```

**虚拟槽分片的映射步骤：**

1. 把 16384 槽按照节点数量进行平均分配，由节点进行管理
2. 对每个 key 按照 CRC 16 规则进行 hash 运算
3. 把 hash 结果对 16383 进行取余
4. 把余数发送给 Redis 节点
5. 节点接收到数据，验证是否在自己管理的槽编号的范围

```
如果在自己管理的槽编号范围内，则把数据保存到数据槽中，然后返回执行结果
如果在自己管理的槽编号范围外，则会把数据发送给正确的节点，由正确的节点来把数据保存在对
应的槽中
```
```
需要注意的是：Redis Cluster的节点之间会共享消息，每个节点都会知道是哪个节点负责哪个范
围内的数据槽
```
虚拟槽分布方式中，由于每个节点管理一部分数据槽，数据保存到数据槽中。

当节点扩容或者缩容时，对数据槽进行重新分配迁移即可，数据不会丢失。

**3 个节点的 Redis 集群虚拟槽分片结果：**

```
[root@localhost redis-cluster]# docker exec -it redis-cluster_redis1_1
redis-cli --cluster check 172.18.8.164:6001
172 .18.8.164:6001 (c4cfd72f...) -> 0 keys | 5461 slots | 1 slaves.
172 .18.8.164:6002 (c15a7801...) -> 0 keys | 5462 slots | 1 slaves.
172 .18.8.164:6003 (3fe7628d...) -> 0 keys | 5461 slots | 1 slaves.
[OK] 0 keys in 3 masters.
0 .00 keys per slot on average.
>>> Performing Cluster Check (using node 172 .18.8.164:6001)
M: c4cfd72f7cbc22cd81b701bd4376fabbe3d162bd 172 .18.8.164:6001
slots:[0-5460] (5461 slots) master
1 additional replica(s)
S: a212e28165b809b4c75f95ddc986033c599f3efb 172 .18.8.164:6006
slots: (0 slots) slave
replicates 3fe7628d7bda14e4b383e9582b07f3bb7a74b469
M: c15a7801623ee5ebe3cf952989dd5a157918af96 172 .18.8.164:6002
slots:[5461-10922] (5462 slots) master
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
```

**虚拟槽分片特点：**

虚拟槽分区巧妙地使用了哈希空间，使用分散度良好的哈希函数把所有数据映射到一个固定范围的整数
集合中，整数定义为槽（slot）。槽是集群内数据管理和迁移的基本单位。

槽的范围一般远远大于节点数，比如 Redis Cluster 槽范围是 0~16383。

采用大范围槽的主要目的是为了方便数据拆分和集群扩展，每个节点会负责一定数量的槽。

**Redis 虚拟槽分区的优点：**

```
解耦数据和节点之间的关系，简化了节点扩容和收缩难度。
节点自身维护槽的映射关系，不需要客户端或者代理服务维护槽分区元数据。
支持节点、槽、键之间的映射查询，用于数据路由，在线伸缩等场景。
无论数据规模大，还是小，Redis虚拟槽分区各个节点的负载，都会比较均衡 。而一致性哈希在大
批量的数据场景下负载更加均衡，但是在数据规模小的场景下，会出现单位时间内某个节点完全空
闲的情况出现。
```
#### 聊聊：Redis 集群高可用常见的几种方式？

Redis 高可用常见的有两种方式：

```
Replication-Sentinel哨兵模式
Redis-Cluster集群模式
中心化代理模式（proxy模式）
```
###### Replication-Sentinel 哨兵模式

Redis sentinel 是一个分布式系统中监控 redis 主从服务器，并在主服务器下线时自动进行故障转移。

```
1 additional replica(s)
S: 5e74257b26eb149f25c3d54aef86a4d2b10269ca 172 .18.8.164:6004
slots: (0 slots) slave
replicates c4cfd72f7cbc22cd81b701bd4376fabbe3d162bd
S: 8fb7f7f904ad1c960714d8ddb9ad9bca2b43be1c 172 .18.8.164:6005
slots: (0 slots) slave
replicates c15a7801623ee5ebe3cf952989dd5a157918af96
M: 3fe7628d7bda14e4b383e9582b07f3bb7a74b469 172 .18.8.164:6003
slots:[10923-16383] (5461 slots) master
1 additional replica(s)
[OK] All nodes agree about slots configuration.
>>> Check for open slots...
>>> Check slots coverage...
[OK] All 16384 slots covered.
```
```
16
17
18
19
20
21
22
23
24
25
26
27
28
29
```

Redis sentinel 其中三个特性：

```
监控（Monitoring）：
```
Sentinel 会不断地检查你的主服务器和从服务器是否运作正常。

```
提醒（Notification）：
```
当被监控的某个 Redis 服务器出现问题时， Sentinel 可以通过 API 向管理员或者其他应用程序发送通
知。

```
自动故障迁移（Automatic failover）：
```
当一个主服务器不能正常工作时， Sentinel 会开始一次自动故障迁移操作。

哨兵本身也有单点故障的问题，可以使用多个哨兵进行监控，哨兵不仅会监控 redis 集群，哨兵之间也会
相互监控。

每一个哨兵都是一个独立的进程，作为进程，它会独立运行。


**特点：**

```
1 、保证高可用
2 、监控各个节点
3 、自动故障迁移
```
**缺点：**

主从模式，切换需要时间丢数据

没有解决 master 写的压力

###### Redis-Cluster 模式

redis 在 3.0 上加入了 Cluster 集群模式，实现了 Redis 的分布式存储，也就是说每台 Redis 节点上存储
不同的数据。

cluster 模式为了解决单机 Redis 容量有限的问题，将数据按一定的规则分配到多台机器，内存/QPS 不受
限于单机，可受益于分布式集群高扩展性。

RedisCluster 是 Redis 的亲儿子，它是 Redis 作者自己提供的 Redis 集群化方案。

相对于 Codis 的不同，它是去中心化的，如图所示，该集群有三个 Redis 节点组成，每个节点负责整
个集群的一部分数据，每个节点负责的数据多少可能不一样。这三个节点相互连接组成一个对等的集
群，它们之间通过一种特殊的二进制协议相互交互集群信息。


如上图，官方推荐，集群部署至少要 3 台以上的 master 节点，最好使用 3 主 3 从六个节点的模式。

Redis Cluster 将所有数据划分为 16384 的 slots，它比 Codis 的 1024 个槽划分得更为精细，每个节点
负责其中一部分槽位。槽位的信息存储于每个节点中，它不像 Codis，它不需要另外的分布式存储来存
储节点槽位信息。

Redis Cluster 是一种服务器 Sharding 技术 (分片和路由都是在服务端实现)， **采用多主多从，每一个分区
都是由一个 Redis 主机和多个从机组成，片区和片区之间是相互平行的。**

Redis Cluster 集群采用了 P 2 P 的模式，完全去中心化。

**3 主 3 从六个节点的 Redis 集群（Redis-Cluster）**

Redis 集群是一个提供在多个 Redis 节点间共享数据的程序集。

下图以三个 master 节点和三个 slave 节点作为示例。


Redis 集群有 16384 个哈希槽，每个 key 通过 CRC 16 校验后对 16384 取模来决定放置哪个槽。

集群的每个节点负责一部分 hash 槽，如图中 slots 所示。

为了使在部分节点失败或者大部分节点无法通信的情况下集群仍然可用，所以集群使用了主从复制模
型，每个节点都会有 1-n 个从节点。

例如 master-A 节点不可用了，集群便会选举 slave-A 节点作为新的主节点继续服务。

###### 中心化代理模式（proxy 模式）

这种方案，将分片工作交给专门的代理程序来做。代

理程序接收到来自业务程序的数据请求，根据路由规则，将这些请求分发给正确的 Redis 实例并返回给
业务程序。

```
其基本原理是：通过中间件的形式，Redis客户端把请求发送到代理 proxy，代理 proxy 根据路由
规则发送到正确的Redis实例，最后 代理 proxy 把结果汇集返回给客户端。
```
redis 代理分片用得最多的就是 Twemproxy，由 Twitter 开源的 Redis 代理，其基本原理是：通过中间件
的形式，Redis 客户端把请求发送到 Twemproxy，Twemproxy 根据路由规则发送到正确的 Redis 实例，
最后 Twemproxy 把结果汇集返回给客户端。

这种机制下，一般会选用第三方代理程序（而不是自己研发），因为后端有多个 Redis 实例，所以这类
程序又称为分布式中间件。

这样的好处是，业务程序不用关心后端 Redis 实例，运维起来也方便。虽然会因此带来些性能损耗，但
对于 Redis 这种内存读写型应用，相对而言是能容忍的。


#### 聊聊：官方 Redis cluster 集群的原理？

Redis 集群通过数据分区来实现数据的分布式存储，通过自动故障转移实现高可用。

###### 集群创建

Redis 集群一般由多个节点组成，节点数量至少为 6 个才能保证组成完整高可用的集群。

每个节点需要开启配置 cluster-enabled yes，让 Redis 运行在集群模式下。

建议为集群内所有节点统一目录，一般划分三个目录：conf、data、log，分别存放配置、数据和日志
相关文件。

把 6 个节点配置统一放在 conf 目录下，集群相关配置如下：

集群模式的 Redis 除了原有的配置文件之外又加了一份集群配置文件。

当集群内节点信息发生变化，如添加节点、节点下线、故障转移等。

第一次启动时如果没有集群配置文件，它会自动创建一份，文件名称采用 cluster-config-file 参数项控
制，建议采用 node-{port}. conf 格式定义，通过使用端口号区分不同节点，防止同一机器下多个节点彼
此覆盖，造成集群信息异常。

如果启动时存在集群配置文件，节点会使用配置文件内容初始化集群信息。启动过程如图所示。

```
# 节点端口
port 6379
# 开启集群模式
cluster-enabled yes
# 节点超时时间，单位毫秒
cluster-node-timeout 15000
# 集群内部配置文件
cluster-config-file "nodes-6379.conf"
```
```
1 2 3 4 5 6 7 8
```

节点会自动保存集群状态到配置文件中。

需要注意的是，Redis 自动维护集群配置文件，不要手动修改，防止节点重启时产生集群信息错乱。

###### 节点握手

Redis 集群一般由多个节点组成，节点数量至少为 6 个才能保证组成完整高可用的集群。

节点握手是指一批运行在集群模式下的节点通过 Gossip 协议彼此通信，达到感知对方的过程。

节点握手是集群彼此通信的第一步，由客户端发起命令：cluster meet{ip}{port}，如图所示。

下图是一个例子：


图中执行的命令是：cluster meet 127.0.0.16380 让节点 6379 和 6380 节点进行握手通信。cluster meet
命令是一个异步命令，执行之后立刻返回。内部发起与目标节点进行握手通信，如图所示。
1 ）节点 6379 本地创建 6380 节点信息对象，并发送 meet 消息。
2 ）节点 6380 接受到 meet 消息后，保存 6379 节点信息并回复 pong 消息。
3 ）之后节点 6379 和 6380 彼此定期通过 ping/pong 消息进行正常的节点通信。
这里的 meet、ping、pong 消息是 Gossip 协议通信的载体，之后的节点通信部分做进一步介绍，它的主
要作用是节点彼此交换状态数据信息。 6379 和 6380 节点通过 meet 命令彼此建立通信之后，集群结构如
图所示。对节点 6379 和 6380 分别执行 cluster nodes 命令，可以看到它们彼此已经感知到对方的存在。

cluster meet 命令进行节点握手的过程

通过两个节点握手的集群结构


下面分别执行 meet 命令让其他节点加入到集群中：

我们只需要在集群内任意节点上执行 cluster meet 命令加入新节点，握手状态会通过消息在集群内传
播，这样其他节点会自动发现新节点并发起握手流程。最后执行 cluster nodes 命令确认 6 个节点都彼此
感知并组成集群：

节点建立握手之后集群还不能正常工作，这时集群处于下线状态，所有的数据读写都被禁止。通过如下
命令可以看到：

```
127.0.0.1: 6379 > cluster nodes
cfb28ef1deee4e0fa78da86abe5d24566744411e 127.0.0.1: 6379 myself,master - 0 0
0 connected
8e41673d59c9568aa9d29fb174ce733345b3e8f1 127.0.0.1: 6380 master - 0
1468073534265
1 connected
127.0.0.1: 6380 > cluster nodes
cfb28ef1deee4e0fa78da86abe5d24566744411e 127.0.0.1: 6379 master - 0
1468073571641
0 connected
8e41673d59c9568aa9d29fb174ce733345b3e8f1 127.0.0.1: 6380 myself,master - 0 0
1 connected
```
```
1 2 3 4 5 6 7 8 9
```
```
10
```
```
127.0.0.1: 6379 >cluster meet 127.0.0.1 6381
127.0.0.1: 6379 >cluster meet 127.0.0.1 6382
127.0.0.1: 6379 >cluster meet 127.0.0.1 6383
127.0.0.1: 6379 >cluster meet 127.0.0.1 6384
```
```
1
2
3
4
```
```
127.0.0.1: 6379 > cluster nodes
4fa7eac4080f0b667ffeab9b87841da49b84a6e4 127.0.0.1: 6384 master - 0
1468073975551
5 connected
cfb28ef1deee4e0fa78da86abe5d24566744411e 127.0.0.1: 6379 myself,master - 0 0
0 connected
be9485a6a729fc98c5151374bc30277e89a461d8 127.0.0.1: 6383 master - 0
1468073978579
4 connected
40622f9e7adc8ebd77fca0de9edfe691cb8a74fb 127.0.0.1: 6382 master - 0
1468073980598
3 connected
8e41673d59c9568aa9d29fb174ce733345b3e8f1 127.0.0.1: 6380 master - 0
1468073974541
1 connected
40b8d09d44294d2e23c7c768efc8fcd153446746 127.0.0.1: 6381 master - 0
1468073979589
2 connected
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
```
```
12
```
```
127.0.0.1: 6379 > set hello redis
(error) CLUSTERDOWN The cluster is down
```
```
1
2
```

通过 cluster info 命令可以获取集群当前状态：

###### 分配槽（slot）

Redis 集群把所有的数据映射到 16384 个槽中。

每个节点对应若干个槽，只有当节点分配了槽，才能响应和这些槽关联的键命令。通过 cluster
addslots 命令为节点分配槽。

```
127.0.0.1: 6379 > cluster info
cluster_state:fail
cluster_slots_assigned: 0
cluster_slots_ok: 0
cluster_slots_pfail: 0
cluster_slots_fail: 0
cluster_known_nodes: 6
cluster_size: 0
...
```
```
1 2 3 4 5 6 7 8 9
```

分配槽

###### 故障转移

Redis 集群的故障转移和哨兵的故障转移类似，但是 Redis 集群中所有的节点都要承担状态维护的任务。

**故障发现**

Redis 集群内节点通过 ping/pong 消息实现节点通信，集群中每个节点都会定期向其他节点发送 ping 消
息，接收节点回复 pong 消息作为响应。如果在 cluster-node-timeout 时间内通信一直失败，则发送节
点会认为接收节点存在故障，把接收节点标记为主观下线（pfail）状态。

当某个节点判断另一个节点主观下线后，相应的节点状态会跟随消息在集群内传播。通过 Gossip 消息传
播，集群内节点不断收集到故障节点的下线报告。当半数以上持有槽的主节点都标记某个节点是主观下
线时。触发客观下线流程。


**故障恢复**

故障节点变为客观下线后，如果下线节点是持有槽的主节点则需要在它的从节点中选出一个替换它，从
而保证集群的高可用。

故障恢复流程

```
1. 资格检查 每个从节点都要检查最后与主节点断线时间，判断是否有资格替换故障 的主节点。
```

```
2. 准备选举时间 当从节点符合故障转移资格后，更新触发故障选举的时间，只有到达该 时间后才能
执行后续流程。
3. 发起选举 当从节点定时任务检测到达故障选举时间（failover_auth_time）到达后，发起选举流
程。
4. 选举投票 持有槽的主节点处理故障选举消息。投票过程其实是一个领导者选举的过程，如集群内
有N个持有槽的主节 点代表有N张选票。由于在每个配置纪元内持有槽的主节点只能投票给一个
从节点，因此只能有一个从节点获得N/2+1的选票，保证能够找出唯一的从节点。
```
```
5. 替换主节点 当从节点收集到足够的选票之后，触发替换主节点操作。
```
#### 聊聊：部署 Redis 集群至少需要几个物理节点？

在投票选举的环节，故障主节点也算在投票数内，假设集群内节点规模是 3 主 3 从，

其中有 2 个主节点部署在一台机器上，当这台机器宕机时，由于从节点无法收集到 3/2+1 个主节点选票
将导致故障转移失败。

这个问题也适用于故障发现环节。

因此部署集群时所有主节点最少需要部署在 3 台物理机上才能避免单点问题。

#### 聊聊：说说集群的伸缩？

Redis 集群提供了灵活的节点扩容和收缩方案，可以在不影响集群对外服务的情况下，为集群添加节点
进行扩容也可以下线部分节点进行缩容。


其实，集群扩容和缩容的关键点，就在于槽和节点的对应关系，扩容和缩容就是将一部分槽和数据迁
移给新节点。

例如下面一个集群，每个节点对应若干个槽，每个槽对应一定的数据，如果希望加入 1 个节点希望实现
集群扩容时，需要通过相关命令把一部分槽和内容迁移给新节点。

缩容也是类似，先把槽和数据迁移到其它节点，再把对应的节点下线。


#### 聊聊：能说说布隆过滤器吗？

布隆过滤器，它是一个连续的数据结构，每个存储位存储都是一个 bit，即 0 或者 1 , 来标识数据是否
存在。

存储数据的时时候，使用 K 个不同的哈希函数将这个变量映射为 bit 列表的的 K 个点，把它们置为 1 。

我们判断缓存 key 是否存在，同样，K 个哈希函数，映射到 bit 列表上的 K 个点，判断是不是 1 ：

```
如果全不是 1 ，那么key不存在；
如果都是 1 ，也只是表示key可能存在。
```
布隆过滤器也有一些缺点：

```
1. 它在判断元素是否在集合中时是有一定错误几率，因为哈希算法有一定的碰撞的概率。
2. 不支持删除元素。
```
#### 聊聊：如何保证本地缓存和分布式缓存的一致？

在日常的开发中，我们常常采用两级缓存：本地缓存+分布式缓存。

所谓本地缓存，就是对应服务器的内存缓存，比如 guava，分布式缓存基本就是采用 Redis。

那么问题来了，本地缓存和分布式缓存怎么保持数据一致？


Redis 缓存，数据库发生更新，直接删除缓存的 key 即可，因为对于应用系统而言，它是一种中心化的缓
存。

但是本地缓存，它是非中心化的，散落在分布式服务的各个节点上，没法通过客户端的请求删除本地缓
存的 key，所以得想办法通知集群所有节点，删除对应的本地缓存 key。


可以采用消息队列的方式：

```
1. 采用Redis本身的Pub/Sub机制，分布式集群的所有节点订阅删除本地缓存频道，删除Redis缓存
的节点，同事发布删除本地缓存消息，订阅者们订阅到消息后，删除对应的本地key。但是Redis
的发布订阅不是可靠的，不能保证一定删除成功。
2. 引入专业的消息队列，比如RocketMQ，保证消息的可靠性，但是增加了系统的复杂度。
3. 设置适当的过期时间兜底，本地缓存可以设置相对短一些的过期时间。
```
#### 聊聊：如何保证缓存和数据库数据的一致性？

根据 CAP 理论，在保证可用性和分区容错性的前提下，无法保证一致性，

所以缓存和数据库的绝对一致是不可能实现的，只能尽可能保存缓存和数据库的最终一致性。

**选择合适的缓存更新策略**

**1. 删除缓存而不是更新缓存**

当一个线程对缓存的 key 进行写操作的时候，如果其它线程进来读数据库的时候，读到的就是脏数据，
产生了数据不一致问题。


相比较而言，删除缓存的速度比更新缓存的速度快很多，所用时间相对也少很多，读脏数据的概率也小
很多。

**先更数据，后删缓存**

先更数据库还是先删缓存？这是一个问题。

更新数据，耗时可能在删除缓存的百倍以上。

在缓存中不存在对应的 key，数据库又没有完成更新的时候，如果有线程进来读取数据，并写入到缓
存，那么在更新成功之后，这个 key 就是一个脏数据。

毫无疑问，先删缓存，再更数据库，缓存中 key 不存在的时间的时间更长，有更大的概率会产生脏数
据。

目前最流行的缓存读写策略 cache-aside-pattern 就是采用先更数据库，再删缓存的方式。

**缓存不一致处理**

如果不是并发特别高，对缓存依赖性很强，其实一定程序的不一致是可以接受的。

但是如果对一致性要求比较高，那就得想办法保证缓存和数据库中数据一致。

缓存和数据库数据不一致常见的两种原因：


```
缓存key删除失败
并发导致写入了脏数据
```
缓存一致性

**消息队列保证 key 被删除**

可以引入消息队列，把要删除的 key 或者删除失败的 key 丢尽消息队列，利用消息队列的重试机制，重试
删除对应的 key。

这种方案看起来

不错，缺点是对业务代码有一定的侵入性。

**数据库订阅+消息队列保证 key 被删除** 可以用一个服务（比如阿里的 canal）去监听数据库的 binlog，获
取需要操作的数据。


然后用一个公共的服务获取订阅程序传来的信息，进行缓存删除操作。

这种方式降低了对业务的侵入，但其实整个系统的复杂度是提升的，适合基建完善的大厂。

**延时双删防止脏数据** 还有一种情况，是在缓存不存在的时候，写入了脏数据，这种情况在先删缓存，再
更数据库的缓存更新策略下发生的比较多，解决方案是延时双删。

简单说，就是在第一次删除缓存之后，过了一段时间之后，再次删除缓存。


这种方式的延时时间设置需要仔细考量和测试。

**设置缓存过期时间兜底**

这是一个朴素但是有用的办法，给缓存设置一个合理的过期时间，即使发生了缓存数据不一致的问题，
它也不会永远不一致下去，缓存过期的时候，自然又会恢复一致。

#### 聊聊：Redis 如何进行缓存降级

缓存降级，其实都应该是指服务降级。在访问量剧增、服务响应出现问题（如响应延迟或不响应）或非
核心服务影响到核心流程的性能的情况下，仍然需要保证核心服务可用，尽管可能一些非主要服务不可
用，这时就可以采取服务降级策略。


服务降级的最终目的是保证核心服务可用，即使是有损的。服务降级应当事先确定好降级方案，确定哪
些服务是可以降级的，哪些服务是不可降级的。根据当前业务情况及流量对一些服务和页面有策略的降
级，以此释放服务器资源以保证核心服务的正常运行。

降级往往会指定不同的级别，面临不同的异常等级执行不同的处理。根据服务方式：可以拒接服务，可
以延迟服务，也可以随机提供服务。根据服务范围：可以暂时禁用某些功能或禁用某些功能模块。总之
服务降级需要根据不同的业务需求采用不同的降级策略。主要的目的就是服务虽然有损但是总比没有
好。

#### 聊聊：怎么处理热 key？

```
什么是热Key？ 所谓的热key，就是访问频率比较的key。
```
比如，热门新闻事件或商品，这类 key 通常有大流量的访问，对存储这类信息的 Redis 来说，是不小的
压力。

假如 Redis 集群部署，热 key 可能会造成整体流量的不均衡，个别节点出现 OPS 过大的情况，极端情况下
热点 key 甚至会超过 Redis 本身能够承受的 OPS。

```
怎么处理热key？
```
对热 key 的处理，最关键的是对热点 key 的监控，可以从这些端来监控热点 key:

```
1. 客户端 客户端其实是距离key“最近”的地方，因为Redis命令就是从客户端发出的，例如在客户端
设置全局字典（key和调用次数），每次调用Redis命令时，使用这个字典进行记录。
2. 代理端 像Twemproxy、Codis这些基于代理的Redis分布式架构，所有客户端的请求都是通过代理
端完成的，可以在代理端进行收集统计。
3. Redis服务端 使用monitor命令统计热点key是很多开发和运维人员首先想到，monitor命令可以监
控到Redis执行的所有命令。
```
只要监控到了热 key，对热 key 的处理就简单了：

```
1. 把热key打散到不同的服务器，降低压力
```

```
2. 加入二级缓存，提前加载热key数据到内存中，如果redis宕机，走内存查询
```
#### 聊聊：缓存预热怎么做呢？

所谓缓存预热，就是提前把数据库里的数据刷到缓存里，通常有这些方法：

1 、直接写个缓存刷新页面或者接口，上线时手动操作

2 、数据量不大，可以在项目启动的时候自动进行加载

3 、定时任务刷新缓存.

#### 聊聊：热点 key 重建？问题？解决？

开发的时候一般使用“缓存+过期时间”的策略，既可以加速数据读写，又保证数据的定期更新，这种模式
基本能够满足绝大部分需求。

但是有两个问题如果同时出现，可能就会出现比较大的问题：

```
当前key是一个热点key（例如一个热门的娱乐新闻），并发量非常大。
重建缓存不能在短时间完成，可能是一个复杂计算，例如复杂的 SQL、多次IO、多个依赖等。在
缓存失效的瞬间，有大量线程来重建缓存，造成后端负载加大，甚至可能会让应用崩溃。
怎么处理呢？
```
要解决这个问题也不是很复杂，解决问题的要点在于：

```
减少重建缓存的次数。
数据尽可能一致。
较少的潜在危险。
```
所以一般采用如下方式：

```
1. 互斥锁（mutex key） 这种方法只允许一个线程重建缓存，其他线程等待重建缓存的线程执行
完，重新从缓存获取数据即可。
2. 永远不过期 “永远不过期”包含两层意思：
```
```
从缓存层面来看，确实没有设置过期时间，所以不会出现热点key过期后产生的问题，也就是“物
理”不过期。
从功能层面来看，为每个value设置一个逻辑过期时间，当发现超过逻辑过期时间后，会使用单独
的线程去构建缓存。
```
#### 聊聊：无底洞问题吗？如何解决？

```
什么是无底洞问题？
```
2010 年，Facebook 的 Memcache 节点已经达到了 3000 个，承载着 TB 级别的缓存数据。

但开发和运维人员发现了一个问题，为了满足业务要求添加了大量新 Memcache 节点，但是发现性能不
但没有好转反而下降了，当时将这种现象称为缓存的“ **无底洞** ”现象。

那么为什么会产生这种现象呢?

通常来说添加节点使得 Memcache 集群性能应该更强了，但事实并非如此。

键值数据库由于通常采用哈希函数将 key 映射到各个节点上，造成 key 的分布与业务无关，但是由于数
据量和访问量的持续增长，造成需要添加大量节点做水平扩容，导致键值分布到更多的节点上，所以无
论是 Memcache 还是 Redis 的分布式，批量操作通常需要从不同节点上获取，相比于单机批量操作只涉
及一次网络操作，分布式批量操作会涉及多次网络时间。


```
无底洞问题如何优化呢？
```
先分析一下无底洞问题：

```
客户端一次批量操作会涉及多次网络操作，也就意味着批量操作会随着节点的增多，耗时会不断增
大。
网络连接数变多，对节点的性能也有一定影响。
```
常见的优化思路如下：

```
命令本身的优化，例如优化操作语句等。
减少网络通信次数。
降低接入成本，例如客户端使用长连/连接池、NIO等。
```
#### 聊聊：Redis 报内存不足怎么处理？

Redis 内存不足有这么几种处理方式：

```
修改配置文件 redis.conf 的 maxmemory 参数，增加 Redis 可用内存
也可以通过命令set maxmemory动态设置内存上限
修改内存淘汰策略，及时释放内存空间
使用 Redis 集群模式，进行横向扩容。
```
#### 聊聊：Redis 的过期数据回收策略有哪些？

Redis 主要有 2 种过期数据回收策略：

**惰性删除**

惰性删除指的是当我们查询 key 的时候才对 key 进行检测，如果已经达到过期时间，则删除。显然，他有
一个缺点就是如果这些过期的 key 没有被访问，那么他就一直无法被删除，而且一直占用内存。

**定期删除**

定期删除指的是 Redis 每隔一段时间对数据库做一次检查，删除里面的过期 key。由于不可能对所有 key
去做轮询来删除，所以 Redis 会每次随机取一些 key 去做检查和删除。

#### 聊聊：Redis 阻塞？怎么解决？


Redis 发生阻塞，可以从以下几个方面排查：

**API 或数据结构使用不合理**

通常 Redis 执行命令速度非常快，但是不合理地使用命令，可能会导致执行速度很慢，导致阻塞，

###### 慢查询问题

对于高并发的场景，应该尽量避免在大对象上执行算法复杂度超过 O（n）的命令。

对慢查询的处理分为两步：

```
1. 发现慢查询：slowlog get{n}命令可以获取最近 的n条慢查询命令；
```
```
2. 发现慢查询后，可以从两个方向去优化慢查询： 1 ）修改为低算法复杂度的命令，如hgetall改为
hmget等，禁用keys、sort等命 令 2 ）调整大对象：缩减大对象数据或把大对象拆分为多个小对
象，防止一次命令操作过多的数据。
```
###### CPU 饱和的问题

单线程的 Redis 处理命令时只能使用一个 CPU。

而 CPU 饱和是指 Redis 单核 CPU 使用率跑到接近 100%。

针对这种情况，处理步骤一般如下：

```
1. 判断当前Redis并发量是否已经达到极限，可以使用统计命令redis-cli-h{ip}-p{port}--stat获
取当前 Redis使用情况
2. 如果Redis的请求几万+，那么大概就是Redis的OPS已经到了极限，应该做集群化水品扩展来
分摊OPS压力
```

```
3. 如果只有几百几千，那么就得排查命令和内存的使用
```
###### 持久化相关的阻塞

对于开启了持久化功能的 Redis 节点，需要排查是否是持久化导致的阻塞。

```
1. fork阻塞 fork操作发生在RDB和AOF重写时，Redis主线程调用fork操作产生共享 内存的子进
程，由子进程完成持久化文件重写工作。如果fork操作本身耗时过长，必然会导致主线程的
阻塞。
2. AOF刷盘阻塞 当我们开启AOF持久化功能时，文件刷盘的方式一般采用每秒一次，后台线程
每秒对AOF文件做fsync操作。当硬盘压力过大时，fsync操作需要等 待，直到写入完成。如
果主线程发现距离上一次的fsync成功超过 2 秒，为了 数据安全性它会阻塞直到后台线程执行
fsync操作完成。
3. HugePage写操作阻塞 对于开启Transparent HugePages的 操作系统，每次写命令引起的复
制内存页单位由4K变为2MB，放大了 512 倍，会拖慢写操作的执行时间，导致大量写操作慢
查询。
```
#### 聊聊：大 key 问题了解吗？

Redis 使用过程中，有时候会出现大 key 的情况，比如：

```
单个简单的key存储的value很大，size超过10KB
hash， set，zset，list 中存储过多的元素（以万为单位）
大 key 会造成什么问题呢？
```
```
客户端耗时增加，甚至超时
对大 key 进行 IO 操作时，会严重占用带宽和 CPU
造成 Redis 集群中数据倾斜
主动删除、被动删等，可能会导致阻塞
```
```
如何找到大 key?
```
```
bigkeys 命令：使用 bigkeys 命令以遍历的方式分析 Redis 实例中的所有 Key，并返回整体统计信息
与每个数据类型中 Top 1 的大 Key
redis-rdb-tools：redis-rdb-tools 是由 Python 写的用来分析 Redis 的 rdb 快照文件用的工具，它可
以把 rdb 快照文件生成 json 文件或者生成报表用来分析 Redis 的使用详情。
```
```
如何处理大 key?
```

**删除大 key**

```
当 Redis 版本大于 4.0 时，可使用 UNLINK 命令安全地删除大 Key，该命令能够以非阻塞的方式，逐
步地清理传入的 Key。
当 Redis 版本小于 4.0 时，避免使用阻塞式命令 KEYS，而是建议通过 SCAN 命令执行增量迭代扫描
key，然后判断进行删除。
```
**压缩和拆分 key**

```
当 vaule 是 string 时，比较难拆分，则使用序列化、压缩算法将 key 的大小控制在合理范围内，但是
序列化和反序列化都会带来更多时间上的消耗。
当 value 是 string，压缩之后仍然是大 key，则需要进行拆分，一个大 key 分为不同的部分，记录每
个部分的 key，使用 multiget 等操作实现事务读取。
当 value 是 list/set 等集合类型时，根据预估的数据规模来进行分片，不同的元素计算后分到不同的
片。
```
#### 聊聊：Redis 常见性能问题和解决方案？

```
1. Master 最好不要做任何持久化工作，包括内存快照和 AOF 日志文件，特别是不要启用内存快照做
持久化。
2. 如果数据比较关键，某个 Slave 开启 AOF 备份数据，策略为每秒同步一次。
3. 为了主从复制的速度和连接的稳定性，Slave 和 Master 最好在同一个局域网内。
4. 尽量避免在压力较大的主库上增加从库。
5. Master 调用 BGREWRITEAOF 重写 AOF 文件，AOF 在重写的时候会占大量的 CPU 和内存资源，
导致服务 load 过高，出现短暂服务暂停现象。
6. 为了 Master 的稳定性，主从复制不要用图状结构，用单向链表结构更稳定，即主从关为：
Master<–Slave 1<–Slave 2<–Slave 3...，这样的结构也方便解决单点故障问题，实现 Slave 对
Master 的替换，也即，如果 Master 挂了，可以立马启用 Slave 1 做 Master，其他不变。
```

#### 聊聊：Redis 和 Lua 脚本的使用了解吗？

Redis 的事务功能比较简单，平时的开发中，可以利用 Lua 脚本来增强 Redis 的命令。

Lua 脚本能给开发人员带来这些好处：

```
Lua 脚本在 Redis 中是原子执行的，执行过程中间不会插入其他命令。
Lua 脚本可以帮助开发和运维人员创造出自己定制的命令，并可以将这些命令常驻在 Redis 内存
中，实现复用的效果。
Lua 脚本可以将多条命令一次性打包，有效地减少网络开销。
```
比如这一段很（烂）经（大）典（街）的秒杀系统利用 lua 扣减 Redis 库存的脚本：

#### 聊聊：Redis 的管道了解吗？

Redis 提供三种将客户端多条命令打包发送给服务端执行的方式：

Pipelining (管道) 、 Transactions (事务) 和 Lua Scripts (Lua 脚本) 。

**Pipelining** （管道）

Redis 管道是三者之中最简单的，当客户端需要执行多条 redis 命令时，可以通过管道一次性将要执行
的多条命令发送给服务端，其作用是为了降低 RTT (Round Trip Time) 对性能的影响，比如我们使用 nc
命令将两条指令发送给 redis 服务端。

Redis 服务端接收到管道发送过来的多条命令后，会一直执命令，并将命令的执行结果进行缓存，直到
最后一条命令执行完成，再所有命令的执行结果一次性返回给客户端。

```
-- 库存未预热
if (redis.call ('exists', KEYS[ 2 ]) == 1 ) then
return - 9 ;
end;
-- 秒杀商品库存存在
if (redis.call ('exists', KEYS[ 1 ]) == 1 ) then
local stock = tonumber (redis.call ('get', KEYS[ 1 ]));
local num = tonumber (ARGV[ 1 ]);
-- 剩余库存少于请求数量
if (stock < num) then
return - 3
end;
-- 扣减库存
if (stock >= num) then
redis.call ('incrby', KEYS[ 1 ], 0 - num);
-- 扣减成功
return 1
end;
return - 2 ;
end;
-- 秒杀商品库存不存在
return - 1 ;
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
12
13
14
15
16
17
18
19
20
21
22
```

**Pipelining 的优势**

在性能方面， Pipelining 有下面两个优势：

```
节省了 RTT ：将多条命令打包一次性发送给服务端，减少了客户端与服务端之间的网络调用次数
减少了上下文切换 ：当客户端/服务端需要从网络中读写数据时，都会产生一次系统调用，系统调
用是非常耗时的操作，其中设计到程序由用户态切换到内核态，再从内核态切换回用户态的过程。
当我们执行 10 条 redis 命令的时候，就会发生 10 次用户态到内核态的上下文切换，但如果我们
使用 Pipeining 将多条命令打包成一条一次性发送给服务端，就只会产生一次上下文切换。
```
#### 聊聊：假如 Redis 里面有 1 亿个 key，其中有 10 w 个 key 是以

#### 某个固定的已知的前缀开头的，如何将它们全部找出来？

使用 keys 指令可以扫出指定模式的 key 列表。

但是要注意 keys 指令会导致线程阻塞一段时间，线上服务会停顿，直到指令执行完毕，服务才能恢
复。

这个时候可以使用 scan 指令，scan 指令可以无阻塞的提取出指定模式的 key 列表，但是会有一定
的重复概率，在客户端做一次去重就可以了，但是整体所花费的时间会比直接用 keys 指令长。

#### 聊聊：说说 Redis 底层数据结构？


Redis 有 **动态字符串 (sds)** 、 **链表 (list)** 、 **字典 (ht)** 、 **跳跃表 (skiplist)** 、 **整数集合 (intset)** 、 **压缩列表
(ziplist)** 等底层数据结构。

Redis 并没有使用这些数据结构来直接实现键值对数据库，而是基于这些数据结构创建了一个对象系
统，来表示所有的 key-value。

我们常用的数据类型和编码对应的映射关系：

简单看一下底层数据结构，如果对数据结构掌握不错的话，理解这些结构应该不是特别难：

```
1. 字符串 ：redis 没有直接使用 C 语言传统的字符串表示，而是自己实现的叫做简单动态字符串 SDS 的
抽象类型。
C 语言的字符串不记录自身的⻓度信息，而 SDS 则保存了⻓度信息，这样将获取字符串⻓度的时间
由 O (N) 降低到了 O (1)，同时可以避免缓冲区溢出和减少修改字符串⻓度时所需的内存重分配次
数。
```

SDS

```
1. 链表 linkedlist ：redis 链表是一个双向无环链表结构，很多发布订阅、慢查询、监视器功能都是使
用到了链表来实现，每个链表的节点由一个 listNode 结构来表示，每个节点都有指向前置节点和后
置节点的指针，同时表头节点的前置和后置节点都指向 NULL。
```
```
1. 字典 dict ：用于保存键值对的抽象数据结构。Redis 使用 hash 表作为底层实现，一个哈希表里可以
有多个哈希表节点，而每个哈希表节点就保存了字典里中的一个键值对。每个字典带有两个 hash
表，供平时使用和 rehash 时使用，hash 表使用链地址法来解决键冲突，被分配到同一个索引位置
的多个键值对会形成一个单向链表，在对 hash 表进行扩容或者缩容的时候，为了服务的可用性，
```

```
rehash 的过程不是一次性完成的，而是渐进式的。
```
2. **跳跃表 skiplist** ：跳跃表是有序集合的底层实现之一，Redis 中在实现有序集合键和集群节点的内
部结构中都是用到了跳跃表。Redis 跳跃表由 zskiplist 和 zskiplistNode 组成，zskiplist 用于保存跳
跃表信息（表头、表尾节点、⻓度等），zskiplistNode 用于表示表跳跃节点，每个跳跃表节点的
层高都是 1-32 的随机数，在同一个跳跃表中，多个节点可以包含相同的分值，但是每个节点的成
员对象必须是唯一的，节点按照分值大小排序，如果分值相同，则按照成员对象的大小排序。


```
3. 整数集合 intset ：用于保存整数值的集合抽象数据结构，不会出现重复元素，底层实现为数组。
```
```
4. 压缩列表 ziplist ：压缩列表是为节约内存而开发的顺序性数据结构，它可以包含任意多个节点，每
个节点可以保存一个字节数组或者整数值。
```
压缩列表组成

#### 聊聊：Redis 的 SDS 和 C 中字符串相比有什么优势？

C 语言使用了一个长度为 N+1 的字符数组来表示长度为 N 的字符串，并且字符数组最后一个元素总是
\0，这种简单的字符串表示方式不符合 Redis 对字符串在安全性、效率以及功能方面的要求。

C 语言的字符串

```
C 语言的字符串可能有什么问题？
```
这样简单的数据结构可能会造成以下一些问题：

```
获取字符串长度复杂度高 ：因为 C 不保存数组的长度，每次都需要遍历一遍整个数组，时间复杂
度为 O (n)；
不能杜绝缓冲区溢出/内存泄漏的问题 : C 字符串不记录自身长度带来的另外一个问题是容易造成
缓存区溢出（buffer overflow），例如在字符串拼接的时候，新的
C 字符串只能保存文本数据 → 因为 C 语言中的字符串必须符合某种编码（比如 ASCII），例如中
间出现的 '\0' 可能会被判定为提前结束的字符串而识别不了；
```
```
Redis 如何解决？优势？
```

Redis sds

简单来说一下 Redis 如何解决的：

```
1. 多增加 len 表示当前字符串的长度 ：这样就可以直接获取长度了，复杂度 O (1)；
2. 自动扩展空间 ：当 SDS 需要对字符串进行修改时，首先借助于 len 和 alloc 检查空间是否满足
修改所需的要求，如果空间不够的话，SDS 会自动扩展空间，避免了像 C 字符串操作中的溢出情
况；
3. 有效降低内存分配次数 ：C 字符串在涉及增加或者清除操作时会改变底层数组的大小造成重新分
配，SDS 使用了空间预分配和惰性空间释放机制，简单理解就是每次在扩展时是成倍的多分配
的，在缩容是也是先留着并不正式归还给 OS；
4. 二进制安全 ：C 语言字符串只能保存 ascii 码，对于图片、音频等信息无法保存，SDS 是二进制
安全的，写入什么读取就是什么，不做任何过滤和限制；
```
#### 聊聊：字典是如何实现的？Rehash 了解吗？

字典是 Redis 服务器中出现最为频繁的复合型数据结构。除了 **hash** 结构的数据会用到字典外，整个
Redis 数据库的所有 key 和 value 也组成了一个 **全局字典** ，还有带过期时间的 key 也是一个字典。
_(_ 存储在 _RedisDb_ 数据结构中 _)_

```
字典结构是什么样的呢？
```
**Redis** 中的字典相当于 Java 中的 **HashMap** ，内部实现也差不多类似，采用哈希与运算计算下标位置；
通过 **"数组 + 链表" *的** **_*_** **链地址法** 来解决哈希冲突，同时这样的结构也吸收了两种不同数据结构的优
点。

```
字典是怎么扩容的？
```

字典结构内部包含 **两个 hashtable** ，通常情况下只有一个哈希表 ht[0] 有值，在扩容的时候，把 ht[0]
里的值 rehash 到 ht[1]，然后进行 **渐进式 rehash** ——所谓渐进式 rehash，指的是这个 rehash 的动作并
不是一次性、集中式地完成的，而是分多次、渐进式地完成的。

待搬迁结束后，h[1]就取代 h[0]存储字典的元素。

#### 聊聊：跳跃表是如何实现的？原理？

PS: 跳跃表是比较常问的一种结构。

跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其它节点的指针，从而达到
快速访问节点的目的。

```
为什么使用跳跃表?
```
首先，因为 zset 要支持随机的插入和删除，所以它 **不宜使用数组来实现** ，关于排序问题，我们也很容
易就想到 **红黑树/ 平衡树** 这样的树形结构，为什么 Redis 不使用这样一些结构呢？

```
1. 性能考虑： 在高并发的情况下，树形结构需要执行一些类似于 rebalance 这样的可能涉及整棵树
的操作，相对来说跳跃表的变化只涉及局部；
2. 实现考虑： 在复杂度与红黑树相同的情况下，跳跃表实现起来更简单，看起来也更加直观；
```
基于以上的一些考虑，Redis 基于 **William Pugh** 的论文做出一些改进后采用了 **跳跃表** 这样的结构。

本质是解决查找问题。

```
跳跃表是怎么实现的？
```
跳跃表的节点里有这些元素：

```
层跳跃表节点的 level 数组可以包含多个元素，每个元素都包含一个指向其它节点的指针，程序可
以通过这些层来加快访问其它节点的速度，一般来说，层的数量月多，访问其它节点的速度就越
快。
每次创建一个新的跳跃表节点的时候，程序都根据幂次定律，随机生成一个介于 1 和 32 之间的值作
为 level 数组的大小，这个大小就是层的“高度”
前进指针每个层都有一个指向表尾的前进指针（level[i]. forward 属性），用于从表头向表尾方向访
问节点。
```

```
我们看一下跳跃表从表头到表尾，遍历所有节点的路径：
```
```
跨度层的跨度用于记录两个节点之间的距离。跨度是用来计算排位（rank）的：在查找某个节点
的过程中，将沿途访问过的所有层的跨度累计起来，得到的结果就是目标节点在跳跃表中的排位。
例如查找，分值为 3.0、成员对象为 o 3 的节点时，沿途经历的层：查找的过程只经过了一个层，并
且层的跨度为 3 ，所以目标节点在跳跃表中的排位为 3 。
```
```
分值和成员节点的分值（score 属性）是一个 double 类型的浮点数，跳跃表中所有的节点都按分值
从小到大来排序。
节点的成员对象（obj 属性）是一个指针，它指向一个字符串对象，而字符串对象则保存这一个
SDS 值。
```
#### 聊聊：压缩列表了解吗？

压缩列表是 Redis **为了节约内存** 而使用的一种数据结构，是由一系列特殊编码的连续内存快组成的顺序
型数据结构。

一个压缩列表可以包含任意多个节点（entry），每个节点可以保存一个字节数组或者一个整数值。

压缩列表由这么几部分组成：

```
zlbyttes : 记录整个压缩列表占用的内存字节数
zltail : 记录压缩列表表尾节点距离压缩列表的起始地址有多少字节
zllen : 记录压缩列表包含的节点数量
entryX : 列表节点
zlend : 用于标记压缩列表的末端
```

压缩列表示例

#### 聊聊：快速列表 quicklist 了解吗？

Redis 早期版本存储 list 列表数据结构使用的是压缩列表 ziplist 和普通的双向链表 linkedlist，也就是说
当元素少时使用 ziplist，当元素多时用 linkedlist。

但考虑到链表的附加空间相对较高，prev 和 next 指针就要占去 16 个字节（ 64 位操作系统占用 8
个字节），另外每个节点的内存都是单独分配，会家具内存的碎片化，影响内存管理效率。

后来 Redis 新版本（3.2）对列表数据结构进行了改造，使用 quicklist 代替了 ziplist 和
linkedlist，quicklist 是综合考虑了时间效率与空间效率引入的新型数据结构。

quicklist 由 list 和 ziplist 结合而成，它是一个由 ziplist 充当节点的双向链表。

#### 聊聊：Redis 实现分布式锁了解吗？

Redis 是分布式锁本质上要实现的目标就是在 Redis 里面占一个“茅坑”，当别的进程也要来占时，发现已
经有人蹲在那里了，就只好放弃或者稍后再试。

```
V 1：setnx 命令
```

占坑一般是使用 setnx (set if not exists) 指令，只允许被一个客户端占坑。先来先占，用完了，再调用
del 指令释放茅坑。

但是有个问题，如果逻辑执行到中间出现异常了，可能会导致 del 指令没有被调用，这样就会陷入死
锁，锁永远得不到释放。

```
V 2: 锁超时释放
```
```
> setnx lock: fighter true
OK
... do something critical ...
> del lock:fighter
(integer) 1
```
```
1
2
3
4
5
```

所以在拿到锁之后，再给锁加上一个过期时间，比如 5 s，这样即使中间出现异常也可以保证 5 秒之后

锁会自动释放。

但是以上逻辑还有问题。

如果在 setnx 和 expire 之间服务器进程突然挂掉了，可能是因为机器掉电或者是被人为杀掉的，就会
导致 expire 得不到执行，也会造成死锁。

这种问题的根源就在于 setnx 和 expire 是两条指令而不是原子指令。如果这两条指令可以一起执行就
不会出现问题。

```
V 3: set 指令
```
这个问题在 Redis 2.8 版本中得到了解决，这个版本加入了 set 指令的扩展参数，使得 setnx 和 expire
指令可以一起执行。

```
> setnx lock: fighter true
OK
> expire lock: fighter 5
... do something critical ...
> del lock:fighter
(integer) 1
```
```
1 2 3 4 5 6
```

上面这个指令就是 setnx 和 expire 组合在一起的原子指令，这个就算是比较完善的分布式锁了。

当然实际的开发，没人会去自己写分布式锁的命令，因为有专业的轮子—— **Redisson** 。

#### 聊聊：用过分布式锁吗？遇到过什么问题？如何解决的？

###### 为什么需要分布式锁？

微服务的架构下，多个应用服务要同时对同一条数据做修改，那么要确保数据的一致性，就只能有一个
应用修改成功。

下图中，server 1、server 2、server 3 这三个服务都要修改 amount 这个数据，每个服务更新的值不
同，

为了保证数据的正确性，三个服务都向 lock server 服务申请分布式排他权限，最终 server 2 拿到了修改
权限，即 server 2 将 amount 更新为 2 ，其他服务由于没有获取到修改权限则返回更新失败。

```
set lock: fighter 3 true ex 5 nx OK ... do something critical ... > del
lock:codehole
```
```
1
```

###### 分布式锁的实现方案

```
基于数据库的悲观锁或者乐观锁
基于 redis 实现分布式锁
基于 zookeeper 实现分布式锁
基于其他的中间件实现分布式锁
```
###### 基于数据库实现分布式锁

性能比较低，数据库的性能，摆在那儿

和业务相关度高，无论是悲观锁或者乐观锁，都是和业务高度耦合的

通用的分布式锁方案，一般是基于 redis、zookeeper 等其他的中间件实现。

请参见：Redis 分布式锁 （图解-秒懂-史上最全）

###### 基于 redis 实现分布式锁

因为 redis 是一个单独的非业务服务，不会受到其他业务服务的限制，所有的业务服务都可以向 redis 发
送写入命令，

且只有一个业务服务可以写入命令成功，那么这个写入命令成功的服务即获得了锁，可以进行后续对资
源的操作，其他未写入成功的服务，则进行其他处理。


###### 简单加锁：使用 set 的命令时，同时设置过期时间

早期版本使用 setnx (set if not exists) 指令简单加锁，expire 设置锁过期时间。由于 setnx 和 expire 是
两条指令而不是原子指令。如果中间出现问题，有可能造成永远不过期而发生死锁。如果这两条指令可
以一起执行就不会出现问题。

新的版本使用 set 的命令时，同时设置过期时间，示例如下：

这样就完美的解决了分布式锁的原子性； set 命令的完整格式：

```
set key value [EX seconds] [PX milliseconds] [NX|XX]
```
使用 set 命令实现加锁操作，先展示加锁的简单代码实习，再带大家慢慢解释为什么这样实现。

###### 锁的释放

当客户端 1 操作完后，释放锁资源，即删除 key 。

如果没有删除，则在过期时间之后，锁会自动释放。

之后，其他客户端尝试获取锁时，则会获取锁成功。

###### 锁过期处理

假如服务 A 加锁成功，锁会在 10 s 后自动释放，但由于业务复杂，执行时间过长，10 s 内还没执行完，此
时锁已经被 redis 自动释放掉了。

此时服务 B 就重新获取到了该锁，服务 B 开始执行他的业务，服务 A 在执行到第 12 s 的时候执行完了，那
么服务 A 会去释放锁，则此时释放的却是服务 B 刚获取到的锁。

这会有锁过期和释放其他服务锁这种严重的问题。

那么锁过期这种问题该如何处理的？

虽然可以通过增加删除 key 时间来处理这个问题，但是并没有从根本上解决。

假设设个 100 s，绝大多数都是 1 s 后就会释放锁，但是由于服务宕机，则会导致 100 s 内其他服务都无法
获取到锁，这也是灾难性的。

我们可以这样做，在锁将要过期的时候，如果服务还没有处理完业务，那么将这个锁再续一段时间。

比如设置 key 在 10 s 后过期，那么再开启一个守护线程，在第 8 s 的时候检测服务是否处理完，如果没有，
则将这个 key 再续 10 s 后过期。

```
127.0.0.1:6379> set unlock "234" EX 100 NX
(nil)
127.0.0.1:6379>
127.0.0.1:6379> set test "111" EX 100 NX
OK
```
```
1
2
3
4
5
```
```
EX seconds：设置失效时长，单位秒
PX milliseconds：设置失效时长，单位毫秒
NX：key 不存在时设置 value，成功返回 OK，失败返回 (nil)
XX：key 存在时设置 value，成功返回 OK，失败返回 (nil)
```
```
1
2
3
4
```

在 Redisson（Redis SDK 客户端）中，就已经帮我们实现了这个功能，这个自动续时的我们称其为”看门
狗”。

###### 如果进行线程标识，避免错误释放，并且保证释放的原子性？

每个服务在设置 value 的时候，带上自己服务的唯一标识，如 UUID，或者一些业务上的独特标识。

这样在删除 key 的时候，只删除自己服务之前添加的 key 就可以了。

如果需要先查看锁是否是自己服务添加的，需要先 get 取出来判断，然后再进行 del。

这样的话就无法保证原子性了。

我们可以通过 Lua 脚本，将这两个操作合并成一个操作，就可以保证其原子性了。

如果是在单 redis 实例的情况下，上面的已经完全实现了分布式锁的功能了。

关于 Lua 脚本的内容，请阅读《Java 高并发核心编程卷 3 》

###### 那么 Redis 宕机，Key 丢失怎么办？

在生产环境上，都会使用 redis 集群，但是，且主从数据并不是强一致性。

当主节点宕机后，主节点的数据还未来得及同步到从节点，进行主从切换后，新的主节点并没有老的主
节点的全部数据，这就会导致刚写入到老的主节点的锁在新的主节点并没有，其他服务来获取锁时还是
会加锁成功。

此时则会有 2 个服务都可以操作公共资源，此时的分布式锁则是不安全的。


redis 的作者也想到这个问题，于是他发明了 RedLock。

**什么是高可用的 RedLock？**

要实现高可用的 RedLock，需要至少 5 个实例（官方推荐），且每个实例都是 master，不需要从库和哨
兵。

RedLock 算法思想：

```
不能只在一个 redis 实例上创建锁，应该是在多个 redis 实例上创建锁，n / 2 + 1，必须在大多数
redis 节点上都成功创建锁，才能算这个整体的 RedLock 加锁成功，避免说仅仅在一个 redis 实例上
加锁而带来的问题。
```
这个场景是假设有一个 redis cluster，有 5 个 redis master 实例。然后执行如下步骤获取一把红锁：

```
1. 获取当前时间戳，单位是毫秒；
2. 跟上面类似，轮流尝试在每个 master 节点上创建锁，过期时间较短，一般就几十毫秒；
3. 尝试在大多数节点上建立一个锁，比如 5 个节点就要求是 3 个节点 n / 2 + 1；
4. 客户端计算建立好锁的时间，如果建立锁的时间小于超时时间，就算建立成功了；
5. 要是锁建立失败了，那么就依次之前建立过的锁删除；
6. 只要别人建立了一把分布式锁，你就得不断轮询去尝试获取锁。
```
即当客户端在大多数 redis 实例上申请加锁成功后，且加锁总耗时小于锁过期时间，则认为加锁成功。

释放锁需要向全部节点发送锁释放命令。

第 3 步为啥要计算申请锁前后的总耗时与锁释放时间进行对比呢?

因为如果申请锁的总耗时已经超过了锁释放时间，那么可能前面申请 redis 的锁已经被释放掉了，保证不
了大于等于 3 个实例都有锁存在了，锁也就没有意义了

这样的话分布式锁就真的没问题了嘛？

1 、得 5 个 redis 实例，成本大大增加

2 、可以通过上面的流程感受到，这个 RedLock 锁太重了

3 、主从切换这种场景绝大多数的时候不会碰到，偶尔碰到的话，保证最终的兜底操作我觉得也没
啥问题。

4 、 **分布式系统中的 NPC 问题**

RedLock 是基于 redis 实现的分布式锁，它能够保证以下特性：

```
互斥性：在任何时候，只能有一个客户端能够持有锁；避免死锁：
当客户端拿到锁后，即使发生了网络分区或者客户端宕机，也不会发生死锁；（利用 key 的存活时
间）
容错性：只要多数节点的 redis 实例正常运行，就能够对外提供服务，加锁或者释放锁；
```
###### 高可用的红锁会导致性能降低

提前说明，使用 redis 分布式锁，是追求高性能，在 cap 理论中，追求的是 ap 而不是 cp。


所以，如果追求高可用，建议使用 zookeeper 分布式锁。

```
redis 分布式锁可能导致的数据不一致性，建议使用业务补偿的方式去弥补。所以，不太建议使用
红锁，但是从学习的层面来说，大家还是一定要掌握的。
```
聊了这么多的 redis 实现分布式锁。也简单了解下 zookeeper 是如何实现分布式锁的吧。

###### 基于 zookeeper 实现分布式锁

尼恩的这篇博客，非常细致

Zookeeper 分布式锁 （图解+秒懂+史上最全）

###### 那么实际的工作中，该如何选择分布式锁呢?

AP Redis 分布式锁

CP Redis 红锁（>=5 个 redis 实例）、或者 Zookeeper 分布式锁

#### 聊聊：什么是 Redis 的脑裂问题？ 该如何解决？

什么是脑裂问题? 脑裂问题，通常分布式、高可用集群，是因为网络问题导致的共性问题。

所以，脑裂不是 redis 集群的专利， zookeeper 集群/elasticSearch 集群等等，都存在脑裂问题。

###### step 1： 回答一下，什么是脑裂问题?

在一个高可用集群中，当多个服务器在指定的时间内，由于网络的原因无法互相检测到对方，而各自形
成一个新的小规模集群，并且各小集群当中，会选举新的 master 节点，都对外提供独立的服务，

由于网络断裂的原因，一个高可用集群中，实际上分裂为多个小的集群，这种情况就称为裂脑。

也有的人称之为分区集群，或者大脑垂直分隔，互相接管对方的资源，出现多个 Master 的情况，都可以
称为脑裂。

脑裂 (Split-Brain) 是一个形象的比喻，好比“大脑分裂”，也就是本来一个“大脑”被拆分了两个或多个“大
脑”。

裂脑之后的后果是，可能会导致服务器端的数据不一致，或造成数据的丢失

###### step 2：嘚瑟一下，ZooKeeper 如何解决脑裂

安装 ZooKeeper 之前，需要规划一下节点，ZooKeeper 节点数有一个重要的要求： **ZooKeeper 集群节
点数必须是奇数** 。


这个要求，与 ZooKeeper 的默认解决脑裂的策略有关系。

对于一个集群，想要提高这个集群的可用性，通常会采用多机房部署，

比如，为了高可用，将一个由 6 个节点的 zkServer 集群，部署在了两个机房，具体如下图：

正常情况下，此集群只会有一个 Leader，

并且集群的 Leader 节点是集群通过选举的规则所有节点中选出来的，简称为选主。

那么如果机房之间，发生断网，一个子网是 3 个节点，

一个大的集群，被分割为 2 个小的集群，每个小的集群各自 3 个节点，

选举出各自的 leader，对外提供服务，发生脑裂。


zk 如何解决脑裂问题呢？

ZooKeeper 选主规则中很重要的一条是：要求“可用节点数量 > 总节点数量/2” 。

这条规则，叫做 Quorums 过半机制。

ZooKeeper 集群使用了一种简单的节点数过半机制，确保集群被分裂后，还能否正常工作。

Quorums 直接翻译是法定人数，就是通过投票的方式来，多数派才能选择 leader。ZooKeeper 默认设
置的是采用 Majority Qunroms 的方式来支持 Leader 选举。

过半机制就是“可用节点数量 > 总节点数量/2”，集群才能选举 Leader，才是可用的，才可以对外服务；

为什么要“可用节点数量 > 总节点数量/2”呢？

在上图中，如果机房之间的网络断了之后，两个机房内的 zkServer 还是可以相互通信的，如果不考虑
过半机制，那么就会出现每个机房内部都将选出一个 Leader。这就出现了集群脑裂 (Split-Brain)。

所以，要求 “可用节点数量 > 总节点数量/2”。

但是，在上面的例子中，每个 IDC 机房，每个小的集群各自 3 个节点，都没有过半，所以，每个小集群
都选举不了 Leader，都不可用，当然，整个集群也不可用用。

从而， ZooKeeper 集群节点数必须是基数。

发生断网之后，一定会出现一个大点的子集群和一个小的子集群。

```
小的集群里边，选举不了 leader，不能提供服务。
由大点的子集群，选举一个 leader，提供服务。
```
比如，集群节点只有 5 个，断网之后， 3 个节点的小集群，满足过半机制，还可以提供服务。


Quorums 过半机制，就是解决集群的脑裂问题的默认机制。

为啥 **ZooKeeper 集群节点数必须是奇数** 呢？

从上面的例子可以看到，Quorums 过半机制在偶数节点的场景下，发生失效，而集群节点数必须是
奇数可以规避这个问题。

更极端的例子是: 100 个节点的集群，如果网络问题导致分为两个部分， 50 个节点和 50 个节点，这样整
个集群还是不可用的，因为按照 Quorums 的方式必须 51 个节点才能保证选出 1 个 Leader。

所以，ZooKeeper 集群节点数必须是奇数，规避 Quorums 在偶数场景可能导致的无效问题。

另外，节点数配置成奇数，还有一个好处： **集群的容忍度更高，节省服务器资源** 。

```
比如 3 个节点的集群，Quorums = 2, 也就是说: 集群可以容忍 1 个节点失效，这时候还能选举出 1
个 lead，集群还可用.
比如 4 个节点的集群，它的 Quorums = 3，Quorums 要超过 3 ，相当于集群的容忍度还是 1 ，如果 2
个节点失效，那么整个集群还是无效的, 集群可以容忍的，仍然是 1 个节点失效，
```
所以：

**4 个节点的集群的容忍度 = 3 个节点的集群的容忍度** ，但是 4 个节点的集群多了 1 个节点，相当于浪费了
资源。

###### step 3：嘚瑟一下，elasticSearch 如何解决脑裂

ElasticSearch 和 zookeeper 集群一样，也存在脑裂问题。

不过，es 集群的 leader ，改名字了，叫做 Master 节点，不叫做 leader 节点，但是换汤不换药，本质
是一样的。

es 集群中，候选主节点（即有资格成为主节点、master 候选人）配置为：

```
node. master: true
node. data: false
```
```
1
2
```

从节点配置为：

候选主节点参与 master 的选举。

一个高可用的 Es 集群，候选 master 至少需要 3 个，保证 master 节点的高可用。

当然，可以更多，但是正式的 master 的选举，同样遵守 Quorums 过半机制。

只是， ES 必须手动设置法定候选人的数量，通过以下参数设置：

上面的参数值，设置超过所有候选节点一半以上来解决脑裂问题，即设置为 (N/2)+1；

该参数是用于控制选举行为发生的 **最小集群主节点数量** 。

当备选主节点的个数大于等于该参数的值，且备选主节点中 **有该参数个节点认为主节点挂了** ，进行选
举。

官方建议为（n/2）+1，n 为候选 master 个数（即有资格成为主节点的节点个数）

###### step 4： 再来回答 redis 集群的脑裂

包括：

```
哨兵 (sentinel) 模式下的脑裂
集群 (cluster) 模式下的脑裂
```
**哨兵 (sentinel) 模式下的脑裂**

哨兵 (sentinel) 模式下的脑裂，主要是由于网络分区，导致 master、slave 和 sentinel 三类节点处于不
同的网络分区。

此时哨兵无法感知到 master 的存在，会将 slave 提升为 master 节点。

此时就会存在两个 master，就像大脑分裂，那么原来的客户端往继续往旧的 master 写入数据，而新
的 master 就会丢失这些数据

下面是一个例子：

```
node. master: false
node. data: true
```
```
1
2
```
```
1 discovery. zen. minimum_master_nodes
```

1 个 master 与 3 个 slave 组成的哨兵模式（哨兵独立部署于其它机器），

刚开始时， 2 个应用服务器 server 1、server 2 都连接在 master 上，

如果 master 与 slave 及哨兵之间的网络发生故障，但是哨兵与 slave 之间通讯正常，

这时 3 个 slave 其中 1 个，经过哨兵投票后，提升为新 master，

如果恰好此时 server 1 仍然连接的是旧的 master，而 server 2 连接到了新的 master 上。

脑裂之后，会数据就不一致了，下面有两个例子：

```
1 ：基于 setNX 指令的分布式锁，可能会拿到相同的锁，因为这个锁，处于不同的 mater 上边；
```
```
2 ： 基于 incr 生成的全局唯一 id，也可能出现重复，因为这个 id，在不同的 master 上边。
```
**集群 (cluster) 模式下的脑裂**


cluster 模式下，这种情况要更复杂，例如集群中有 6 组分片，每给分片节点都有 1 主 1 从，

如果出现网络分区时，各种节点之间的分区组合都有可能。

**手动解决问题**

在正常情况下，如果 master 挂了，那么写入就会失败，

如果是手动解决，那么人为会检测 master 以及 slave 的网络状况，然后视情况，

如果是 master 挂了，重启 master，

如果是 master 与 slave 之间的连接断了，可以调试网络，

这样虽然麻烦，但是是可以保证只有一个 master 的，所以只要认真负责，不会出现脑裂。

**自动解决问题**

Redis cluter 内部中有一个故障转移机制，如果一旦发现 master 挂了，就在 slave 中选举新的 master 节
点以实现故障自动转移。

问题，就出现在这个自动故障转移上，如果一旦大家监测不到一个 master，尽管 master 还是在正常运
行，集群也认为它挂了，会在 slave 中选举新的 master，

而有一部分应用仍然与旧的 master 交互，当旧的 master 与新的 master 重新建立连接，旧的 master 会同
步新的 master 中的数据，而旧的 master 中的数据就会丢失。

所以，自动故障转移，在发生脑裂的之后恢复的时候，会导致老 master 数据的丢失

###### 如何解决脑裂？

设置每个 master 限制 slave 的数量


redis 的配置文件中，存在两个参数

```
第一个参数表示连接到 master 的最少 slave 数量
第二个参数表示 slave 连接到 master 的最大延迟时间
```
按照上面的配置，要求至少 3 个 slave 节点，且数据复制和同步的延迟不能超过 10 秒，否则的话 master
就会拒绝写请求，

配置了这两个参数之后，如果发生集群脑裂，原先的 master 节点接收到客户端的写入请求会拒绝，就可
以减少数据同步之后的数据丢失。

**注意：较新版本的 redis. conf 文件中的参数变成了**

解决 redis 中的异步复制情况下的数据丢失问题，也能使用这两个参数

配置这两个参数之后，如果发生集群脑裂，原先的 master 节点接收到写入请求就会拒绝，就会减少数据
同步之后的数据丢失

#### 聊聊：redis 挂了怎么办？ ( 字节面试题)

Redis 是基于内存的非关系型 K-V 数据库，既然它是基于内存的，如果 Redis 服务器挂了，数据就会丢
失。

为了避免数据丢失了，Redis 提供了持久化，即把数据保存到磁盘。

Redis 提供了 **RDB 和 AOF** 两种持久化机制，它持久化文件加载流程如下：

```
min-slaves-to-write 3
min-slaves-max-lag 10
```
```
1
2
```
```
min-replicas-to-write 3
min-replicas-max-lag 10
```
```
1
2
```

RDB，就是把内存数据以快照的形式保存到磁盘上。

**什么是快照?** 可以这样理解，给当前时刻的数据，拍一张照片，然后保存下来。

**RDB 持久化** ，是指在指定的时间间隔内，执行指定次数的写操作，将内存中的数据集快照写入磁盘中，
它是 Redis 默认的持久化方式。执行完操作后，在指定目录下会生成一个 dump. rdb 文件，Redis 重启的
时候，通过加载 dump. rdb 文件来恢复数据。RDB 触发机制主要有以下几种：

```
适合大规模的数据恢复场景，如备份，全量复制等
```
**RDB 缺点**


```
没办法做到实时持久化/秒级持久化。
新老版本存在 RDB 格式兼容问题
```
###### AOF

AOF（append only file） 持久化，采用日志的形式来记录每个写操作，追加到文件中，重启时再重新
执行 AOF 文件中的命令来恢复数据。它主要解决数据持久化的实时性问题。默认是不开启的。

AOF 的工作流程如下：

```
数据的一致性和完整性更高
```
**AOF 的缺点**

```
AOF 记录的内容越多，文件越大，数据恢复变慢。
```

## 阿里二面： BigKey、HotKey 问题严重，该

## 如何预防和解决

BigKey、HotKey 是日常生产中经常会碰到由于 redis 集群的不当访问，造成的线上问题。

而且，这也是常见的面试题。

在咱们社群的面试交流中，有很多小伙伴在面试网易、滴滴、京东等大厂的二面、三面中遇到了这个问
题。

前段时间，有一个小伙伴在面试阿里的时候，又遇到了此问题。

所以，尼恩在这里，结合行业生产案例，特意给大家，做一个彻底的、系统的梳理。

大家按照这个思路去作答，一定能拿出一个令人满意的答案，喜提一个优质 offer。

###### 问题的严重性

首先，要申明一下，问题的严重性。

BigKey（大 key）和 HotKey（热 key）的问题是较常见。

这类问题不止会使服务的性能下降，还会影响用户正常使用功能，甚至会造成大范围的服务故障，故障
有时还会发生连环效应，导致更加严重的后果，发生系统的雪崩， **造成巨大的经济损失，巨大的品牌损
伤** 。

所以，在 Redis 运维过程中，由于 Bigkey 的存在，DBA 也一直和业务开发方强调 Bigkey 的规避方法
以及危害。

在开发的过程中，开发同学，也需要十分重视和预防这个问题。

###### 一、什么是 BigKey、HotKey？

**什么是 BigKey：**

俗称“大 key”，是指 redis 在日常生产的过程中，某些 key 所占内存空间过大。

通俗来说，redis 是 key-value 的存储方式，当一个 key 所对应的存储数值达到一定程度，就会出现大 key
的情况。

redis 里有多种数据存储结构，如 String、List、Hash 等，每种存储结构都有能够承载的数据限值。当一
个 key 包含的内容接近限制，或者高于平均值，大 key 就产生了。

在 Redis 中，一个字符串类型最大可以到 512 MB，一个二级数据结构（比如 hash、list、set、zset
等）可以存储大约 40 亿个 (2^32-1) 个元素，

但实际上不会达到这么大的值，一般情况下如果达到下面的情况，就可以认为它是 Bigkey 了。

```
【字符串类型】： 单个 string 类型的 value 值超过 1 MB，就可以认为是 Bigkey。
【非字符串类型】：哈希、列表、集合、有序集合等，它们的元素个数超过 2000 个，就可以认
为是 Bigkey。
```
**什么是 HotKey：**


俗称“热 key”，一个 key 对应在一个 redis 分片上，当短时间内大量的请求打到该分片上，key 被频繁访
问，该 key 就是热 key。

当大量的请求，经过分发和计算，最终集中于同一个 redis 实例下的某个 key 时，该 key 由于被请求频率
过高，而占用掉了大量资源。

而其他分片，由于 key 的不合理分配导致请求量较少。

整个 redis 集群呈现出了资源使用不均衡的现象。

**举个例子：** 一线女明星官宣领证结婚，短时间内该女星微博账号被访问量激增（假设该账号内容被同步
在缓存，账号 id 作为 key），微博服务瘫痪（不具备任何实时参考性，仅作为虚拟的例子）。

在该场景下，上述 key 被大量访问，造成热 key。

总之，在某个 Key 接收到的访问次数、显著高于其它 Key 时，我们可以将其称之为 HotKey，

从访问量上来说，常见的 HotKey 如：

```
某 Redis 实例的每秒总访问量为 10000 ，而其中一个 Key 的每秒访问量达到了 7000 （访问次数显著
高于其它 Key）
对一个拥有上千个成员且总大小为 1 MB 的 HASH Key 每秒发送大量的 HGETALL（带宽占用显著高于
其它 Key）
对一个拥有数万个成员的 ZSET Key 每秒发送大量的 ZRANGE（CPU 时间占用显著高于其它 Key）
```
###### 二、服务中的 bigkey 和 hotkey 会导致什么问题

我们可以通过上述两种 key 的特性，来简单分析可能出现的几种问题。

**第 1 ：bigkey 的问题**

主要的问题是一个 key 所占空间太大，内存空间分配不均衡（小 tips：redis 是内存型 key-value 数据
库）。那就可能引发以下问题：

**1. 数据请求大量超时** ：

redis 是单线程的，当一个 key 数据响应的久一点，就会造成后续请求频繁超时。如果服务容灾措施考虑
得不够，会引发更大的问题。

**2. 侵占带宽网络拥堵** ：

当一个 key 所占空间过大，多次请求就会占用较大的带宽，直接影响服务的正常运行。

**3. 内存溢出或处理阻塞** ：


当一个较大的 key 存在时，持续新增，key 所占内存会越来越大，严重时会导致内存数据溢出；当 key 过
期需要删除时，由于数据量过大，可能发生主库较响应时间过长，主从数据同步异常（删除掉的数据，
从库还在使用）。

**第 2 ：hotkey 的问题**

**热 key** ，热 key 的问题是单点访问频率过高。那就可能引发以下问题：

**1. 分片服务瘫痪** ：

redis 集群会分很多个分片，每个分片有其要处理的数据范围。当某一个分片被频繁请求，该分片服务就
可能会瘫痪。

**2. Redis 分布式集群优势弱化** ：

如果请求不够均衡，过于单点，那么 redis 分布式集群的优势也必然被弱化。

**3. 可能造成资损** ：

在极端场景下，容易发生边界数据处理不及时，在订单等场景下，可能造成资损。

**4. 引发缓存击穿** ：

我们都知道，当缓存请求不到，就会去请求数据库。如果请求过于集中，redis 承载不了，就会有大量请
求打到数据库。 **此时，可能引发数据库服务瘫痪。进而引发系统雪崩** 。

**5. cpu 占用高，影响其他服务** ：

单个分片 cpu 占用率过高，其他分片无法拥有 cpu 资源，从而被影响。

###### 三、如何发现 bigkey 和 hotkey

**1. 业务分析结合技术方案：**

通常需要对业务场景做分析，结合技术方案去判断是否会出现大 key、热 key 的问题。

比如说：

（ 1 ）购物车场景，当一个购物车的 key 设计，没有上限，没有其他随机值约束，仅使用了 mid。这个时
候就要注意，如果有个购物狂，一次加购 5 w 件商品怎么办？

（ 2 ）活动资格列表场景，当一个活动的资格查询 list 被放入一个 key，活动期间频繁的查询和操作。这
个时候就要注意，list 的数据量有多少？查询资格的操作是否集中？如果集中，qps 是多少？

**2. 借助 redis 命令来发现：**


Redis 4.0 及以上版本提供了--Bigkeys, --hotkeys 命令，可以分析出实例中每种数据结构的 top 1 的
Bigkey，同时给出了每种数据类型的键值个数以及平均大小。

查看 bigkey：redis-cli -a 登录密码 --bigkeys

查看 hotkey：redis-cli -a 登录密码 --hotkeys

--bigkey 的使用示例

**3. 借助工具：**

(1) 可使用 redis 可视化工具进行查看（例如：another redis desktop manager）

可视化的工具可以明确给出 redis 集群当下的信息，经过简要数据分析，便可观测异常。


(2) 借助市面上的开源工具（本文暂不对此深入探讨）

redis-rdb-tools（附：https://github.com/sripathikrishnan/redis-rdb-tools）

（ 3 ）借助公司的自研工具

如果 vivo 内部的 DaaS（数据即服务）平台。

**4. RDB 文件分析法**

通过 RDB 文件，分析 big key

###### 四、如何解决 bigkey 和 hotkey 问题

解决方案

**bigkey 的解决方案**

主要的方法：对 big key 进行拆分

对 big key 存储的数据 （big value）进行拆分，变成 value 1，value 2... valueN,

如果 big value 是个大 json 通过 mset 的方式，将这个 key 的内容打散到各个实例中，减小 big key 对数
据量倾斜造成的影响。

如果 big value 是个大 list，可以拆成将 list 拆成。= list_1， list_2, list 3, listN

其他数据类型同理

**hotkey 的解决方案**

主要的方法：使用本地缓存

在 client 端使用本地缓存，从而降低了 redis 集群对 hot key 的访问量，

但是本地缓存，带来两个问题：
1 、如果对可能成为 hot key 的 key 都进行本地缓存，那么本地缓存是否会过大，从而影响应用程序本
身所需的缓存开销。

2 、如何保证本地缓存和 redis 集群数据的有效期的一致性。

以上两个问题，具体请去看尼恩的《第 26 章 100 Wqps 三级缓存组件实操》，对本地缓存、redis、db
的一致性，做了穿透式、起底式、绞杀式的介绍。

###### 五、生产实例：vivo 团队 Bigkey 问题的解决方案

此生产实例，非常宝贵，是珍贵的一线工业级实操案例，来源于 vivo 互联网数据库团队- Du Ting

尼恩仅仅是将其结构，做进一步的梳理，方便大家学习。

如果有看不懂的，可以找尼恩交流。


###### vivo 团队运维的 Redis 集群的介绍

全网 Redis 集群有 2200 个以上，实例数量达到 4.5 万以上，

在当前阶段进行一次全网 Bigkey 检查，估计需要以年为时间单位，非常耗时。我们需要新的思路去解
决 Bigkey 问题。

###### Bigkey 的来源

我们遇到的 Bigkey 一般都是由于程序设计不当或者对于数据规模预料不清楚造成的，比如以下的情
况。

```
【统计】场景
遇到一个统计类的 key，是记录某网站的访问用户的 IP，随着时间的推移，网站访问的用户越来越
多，这个 key 的元素数量也会越来越大，形成 Bigkey。
【缓存】场景
CacheAside 模式，业务程序将数据从数据库查询出来序列化放到 Redis 里，
如果业务程序从 Redis 没有访问到，就会查询数据库并将查询到的数据追加到 Redis 缓存中，
短时间内会缓存大量的数据到 Redis 的 key 中，形成 Bigkey。
【队列】场景
把 Redis 当做队列使用，处理任务，如果消费出现不及时情况，将导致队列越来越大，形成
Bigkey。
```
这三种情况，都是我们实际运维中遇到的，需要谨慎使用，合理优化。

###### 生产上的 Bigkey 危害

我们在运维中，遇到 Bigkey 的情况下，会导致一些问题，会触发监控报警，严重的还会影响 Redis 实
例可用性，进而影响业务可用性，在需要水平扩容时候，可能导致水平扩容失败。

**问题 1 ：内存空间不均匀**

内存空间不均匀会不利于集群对内存的统一管理，有数据丢失风险。

下图中的三个节点是同属于一个集群，它们的 key 的数量比较接近，但内存容量相差比较多，存在
Bigkey 的实例占用的内存多了 4 G 以上了。

可以使用 Daas 平台“工具集-操作项管理”，选择对应的 slave 实例执行分析，找出具体的 Bigkey。

**问题 2 ：超时阻塞**


Redis 是单线程工作的，通俗点讲就是同一时间只能处理一个 Redis 的访问命令，

操作 Bigkey 的命令通常比较耗时，这段时间 Redis 不能处理其他命令，其他命令只能阻塞等待，这样
会造成客户端阻塞，导致客户端访问超时，更严重的会造成 master-slave 的故障切换。

当然，造成阻塞的操作不仅仅是业务程序的访问，还有 key 的自动过期的删除、del 删除命令，对于
Bigkey，这些操作也需要谨慎使用。

**来一个生产上的超时阻塞案例**

我们遇到一个这样超时阻塞的案例，业务方反映：程序访问 Redis 集群出现超时现象，hkeys 访问
Redis 的平均响应时间在 200 毫秒左右，最大响应时间达到了 500 毫秒以上，如下图。

hkeys 是获取所有哈希表中的字段的命令，分析应该是集群中某些实例存在 hash 类型的 Bigkey，导致
hkeys 命令执行时间过长，发生了阻塞现象。

1. 使用 Daas 平台“服务监控-数据库实例监控”，选择 master 节点，选择 Redis 响应时间监控指标
“redis. instance. latency. max”，如下图所示，从监控图中我们可以看到

（ 1 ）正常情况下，该实例的响应时间在 0.1 毫秒左右。

（ 2 ）监控指标上面有很多突刺，该实例的响应时间到了 70 毫秒左右，最大到了 100 毫秒左右，这种
情况就是该实例会有 100 毫秒都在处理 Bigkey 的访问命令，不能处理其他命令。

通过查看监控指标，验证了我们分析是正确的，是这些监控指标的突刺造成了 hkeys 命令的响应时间比
较大，我们找到了具体的 master 实例，然后使用 master 实例的 slave 去分析下 Bigkey 情况。


2. 使用 Daas 平台“工具集-操作项管理”，选择 slave 实例执行分析，分析结果如下图，有一个 hash 类
型 key 有 12102218 个 fields。


```
3. 和业务沟通，进行 Bigkey 拆分
这个 Bigkey 是连续存放了 30 天的业务数据了，建议根据二次 hash 方式拆分成多个 key，
也可把 30 天的数据根据分钟级别拆分成多个 key，把每个 key 的元素数量控制在 5000 以内。
优化后，监控指标的响应时间的突刺就会消失了。
```
**问题 3 ： 网络阻塞**

Bigkey 的 value 比较大，也意味着每次获取要产生的网络流量较大，假设一个 Bigkey 为 10 MB，客户
端每秒访问量为 100 ，那么每秒产生 1000 MB 的流量，对于普通的千兆网卡 (按照字节算是 128 MB/s) 的
服务器来说简直是灭顶之灾。

而且我们现在的 Redis 服务器是采用单机多实例的方式来部署 Redis 实例的，也就是说一个 Bigkey 可
能会对同一个服务器上的其他 Redis 集群实例造成影响，影响到其他的业务。

**问题 4 ： 迁移困难**

我们在运维中经常做的变更操作是水平扩容，就是增加 Redis 集群的节点数量来达到扩容的目的，这个
水平扩容操作就会涉及到 key 的迁移，把原实例上的 key 迁移到新扩容的实例上。

当要对 key 进行迁移时，是通过 migrate 命令来完成的，migrate 实际上是通过 dump + restore + del
三个命令组合成原子命令完成，它在执行的时候会阻塞进行迁移的两个实例，直到以下任意结果发生才
会释放：迁移成功，迁移失败，等待超时。

如果 key 的迁移过程中遇到 Bigkey，会长时间阻塞进行迁移的两个实例，可能造成客户端阻塞，导致
客户端访问超时；也可能迁移时间太长，造成迁移超时导致迁移失败，水平扩容失败。

###### 来一个生产上的迁移失败案例

我们也遇到过一些因为 Bigkey 扩容迁移失败的案例，如下图所示，

这是一个 Redis 集群水平扩容的工单，需要进行 key 的迁移，当工单执行到 60%的时候，迁移失败
了。

如何解决呢？

大概的解决流程，如下：

```
1. 进入工单找到失败的实例，使用失败实例的 slave 节点，在 Daas 平台的“工具集-操作项管理”进行
Bigkey 分析。
```

```
2. 经过分析找出了 hash 类型的 Bigkey 有 8421874 个 fields，正是这个 Bigkey 导致迁移时间太
长，超过了迁移时间限制，导致工单失败了。
```
3. 和业务沟通，这些 key 是记录用户访问系统的某个功能模块的 ip 地址的，访问该功能模块的所有 ip
都会记录到给 key 里面，随着时间的积累，这个 key 变的越来越大。同样是采用拆分的方式进行优化，
可以考虑按照时间日期维度来拆分，就是一段时间段的访问 ip 记录到一个 key 中。

4. Bigkey 优化后，扩容的工单可以重试，完成集群扩容操作。

###### 生产上如何进行 Bigkey 的发现

```
首先需要重源头治理，防止 Bigkey 的产生；
其次是需要能够及时的发现，发现后及时处理。
```
分析 Bigkey 的方法不少，这里介绍两种比较常用的方法，也是 Daas 平台分析 Bigkey 使用的两种方
式，分别是 Bigkeys 命令分析法、RDB 文件分析法。

**1. Bigkeys 命令分析**

Redis 4.0 及以上版本提供了--Bigkeys 命令，可以分析出实例中每种数据结构的 top 1 的 Bigkey，同时
给出了每种数据类型的键值个数以及平均大小。

执行--Bigkeys 命令时候需要注意以下几点：

```
建议在 slave 节点执行，因为--Bigkeys 也是通过 scan 完成的，可能会对节点造成阻塞。
建议在节点本机执行，这样可以减少网络开销。
如果没有从节点，可以使用--i 参数，例如 (--i 0.1 代表 100 毫秒执行一次)。
--Bigkeys 只能计算每种数据结构的 top 1，如果有些数据结构有比较多的 Bigkey，是查找不出来
的。
```
Daas 平台集成了基于原生--Bigkeys 代码实现的查询 Bigkey 的方式，这个方式的缺点是只能计算每种
数据结构的 top 1，如果有些数据结构有比较多的 Bigkey，是查找不出来的。该方式相对比较安全，已
经开放出来给业务开发同学使用。

**2. RDB 文件分析**

借助开源的工具，比如 rdb-tools，分析 Redis 实例的 RDB 文件，找出其中的 Bigkey，这种方式需要生
成 RDB 文件，需要注意以下几点：

```
建议在 slave 节点执行，因为生成 RDB 文件会影响节点性能。
需要生成 RDB 文件，会影响节点性能，虽然在 slave 节点执行，但是也是有可能造成主从中断，
进而影响到 master 节点。
```
Daas 平台集成了基于 RDB 文件分析代码实现的查询 Bigkey 的方式，可以根据实际需求自定义填写
N，分析的 top N 个 Bigkey。该方式相对有一定风险，只有 DBA 有权限执行分析。


**3. Bigkey 巡检**

通过巡检，可以暴露出隐患，提前解决，避免故障的发生，进行全网 Bigkey 的巡检，是避免 Bigkey 故
障的比较好的方法。

由于全网 Redis 实例数量非常大，分析的速度比较慢，使用当前的分析方法很难完成。

为了解决这个问题，存储研发组分布式数据库同学计划开发一个高效的 RDB 解析工具，然后通过大规
模解析 RDB 文件来分析 Bigkey，可以提高分析速度，实现 Bigkey 的巡检。

###### 生产上 Bigkey 处理优化

**1 Bigkey 拆分**

优化 Bigkey 的原则就是 string 减少字符串长度，list、hash、set、zset 等减少元素数量。当我们知道
哪些 key 是 Bigkey 时，可以把单个 key 拆分成多个 key，比如以下拆分方式可以参考。

```
big list：list 1、list 2、... listN
big hash：可以做二次的 hash，例如 hash%100
按照日期拆分多个：key 20220310、key 20220311、key 202203212
```
**2 Bigkey 分析工具优化**

我们全网 Redis 集群有 2200 以上，实例数量达到 4.5 万以上，有的比较大的集群的实例数量达到了
1000 以上，前面提到的两种 Bigkey 分析工具还都是实例维度分析，对于实例数量比较大的集群，进行
全集群分析也是比较耗时的，为了提高分析效率，从以下几个方面进行优化：

```
可以从集群维度选择全部 slave 进行分析。
同一个集群的相同服务器 slave 实例串行分析，不同服务器的 slave 实例并行分析，最大并发度默
认 10 ，同时可以分析 10 个实例，并且可以自定义输入执行分析的并发度。
分析出符合 Bigkey 规定标准的所有 key 信息：大于 1 MB 的 string 类型的所有 key，如果不存在
就列出最大的 50 个 key；hash、list、set、zset 等类型元素个数大于 2000 的所有 key，如不存
在就给出每种类型最大的 50 个 key。
增加暂停、重新开始、结束功能，暂停分析后可以重新开始。
```
###### 水平扩容迁移优化

目前情况，我们有一些 Bigkey 的发现是被动的，一些是在水平扩容时候发现的，由于 Bigkey 的存在导
致扩容失败了，严重的还触发了 master-slave 的故障切换，这个时候可能已经造成业务程序访问超
时，导致了可用性下降。

我们分析了 Daas 平台的水平扩容时迁移 key 的过程及影响参数，内容如下：

（ 1 ）【cluster-node-timeout】：控制集群的节点切换参数，

master 堵塞超过 cluster-node-timeout/2 这个时间，就会主观判定该节点下线 pfail 状态，如果迁移
Bigkey 阻塞时间超过 cluster-node-timeout/2，就可能会导致 master-slave 发生切换。

（ 2 ）【migrate timeout】：控制迁移 io 的超时时间

超过这个时间迁移没有完成，迁移就会中断。

（ 3 ）【迁移重试周期】：迁移的重试周期是由水平扩容的节点数决定的，

比如一个集群扩容 10 个节点，迁移失败后的重试周期就是 10 次。

（ 4 ）【一个迁移重试周期内的重试次数】：在一个起迁移重试周期内，会有 3 次重试迁移，

每一次的 migrate timeout 的时间分别是 10 秒、 20 秒、 30 秒，每次重试之间无间隔。


比如一个集群扩容 10 个节点，迁移时候遇到一个 Bigkey，第一次迁移的 migrate timeout 是 10 秒，
10 秒后没有完成迁移，就会设置 migrate timeout 为 20 秒重试，如果再次失败，会设置 migrate
timeout 为 30 秒重试，

如果还是失败，程序会迁移其他新 9 个的节点，但是每次在迁移其他新的节点之前还会分别设置
migrate timeout 为 10 秒、 20 秒、 30 秒重试迁移那个迁移失败的 Bigkey。

这个重试过程，每个重试周期阻塞（10+20+30）秒，会重试 10 个周期，共阻塞 600 秒。其实后面的 9
个重试周期都是无用的，每次重试之间没有间隔，会连续阻塞了 Redis 实例。

（ 5 ）【迁移失败日志】：日志的缺失

迁移失败后，记录的日志没有包括迁移节点、solt、key 信息，不能根据日志立即定位到问题 key。

我们对这个迁移过程做了优化，具体如下：

（ 1 ）【cluster-node-timeout】：延长超时时间

默认是 60 秒，在迁移之前设置为 15 分钟，防止由于迁移 Bigkey 阻塞导致 master-slave 故障切换。

（ 2 ）【migrate timeout】：减少阻塞时间

为了最大限度减少实例阻塞时间，每次重试的超时时间都是 10 秒， 3 次重试之间间隔 30 秒，这样最多
只会连续阻塞 Redis 实例 10 秒。

（ 3 ）【重试次数】：去掉了其他节点迁移的重试

迁移失败后，只重试 3 次（重试是为了避免网络抖动等原因造成的迁移失败），每次重试间隔 30 秒，
重试 3 次后都失败了，会暂停迁移，日志记录下 Bigkey，去掉了其他节点迁移的重试。

（ 4 ）【优化日志记录】：日志记录

迁移失败日志记录迁移节点、solt、key 信息，可以立即定位到问题节点及 key。

###### 关于 BigKey、Hotkey 的总结

首先是需要从源头治理，防止 Bigkey 、Hotkey 形成，加强对业务开发同学 bigkey 相关问题的宣导；

其次，提升及时发现的能力，实现 Bigkey 、Hotkey 及时探测能力。

## 滴滴一面：BigKey 问题很致命，如何排查和

## 处理？

#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，最近有小伙伴拿到了一线互联网企业如极兔、有赞、希
音、百度、网易、滴滴的面试资格，遇到一几个很重要的面试题：


```
致命的的 Redis BigKey 如何排查，你处理过吗？
```
与之类似的、其他小伙伴遇到过的问题还有：

```
BigKey 问题严重，该如何预防和解决？
```
**尼恩提示，redis Bigkey 又是开发的核心知识，又是线上的重点难题。**

所以，这里尼恩给大家做一下系统化、体系化的线程池梳理，使得大家可以充分展示一下大家雄厚的
“技术肌肉”， **让面试官爱到 “不能自已、口水直流”** 。

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 63 版本，供后面的小伙伴参考，
提升大家的 3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，最新尼恩架构笔记、面试题的 PDF 文件，请从公众号 【技术自由
圈】获取。
```
#### 一、什么是 Big Key?

**通俗易懂的讲，Big Key 就是某个 key 对应的 value 很大，占用的 redis 空间很大，本质上是大 value 问
题。**

key 往往是程序可以自行设置的，value 往往不受程序控制，因此可能导致 value 很大。

redis 中这些 Big Key 对应的 value 值很大，在序列化/反序列化过程中花费的时间很大，因此当我们操作
Big Key 时，通常比较耗时，这就可能导致 redis 发生阻塞，从而降低 redis 性能。

BigKey 指以 Key 的大小和 Key 中成员的数量来综合判定，用几个实际的例子对大 Key 的特征进行描述：

```
Key 本身的数据量过大：一个 String 类型的 Key，它的值为 5 MB
Key 中的成员数过多：一个 ZSET 类型的 Key，它的成员数量为 10000 个
Key 中成员的数据量过大：一个 Hash 类型的 Key，它的成员数量虽然只有 1000 个但这些成员的
Value 值总大小为 100 MB
```
**在实际业务中，大 Key 的判定仍然需要根据 Redis 的实际使用场景、业务场景来进行综合判断。通常都
会以数据大小与成员数量来判定。**

#### 二、Big Key 产生的场景？

```
1 、redis 数据结构使用不恰当
```
将 Redis 用在并不适合其能力的场景，造成 Key 的 value 过大，如使用 String 类型的 Key 存放大体积二进制
文件型数据。

```
2 、未及时清理垃圾数据
```
没有对无效数据进行定期清理，造成如 HASH 类型 Key 中的成员持续不断的增加。即一直往 value 塞数
据，却没有删除机制，value 只会越来越大。

```
3 、对业务预估不准确
```
业务上线前规划设计考虑不足没有对 Key 中的成员进行合理的拆分，造成个别 Key 中的成员数量过多。

```
4 、明星、网红的粉丝列表、某条热点新闻的评论列表
```

假设我们使用 List 数据结构保存某个明星/网红的粉丝，或者保存热点新闻的评论列表，因为粉丝数量巨
大，热点新闻因为点击率、评论数会很多，这样 List 集合中存放的元素就会很多，可能导致 value 过大，
进而产生 Big Key 问题。

#### 三、Big Key 的危害？

###### 1 、阻塞请求

Big Key 对应的 value 较大，我们对其进行读写的时候，需要耗费较长的时间，这样就可能阻塞后续的请
求处理。Redis 的核心线程是单线程，单线程中请求任务的处理是串行的，前面的任务完不成，后面的
任务就处理不了。

###### 2 、内存增大

读取 Big Key 耗费的内存比正常 Key 会有所增大，如果不断变大，可能会引发 OOM（内存溢出），或达
到 redis 的最大内存 maxmemory 设置值引发写阻塞或重要 Key 被逐出。

###### 3 、阻塞网络

读取单 value 较大时会占用服务器网卡较多带宽，自身变慢的同时可能会影响该服务器上的其他 Redis 实
例或者应用。

###### 4 、影响主从同步、主从切换

删除一个大 Key 造成主库较长时间的阻塞并引发同步中断或主从切换。

#### 四、如何识别 Big Key？

###### 方法 1 、使用 redis-cli 命令加上--bigkeys 参数识别

可以使用 Redis 官方客户端 redis-cli 加上--bigkeys 参数，

可以找到某个实例 5 种数据类型 (String、hash、list、set、zset) 的最大 key。

**优点：**

可以在线扫描，不阻塞服务；

**缺点**

是信息较少，内容不够精确。

###### 方法 2 、scan 扫描+ 长度命令

redis 老的版本，在没有 scan 之前，使用 key 进行扫描

新的 redis 版本，有了性能更好的 scan 命令

利用 scan 扫描 Redis 中的所有 key，利用 strlen、hlen 等命令判断 kev 的长度

推荐 scan 扫描，并且，尼恩强烈建议大家，一定实操一下


###### 方法 3 、使用 debug object key 命令

根据传入的对象（Key 的名称）来对 Key 进行分析并返回大量数据，其中 serializedlength 的值为该 Key
的序列化长度，需要注意的是，Key 的序列化长度并不等同于它在内存空间中的真实长度，

此外，debug object 属于调试命令，运行代价较大，此命令是阻塞式的，在其运行时，进入 Redis 的其
余请求将会被阻塞直到其执行完毕。

并且每次只能查找单个 key 的信息，官方不推荐使用。

###### 方法 4 、redis-rdb-tools 开源工具

这种方式是在 redis 实例上执行 bgsave，bgsave 会触发 redis 的快照备份，生成 rdb 持久化文件，然后对
dump 出来的 rdb 文件进行分析，找到其中的大 key。

GitHub 地址：https://github.com/sripathikrishnan/redis-rdb-tools

**优点**

获取的 key 信息详细、可选参数多、支持定制化需求

结果信息可选择 json 或 csv 格式，后续处理方便，

**缺点**

是需要离线操作，获取结果时间较长。

#### 五：实操一下，使用 keys 命令进行扫描

redis 老的版本，在没有 scan 之前，使用 key 进行扫描

新的 redis 版本，有了性能更好的 scan 命令

利用 scan 扫描 Redis 中的所有 key，利用 strlen、hlen 等命令判断 kev 的长度

虽然推荐 scan 扫描，并且，尼恩强烈建议大家，一定实操一下

但是知己知彼，一定要把过时的技术，体验一下

###### 客户端连接 redis

###### Keys 命令的使用实操

KEYS 命令使用很简单, redis KEYS 命令基本语法如下：

eg ，查找以 store: 为开头的 key：

```
docker exec -it redis-standalone redis-cli
auth 123456
```
```
1
2
```
```
1 KEYS PATTERN
```

###### key 命令的性能问题

keys * 这个命令千万别在生产环境乱用。

特别是数据庞大的情况下。

因为 Keys 会引发 Redis 锁，并且增加 Redis 的 CPU 占用。很多公司的运维都是禁止了这个命令的

当需要扫描 key，匹配出自己需要的 key 时，可以使用 scan 命令

###### Redis 字符串命令


```
命令说明
```
```
SET key value 用于设定指定键的值。
```
```
GET key 用于检索指定键的值。
```
```
GETRANGE key start end 返回 key 中字符串值的子字符。
```
```
GETSET key value 将给定 key 的值设置为 value，并返回 key 的旧值。
```
```
GETBIT key offset 对 key 所存储的字符串值，获取其指定偏移量上的位（bit）。
```
```
MGET key 1 [key 2..] 批量获取一个或多个 key 所存储的值，减少网络耗时开销。
```
```
SETBIT key offset value 对 key 所储存的字符串值，设置或清除指定偏移量上的位 (bit)。
```
```
SETEX key seconds value 将值 value 存储到 key 中^ ，并将 key 的过期时间设为 seconds (以
秒为单位)。
```
```
SETNX key value 当 key 不存在时设置 key 的值。
```
```
SETRANGE key offset
value
```
```
从偏移量 offset 开始，使用指定的 value 覆盖的 key 所存储的部
分字符串值。
```
```
STRLEN key 返回 key 所储存的字符串值的长度。
```
```
MSET key value [key value
...]
```
```
该命令允许同时设置多个键值对。
```
```
MSETNX key value [key
value ...]
```
```
当指定的 key 都不存在时，用于设置多个键值对。
```
```
PSETEX key milliseconds
value 此命令用于设置 key 的值和有过期时间（以毫秒为单位）。
```
```
INCR key 将 key 所存储的整数值加 1 。
```
```
INCRBY key increment 将 key 所储存的值加上给定的递增值（increment）。
```
```
INCRBYFLOAT key
increment
```
```
将 key 所储存的值加上指定的浮点递增值（increment）。
```
```
DECR key 将 key 所存储的整数值减 1 。
```
```
DECRBY key decrement 将 key 所储存的值减去给定的递减值（decrement）。
```
```
APPEND key value 该命令将 value 追加到 key 所存储值的末尾。
```
Redis string 的命令只能一次设置/查询一个键值对，这样虽然简单，但是效率不高。为了提高命令的执
行效率，Redis 提供了可以批量操作多个字符串的读写命令 MSET/MGET（“M”代表“Many”），它们允
许你一次性设置或查询多个键值对，这样就有效地减少了网络耗时。

###### 嘚瑟一下底层知识：Redis 字符串的内部大小

Redis 使用标准 C 语言编写，但在存储字符时，Redis 并未使用 C 语言的字符类型，

为了存储字符串，Redis 自定义了一个属于特殊结构 SDS（Simple Dynamic String）即简单动态字符
串），


SDS 是一个可以修改的内部结构，非常类似于 Java 的 ArrayList。

**1. SDS 动态字符串**

SDS 的结构定义如下：

从上述结构体可以看出，Redis string 将字符串存储到字符类型的 buf[] 、len、free

**2. 分配冗余空间**

string 采用了预先分配冗余空间的方式来减少内存的频繁分配，如下图所示：

如图所示，Redis 每次给 string 分配的空间都要大于字符串实际占用的空间，这样就在一定程度上提
升了 Redis string 存储的效率，比如当字符串长度变大时，无需再重新申请内存空间。

当字符串所占空间小于 1 MB 时，Redis 对字符串存储空间的扩容是以成倍的方式增加的；而当所占空
间超过 1 MB 时，每次扩容只增加 1 MB。Redis 字符串允许的最大值字节数是 512 MB。

#### 六：实操一下，使用 SCAN 命令进行扫描

###### scan 命令和 keys 命令的对比

在巨大的数据量的状况下，作查找符合某种规则的 Key 的信息，这里就有两种方式:java

```
1. keys 命令：
简单粗暴，可是因为 Redis 是单线程，keys 命令是以阻塞的方式执行的，keys 是以遍历的方式实现
的复杂度是 O (n），Redis 库中的 key 越多，查找实现代价越大，产生的阻塞时间越长。
2. scan 命令:
```
```
struct sdshdr{
//记录 buf 数组中已使用字符的数量，等于 SDS 保存字符串的长度
int len;
//记录 buf 数组中未使用的字符数量
int free;
//字符数组，用于保存字符串
char buf[];
```
```
1 2 3 4 5 6 7
```

```
以非阻塞的方式实现 key 值的查找，绝大多数状况下是能够替代 keys 命令的，可选性更强
```
基于 SCAN 的这种安全性，建议大家在生产环境都使用 SCAN 命令来代替 KEYS，不过注意，该命令是在
2.8.0 版本之后加入的，如果你的 Redis 低于这个版本，则需要升级 Redis。

**1. scan 相关命令**

都是用于增量迭代集合元素。正则表达式

```
1. SCAN 命令用于迭代当前数据库中的数据库键。
2. SSCAN 命令用于迭代集合键中的元素。
3. HSCAN 命令用于迭代哈希键中的键值对。
4. ZSCAN 命令用于迭代有序集合中的元素（包括元素成员和元素分值）。
```
以后的例子会以 sscan 为例 redis

**2. 命令参数**

SCAN 每次执行都只会返回少量元素，所以可以用于生产环境，而不会出现像 KEYS 或者 SMEMBERS
命令带来的可能会阻塞服务器的问题。

SCAN 命令是一个基于游标的迭代器。 redis Scan 命令基本语法如下：

```
cursor - 游标。
pattern - 匹配的模式。
count - 可选，用于指定每次迭代返回的 key 的数量，默认值为 10 。
```
pattern 参数进行样式的模糊匹配，是一个 glob 风格的模式参数，让命令只返回和给定模式相匹配的元
素。比如

每次被调用 scan, 都需要使用上一次这个调用返回的游标作为该次调用的游标参数，以此来延续之前的
迭代过程;

**当 SCAN 命令的游标参数（即 cursor）被设置为 0 时，redis 将开始一次新的迭代，而当服务器向用户
返回值为 0 的游标时，表示迭代已结束。**

###### redis-cli 的使用 SCAN 演示：

现在有 7 个 key，使用 scan 扫描，每次 2 个

```
1 SCAN cursor [MATCH pattern] [COUNT count]
```
```
1 SCAN 0 match store:* count 2
```

扫描过程如下，注意游标的编号，不是有序的

在上面这个例子中，第一次迭代使用 0 作为游标，表示开始一次新的迭代。

第二次迭代使用的是第一次迭代时返回的游标 8 ，作为新的迭代参数。

显而易见，SCAN 命令的返回值，是一个包含两个元素的数组：

```
第一个数组元素是用于进行下一次迭代的新游标，
而第二个数组元素则又是一个数组，这个数组中包含了所有被迭代的元素。
```
**一次 scan full iteration (完全迭代) 的过程如下：**

以 0 作为游标开始一次新的迭代，一直调用 SCAN 命令，直到命令返回游标 0 ，我们称这个过程为一
次完整遍历。

**注意两点：**

```
返回的游标不一定是递增的，可能后一次返回的游标比前一次的小。
SCAN 增量式迭代命令并不保证每次执行都返回某个给定数量的元素, 甚至可能会返回零个元素，
但只要命令返回的游标不是 0 ，应用程序就不应该将迭代视作结束。
```
在最后一次调用 SCAN 命令时，命令返回了游标 0 ，这表示迭代已经结束，整个数据集已经被完整遍
历过了。


#### 七、SpringBoot BigKey 的 scan 扫描实操

SpringBoot 应用中，可是经过用 scan，咱们就能够指定有共性的 key，并指定一次性查询条件。

演示的代码如下：

这里例子中，是以大于 50 个字节，就计算为 bigkey.

这个阈值，仅仅是为了演示方便，生产场景，可以设置一个大的阈值，比如，一个 String 类型的 Key，
它的阈值为 5 MB

###### 执行的结果

启动应用，可以得到执行的结果


实验完美成功

###### 生产场景的 bigkey 扫描

结合 scan + 定时任务的方式，在吞吐量的低峰期，进行扫描

发现了 bigkey，可以及时的进行运维告警，发送邮件通知或者钉钉企业信息

###### 类似场景，对大量 key 进行扫描的集群

在线上有时候，须要对大量 key 进行扫描（如删除）操做，有几个风险点：

```
1. 一次性查询所指定的 key,
如果是使用 keys，数量较大可能形成 redis 服务卡顿，Redis 是单线程程序，顺序执行全部指令，其
它指令必须等到当前的 keys 指令执行完了才能够继续。
2. 从海量的 key 中找出知足特定前缀的 key
```
上面的场景中，都可以用 scan，咱们就能够指定有共性的 key，并指定一次性查询条件。

**要点是：使用 SCAN 命令扫描 key 替代 KEYS 避免 redis 服务器阻塞，无坑！**

#### 八、如何解决 Big Key 问题？

要解决 Big Key 问题，无非就是减小 key 对应的 value 值的大小，也就是对于 String 数据结构的话，减少存
储的字符串的长度；对于 List、Hash、Set、ZSet 数据结构则是减少集合中元素的个数。

###### 1 、对大 Key 进行拆分


将一个 Big Key 拆分为多个 key-value 这样的小 Key，并确保每个 key 的成员数量或者大小在合理范围内，
然后再进行存储，通过 get 不同的 key 或者使用 mget 批量获取。

###### 2 、对大 Key 进行清理

对 Redis 中的大 Key 进行清理，从 Redis 中删除此类数据。

Redis 自 4.0 起提供了 UNLINK 命令，该命令能够以非阻塞的方式缓慢逐步的清理传入的 Key，

通过 UNLINK，你可以安全的删除大 Key 甚至特大 Key。

###### 3 、监控 Redis 的内存、网络带宽、超时等指标

通过监控系统并设置合理的 Redis 内存报警阈值来提醒我们此时可能有大 Key 正在产生，如：Redis 内存
使用率超过 70%，Redis 内存 1 小时内增长率超过 20%等。

###### 4 、定期清理失效数据

如果某个 Key 有业务不断以增量方式写入大量的数据，并且忽略了其时效性，这样会导致大量的失效数
据堆积。

可以通过定时任务的方式，对失效数据进行清理。

###### 5 、压缩 value

使用序列化、压缩算法将 key 的大小控制在合理范围内，但是需要注意序列化、反序列化都会带来一定
的消耗。

如果压缩后，value 还是很大，那么可以进一步对 key 进行拆分。

## 1000 W 用户 1 Wqps 高并发签到系统的架构和

## 实操

#### 说在前面

在尼恩的（50+）读者社群中，经常有小伙伴面试的时候，遇到一个一个高并发架构方面的问题，比
如：

```
(1) 高并发秒杀系统如何架构？
```
```
(2) 高并发签到系统如何架构？
```
```
(3) 等等等等......
```
**刚刚，在尼恩的社群（50+）中，有小伙伴又问了这个问题。** 尼恩作为技术中台的架构师，高并发架
构是尼恩架构的重点，所以，一直想带大家从架构到实操，这里，带大家完成一个 1000 W 用户
1 Wqps+ 签到系统的架构和实操。

本文也一并收入咱们的《尼恩 Java 面试宝典》V 64 版本 PDF，供后面的小伙伴参考，提升大家的 3 高架
构、设计、开发水平。


当然，作为一篇文章，仅仅是抛砖引玉，后面有机会，带大家做一下这个高质量的实操，并且指导大家
写入简历。

#### 签到场景业务需求分析

一般像微博，各种社交软件，游戏等 APP，都会有一个签到功能，连续签到多少天，送什么东西，比
如：

```
签到 1 天送 10 积分，连续签到 2 天送 20 积分， 3 天送 30 积分， 4 天以上均送 50 积分等
如果连续签到中断，则重置计数，每月初重置计数
显示用户某个月的签到次数
```
#### 1000 W 级用户场景的签到优化

###### 优化 1 ：利用 Bitmap 实现用户签到存储优化

为了实现用户的签到功能，通过 mysql 来完成，

为了实现签到的存储，可以设计一个类似下面的表

假如有 1000 万用户，平均每人每年签到次数为 10 次，一年下来，则这张表数据量为多少呢？

数据比较吓人： 1 亿条

每签到一次需要使用（8 + 8 + 1 + 1 + 3 + 1）共 22 字节的内存，一个月则最多需要 600 多字节

我们如何能够简化一点呢？

其实可以考虑小时候一个挺常见的方案，就是小时候，咱们准备一张小小的卡片，你只要签到就打上一
个勾，我最后判断你是否签到，其实只需要到小卡片上看一看就知道了。

我们可以采用类似这样的方案来实现我们的签到需求。

我们按月来统计用户签到信息，签到记录为 1 ，未签到则记录为 0 。

把每一个 bit 位对应当月的每一天，形成了映射关系。用 0 和 1 标示业务状态，这种思路就称为位图
（BitMap）。


这样我们就用极小的空间，来实现了大量数据的表示。

那么，一个月的签到数据，可以使用一个无符号整数来存储

之前一个月要 600 个字节，现在保存一个人一个月的签到数据，只要 24 个字节，一下就提升了 25 倍

**注意：是存储空间，节约了 25 倍哈**

###### 优化 2 ：利用 Redis Bitmap 实现用户签到的性能优化

刚好 redis 有 Bitmap 结构。

可以利用 Redis Bitmap 实现用户签到的性能优化，将当前用户当天签到信息保存到 Redis 中。

具体的架构如下：


redis 的吞吐量为 2 Wqps 以上，完全可以满足 1000 W 用户签到的需求。

但是 SpringCloud 微服务够呛，怎么办呢？

###### 优化 3 ：利用 Nginx +lus 实现更进一步的用户签到的性能优化

SpringCloud 微服务够呛，但是 nginx 可以，

nignx 的吞吐量为 2 Wqps 以上，完全可以满足 1000 W 用户签到的需求。

具体的架构如下：


架构介绍完了，接下来就开始实操。

但是，在开始实操之前，咱们得补一下基础知识。

#### 基础知识：什么是 Bitmap

Bitmap 是一种位图数据结构，它用来表示一个集合中每个元素是否出现。

在 Bitmap 中，每个元素都与一个位（bit）相对应，如果元素出现，则对应位的值为 1 ，否则为 0 。

Bitmap 可以用来进行快速的集合运算，如并集、交集、差集等操作。

Bitmap 的优点在于它的空间利用率非常高，通常只需要占用一个二进制位来表示一个元素是否出现，
因此对于稀疏的数据集合，Bitmap 可以显著减少存储空间的使用。

此外，由于 Bitmap 的位运算操作非常高效，因此它也能够快速地进行集合运算操作。

Redis 中是利用 string 类型数据结构实现 BitMap，因此最大上限是 512 M，转换为 bit 则是 2^32 个 bit 位。

###### Bitmap 的使用场景

Bitmap 可以应用于许多场景，主要包括以下几个方面：

```
去重：
可以使用 Bitmap 去重，将出现的元素映射到 Bitmap 中，若 Bitmap 中对应的位置已经被标记为 1 ，
即表示该元素已经出现过，可以避免重复。
```

```
排序：
可以使用 Bitmap 实现排序，将元素映射到 Bitmap 中，遍历 Bitmap 中的所有位，对于值为 1 的位，
输出对应元素。
数据库查询：
在数据库中，可以使用 Bitmap 对记录进行索引，
例如，在一个表中记录用户的性别，可以使用 Bitmap 将每个用户的性别映射到 Bitmap 中，然后通
过位运算来查询特定性别的用户。
网络流量分析：
在网络流量分析中，可以使用 Bitmap 来记录每个 IP 地址的访问情况，然后通过位运算进行流量统
计和分析。
压缩编码：
可以使用 Bitmap 进行数据压缩编码，将数据压缩为一系列 0 和 1 的位序列，通过位运算进行解码。
```
总的来说，Bitmap 具有高效、灵活、易用等优点，在许多数据处理和分析的场景中都有广泛的应用。

#### Redis 中 Bitmap 的相关命令

###### 客户端连接 redis

Redis 提供了一系列 Bitmap 相关的指令，包括以下几个：

###### 指定 key 中的 offset 位设置为 value

将指定 key 中的 offset 位设置为 value（ 0 或 1 ），若 key 不存在，则会自动创建一个新的空 Bitmap。

例：SETBIT mybitmap 1001 1 将 mybitmap 的第 1001 位设置为 1 。

###### 获取指定 key 中的 offset 位的值

获取指定 key 中的 offset 位的值（ 0 或 1 ），若 key 不存在或 offset 超出范围，则返回 0 。

```
docker exec -it redis-standalone redis-cli
```
```
auth 123456
```
```
1
2
3
```
```
1 SETBIT key offset value
```
```
127 .0.0.1:6379> setbit mybitmap 1001 1
(integer) 0
```
```
1
2
```

例如：GETBIT mybitmap 1001 将返回 mybitmap 的第 1001 位的值。

###### 统计指定 key 中值为 1 的位的数量。

可以通过可选参数 start 和 end 指定统计的范围（单位是位），若不指定，则默认统计整个 Bitmap。

例如：BITCOUNT mybitmap 100 1000 将统计 mybitmap 中第 100 位到第 1000 位值为 1 的位的数量。

###### 对多个 Bitmap 进行位运算，并将结果保存到 destkey 中。

operation 可以是 AND、OR、XOR 和 NOT 中的一个，表示进行与、或、异或和非运算。

例如：BITOP AND mybitmap 1 mybitmap 2 mybitmap 3 将 mybitmap 2 和 mybitmap 3 进行与运算，并
将结果保存到 mybitmap 1 中。

###### 查找指定 key 中第一个值为 bit（ 0 或 1 ）的位的位置

查找指定 key 中第一个值为 bit（ 0 或 1 ）的位的位置，并返回其索引（单位是位）。

可以通过可选参数 start 和 end 指定查找的范围。若 bit 不存在于指定范围内，则返回-1。

例如：BITPOS mybitmap 1 100 1000 将在 mybitmap 的第 100 位到第 1000 位中查找值为 1 的位的位置。

```
1 GETBIT key offset
```
```
127 .0.0.1:6379> getbit mybitmap 1001
(integer) 1
```
```
1
2
```
```
1 BITCOUNT key [start end]
```
```
127 .0.0.1:6379> bitcount mybitmap 100 1000
(integer) 1
```
```
1
2
```
```
1 BITOP operation destkey key [key ...]
```
```
127 .0.0.1:6379> bitop and mybitmap 1 mybitmap 2 mybitmap 3
(integer) 0
```
```
1
2
3
```
```
1 BITPOS key bit [start] [end]
2
```
```
127 .0.0.1:6379> bitpos mybitmap 1 100 1000
(integer) 1001
```
```
1
2
3
```

###### BITFIELD：在位图中存储整数值

BITFIELD 命令允许用户在位图中的任意区域（field）存储指定长度的整数值，并对这些整数值执行加法
或减法操作。

BITFIELD 命令支持 SET、GET、INCRBY、OVERFLOW 这 4 个子命令，接下来将分别介绍这些子命令。

```
语法：
```
官方文档

###### 根据偏移量对区域进行设置

除了根据偏移量对位图进行设置之外，SET 子命令还允许用户根据给定类型的位长度，对位图在指定索
引上存储的整数值进行设置。

通过使用 BITFIELD 命令的 SET 子命令，用户可以在位图的指定偏移量 offset 上设置一个 type 类型的整数
值 value，

来一个列子，从第 0 位开始，设置 sign:1880000000:: 202305 的值为 198 ：

```
BITFIELD key [GET encoding offset | [OVERFLOW <WRAP | SAT | FAIL>]
<SET encoding offset value | INCRBY encoding offset increment>
[GET encoding offset | [OVERFLOW <WRAP | SAT | FAIL>]
<SET encoding offset value | INCRBY encoding offset increment>
...]]
```
```
1 2 3 4 5 6
```

主要的参数如下：

```
offset 操作的偏移量
type 操作的值的数值类型
value 要操作的值
```
对于参数的介绍如下：

**参数 1 ：offset 参数用于指定设置的起始偏移量。**

这个偏移量从 0 开始计算，偏移量为 0 表示设置从位图的第 1 个二进制位开始。

如果被设置的值长度不止一位，那么设置将自动延伸至之后的二进制位。

**参数 2 ：type 参数用于指定等待设置的值类型，**

**type** 参数的值需要以 i 或者 u 为前缀，后跟被设置值的位长度，

其中 i 表示被设置的值为有符号整数，而 u 则表示被设置的值为无符号整数。

比如 i 8 表示被设置的值为有符号 8 位整数，

而 u 16 则表示被设置的值为无符号 16 位整数，诸如此类。

BITFIELD 的各个子命令目前最大能够对 64 位长的有符号整数（i 64）和 63 位长的无符号整数（u 63）进
行操作。

**参数 3 ：value 参数用于指定被设置的整数值**

这个值的类型应该和 type 参数指定的类型一致。

如果给定值的长度超过了 type 参数指定的类型，那么 SET 命令将根据 type 参数指定的类型截断给定值。

比如，如果用户尝试将整数 123 （二进制表示为 01111011 ）存储到一个 u 4 类型的区域中，那么命令会
先将该值截断为 4 位长的二进制数字 1011 （即十进制数字 11 ），然后再进行设置。

**设置的结果**

```
1 BITFIELD sign:1880000000:: 202306 set u 8 0 198
2
```

设置 sign:1880000000:: 202305 的值为 198 ：

通过命令，我们可以从偏移量 0 开始，设置一个 8 位长的无符号整数值 198 （二进制表示为
11000110 ）：

从子命令返回的结果可以看出，该区域被设置之前存储的整数值为 0 。下图展示了执行设置命令之后的
位图：

###### 批量操作：一次调用中执行多个子命令

**尼恩提示：高并发场景，为了减少 io 次数，一般都是建议批量操作。**

BITFIELD 命令允许用户在一次调用中执行多个子命令，比如，通过在一次 BITFIELD 调用中使用多个 SET
子命令，我们可以同时对位图的多个区域进行设置：

```
1 BITFIELD sign:1880000000:: 202306 set u 8 0 198
2
```
```
1 BITFIELD sign:1880000000:: 202306 SET u 8 0 123 SET i 32 20 10086
2
```

```
第 1 个子命令 SET u 8 0 123 从偏移量 0 开始，设置一个 8 位长无符号整数值 123 。
第 2 个子命令 SET i 32 20 10086 从偏移量 20 开始，设置一个 32 位长有符号整数值 10086 。
```
对于这 2 个子命令，BITFIELD 命令返回了一个包含 2 个元素的数组作为命令的执行结果，

这 2 个元素分别代表 2 个指定区域被设置之前存储的整数值，比如第一个子命令返回的结果就是我们之前
为该区域设置的值 123 。

下图展示了这个 BITFIELD 命令创建出的位图以及被设置的 3 个整数值在位图中所处的位偏移量。

上图也展示了 SET 子命令的两个特点：

```
设置可以在位图的任意偏移量上进行，被设置区域之间不必是连续的，也不需要进行对齐
（align）。
各个区域之间可以有空洞，即未被设置的二进制位，这些二进制位会自动被初始化为 0 。
在同一个位图中可以存储多个不同类型和不同长度的整数。
```
**虽然这两个特点可以带来很大的灵活性，但是从节约内存、避免发生错误等情况考虑，我们一般还是应
该：**

```
以对齐的方式使用位图，并且让位图尽可能地紧凑，避免包含过多空洞。
每个位图只存储同一种类型的整数，并使用 int-8 bit、unsigned-16 bit 这样的键名前缀来标识位图
中存储的整数类型。
```
###### 获取区域存储的值

通过使用 BITFIELD 命令的 GET 子命令，用户可以从给定的偏移量或者索引中取出指定类型的整数值：


GET 子命令各个参数的意义与 SET 子命令中同名参数的意义完全一样。

###### 执行加法操作或减法操作

除了设置和获取整数值之外，BITFIELD 命令还可以对位图存储的整数值执行加法操作或者减法操作，

这两个操作都可以通过 INCRBY 子命令实现。

**语法** ：

BITFIELD 命令并没有提供与 INCRBY 子命令相对应的 DECRBY 子命令，但是用户可以通过向 INCRBY 子命
令传入负数增量来达到执行减法操作的效果。

INCRBY 子命令在执行完相应的操作之后会返回整数的当前值作为结果。例子如下：


###### 处理溢出

BITFIELD 命令除了可以使用 INCRBY 子命令来执行加法操作和减法操作之外，还可以使用 OVERFLOW 子
命令去控制 INCRBY 子命令在发生计算溢出时的行为。

**语法** ：

OVERFLOW 子命令的参数可以是 WRAP、SAT 或者 FAIL 中的一个：

```
WRAP 表示使用回绕（wrap around）方式处理溢出，这也是 C 语言默认的溢出处理方式。在这一
模式下，向上溢出的整数值将从类型的最小值开始重新计算，而向下溢出的整数值则会从类型的最
大值开始重新计算。
SAT 表示使用饱和运算（saturation arithmetic）方式处理溢出，在这一模式下，向上溢出的整数
值将被设置为类型的最大值，而向下溢出的整数值则会被设置为类型的最小值。
FAIL 表示让 INCRBY 子命令在检测到计算会引发溢出时拒绝执行计算，并返回空值表示计算失败。
```
OVERFLOW 子命令在执行时将不产生任何回复。此外，如果用户在执行 BITFIELD 命令时没有指定具体
的溢出处理方式，那么 INCRBY 子命令默认使用 WRAP 方式处理计算溢出。

需要注意的是，因为 OVERFLOW 子命令只会对同一个 BITFIELD 调用中排在它之后的那些 INCRBY 子命令
产生效果，所以用户必须把 OVERFLOW 子命令放到它想要影响的 INCRBY 子命令之前。

###### 其他命令

除此之外，还有其他一些 Bitmap 相关的指令，如 BITMAP 等，可以根据实际需求进行选择。

redis bitmap 常用命令：

```
#向指定位置 （offset）存入 0 或 1
SETBIT key offset value
```
```
#获取指定位置 （offset）的 bit 值
GETBIT key offset
```
```
#统计bitmap中 (从 start 到 end，如果不写起始位置，就统计整个 key) 值为 1 的 bit 数量
BITCOUNT key [start end]
```
```
#操作 （查询，修改，自增）Bitmap 中指定的位置（offset）的值
BITFIELD key [GET type offset] [SET type offset value] [INCRBY type offset
increment] [OVERFLOW WRAP|SAT|FAIL]
```
```
1 2 3 4 5 6 7 8 9
```
```
10
11
```

在线练习工具：https://try.redis.io/
查看更多命令：https://redis.io/commands

###### 尼恩建议，优先使用位图存储整数

尼恩建议，在 redis 中，优先使用位图存储整数，而不是使用 String 存储整数

为啥呢？

在一般情况下，当用户使用字符串或者散列去存储整数的时候，Redis 都会为被存储的整数分配一个
long 类型的值（通常为 32 位长或者 64 位长），并使用对象去包裹这个值，然后再把对象关联到数据库或
者散列中。

与此相反，BITFIELD 命令允许用户自行指定被存储整数的类型，并且不会使用对象去包裹这些整数，因
此当我们想要存储长度比 long 类型短的整数，并且希望尽可能地减少对象包裹带来的内存消耗时，就可
以考虑使用位图来存储整数。

###### 使用 strlen 获取 Bitmap 的长度

把一个 key 设置到第 31 位，那么这个 key 的长度为 4 个字节。

Redis 中是利用 string 类型数据结构实现 BitMap，因此最大上限是 512 M，转换为 bit 则是 2^32 个 bit 位。

#### 使用 SpringCloud+Redis BitMap 用户场景的签到实操

###### 实操包括以下的操作：

```
用户签到实操
用户签到查询
查询获取本月签到信息签到
```
```
#获取Bitmap中的bit数组 ，并以十进制返回
BITFIELD_RO
```
```
12
13
14
15
```

###### 用户签到实操

代码如下：

测试如下：


###### 用户签到查询

代码如下：

测试如下：


###### 查询获取本月签到信息签到

代码如下：


测试如下：

#### 本文的版本计划和基础学习资料

尼恩作为技术中台、数据中台的架构师，高并发是尼恩架构的重点，所以，后面会大家从架构到实
操，多个维度、多种场景的高并发实操。

而且尼恩指导简历的过程中，也指导过小伙伴写过 10 Wqps 超高并发网关、超高并发秒杀、超高并发
物联网等等简历，里边涉及到大量的设计模式，

经过尼恩的指导之后，很多小伙伴的简历，里边立马金光闪闪，并且顺利走上了架构师之路。

后面有机会，带大家做一下这个高质量的实操，并且指导大家写入简历。

所以，这个材料后面也会进行持续迭代，大家可以找尼恩来获取最新版本和技术交流。


**尼恩编著的 400 页 PDF 电子书《SpringCloud Alibaba 技术圣经》**

**尼恩编著的 500 页 PDF 电子书《Java 高并发核心编程卷 3 加强版》，清华大学出版社出版**

pdf 领取方式，请参见公众号： 技术自由圈

## 有赞一面：亿级用户日活统计，有几种方案？

#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，最近有小伙伴拿到了一线互联网企业如极兔、有赞、希
音、百度、网易、滴滴的面试资格，遇到一几个很重要的面试题：

```
(1) 亿级用户场景，如何高性能统计日活？
```
```
(2 ) 如何实现亿级数据统计？
(3 ）亿级用户日活统计，有几种方案？
```
```
等等等等......
```
高并发 Redis 的使用，是面试的重点和高频点。

尼恩作为技术中台、数据中台的架构师，致力于为大家研究出一个 3 高架构知识宇宙，所以，这里，带
大家完成一个亿级用户场景，如何高性能统计日活的架构分析和实操。

当然，作为一篇文章，仅仅是抛砖引玉，后面有机会，带大家做一下这个高质量的实操，并且指导大家
写入简历。

**让面试官爱到 “不能自已、口水直流”** 。

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 65 版本，供后面的小伙伴参考，
提升大家的 3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，最新尼恩架构笔记、面试题的 PDF 文件，请从公众号 【技术自由
圈】获取。
```
#### 业务场景分析

什么是日活？

日活跃用户数量 (Daily Active User，DAU) 是用于反映网站、互联网应用或网络游戏的运营情况的统计
指标。


日活跃用户数量通常统计一日（统计日）之内，登录或使用了某个产品的用户数（去除重复登录的用
户）。

受统计方式限制，互联网行业使用的日均活跃用户数指在统计周期 (周/月) 内，该 App 的每日活跃用户数
的平均值。

#### 亿级用户日活统计的存储架构

一个用户一天内多次访问一个网站只能算作一次，

怎么做存储架构呢？

大概有四种方案，可供技术选型：

```
方式 1 ： 通过 Redis 的 Set 集合来实现。
方式 2 ：利用 Hash 类型实现
方式 3 ： 利用 bitmap 实现
方式 4 ： 利用 HyperLogLog 实现
```
###### 方式 1 ： 通过 Redis 的 Set 集合来实现。

将用户 id 放到 Set 中，Set 的去重功能能保证不会重复记录同一个用户 ID。

一个 ZSET 类型的 Key，如果它的成员数量为 10000 个，一般来说，这个 ZSET 就是 bigkey


###### 方式 2 ：利用 Hash 类型实现：

将用户 ID 作为 Hash 集合的 key，访问页面则执行 HSET 命令将 value 设置成 1 。

即使用户重复访问，重复执行命令，也只会把这个 userId 的值设置成 “1"。

利用 HLEN 命令，统计 Hash 集合中的元素个数就是 UV。

一个 Hash 类型的 Key，它的成员数量虽然只有 1000 个但这些成员的 Value 值总大小为 100 MB，一般来
说，这个 Hash 就是 bigkey

###### 方式 3 ： 利用 bitmap 实现

使用 bitmap，记录用户 id 的访问，则把指定 key 的用户 id 对应的 bit 位标记为 1 ，

统计日活，就是就是指定 key 中 1 的个数。

显然这里是操作位，相比 2 中，一个字节为 8 位，估算一下占用空间：96 M/8=12 M，

1 千万用户只要 1 M 多的空间，但是 1 亿的用户需要 12 M 的大小即可记录。


一个 String 类型的 Key，它的值为 5 MB，就是 bigkey

bitmap 底层结构，和 String 类型是类似的。

###### 方式 4 ： 利用 HyperLogLog 实现

在输入用户数量非常大时, 计算基数所需要的空间总是固定的, 并且是很小的,

每个 hyperloglog 键需要 12 kb 内存可以计算 2^64 个不同元素的基数,

这和元素基数元素越多，耗费内存越多的集合形成鲜明对比,

但是 hyperloglog 只会根据元素来计算基数，不会存储元素本身, 所以不能像其它类型一样返回各个元素

hyperloglog 是概率算法，是牺牲准确率换区空间的,

对于对精度要求不高的情况下可以使用，因为概率算法本身不直接存储数据本身，能保证误差在一定范
围内，又不占用空间, 误差在 0.81%左右


#### 存储方案的问题分析

###### bigkey 问题：

方案 1 、方案 2 、方案 3

###### 准确性问题

方案四

###### 方案选择：

如果允许存在准确性问题，就使用 hyperloglog 存储架构

如果允许存在 bigkey 问题，或者解决 bigkey 问题，就使用方案 3 存储架构

这里优先使用 hyperloglog 存储架构

#### 回顾：什么是 Big Key?

**通俗易懂的讲，Big Key 就是某个 key 对应的 value 很大，占用的 redis 空间很大，本质上是大 value 问
题。**

key 往往是程序可以自行设置的，value 往往不受程序控制，因此可能导致 value 很大。

redis 中这些 Big Key 对应的 value 值很大，在序列化/反序列化过程中花费的时间很大，因此当我们操作
Big Key 时，通常比较耗时，这就可能导致 redis 发生阻塞，从而降低 redis 性能。

BigKey 指以 Key 的大小和 Key 中成员的数量来综合判定，用几个实际的例子对大 Key 的特征进行描述：

```
Key 本身的数据量过大：一个 String 类型的 Key，它的值为 5 MB
Key 中的成员数过多：一个 ZSET 类型的 Key，它的成员数量为 10000 个
Key 中成员的数据量过大：一个 Hash 类型的 Key，它的成员数量虽然只有 1000 个但这些成员的
Value 值总大小为 100 MB
```
**Big Key 的危害？**

1 、阻塞请求

Big Key 对应的 value 较大，我们对其进行读写的时候，需要耗费较长的时间，这样就可能阻塞后续的请
求处理。Redis 的核心线程是单线程，单线程中请求任务的处理是串行的，前面的任务完不成，后面的
任务就处理不了。

**2 、** 内存增大

读取 Big Key 耗费的内存比正常 Key 会有所增大，如果不断变大，可能会引发 OOM（内存溢出），或达
到 redis 的最大内存 maxmemory 设置值引发写阻塞或重要 Key 被逐出。

3 、阻塞网络


读取单 value 较大时会占用服务器网卡较多带宽，自身变慢的同时可能会影响该服务器上的其他 Redis 实
例或者应用。

4 、影响主从同步、主从切换

删除一个大 Key 造成主库较长时间的阻塞并引发同步中断或主从切换。

#### HyperLogLog 原理和实操

HyperLogLog 是大数据基数统计中的常见方法，无论是 Redis，Spark 还是 Flink 都提供了这个功能，
其目的就是在一定的误差范围内，用最小的空间复杂度来估算一个数据流的基数。

这个最小的空间，小到什么程度呢？在 Redis 中实现的 HyperLogLog，只需要 12 K 内存就能统计 2^64
个数据。不过有得必有失，HyperLogLog 计数存在一定的误差，误差率整体较低。标准误差为 0.81%
，不到 1%。当然，误差可以被设置辅助计算因子进行降低。

###### 什么是 HyperLogLog ？

HyperLogLog 是一种概率性数据结构，它是 LogLog 算法的升级版，作用是能够提供不精确的去重计
数。HyperLogLog 下面简称为 HLL，

Redis 中的 HLL 是基于 string 结构实现的，单个 HLL 的内存 **永远小于 16 kb** ， **内存占用低** 的令人发指！作为
代价，其测量结果是概率性的， **有小于 0.81％的误差** 。

HLL 是一种用于基数统计的算法，可以用来估计一个集合中不同元素的数量，而不需要存储这些元素本
身。它可以高效地处理大规模的数据集，且占用的空间非常小，通常只需要几千个字节的存储空间就可
以处理数十亿个元素。HLL 算法的实现非常简单，可以使用位图和随机哈希函数来实现。

HLL 算法的基本思想是利用随机哈希函数将元素映射到一个二进制字符串中，并根据哈希函数的结果将
字符串分为若干个桶。在每个桶中，记录哈希值的最大前导零的数量。

对于一个大的数据集，可以对每个元素进行哈希并记录其对应桶的最大前导零的数量，然后计算所有桶
的平均值，得到一个近似的基数估计值。

HLL 算法的误差率可以控制在 0.81/sqrt (m) 以内，其中 m 是桶的数量。

因此，随着桶的数量增加，误差率将变得越来越小。

HLL 算法的优点在于它具有极低的内存消耗和高效的计算速度，并且可以处理极大的数据集。

###### HyperLogLog 与 bitmap 对比

1 、bitmap

优势是：非常均衡的特性，精准统计，可以得到每个统计对象的状态，秒出。

缺点是：当你的统计对象数量十分十分巨大时，可能会占用到一点存储空间，但也可在接受范围内。也
可以通过分片，或者压缩的额外手段去解决。

**注意：bitmap 是精确的**


2 、HyperLogLog

优势是：

可以统计夸张到无法想象的数量，并且占用小的夸张的内存。

缺点是：

建立在牺牲准确率的基础上，而且无法得到每个统计对象的状态。

**注意：HyperLogLog 不是精确的，误差在 1%左右**

###### HyperLogLog 的使用场景

HyperLogLog 算法主要用于基数统计场景，即需要快速统计一个数据集中不同元素的数量的场合。在实
际应用中，HyperLogLog 算法通常应用于以下场景：

```
大数据去重：
在大数据场景下，需要去重的数据量非常大，如果使用传统的去重算法，需要对每个元素进行存储
和比对，时间和空间消耗非常高。HyperLogLog 算法可以在占用极小的空间的情况下，高效地对
大规模数据进行去重，提高去重效率。
用户活跃度统计：
在 Web 应用和移动应用中，需要对用户的活跃度进行统计。如果每个用户的活跃度都进行存储，
需要消耗大量的存储空间。HyperLogLog 算法可以在占用极小的空间的情况下，高效地统计活跃
用户数量，提高统计效率。
网站 UV 统计：
在 Web 应用中，需要统计网站每日独立访客数量（即 UV），但是由于数据量非常大，不能简单地
直接计数，因为会导致内存不足。HyperLogLog 算法可以在占用极小的空间的情况下，高效地对
大规模的访问日志进行去重和统计，提高统计效率。
社交网络推荐：
在社交网络中，需要对用户的兴趣爱好进行统计，以便向用户推荐相关内容。HyperLogLog 算法
可以在占用极小的空间的情况下，高效地对用户行为进行去重和统计，提高推荐效率。
```
总之，HyperLogLog 算法可以在需要高效处理大规模数据集的场景下发挥作用，适用于各种基数统计场
合，可以提高数据处理效率，减少存储空间的消耗。

#### HyperLogLog 的相关命令

Redis 提供了多个 HyperLogLog 相关的指令，包括以下几个：

```
PFADD：将一个或多个元素添加到指定的 HyperLogLog 数据结构中。
语法：PFADD key element [element ...]
```
```
PFCOUNT：统计指定的 HyperLogLog 数据结构中不同元素的数量。
语法：PFCOUNT key [key ...]
```
```
1 PFADD hll_key a b c
```
```
1 PFCOUNT hll_key
```

```
PFMERGE：将多个 HyperLogLog 数据结构合并为一个。
语法：PFMERGE destkey sourcekey [sourcekey ...]
```
这些指令可以方便地对 HyperLogLog 数据结构进行添加、统计和合并操作，以满足各种基数统计场景的
需求。

需要注意的是，HyperLogLog 数据结构虽然占用空间非常小，但是在添加元素时需要进行哈希计算，因
此添加元素的效率可能会受到影响。

因此，在 java 代码中，可以使用队列缓存+ 批量写入的架构，进行批量添加，尽量减少 io 时间。

在使用 HyperLogLog 数据结构时，需要根据实际情况评估其效率和误差率，以确定是否适合使用
HyperLogLog 算法。

#### SpringBoot 实操：利用 HyperLogLog 实现网站 UV 统计

利用 HyperLogLog 实现网站 UV 统计，代码如下：

测试如下：

```
1 PFMERGE hll_key 1 hll_key 2 hll_key 3
```

误差计算：

1 百万，减去 99 6723 ，大概在 4000 左右，不到 1%

#### 超高并发异步架构

通过阻塞队列，使用队列缓存+批量写入的架构

###### 队列缓存+批量写入的架构

这里用了阻塞队列，这个非常常用

具体的架构图如下：


所以阻塞队列的结构，以及底层原理，大家好好掌握

访问记录，直接进入到阻塞队列，参考代码如下

异步写入的参考代码如下：

```
BlockingDeque<String> dauList = new LinkedBlockingDeque<>();
```
```
1
2
3
```

#### 本文的版本计划和基础学习资料：

尼恩作为技术中台、数据中台的架构师，高并发是尼恩架构的重点，所以，后面会大家从架构到实
操，多个维度、多种场景的高并发实操。

而且尼恩指导简历的过程中，也指导过小伙伴写过 10 Wqps 超高并发网关、超高并发秒杀、超高并发
物联网等等简历，里边涉及到大量的设计模式，

经过尼恩的指导之后，很多小伙伴的简历，里边立马金光闪闪，并且顺利走上了架构师之路。

后面有机会，带大家做一下这个高质量的实操，并且指导大家写入简历。

所以，这个材料后面也会进行持续迭代，大家可以找尼恩来获取最新版本和技术交流。

**尼恩编著的 400 页 PDF 电子书《SpringCloud Alibaba 技术圣经》**

**尼恩编著的 500 页 PDF 电子书《Java 高并发核心编程卷 2 加强版》，清华大学出版社出版**

pdf 领取方式，请参见公众号： 技术自由圈

## 作者介绍：

尼恩， 40 岁资深老架构师，《Java 高并发核心编程加强版卷 1 、卷 2 、卷 3 》创世作者，著名博主。
《K 8 S 学习圣经》《Docker 学习圣经》等 11 个 PDF 圣经的作者。

## 参考文献

https://blog.csdn.net/Weixiaohuai/article/details/125391957

Redis 分布式锁 （图解-秒懂-史上最全）

https://www.cnblogs.com/crazymakercircle/p/14731826.html

Zookeeper 分布式锁 （图解+秒懂+史上最全）

https://www.cnblogs.com/crazymakercircle/p/14504520.html

https://www.cnblogs.com/crazymakercircle/p/14731826.html

https://blog.csdn.net/zs18753479279/article/details/115751593

[http://blog.csdn.net/jackpk/article/details/30073097](http://blog.csdn.net/jackpk/article/details/30073097)

[http://www.jb51.net/article/65264.htm](http://www.jb51.net/article/65264.htm)


https://juejin.cn/post/6844904116485898248

https://www.jianshu.com/p/4b929f54a8d1

https://blog.csdn.net/weixin_42452888/article/details/127557245

https://www.jianshu.com/p/16db5e666e65

Github：rdb-tools

(1) redis 命令：Redis 命令参考 — Redis 命令参考

(2) Github: https://github.com/sripathikrishnan/redis-rdb-tools

(3) another redis desktop manager 下载地址 AnotherRedisDesktopManager 发行版 - Gitee. com


```
技术自由圈
```
## 未来职业，如何突围：三栖架构师


```
技术自由圈
```
### 成功案例： 2 年翻 3 倍， 35 岁卷王成功转型为架构师

详情：http://topcoder.cloud/forum.php?mod=forumdisplay&fid=43&page=1


技术自由圈


技术自由圈


技术自由圈


```
技术自由圈
```
### 硬核推荐：尼恩 Java 硬核架构班

详情：https://www.cnblogs.com/crazymakercircle/p/9904544.html


技术自由圈


```
技术自由圈
```
##### 架构班（社群 VIP）的起源：

最初的视频，主要是给读者加餐。很多的读者，需要一些高质量的实操、理论视频，所以，我就围绕书，和底层，做了几个
实操、理论视频，然后效果还不错，后面就做成迭代模式了。

##### 架构班（社群 VIP）的功能：^

提供高质量实操项目整刀真枪的架构指导、快速提升大家的:
⚫ 开发水平
⚫ 设计水平
⚫ 架构水平
弥补业务中 CRUD 开发短板，帮助大家尽早脱离具备 3 高能力，掌握：
⚫ 高性能
⚫ 高并发
⚫ 高可用
作为一个高质量的架构师成长、人脉社群，把所有的卷王聚焦起来，一起卷：
⚫ 卷高并发实操
⚫ 卷底层原理
⚫ 卷架构理论、架构哲学
⚫ 最终成为顶级架构师，实现人生理想，走向人生巅峰

##### 架构班（社群 VIP）的目的：^

⚫ 高质量的实操，大大提升简历的含金量，吸引力，增强面试的召唤率
⚫ 为大家提供九阳真经、葵花宝典，快速提升水平
⚫ 进大厂、拿高薪
⚫ 一路陪伴，提供助学视频和指导，辅导大家成为架构师
⚫ 自学为主，和其他卷王一起，卷高并发实操，卷底层原理、卷大厂面试题，争取狠卷 3 月成高手，狠卷 3 年成为顶级架
构师


```
技术自由圈
```
##### N 个超高并发实操项目：简历压轴、个顶个精彩


```
技术自由圈
```
【样章】第 17 章：横扫全网 Rocketmq 视频第 2 部曲: 工业级 rocketmq 高可用（HA）底层原
理和实操

工业级 rocketmq 高可用底层原理，包含：消息消费、同步消息、异步消息、单向消息等不同消息的底层原理和源码实现；
消息队列非常底层的主从复制、高可用、同步刷盘、异步刷盘等底层原理。
工业级 rocketmq 高可用底层原理和搭建实操，包含：高可用集群的搭建。
解决以下难题：
1 、技术难题：RocketMQ 如何最大限度的保证消息不丢失的呢？RocketMQ 消息如何做到高可靠投递？
2 、技术难题：基于消息的分布式事务，核心原理不理解
3 、选型难题： kafka or rocketmq ，该娶谁？
下图链接：https://www.processon.com/view/6178e8ae0e3e7416bde9da19


```
技术自由圈
```
### 简历优化后的成功涨薪案例（ VIP 含免费简历优化）


技术自由圈


技术自由圈


技术自由圈


技术自由圈


技术自由圈


技术自由圈


技术自由圈


```
技术自由圈
```
### 修改简历找尼恩（资深简历优化专家）

⚫ 如果面试表达不好，尼恩会提供简历优化指导

⚫ 如果项目没有亮点，尼恩会提供项目亮点指导

⚫ 如果面试表达不好，尼恩会提供面试表达指导

作为 40 岁老架构师，尼恩长期承担技术面试官的角色：

⚫ 从业以来，“阅历”无数，对简历有着点石成金、改头换面、脱胎换骨的指导能力。

⚫ 尼恩指导过刚刚就业的小白，也指导过 P 8 级的老专家，都指导他们上岸。

如何联系尼恩。尼恩微信，请参考下面的地址：

语雀：https://www.yuque.com/crazymakercircle/gkkw8s/khigna
码云：https://gitee.com/crazymaker/SimpleCrayIM/blob/master/疯狂创客圈总目录.md


