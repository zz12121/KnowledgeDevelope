```
技术自由圈
```
# 牛逼的职业发展之路

40 岁老架构尼恩用一张图揭秘: Java 工程师的高端职业发展路径，走向食物链顶端的之路

链接：https://www.processon.com/view/link/618a2b62e0b34d73f7eb3cd


```
技术自由圈^
```
# 史上最全：价值 10 W 的架构师知识图谱

此图梳理于尼恩的多个 3 高生产项目：多个亿级人民币的大型 SAAS 平台和智慧城市项目

链接：https://www.processon.com/view/link/60fb9421637689719d


```
技术自由圈
```
# 牛逼的架构师哲学

40 岁老架构师尼恩对自己的 20 年的开发、架构经验总结

链接：https://www.processon.com/view/link/616f801963768961e9d9aec


```
技术自由圈
```
# 牛逼的 3 高架构知识宇宙

尼恩 3 高架构知识宇宙，帮助大家穿透 3 高架构，走向技术自由，远离中年危机

链接：https://www.processon.com/view/link/635097d2e0b34d40be778ab


```
技术自由圈
```
# 尼恩 Java 面试宝典

40 个专题（卷王专供+ 史上最全 + 2023 面试必备）
详情：https://www.cnblogs.com/crazymakercircle/p/13917138.html


```
技术自由圈^
```
# 未来职业，如何突围：三栖架构师


## 专题 4 ：架构设计篇（史上最全、定期更新）

#### 本文版本说明：V

```
此文的格式，由markdown 通过程序转成而来，由于很多表格，没有来的及调整，出现一个格式
问题，尼恩在此给大家道歉啦。
由于社群很多小伙伴，在面试，不断的交流最新的面试难题，所以，《尼恩Java面试宝典》， 后
面会不断升级，迭代。
```
```
本专题，作为 《Java面试红宝书》专题之一， 《Java面试红宝书》一共 41 个面试专题，后续还
会增加
```
###### 升级说明：

**升级说明（2023-09-14）**

亿级长连接，淘宝接入层网关的架构设计

**升级说明（2023-09-07）**

100 万级连接，爱奇艺 WebSocket 网关如何架构

**升级说明（2023-09-05）**

日 200 亿次调用，喜马拉雅网关的架构设计

**升级说明（2023-09-04）**

千万级连接，知乎如何架构长连接网关？

**升级说明（2023-09-03）**

日流量 200 亿，携程网关的架构设计

**V 105 升级说明（2023-09-02）**

多级缓存架构设计

**V 104 升级说明（2023-09-01）**

百亿级访问量，如何做缓存架构设计

**V 103 升级说明（2023-08-29）**

消息推送架构设计

**V 102 升级说明（2023-08-27）**

阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？

**V 101 升级说明（2023-08-26）**

美团 2 面： 5 个 9 高可用 99.999%，如何实现？


**V 97 升级说明（2023-08-16）**

亿级短视频，如何架构？

**V 96 升级说明（2023-08-14）**

字节二面：10 Wqps 会员系统，如何设计？

**V 94 升级说明（2023-08-04）**

大厂必面：你们系统 qps 多少，怎么部署的？假设每天有几千万请求，该如何部署？

**V 92 升级说明（2023-07-28）**

1000 Wqps 生产级 IM，怎么架构？

**V 90 升级说明（2023-07-26）**

腾讯太狠： 10 亿 QPS 的 IM，如何实现？

**V 87 升级说明（2023-07-22）**

滴滴太狠：分布式 ID，如何达到 1000 Wqps？

**V 86 升级说明（2023-07-18）**

10 亿级用户，如何做熔断降级架构？微信和 hystrix 的架构对比

**V 76 升级说明**

B 站崩，唯品崩，大型网站如何做到高可用？

**V 75 升级说明**

美团一面：接口被恶刷 10 Wqps，怎么解决？

**V 74 升级说明**

如果你当架构师，从 0 开始，如何做一个后台项目的架构？

**V 67 升级说明（2023-05-16）：**

30 Wqps+闲鱼优惠中台，如何架构的？

**V 35 升级说明（2022-11-08）：**

字节二面真题：100 Wqps 短链系统，怎么设计？

**V 10 升级说明（2022-11-08）：**

综合题: 如何设计一个高并发系统?

###### 面试问题交流说明：

如果遇到面试难题，或者职业发展问题，或者中年危机问题，都可以来疯狂创客圈社群交流，

加入交流群，加尼恩微信即可，


尼恩的微信二维码在哪里呢 ？ 具体参见文末

#### 史上最全 Java 面试题：架构设计篇

#### 场景题

整理了一些常见的架构设计面试题，主要记录关键点，具体细节就不详细叙述了，案例慢慢补充。目前
想起以下问题：

```
秒杀系统
短链接生成
高并发的红包系统
分布式ID生成
分布式限流
分布式定时任务
新浪微博怎么推送微博
大文件有限内存排序
分布式IM
```
###### 分布式 IM 架构

一次 p 8 级的面试真题： 如果让你做一个分布式的 IM，该怎么做架构设计？

P 8 级候选人回答的架构方案，和尼恩的《Java 高并发核心编程卷 1 加强版》里边 IM 的架构方案，一模
一样。


###### 秒杀系统架构

秒杀系统基本面试被问烂了，网上资料也很多，基本整理了内容如下：

设计难点：并发量大，应用、数据库都承受不了。另外难控制超卖。

设计要点：


```
将请求尽量拦截在系统上游，html尽量静态化，部署到cdn上面。按钮及时设置为不可用，禁止用
户重复提交请求。
设置页面缓存，针对同一个页面和uid一段时间内返回缓存页面。
数据用缓存抗，不直接落到数据库。
读数据的时候不做强一致性教研，写数据的时候再做。
在每台物理机上也缓存商品信息等等变动不大的相关的数据
像商品中的标题和描述这些本身不变的会在秒杀开始之前全量推送到秒杀机器上并一直缓存直到秒
杀结束。
像库存这种动态数据会采用被动失效的方式缓存一定时间（一般是数秒），失效后再去Tair缓存拉
取最新的数据。
如果允许的话，用异步的模式，等缓存都落库之后再返回结果。
如果允许的话，增加答题教研等验证措施。
```
其他业务和技术保障措施：

```
业务隔离。把秒杀做成一种营销活动，卖家要参加秒杀这种营销活动需要单独报名，从技术上来
说，卖家报名后对我们来说就是已知热点，当真正开始时我们可以提前做好预热。
系统隔离。系统隔离更多是运行时的隔离，可以通过分组部署的方式和另外 99% 分开。秒杀还申
请了单独的域名，目的也是让请求落到不同的集群中。
数据隔离。秒杀所调用的数据大部分都是热数据，比如会启用单独 cache 集群或 MySQL 数据库来
放热点数据，目前也是不想0.01%的数据影响另外99.99%。
```
另外需要复习缓存穿透、雪崩等等问题，主要的流量都落在了缓存数据库上，需要针对缓存数据库的高
可用作保障。

短链接生成

这个应该是比较公认的方案了：

```
1. 分布式ID生成器产生ID
2. ID转 62 进制字符串
3. 记录数据库，根据业务要求确定过期时间，可以保留部分永久链接
```
主要难点在于分布式 ID 生成。鉴于短链一般没有严格递增的需求，可以使用预先分发一个号段，然后生
成的方式。

看了下新浪微博的短链接， 8 位，理论上可以保存超过 200 万亿对关系，具体怎么存储的还有待研究。

###### 红包系统架构

红包系统其实很像秒杀系统，只不过同一个秒杀的总量不大，但是全局的并发量非常大，比如春晚可能
几百万人同时抢红包。

主要技术难点也类似，主要在数据库，减库存的时候会抢锁。另外由于业务需求不同，没办法异步，也
不能超卖，事务更加严格。

不能采用的方式：

```
乐观锁：手慢会失败，DB 面临更大压力，所以不能采用。
直接用缓存顶，涉及到钱，一旦缓存挂掉就完了。
```
建议的方式：

```
接入层垂直切分，根据红包ID，发红包、抢红包、拆红包、查详情详情等等都在同一台机器上处
理，互不影响，分而治之。
请求进行排队，到数据库的时候是串行的，就不涉及抢锁的问题了。
为了防止队列太长过载导致队列被降级，直接打到数据库上，所以数据库前面再加上一个缓存，用
CAS自增控制并发，太高的并发直接返回失败。
```

```
红包冷热数据分离，按时间分表。
```
###### 分布式 ID 架构

分布式 ID 生成大概也算老生常谈的问题了，主要关键在于是否需要严格递增，严格递增的话效率必然大
降。

不需要递增的话比较简单:

```
一种方式是预先分片，比如十台机器，每台先分一千个ID，一号机从 0 开始，二号从 1000 开始等
等。缺点是大致上可以被人看出来业务量。
另一种方式是类似雪花算法，每个机器有个id，然后基于时间算一个id，再加上一个递增id。比如
如下美团的方案。缺点是机器的时间戳不能回拨，回拨的话会出现问题。
```
如果要求严格递增，我没找到现成的很好的方案，大概只能单机生成，不能分布式了，然后都去单机上
取号。效率的话，类似 Redis 的数据库大概能到每秒十几二十几万的速度。

###### 分布式限流架构

常见的限流方法：

```
固定窗口计数器：按照时间段划分窗口，有一次请求就+1，最为简单的算法，但这个算法有时会
让通过请求量允许为限制的两倍。
滑动窗口计数器：通过将窗口再细分，并且按照时间“滑动”来解决突破限制的问题，但是时间区间
的精度越高，算法所需的空间容量就越大。
漏桶：请求类似水滴，先放到桶里，服务的提供方则按照固定的速率从桶里面取出请求并执行。缺
陷也很明显，当短时间内有大量的突发请求时，即便此时服务器没有任何负载，每个请求也都得在
队列中等待一段时间才能被响应。
令牌桶：往桶里面发放令牌，每个请求过来之后拿走一个令牌，然后只处理有令牌的请求。令牌桶
满了则多余的令牌会直接丢弃。令牌桶算法既能够将所有的请求平均分布到时间区间内，又能接受
服务器能够承受范围内的突发请求，因此是目前使用较为广泛的一种限流算法。
```
Google 的开源项目 guava 提供了 RateLimiter 类，实现了单点的令牌桶限流。

分布式环境下，可以考虑用 Redis+Lua 脚本实现令牌桶。

如果请求量太大了，Redis 也撑不住怎么办？我觉得可以类似于分布式 ID 的处理方式，Redis 前面在增
加预处理，比如每台及其预先申请一部分令牌，只有令牌用完之后才去 Redis。如果还是太大，是否可
以垂直切分？按照流量的来源，比如地理位置、IP 之类的再拆开。

###### 分布式定时任务架构

任务轮询或任务轮询+抢占排队方案

```
每个服务器首次启动时加入队列；
每次任务运行首先判断自己是否是当前可运行任务，如果是便运行；
```

```
如果不是当前运行的任务，检查自己是否在队列中，如果在，便退出，如果不在队列中，进入队
列。
```
###### 微博推送架构

主要难点：关系复杂，数据量大。一个人可以关注非常多的用户，一个大 V 也有可能有几千万的粉丝。

先介绍最基本的方案：

```
1. 推模式：推模式就是，用户A关注了用户 B，用户 B 每发送一个动态，后台遍历用户B的粉丝，往
他们粉丝的 feed 里面推送一条动态。
2. 拉模式：推模式相反，拉模式则是，用户每次刷新 feed 第一页，都去遍历关注的人，把最新的动
态拉取回来。
```
一般采用推拉结合的方式，用户发送状态之后，先推送给粉丝里面在线的用户，然后不在线的那部分等
到上线的时候再来拉取。

另外冷热数据分离，用户关系在缓存里面可以设置一个过期时间，比如七天。七天没上线的可能就很少
用这个 APP。

###### 大文件排序架构

对于远高于内存的文件排序。

外归并排序：

```
对文件分割，然后分别排序
排好序的文件依次读取一个缓冲区的大小，然后进行排序，输出到输出缓冲区，然后保存到结果文
件。
```
如果是数字，可以用位图排序，但是要求比较苛刻：

```
数字不重复
知道最大值
相对密集，因为没出现的数字也会占用空间
```
比较适合电话号之类的。

###### 其他场景题

1 、 **情景题：如果一个外卖配送单子要发布，现在有 200 个骑手都想要接这一单，如何保证只有一个骑手
接到单子？**

这个可以用 redis 的 lpush rpop 来实现。

2 、 **场景题：美团首页每天会从 10000 个商家里面推荐 50 个商家置顶，每个商家有一个权值，你如何来
推荐？第二天怎么更新推荐的商家？**

这个可以用堆排，第二天更新推荐的可以在要更新之前的时候在 redis 做计算操作，然后放数据库做个同
步就行了。

3 、 **场景题：微信抢红包问题**
悲观锁，乐观锁，存储过程放在 mysql 数据库中。
4 、 **场景题： 1000 个任务，分给 10 个人做，你怎么分配，先在纸上写个最简单的版本，然后优化。**
全局队列，把 1000 任务放在一个队列里面，然后每个人都是取，完成任务。
分为 10 个队列，每个人分别到自己对应的队列中去取务。
5 、 **场景题：保证发送消息的有序性，消息处理的有序性。**


给消息加一个 header，识别一下 header 的 syn 就行

6 、 **如何把一个文件快速下发到 100 w 个服务器**

边下发，边复制

7 、 **给每个组分配不同的 IP 段，怎么设计一种结构使的快速得知 IP 是哪个组的?**

8 、 **10 亿个数，找出最大的 10 个。**
建议一个大小为 10 的小根堆。
9 、 **有几台机器存储着几亿淘宝搜索日志，你只有一台 2 g 的电脑，怎么选出搜索热度最高的十个搜索关
键词？**

分 bucket，每个 bucket 找出频次最高的 10 个，总体用分治算法做。

10 、 **分布式集群中如何保证线程安全？**

分布式锁，意在让分布式多线程的环境针对一个共享资源一次性只会有一个线程获取到锁里的资源。分
布式锁的实现一般就是 redis 和 zk 居多。redis 设置一下 expire time 就行。

11 、 **10 万个数，输出从小到大？**
先划分成多个小文件，送进内存排序，然后再采用多路归并排序。
12 、 **有十万个单词，找出重复次数最高十个？**

map<String,Integer> 字符串，频次，然后堆排。

###### 场景题答题小建议：

架构设计题目远不止这些，我觉得主要从以下几个方面准备：

```
先了解常用算法，针对解决各种问题能用哪些算法，比如大文件排序用外排序，大量数据中的命中
判断用位图/布隆过滤器等等。
注意扩展性、多考虑极端情况，多问自己几个为什么。比如说起单机的限流算法想想分布式的怎么
做。
实在不知道怎么弄的叙述自己的思考过程，着重展示自己考虑周全、思维缜密。
```
比如之前一个同事面阿里被问整个机房网络挂了/断电了之类的极端问题，相信很多人不可能真的遇到
这种情况，而且可用性一般也到不了这个级别。如果是我的话，我会着重考虑数据一致性、数据恢复、
脏数据处理之类的问题，是否有其他机房提供服务，如果有的话涉及到网络分区，是不是可以引申谈谈
zab、raft 算法，另外原本两个或者三个机房提供服务，现在瞬间少了一个，其他机房的负载瞬间上
升，怎么做削峰、降级，这就有回到我们会的问题上了。另外等到网络恢复了，怎么恢复服务？之前处
理到一半的数据怎么处理？这些引申开来都有太多可以聊。

#### 场景题: 如何设计一个高并发系统?

**题目描述**

面试官有时在面试中会直接问你：你是如何设计一个高并发系统？

###### 面试官心理分析（解题思维方向）

现在很多公司招聘的 JD 里都是说啥，有高并发就经验者优先。

**面试题剖析**


分为以下 6 点：

```
系统拆分
缓存
MQ
分库分表
读写分离
ElasticSearch
```
**系统拆分**

将一个系统拆分为多个子系统，用微服务去解耦。

然后每个系统连一个数据库，这样本来就一个库，现在多个数据库，不也可以扛高并发么。

```
参考： 秒杀实操
```
**缓存**

缓存，必须得用缓存。

读多写少场景，读的时候大量走缓存，保证 db 与 cache 的一致性就 ok。

redis 轻轻松松单机几万的并发。

```
参考： 秒杀实操
```
**MQ**

写高并发的场景，必须得用 MQ。

mysql 的吞吐量低，这样通过 MQ 做削峰填谷

而且可以通过 disruptor 组件，进行队列缓存+批量写入的高并发写入架构

```
参考： 100w qps 日志中台实操
```
**分库分表**

最后数据库层面还是免不了抗高并发的要求，

那就，分库分表，

```
参考： 10w qps 推送中台实操
```
**读写分离**

读写分离，这个就是说大部分时候数据库可能也是读多写少，

没必要所有请求都集中在一个库上，可以搞搞一个读写分离, 数据库主从架构，一主多从，主库写入，
从库读取。

读从库，写主库

当然，这里要能容忍解决数据的同步延迟的问题。

**高速全文搜索**

Elasticsearch，简称 es。


es 是分布式的，可以随便扩容，分布式天然就可以支撑高并发，因为动不动就可以扩容加机器来扛更高
的并发。那么一些比较简单的查询、统计类的操作，可以考虑用 es 来承载，还有一些全文搜索类的操
作，也可以考虑用 es 来承载。

**尼恩暗语：**

具体的高并发方案，需要因地制宜，和项目结合而定

具体，可以和尼恩或者在卷王群，针对项目做交流

#### 分布式微服务架构

###### 问 1. 什么是分布式系统

**分布式系统的目标与要素**

分布式系统的目标是提升系统的整体性能和吞吐量另外还要尽量保证分布式系统的容错性（假如增加 10
台服务器才达到单机运行效果 2 倍左右的性能，那么这个分布式系统就根本没有存在的意义）。

即使采用了分布式系统，我们也要尽力运用并发编程、高性能网络框架等等手段提升单机上的程序性
能。

**分布式系统设计两大思路：中心化和去中心化**

**中心化设计**

```
两个角色： 中心化的设计思想很简单，分布式集群中的节点机器按照角色分工，大体上分为两种
角色： “领导” 和 “干活的”
角色职责： “领导”通常负责分发任务并监督“干活的”，发现谁太闲了，就想发设法地给其安排新任
务，确保没有一个“干活的”能够偷懒，如果“领导”发现某个“干活的”因为劳累过度而病倒了，则是
不会考虑先尝试“医治”他的，而是一脚踢出去，然后把他的任务分给其他人。其中微服务架构
Kubernetes 就恰好采用了这一设计思路。
中心化设计的问题
1. 中心化的设计存在的最大问题是“领导”的安危问题，如果“领导”出了问题，则群龙无首，整个
集群就奔溃了。但我们难以同时安排两个“领导”以避免单点问题。
2. 中心化设计还存在另外一个潜在的问题，既“领导”的能力问题：可以领导 10 个人高效工作并
不意味着可以领导 100 个人高效工作，所以如果系统设计和实现得不好，问题就会卡在“领导”
身上。
```

```
领导安危问题的解决办法： 大多数中心化系统都采用了主备两个“领导”的设计方案，可以是热备或
者冷备，也可以是自动切换或者手动切换，而且越来越多的新系统都开始具备自动选举切换“领导”
的能力，以提升系统的可用性。
```
**去中心化设计**

```
众生地位平等： 在去中心化的设计里，通常没有“领导”和“干活的”这两种角色的区分，大家的角色
都是一样的，地位是平等的，全球互联网就是一个典型的去中心化的分布式系统，联网的任意节点
设备宕机，都只会影响很小范围的功能。
“去中心化”不是不要中心，而是由节点来自由选择中心。 （集群的成员会自发的举行“会议”选举新
的“领导”主持工作。最典型的案例就是ZooKeeper及Go语言实现的Etcd）
去中心化设计的问题： 去中心化设计里最难解决的一个问题是 “脑裂”问题 ，这种情况的发生概率
很低，但影响很大。脑裂指一个集群由于网络的故障，被分为至少两个彼此无法通信的单独集群，
此时如果两个集群都各自工作，则可能会产生严重的数据冲突和错误。一般的设计思路是，当集群
判断发生了脑裂问题时，规模较小的集群就“自杀”或者拒绝服务。
```
**分布式与集群的区别是什么？**

```
分布式： 一个业务分拆多个子业务，部署在不同的服务器上
集群： 同一个业务，部署在多个服务器上。比如之前做电商网站搭的redis集群以及solr集群都是
属于将redis服务器提供的缓存服务以及solr服务器提供的搜索服务部署在多个服务器上以提高系
统性能、并发量解决海量存储问题。
```
###### 问 2. 如何防止 HA 集群的脑裂

**1. 引言**

脑裂（split-brain），指在一个高可用（HA）系统中，当联系着的两个节点断开联系时，本来为一个整
体的系统，分裂为两个独立节点，这时两个节点开始争抢共享资源，结果会导致系统混乱，数据损坏。

对于无状态服务的 HA，无所谓脑裂不脑裂；但对有状态服务 (比如 MySQL) 的 HA，必须要严格防止脑
裂。（但有些生产环境下的系统按照无状态服务 HA 的那一套去配置有状态服务，结果可想而知...）

**2 如何防止 HA 集群脑裂**

一般采用 2 个方法

```
1. 仲裁
当两个节点出现分歧时，由第 3 方的仲裁者决定听谁的。这个仲裁者，可能是一个锁服务，一个共
享盘或者其它什么东西。
2. fencing
当不能确定某个节点的状态时，通过fencing把对方干掉，确保共享资源被完全释放，前提是必须
要有可靠的fence设备。
```
理想的情况下，以上两者一个都不能少。但是，如果节点没有使用共享资源，比如基于主从复制的数据
库 HA，我们也可以安全的省掉 fence 设备，只保留仲裁。而且很多时候我们的环境里也没有可用的
fence 设备，比如在云主机里。

所以，单纯的双节点，无论如何也防止不了脑裂。

**3. 没有 fence 设备是否安全**


以 PostgreSQL 或 MySQL 的数据复制为例来说明这个问题。

客户端路由有几种方式，基于 VIP，基于 Proxy，基于 DNS 或者干脆客户端维护一个服务端地址列表自己
判断主从。不管采用哪种方式，主从切换的时候都要更新路由。

基于 VIP 的路由有一些变数，如果本该死掉的节点没有摘掉自己身上的 VIP，那么它随时可能出来捣乱
（即使新主已经通过 arping 更新了所有主机上的 arp 缓存，如果某个主机的 arp 过期，发一个 arp 查询，
那么就会发生 ip 冲突）。所以可以认为 VIP 也是一种特殊的共享资源，必需把它从故障节点上摘掉。至
于怎么摘，最简单的办法就是故障节点发现自己失联后自己摘，如果它还活着的话（如果它死了，也就
不用摘了）。如果负责摘 vip 的进程无法工作怎么办？这时候就可以用上本来不太靠谱的软 fence 设备了
(比如 ssh)。
也要考虑 Proxy 的高可用
至于基于服务端地址列表的方法，客户端需要通过后台服务判断主从（比如 PostgreSQL/MySQL 会话是
否处于只读模式）。这时，如果出现 2 个主，客户端就会错乱。为防止这个问题，原主节点发现自己失
联后要自己把服务停掉，这和前面摘 vip 的道理是一样的。

**4. 主从切换后数据能否保证不丢**

主从切换后数据会不会丢和脑裂可以认为是 2 个不同的问题。还以 PostgreSQL 或 MySQL 的数据复制为例
来说明。
对 PostgreSQL，如果配置成同步流复制，可以做到不管路由是否正确，都不会丢数据。因为路由到错
误节点的客户端根本写不进任何数据，它会一直等待从节点的反馈，而它以为的从节点，现在已经是主
子了，当然不会理它。当然如果老是这样也不好，但它给集群监视软件纠正路由错误提供了充足的时
间。
如果本来就是配置的异步复制，那就是说已经做好丢数据的准备了。这时候，主从切换时丢点数据也没
啥大不了，但要控制自动切换的次数。比如控制已经被 failover 掉的原主不允许自动上线，否则如果因
为网络抖动导致故障切换，那么主从就会不停的来回切，不停的丢数据，破坏数据的一致性。

**5. 如何实现上面的策略**

你可以自己完全从头开始实现一套符合上述逻辑的脚本。但我更倾向于基于成熟的集群软件去搭建，比
如 Pacemaker+Corosync+合适的资源 Agent。Keepalived 我是极不推荐的，它就不适合用于有状态服
务的 HA，即使你把仲裁，fence 那些东西都加到方案里，总觉得别扭。

使用 Pacemaker+Corosync 的方案也有一些注意事项
1 ）了解资源 Agent 的功能和原理
了解资源 Agent 的功能和原理，才能知道它适用的场景。比如 pgsql 的资源 Agent 是比较完善的，支持
同步和异步流复制，并且可以在两者之前自动切换，并且可以保证同步复制下数据不会丢失。但目前
MySQL 的资源 Agent 就很弱了，没有使用 GTID 又没有日志补偿，很容易丢数据，还是不要用的好，继续
用 MHA 吧（但是，部署 MHA 时务必要防范脑裂）。

2 ）确保法定票数 (quorum)
quorum 可以认为是 Pacemkaer 自带的仲裁机制，集群的所有节点中的多数选出一个协调者，集群的
所有指令都由这个协调者发出，可以完美的杜绝脑裂问题。为了使这套机制有效运转，集群中至少有 3
个节点，并且把 no-quorum-policy 设置成 stop，这也是默认值。（很多教程为了方便演示，都把 no-
quorum-policy 设置成 ignore，生产环境如果也这么搞，又没有其它仲裁机制，是很危险的！）
但是，如果只有 2 个节点该怎么办？
一是拉一个机子借用一下凑足 3 个节点，再设置 location 限制，不让资源分配到那个节点上。
二是把多个不满足 quorum 小集群拉到一起，组成一个大的集群，同样适用 location 限制控制资源的分
配的位置。


但是如果你有很多双节点集群，找不到那么多用于凑数的节点，又不想把这些双节点集群拉到一起凑成
一个大的集群（比如觉得不方便管理）。那么可以考虑第三种方法。
第三种方法是配置一个抢占资源，以及服务和这个抢占资源的 colocation 约束，谁抢到抢占资源谁提供
服务。这个抢占资源可以是某个锁服务，比如基于 zookeeper 包装一个，或者干脆自己从头做一个，就
像下面这个例子。

[http://my.oschina.net/hanhanztj/blog/](http://my.oschina.net/hanhanztj/blog/)

（这个例子是基于 http 协议的短连接，更细致的做法是使用长连接心跳检测，这样服务端可以及时检出
连接断开而释放锁）但是，一定要同时确保这个抢占资源的高可用，可以把提供抢占资源的服务做成
lingyig 高可用的，也可以简单点，部署 3 个服务，双节点上个部署一个，第三个部署在另外一个专门的
仲裁节点上，至少获取 3 个锁中的 2 个才视为取得了锁。这个仲裁节点可以为很多集群提供仲裁服务（因
为一个机器只能部署一个 Pacemaker 实例，否则可以用部署了 N 个 Pacemaker 实例的仲裁节点做同样的
事情。）。

但是，如非迫不得已，尽量还是采用前面的方法，即满足 Pacemaker 法定票数，这种方法更简单，可靠

###### 问 3. 微服务架构基本理念和原则，为什么会在团队中使用微服务架

###### 构，实行微服务架构过程中碰到的问题及其解决方案。

**关键思路**

对于微服务架构而言，服务建模、服务拆分和服务集成是基本的设计理念，而 RPC、RESTful、API 网
关、分布式配置中心等基础组件以及服务可用性和数据最终一致性等关键要素也是重点内容。至于引入
微服务架构的原因和碰到的困难，团队业务发展特点和组织架构、微服务粒度和边界等都是回答该问题
的切入点。为了实现微服务架构，我们可以引入 Spring Cloud 等相对完善的技术实现体系，也可以使
用 Dubbo 作为我们的基础微服务架构。

**参考答案：**

**一体化架构的问题**

或者说是微服务架构所解决的问题。

1. 难以扩展

一体化架构应用只能通过在负载均衡器后面放置整个应用程序的多个实例来进行水平扩展。如果应用中
的特定服务需要扩展，则没有简单的选项。我们需要完整地扩展应用程序，这显然会造成不必要的资源
浪费。

相比之下，基于微服务的应用程序允许我们根据需要独立扩展单个服务。在上图中，如果需要缩放服务
B，则可以有 10 个实例，同时保持其他实例，并可以根据需要随时更改。

2. 交付时间长

一体化架构在单个应用的任何部分/层中进行的任何更改都需要构建和部署整个应用程序。个人开发人
员还需要下载整个应用程序代码来修复和测试，而不仅仅是受影响的模块，这就影响到了持续部署的效
率。

而在微服务架构中，如果仅在一百个微服务中的一个中需要改变，则仅构建和部署改变的微服务，没有
必要部署一切。我们甚至可以在短时间内多次部署。

3. 应用复杂性


过去，随着应用规模的增长（功能、功能等），团队也会相应扩张，应用很快就就会变得复杂和交织在
一起。随着不同的团队不断修改代码，维护模块化结构慢慢变得越来越困难，并慢慢导致像意大利面一
样交织的代码。这不仅会影响代码质量，还会影响整个组织。

在基于微服务的应用中，每个团队都在单独的微服务上工作，代码会有序很多。

4. 没有明确的所有权

在一体化应用中，看起来独立的团队实际上并不是独立的。它们同时在相同的代码库上工作，严重依赖
于彼此。

在基于微服务的应用中，独立团队处理单独的微服务。一个团队将拥有一个完整的微服务。工作的明确
所有权明确控制服务的一切，包括开发、部署和监控。

5. 故障级联

如果没有正确设计，一体化交媾应用的一部分失败可能会级联并导致整个系统崩溃。

在基于微服务的架构的情况下，我们可以使用断路器来避免这种故障。

6. Dev 和 Ops 之间的墙

开发团队通常会进行开发、测试，一旦部署，就会将维护和支持的所有权交给运维团队，应用此时与开
发团队无关了，而运维团队需要努力在生产环境中支持一体化架构应用。

在基于微服务的应用中，团队的组织理解为“构建它、运行它”，开发团队继续在生产中拥有该应用。

7. 陷入某种技术/语言

使用一体化架构，意味着被某种已实现的技术/语言锁定。如果需要更改技术/语言，则必须重写整个应
用程序。

使用微服务，每个服务可以根据需求和业务以不同的技术或语言实现。任何改变服务技术/语言的决定
都只需要重写该特定服务，因为所有微服务都是相互独立的。

8. 支持微服务的正确工具/技术的可用性

几年前，我们还没有适当的工具和技术来支持微服务。但自从 Docker 容器和云基础设施（特别是
PaaS）向大众提供服务以来，微服务正在大规模采用，因为它们提供了我们所需的“自由”，而无需进行
传统的配置程序。

**小结**

简单来说，使用微服务架构会获得以下好处：

```
独立开发部署服务
速度和敏捷性
更高的代码质量
获得围绕业务功能创建/组织的代码
提高生产力
更容易扩展
自由（在某种程度上）选择实施技术/语言
```
###### 问 3. RPC 的概念及其包含的核心组件和主流实现技术，如何实现一

###### 个自定义的 RPC 框架。

**关键思路**


该面试题相对容易回答，RPC 是分布式系统的基础，从思路上我们应该理解它是由网络通信、序列化、
传输协议、服务调用等组件所构成。同时，对业界主流 RPC 的实现技术也要有足够的了解，如 Alibaba
Dubbo、Google gRPC、Facebook Thrift 等。

**RPC 的由来**

随着互联网的发展，网站应用的规模不断扩大，常规的垂直应用架构已无法应对，分布式服务架构以及
流动计算架构势在必行，亟需一个治理系统确保架构有条不紊的演进。

```
单一应用架构
当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。
此时，用于简化增删改查工作量的 数据访问框架（ORM） 是关键。
垂直应用架构
当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，
以提升效率。
此时，用于加速前端页面开发的 Web框架（MVC） 是关键。
分布式服务架构
当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成
稳定的服务中心，使前端应用能更快速的响应多变的市场需求。
此时，用于提高业务复用及整合的 分布式服务框架（RPC），提供统一的服务是关键。
```
例如：各个团队的服务提供方就不要各自实现一套序列化、反序列化、网络框架、连接池、收发线程、
超时处理、状态机等“业务之外”的重复技术劳动，造成整体的低效。

所以，统一 RPC 框架来解决提供统一的服务。

**以下我将分别从如下四个方面详解 RPC。**

**RPC 的实现原理**


也就是说两台服务器 A，B，一个应用部署在 A 服务器上，想要调用 B 服务器上应用提供的函数/方法，由
于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。

比如说，A 服务器想调用 B 服务器上的一个方法：

Employee getEmployeeByName（String fullName）

**整个调用过程，主要经历如下几个步骤：**

**1 、建立通信**

首先要解决通讯的问题：即 A 机器想要调用 B 机器，首先得建立起通信连接。

主要是通过在客户端和服务器之间建立 TCP 连接，远程过程调用的所有交换的数据都在这个连接里传
输。连接可以是按需连接，调用结束后就断掉，也可以是长连接，多个远程过程调用共享同一个连接。

**2 、服务寻址**

要解决寻址的问题，也就是说，A 服务器上的应用怎么告诉底层的 RPC 框架，如何连接到 B 服务器（如主
机或 IP 地址）以及特定的端口，方法的名称名称是什么。

通常情况下我们需要提供 B 机器（主机名或 IP 地址）以及特定的端口，然后指定调用的方法或者函数的
名称以及入参出参等信息，这样才能完成服务的一个调用。

可靠的寻址方式（主要是提供服务的发现）是 RPC 的实现基石，比如可以采用 redis 或者 zookeeper 来注
册服务等等。


```
1. 从服务提供者的角度看：当提供者服务启动时，需要自动向注册中心注册服务；
2. 当提供者服务停止时，需要向注册中心注销服务；
3. 提供者需要定时向注册中心发送心跳，一段时间未收到来自提供者的心跳后，认为提供者已经停止
服务，从注册中心上摘取掉对应的服务。
4. 从调用者的角度看：调用者启动时订阅注册中心的消息并从注册中心获取提供者的地址；
5. 当有提供者上线或者下线时，注册中心会告知到调用者；
6. 调用者下线时，取消订阅。
```
**3 、网络传输**

**3.1、序列化**

当 A 机器上的应用发起一个 RPC 调用时，调用方法和其入参等信息需要通过底层的网络协议如 TCP 传输到
B 机器，由于网络协议是基于二进制的，所有我们传输的参数数据都需要先进行序列化（Serialize）或
者编组（marshal）成二进制的形式才能在网络中进行传输。然后通过寻址操作和网络传输将序列化或
者编组之后的二进制数据发送给 B 机器。

**3.2、反序列化**

当 B 机器接收到 A 机器的应用发来的请求之后，又需要对接收到的参数等信息进行反序列化操作（序列化
的逆操作），即将二进制信息恢复为内存中的表达方式，然后再找到对应的方法（寻址的一部分）进行
本地调用（一般是通过生成代理 Proxy 去调用,
通常会有 JDK 动态代理、CGLIB 动态代理、Javassist 生成字节码技术等），之后得到调用的返回值。

**4 、服务调用**

B 机器进行本地调用（通过代理 Proxy）之后得到了返回值，此时还需要再把返回值发送回 A 机器，同样
也需要经过序列化操作，然后再经过网络传输将二进制数据发送回 A 机器，而当 A 机器接收到这些返回值
之后，则再次进行反序列化操作，恢复为内存中的表达方式，最后再交给 A 机器上的应用进行相关处理
（一般是业务逻辑处理操作）。

通常，经过以上四个步骤之后，一次完整的 RPC 调用算是完成了。

**PRC 架构组件**

一个基本的 RPC 架构里面应该至少包含以下 4 个组件：

1 、客户端（Client）: 服务调用方（服务消费者）


2 、客户端存根（Client Stub）: 存放服务端地址信息，将客户端的请求参数数据信息打包成网络消息，
再通过网络传输发送给服务端

3 、服务端存根（Server Stub）: 接收客户端发送过来的请求消息并进行解包，然后再调用本地服务进行
处理

4 、服务端（Server）: 服务的真正提供者

**RPC 调用过程**

1 、服务消费者（client 客户端）通过本地调用的方式调用服务

2 、客户端存根（client stub）接收到调用请求后负责将方法、入参等信息序列化（组装）成能够进行
网络传输的消息体

3 、客户端存根（client stub）找到远程的服务地址，并且将消息通过网络发送给服务端

4 、服务端存根（server stub）收到消息后进行解码（反序列化操作）

5 、服务端存根（server stub）根据解码结果调用本地的服务进行相关处理

6 、本地服务执行具体业务逻辑并将处理结果返回给服务端存根（server stub）

7 、服务端存根（server stub）将返回结果重新打包成消息（序列化）并通过网络发送至消费方

8 、客户端存根（client stub）接收到消息，并进行解码（反序列化）

9 、服务消费方得到最终结果

###### 问 4 说说 springcloud rpc 的执行流程和原理? 如何对 springcloud

###### 微服务进行高并发的性能优化？

请参考《springcloud nginx 高并发核心编程》一书

#### 分布式事务


###### 问 1 ：什么是分布式事务？

指事务的每个操作步骤都位于不同的节点上，需要保证事务的 AICD 特性。

```
1. 产生原因
```
数据库分库分表；

SOA 架构，比如一个电商网站将订单业务和库存业务分离出来放到不同的节点上。

```
2. 应用场景
```
下单：减少库存同时更新订单状态。库存和订单不在不同一个数据库，因此涉及分布式事务。

支付：买家账户扣款同时卖家账户入账。买家和卖家账户信息不在同一个数据库，因此涉及分布式事
务。

```
3. 解决方案
```
3.1 两阶段提交协议

两阶段提交协议可以很好得解决分布式事务问题，它可以使用 XA 来实现，XA 它包含两个部分：事务管
理器和本地资源管理器。其中本地资源管理器往往由数据库实现，比如 Oracle、DB 2 这些商业数据库
都实现了 XA 接口，而事务管理器作为全局的协调者，负责各个本地资源的提交和回滚。

3.2 消息中间件

消息中间件也可称作消息系统 (MQ)，它本质上是一个暂存转发消息的一个中间件。在分布式应用当
中，我们可以把一个业务操作转换成一个消息，比如支付宝的余额转如余额宝操作，支付宝系统执行减
少余额操作之后向消息系统发一个消息，余额宝系统订阅这条消息然后进行增加账户金额操作。

3.2.1 消息处理模型

点对点

.

发布/订阅


.

3.2.2 消息的可靠性

消息的发送端的可靠性：发送端完成操作后一定能将消息成功发送到消息系统。

消息的接收端的可靠性：接收端仅且能够从消息中间件成功消费一次消息。

发送端的可靠性

在本地数据建一张消息表，将消息数据与业务数据保存在同一数据库实例里，这样就可以利用本地数据
库的事务机制。事务提交成功后，将消息表中的消息转移到消息中间件，若转移消息成功则删除消息表
中的数据，否则继续重传。

接收端的可靠性

保证接收端处理消息的业务逻辑具有幂等性：只要具有幂等性，那么消费多少次消息，最后处理的结果
都是一样的。

保证消息具有唯一编号，并使用一张日志表来记录已经消费的消息编号。

###### CAP 定理


```
选项 描述
```
```
Consistency（一致
性）
```
```
指数据在多个副本之间能够保持一致的特性（严格的一致性）
```
```
Availability（可用
性）
```
```
指系统提供的服务必须一直处于可用的状态，每次请求都能获取到非错的
响应（不保证获取的数据为最新数据）
```
```
Partition
tolerance（分区容
错性）
```
```
分布式系统在遇到任何网络分区故障的时候，仍然能够对外提供满足一致
性和可用性的服务，除非整个网络环境都发生了故障
```
在理论计算机科学中，CAP 定理（CAP theorem），又被称作布鲁尔定理（Brewer’s theorem），它指
出对于一个分布式计算系统来说，不可能同时满足以下三点：

**Spring Cloud 在 CAP 法则上主要满足的是 A 和 P 法则，Dubbo 和 Zookeeper 在 CAP 法则主要满足的是 C
和 P 法则**

CAP 仅适用于原子读写的 NOSQL 场景中，并不适合数据库系统。现在的分布式系统具有更多特性比如扩
展性、可用性等等，在进行系统设计和开发时，我们不应该仅仅局限在 CAP 问题上。

**注意：不是所谓的 3 选 2 （不要被网上大多数文章误导了）**

现实生活中，大部分人解释这一定律时，常常简单的表述为：“一致性、可用性、分区容忍性三者你只
能同时达到其中两个，不可能同时达到”。实际上这是一个非常具有误导性质的说法，而且在 CAP 理论诞
生 12 年之后，CAP 之父也在 2012 年重写了之前的论文。

**当发生网络分区的时候，如果我们要继续服务，那么强一致性和可用性只能 2 选 1 。也就是说当网络分区
之后 P 是前提，决定了 P 之后才有 C 和 A 的选择。也就是说分区容错性（Partition tolerance）我们是必
须要实现的。**

###### CAP 定理的证明


关于 CAP 这三个特性我们就介绍完了，接下来我们试着证明一下 **为什么 CAP 不能同时满足** 。

为了简化证明的过程，我们假设整个集群里只有两个 N 1 和 N 2 两个节点，如下图：

N 1 和 N 2 当中各自有一个应用程序 AB 和数据库，当系统满足一致性的时候，我们认为 N 1 和 N 2 数据库中
的数据保持一致。在满足可用性的时候，我们认为无论用户访问 N 1 还是 N 2，都可以获得正确的结果，
在满足分区容错性的时候，我们认为无论 N 1 还是 N 2 宕机或者是两者的通信中断，都不影响系统的运
行。

我们假设一种极端情况，假设某个时刻 N 1 和 N 2 之间的网络通信突然中断了。如果系统 **满足分区容错
性** ，那么显然可以支持这种异常。问题是在此前提下，一致性和可用性是否可以做到不受影响呢？

我们做个假象实验，如下图，突然某一时刻 N 1 和 N 2 之间的关联断开：

有用户向 N 1 发送了请求更改了数据，将数据库从 V 0 更新成了 V 1。由于网络断开，所以 N 2 数据库依然是
V 0，如果这个时候有一个请求发给了 N 2，但是 N 2 并没有办法可以直接给出最新的结果 V 1，这个时候该
怎么办呢？

这个时候无法两种方法， **一种是将错就错，将错误的 V 0 数据返回给用户。第二种是阻塞等待，等待网络
通信恢复，N 2 中的数据更新之后再返回给用户** 。显然前者牺牲了一致性，后者牺牲了可用性。

这个例子虽然简单，但是说明的内容却很重要。在分布式系统当中，CAP 三个特性我们是无法同时满足
的，必然要舍弃一个。三者舍弃一个，显然排列组合一共有三种可能。

###### BASE 理论

BASE 理论由 eBay 架构师 Dan Pritchett 提出，在 2008 年上被分表为论文，并且 eBay 给出了他们在实践
中总结的基于 BASE 理论的一套新的分布式事务解决方案。


**BASE** 是 **Basically Available（基本可用）** 、 **Soft-state（软状态）** 和 **Eventually Consistent（最
终一致性）** 三个短语的缩写。BASE 理论是对 CAP 中一致性和可用性权衡的结果，其来源于对大规模互
联网系统分布式实践的总结，是基于 CAP 定理逐步演化而来的，它大大降低了我们对系统的要求。

**BASE 理论的核心思想**

即使无法做到强一致性，但每个应用都可以根据自身业务特点，采用适当的方式来使系统达到最终一致
性。也就是牺牲数据的一致性来满足系统的高可用性，系统中一部分数据不可用或者不一致时，仍需要
保持系统整体“主要可用”。

针对数据库领域，BASE 思想的主要实现是对业务数据进行拆分，让不同的数据分布在不同的机器上，
以提升系统的可用性，当前主要有以下两种做法：

```
按功能划分数据库
分片（如开源的Mycat、Amoeba等）。
```
由于拆分后会涉及分布式事务问题，所以 eBay 在该 BASE 论文中提到了如何用最终一致性的思路来实现
高性能的分布式事务。

**BASE 理论三要素**

**1. 基本可用**

基本可用是指分布式系统在出现不可预知故障的时候，允许损失部分可用性。但是，这绝不等价于系统
不可用。

比如：

```
响应时间上的损失 ：正常情况下，一个在线搜索引擎需要在0.5秒之内返回给用户相应的查询结
果，但由于出现故障，查询结果的响应时间增加了1~2秒
系统功能上的损失 ：正常情况下，在一个电子商务网站上进行购物的时候，消费者几乎能够顺利完
成每一笔订单，但是在一些节日大促购物高峰的时候，由于消费者的购物行为激增，为了保护购物
系统的稳定性，部分消费者可能会被引导到一个降级页面
```

**2. 软状态**

软状态指允许系统中的数据存在中间状态，并认为该中间状态的存在不会影响系统的整体可用性，即允
许系统在不同节点的数据副本之间进行数据同步的过程存在延时

**3. 最终一致性**

最终一致性强调的是系统中所有的数据副本，在经过一段时间的同步后，最终能够达到一个一致的状
态。因此，最终一致性的本质是需要系统保证最终数据能够达到一致，而不需要实时保证系统数据的强
一致性。

#### 负载均衡的算法与实现

###### 1. 轮询（Round Robin）

轮询算法把每个请求轮流发送到每个服务器上。下图中，一共有 6 个客户端产生了 6 个请求，这 6 个请
求按 (1, 2, 3, 4, 5, 6) 的顺序发送。最后，(1, 3, 5) 的请求会被发送到服务器 1 ，(2, 4, 6) 的请求会被发送
到服务器 2 。

.

该算法比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务
器可能无法承担多大的负载。下图中，服务器 2 的性能比服务器 1 差，那么服务器 2 可能无法承担多大
的负载。


.

###### 1. 加权轮询（Weighted Round Robbin）

加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值。例如下图中，服务器
1 被赋予的权值为 5 ，服务器 2 被赋予的权值为 1 ，那么 (1, 2, 3, 4, 5) 请求会被发送到服务器 1 ，(6) 请
求会被发送到服务器 2 。

.

1.3 最少连接（least Connections）

由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数多
大，而另一台服务器的连接多小，造成负载不均衡。例如下图中，(1, 3, 5) 请求会被发送到服务器 1 ，
但是 (1, 3) 很快就断开连接，此时只有 (5) 请求连接服务器 1 ；(2, 4, 6) 请求被发送到服务器 2 ，它们的
连接都还没有断开，继续运行时，服务器 2 会承担多大的负载。


.

最少连接算法就是将请求发送给当前最少连接数的服务器上。例如下图中，服务器 1 当前连接数最小，
那么请求 6 就会被发送到服务器 1 上。

.

###### 1.4 加权最小连接（Weighted Least Connection）

在最小连接的基础上，根据服务器的性能为每台服务器分配权重，然后根据权重计算出每台服务器能处
理的连接数。


.

###### 1.5 随机算法（Random）

把请求随机发送到服务器上。和轮询算法类似，该算法比较适合服务器性能差不多的场景。

.

###### 2. 实现

###### 2.1 DNS 解析

使用 DNS 作为负载均衡器，会根据负载情况返回不同服务器的 IP 地址。大型网站基本使用了这种方式
最为第一级负载均衡手段，然后在内部在第二级负载均衡。


.

###### 2.2 修改 MAC 地址

使用 LVS（Linux Virtual Server）这种链路层负载均衡器，根据负载情况修改请求的 MAC 地址。


.

###### 2.3 修改 IP 地址

在网络层修改请求的目的 IP 地址。


.

###### 2.4 HTTP 重定向

HTTP 重定向负载均衡服务器收到 HTTP 请求之后会返回服务器的地址，并将该地址写入 HTTP 重定向
响应中返回给浏览器，浏览器收到后再次发送请求。


.

###### 2.5 反向代理

正向代理：发生在客户端，是由用户主动发起的。比如翻墙，客户端通过主动访问代理服务器，让代理
服务器获得需要的外网数据，然后转发回客户端。

反向代理：发生在服务器端，用户不知道发生了代理。


.

#### 分布式锁

Java 提供了两种内置的锁的实现，一种是由 JVM 实现的 synchronized 和 JDK 提供的 Lock，当你的应
用是单机或者说单进程应用时，可以使用 synchronized 或 Lock 来实现锁。当应用涉及到多机、多进
程共同完成时，那么这时候就需要一个全局锁来实现多个进程之间的同步。

```
1. 使用场景
```
例如一个应用有手机 APP 端和 Web 端，如果在两个客户端同时进行一项操作时，那么就会导致这项操
作重复进行。

```
2. 实现方式
```
###### 数据库分布式锁

基于 MySQL 锁表

该实现方式完全依靠数据库唯一索引来实现。当想要获得锁时，就向数据库中插入一条记录，释放锁时
就删除这条记录。如果记录具有唯一索引，就不会同时插入同一条记录。这种方式存在以下几个问题：

锁没有失效时间，解锁失败会导致死锁，其他线程无法再获得锁。

只能是非阻塞锁，插入失败直接就报错了，无法重试。

不可重入，同一线程在没有释放锁之前无法再获得锁。

采用乐观锁增加版本号

根据版本号来判断更新之前有没有其他线程更新过，如果被更新过，则获取锁失败。


###### Redis 分布式锁

基于 SETNX、EXPIRE

使用 SETNX（set if not exist）命令插入一个键值对时，如果 Key 已经存在，那么会返回 False，否则
插入成功并返回 True。因此客户端在尝试获得锁时，先使用 SETNX 向 Redis 中插入一个记录，如果返
回 True 表示获得锁，返回 False 表示已经有客户端占用锁。

EXPIRE 可以为一个键值对设置一个过期时间，从而避免了死锁的发生。

RedLock 算法

ReadLock 算法使用了多个 Redis 实例来实现分布式锁，这是为了保证在发生单点故障时还可用。

尝试从 N 个相互独立 Redis 实例获取锁，如果一个实例不可用，应该尽快尝试下一个。

计算获取锁消耗的时间，只有当这个时间小于锁的过期时间，并且从大多数（N/2+1）实例上获取了
锁，那么就认为锁获取成功了。

如果锁获取失败，会到每个实例上释放锁。

###### Zookeeper 分布式锁

Zookeeper 是一个为分布式应用提供一致性服务的软件，例如配置管理、分布式协同以及命名的中心化
等，这些都是分布式系统中非常底层而且是必不可少的基本功能，但是如果自己实现这些功能而且要达
到高吞吐、低延迟同时还要保持一致性和可用性，实际上非常困难。

抽象模型

Zookeeper 提供了一种树形结构级的命名空间，/app 1/p_1 节点表示它的父节点为 /app 1。

.

节点类型

永久节点：不会因为会话结束或者超时而消失；

临时节点：如果会话结束或者超时就会消失；

有序节点：会在节点名的后面加一个数字后缀，并且是有序的，例如生成的有序节点为 /lock/node-
0000000000 ，它的下一个有序节点则为 /lock/node-0000000001，依次类推。


监听器

为一个节点注册监听器，在节点状态发生改变时，会给客户端发送消息。

分布式锁实现

创建一个锁目录 /lock。

在 /lock 下创建临时的且有序的子节点，第一个客户端对应的子节点为 /lock/lock-0000000000，第二
个为 /lock/lock-0000000001，以此类推。

客户端获取 /lock 下的子节点列表，判断自己创建的子节点是否为当前子节点列表中序号最小的子节
点，如果是则认为获得锁，否则监听自己的前一个子节点，获得子节点的变更通知后重复此步骤直至获
得锁；

执行业务代码，完成后，删除对应的子节点。

会话超时

如果一个已经获得锁的会话超时了，因为创建的是临时节点，因此该会话对应的临时节点会被删除，其
它会话就可以获得锁了。可以看到，Zookeeper 分布式锁不会出现数据库分布式锁的死锁问题。

羊群效应

在步骤二，一个节点未获得锁，需要监听监听自己的前一个子节点，这是因为如果监听所有的子节点，
那么任意一个子节点状态改变，其它所有子节点都会收到通知，而我们只希望它的下一个子节点收到通
知。

#### 分布式 Session

如果不做任何处理的话，用户将出现频繁登录的现象，比如集群中存在 A、B 两台服务器，用户在第一
次访问网站时，Nginx 通过其负载均衡机制将用户请求转发到 A 服务器，这时 A 服务器就会给用户创建
一个 Session。当用户第二次发送请求时，Nginx 将其负载均衡到 B 服务器，而这时候 B 服务器并不存
在 Session，所以就会将用户踢到登录页面。这将大大降低用户体验度，导致用户的流失，这种情况是
项目绝不应该出现的。

###### 1 粘性 Session

原理

粘性 Session 是指将用户锁定到某一个服务器上，比如上面说的例子，用户第一次请求时，负载均衡器
将用户的请求转发到了 A 服务器上，如果负载均衡器设置了粘性 Session 的话，那么用户以后的每次请
求都会转发到 A 服务器上，相当于把用户和 A 服务器粘到了一块，这就是粘性 Session 机制。

优点

简单，不需要对 Session 做任何处理。

缺点

缺乏容错性，如果当前访问的服务器发生故障，用户被转移到第二个服务器上时，他的 Session 信息都
将失效。

适用场景

发生故障对客户产生的影响较小；

服务器发生故障是低概率事件。

###### 2 服务器 Session 复制


原理

任何一个服务器上的 Session 发生改变，该节点会把这个 Session 的所有内容序列化，然后广播给所有
其它节点，不管其他服务器需不需要 Session，以此来保证 Session 同步。

优点

可容错，各个服务器间 Session 能够实时响应。

缺点

会对网络负荷造成一定压力，如果 Session 量大的话可能会造成网络堵塞，拖慢服务器性能。

实现方式

设置 Tomcat 的 server. xml 开启 tomcat 集群功能。

在应用里增加信息：通知应用当前处于集群环境中，支持分布式，即在 web. xml 中添加选项。

###### 3 Session 共享机制

使用分布式缓存方案比如 Memcached、Redis，但是要求 Memcached 或 Redis 必须是集群。

使用 Session 共享也分两种机制，两种情况如下：

3.1 粘性 Session 共享机制

和粘性 Session 一样，一个用户的 Session 会绑定到一个 Tomcat 上。Memcached 只是起到备份作
用。

.

3.2 非粘性 Session 共享机制

原理

Tomcat 本身不存储 Session，而是存入 Memcached 中。Memcached 集群构建主从复制架构。


.

优点

可容错，Session 实时响应。

实现方式

用开源的 msm 插件解决 Tomcat 之间的 Session 共享：Memcached_Session_Manager（MSM）

###### 4 Session 持久化到数据库

原理

拿出一个数据库，专门用来存储 Session 信息。保证 Session 的持久化。

优点

服务器出现问题，Session 不会丢失

缺点

如果网站的访问量很大，把 Session 存储到数据库中，会对数据库造成很大压力，还需要增加额外的开
销维护数据库。

###### 5 Terracotta 实现 Session 复制

原理

Terracotta 的基本原理是对于集群间共享的数据，当在一个节点发生变化的时候，Terracotta 只把变化
的部分发送给 Terracotta 服务器，然后由服务器把它转发给真正需要这个数据的节点。它是服务器
Session 复制的优化。


.

优点

这样对网络的压力就非常小，各个节点也不必浪费 CPU 时间和内存进行大量的序列化操作。把这种集
群间数据共享的机制应用在 Session 同步上，既避免了对数据库的依赖，又能达到负载均衡和灾难恢复
的效果。

#### 分库与分表

分库与分表带来的分布式困境与应对之策

.

```
1. 事务问题
```

使用分布式事务。

```
2. 查询问题
```
使用汇总表。

```
3. ID 唯一性
```
使用全局唯一 ID：GUID；

为每个分片指定一个 ID 范围

#### 聊聊：你怎么防止优惠券有人重复刷？ ( 字节面试题)

对于重复请求，要考虑 **接口幂等** 和 **接口防重** 。

防刷的话，可以限流以及加入黑名单处理。

```
为了防止某个用户请求优惠券过于频繁，我们可以对同一用户限流。
为了防止黄牛等模拟几个用户请求，我们可以对某个IP进行限流。
为了防止有人使用代理，每次请求都更换IP请求，我们可以对接口进行限流。
```
#### 10 WQPS 高并发架构的 10 个思想

记得很久之前，去面试过 **字节跳动** 。

被三面的面试官问了一道场景设计题目： **如何设计一个高并发系统** 。

如何设计一个高并发系统，是非常常见的面试题，大家一定要从思想上，对高并发系统的架构和设计，
有深入的理解和总结。

接下来，所以整理了设计高并发系统的 10 个锦囊，相信大家看完，对如何架构高并发系统，会有大大帮
助的。

###### 如何理解高并发系统

所谓设计 **高并发** 系统，首先保证它 **整体可用** 的同时，然后，能够承受 **很大的流量冲击** 。

要设计高并发的系统，要识别系统的各种瓶颈，如 **内存不足、磁盘空间不足，连接数不够，网络宽带不
够** 等等，以应对突发的流量洪峰。

###### 1. 业务分治思想+微服务拆分

业务分治思想，就是从业务的维度，分而治之，横向扩展

设计一个高并发系统，我们可以 **分而治之，横向扩展** 。

不同的业务，流量的规模不一样，需要分开应对。

也就是说，高频业务，需要更多的部署多台服务器，把流量分流开，让每个服务器都承担一部分的并发
和流量，提升 **整体系统的并发能力** 。

业务分治思想之后，就可以进行业务的分开建模，


对应在模块设计、模块架构的维度，可以做 **微服务拆分** ，这样就可以达到分摊请求流量的目的，提高了
并发能力。

所谓的 **微服务拆分** ，其实就是把一个单体的应用，按功能单一性，拆分为多个服务模块。

**比如一个电商系统，拆分为用户系统、订单系统、商品系统等等** 。

###### 2. 数据分治思想+分库分表

当业务量暴增的话，MySQL 单机 **磁盘容量会撑爆** 。

并且，我们知道数据库连接数是有限的。

**在高并发的场景下** ，大量请求访问数据库，MySQL 单机是扛不住的！

高并发场景下，会出现 too many connections 报错。

所以高并发的系统， **需要考虑拆分为多个数据库，来抗住高并发的毒打** 。

而假如你的单表数据量非常大，存储和查询的性能就会遇到瓶颈了，如果你做了很多优化之后还是无法
提升效率的时候，就需要考虑做 **分表** 了。

一般千万级别数据量，就需要 **分表** ，每个表的数据量少一点，提升 SQL 查询性能。

当面试官问要求你设计一个高并发系统的时候，一般都要说到 **分库分表** 这个点。

###### 3. 读写分离思想+主从分离

通常来说，一台单机的 MySQL 服务器，可以支持 500 左右的 TPS 和 10000 左右的 QPS，即单机支撑的
**请求访问是有限** 的。

因此你做了分布式部署，部署了多台机器，部署了主数据库、从数据库。

但是，如果双十一搞活动，流量肯定会猛增的。

如果所有的查询请求，都走主库的话，主库肯定扛不住，因为查询请求量是非常非常大的。

因此一般都要求做 **主从分离** ，然后实时性要求不高的读请求，都去读从库， **写的请求或者实时性要求高
的请求，才走主库** 。

这样就很好保护了主库，也提高了系统的吞吐。

当然，如果回答了主从分离，面试官可能扩展开问你 **主从复制原理，问你主从延迟问题** 等等，这块大家
需要 **全方位复习好** 哈。


###### 4. 池化思想

在高并发的场景下， **数据库连接数** 可能成为瓶颈，因为连接数是有限的。

我们的请求调用数据库时，都会先获取数据库的连接，然后依靠这个连接来查询数据，搞完收工，最后
关闭连接，释放资源。

如果我们不用数据库连接池的话，每次执行 SQL，都要创建连接和销毁连接，这就会导致每个查询请求
都变得更慢了，相应的，系统处理用户请求的能力就降低了。

因此，需要使用池化技术，即 **数据库连接池、HTTP 连接池、Redis 连接池** 等等。

使用数据库连接池，可以避免每次查询都新建连接，减少不必要的资源开销，通过复用连接池， **提高系
统处理高并发请求的能力** 。

同理，我们使用线程池，也能 **让任务并行处理，更高效地完成任务** 。

###### 5. 缓存思想

缓存思想是高并发的一大核心架构方案，

无论是各种中间件内部，还是在 cpu 的内部，还是操作系统内部、在 web 应用、客户端浏览器的架构设
计过程中，广泛的使用缓存思想和模式。

除了一级缓存，甚至有二级、三级缓存、多级缓存架构。

我们使用缓存，主要是提升系统接口的性能，这样高并发场景，你的系统就可以支持更多的用户同时访
问。

web 应用中，常用的缓存包括：Redis 缓存，JVM 本地缓存，nginx 本地缓存，memcached、CDN 静态
资源加速等等。

就拿 Redis 来说，它单机就能轻轻松松应对几万的并发，你读场景的业务，可以用缓存来抗高并发。

缓存虽然用得爽，但是要 **注意缓存使用的一些问题** ：

```
缓存与数据库的一致性问题
缓存雪崩
缓存穿透
缓存击穿
```
然后拿 CDN 来说，也属于缓存思想的一种应用，将静态资源，缓存到离用于最近的 CDN 机房，加速静
态资源访问

商品图片，icon 等等静态资源，可以对页面做 **静态化处理，减少访问服务端的请求** 。

如果用户分布在全国各地，有的在上海，有的在深圳，地域相差很远，网速也各不相同。

为了让用户最快访问到页面，可以使用 CDN。

```
CDN可以让用户就近获取所需内容。
```
什么是 CDN？

```
Content Delivery Network/Content Distribution Network,翻译过来就是内容分发网络，它表示
将静态资源分发到位于多个地理位置机房的服务器，可以做到数据就近访问，加速了静态资源的
访问速度，因此让系统更好处理正常别的动态请求。
```

###### 6. 异步思想+消息队列削锋

回忆一下什么是同步，什么是异步呢？

以 **方法调用** 为例，它代表 **调用方要阻塞等待被调用方法中的逻辑执行完成** 。

这种方式下，当被调用方法响应时间较长时，会造成调用方长久的阻塞，在高并发下会造成整体系统性
能下降甚至发生雪崩。

异步调用恰恰相反，调用方不需要等待方法逻辑执行完成就可以返回执行其他的逻辑，在被调用方法执
行完毕后再通过回调、事件通知等方式将结果反馈给调用方。

因此，设计一个高并发的系统， **需要在恰当的场景使用异步** 。

如何使用异步呢？

后端可以借用消息队列实现。

比如在海量秒杀请求过来时，先放到消息队列中，快速响应用户，告诉用户请求正在处理中，这样就可
以释放资源来处理更多的请求。

秒杀请求处理完后，通知用户秒杀抢购成功或者失败。

我们搞一些双十一、双十二等运营活动时，需要 **避免流量暴涨，打垮应用系统的风险** 。

因此一般会引入消息队列，来应对 **高并发的场景** 。

假设你的应用系统每秒最多可以处理 2 k 个请求，每秒却有 5 k 的请求过来，可以引入消息队列，应用系
统每秒从消息队列拉 2 k 请求处理得了。

有些伙伴担心这样可能会出现 **消息积压** 的问题：

```
首先，搞一些运营活动，不会每时每刻都那么多请求过来你的系统（ 除非有人恶意攻击 ），高峰期
过去后，积压的请求可以慢慢处理；
其次，如果消息队列长度超过最大数量，可以直接抛弃用户请求或跳转到错误页面；
```
###### 7. 熔断思想

**熔断降级** 是保护系统的一种手段。

当前互联网系统一般都是分布式部署的。

而分布式系统中偶尔会出现某个基础服务不可用，最终导致整个系统不可用的情况, 这种现象被称为 **服
务雪崩效应** 。

比如分布式调用链路 A->B->C....，下图所示：


如果服务 C 出现问题，比如是因为慢 SQL 导致调用缓慢，那将导致 B 也会延迟，从而 A 也会延迟。

堵住的 A 请求会消耗占用系统的线程、IO、CPU 等资源。

当请求 A 的服务越来越多，占用计算机的资源也越来越多，最终会导致系统瓶颈出现，造成其他的请求
同样不可用，最后导致业务系统崩溃。

为了应对服务雪崩, 常见的做法是 **熔断和降级** 。

最简单是加开关控制，当下游系统出问题时，开关打开降级，不再调用下游系统。还可以选用开源组件
Hystrix 来支持。

你要保证设计的系统能应对 **高并发场景** ，那肯定要考虑 **熔断降级** 逻辑进来。

###### 8. 限流思想

限流也是我们应对高并发的一种方案。

我们当然希望，在高并发大流量过来时，系统能全部请求都正常处理。

但是有时候没办法，系统的 CPU、网络带宽、内存、线程等资源都是有限的。因此，我们要考虑限流。

如果你的系统每秒扛住的请求是一千， **如果一秒钟来了十万请求呢** ？

换个角度就是说，高并发的时候，流量洪峰来了，超过系统的承载能力，怎么办呢？

这时候，我们可以采取限流方案。就是为了保护系统，多余的请求，直接丢弃。

**什么是限流** ：

在计算机网络中，限流就是控制网络接口发送或接收请求的速率，它可防止 DoS 攻击和限制 Web 爬虫。

限流，也称流量控制。

是指系统在面临高并发，或者大流量请求的情况下，限制新的请求对系统的访问，从而保证系统的稳定
性。

可以使用 Guava 的 RateLimiter 单机版限流，也可以使用 Redis 分布式限流，还可以使用阿里开源组
件 sentinel 限流。

面试的时候，你说到限流这块的话？


面试官很大概率会问你限流的算法，因此，大家在准备面试的时候，需要复习一下这几种经典的限流算
法哈

###### 9. 扩容思想+切流量

如果是突发的流量高峰，除了降级、限流保证系统不跨，我们可以采用这两种方案，保证系统尽可能服
务用户请求：

```
扩容： 比如增加从库、提升配置的方式 ，提升系统/组件的流量承载能力。
比如增加MySQL、Redis从库来处理查询请求。
切流量： 服务多机房部署 ，如果高并发流量来了，把流量从一个机房切换到另一个机房。
```
###### 10. 海量数据处理思想 ElasticSearch+Hbase

```
Elasticsearch，大家都使用得比较多了吧， 一般搜索功能都会用到它 。
```
它是一个分布式、高扩展、高实时的搜索与数据分析引擎，简称为 ES。

我们在聊高并发，为啥聊到 ES 呢？

因为 ES 可以扩容方便，天然支撑高并发。

**当数据量大的时候，不用动不动就加机器扩容，分库等等** ，可以考虑用 ES 来支持简单的查询搜索、统
计类的操作。



以上内容，来自《java 高并发核心编程卷 1 加强版》

###### 前提：压力测试确定系统瓶颈

设计高并发系统，离不开最重要的一环， **就是压力测试** 。

就是在系统上线前，需要对系统进行压力测试，测清楚你的系统支撑的最大并发是多少，确定系统的瓶
颈点，让自己心里有底，最好预防措施。

压测完要分析整个调用链路，性能可能出现问题是网络层（如带宽）、Nginx 层、服务层、还是数据路
缓存等中间件等等。

```
loadrunner是一款不错的压力测试工具，jmeter则是接口性能测试工具，都可以来做下压测。
```
###### 附： 接口的常规优化的 18 个方案

设计一个高并发的系统，需要设计接口的性能足够好，这样系统在相同时间，就可以处理更多的请求。

当说到这里的话，可以跟面试官说说接口优化的一些方案了。


#### 字节二面真题：100 Wqps 短链系统，怎么设计？

前段时间，社群小伙伴，在交流一个字节的二面真题：

100 Wqps 短链系统，怎么设计？

这道题，非常优质。业务简单，但是覆盖的知识点非常多：

```
高并发、高性能分布式 ID
Redis Bloom Filter 高并发、低内存损耗的 过滤组件知识
分库、分表海量数据存储
多级缓存的知识
HTTP传输知识
二进制、十六进制、六十二进制知识
```
总体来说，高并发、高性能系统的核心领域，都覆盖了。所以，尼恩分析下来，得到一个结论：是一个
超级好的问题。

现在把这个题目，以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 35 版，供后面的小伙伴参考，提
升大家的 3 高架构、设计、开发水平。

###### 1 、短 URL 系统的背景：


短网址替代长 URL，在互联网网上传播和引用。

例如 QQ 微博的 url. cn，新郎的 sinaurl. cn 等。

在 QQ、微博上发布网址的时候，会自动判别网址，并将其转换，例如：http://url.cn/2hytQx

为什么要这样做的，无外乎几点：

```
1. 缩短地址长度，留足更多空间的给 有意义的内容
URL是没有意义的，有的原始URL很长，占用有效的屏幕空间。
微博限制字数为 140 字一条，那么如果这个连接非常的长，以至于将近要占用我们内容的一半篇
幅，这肯定是不能被允许的，链接变短，对于有长度限制的平台发文，可编辑的文字就变多了，
所以短网址应运而生了。
2. 可以很好的对原始URL内容管控。
有一部分网址可以会涵盖XX，暴力，广告等信息，这样我们可以通过用户的举报，完全管理这个
连接将不出现在我们的应用中，应为同样的URL通过加密算法之后，得到的地址是一样的。
3. 可以很好的对原始URL进行行为分析
我们可以对一系列的网址进行流量，点击等统计，挖掘出大多数用户的关注点，这样有利于我们对
项目的后续工作更好的作出决策。
4. 短网址和短ID相当于间接提高了带宽的利用率、节约成本
5. 链接太长在有些平台上无法自动识别为超链接
6. 短链接更加简洁好看且安全，不暴露访问参数。而且，能规避关键词、域名屏蔽等手段
```
###### 2 、短 URL 系统的原理：

短 URL 系统的核心： **将长的 URL 转化成短的 URL** 。

客户端在访问系统时，短 URL 的工作流程如下：

```
先使用短地址A访问 短链Java 服务
短链Java 服务 进行 地址转换和映射，将 短URL系统映射到对应的长地址URL
短链Java 服务 返回 302 重定向 给客户端
然后客户端再重定向到原始服务
```
如下图所示：


那么，原始 URL 如何变短呢？简单来说，可以将原始的地址，使用编号进行替代

编号如何进一步变短呢？ 可以使用更大的进制来表示

**六十二进制表示法**

顾名思义短网址就是非常短的网址，比如http://xxx.cn/EYyCO9T，其中核心的部分 EYyCO 9 T 只有 7 位
长度。

其实这里的 7 位长度是使用 62 进制来表示的，就是常用的 0-9、a-z、A-Z，也就是 10 个数字+26 个小写
+26 个大写=62 位。

那么 7 位长度 62 进制可以表示多大范围呢?

至于短网址的长度，可以根据自己需要来调整，如果需要更多，可以增加位数，

即使 6 位长度 62^6 也能达到 568 亿的范围，

这样的话只要算法得当，可以覆盖很大的数据范围。

```
62 ^7 = 3 , 521 , 614 , 606 , 208 (合计 3. 5 万亿)，
```
```
说明：
```
```
10 进制 最大只能生成 10 ^ 6 - 1 = 999999 个
16 进制 最大只能生成 16 ^ 6 - 1 = 16777215 个
16 进制里面已经包含了 A B C D E F 这几个字母
62 进制 最大竟能生成 62 ^ 6 - 1 = 56800235583 个 基本上够了。
A-Z a-z 0 - 9 刚好等于 62 位
```
```
注意：
```
```
int( 4 个字节) ，存储的范围是- 21 亿到 21 亿
long( 8 个字节)，存储的范围是- 900 万万亿 到 900 万万亿
```

在编码的过程中，可以按照自己的需求来调整 62 进制各位代表的含义。

一个典型的场景是，在编码的过程中，如果不想让人明确知道转换前是什么，可以进行弱加密，

比如 A 站点将字母 c 表示 32 、B 站点将字母 c 表示 60 ，就相当于密码本了。

**128 进制表示法**

标准 ASCII 码也叫基础 ASCII 码，使用 7 位二进制数（剩下的 1 位二进制为 0 ）, 包含 128 个字符，

看到这里你或许会说，使用 128 进制 (如果有的话) 岂不是网址更短，

是的，

7 位二进制数（剩下的 1 位二进制为 0 ）表示所有的大写和小写字母，数字 0 到 9 、标点符号，以及在美
式英语中使用的特殊控制字符 [1] 。

###### 3 、短 URL 系统的功能分析：

假设短地址长度为 8 位， 62 的 8 次方足够一般系统使用了

**系统核心实现，包含三个大的功能：**

```
发号
存储
映射
```
可以分为两个模块：发号与存储模块、映射模块

**发号与存储模块**

```
发号：使用发号器发号 ， 为每个长地址分配一个号码ID，并且需要防止地址二义，也就是防止同
一个长址多次请求得到的短址不一样
存储：将号码与长地址存放在DB中，将号码转化成 62 进制，用于表示最终的短地址，并返回给用
户
```
**映射模块**

用户使用 62 进制的短地址请求服务，

```
转换：将 62 进制的数转化成 10 进制，因为咱们系统内部是long 类型的 10 进制的数字ID
映射：在DB中寻找对应的长地址
通过 302 重定向，将用户请求重定向到对应的地址上
```
```
注意：
```
```
128 个进制就可能会出现大量的不常用字符
```
```
比如 # % & * 这些，
```
```
这样的话，对于短链接而言，通用性和记忆性就变差了，
```
```
所以， 62 进制是个权衡折中。
```

###### 4 、发号器的高并发架构：

回顾一下发号器的功能：

```
为每个长地址分配一个号码ID
并且需要防止地址歧义
```
以下对目前流行的分布式 ID 方案做简单介绍

**方案 1 ：使用地址的 hash 编码作为 ID**

可以通过原始 Url 的 hash 编码，得到一个整数，作为短链的 ID

哈希算法简单来说就是将一个元素映射成另一个元素，

哈希算法可以简单分类两类，

```
加密哈希，如MD5，SHA256等，
非加密哈希，如MurMurHash，CRC32，DJB等。
```
**MD 5 算法**

MD 5 消息摘要算法（MD 5 Message-Digest Algorithm），一种被广泛使用的密码散列函数，

可以产生出一个 128 位（ 16 字节）的散列值（hash value），

MD 5 算法将数据（如一段文字）运算变为另一固定长度值，是散列算法的基础原理。

由美国密码学家 Ronald Linn Rivest 设计，于 1992 年公开并在 RFC 1321 中被加以规范。

**CRC 算法**

循环冗余校验（Cyclic Redundancy Check）是一种根据网络数据包或电脑文件等数据，

产生简短固定位数校验码的一种散列函数，由 W. Wesley Peterson 于 1961 年发表。

生成的数字在传输或者存储之前计算出来并且附加到数据后面，然后接收方进行检验确定数据是否发生
变化。

由于本函数易于用二进制的电脑硬件使用、容易进行数学分析并且尤其善于检测传输通道干扰引起的错
误，因此获得广泛应用。

**MurmurHash**

MurmurHash 是一种非加密型哈希函数，适用于一般的哈希检索操作。

由 Austin Appleby 在 2008 年发明，并出现了多个变种，与其它流行的哈希函数相比，对于规律性较强
的键，MurmurHash 的随机分布特征表现更良好。

这个算法已经被很多开源项目使用，比如 libstdc++ (4.6 版)、Perl、nginx (不早于 1.0.1 版)、Rubinius、
libmemcached、maatkit、Hadoop、Redis，Memcached，Cassandra，HBase，Lucene 等。

MurmurHash 计算可以是 128 位、 64 位、 32 位，位数越多，碰撞概率越少。

所以，可以把长链做 MurmurHash 计算，可以得到的一个整数哈希值，

所得到的短链，类似于下面的形式

如何缩短域名？ 传输的时候，可以把 MurmurHash 之后的数字为 10 进制，可以把数字转成 62 进制

```
固定短链域名+哈希值 = http://www.weibo.com/888888888
```

**那么，使用地址的 hash 编码作为 ID 的问题是啥呢？**

会出现碰撞，所以这种方案不适合。

**方案 2 ：数据库自增长 ID**

属于完全依赖数据源的方式，所有的 ID 存储在数据库里，是最常用的 ID 生成办法，在单体应用时期得到
了最广泛的使用，建立数据表时利用数据库自带的 auto_increment 作主键，或是使用序列完成其他场
景的一些自增长 ID 的需求。

但是这种方式存在在高并发情况下性能问题，要解决该问题，可以通过批量发号来解决，

提前为每台机器发放一个 ID 区间 [low, high]，然后由机器在自己内存中使用 AtomicLong 原子类去保证
自增，减少对 DB 的依赖，

每台机器，等到自己的区间即将满了，再向 DB 请求下一个区段的号码，

为了实现写入的高并发，可以引入队列缓冲+批量写入架构，

等区间满了，再一次性将记录保存到 DB 中，并且异步进行获取和写入操作, 保证服务的持续高并发。

比如可以每次从数据库获取 10000 个号码，然后在内存中进行发放，当剩余的号码不足 1000 时，重新向
MySQL 请求下 10000 个号码，在上一批号码发放完了之后，批量进行写入数据库。

但是这种方案，更适合于单体的 DB 场景，在分布式 DB 场景下，使用 MySQL 的自增主键，会存在不同
DB 库之间的 ID 冲突，又要使用各种办法去解决，

总结一下， MySQL 的自增主键生成 ID 的优缺点和使用场景：

```
优点：
非常简单，有序递增，方便分页和排序。
缺点：
分库分表后，同一数据表的自增ID容易重复，无法直接使用（可以设置步长，但局限性很明
显）；
性能吞吐量整个较低，如果设计一个单独的数据库来实现 分布式应用的数据唯一性，
即使使用预生成方案，也会因为事务锁的问题，高并发场景容易出现单点瓶颈。
适用场景：
单数据库实例的表ID（包含主从同步场景），部分按天计数的流水号等；
分库分表场景、全系统唯一性ID场景不适用。
```
所以，高并发场景， MySQL 的自增主键，很少用。

**方案 3 ：分布式、高性能的中间件生成 ID**

Mysql 不行，可以考虑分布式、高性能的中间件完成。

比如 Redis、MongoDB 的自增主键，或者其他分布式存储的自增主键，但是这就会引入额外的中间组
件。

假如使用 Redis，则通过 Redis 的 INCR/INCRBY 自增原子操作命令，能保证生成的 ID 肯定是唯一有序的，
本质上实现方式与数据库一致。

但是，超高并发场景，分布式自增主键的生产性能，没有本地生产 ID 的性能高。

```
http://www.weibo.com/abcdef
```

总结一下，分布式、高性能的中间件生成 ID 的优缺点和使用场景：

```
优点：
整体吞吐量比数据库要高。
缺点：
Redis实例或集群宕机后，找回最新的ID值有点困难。
适用场景：
比较适合计数场景，如用户访问量，订单流水号（日期+流水号）等。
```
**方案 4 ：UUID、GUID 生成 ID**

**UUID：**

按照 OSF 制定的标准计算，用到了以太网卡地址、纳秒级时间、芯片 ID 码和许多可能的数字。由以下几
部分的组合：当前日期和时间 (UUID 的第一个部分与时间有关，如果你在生成一个 UUID 之后，过几秒又
生成一个 UUID，则第一个部分不同，其余相同)，时钟序列，全局唯一的 IEEE 机器识别号（如果有网
卡，从网卡获得，没有网卡以其他方式获得）

**GUID：**

微软对 UUID 这个标准的实现。UUID 还有其它各种实现，不止 GUID 一种，不一一列举了。

这两种属于不依赖数据源方式，真正的全球唯一性 ID

总结一下，UUID、GUID 生成 ID 的优缺点和使用场景：

```
优点：
不依赖任何数据源，自行计算，没有网络ID，速度超快，并且全球唯一。
缺点：
没有顺序性，并且比较长（128bit），作为数据库主键、索引会导致索引效率下降，空间占用较
多。
适用场景：
只要对存储空间没有苛刻要求的都能够适用，比如各种链路追踪、日志存储等。
```
**方式 5 ：snowflake 算法（雪花算法）生成 ID**

snowflake ID 严格来说，属于本地生产 ID，这点和 Redis ID、MongoDB ID 不同，后者属于远程生产
的 ID。

本地生产 ID 性能高，远程生产的 ID 性能低。

snowflake ID 原理是使用 Long 类型（ 64 位），按照一定的规则进行分段填充：时间（毫秒级）+集群
ID+机器 ID+序列号，每段占用的位数可以根据实际需要分配，其中集群 ID 和机器 ID 这两部分，在实际应
用场景中要依赖外部参数配置或数据库记录。

总结一下，snowflake ID 的优缺点和使用场景：

```
优点：
高性能、低延迟、去中心化、按时间总体有序
缺点：
要求机器时钟同步（到秒级即可），需要解决 时钟回拨问题
如果某台机器的系统时钟回拨，有可能造成 ID 冲突，或者 ID 乱序。
适用场景：
```

```
分布式应用环境的数据主键
```
**高并发 ID 的技术选型**

这里，不用地址的 hash 编码作为 ID

这里，不用数据库的自增长 ID

这里，不用 redis、mongdb 的分布式 ID

最终，

这里，从发号性能、整体有序（B+树索引结构更加友好）的角度出发，最终选择的 snowflake 算法

snowflake 算法的吞吐量在 100 W ops +

但是 snowflake 算法问题是啥呢？需要解决时钟回拨的问题。

如何解决时钟回拨的问题，可以参考推特官方的代码、百度 ID 的代码、Shardingjdbc ID 的源码，综合
存储方案设计解决。

这块内容涉及多个组件的源码，内容繁多，请大家自行去看尼恩关于 100 Wqps 推送中台相关的讲义
和视频。

###### 5 、数据存储的高并发架构：

这个数据，非常的结构化，可以使用结构化数据库 MYSQL 存储。

接下来，开始高并发、海量数据场景，需要进行 MYSQL 存储的分库分表架构。

```
尼恩提示，这里可以说说自己的分库分表 操作经验，操作案例。
```
```
然后进行 互动式作答。
```
```
也就是，首先是进行 输入条件 询问，并且进行确认。
```
然后按照分治模式，进行两大维度的分析架构：

```
数据容量（存储规模） 的 分治架构、
访问流量 （吞吐量规模）的 分治架构。
```
```
结构非常简单，我们会有二列：
```
1. ID，int, // 分布式雪花 id；
2. SURL，varchar, // 原始 URL；


这块内容涉的方案，不同的项目，基本是想通的，

```
具体的方案内容太多，
请大家 自行去看尼恩 关于 100Wqps 推送中台相关的 讲义和视频。
```
###### 6 、二义性检查的高并发架构：

所谓的地址二义性，就行同一个长址多次请求得到的短址不一样。

在生产地址的时候，需要进行二义性检查，防止每次都会重新为该长址生成一个短址，一个个长址多次
请求得到的短址是不一样。

通过二义性检查，实现长短链接真正意义上的一对一。

怎么进行二义性检查？

最简单，最为粗暴的方案是： **直接去数据库中检查** 。

但是，这就需要付出很大的性能代价。

要知道：

数据库主键不是原始 _url_ ，而是短链 _url_ 。


如果根据原始 _url_ 去进行存在性检查，还需要额外建立索引。

问题的关键是，数据库性能特低，没有办法支撑超高并发二义性检查

所以，这里肯定不能每次用数据库去检查。

这里很多同学可能会想到另一种方案，就是 redis 的布隆过滤，把已经生成过了的原始 url，

大致的方案是，可以把已经生成过的原始 url ，在 redis 布隆过滤器中进行记录。

**每次进行二义性检查，走 redis 布隆过滤器。**

布隆过滤器就是 bitset+多次 hash 的架构，宏观上是空间换时间，不对所有的 surl （原始 url）进行内容
存储，只对 surl 进行存在性存储，这样就节省大家大量的内存空间。

在数据量比较大的情况下，既满足时间要求，又满足空间的要求。

布隆过滤器的巨大用处就是，能够迅速判断一个元素是否在一个集合中。

布隆过滤器的常用使用场景如下：

```
1. 黑名单 : 反垃圾邮件，从数十亿个垃圾邮件列表中判断某邮箱是否垃圾邮箱（同理，垃圾短信）
2. URL去重 : 网页爬虫对 URL 的去重，避免爬取相同的 URL 地址
3. 单词拼写检查
4. Key-Value 缓存系统的 Key 校验 (缓存穿透) : 缓存穿透，将所有可能存在的数据缓存放到布隆过滤
器中，当黑客访问不存在的缓存时迅速返回避免缓存及 DB 挂掉。
5. ID 校验，比如订单系统查询某个订单 ID 是否存在，如果不存在就直接返回。
```
Bloom Filter 专门用来解决我们上面所说的去重问题的，使用 Bloom Filter 不会像使用缓存那么浪费空
间。

当然，他也存在一个小小问题，就是不太精确。

**规则是：存在不一定存在，说不存在一定不存在**

Bloom Filter 相当于是一个不太精确的 set 集合，我们可以利用它里边的 contains 方法去判断某一个对
象是否存在，但是需要注意，这个判断不是特别精确。

一般来说，通过 contains 判断某个值不存在，那就一定不存在，但是判断某个值存在的话，则他可能
不存在。


**那么对于 surl，处理的方案是：**

```
如果 redis bloom filter 不存在，直接生成
否则，如果 redis bloom filter 判断为存在，可能是误判，还需要进行db的检查。
```
但是， redis bloom filter 误判的概率很低，合理优化之后，也就在 1%以下。

可能有小伙伴说，如果 100 Wqps，1%也是 10 W 1 ps，DB 还是扛不住，怎么办？

**可以使用缓存架构，甚至多级缓存架构**

具体来说，可以使用 Redis 缓存进行热门 url 的缓存，实现部分地址的一对一缓存

比如将最近/最热门的对应关系存储在 K-V 数据库中，比如在本地缓存 Caffeine 中存储 **最近生成** 的长对短
的对应关系，并采用过期机制实现 LRU 淘汰，从而保证频繁使用的 URL 的总是对应同一个短址的，但
是不保证不频繁使用的 URL 的对应关系，从而大大减少了空间上的消耗。

###### 7 、映射模块（/转换模块）的高并发架构

这里，主要是介绍自己对多级缓存的掌握和了解。

可以使用了缓存，二级缓存、三级缓存，加快 id 到 surl 的转换。

**简单的缓存方案：**

将热门的长链接（需要对长链接进来的次数进行计数）、最近的长链接（可以使用 Redis 保存最近一个
小时的数据）等等进行一个缓存，如果请求的长 URL 命中了缓存，那么直接获取对应的短 URL 进行返
回，不需要再进行生成操作

**复杂的缓存方案：**

```
方案非常复杂
```
```
具体，请参考尼恩的第 26 章视频《100Wqps 三级缓存架构和实操》
```
**补充服务间的重定向 301 和 302 的不同：**

301 永久重定向和 302 临时重定向。

```
301 永久重定向：第一次请求拿到长链接后，下次浏览器再去请求短链的话，不会向短网址服务器
请求了，而是直接从浏览器的缓存里拿，减少对服务器的压力。
302 临时重定向：每次去请求短链都会去请求短网址服务器（除非响应中用 Cache-Control 或
Expired 暗示浏览器进行缓存）
```
使用 301 虽然可以减少服务器的压力，但是无法在 server 层获取到短网址的访问次数了，如果链接刚
好是某个活动的链接，就无法分析此活动的效果以及用于大数据分析了。

而 302 虽然会增加服务器压力，但便于在 server 层统计访问数，所以如果对这些数据有需求，可以采
用 302 ，因为这点代价是值得的，但是具体采用哪种跳转方式，还是要结合实际情况进行选型。


###### 8 、架构的魅力

架构魅力，在于没有最好的方案，只有更好的方案

大家如果有疑问，或者更好的方案，可以多多交流，

此题，后面的答案，也会不断的完善和优化

#### 全链路异步，让你的 SpringCloud 性能优化 10 倍+

###### 背景

随着业务的发展，微服务应用的流量越来越大，使用到的资源也越来越多。

在微服务架构下，大量的应用都是 SpringCloud 分布式架构，这种架构，总体是 **全链路同步模式** 。

同步编程模式不仅造成了资源的极大浪费，并且在流量发生激增波动的时候，受制于系统资源而无法快
速的扩容。

全球后疫情时代，降本增效是大背景。

如何降本增效？

可以通过技术升级， **全链路同步模式** ，升级为 **全链路异步模式** 。

尼恩作为 40 岁资深老架构师，带大家来做一把 **全链路异步模式** 改造，给大家看看研究成果，一定会惊到
大家目瞪口呆。

本文作为全链路异步架构的知识，收录在尼恩《尼恩 Java 面试宝典》的架构专题中

```
注：本文以 PDF 持续更新，最新尼恩 架构笔记、面试题 的PDF文件，请从这里获取：码云
```
###### 全链路同步模式架构图

先回顾一下全链路同步模式架构图

**全链路同步模式** ，如何升级为 **全链路异步模式** ，就是一个一个环节的异步化。

40 岁老架构师尼恩，持续深化自己的 3 高架构知识宇宙，当然首先要去完成一次牛逼的 **全链路异步模式
微服务实操，下面是尼恩的实操过程、效果、压测数据。**

###### 全链路异步模式


**网关纯异步化（提升 9 倍以上）**

网关层的特点：

```
不需要访问业务数据库只做协议转换和流量转发
特点是 IO 密集型，特别适合纯异步的架构，可以极大的节省资源。
```
**如何进行网关异步化？**

使用高性能的通信框架 Netty，这是一个基于 NIO 非阻塞 IO+ Reactor 纯异步线程模型的纯异步化框
架。

网关的技术选型主要有 zuul，SpringCloud GetWay 。

```
zuul 1虽然使用的同步io，zuul2它也是使用异步的netty，但是没有和SpringCloud 框架集成
springcloud getway 它是基于spring 5.0 、spring boot 2.0 和spring reacter，为微服务提供一个
简单有效的网关API路由接口。和SpringCloud 框架完美集成，目标是为了代替zuul
```
SpringCloud GetWay 是基于 webFlux 框架实现的，而 WebFlux 框架底层则使用了高性能的 Reactor 模式
通信框架 Netty。所以最终还是基于 IO 的王者组件 Netty。

**如果大家使用 Zuul 1，那么升级为 SpringCloud GetWay，性能可以提升 9 倍以上，**

**以上结论，是来自于尼恩的读者群（50+），如有疑问，可以来单挑。**

总体来说，这个环节，是纯异步化最容易的。

这个环节，大部分已经升级到了 springcloud getway 已经使用了纯异步的架构；

**Web 服务异步化（2 W 并发场景提升 20 倍以上）**

Web 服务作为微服务体系内的重要组成，服务节点众多，

Springboot 的 Web 服务默认为 Tomcat + Servlet 不支持纯异步化编程，

Tomcat + Servlet 模式的问题：总体上没有使用 Reactor 反应器模式，每一个请求是阻塞处理的，属于
同步 Web 服务类型。

Servlet 有异步的版本，可惜没有用起来。具体请参考 40 岁老架构师尼恩为大家整理的深度文章：

京东一面： 20 种异步，你知道几种？ 含协程

所以：跑在大家生产环境上的，还是 Tomcat + Servlet 同步 Web 服务。

如何实现 Web 服务异步化：

```
方式一：基于 Netty 实现web服务
方式二：使用 WebFlux （还是 Netty 实现web服务）
```
Spring WebFlux 是一个响应式堆栈 Web 框架，它是完全非阻塞的，支持响应式流 (Reactive Stream) 背
压，并在 Netty，Undertow 和 Servlet 3.1 +容器等服务器上运行

我们再来看一下对于 WebFlux 的对比测试数据 （来自于参考文献 1 ）：


可见，非阻塞的处理方式规避了线程排队等待的情况，从而可以用少量而固定的线程处理应对大量请求
的处理。

还有更绝的，小伙伴又一步到位直接测试了一下 20000 用户的情况：

```
1. 对 mvc 的测试由于出现了许多的请求fail，最终以失败告终；
2. 而 WebFlux 应对 20000 用户已然面不改色心不慌，吞吐量达到7228 req/sec
```
**注意：正好是 10000 用户下的两倍，绝对是真实数据！也就是说, 2 W 并发场景提升 20 倍以上**

95%响应时长仅 117 ms。

最后，再给出两个吞吐量和响应时长的图，更加直观地感受异步非阻塞的 WebFlux 是如何一骑绝尘的
吧：


此时，我们更加理解了 Nodejs 的骄傲，不过我们大 Java 语言也有了 Vert. x 和现在的 Spring WebFlux。

**RPC 调用异步化（提升 9 倍以上）**

异步 RPC 调用，等待 upstream 上游 response 返回时，线程不处于 block 状态

作为微服务架构中数据流量最大的一部分，RPC 调用异步化的收益巨大；

RPC 调用主要的框架有：

特点是：

```
feign 是同步IO 、阻塞模式的同步 RPC框架
dubbo 是基于Netty的非阻塞IO + Reactor 反应堆线程模型的 异步RPC框架
```
40 岁老架构师尼恩，完成了 SpringCloud + Dubbo RPC 的集成，在同一个微服务下，同时使用了 Feign
+ Dubbo


然后进行了性能的对比验证

**dubbo 的压测数据**

```
wrk -t8 -c200 -d30s --latency http://cdh1:18081/dubbo-consumer-
demo/user/detail/v1?userId= 1
```
```
[root@centos1 src]# wrk -t8 -c200 -d30s --latency http://cdh1:18081/dubbo-
consumer-demo/user/detail/v1?userId=1
Running 30s test @ http://cdh1:18081/dubbo-consumer-demo/user/detail/v1?userId= 1
 8 threads and 200 connections
Thread Stats Avg Stdev Max +/- Stdev
Latency 30 .10ms 45 .68ms 644 .45ms 95 .43%
Req/Sec 1 .12k 465 .63 2 .36k 66 .87%
Latency Distribution
50 % 18 .94ms
75 % 28 .43ms
90 % 46 .21ms
99 % 283 .56ms
 264316 requests in 30 .07s, 148 .47MB read
Requests/sec: 8788 .96
Transfer/sec: 4 .94MB
```

**feign 的压测数据**

**从数据来看， dubbo rpc 是 feign rpc 性能 10 倍**

**当然，感兴趣的小伙伴，也可以自己实操一下，更有感触。**

**Cache 异步化（提升 2 倍+）**

Cache Aside 缓存模式，是大家通用的 Cache 使用方式，Cache 纯异步的架构，必须使用异步存储层客
户端，

主要有：

```
Redisson
Lettuce
```
Redisson、Lettuce 如何选型？请参考 40 岁老架构师尼恩的文章：

Jedis 那么低性能，还在用？赶紧换上 lettuce 吧

40 岁老架构师尼恩，完成了自己的开发脚手架 Crazy-SpringCloud 的 Cache 异步化，经过对比验证，性
能提升足足 2 倍多

**使用 Lettuce 的场景：**

```
wrk -t8 -c200 -d30s --latency http://cdh1:18081/dubbo-consumer-
demo/echo/variable/11
```
```
[root@centos1 src]# wrk -t8 -c200 -d30s --latency http://cdh1:18081/dubbo-
consumer-demo/echo/variable/11
Running 30s test @ http://cdh1:18081/dubbo-consumer-demo/echo/variable/11
 8 threads and 200 connections
Thread Stats Avg Stdev Max +/- Stdev
Latency 321 .50ms 294 .59ms 2 .00s 61 .77%
Req/Sec 87 .18 43 .39 232 .00 67 .00%
Latency Distribution
50 % 309 .06ms
75 % 503 .06ms
90 % 687 .99ms
99 % 1 .21s
 20495 requests in 30 .10s, 7 .64MB read
Socket errors: connect 0 , read 0 , write 0 , timeout 49
Requests/sec: 680 .90
Transfer/sec: 259 .99KB
```

**使用 jedis 的场景**

吞吐量从 5000 提升到 10000

99% 响应时间从 199.81 ms 降低到 76.70 ms

**DB 的异步化 （假装提升 10 倍）**

```
[root@centos1 ~]# wrk -t8 -c200 -d30s --latency
http://192.168.56.121:7703/uaa-react-provider/api/userCacheAside/detail/v1?
userId=1
Running 30s test @ http://192.168.56.121:7703/uaa-react-
provider/api/userCacheAside/detail/v1?userId= 1
 8 threads and 200 connections
Thread Stats Avg Stdev Max +/- Stdev
Latency 18 .29ms 13 .56ms 213 .57ms 89 .56%
Req/Sec 1 .51k 504 .74 4 .26k 72 .86%
Latency Distribution
50 % 14 .56ms
75 % 19 .92ms
90 % 31 .20ms
99 % 76 .70ms
 359546 requests in 30 .10s, 53 .15MB read
Requests/sec: 11945 .39
Transfer/sec: 1 .77MB
```
```
wrk -t8 -c200 -d30s --latency http://192.168.56.121:7702/uaa-
provider/api/user/detailCacheAside/v1?userId= 1
```
```
[root@centos1 src]# wrk -t8 -c200 -d30s --latency
http://192.168.56.121:7702/uaa-provider/api/user/detailCacheAside/v1?userId=1
Running 30s test @ http://192.168.56.121:7702/uaa-
provider/api/user/detailCacheAside/v1?userId= 1
 8 threads and 200 connections
Thread Stats Avg Stdev Max +/- Stdev
Latency 42 .20ms 44 .79ms 1 .11s 93 .41%
Req/Sec 683 .30 245 .08 1 .85k 67 .39%
Latency Distribution
50 % 32 .65ms
75 % 48 .30ms
90 % 72 .32ms
99 % 199 .81ms
 162271 requests in 30 .09s, 71 .96MB read
Requests/sec: 5393 .75
Transfer/sec: 2 .39MB
```

数据操作是每个请求调用链的终点，纯异步的架构必须使用异步存储层客户端，

比如说，可以使用纯异步化的框架 **Spring Data R 2 DBC**

在尼恩的 Crazy-SpringCloud 脚手架纯异步化改造中，没有对的 DB 进行异步化改造，为啥呢？DB 是
一个低吞吐的物种，对于 DB 而已，请求太多，反而忙不过来，造成整体的性能下降。

所以，尼恩没有对 DB 进行纯异步化改造，反而是进行隔离和保护：

```
参考 Hystrix 舱壁模式， 通过 DB 的操作进行 线程池隔离，
使用 手写 Hystrix Command 的方式，进行 DB 操作的 高压防护。
```
控制线程数和请求数，保护不至于拖垮 DB

由于高压防护，在高并发场景能快速失败，所以肯定提升不止 10 倍，不过是假装提升 10 倍

**纯异步与伪异步**

异步调用目的在于防止当前业务线程被阻塞。

伪异步将任务包装为 Runnable 放入另一个线程执行并等待，当前 Biz 线程不阻塞；

纯异步为响应式编程模型，通过 IO 实践驱动任务完成。

两个概念很重要，这里不做赘述，具体请参考 40 岁老架构师尼恩为大家整理的深度文章：

京东一面： 20 种异步，你知道几种？ 含协程

**全链路异步，让你的性能优化 10 倍+**

降本增效时代，大家行动起来吧，对 SpringCloud 微服务进行一场性能提升革命

想尽办法，让一台服务器，发挥 10 台的价值

特别提示：

在尼恩的全链路异步改造的过程中，大量使用了响应式编程。关于响应式编程的知识，请参考尼恩的
深度文章：

Flux、Mono、Reactor 实战（史上最全）

**遗憾的是，响应式编程非常复杂，**


后面，尼恩还会有响应式编程专题的 3 高架构笔记 pdf，做到通俗易懂，带大家轻轻松松成为响应式编程
专家。

## 30 Wqps+闲鱼优惠中台，如何架构的？

#### 说在前面

在尼恩的（50+）读者社群中，经常遇到一个非常、非常高频的一个面试题，但是很不好回答，类似如
下：

```
千万级数据，如何做系统架构？
亿级数据，如何做做系统架构？
千万级流量，如何做系统架构？
亿级流量，如何做做系统架构？
高并发系统，如何架构？
```
**最近，这段时间，好几个小伙伴都和尼恩来反馈：在面试过程中，遇到了这样的真题。**

其实，答案不是一成不变的。

高并发、高性能、高扩展的案例，千千万万，尼恩一直结合行业案例，梳理一个最为全面、最为系统化
的答案，

这里有一个新的行业案例《兼顾可扩展、高并发与数据一致性：闲鱼鱼优惠系统设计实践》，尼恩从面
试维度，对这个方案，进行二次重构和梳理，现在把其做为参考答案，收入咱们的《尼恩 Java 面试宝典
PDF》 V 65 版本

供后面的小伙伴参考，大家一定好好看看这个生产级别的答案。

本文原文：《兼顾可扩展、高并发与数据一致性：咸鱼优惠系统设计实践》原始方案的作者是闲鱼的资
深开发工程师泊垚，原文来自于公众号，闲鱼技术（ID：XYtech_Alibaba）。

下面的内容，是尼恩是结合自己的 3 高架构笔记，以及尼恩的 3 高架构知识体系（ 3 高架构宇宙），在原
文的基础上，做的二次架构分析和创作。

#### 优惠券业务的场景分析

优惠券业务，在大量的场景中，会有使用。

在我们日常生活中，常常会遇到下面这样的场景：优惠券业务是一种促销方式，通常由商家向消费者提
供的折扣或者特价优惠，在推广和销售产品时具有重要的作用。

###### 优惠券业务主要使用场景分析

**场景 1 ：电商平台**

在电商平台上，商家可以通过发布优惠券来吸引更多用户购买商品，从而提高销售额。比如，在双十一
或者 618 等大促销活动中，商家会发布各种优惠券，包括满减券、折扣券、免邮券等等，以达到促销的
目的。

**场景 2 ：实体店铺**


实体店铺也可以通过发放优惠券来吸引更多顾客到店消费。

比如，在超市或者餐厅中，可以提供满减券、折扣券、赠品券等等，让消费者享受到更多的实惠，从而
增加消费频次和消费金额。

**场景 3 ：O 2 O 平台**

在 O 2 O 平台中，商家可以通过发放优惠券来吸引用户使用其服务。

比如，在外卖平台上，商家可以发布满减券、新用户专属券等等，以吸引更多的用户尝试其服务；在打
车平台上，也可以发布优惠券来吸引用户使用其服务。

**场景 4 ：品牌推广**

品牌推广也是优惠券业务的一个重要场景。

比如，在新品上市或者品牌促销活动中，可以通过发放折扣券或者礼品券等等，来吸引更多用户尝试品
牌产品或者服务，提高品牌知名度和美誉度。

总之，优惠券业务在各个行业中都有广泛的应用，可以帮助商家提高销售额、增加用户粘性和忠诚度，
同时也能为消费者提供更多的实惠和福利。

###### 优惠券场景的业务迭代

如何提升优惠券的引流能力。答案是： 设计一个个性化的优惠券系统，为不同的粉丝群体，设置不同
的优惠券价格。

为了设计一个个性化的优惠券系统，闲鱼团队需要考虑以下几个方面：

**粉丝群体分类**

首先，需要将粉丝群体进行分类，比如按照年龄、性别、地域、消费习惯等等进行分类。这样可以更好
地理解不同群体的需求和行为特征，有针对性地推出不同的优惠券。

**优惠券类型**

其次，需要确定不同的优惠券类型，比如满减券、折扣券、免单券等等。根据不同的群体需求，设置不
同的优惠力度和使用条件，例如对于高消费群体，可以设置更高额度的满减券或者更高折扣力度的折扣
券。

**优惠券价格**

最后，需要考虑不同粉丝群体的经济实力和消费能力，合理设置优惠券价格。

例如，对于大学生群体，可以设置较低的价格，以吸引他们尝试新产品或服务；而对于高收入群体，则
可以设置更高的价格，以提升产品或服务的价值感。

**优惠券的迭代分析：**

除此之外，可以通过数据分析的方式，不断优化和调整优惠券系统，以达到更好的促销效果和用户满意
度。

同时，还需要注意保障优惠券系统的安全性和有效性，例如设置使用期限、使用限制等措施，避免滥用
和恶意操作。

###### 闲鱼的个性化优惠场景


闲鱼是一款二手交易平台 APP，主要面向年轻用户群体。以下是闲鱼 APP 的用户分析：

**年龄分布**

闲鱼 APP 的主要用户群体年龄在 18-35 岁之间，其中以 25-30 岁的用户占比最高。这个年龄段的用户更注
重物品的性价比和实用性，同时也更善于使用互联网和移动设备进行购物。

**性别分布**

相比于其他二手交易平台 APP，闲鱼 APP 的用户男女比例较为接近，女性用户占比略高。这也反映出闲
鱼 APP 对女性用户的吸引力较大，可能与其简单易用、社区氛围浓厚等特点有关。

**地域分布**

闲鱼 APP 的用户主要集中在一二线城市，尤以杭州、上海、北京等城市为主。这些城市的用户更注重生
活品质和消费体验，对于二手商品的需求也更为广泛和多样化。

**用户行为特征**

闲鱼 APP 的用户通常具有以下几个行为特征：爱好交友、追求个性化、注重环保节能等等。他们不仅使
用闲鱼 APP 进行二手交易，还会通过闲鱼社区分享生活经验、交流兴趣爱好等，形成了一种类似于社交
媒体的共享氛围。

**用户需求和偏好**

闲鱼 APP 的用户需求和偏好主要集中在以下几个方面：时尚潮流、个性化定制、品质保障等。他们通常
会在闲鱼 APP 上寻找一些独特而实用的物品，包括衣物、配饰、家居用品等等，同时也关注卖家的信誉
度和商品质量。

总闲鱼 APP 的用户具有年轻、多样化、社交化等特点，商家可以根据这些特点进行针对性的营销策略和
产品服务优化，提高用户满意度和购买转化率。

在闲鱼上，针对闲鱼交易中的粉丝群体，提供了专门的优策略，针对粉丝购买和粉丝回购的优惠促
销场景，提供了一种定向的/个性化的优惠价：

```
卖家可以按商品分别面向全部粉丝、老粉、已购粉设置不同的优惠价格。
买家在导购、下单等场景可以实时看到自己能够享受的最低优惠价格。
```
虽然闲鱼没有使用优惠券的概念，使用的优惠价格。但是和个性化的优惠券，本质是一样的。

所以，闲鱼的优惠中台的架构，对大家做个性化的优惠券中台的架构，具有巨大的借鉴的架构。

尼恩提示：技术自由圈 _3_ 高社群的宗旨：聚焦研究 _3_ 高架构，研究成熟案例，研究生产案例，为大家做
架构提供方案支撑。


#### 海量用户场景问题与挑战

闲鱼 APP 的 DAU，注册用户数 2.5 个亿，日活跃用户数（DAU）为 2900 万左右。

按照尼恩的 3 高架构理论，吞吐量峰值至少在 30 Wqps+。

这么大的海量用户场景，在优惠券计算、优惠券展示的过程中，存在巨大的技术难题:

```
难题 1 ： 如何描述、存储和计算优惠，提供较好的业务可扩展性?
难题 2 ： 如何保障大流量下，优惠实时计算的性能?
难题 3 ：为优惠查询加速做的数据同步，如何实现一致性?
```
#### 闲鱼的个性化优惠中台的技术演进

闲鱼的个性化优中台的技术演进, 分为三个阶段来实现：

```
阶段 1 ：分解优惠的基本要素，实现优惠的基本表达和计算；
阶段 2 ：对优惠对象的判定过程进行抽象和加速
为了保障大流量下的优惠查询下性能和业务的可扩展性，对优惠对象的判定过程进行抽象和加速；
阶段 3 ：在优惠对象制备的过程中，通过离线+实时的方式同步数据，保障数据一致性。
```
#### 阶段 1 ：分解优惠的基本要素，实现优惠的基本表达和计算

###### 分解优惠的基本要素

一个优惠主要描述了“谁对哪个商品享受什么优惠”，拆解为三个要素就是：

【优惠对象】+【优惠商品】+【优惠价格】。

在粉丝优惠的场景下，优惠对象是指卖家的粉丝、卖家的已购粉丝等，

优惠对象如何存储呢？


一个卖家的粉丝，可以被描述为“卖家 ID_all_fans”的符号

一个卖家的已购用户，可以被描述为“卖家 ID_buy_fans” 的符号。

这样闲鱼团队可以得到一个优惠规则的描述大致如下：

**【卖家 A_all_fans】+【商品 1234 】+【18.88 元】，**

对应的业务语义是：

**卖家 A 的所有粉丝，对于（卖家 A 的）商品 1234 ，可以以 18.88 元的优惠价格。**

###### 实现优惠的基本表达和计算的三个步骤

以这条优惠为例，当买家 B 访问商品 1234 时，闲鱼团队会执行这样的一个过程：

**第一步： 根据商品，查询优惠规则**

查询商品 1234 上的优惠规则，发现一条【卖家 A_all_fans】+【商品 1234 】+【18.88 元】的规则；

**第二步：分析优惠对象的语义**

分析【卖家 A_all_fans】表达的含义，表示的是卖家 A 的全部粉丝可以享受优惠；

**第三步：根据规则的语义，计算当前用户的优惠价格**

确定买家 B 是否是卖家 A 的粉丝，如果是，则以 18.88 元的价格展示优惠或者成交。

###### 闲鱼的优惠中台的架构 1.0 版本

为了实现了优惠设置和计算的能力，闲鱼的优惠中台的架构 1.0 版本, 大致如下：


#### 阶段 2 ：对优惠对象的判定过程进行抽象和加速

###### 闲鱼的优惠中台的架构 1.0 版本存在两个问题：

```
问题 1 ：优惠对象语义分析，可扩展性差
```
优惠计算过程需要解析【优惠对象】这个符号背后所包含的业务语义，再由系统进行判断买家是否符合
条件，随着业务规则的升级，系统的会变的非常复杂，可扩展性差。

```
问题 2 ：太多的RPC调用，性能差
```
每一次优惠查询，都需要访问用户的关注关系、购买关系，这整个查询过程非常长，性能低下，当面对
大流量时，系统会陷入瘫痪。

###### 对优惠对象的计算进行抽取和解耦

为了解决这两个问题，闲鱼希望优惠计算过程不再需要理解【优惠对象】的语义，判定过程中也不要再
去查询各个业务系统。

闲鱼团队发现，优惠对象的判定过程都是在回答“用户是否属于某个群体”，于是，可以将这个关系进行
抽象，提前制备并存储起来。


常见的技术手段中，表达一个用户是否属于某个群体有两种实现：

```
在用户对象上打上一个标记。
创建一个“人群”对象，将用户关联到人群。
```
一般情况下，第一种方式使用于群体较少可枚举的情况，第二种方案适用于群体较多的情况。在闲鱼的
实现中，使用了第二种方案。

具体的措施是，抽取出一个新的实体：人群，并且提前进行异步计算。

闲鱼将用于描述优惠对象的符号（例如“卖家 A_all_fans”）作为人群的名称去定义一个人群。按照这个规
则，平台为每个卖家的不同分组各定义这样一个人群。

闲鱼定义了人群的概念，并提供了一种实现人群的技术方案，这个架构中，人群在同时充当了“协议”和
“缓存”的作用。

人群和用户的关系，如何存储呢？

方案一：可以通过 redis string 实现，设计一个类似：${user_A} ${crowd_B}的 key 写入 redis。

在查询时，查询 ${user_A}_${crowd_B}这个 key 是否存在，就可以判定 user_A 是否属于 crowd_B。

方案二：可以通过 redis set 实现，设计一个类似 ${crowd_B} 的 key 写入 redis, 然后把 ${user_A} 的用
户加入到 set 。

在查询时，查询${crowd_B}, 是否在 ${user_A}的集合中，就可以判定 user_A 是否属于 crowd_B。

当然，上面仅仅是参考的案例，闲鱼设计中需要根据数据特性进行优化。

如果读者有更好的方案，也可以来高并发社群，技术自由圈（原疯狂创客圈） 中交流。

###### 闲鱼的优惠中台的架构 2.0 版本

这时闲鱼的得到的整体架构是这样的：


在上面的架构中，顺带缓存了一下优惠数据

事实上，在闲鱼基于中台的解决方案中，从一开始面临的就是这样的架构（实际中台的架构比这个会更
复杂一些）。

如果尝试从头演进了这个系统，也得到这样的一个方案。

**从一定程度来说，这也是架构的必然性.**

具体来说，当我们从业务的可扩展性、系统的性能角度从头进行推演的时候，我们发现最终会回到类似
的架构上来。

可以说，在特定的业务规模下，架构的演进有它历史的必然性。

#### 阶段 3 ：在优惠对象制备的过程中，通过离线+实时的方式

#### 同步数据，保障数据一致性。

###### 闲鱼的优惠中台的架构 2.0 版本的问题


在实际落地的过程中，如何将业务系统中的关注和购买关系同步到人群中，并保证数据的一致性。

人群的同步整体上分为两个主要部分：

```
将离线业务数据通过T+1的方式，同步到人群服务中。
通过实时同步的方式，将当天实时产生的关注、取消关注等行为产生的变动，同步的更新到人群服
务中。
```
这种结合的方式具有以下优点：

```
实时消费消息进行同步，保障了数据的实时性。
离线T+1的全量同步，保证实时同步过程中产生的数据不一致会被及时的纠正，保障了数据的最终
一致。
离线同步解决了数据初始化过程中的全量同步问题。
```
但上述的两个过程中，会出现两类问题：

```
离线数据因为其数据存储的特征，只会记录存在的关注关系，如果是被删除的关注关系（取消关
注），则不会出现在离线数据中。因此实时同步中，因未同步取消关注事件产生了不一致，数据无
法被全量同步纠正。
离线同步和实时同步在实际实施过程中，会产生一种常见的数据冲突：用户A今天原本关注了用户
B，某天较早的时候取消关注了，如果这个时候的离线数据还没同步完成，全量同步会再次将A对B
的关注关系写入到人群中，出现了与实际数据的不一致。
```

###### 闲鱼的优惠中台的架构 3.0 版本

针对上述的两个问题，分别给出了以下两个解决方案：

```
针对取关数据误差无法通过全量同步纠正的问题，同步过程中，写入人群的时候会添加一个过期时
间，这个过期时间略长于离线全量同步的间隔，这样的好处是一旦在实时同步过程中，出现了取关
但未同步到人群的情况，这条记录会自动过期，从而避免了不一致的数据在系统中积累。
针对同步过程中发生数据冲突的问题，通过在实时同步的过程中，取关的事件在redis写入一条临
时记录，表示该数据近期发生过取关；在全量同步过程中，去比对redis中是否有取关记录，避免
发生冲突。
```
通过上述两个解决方案，闲鱼实现了人群同步的最终一致性，最终实现的方式如图：


###### 闲鱼数据一致性方案的普适性

这样的同步方案，对于搜索、推荐等大流量的导购场景，提供了充分的数据一致性保障。

绝大多数情况下，数据实时一致，对于小概率出现数据实时同步不一致，通过全量同步保障数据最终一
致，满足导购场景的一致性要求。

此外，针对交易这样的要求强一致性但访问规模较小的场景，闲鱼团队通过下单前对人群同步的数据进
行核对，保障数据的实时完全一致。

#### 闲鱼团队结语

本文从三个部分介绍了优惠的实现：

```
通过对优惠要素的拆解和人群的定义，我们在描述、存储和计算优惠的同时，提供较好的业务可扩
展性。
```

```
通过提前制备人群数据，我们保障了大流量下的优惠查询下性能，系统能够支持几十万QPS下的毫
秒级响应。
在人群同步的过程中，通过离线+实时的方式同步数据，保障了数据的最终一致性。
```
在优惠的实现过程中，直接面临了一个迭代了多年的优惠中台，需要闲鱼团队通过同步人群数据的方式
进行接入。可能一开始会疑惑为什么需要执行一个复杂、高成本且会引入数据一致性风险的同步过程。

但当闲鱼团队从业务的可扩展性、系统的性能角度从头进行推演的时候，闲鱼团队发现最终会回到类似
的架构上来。

可以说，在特定的业务规模下，架构的演进有它历史的必然性。

当然，也不是说这样的架构是适用于所有情况的，架构选型还是需要结合实际情况出发量身定制。

#### 结合闲鱼的方案，回顾前面的面试题：

```
千万级数据，如何做系统架构？
亿级数据，如何做做系统架构？
千万级流量，如何做系统架构？
亿级流量，如何做做系统架构？
高并发系统，如何架构？
```
以上的方案，可以作为大家的一个参考答案。后续尼恩会给大家结合行业案例，分析出更多，更加劲爆
的答案。

当然，如果大家遇到这类高并发的面试难题，可以找来尼恩的社群交流。

## 美团一面：接口被恶刷，破 10 Wqps 后系统崩

## 溃，怎么解决？

#### 背景说明：

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，最近有小伙伴拿到了一线互联网企业如美团、极兔、有
赞、希音、百度、网易、滴滴的面试资格，遇到一几个很重要的面试题：

近段时间，有小伙伴面试美团，说遇到一个去重调优的面试题：

```
接口被恶刷，破10Wqps后系统崩溃，怎么解决？
```
MySQL 设计的时候，如何高性能进行数据去重，也是调优的重点和难点，社群中，还遇到过大概的变
种：

```
形式 1 ：短信验证码接口，如何防刷？
```
```
形式 2 ：登录注册入口被恶意调用攻击，该如何破解？
```
```
形式 3 ：接口被恶意狂刷，怎么办？
```

```
形式 4 ：接口被狂刷10Wqps，怎么解决？
```
```
形式 5 ：........， 后面的变种很多，都会收入 《尼恩Java面试宝典》。
```
这里尼恩给大家对数据去重的调优，做一下系统化、体系化的梳理，使得大家可以充分展示一下大家
雄厚的 “技术肌肉”， **让面试官爱到 “不能自已、口水直流”** 。

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 75，供后面的小伙伴参考，提升
大家的 3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，最新尼恩 架构笔记、面试题 的PDF文件，请从这里获取，公号：技
术自由圈。
```
#### 接口被狂刷的严重后果

恶意攻击者通常会通过自动化工具进行攻击，尤其是会针对一些高频接口、核心接口进行恶意的访问，
恶意的攻击，比如：

```
注册登录接口
秒杀抢购接口
等等
```
接口被狂刷会带来很高的瞬时吞吐量，很容易超过 1 Wqps，甚至 10 WQPS。这样的超高并发，会导致系
统的瞬时雪崩，严重的可能会导致线上系统瘫痪。

#### 接口狂刷的主要防护措施：

```
交互式验证
安全参数校验
使用 HTTPS
用户访问认证
资源访问授权
访问限流
IP封禁
日志监控和异步分析
升级硬件设备
基于时序的统计预警
```
###### 交互式验证

主要包括：

```
验证码验证 ：在发送验证码之前，可以要求用户输入一个验证码，以验证用户的身份。这种方式可
以有效地防止自动化攻击。
人机验证 ：人机验证是一种更高级的验证方式，可以检测用户行为是否类似于自动化攻击。例如，
可以要求用户在发送验证码之前完成一个简单的任务，如拖动滑块或识别图片中的文字。
```
###### 安全参数校验


当接口被恶意狂刷时，可以通过安全参数校验来防止这种攻击。安全参数校验是指在接口请求中添加一
些校验参数，例如时间戳、随机字符串、签名等，来验证请求的合法性。这样可以防止攻击者通过恶意
程序进行大量的请求攻击。

具体来说，可以通过以下步骤来实现安全参数校验：

```
1. 在接口请求中添加时间戳参数，例如：timestamp=1622945123。
2. 在接口请求中添加随机字符串参数，例如：nonce=abc123。
3. 将所有请求参数按照参数名的字母顺序排序，例如：nonce=abc123&timestamp=1622945123。
4. 将排序后的参数按照“参数名=参数值”的格式拼接成一个字符串，例如：
nonce=abc123&timestamp=1622945123。
5. 将拼接后的字符串加上一个密钥（可以是预先约定好的密钥），例如：
nonce=abc123&timestamp=1622945123&key=secret。
6. 对加密后的字符串进行哈希计算，例如使用 MD5 算法，得到一个签名值，例如：
c0c3f9a2a4c4c4dcd6d5b7b2a2e4d7b1。将签名值添加到接口请求中，例如：
nonce=abc123&timestamp=1622945123&signature=c0c3f9a2a4c4c4dcd6d5b7b2a2e4d7b1。
7. 在接口服务端对接口请求进行校验时，按照相同的算法计算签名值，并与请求中的签名值进行比
对，如果一致，则说明请求合法，否则说明请求不合法。
```
通过以上步骤，可以有效地防止接口被恶意狂刷的攻击。

理论上，哈希计算很难破解，但是如果攻击者知道了 hash 算法和盐，攻击者就有可能伪造出带有正确校
验位的签名值，从而绕过 Java 接口的限流和安全机制。

因此，该方案主要适用于需要简单防范一些低强度攻击的场景，例如防范垃圾请求或非法爬虫等。

对于高强度攻击，建议采取更为复杂的验证策略，例如使用使用用户访问认证，资源访问授权、IP 白名
单、签名算法等。

###### 使用 HTTPS

使用 HTTPS 可以保护数据传输的安全性，可以防止恶意攻击者窃取数据。HTTPS 使用 SSL/TLS 协议对
数据进行加密，可以确保数据在传输过程中不被篡改或窃取。

因此，在一些恶意狂刷的高频接口，比如短信验证码接口、登录注册入口等敏感区域使用 HTTPS 是必
要的。

当然，尽量在客户端和服务端在全部通讯，都使用 HTTPS 协议进行加密，防止数据被窃听或篡改。

###### 用户访问认证

用户访问认证是指在系统中验证用户身份以授权其访问系统资源的过程。

用户访问认证是信息安全中非常重要的一环，可以保护系统免受未经授权的访问和攻击。

常见的用户访问认证方式包括用户名密码认证、双因素认证、证书认证等

这里来看最为简单的用户访问认证： 用户名密码认证

用户名密码认证的方式，要求用户提供用户名和密码，换取访问的令牌。

参考的代码如下：


在上述代码中，当用户调用 login 接口时，需要提供用户名和密码。

此时会进行用户校验，若校验失败则返回错误信息，否则生成 token 并保存，最终返回给用户。

生成 Token 的作用是为了在接口请求时验证用户身份。

具体来说，当用户第一次登录系统后，该接口可以根据用户信息生成一个 Token 字符串，并将其保存至
服务端或客户端。

```
当此用户访问其他需要鉴权的接口时，需要在请求头中带上这个Token字符串，以便服务器进行身
份验证。
由于Token是由服务端生成的，攻击方无法自己生成有效的Token，因此只有拥有合法Token的用
户才能成功调用相关接口。
```
对于 Java 接口被恶意狂刷问题，Token 的作用是防止非法请求。

如果 Token 验证失败，则返回错误信息并拦截该请求。

```
关于Token的验证，可以通过拦截器实现。
拦截器可以在接口调用前检查请求头中是否包含合法的Token，并验证Token是否过期、是否被篡
改等。
```
下面是使用拦截器进行令牌校验的示例代码：

```
@RequestMapping("/api/login")
public String login(@RequestParam("username") String username,
@RequestParam("password") String password){
if(!checkUser(username, password)){
return "用户名或密码错误";
}
String token = getToken();
saveToken(token);
return token;
}
```
```
private boolean checkUser(String username, String password){
//校验用户是否合法
}
```
```
private String getToken(){
//生成token
}
```
```
private void saveToken(String token){
//保存token
}
```
```
// 鉴权拦截器
public class AuthInterceptor extends HandlerInterceptorAdapter {
```
```
@Override
public boolean preHandle(HttpServletRequest request, HttpServletResponse
response,
```

AuthInterceptor 类是拦截器类，用于检查请求头中的 Token 是否合法。

如果 Token 验证失败，则返回 401 错误码并拦截该请求。

###### 资源访问授权

如果接口的安全性要求非常高，只有特定的用户才能访问。

或者说，如果遇到要对资源进行更细粒度的防刷处理，可以对资源进行访问权限的管理和授权。主要
的策略有 RBAC 的机制。

主要的思路为：使用访问控制策略对资源权限进行精准控制。场景的访问控制策略为 RBAC 策略。

RBAC（Role-Based Access Control，基于角色的访问控制）是一种常见的访问控制策略，它将用户分
配到不同的角色中，每个角色具有一组权限，从而控制用户对系统资源的访问。

在 RBAC 中，管理员可以根据用户的职责和职位，将用户分配到适当的角色中，从而控制用户对系统资
源的访问权限。RBAC 还可以提高系统的安全性和可管理性，减少权限管理的复杂性。

Shiro 是一个强大且易于使用的 RBAC 访问的安全框架，提供了身份验证、授权、加密、会话管理等安
全功能。其中授权是 Shiro 的核心功能之一，它可以帮助我们实现资源访问授权。

在 Shiro 中，授权是通过授权信息和角色信息来实现的。授权信息是指哪些用户可以访问哪些资源，角
色信息是指用户可以拥有哪些权限。

Shiro 中的授权流程如下：

```
1. 用户登录系统，进行身份认证。
2. 身份验证成功后，Shiro 将用户信息存储在 Subject 中。
3. 用户请求访问某个资源。
4. Shiro 从 Subject 中获取用户信息，并根据用户信息和授权信息判断用户是否有权限访问该资源。
5. 如果用户有权限访问该资源，则允许访问；否则拒绝访问。
```
在 Shiro 中，授权信息和角色信息可以通过配置文件或数据库来管理。我们可以在配置文件或数据库中
定义哪些用户可以访问哪些资源，以及哪些角色可以拥有哪些权限。在程序运行时，Shiro 会从配置文
件或数据库中读取授权信息和角色信息，并根据这些信息进行授权判断。

除了配置文件和数据库，Shiro 还提供了编程式授权方式，即通过编写代码来实现授权。这种方式可以
实现更加灵活的授权，但需要开发人员自己编写授权逻辑。

下面是 Shiro 的使用入门步骤：

```
1. 引入 Shiro 依赖
```
在 Maven 项目中，可以通过在 pom. xml 文件中添加以下依赖来引入 Shiro：

```
Object handler) throws Exception {
String token = request.getHeader("Authorization");
if (token == null || !checkToken(token)) {
response.setStatus(HttpStatus.UNAUTHORIZED.value());
return false;
}
return true;
}
```
```
private boolean checkToken(String token) {
// 验证Token是否合法，是否过期等
}
}
```

```
2. 配置 Shiro
```
在 Shiro 中，可以通过配置文件或编程方式来配置安全策略。下面是一个简单的 Shiro 配置文件示例：

```
3. 创建 Realm
```
在 Shiro 中，Realm 是用于认证和授权的核心组件。可以通过实现 org. apache. shiro. realm. Realm 接
口来创建自定义的 Realm，或者使用 Shiro 提供的现成的 Realm 实现。下面是一个简单的自定义
Realm 示例：

```
<dependency>
<groupId>org.apache.shiro</groupId>
<artifactId>shiro-core</artifactId>
<version>1.7.1</version>
</dependency>
```
```
[main]
# 定义一个默认的 Realm，用于认证和授权
myRealm = com.example.MyRealm
```
```
# 定义一个默认的加密算法
passwordService = org.apache.shiro.authc.credential.DefaultPasswordService
passwordMatcher = org.apache.shiro.authc.credential.PasswordMatcher
passwordMatcher.passwordService = $passwordService
```
```
# 配置安全管理器
securityManager = org.apache.shiro.mgt.DefaultSecurityManager
securityManager.realm = $myRealm
```
```
# 配置加密器
securityManager.passwordService = $passwordService
securityManager.authenticator.passwordMatcher = $passwordMatcher
```
```
# 配置会话管理器
sessionManager = org.apache.shiro.web.session.mgt.DefaultWebSessionManager
securityManager.sessionManager = $sessionManager
```
```
# 配置缓存管理器
cacheManager = org.apache.shiro.cache.ehcache.EhCacheManager
securityManager.cacheManager = $cacheManager
```
```
[users]
# 定义用户及其密码和角色
admin = admin, admin_role
user1 = password1, user_role1
user2 = password2, user_role2
```
```
[roles]
# 定义角色及其权限
admin_role = *
user_role1 = user:read, user:write
user_role2 = user:read
```
```
public class MyRealm implements Realm {
```
```
@Override
```

```
4. 认证和授权
```
在应用程序中，可以通过调用 Shiro 提供的 Subject 类的方法来进行认证和授权。下面是一个简单的示
例：

```
public String getName() {
return "myRealm";
}
```
```
@Override
public boolean supports(AuthenticationToken token) {
return token instanceof UsernamePasswordToken;
}
```
```
@Override
public AuthenticationInfo getAuthenticationInfo(AuthenticationToken token)
throws AuthenticationException {
String username = (String) token.getPrincipal();
String password = new String((char[]) token.getCredentials());
if (!"admin".equals(username)) {
throw new UnknownAccountException("Unknown user");
}
if (!"password".equals(password)) {
throw new IncorrectCredentialsException("Incorrect password");
}
return new SimpleAuthenticationInfo(username, password, getName());
}
```
```
@Override
public AuthorizationInfo getAuthorizationInfo(PrincipalCollection
principals) {
SimpleAuthorizationInfo info = new SimpleAuthorizationInfo();
info.addRole("admin_role");
info.addStringPermission("user:read");
info.addStringPermission("user:write");
return info;
}
}
```
```
// 获取当前用户的 Subject
Subject currentUser = SecurityUtils.getSubject();
```
```
// 创建一个用户名和密码的 Token
UsernamePasswordToken token = new UsernamePasswordToken("admin", "password");
```
```
try {
// 进行认证
currentUser.login(token);
```
```
// 进行授权
if (currentUser.hasRole("admin_role")) {
System.out.println("User has admin role");
}
if (currentUser.isPermitted("user:read")) {
System.out.println("User has read permission");
}
if (currentUser.isPermitted("user:write")) {
```

以上就是 Shiro 的入门使用步骤。当然，Shiro 还提供了很多其他的功能和配置选项，需要根据具体的
应用场景进行选择和使用。

```
40 岁老架构师尼恩提示：
```
```
和Shiro 类似，SpringSecurity 也是一个 资源访问授权的 框架。
```
```
原理都是类似的，大家精通一个，另一个也触类旁通了。
```
###### 访问限流

访问限流是一种常见的保护机制，用于控制对某个资源的访问速率，以防止过多的请求导致系统负载过
高或崩溃。

访问限流包括两个维度：

```
访问限流策略
访问限流算法
```
维度一：访问限流策略

```
面向接口限流
面向用户限流
```
维度二：访问限流算法

```
令牌桶算法
漏桶算法
```
在令牌桶算法中，系统会按照一定速率往令牌桶中添加令牌，每个令牌代表一个请求的访问权限。当请
求到来时，系统会从令牌桶中取出一个令牌，如果令牌桶中没有令牌，则拒绝该请求。

在漏桶算法中，系统会按照一定速率从漏桶中释放请求，当请求到来时，如果漏桶中还有空余容量，则
将该请求放入漏桶中，否则拒绝该请求。

接口被恶意狂，可以使用基于漏桶算法 + 基于用户限流的综合性限流策略。

可以结合黑名单策略，对恶意用户进行有效人工管理。如果用户被限流，甚至可以加入黑名单，封掉这
个用户。

```
System.out.println("User has write permission");
}
} catch (UnknownAccountException e) {
System.out.println("Unknown user");
} catch (IncorrectCredentialsException e) {
System.out.println("Incorrect password");
} catch (LockedAccountException e) {
System.out.println("Account is locked");
} catch (AuthenticationException e) {
System.out.println("Authentication error");
}
```

关于限流的详细内容，请查看尼恩的深度笔记 ：

限流深入解读：计数器、漏桶、令牌桶三大算法的原理与实战（史上最全）

###### IP 封禁

IP 封禁是常见的网络安全措施，用于保护服务器免受恶意攻击。

IP 封禁是指将某个 IP 地址列入黑名单，禁止其访问服务器。

在实际应用中，可以通过配置防火墙规则、使用反向代理服务器、使用专业的防火墙软件等方式来实现
IP 封禁和防刷。

也可以在应用层代码中，通过过滤器的方式，进行 IP 封禁

参考代码如下：

在上述代码中，通过 IpFilter 过滤器来阻止特定的 IP 地址访问接口。其中，IP_SET 为需要封禁的 IP 地址集
合。

###### 日志监控和异步分析

访问日志监控是一种常见的监控方式，用于监控网站、应用程序等的访问情况，可以帮助我们了解用户
的行为和需求，以便做出相应的优化和改进。

常见的访问日志监控工具有 Apache 的 AccessLog、Nginx 的 AccessLog、ELK Stack 、Java 请求日志
监控等。

这些工具、框架帮助我们收集、分析和可视化访问日志数据，从而更好地了解用户的需求和行为。

```
public class IpFilter extends OncePerRequestFilter {
private static final Set<String> IP_SET = new HashSet<>();
```
```
static {
IP_SET.add("192.168.1.100");
IP_SET.add("127.0.0.1");
//添加其他需要封禁的IP
}
```
```
@Override
protected void doFilterInternal(HttpServletRequest request,
HttpServletResponse response,
FilterChain filterChain) throws
ServletException, IOException {
String ipAddress = request.getRemoteAddr();
if(IP_SET.contains(ipAddress)){
response.setStatus(HttpStatus.FORBIDDEN.value());
return;
}
```
```
filterChain.doFilter(request, response);
}
}
```

同时，我们也可以通过访问日志监控来检测和排查一些常见的安全问题，如 SQL 注入、XSS 攻击等。

监控访问日志可以帮助发现未经授权的访问请求。可以使用日志记录工具来记录每个请求的 IP 地址、
时间戳和请求参数。

如果发现异常请求，可以及时采取措施，以防止攻击。

下面是一个参考的，进行响应记录的过滤器。

在上述代码中，通过 Filter 过滤器来实现日志监控。

当请求进入时记录请求 URI，当请求结束时记录响应状态码，如此可及时发现异常情况。

有了日志仅仅是第一步，还需要结合定时任务或者流式计算工具，进行异步分析，甚至是离线分析。

异步分析或者离线分析的，最终得到恶意请求的用户或者 ip，然后进行拉黑或者 IP 封禁。

###### 升级硬件设备

如果服务器无法承受恶意攻击，可以通过升级硬件设备来增加服务器的承载能力。

例如，可以增加 CPU 或内存等硬件资源，降低服务器的响应时间。

###### 基于时序的统计预警

当 Java 接口被恶意狂刷时，及时通知相关管理人员或安全团队是非常重要的。他们可以采取更加有效的
措施，如封禁 IP 地址、加强认证机制等，从而保障接口的安全。

系统监控和预警通知是保持系统稳定和可靠性的重要手段。通常，我们需要对系统的各种指标进行监控
和预警，如 CPU 使用率、内存使用率、磁盘空间、网络流量等等。当这些指标超过预设的阈值时，系
统就会触发警报，并通知相关人员进行处理。

对于系统的恶意狂刷，也可以基于 **时序进行** 统计和预警。

为了实现系统监控和预警通知，可以使用一些开源的工具，如 Prometheus、Grafana、Alertmanager
等等。

```
public void doFilter (ServletRequest request, ServletResponse response,
FilterChain chain)
throws IOException, ServletException {
HttpServletRequest httpRequest = (HttpServletRequest) request;
HttpServletResponse httpResponse = (HttpServletResponse) response;
String requestURI = httpRequest.getRequestURI ();
```
```
try {
log.info ("Request Received. URI: {}", requestURI);
chain.doFilter (request, response);
} catch (Exception e) {
log.error ("Exception occurred while processing request. URI: {}",
requestURI, e);
throw e;
} finally {
log.info ("Request Completed. URI: {} Response Status: {}", requestURI,
httpResponse.getStatus ());
}
}
```

其中，Prometheus 是一个广泛使用的监控系统，它支持多种数据源，如本地文件、HTTP、JMX、
SNMP 等等。

Grafana 则是一个可视化监控工具，它可以将 Prometheus 收集的数据进行可视化展示。

Alertmanager 则是一个通知管理器，它可以根据不同的警报级别和通知方式，将警报发送给不同的人
员或团队。

结合 Prometheus +Grafana +Alertmanager ，可以对 Java 接口被恶意狂刷 **进行时序统计** ，一旦超过
一定的阈值，比如 **1 分钟被狂刷 10 W 次** ，进行预警，方便开发和运维进行防范。

#### 说在最后：有问题可以找老架构取经

接口被狂刷 10 Wqps，怎么破？其实是一个 **架构问题** 。甚至是一个架构难题。

架构和高级开发不一样，架构的问题是 open 的、开发式的、没有标准答案的。高并发的架构之路，其
实是充满了坎坷。在做架构过程中，或者在转型过程中，如果遇到复杂的场景，确实不知道怎么做架构
方案，确实找不到有底的方案，怎么办？ 可以以来找 40 岁老架构尼恩求助.

就在前几天，一个小伙伴遇到了一个 **电商网站的黄金链路架构** ，开始找不到思路，但是经过尼恩 10 分
钟语音指导，一下就豁然开朗。

so，大家如果遇到架构问题，甚至架构难题，可以找尼恩来交流，来求助。

## B 站崩，唯品崩，大型网站如何做到高可用？

#### 说在前面

在 **40 岁老架构师尼恩** 的数千读者群中，一直在指导大家简历和职业升级。前几天，指导了一个 **华为老伙
伴** 的简历，小伙伴的优势在异地多活，但是在简历指导的过程中，尼恩发现： **异地多活的概念、异地多
活的架构、非常重要，但是小伙伴却对整个异地多活的体系，不是太清晰。**

而且，异地多活的架构非常重要， 3 月份出了两个大的线上事故，B 站刚崩，唯品会又崩了。

在这里，尼恩给自己的 Future Super Architect Community （未来超级架构师） 社区的小伙伴，梳
理一份顶级的解决方案。

主要的目标： 方便在架构指导的时候，作为参考资料。


当然，好知识不能独享，这份方案，顺便通过尼恩的自媒体渠道公布给大家，为大家做架构提供参考资
料。

也一并把这个方案作为系统高可用架构参考答案，收入咱们的《尼恩 Java 面试宝典》V 76，供后面的小
伙伴参考，提升大家的 3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，最新尼恩架构笔记、面试题的 PDF 文件，请从这里获取，公号：技
术自由圈。
```
#### 接二连三的 P 0 级事故（高可用事故）

```
3 月 5 日 B 站崩了
3 月 29 日唯品会又崩
```
###### P 0 级事故： 3 月 5 日 B 站崩了


3 月 5 日晚，尼恩的 Future Super Architect Community （未来超级架构师社区）中，有小伙伴发
现，从20:22分开始 B 站的服务器就处于状态，用户无法观看视频和刷新推荐内容。直至20:40左右才恢
复正常，持续时间近二十分钟。

**事故复盘**

B 站 APP 端，用户可以在有缓存的情况下打开首页，

在没有缓存的情况下，会得到的是报错提示，访问视频资源时无法正常加载页面。

Web 端主站的用户点击“换一换”无法正常刷新，多尝试几次会得到提示“暂时没有新内容了”。

**事故原因**

次日凌晨 2 点，B 站发布公告称，昨晚，B 站的部分服务器机房发生故障，造成无法访问。

技术团队随即进行了问题排查和修复，现在服务已经陆续恢复正常。


**影响范围**

以 B 站 6000 万的日活、晚 8 点是传统的视频用户高活跃期来看，本次事故影响的用户量级超千万。

以互联网企业常规的事故评判标准来看，应该属于 P 0 级事故，

对于这种严重的事故，主要 **技术负责人面临扣绩效甚至背锅走人** 的风险。

###### P 0 级事故： 3 月 29 日唯品会又崩

6.6 号，尼恩的 Future Super Architect Community （未来超级架构师社区）中，有小伙伴贴出来一
份唯品会的处罚公告。

小伙的问题是：大佬们说说，如何避免这种情况（P 0 级事故，负责人下课）。

**事故复盘**

3 月 29 日发生的突发事件，唯品会 App 崩了当天冲上热搜。


故障的现象：“加购”等功能或出现异常。

故障的时长： 12 小时。

6 月 6 日消息，唯品会发布了一份处理公告， 3 月 29 日唯品会 App 崩了的事故，判定为 P 0 级故障。


**什么是 P 0 级事故?**

P 0 属于最高级别事故，比如崩溃、页面无法访问、主流程不通、主功能未实现，或在影响面上影响很大
(即使 Bug 本身不严重)。

**官方在公告中称，此次南沙机房重大故障影响时间持续 12 个小时，导致公司业绩损失超亿元，影响客户
达 800 多万。**

唯品会表示，决定对此次事件严肃处理，对应部门的直接管理者承担此次事故责任。

关键是，主要 **技术负责人面临扣绩效甚至背锅走人** ：基础平台部负责人予以免职做相应处理。

```
事故等级主要针对生产环境，划分依据类似于 bug 等级。
```
```
P 0 级属于最高级别事故。比如崩溃，页面无法访问，主流程不通，主功能未实现，或者在影响面上影响很
大（即使 bug 本身不严重）。
```
```
P 1 级属于高级别事故。一般属于主功能上的分支，支线流程，核心次功能等
```
```
P 2 级属于中级别事故。主要根据企业实际情况划分。
```
```
P 3 级属于低级别事故。主要根据企业实际情况划分。
```
```
PN 级 ... 级别越高。
```

#### 架构师们，锅能不背么？

尼恩的 Future Super Architect Community （未来超级架构师） 社区中，有大量的架构师，很多都
是资深的 40 岁老架构师。

所以，尼恩的视角，不是关注 B 站、唯品会损失了多少亿。

而是关注的是咱们架构师的职业生涯，简单来说，就是一句话：

**架构师们，锅能不背么？**

这里，先把责任明确一下。

基础平台部负责人虽然是管理岗，本身也有一定的架构职责，所以，从一定意义上说，也是架构师。

当然，有的小伙伴会说，架构师就是技术军师、技术师爷，负责出方案，出主意的。基础平台部负责
人不是架构师。

如果一定要这么说，也行。

**既然老帅都丢了，军师会有好受的吗？ 同样要背锅走人** 。

所以，还是同一个问题：架构师们，当如何拜托背锅走人的宿命？

#### 什么是优秀的架构

如何不背锅呢？先得回到问题的本身。

尼恩为咱们的 Future Super Architect Community （未来超级架构师） 社区梳理过一个三高架构知
识宇宙，其中有一张价值十万的架构师知识图谱。

在尼恩的那个三高架构知识宇宙知识图谱中，有一个超级大的图，给大家揭示了一个好的软件架构，应
该遵循以下 3 个原则：

```
1. 高性能
2. 高并发
3. 高可用
```
```
该图谱的 url 链接地址，在尼恩很多圣经电子书 PDF 的最前面，在这里就不贴了
具体请参考尼恩的《Java 高并发核心编程卷 1 》《Java 高并发核心编程卷 2 》《Java 高并发核心
编程卷 3 》的 PDF 最前面。
```
###### 三高架构的三原则

**原则 1 ：高性能** 意味着系统拥有更大流量的处理能力，更低的响应延迟。

例如 1 秒可处理 10 W 并发请求，接口响应时间 5 ms 等等。

**原则 2 ：高并发** 表示系统在迭代新功能时，能以最小的代价去扩展，系统遇到流量压力时，可以在不改
动代码的前提下，去扩容系统。

**原则 3 ：高可用** 通常用 2 个指标来衡量：


```
系统可用性年故障时间日故障时间
```
```
90% (1 个 9) 36.5 天 2.4 小时
```
```
99% (2 个 9) 3.65 天 14 分钟
```
```
99.9% (3 个 9) 8 小时 86 秒
```
```
99.99%(4 个 9) 52 分钟 8.6 秒
```
```
99.999%(5 个 9) 5 分钟 0.86 秒
```
```
99.9999%(6 个 9) 32 秒 86 毫秒
```
```
平均故障间隔 MTBF （Mean Time Between Failure）：表示两次故障的间隔时间，也就是系统
「正常运行」的平均时间，这个时间越长，说明系统稳定性越高
故障恢复时间 MTTR （Mean Time To Repair）：表示系统发生故障后「恢复的时间」，这个值越
小，故障对用户的影响越小
```
可用性与这两者的关系：

```
可用性（Availability）= MTBF / (MTBF + MTTR) * 100%
```
这个公式得出的结果是一个比例，通常我们会用「N 个 9 」来描述一个系统的可用性。

从这张图，大家最好是能耳熟能详。

从图中，可以看到，要想达到 4 个 9 以上的可用性，一年的不可以时间为 52 分钟，平均每天故障时间
必须控制在 10 秒以内。

###### 什么是优秀的架构？

原则 1 告诉大家：要用最少的资源，得到最大的受益。

原则 2 告诉大家：要能高扩展、自伸缩，能够承担高吞吐、高并发，能够自动扩容缩容

原则 3 告诉大家： 一年的可用性要达到至少 4 个 9 ，不可用时间不能超过 52 分钟。

从这个角度来说，前面的 B 站事故、唯品会事故，都说明了一个问题：

**B 站、唯品会，都没有实现原则 3 的高可用： 高可用都没有达到 4 个 9 ，更不用说 5 个 9 。**

从这个维度来说： B 站、唯品会这么多人、这么大的技术团队，并没有做到架构的优秀。

他们的架构团队，到了应该好好反思的时刻了。

**是时候好好的反思了。**

#### 两个 P 0 级故障的根因分析


尼恩为咱们的 Future Super Architect Community （未来超级架构师） 社区的小伙伴，指导架构转
型和升级的时候，首先强调的是： **根因分析**

一般来讲，无论 B 站还是唯品会，单机房内部的链路，一定是高可用的。

为啥？那么多架构师，如果单机房内部的高可用架构都实现不了，那就白混了。

```
如果有读者确实不知道：怎么做单机房内部的高可用架构。
```
```
这个简单，看看 40 岁老尼恩的价值 10 W 架构师知识图谱，翻翻尼恩的博客，就大致知道了。
```
单机房内部高可用，有架构师保障。

而机房的高可用，由机房厂商保障： 建设一个机房的要求其实是很高的，地理位置、温湿度控制、备用
电源等等，机房厂商会在各方面做好防护。

关键是，怎么确保地域维度的不出现基础设施问题呢？

比如：

```
2015 年 5 月 27 日，杭州市某地光纤被挖断，近 3 亿用户长达 5 小时无法访问支付宝
2021 年 7 月 13 日，B 站部分服务器机房发生故障，造成整站持续 3 个小时无法访问
2021 年 10 月 9 日，富途证券服务器机房发生电力闪断故障，造成用户 2 个小时无法登陆、交易
2023 年 3 月 29 日，唯品会遭遇了一场灾难性的机房故障，南沙 IDC 冷冻系统故障导致机房设备温
度快速升高宕机，造成线上商城停止服务。事故影响时间持续 12 个小时，导致唯品会业绩损失超
亿元，影响客户达 800 多万
..... 都是 P 0 级事故
```
可见， **即使机房级别的防护已经做得足够好** ，但只要地域维度的基础设施问题（网络问题、电力问题、
地震问题、水灾问题），咱们的系统，也就不可用了。

如何解决地域维度的基础设施问题呢？

对比起，这个神也搞不定。

咱们作为应用架构师，在这块只能规避，只能规避，只能规避。

如何规避呢？ 核心的措施就是 ：异地多活。

#### 什么是异地多活

异地多活的概念很多，像什么同城双活、两地三中心、三地五中心等等概念。

要想理解异地多活，需要从架构设计的 3 高原则说起。

#### 常见的多活方案

4 个 9 高可用的核心方案就是异地多活

异地多活指分布在异地的多个站点同时对外提供服务的业务场景。

异地多活是高可用架构设计的一种，与传统的灾备设计的最主要区别在于“多活”，即所有站点都是同时
在对外提供服务的。


常见的多活方案有同城双活、两地三中心、三地五中心等多种技术方案，

#### 方案 1 ：同城双活

同城双活是在同城或相近区域内建立两个机房。

同城双机房距离比较近，通信线路质量较好，比较容易实现数据的同步复制，保证高度的数据完整性和
数据零丢失。

同城两个机房各承担一部分流量，一般入口流量完全随机，内部 RPC 调用尽量通过就近路由闭环在同机
房，相当于两个机房镜像部署了两个独立集群，数据仍然是单点写到主机房数据库，然后实时同步到另
外一个机房。

下图展示了同城双活简单部署架构，当然一般真实部署和考虑问题要远远比下图复杂。

服务调用基本在同机房内完成闭环，数据仍然是单点写到主机房数据储存，然后实时同步复制到同城备
份机房。

当机房 A 出现问题时候运维人员只需要通过 GSLB 或者其他方案手动更改路由方式将流量路由到 B 机房。

同城双活可有效用于防范火灾、建筑物破坏、供电故障、计算机系统及人为破坏引起的机房灾难。

同城双活中的核心组件 _GSLB_ 的原理，可以参见尼恩的高并三部曲之三《 _Java_ 高并发核心编程卷 _3_ 加强
版》 _PDF_ 。

###### 同城双活关键：

（ 1 ）如何双机房切流


（ 2 ） 如何保证数据一致性

**如何双机房切流**

那怎么让 B 机房也接入流量呢？

最为简单的措施，就是进行 DNS 切流。把 B 机房的接入层 IP 地址，加入到 DNS 中，这样，B 机房从
上层就可以有流量进来了。


**如何保证数据一致性**

业务应用在操作数据库时，需要区分「 **读写分离** 」, 假设 A 主 B 从，

```
「读」流量，可以读任意机房的存储，
「写」流量，只允许写 A 机房，因为主库在 A 机房。
然后进行 A -B 机房的数据同步
```

这种架构，涉及用的所有存储，例如项目中用到了 MySQL、Redis、MongoDB 等等，

操作这些数据库，都需要区分读写请求，所以这块需要一定的业务「改造」成本。

最好的方式： **是通过 proxy 中间组件，完成统一的读写改造。**

###### 为啥不是立即做到异城多活？

上面的方案，仅仅是同城多活，不是异城多活。

同城多活可以解决 **机房级别的不可抗拒灾难** ，但是 **地域级别的不可抗拒灾难** ，就没有办法搞定。

**同城多活的机房，放到两个城市，不就变成异城多活了吗？**

没有那么简单，来看看问题吧。

一般来说，多活机房的网络是通过「 **跨城专线** 」连通的。

如果两个机房距离较远，受到物理距离的限制，现在，两地之间的网络延迟就变成了「 **不可忽视** 」的因
素了。

比如：北京到上海的距离大约 1300 公里，即使架设一条高速的「网络专线」，光纤以光速传输，一个
来回也需要近 10 ms 的延迟。

况且，网络线路之间还会经历各种路由器、交换机等网络设备，实际延迟可能会达到 30 ms ~ 100 ms，
如果网络发生抖动，延迟甚至会达到 1 秒。

此时两个机房都接入流量，那上海机房的请求，可能要去读写北京机房的存储，这里存在一个很大的问
题： **网络延迟、用户体验差、数据存在丢失风险** 。

也就是说，如果是异城多活，距离太远，网络延迟太大。

这个时候，如果 A 机房挂了，而数据还没有完成同步，就会出现 1 秒的数据丢失。

再来个用户体验差的案例： 一个客户端请求打到上海机房，上海机房要去读写北京机房的存储，一次跨
机房访问延迟就达到了 30 ms，这大致是机房内网网络（0.5 ms）访问速度的 60 倍（30 ms /
0.5 ms），一次请求慢 60 倍，来回往返就要慢 100 倍以上。

而我们在 App 打开一个页面，可能会访问后端几十个 API，每次都跨机房访问，整个页面的响应延迟有
可能就达到了 **秒级** ，这个性能简直惨不忍睹，难以接受。

所以：

**同城多活的机房，放到两个城市，不就变成异城多活了吗？** 这种想法，太肤浅了。

#### 方案 2 ：两地三中心

所谓两地三中心是指同城双中心 + 异地灾备中心。

异地灾备中心是指在异地的城市建立一个备份的灾备中心，用于双中心的数据备份，数据和服务平时都
是冷的，


当双中心所在城市或者地区出现异常而都无法对外提供服务的时候，异地灾备中心可以用备份数据进行
业务的恢复。

**两地三中心方案特点**

优势

```
服务同城双活，数据同城灾备，同城不丢失数据情况下跨机房级别容灾。
架构方案较为简单，核心是解决底层数据双活，由于双机房距离近，通信质量好，底层储存
例如 mysql 可以采用同步复制，有效保证双机房数据一致性。
灾备中心能防范同城双中心同时出现故障时候利用备份数据进行业务的恢复。
```
劣势

```
数据库写数据存在跨机房调用，在复杂业务以及链路下频繁跨机房调用增加响应时间，影响
系统性能和用户体验。
服务规模足够大 (例如单体应用超过万台机器)，所有机器链接一个主数据库实例会引起连接
不足问题。
出问题不敢轻易将流量切往异地数据备份中心，异地的备份数据中心是冷的，平时没有流量
进入，因此出问题需要较长时间对异地灾备机房进行验证。
```
同城双活和两地三中心建设方案建设复杂度都不高，两地三中心相比同城双活有效解决了异地数据灾备
问题，但是依然不能解决同城双活存在的多处缺点，想要解决这两种架构存在的弊端就要引入更复杂的
解决方案去解决这些问题。

#### 方案 3 ：单元化+异地多活

阿里在实施这种方案时，给它起了个名字，叫做「 **单元化** 」。

单元化+异地多活结合的策略，是真正的异地多活策略，核心点有两个：

```
用户单元化
数据全局化
```

###### 什么是用户单元化

同一个用户只会落在同一个机房内。之后的所有业务操作，都在这一个机房内完成，从根源上避免「跨
机房」。

正常情况下，但用户的请求处理不会在两个机房「漂移」。

用户单元化的核心措施：要在最上层就把用户「区分」开，部分用户请求固定打到北京机房，其它用户
请求固定打到上海机房，进入某个机房的用户请求，之后的所有业务操作，都在这一个机房内完成，从
根源上避免「跨机房」。

安全起见，每个机房在写存储时，还需要有一套机制，能够检测「数据归属」，应用层操作存储时，需
要通过中间件来做「兜底」，避免不该写本机房的情况发生。

用户单元化之后，就可以进行用户分片。

分片的核心思路在于， **让同一个用户的相关请求，只在一个机房内完成所有业务「闭环」，不再出现
「跨机房」访问。**

###### 什么是数据全局化

多个机房，数据都是全量数据。

当然，也可以部分全量，部分进行分区域存储。

架构的本质，都不是一刀切。

如果一刀切，就违背了尼恩的 Future Super Architect Community （未来超级架构师） 社区的架构
精神。

怎么做到数据全局化呢？

多个机房在接收「读写」流量（做好分片的请求），底层存储保持「双向」同步，两个机房都拥有全量
数据

当任意机房故障时，另一个机房就可以「接管」全部流量，实现快速切换

###### 用户单元化场景的流量路由

单元化+异地多活策略中，在接入层之上，再部署一个「路由层」（通常部署在云服务器上）

流量路由层的职责，就是把用户「分流」到不同的机房内。


###### 多机房流量路由的规则

但这个路由规则，具体怎么定呢？

大致的路由规则有：

```
1. 按业务类型分片
2. 直接哈希分片
```

```
3. 按地理位置分片
```
**1 、按业务类型分片**

假设有 4 个应用，北京和上海机房都部署这些应用。

但应用 1 、 2 只在北京机房接入流量，在上海机房只是热备。

应用 3 、 4 只在上海机房接入流量，在北京机房是热备。

这样一来，应用 1 、 2 的所有业务请求，只读写北京机房存储，应用 3 、 4 的所有请求，只会读写上海
机房存储。


这里按业务类型在不同机房接入流量，还需要考虑多个应用之间的依赖关系，要尽可能的把完成「相
关」业务的应用部署在同一个机房，避免跨机房调用。

**2 、直接哈希分片**


比如路由层会根据用户 ID 计算「哈希」取模，然后从路由表中找到对应的机房，之后把请求转发到指
定机房内。

举例：一共 200 个用户，根据用户 ID 计算哈希值，然后根据路由规则，

用户 1 - 100 路由到北京机房，

用户 101 - 200 用户路由到上海机房，

这样，就避免了同一个用户修改同一条数据的情况发生。


**3 、按地理位置分片**

按地理位置分片方案，非常适合与地理位置密切相关的业务，例如打车、外卖服务就非常适合这种方
案。

卖肯定是「就近」点餐，整个业务范围相关的有商家、用户、骑手，它们都是在相同的地理位置内的。


针对这种特征，就可以在最上层，按用户的「地理位置」来做分片，分散到不同的机房。

举例：北京、河北地区的用户点餐，请求只会打到北京机房，而上海、浙江地区的用户，请求则只会打
到上海机房。这样的分片规则，也能避免数据冲突。

总之，


至此，我们才算实现了真正的「 **异地双活** 」！

```
到这里你可以看出，完成这样一套架构，需要投入的成本是巨大的。
路由规则、路由转发、数据同步中间件、数据校验兜底策略，不仅需要开发强大的中间件，同时
还要业务配合改造（业务边界划分、依赖拆分）等一些列工作，没有足够的人力物力，这套架构
很难实施。
```
#### 异地多活 3 大挑战

###### 1 、数据同步延迟挑战

（ 1 ）应用要走向异地，首先要面对的便是物理距离带来的延时。

如果某个应用请求需要在异地多个单元对同一行记录进行修改，为满足异地单元间数据库数据的一致性
和完整性，需要付出高昂的时间成本。

（ 2 ）解决异地高延时即要做到单元内数据读写封闭，不能出现不同单元对同一行数据进行修改，所以
我们需要找到一个维度去划分单元。

（ 3 ）某个单元内访问其他单元数据需要能正确路由到对应的单元，例如 A 用户给 B 用户转账，A 用户和 B
用户数据不在一个单元内，对 B 用户的操作能路由到相应的单元。

（ 4 ）面临的数据同步挑战，对于单元封闭的数据需全部同步到对应单元，对于读写分离类型的，我们
要把中心的数据同步到单元。

###### 2 、单元化解耦挑战

所谓单元 (下面我们用 RZone 代替)，是指一个能完成所有业务操作的自包含集合，在这个集合中包含了
所有业务所需的所有服务，以及分配给这个单元的数据。


单元化架构就是把单元作为系统部署的基本单位，在全站所有机房中部署数个单元，每个机房里的单元
数目不定，任意一个单元都部署了系统所需的所有的应用。

单元化架构下，服务仍然是分层的，不同的是每一层中的任意一个节点都属于且仅属于某一个单元，上
层调用下层时，仅会选择本单元内的节点。

选择什么维度来进行流量切分，要从业务本身入手去分析。

例如电商业务和金融的业务，最重要的流程即下单、支付、交易流程，通过对用户 id 进行数据切分拆分
是最好的选择，买家的相关操作都会在买家所在的本单元内完成。

对于商家相关操作则无法进行单元化，需要按照下面介绍的非单元化模式去部署。

当然用户操作业务并非完全能避免跨单元甚至是跨机房调用，例如两个买家 A 和 B 转账业务，A 和 B 所属
数据单元不一致的时候，对 B 进行操作就需要跨单元去完成，后面我们会介绍跨单元调用服务路由问
题。

###### 3 、流量的路由挑战

```
流量调度，系统部署过去后流量怎么跟着怎么过去。
流量自闭环。由于距离的原因，跨地域的物理延时是没法避免的，流量过去之后怎么保证所有的操
作都在本地完成，如果做不到那怎么将这种延时影响降到最低。
容灾切流。当某个机房出现故障时，如何快速把流量无损地切至其他机房。这里并不是说简单把流
量切过去就完事，由于数据在多区域同步，流量切过去之后能否保证数据的一致性？
```
#### 异地多活成功案例：得物 APP 的异地多活改造

看到前面那么多 P 0 级异地多活案例，咱们看看成功的案例吧：

高可用 100 Wqps 异地多活，得物是怎么架构的？

另外，此文的异地多活架构，和尼恩其他的架构文章一起，

组成一个架构知识系统，帮助大家实现你的 **架构自由** ：

《吃透 8 图 1 模板，人人可以做架构》

《10 Wqps 评论中台，如何架构？B 站是这么做的！！！》

《阿里二面：千万级、亿级数据，如何性能优化？教科书级答案来了》

《峰值 21 WQps、亿级 DAU，小游戏《羊了个羊》是怎么架构的？》

《 100 亿级订单怎么调度，来一个大厂的极品方案》

《 2 个大厂 100 亿级超大流量红包架构方案》

架构和高级开发不一样： 架构的问题是 open 的、开发式的、没有标准答案的。

架构之路，注定是充满了坎坷。


在做架构过程中，或者在转型过程中，如果遇到复杂的场景，确实不知道怎么做架构方案，确实找不到
有底的方案，怎么办？ 可以以来找 40 岁老架构尼恩求助.

就在前几天，一个小伙伴遇到了一个 **电商网站的黄金链路架构** ，开始找不到思路，但是经过尼恩 10 分
钟语音指导，一下就豁然开朗。

so，大家如果遇到架构问题，甚至架构难题，可以找尼恩来交流，来求助。

## 如果你当架构师，从 0 开始，如何做一个后台

## 项目的架构？

###### 前言

在 40 岁老架构师尼恩的 **读者交流群 (50+)** 中，很多小伙伴要拿高薪，这就要面试架构师，要完成架构的
升级，进入架构赛道。

在架构师的面试过程中，常常会遇到下面的问题：

```
如果给你一个项目要你从 0 到 1 做架构，需要从哪些方面展开
你是怎么做项目的架构的？
```
40 岁老架构师尼恩，不知道做过多少架构方案。目前尼恩已经专门从事架构师转型辅导 2 年了，也不知
道指导了多少开发完成了架构师的华丽转身。

现在，给大家提供一份比较全面的参考答案。使得大家可以充分展示一下大家雄厚的 “技术肌肉”， **让你
的主管、同事爱到 “不能自已、口水直流”** 。

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 74 版本，供后面的小伙伴参考，
提升大家的 3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，最新尼恩架构笔记、面试题的 PDF 文件，请从这里获取：码云
```
###### 总览一下：后台架构的 10 个维度

如何您是一名团队的技术负责人，如何从 0 搭建公司的后端技术栈。

作为 40 岁的老架构师，如果让我从零开始搭建公司的后端技术栈，我会按照以下步骤进行：


架构 1 ：团队协助基础工具链的选型和培训

架构 2 ：搭建微服务开发基础设施

架构 3 ：选择合适的 RPC 框架

架构 4 ：选择和搭建高可用的注册中心

架构 5 ：选择和搭建高可用的配置中心

架构 6 ：选择和搭建高性能的缓存中间件

架构 7 ：选择和搭建高性能的消息中间件

架构 8 ：选择和搭建高性能的关系数据库

架构 9 ：CICD 发布系统/部署系统的架构

架构 10 ： 360 度全方位监控和维护的架构

架构 11 ：生产环境高并发高吞吐负载均衡部署架构

整个后台技术架构，主要包括 4 个层面的内容：

```
语言：用了哪些开发语言，如：C++/Java/Go/PHP/Python/Ruby 等等；
组件：用了哪些组件，如：MQ 组件，数据库组件等等；
流程：怎样的流程和规范，如：开发流程，项目流程，发布流程，监控告警流程，代码规范等等；
系统：系统化建设，上面的流程需要有系统来保证，如：规范发布流程的发布系统，代码管理系统
等等；
结合以上的的 4 个层面的内容，
```
整个后台技术栈的结构如图所示：

图后台技术栈结构

咱们一个个系统和组件的做选型，最终形成我们的后台技术栈。

###### 团队协助基础工具链的选型和培训


团队协助基础工具链，主要是三大管理

```
项目管理
任务管理
问题管理
```
项目管理软件是整个业务的需求，问题，流程等等的集中地，大家的跨部门沟通协同大多依赖于项目管
理工具。

有一些 SaaS 的项目管理服务可以使用，但是很多时间不满足需求，此时我们可以选择一些开源的项
目，这些项目本身有一定的定制能力，有丰富的插件可以使用，一般的创业公司需求基本上都能得到满
足，常用的项目如下：

```
Jira：用 Java 开发的，有用户故事，task 拆分，燃尽图等等，可以做项目管理，也可以应用于跨
部门沟通场景，较强大；
Redmine：用 Ruby 开发的，有较多的插件可以使用，能自定义字段，集成了项目管理，Bug 问
题跟踪，WIKI 等功能，不过好多插件 N 年没有更新了；
Phabricator：用 PHP 开发的，Facebook 之前的内部工具，开发这工具的哥们离职后自己搞了一
个公司专门做这个软件，集成了代码托管， Code Review，任务管理，文档管理，问题跟踪等功
能，强烈推荐较敏捷的团队使用；
```
**40 岁老架构师尼恩的建议**

尼恩都用过，目前建议是 Jira

###### 搭建微服务开发基础设施

搭建微服务开发基础设施需要考虑多个方面，包括但不限于以下几点：

```
1. 选择合适的微服务框架和技术栈：目前比较流行的微服务框架有 Spring Cloud、Go-Micro、gRPC
等，选择适合自己团队技术栈的框架非常重要。
2. 选择合适的 RPC 框架
3. 构建基础设施：包括但不限于服务注册与发现、负载均衡、API 网关、分布式配置中心、分布式
锁、消息队列等。
4. 安全：包括但不限于服务间通信的加密、访问控制、身份认证等。
```
在搭建微服务开发基础设施之前，需要对自己的业务场景进行分析和规划，确定需要哪些基础设施和技
术栈，然后再逐步实现。同时，需要注重可扩展性和可维护性，以便在业务发展过程中能够快速适应变
化。

**选择合适的微服务框架和技术栈**

选择合适的微服务框架和技术栈需要考虑多个因素，包括以下几个方面：

```
1. 业务需求：不同的业务需求需要不同的技术栈和框架来支持。比如，如果需要高并发和高可用性，
可以选择使用 Go 语言和 Kubernetes 等技术来构建微服务。
2. 开发团队技能：选择的技术栈和框架应该符合开发团队的技能水平，以便开发人员能够快速上手并
高效开发。
```

```
3. 社区支持：选择流行的技术栈和框架可以获得更好的社区支持，能够更快地解决问题和获得更新的
功能。
4. 性能和稳定性：选择的技术栈和框架应该具有良好的性能和稳定性，以便能够支持高负载和长时间
运行。
```
常见的微服务框架和技术栈包括：

```
1. Spring Cloud：适用于 Java 开发团队，具有丰富的功能和社区支持。
2. Go Micro：适用于 Go 开发团队，具有高性能和简单易用的特点。
3. Node. js + Express：适用于 JavaScript 开发团队，具有轻量级和快速开发的特点。
4. Kubernetes：适用于需要高可用性和弹性的微服务架构，可以支持多种编程语言和框架。
5. Istio：适用于需要服务网格功能的微服务架构，可以提供流量管理、安全性和可观察性等功能。
```
在选择时，需要根据具体的业务需求和开发团队技能来选择合适的微服务框架和技术栈。

**40 岁老架构师尼恩的建议**

40 岁老架构师尼恩的建议，建议选用 SpringCloud Alibaba+ Dubbo RPC + Dubbo-Go，两个原因：

（ 1 ） 高性能： 尼恩的性能测试案例中， Dubbo 比 Feign 性能强 10 倍，具体请参见尼恩博客

（ 2 ） 兼顾团队技术栈： 可以跨 Go 和 Java 多语言微服务架构，Java 技术栈的同学们，可以基于 Java 开
发业务微服务，这块侧重业务开发。Go 技术栈的同学们，可以基于 Go 开发高性能的技术微服务，这
块侧重技术开发和性能优化。

（ 3 ）功能和性能兼顾： Java 侧重功能的快速开发， Go 侧重性能的快速提升。

**基于以上架构，尼恩指导了一个 6 年小伙伴，拿到了年薪 60 W 的 offer。**

###### 选择合适的 RPC 框架

维基百科对 RPC 的定义是：远程过程调用（Remote Procedure Call，RPC）是一个计算机通信协议。
该协议允许运行于一台计算机的程序调用另一台计算机的子程序，而程序员无需额外地为这个交互作用
编程。

通俗来讲，一个完整的 RPC 调用过程，就是 Server 端实现了一个函数，客户端使用 RPC 框架提供的接
口，调用这个函数的实现，并获取返回值的过程。

业界 RPC 框架大致分为两大流派，一种侧重跨语言调用，另一种是偏重服务治理。

**跨语言调用型 RPC ：**

跨语言调用型的 RPC 框架有 Thrift、gRPC、Hessian、Hprose 等。这类 RPC 框架侧重于服务的跨语言
调用，能够支持大部分的语言进行语言无关的调用，非常适合多语言调用场景。但这类框架没有服务发
现相关机制，实际使用时需要代理层进行请求转发和负载均衡策略控制。

其中，gRPC 是 Google 开发的高性能、通用的开源 RPC 框架，其由 Google 主要面向移动应用开发并
基于 HTTP/2 协议标准而设计，基于 ProtoBuf（Protocol Buffers）序列化协议开发，且支持众多开发
语言。本身它不是分布式的，所以要实现框架的功能需要进一步的开发。

Hprose（High Performance Remote Object Service Engine）是一个 MIT 开源许可的新型轻量级跨语
言跨平台的面向对象的高性能远程动态通讯中间件。

**冶理型 RPC ：**


**服务治理型的 RPC 框架** 的特点是功能丰富，提供高性能的远程调用、服务发现及服务治理能力，适用
于大型服务的服务解耦及服务治理，对于特定语言 (Java) 的项目可以实现透明化接入。缺点是语言耦合
度较高，跨语言支持难度较大。

国内常见的冶理型 RPC 框架如下：

Dubbo：Dubbo 是阿里巴巴公司开源的一个 Java 高性能优秀的服务框架，使得应用可通过高性能的
RPC 实现服务的输出和输入功能，可以和 Spring 框架无缝集成。当年在淘宝内部，Dubbo 由于跟淘宝
另一个类似的框架 HSF 有竞争关系，导致 Dubbo 团队解散，最近又活过来了，有专职同学投入。
DubboX：DubboX 是由当当在基于 Dubbo 框架扩展的一个 RPC 框架，支持 REST 风格的远程调用、
Kryo/FST 序列化，增加了一些新的 feature。Motan：Motan 是新浪微博开源的一个 Java 框架。它诞
生的比较晚，起于 2013 年， 2016 年 5 月开源。Motan 在微博平台中已经广泛应用，每天为数百个服
务完成近千亿次的调用。

rpcx：rpcx 是一个类似阿里巴巴 Dubbo 和微博 Motan 的分布式的 RPC 服务框架，基于 Golang
net/rpc 实现。

但是 rpcx 基本只有一个人在维护，没有完善的社区，使用前要慎重。

**40 岁老架构师尼恩的建议**

40 岁老架构师尼恩的建议，建议选用 Dubbo，两个原因：

（ 1 ） 高性能： 尼恩的性能测试案例中， Dubbo 比 Feign 性能强 10 倍，具体请参见尼恩博客

（ 2 ） 跨语言： 可以跨 Go 和 Java 进行双语言的 RPC 调用，从而实现多语言微服务架构。

###### 选择和搭建高可用的注册中心

名字发现和服务发现分为两种模式，一个是客户端发现模式，一种是服务端发现模式。框架中常用的服
务发现是客户端发现模式。

所谓服务端发现模式是指客户端通过一个负载均衡器向服务发送请求，负载均衡器查询服务注册表并把
请求路由到一台可用的服务实例上。现在常用的负载均衡器都是此类模式，常用于微服务中。

所有的名字发现和服务发现都要依赖于一个可用性非常高的服务注册表，业界常用的服务注册表有如下
三个：

etcd，一个高可用、分布式、一致性、key-value 方式的存储，被用在分享配置和服务发现中。两个著
名的项目使用了它：Kubernetes 和 Cloud Foundry。
Consul，一个发现和配置服务的工具，为客户端注册和发现服务提供了 API，Consul 还可以通过执行健
康检查决定服务的可用性。
Apache ZooKeeper，是一个广泛使用、高性能的针对分布式应用的协调服务。Apache ZooKeeper 本
来是 Hadoop 的子工程，现在已经是顶级工程了。
除此之外还有 eureka, nacos 等，大家可以根据相关的组件特性，选择适合自己的组件。

选择和搭建高可用的注册中心，需要考虑以下几个方面：

```
1. 功能需求：选择注册中心时，需要根据自己的业务需求来选择，比如服务发现、负载均衡、配置管
理等。
2. 性能要求：注册中心需要具备高性能，能够支持高并发、高吞吐量的请求。
3. 可用性要求：注册中心需要具备高可用性，能够保证 24 小时不间断运行，避免因为单点故障导致
整个系统不可用。
4. 安全要求：注册中心需要具备一定的安全性，能够保证数据的机密性和完整性，避免数据泄露和篡
改。
```

常见的注册中心有 ZooKeeper、Etcd、Consul 等，它们都具备高可用性和安全性，并且都支持服务发
现和配置管理等功能。其中，ZooKeeper 是最早的分布式协调服务，具备成熟的生态系统和广泛的应
用场景；Etcd 是 CoreOS 推出的开源分布式键值存储系统，具备高可用性和一致性保证；Consul 是
HashiCorp 推出的服务发现和配置管理工具，具备易用性和可扩展性。

在搭建高可用的注册中心时，需要采用集群部署的方式，避免单点故障。同时，为了保证数据的安全
性，可以启用 SSL/TLS 加密功能，并采用访问控制机制来限制访问权限。

**40 岁老架构师尼恩的建议**

尼恩都用过，目前建议是高可用的 nacos，也就是 nacos+mysql 的版本

具体请参见尼恩的架构笔记

###### 选择和搭建统一配置中心

随着程序功能的日益复杂，程序的配置日益增多：各种功能的开关、降级开关，灰度开关，参数的配
置、服务器的地址、数据库配置等等，除此之外，对后台程序配置的要求也越来越高：配置修改后实时
生效，灰度发布，分环境、分用户，分集群管理配置，完善的权限、审核机制等等，在这样的大环境
下，传统的通过配置文件、数据库等方式已经越来越无法满足开发人员对配置管理的需求，需要统一
的、基础的配置系统

统一配置系统是指在一个大型系统中，将所有的配置信息集中管理，以便于对系统进行管理和维护。常
见的统一配置系统架构包括以下几个组件：

```
1. 配置中心：用于存储和管理所有的配置信息，提供配置查询、修改、删除等功能。
2. 配置客户端：用于从配置中心获取配置信息，并将其应用到系统中。
3. 配置发布工具：用于将配置信息发布到配置中心，以便于配置客户端获取。
4. 配置管理工具：用于对配置信息进行管理和维护，包括配置的新增、修改、删除等操作。
5. 配置监控工具：用于监控配置信息的变化，及时发现并处理配置信息的异常情况。
```
在实际应用中，可以选择使用开源的配置中心工具，如 ZooKeeper、Etcd、Consul 、Nacos、Apollo
等，也可以自己开发一套配置中心系统。

同时，还需要根据实际情况选择合适的配置客户端和配置发布工具。在配置管理和监控方面，可以使用
一些开源的工具或者自己开发一套系统。总之，统一配置系统的架构需要根据实际需求进行设计和选
择。

**40 岁老架构师尼恩的建议**

尼恩都用过，目前建议是高可用的 nacos，也就是 nacos+mysql 的版本

具体请参见尼恩的架构笔记

###### 选择和搭建高性能的缓存中间件

选择和搭建高性能的缓存中间件需要考虑多个因素，包括性能、可靠性、可扩展性、易用性等。以下是
一些常见的高性能缓存中间件：


```
1. Redis：Redis 是一个开源的高性能缓存和键值存储系统，支持多种数据结构，包括字符串、哈
希、列表、集合和有序集合等。Redis 通过将数据存储在内存中来提高性能，同时支持数据持久化
和集群模式。
2. Memcached：Memcached 是一个开源的高性能分布式内存对象缓存系统，可以缓存任何可序列
化的数据，如数据库查询结果、API 响应等。Memcached 可以通过多个节点组成的集群来提高可
扩展性和可靠性。
3. Hazelcast：Hazelcast 是一个开源的分布式内存数据网格系统，支持缓存、分布式数据结构和分
布式计算等功能。Hazelcast 可以通过多个节点组成的集群来提高可扩展性和可靠性。
4. Couchbase：Couchbase 是一个开源的分布式 NoSQL 数据库和缓存系统，可以缓存任何类型的
数据，包括 JSON 文档、键值对和二进制数据等。Couchbase 支持多个节点组成的集群和数据持
久化等功能。
```
在搭建高性能缓存中间件时，需要考虑以下几个方面：

```
1. 硬件配置：缓存中间件需要占用大量内存，因此需要配置足够的内存和处理器资源。
2. 部署架构：需要考虑缓存中间件的部署架构，如单节点、主从复制、集群等。
3. 数据持久化：需要考虑数据持久化的方式，如内存快照、AOF 日志、RDB 文件等。
4. 安全性：需要考虑缓存中间件的安全性，如访问控制、数据加密等。
5. 监控和管理：需要考虑缓存中间件的监控和管理，如性能监控、故障诊断等。
```
总之，选择和搭建高性能缓存中间件需要综合考虑多个因素，根据具体需求和场景进行选择和配置。

**40 岁老架构师尼恩的建议**

尼恩都用过，目前建议是高可用的 redis cluster，具体请参见尼恩的架构笔记

要特别注意的是， redis 关系到系统的高可用，很容易出生产事故。

如果 redis 出现 bigkey，在高并发场景下，很容易出现系统瘫痪，严重影响系统的可用性，昨天有小
伙伴来求助，他们的 redis bigkey 问题，导致他们的系统瘫痪一小时，经济损失几百万，间接损失几千
万。


我在社群里边说了一下这个问题之后，还有两个小伙伴说，他们也遇到过，都是生产事故。


**如果对 big key 进行探测和解决，具体请参见尼恩的架构笔记**

###### 选择和搭建高性能的消息中间件

消息中间件在后台系统中是必不可少的一个组件，一般我们会在以下场景中使用消息中间件：

```
异步处理：
异步处理是使用消息中间件的一个主要原因，在工作中最常见的异步场景有用户注册成功后需要发
送注册成功邮件、缓存过期时先返回老的数据，然后异步更新缓存、异步写日志等等；通过异步处
理，可以减少主流程的等待响应时间，让非主流程或者非重要业务通过消息中间件做集中的异步处
理。
系统解耦：
比如在电商系统中，当用户成功支付完成订单后，需要将支付结果给通知 ERP 系统、发票系统、
WMS、推荐系统、搜索系统、风控系统等进行业务处理；这些业务处理不需要实时处理、不需要
强一致，只需要最终一致性即可，因此可以通过消息中间件进行系统解耦。通过这种系统解耦还可
以应对未来不明确的系统需求。
削峰填谷：
当系统遇到大流量时，监控图上会看到一个一个的山峰样的流量图，通过使用消息中间件将大流量
的请求放入队列，通过消费者程序将队列中的处理请求慢慢消化，达到消峰填谷的效果。最典型的
场景是秒杀系统，在电商的秒杀系统中下单服务往往会是系统的瓶颈，因为下单需要对库存等做数
据库操作，需要保证强一致性，此时使用消息中间件进行下单排队和流控，让下单服务慢慢把队列
中的单处理完，保护下单服务，以达到削峰填谷的作用。
```
业界消息中间件是一个非常通用的东西，大家在做选型时有使用开源的，也有自己造轮子的，甚至有直
接用 MySQL 或 Redis 做队列的，关键看是否满足你的需求.

选择合适的消息中间件需要考虑多个因素，包括但不限于：

```
需要处理的消息数量和频率
消息的大小和格式
可用性和容错性要求
数据安全性和加密需求
扩展性和灵活性要求
```

```
开发语言和技术栈的兼容性
常见的消息中间件包括 RocketMQ、Kafka、 RabbitMQ、Kafka、ActiveMQ、Redis、NATS 等，
每种中间件都有其特点和适用场景。
```
如果需要处理大量的消息并且需要高吞吐量和低延迟，可以考虑使用 Kafka。如果需要实时处理消息并
且需要高可用性和容错性，可以考虑使用 RabbitMQ。如果需要处理轻量级的消息，并且需要高性能和
低延迟，可以考虑使用 Redis。

在选择消息中间件时，需要根据具体的业务需求和技术栈进行综合考虑，选择最合适的中间件。

**40 岁老架构师尼恩的建议**

尼恩都用过，目前建议 kafka + RocketMQ

具体请参见尼恩的架构笔记 , 以及尼恩的穿透 RocketMQ 源码和架构的四部曲

###### 选择和搭建高性能的关系数据库

关系数据库分为两种，一种是传统关系数据，如 Oracle，MySQL，Maria，DB 2，PostgreSQL 等等，
另一种是 NewSQL，即至少要满足以下五点的新型关系数据库：

```
完整地支持 SQL，支持 JOIN / GROUP BY /子查询等复杂 SQL 查询。
支持传统数据标配的 ACID 事务，支持强隔离级别。
具有弹性伸缩的能力，扩容缩容对于业务层完全透明。
真正的高可用，异地多活、故障恢复的过程不需要人为的接入，系统能够自动地容灾和进行强一致
的数据恢复。
具备一定的大数据分析能力。
```
传统关系数据库用得最多的是 MySQL，成熟，稳定，一些基本的需求都能满足，在一定数据量级之前
基本单机传统数据库都可以搞定，而且现在较多的开源系统都是基于 MySQL，开箱即用，再加上主从
同步和前端缓存，百万 pv 的应用都可以搞定了。

不过 CentOS 7 已经放弃了 MySQL，而改使用 MariaDB。MariaDB 数据库管理系统是 MySQ L 的一个
分支，主要由开源社区在维护，采用 GPL 授权许可。开发这个分支的原因之一是：甲骨文公司收购了
MySQL 后，有将 MySQL 闭源的潜在风险，因此社区采用分支的方式来避开这个风险。

在 Google 发布了 F 1: A Distributed SQL Database That Scales 和 Spanner: Google’s Globally-
Distributed Databasa 之后，业界开始流行起 NewSQL。于是有了 CockroachDB，于是有了奇叔公司
的 TiDB。

国内已经有比较多的公司使用 TiDB，之前在创业公司时在大数据分析时已经开始应用 TiDB，当时应用
的主要原因是 MySQL 要使用分库分表，逻辑开发比较复杂，扩展性不够。

###### 选择和搭建高性能的 NoSQL

NoSQL 顾名思义就是 Not-Only SQL，也有人说是 No – SQL，个人偏向于 Not-Only SQL，它并不是用
来替代关系库，而是作为关系型数据库的补充而存在。

常见 NoSQL 有 4 个类型：

```
键值，适用于内容缓存，适合混合工作负载并发高扩展要求大的数据集，其优点是简单，查询速度
快，缺点是缺少结构化数据，常见的有 Redis，Memcache，BerkeleyDB 和 Voldemort 等等；
```

```
列式，以列簇式存储，将同一列数据存在一起，常见于分布式的文件系统，其中以 Hbase，
Cassandra 为代表。Cassandra 多用于写多读少的场景，国内用得比较多的有 360 ，大概 1500
台机器的集群，国外大规模使用的公司比较多，如 eBay，Instagram，Apple 和沃尔玛等等；
文档，数据存储方案非常适用承载大量不相关且结构差别很大的复杂信息。性能介于 kv 和关系数
据库之间，它的灵感来于 lotus notes，常见的有 MongoDB，CouchDB 等等；
图形，图形数据库擅长处理任何涉及关系的状况。社交网络，推荐系统等。专注于构建关系图谱，
需要对整个图做计算才能得出结果，不容易做分布式的集群方案，常见的有 Neo 4 J，InfoGrid
等。
```
除了以上 4 种类型，还有一些特种的数据库，如对象数据库，XML 数据库，这些都有针对性对某些存储
类型做了优化的数据库。

在实际应用场景中，何时使用关系数据库，何时使用 NoSQL，使用哪种类型的数据库，这是我们在做
架构选型时一个非常重要的考量，甚至会影响整个架构的方案。

###### CICD 发布系统/部署系统的架构

软件生产的层面看，代码到最终服务的典型流程如图所示：

从上图中可以看出，从开发人员写下代码到服务最终用户是一个漫长过程，整体可以分成三个阶段：

```
从代码（Code）到制品库（Artifact）这个阶段主要对开发人员的代码做持续构建，并把构建产生
的制品集中管理，是为部署系统准备输入内容的阶段。
从制品到可运行服务这个阶段主要完成制品部署到指定环境，是部署系统的最基本工作内容。
从开发环境到最终生产环境这个阶段主要完成一次变更在不同环境的迁移，是部署系统上线最终
服务的核心能力。
```
发布系统集成了制品管理，发布流程，权限控制，线上环境版本变更，灰度发布，线上服务回滚等几方
面的内容，是开发人员工作结晶最终呈现的重要通道。

CI/CD 发布系统/部署系统的架构通常包括以下组件：

```
源代码管理系统：例如 Git、SVN 等，用于管理代码库。
持续集成工具：例如 Jenkins、GitLab CI、Travis CI 等，用于自动化构建、测试和打包应用程序。
制品仓库：例如 Docker Hub、Harbor、Aliyun Container Registry 等，用于存储应用程序的镜
像。
```

```
部署工具：例如 Kubernetes、Docker Swarm、Mesos 等，用于自动化部署应用程序。
```
这些组件可以根据实际需求进行选择和组合，形成一个完整的 CI/CD 发布系统/部署系统。

其中，持续集成工具和部署工具是核心组件，它们负责自动化构建、测试、打包和部署应用程序，从而
实现快速、可靠、可重复的软件发布流程。

项目初期可以集成 Jenkins + Gitlab + Harbor，以上方案基本包括制品管理，发布流程，权限控制，线
上环境版本变更，灰度发布（需要自己实现），线上服务回滚等功能。

**代码管理工具选型**

代码是项目的命脉之一，代码管理很重要，常见的考量点包括两块：

安全和权限管理，将代码放到内网并且对于关系公司命脉的核心代码做严格的代码控制和机器的物理隔
离；
代码管理工具，Git 作为代码管理的不二之选，你值得拥有。

GitLab 是当今最火的开源 Git 托管服务端，没有之一，虽然有企业版，但是其社区版基本能满足我们大
部分需求，结合 Gerrit 做 Code review，基本就完美了。

当然 GitLab 也有代码对比，但没 Gerrit 直观。

Gerrit 比 GitLab 提供了更好的代码检查界面与主线管理体验，更适合在对代码质量有高要求的文化下
使用。

**持续集成工具选型**

持续集成简，称 CI（continuous integration），是一种软件开发实践，即团队开发成员经常集成他们
的工作，每天可能会发生多次集成。

每次集成都通过自动化的构建（包括编译，发布，自动化测试）来验证，从而尽早地发现集成错误。

持续集成为研发流程提供了代码分支管理/比对、编译、检查、发布物输出等基础工作，为测试的覆盖
率版本编译、生成等提供统一支持。

业界免费的持续集成工具中系统我们有如下一些选择：

Jenkins：Java 写的有强大的插件机制，MIT 协议开源 （免费，定制化程度高，它可以在多台机器上进
行分布式地构建和负载测试）。Jenkins 可以算是无所不能，基本没有 Jenkins 做不了的，无论从小型
团队到大型团队 Jenkins 都可以搞定。不过如果要大规模使用，还是需要有人力来学习和维护。

TeamCity：TeamCity 与 Jenkins 相比使用更加友好，也是一个高度可定制化的平台。但是用的人多
了，TeamCity 就要收费了。

Strider：Strider 是一个开源的持续集成和部署平台，使用 Node. js 实现，存储使用的是 MongoDB，
BSD 许可证，概念上类似 Travis 和 Jenkins。

GitLab CI：从 GitLab 8.0 开始，GitLab CI 就已经集成在 GitLab，我们只要在项目中添加一个 .gitlab-
ci. yml 文件，然后添加一个 Runner，即可进行持续集成。并且 GitLab 与 Docker 有着非常好的相互协
作的能力。

免费版与付费版本不同可以参见这里：https://about.gitlab.com/products/feature-comparison/。

Travis：Travis 和 GitHub 强关联；闭源代码使用 SaaS 还需考虑安全问题；不可定制；开源项目免费，
其它收费。
Go：Go 是 ThoughtWorks 公司最新的 Cruise Control 的化身。除了 ThoughtWorks 提供的商业支
持，Go 是免费的。它适用于 Windows，Mac 和各种 Linux 发行版。


**自动化测试平台的架构**

接下来，就是自动化测试平台的搭建。

搭建自动化测试平台需要考虑以下几个方面：

```
1. 选择合适的测试框架和工具：可以选择一些流行的测试框架和工具，如 Selenium、Appium、
JMeter 等，根据需要选择适合自己的工具。
2. 搭建测试环境：需要搭建测试环境，包括测试服务器、测试数据库、测试数据等。可以使用虚拟机
或者容器来搭建测试环境，以便进行测试。
3. 编写测试用例：需要编写测试用例，测试用例应该覆盖系统的各个功能点，以便发现潜在的问题。
4. 集成测试工具和测试用例：将测试工具和测试用例集成到自动化测试平台中，以便进行自动化测
试。
5. 运行测试用例：编写好测试用例后，需要运行测试用例，收集测试结果，并生成测试报告。
6. 定期维护和更新：自动化测试平台需要定期维护和更新，以保证测试环境的稳定性和测试用例的有
效性。
```
以上是搭建自动化测试平台的一般步骤，具体实现方式还需要根据实际情况进行调整。

可以结合 SpringBoot + TestNG 测试框架，搭建自己的自动化测试平台

TestNG 是一个开源自动化测试框架;

TestNG 灵感来自 JUnit 和 NUnit，但引入了一些新的功能，使其功能更强大，使用更方便。

TestNG 表示下一代 (Next Generation 的首字母)。

TestNG 类似于 JUnit (特别是 JUnit 4)，但它不是 JUnit 框架的扩展。它的目的是优于 JUnit ，尤其是在用
于测试集成多类时。

TestNG 的创始人是 Cedric Beust (塞德里克·博伊斯特)。

TestNG 消除了大部分的旧框架的限制，使开发人员能够编写更加灵活和强大的测试。因为它在很大程
度上借鉴了 Java 注解 ( JDK 5.0 引入的) 来定义测试，它也可以显示如何使用这个新功能在真实的 Java 语言
生产环境中。

40 岁老架构师尼恩提示，不用自己从 0 到 1 去搭建自动化测试平台，可以基于开源的自动化测试平台进
行改造。

下面的两个测试平台，就是非常好的改造项目：

```
接口自动化测试框架（java httpClient + testNg）
ChenSen 5/ api _ autotest
```
```
基于 SpringBoot 的高效模板化自动化测试框架
jinganglong 123/jg- api - autotest
```
###### 360 度全方位监控和维护的架构

360 度全方位监控和维护的架构包括

```
日志系统
监控系统
```

**日志系统**

日志系统一般包括打日志，采集，中转，收集，存储，分析，呈现，搜索还有分发等。

一些特殊的如 **染色** ，全链条跟踪或者监控都可能需要依赖于日志系统实现。

日志系统的建设不仅仅是工具的建设，还有规范和组件的建设，最好一些基本的日志在框架和组件层面
加就行了，比如全链接跟踪之类的。

对于常规日志系统 ELK 能满足大部分的需求，ELK 包括如下组件：

ElasticSearch 是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，
索引副本机制，RESTful 风格接口，多数据源，自动搜索负载等。

Logstash 是一个完全开源的工具，它可以对你的日志进行收集、分析，并将其存储供以后使用。
Kibana 是一个开源和免费的工具，它可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web
界面，可以帮助汇总、分析和搜索重要数据日志。

Filebeat 已经完全替代了 Logstash-Forwarder 成为新一代的日志采集器，同时鉴于它轻量、安全等特
点，越来越多人开始使用它。

因为免费的 ELK 没有任何安全机制，所以这里使用了 Nginx 作反向代理，避免用户直接访问 Kibana 服
务器。

加上配置 Nginx 实现简单的用户认证，一定程度上提高安全性。

另外，Nginx 本身具有负载均衡的作用，能够提高系统访问性能。

ELK 架构如图所示：

ELK 流程图


对于有实时计算的需求，可以使用 Flume + Kafka + Storm + MySQL 方案，一般架构如图所示：

实时分析系统架构图

其中：

Flume 是一个分布式、可靠、和高可用的海量日志采集、聚合和传输的日志收集系统，支持在日志系统
中定制各类数据发送方，用于收集数据；同时，Flume 提供对数据进行简单处理，并写到各种数据接受
方（可定制）的能力。
Kafka 是由 Apache 软件基金会开发的一个开源流处理平台，由 Scala 和 Java 编写。其本质上是一个
“按照分布式事务日志架构的大规模发布/订阅消息队列”，它以可水平扩展和高吞吐率而被广泛使用。

Kafka 追求的是高吞吐量、高负载，Flume 追求的是数据的多样性，二者结合起来简直完美。

**监控系统**

监控系统只包含与后台相关的，这里主要是两块，一个是操作系统层的监控，比如机器负载，IO，网络
流量，CPU，内存等操作系统指标的监控。

另一个是服务质量和业务质量的监控，比如服务的可用性，成功率，失败率，容量，QPS 等等。

常见业务的监控系统先有操作系统层面的监控（这部分较成熟），然后扩展出其它监控，如 Zabbix，
小米的 Open-Falcon，也有一出来就是两者都支持的，如 Prometheus。

如果对业务监控要求比较高一些，在创业选型中建议可以优先考虑 Prometheus。


这里有一个有趣的分布，如图 6 所示。

图 6 ，监控系统分布

亚洲区域使用 Zabbix 较多，而美洲和欧洲，以及澳大利亚使用 Prometheus 居多，换句话说，英文国
家地区（发达国家？）使用 Prometheus 较多。

Prometheus 是由 SoundCloud 开发的开源监控报警系统和时序列数据库（TSDB）。

Prometheus 使用 Go 语言开发，是 Google BorgMon 监控系统的开源版本。

相对于其它监控系统使用的 push 数据的方式，Prometheus 使用的是 pull 的方式，其架构如图 7 所
示：


图 7 ，Prometheus 架构图

如上图所示，Prometheus 包含的主要组件如下：

Prometheus Server 主要负责数据采集和存储，提供 PromQL 查询语言的支持。

Server 通过配置文件、文本文件、ZooKeeper、Consul、DNS SRV Lookup 等方式指定抓取目标。

根据这些目标会，Server 定时去抓取 metrics 数据，每个抓取目标需要暴露一个 http 服务的接口给它
定时抓取。

客户端 SDK：官方提供的客户端类库有 Go、Java、Scala、Python、Ruby，其他还有很多第三方开发
的类库，支持 Nodejs、PHP、Erlang 等。

Push Gateway 支持临时性 Job 主动推送指标的中间网关。

Exporter Exporter 是 Prometheus 的一类数据采集组件的总称。它负责从目标处搜集数据，并将其转
化为 Prometheus 支持的格式。

与传统的数据采集组件不同的是，它并不向中央服务器发送数据，而是等待中央服务器主动前来抓取。

Prometheus 提供多种类型的 Exporter 用于采集各种不同服务的运行状态。目前支持的有数据库、硬
件、消息中间件、存储系统、HTTP 服务器、JMX 等。

Alertmanager：是一个单独的服务，可以支持 Prometheus 的查询语句，提供十分灵活的报警方式。
Prometheus HTTP API 的查询方式，自定义所需要的输出。

Grafana 是一套开源的分析监视平台，支持 Graphite，InfluxDB，OpenTSDB，Prometheus，
Elasticsearch，CloudWatch 等数据源，其 UI 非常漂亮且高度定制化。

创业公司选择 Prometheus + Grafana 的方案，再加上统一的服务框架（如 gRPC），可以满足大部分
中小团队的监控需求。

###### 生产环境高并发高吞吐负载均衡部署架构

高并发高吞吐负载均衡链路架构, 包括：


```
DNS 的选型和使用设计
LB（负载均衡）的选型和使用设计
CDN 的选型和使用设计
```
**DNS 的选型和使用设计**

DNS 是一个很通用的服务，创业公司基本上选择一个合适的云厂商就行了，国内主要是两家：

阿里万网：阿里 2014 年收购了万网，整合了其域名服务，最终形成了现在的阿里万网，其中就包含
DNS 这块的服务；

腾讯 DNSPod：腾讯 2012 年以 4000 万收购 DNSPod 100% 股份，主要提供域名解析和一些防护功
能；

如果你的业务是在国内，主要就是这两家，选一个就好，像今日头条这样的企业用的也是 DNSPod 的
服务，除非一些特殊的原因才需要自建，比如一些 CDN 厂商，或者对区域有特殊限制的。

要实惠一点用阿里最便宜的基础版就好了，要成功率高一些，还是用 DNSPod 的贵的那种。

在国外还是选择亚马逊吧，阿里的 DNS 服务只有在日本和美国有节点，东南亚最近才开始部点，
DNSPod 也只有美国和日本，像一些出海的企业，其选择的云服务基本都是亚马逊。

如果是线上产品，DNS 强烈建议用付费版，阿里的那几十块钱的付费版基本可以满足需求。如果还需要
一些按省份或按区域调试的逻辑，则需要加钱，一年也就几百块，省钱省力。

如果是国外，优先选择亚马逊，如果需要国内外互通并且有自己的 APP 的话，建议还是自己实现一些
容灾逻辑或者智能调度，因为没有一个现成的 DNS 服务能同时较好的满足国内外场景，或者用多个域
名，不同的域名走不同的 DNS 。

**LB（负载均衡）的选型和使用设计**

LB（负载均衡）是一个通用服务，一般云厂商的 LB 服务基本都会如下功能：

支持四层协议请求（包括 TCP、UDP 协议）；
支持七层协议请求（包括 HTTP、HTTPS 协议）；
集中化的证书管理系统支持 HTTPS 协议；
健康检查；
如果你线上的服务机器都是用的云服务，并且是在同一个云服务商的话，可以直接使用云服务商提供的
LB 服务，如阿里云的 SLB，腾讯云的 CLB，亚马逊的 ELB 等等。如果是自建机房基本都是 LVS +
Nginx。

**CDN 的选型和使用设计**

CDN 现在已经是一个很红很红的市场，基本上只能挣一些辛苦钱，都是贴着成本在卖。国内以网宿为
龙头，他们家占据整个国内市场份额的 40% 以上，后面就是腾讯，阿里。网宿有很大一部分是因为直
播的兴起而崛起。

国外，Amazon 和 Akamai 合起来占比大概在 50%，曾经的国际市场老大 Akamai 拥有全球超一半的份
额，在 Amazon CDN 入局后，份额跌去了将近 20%，众多中小企业都转向后者，Akamai 也是无能为
力。

国内出海的 CDN 厂商，更多的是为国内的出海企业服务，三家大一点的 CDN 服务商里面也就网宿的节
点多一些，但是也多不了多少。阿里和腾讯还处于前期阶段，仅少部分国家有节点。

就创业公司来说，CDN 用腾讯云或阿里云即可，其相关系统较完善，能轻松接入，网宿在系统支持层
面相对较弱一些，而且还贵一些。并且，当流量上来后，CDN 不能只用一家，需要用多家，不同的
CDN 在全国的节点覆盖不一样，而且针对不同的客户云厂商内部有些区分客户集群，并不是全节点覆
盖（但有些云厂商说自己是全网节点），除了节点覆盖的问题，多 CDN 也在一定程度上起到容灾的作
用。


#### 说在最后：有问题可以找老架构取经

架构之路，充满了坎坷

架构和高级开发不一样，架构的问题是 open 的，开发式的，没有标准答案的

在做架构过程中，或者在转型过程中，如果遇到复杂的场景，确实不知道怎么做架构方案，确实找不到
有底的方案，怎么办？

可以来找 40 岁老架构尼恩求助.

昨天一个小伙伴，他们要进行 **电商网站的黄金链路架构** ，开始找不到思路，但是经过尼恩 10 分钟语音
指导，一下就豁然开朗。

#### 参考文章：

https://www.zhihu.com/question/29270034/answer/46446911

https://cloud.tencent.com/developer/article/1451239

https://www.cnblogs.com/jobs2/p/3301955.html

https://blog.csdn.net/get_set/article/details/79492439

https://blog.csdn.net/crazymakercircle/article/details/128899176

https://blog.csdn.net/crazymakercircle/article/details/124120506

## 10 亿级用户，如何做熔断降级架构？微信和

## hystrix 的架构对比

#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，最近有小伙伴拿到了一线互联网企业如极兔、有赞、希
音、百度、网易、滴滴的面试资格，遇到一几个很重要的面试题：

```
(1) 什么是熔断，降级？如何实现？
```
```
(2 ) 服务熔断，解决灾难性雪崩效应的有效利器
(3 ）说一下限流、熔断、高可用
```
```
等等等等......
```
**熔断，降级，防止雪崩，是面试的重点和高频点。** 尼恩作为技术中台、数据中台的架构师，致力于为大
家研究出一个 **3 高架构知识宇宙** ，所以这里，结合亿级 qps 微信后台是如何熔断降级方案，带大家完成
一个亿级用户场景，如何一步一步，进行熔断，降级，防止雪崩架构。

当然，作为一篇文章，仅仅是抛砖引玉，后面有机会，带大家做一下这个高质量的实操，并且指导大家
写入简历。

**让面试官爱到 “不能自已、口水直流”** 。


也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 86 版本，供后面的小伙伴参考，
提升大家的 3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，最新尼恩架构笔记、面试题的 PDF 文件，请从公众号 【技术自由
圈】获取。
```
#### 亿级 qps 微信后台是如何熔断降级，防止崩溃的？

微信作为 **月活过 10 亿** 的国民级应用，是中国最受欢迎的社交网络平台之一，拥有庞大的用户群体和广泛
的社交功能，包括朋友圈、微信支付、小程序、公众号等。

同时，微信也在不断地进行创新和扩展，如推出微信小程序、微信支付海外版等，以满足不同用户的需
求。

微信的日活用户数量一直在增长，截至 2022 年第一季度，微信的日活用户数量已经达到了 10 亿

微信的月活用户数量也在不断增长，截至 2022 年第三季度，微信的月活用户数量已经达到了 13.09 亿

微信作为当之无愧的国民级应用，系统复杂程度超乎想象：

```
其后台由三千多个移动服务构成，
每天需处理大约十的 10~11 次方个外部请求，
整体需要每秒处理大约几亿个请求！亿级 QPS 吞吐量规模
```
作为顶级、超级互联网应用，微信和其他的分布式、微服务应用一样，经常面临特殊节点消息量暴增的
问题，服务很容易出现过载问题。

但微信的服务一直比较稳定，是如何做到的呢？

尼恩带着大家，从降级保护的基本原理讲起。

**并且将微信和 hystrix、sentinel 对比介绍。**

#### 降级保护的基本原理

###### 什么是降级？

所谓降级，一般指整体的资源即将耗尽，为了保留关键的服务， **舍弃非核心的服务** 。

**核心链路** 又称 **黄金链路** 。

黄金链路是团队的生命线链路，由最核心的应用，最关键的 DB，最需要死保的接口，支撑的最核心业
务。

黄金链路的治理就一个目标： **不要让非核心的东西影响了核心的** 。

这里的“东西”包括业务、系统、DB 等等

###### 降级保护的几个核心策略

```
资源隔离
限流降级
```

```
超时降级
故障降级
失败次数降级
熔断降级
分层分级细粒度高精准降级
```
###### 资源隔离

所谓资源隔离，就是隔离黄金链路和非核心链路，对非核心链路进行降级，对黄金链路进行保
护。

具体来说，对黄金链路上的，每一个服务乃至其对应的数据库，分配独立的服务器资源、网络资源、数
据库资源，进行独立部署就行！

对黄金链路进行资源重点投入，做好链路的高并发、高性能、高可用设计。

这样，当非核心链路某个服务出现了故障，就不会影响到黄金链路，达到一种物理层面上的隔离！

资源隔离是一种隐性的降级策略，为什么叫做隐性而不是显性呢？

资源隔离相当于对不同的链路分级对待，对非核心链路，本质是一种降级处理。

###### 限流降级

当访问量太大而导致系统崩溃时，使用限流来进行限制访问量，当达到限流阀值，后续请求会被降级。

限流降级，兜底的处理方案可以是：

```
排队页面
错误页等
```
###### 超时降级

超时降级是当某个微服务响应时间过长，超过了正常的响应时长，我们不能让他一直卡在那里，所以要
在准备一个兜底的策略，当发生这种问题的时候，我们直接调用一个降级方法来快速返回，不让他一直
卡在那。

超时降级的策略为：

```
配置好超时时间和超时重试次数
失败后调用降级方法，拿到降级的结果返回
随后的请求快速失败，
并且使用异步机制，探测恢复情况。一直到接口回复。
```
###### 失败次数降级


失败次数降级是当某个微服务总是调用失败，我们不能让他一直失败，所以要在准备一个兜底的策略，
当发生这种问题的时候，我们直接调用一个降级方法来快速返回，不让他一直卡在那。

失败降级的策略为：

```
主要是一些不稳定的 api，当失败调用次数达到一定阀值自动降级，
降级后的数据，可以是默认值（比如库存服务挂了，返回默认现货）、兜底数据（比如广告挂了，
返回提前准备好的一些静态页面）、缓存（之前暂存的一些缓存数据）
同样要使用异步机制探测回复情况。
```
###### 熔断降级（过载保护）

互联网应用，天生就会有突发流量。

秒杀、抢购、突发大事件、节日甚至恶意攻击等，都会造成服务承受平时数倍的压力。

比如，微博经常出现某明星官宣结婚或者离婚导致服务器崩溃的场景，这就是服务过载。

服务过载是什么意思呢？

就是服务的请求量，超过服务所能承受的最大值，从而导致服务器负载过高，响应延迟加大。

下游客户端的表现：RT 响应时间变长，加载缓慢，甚至无法加载。

**服务过载的存在级联效应：**

**下游会进一步的重试，导致上游服务一直在处理无效请求，导致有效请求跌 0 ，甚至导致整个系统产生
雪崩。**

熔断就像是家里的保险丝一样，当电流达到一定条件时，比如保险丝能承受的电流是 5 A，如果电流达到
了 6 A，因为保险丝承受不了这么高的电流，保险丝就会融化，电路就会断开，起到了保护电器的作用；

在微服务里面也是一样，当下游的服务因为某种原因突然变得不可用或响应过慢，上游服务为了保证自
己整体服务的可用性，不再继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢
复调用；

所以，在互联网应用中，由于某些原因使得服务出现了过载现象，为防止造成整个系统故障，从而采用
的一种熔断降级（过载保护）措施。

**过载保护的好处**

服务过载容易导致系统瘫痪，系统雪崩，系统雪崩就意味着用户流失、口碑变差、导致巨大的经济损失
（亿级以上），和巨大的品牌损失（无法估量）。

提升用户体验、保障服务质量。在发生突发流量时仍然能够提供一部分服务能力，而不是整个系统瘫
痪，

**如何判断过载**


通常判断过载的方式很多，比如：

```
使用吞吐量判断过载
使用访问延迟判断过载
使用 CPU 使用率判断过载
使用丢包率判断过载
使用失败率判断过载
使用待处理请求数判断过载
使用请求处理事件判断过载。
请求在队列中的平均等待时间判断过载。
```
Hystrix 、Sentinel 主要使用使用失败率判断过载

微信使用请求在队列中的平均等待时间判断过载，并且进行分级分层细粒度熔断降级策略。

#### 降级保护的主流架构方案

在大规模分布式微服务应用中，主流的架构方案有

```
基于 Hystrix 熔断降级、限流降级架构方案
基于 Sentinel 熔断降级、限流降级架构方案
```
#### Hystrix 熔断降级、限流降级

Spring Cloud Hystrix 是一款优秀的服务容错与保护组件，也是 Spring Cloud 中最重要的组件之一。
Spring Cloud Hystrix 是基于 Netflix 公司的开源组件 Hystrix 实现的，它提供了熔断器功能，能够有效
地阻止分布式微服务系统中出现联动故障，以提高微服务系统的弹性。

Spring Cloud Hystrix 具有服务降级、服务熔断、线程隔离、请求缓存、请求合并以及实时故障监控等
强大功能。

```
Hystrix [hɪst'rɪks]，中文含义是豪猪，豪猪的背上长满了棘刺，使它拥有了强大的自我保护能
力。而 Spring Cloud Hystrix 作为一个服务容错与保护组件，也可以让服务拥有自我保护的能
力，因此也有人将其戏称为“豪猪哥”。
```
熔断器（Circuit Breaker）一词来源物理学中的电路知识，它的作用是当线路出现故障时，迅速切断电
源以保护电路的安全。

在微服务领域，熔断器最早是由 Martin Fowler 在他发表的《Circuit Breaker》一文中提出。与物理学
中的熔断器作用相似，微服务架构中的熔断器能够在某个服务发生故障后，向服务调用方返回一个符合
预期的、可处理的降级响应（FallBack），而不是长时间的等待或者抛出调用方无法处理的异常。这样
就保证了服务调用方的线程不会被长时间、不必要地占用，避免故障在微服务系统中的蔓延，防止系统
雪崩效应的发生。

hystrix 通过命令模式，将每个请求封装成一个 Command，每个类型的 Command 对应一个线程池 （例
如商品服务 Command）


请求过来，为请求创建 Command

如果 Command 开启了缓存 (配置的一个参数) ，会先向 requestCache 查询调用服务的结果，如果有直接
返回

每个 Command 执行完会上报自己的执行结果状态给熔断器 Circuit breaker，状态包括：成功，失败，
超时，拒绝等，熔断器会统计这些数据，来决定是否降级：

```
如果一个 Command 执行报错或者超时会直接做 fallback 降级处理。
如果熔断器已经开启了，那么所有的请求都直接做降级处理
如果同一类型 Command 的线程池或信号量已经满了，再来的请求会直接做 fallback 降级
```
在微服务系统中，Hystrix 能够帮助我们实现以下目标：

```
Hystrix 限流降级
Hystrix 异常降级
Hystrix 资源隔离降级
Hystrix 熔断降级（过载保护）
```
#### Hystrix 限流降级

同样是 A 服务调用 B 服务，服务 A 的连接已超过自身能承载的最大连接数，比如说 A 能承载的连接数为 5 ，
但是目前的并发有 6 个请求同时进行，前 5 请求能正常请求，最后一个会直接拒绝，执行 fallback 降级逻
辑；

Hystrix 支持线程池或者信号量限流，只要线程池满，或者无限号，就进行限流降级，返回降级后的兜
底结果。


hystrix 可以使用信号量和线程池来进行限流。

**线程池限流**

```
hystrix 也可以使用线程池进行限流，在提供服务的方法上加下面的注解
```
这里要注意：queueSizeRejectionThreshold 建议大于 maxQueueSize

在 java 的线程池中，如果线程数量超过 coreSize，创建线程请求会优先进入队列，如果队列满了，
就会继续创建线程直到线程数量达到 maximumSize，之后走拒绝策略。

但在 hystrix 配置的线程池中多了一个参数 queueSizeRejectionThreshold，如果
queueSizeRejectionThreshold < maxQueueSize, 队列数量达到 queueSizeRejectionThreshold
就会走拒绝策略了，因此 maximumSize 失效了。

如果 queueSizeRejectionThreshold > maxQueueSize, 队列数量达到 maxQueueSize 时，
maximumSize 是有效的，系统会继续创建线程直到数量达到 maximumSize。

**信号量限流**

```
hystrix 可以使用信号量进行限流，比如在提供服务的方法上加下面的注解。
```
这样只能有 20 个并发线程来访问这个方法，超过的就被转到了 errMethod 这个降级方法。

```
@HystrixCommand (
commandProperties = {
@HystrixProperty (name = "execution. isolation. strategy", value =
"THREAD")
},
threadPoolKey = "createOrderThreadPool",
threadPoolProperties = {
@HystrixProperty (name = "coreSize", value = "20"),
@HystrixProperty (name = "maxQueueSize", value = "100"),
@HystrixProperty (name = "maximumSize", value = "30"),
@HystrixProperty (name = "queueSizeRejectionThreshold", value =
"120")
},
fallbackMethod = "errMethod"
)
```

#### Hystrix 异常降级

hystrix 降级时可以忽略某个异常，在方法上加上@HystrixCommand 注解：

下面的代码定义降级方法是 errMethod，对 ParamErrorException 和 BusinessTypeException 这两
个异常不做降级处理。

#### Hystrix 调用超时降级

专门针对调用第三方接口超时降级。

同样是 A 服务调用 B 服务，B 服务响应超过了 A 服务设定的阈值后，就会执行降级逻辑；

下面的方法是调用第三方接口 3 秒未收到响应就降级到 errMethod 方法。

```
@HystrixCommand (
commandProperties= {
@HystrixProperty (name="execution. isolation. strategy", value="SEMAPHORE"),
@HystrixProperty (name="execution. isolation. semaphore. maxConcurrentRequests",
value="20")
},
fallbackMethod = "errMethod"
)
```
```
@HystrixCommand (
fallbackMethod = "errMethod",
ignoreExceptions = {ParamErrorException. class, BusinessTypeException. class}
)
```
```
@HystrixCommand (
commandProperties = {
@HystrixProperty (name="execution. timeout. enabled", value="true"),
```
```
@HystrixProperty (name="execution. isolation. thread. timeoutInMilliseconds",
value="3000"),
},
fallbackMethod = "errMethod"
)
```

#### Hystrix 资源隔离

前面讲到： 资源隔离相当于对不同的链路分级对待，对非核心链路，本质是一种降级处理。

Hystrix 里面核心的一项功能，其实就是所谓的 **资源隔离** ，要解决的最最核心的问题，就是将多个依赖
服务的调用分别隔离到各自的资源池内。

一旦说某个服务的线程资源全部耗尽的话，就可能导致服务崩溃，甚至说这种故障会不断蔓延。Hystrix
资源隔离避免，就是对某一个依赖服务的调用，因为依赖服务的接口调用的延迟或者失败，导致服务所
有的线程资源全部耗费在这个服务的接口调用上。

Hystrix 实现资源隔离，主要有两种技术：

```
线程池
信号量
```
默认情况下，Hystrix 使用线程池模式。

###### 线程池隔离 (舱壁模式)

线程池隔离，本质上来说，就是舱壁模式。

船舶工业上为了使船不容易沉没，使用舱壁将船舶划分为几个部分，以便在船体遭到破坏的情况下可以
将船舶各个部件密封起来。

泰坦尼克号沉没的主要原因之一： **就是其舱壁设计不合理** ，水可以通过上面的甲板进入舱壁的顶部，导
致整个船体淹没。

在 RPC 调用过程中，使用舱壁模式可以保护有限的系统资源不被耗尽。

在一个基于微服务的应用程序中，通常需要调用多个微服务提供者的接口才能完成一个特定任务。不使
用舱壁模式，所有的 RPC 调用都从同一个线程池中获取线程，一个具体的实例如图 6-4 所示。

在该实例中，微服务提供者 Provider A 对依赖 Provider B、Provider C、Provider D 的所有 RPC 调用都从
公共的线程池中获取线程。


图 6-4 公共的 RPC 线程池

在高服务器请求的情况下，对某个性能较低的微服务提供者的 RPC 调用很容易“霸占”整个公共的 RPC 线
程池，对其他性能正常的微服务提供者的 RPC 调用往往需要等待线程资源的释放。最后，整个 Web 容器
（Tomcat）会崩溃。现在假定 Provider A 的 RPC 线程个数为 1000 ，而并发量非常大，其中有 500 个线程
来执行 Provider B 的 RPC 调用，如果 Provider B 不小心宕机了，那么这 500 个线程都会超时，此时剩下的
服务 Provider C、Provider D 的总共可用的线程为 500 个，随着并发量的增大，剩余的 500 个线程估计也
会被 Provider B 的 RPC 耗尽，然后 Provider A 进入瘫痪，最后导致整个系统的所有服务都不可用，这就
是服务的雪崩效应。

为了最大限度地减少 Provider 之间的相互影响，一个很好的做法是对于不同的微服务提供者设置不同的
RPC 调用线程池，让不同 RPC 通过专门的线程池请求到各自的 Provider 微服务提供者，像舱壁一样对
Provider 进行隔离。对于不同的微服务提供者设置不同的 RPC 调用线程池，这种模式就叫作舱壁模式，
如图 6-5 所示。

图 6-5 舱壁模式的 RPC 线程池


使用舱壁模式可以避免对单个 Provider 的 RPC 消耗掉所有资源，从而防止由于某一个服务性能底而引起
的级联故障和雪崩效应。在 Provider A 中，假定对服务 Provider B 的 RPC 调用分配专门的线程池，该线
程池叫作 Thread Pool B，其中有 10 个线程，只要对 Provider B 的 RPC 并发量超过了 10 ，后续的 RPC 就
走降级服务，就算服务的 Provider B 挂了，最多也就导致 Thread Pool B 不可用，而不会影响系统中的
其他服务的 RPC。

一般来说，RPC 线程与 Web 容器的 IO 线程也是需要隔离的。

如图 6-6 所示，当 Provider A 的用户请求涉及 Provider B 和 Provider C 的 RPC 的时候，Provider A 的 IO 线
程会将任务交给对应的 RPC 线程池里面的 RPC 线程来执行，Provider A 的 IO 线程就可以去干别的事情去
了，当 RPC 线程执行完远程调用的任务之后，就会将调用的结果返回给 IO 线程。如果 RPC 线程池耗尽
了，IO 线程池也不会受到影响，从而实现 RPC 线程与 Web 容器的 IO 线程的相互隔离。

图 6-6 RPC 线程与 Web 容器的 IO 线程相互隔离

虽然线程在就绪状态、运行状态、阻塞状态、终止状态间转变时需要由操作系统调度，这会带来一定的
性能消耗，但是 Netflix 详细评估了使用异步线程和同步线程带来的性能差异，结果表明在 99%的情况下
异步线程带来的延迟仅为几毫秒，这种性能的损耗对于用户程序来说是完全可以接受的。

###### Hystrix 线程池隔离

Hystrix 既可以为 HystrixCommand 命令默认创建一个线程池，也可以关联上一个指定的线程池。每一
个线程池都有一个 Key，叫作 Thread Pool Key（线程池名）。

如果没有为 HystrixCommand 指定线程池，Hystrix 会为 HystrixCommand 创建一个与 Group Key（命
令组 Key）同名的线程池，当然，如果与 Group Key 同名的线程池已经存在，则直接进行关联。也就是
说，默认情况下，HystrixCommand 命令的 Thread Pool Key 与 Group Key 是相同的。

总体来说，线程池就是隔离的关键，所有的监控、调用、缓存等都围绕线程池展开。

如果要指定线程池，可以通过如下代码在 Setter 中定制线程池的 Key 和属性：


然后，可以通过 HystrixCommand 或者 HystrixObservableCommand 的构造函数传入 Setter 配置实
例：

HystrixThreadPoolKey 是一个接口，它有一个辅助工厂类 Factory，它的 asKey（String）方法专门用于
创建一个线程池的 Key，示例代码如下：

HystrixThreadPoolKey.Factory.asKey ("threadPoolN")

下面是一个完整的线程池隔离演示例子：创建了两个线程池 threadPool 1 和 threadPool 2，然后通过这
两个线程池发起简单的 RPC 远程调用，其中，通过 threadPool 1 线程池访问一个错误连接
ERROR_URL，通过 threadPool 2 访问一个正常连接 HELLO_TEST_URL。在实验过程中，可以通过调整
RPC 的次数多次运行程序，然后通过结果查看线程池的具体隔离效果。

线程池隔离实例的代码如下：

```
/**
*在 Setter 实例中指定线程池的 Key 和属性
*/
HystrixCommand. Setter rpcPool 1_setter = HystrixCommand. Setter
.withGroupKey (HystrixCommandGroupKey.Factory.asKey ("group 1"))
.andCommandKey (HystrixCommandKey.Factory.asKey ("command 1"))
.andThreadPoolKey (HystrixThreadPoolKey.Factory.asKey ("threadPool 1"))
.andThreadPoolPropertiesDefaults (
HystrixThreadPoolProperties.Setter ()
.withCoreSize ( 10 )  //配置线程池里的线程数
.withMaximumSize ( 10 )
);
```
```
public class HttpGetterCommand extends HystrixCommand<String>
{
private String url;
...
public HttpGetterCommand (String url, Setter setter)
{
super (setter);
this. url = url;
}
...
}
```
```
package com. crazymaker. demo. hystrix;
//省略 import
```
```
@Slf 4 j
public class IsolationStrategyDemo
{
/**
* 测试: 线程池隔离
*/
@Test
public void testThreadPoolIsolationStrategy () throws Exception
{
```

/**
* RPC 线程池 1
*/
HystrixCommand. Setter rpcPool 1_Setter = HystrixCommand. Setter
.withGroupKey (HystrixCommandGroupKey.Factory.asKey ("group 1"))
.andCommandKey (HystrixCommandKey.Factory.asKey ("command 1"))

.andThreadPoolKey (HystrixThreadPoolKey.Factory.asKey ("threadPool 1"))
.andCommandPropertiesDefaults (HystrixCommandProperties.Setter ()
.withExecutionTimeoutInMilliseconds ( 5000 )  //配置执行时间
上限
). andThreadPoolPropertiesDefaults (
HystrixThreadPoolProperties.Setter ()
.withCoreSize ( 10 )  //配置线程池里的线程数
.withMaximumSize ( 10 )
);

/**
* RPC 线程池 2
*/
HystrixCommand. Setter rpcPool 2_Setter = HystrixCommand. Setter
.withGroupKey (HystrixCommandGroupKey.Factory.asKey ("group 2"))
.andCommandKey (HystrixCommandKey.Factory.asKey ("command 2"))

.andThreadPoolKey (HystrixThreadPoolKey.Factory.asKey ("threadPool 2"))
.andCommandPropertiesDefaults (HystrixCommandProperties.Setter ()
.withExecutionTimeoutInMilliseconds ( 5000 )  //配置执行时间
上限
). andThreadPoolPropertiesDefaults (
HystrixThreadPoolProperties.Setter ()
.withCoreSize ( 10 )  //配置线程池里的线程数
.withMaximumSize ( 10 )
);

/**
* 访问一个错误连接，让 threadpool 1 耗尽
*/
for (int j = 1 ; j <= 5 ; j++)
{

new HttpGetterCommand (ERROR_URL, rpcPool 1_Setter)
.toObservable ()
.subscribe (s -> log.info (" result:{}", s));
}

/**
* 访问一个正确连接，观察 threadpool 2 是否正常
*/
for (int j = 1 ; j <= 5 ; j++)
{

new HttpGetterCommand (HELLO_TEST_URL, rpcPool 2_Setter)
.toObservable ()
.subscribe (s -> log.info (" result:{}", s));
}
Thread.sleep (Integer. MAX_VALUE);


运行这个演示程序，输出的结果节选如下：

从上面的结果可知：threadPool 1 的线程使用和 threadPool 2 的线程使用是完全地相互独立和相互隔离
的，无论 threadPool 1 是否耗尽，threadPool 2 的线程都可以正常发起 RPC 请求。

默认情况下，在 Spring Cloud 中，Hystrix 会为每一个 Command Group Key（命令组 Key）自动创建一
个同名的线程池。

而在 Hystrix 客户端，每一个 RPC 目标 Provider 的 Command Group Key（命令组 Key）的默认值为它的
应用名称（application name）。

比如，demo-provider 服务的 Command Group Key 默认值为其名称“demo-provider”。

所以，如果某个 Provider（如 uaa-provider）需发起对 demo-Provider 的远程调用，则 Hystrix 为该
Provider 创建的 RPC 线程池的名称默认为“demo-provider”，专用于对 demo-provider 的 REST 服务进行
RPC 调用和隔离，如图 6-7 所示。

```
}
}
```
```
[hystrix-threadPool 1-4] INFO c.c.d.h.HttpGetterCommand - req 1 begin...
[hystrix-threadPool 1-3] INFO c.c.d.h.HttpGetterCommand - req 4 begin...
[hystrix-threadPool 2-3] INFO c.c.d.h.HttpGetterCommand - req 10 begin...
[hystrix-threadPool 2-5] INFO c.c.d.h.HttpGetterCommand - req 7 begin...
[hystrix-threadPool 1-5] INFO c.c.d.h.HttpGetterCommand - req 9 begin...
[hystrix-threadPool 2-1] INFO c.c.d.h.HttpGetterCommand - req 6 begin...
[hystrix-threadPool 1-1] INFO c.c.d.h.HttpGetterCommand - req 8 begin...
[hystrix-threadPool 1-2] INFO c.c.d.h.HttpGetterCommand - req 2 begin...
[hystrix-threadPool 2-4] INFO c.c.d.h.HttpGetterCommand - req 5 begin...
[hystrix-threadPool 2-2] INFO c.c.d.h.HttpGetterCommand - req 3 begin...
[hystrix-threadPool 1-1] INFO c.c.d.h.HttpGetterCommand - req 8 fallback: 熔断
false, 直接失败 false
[hystrix-threadPool 1-4] INFO c.c.d.h.HttpGetterCommand - req 1 fallback: 熔断
false, 直接失败 false
[hystrix-threadPool 1-2] INFO c.c.d.h.HttpGetterCommand - req 2 fallback: 熔断
false, 直接失败 false
[hystrix-threadPool 1-3] INFO c.c.d.h.HttpGetterCommand - req 4 fallback: 熔断
false, 直接失败 false
[hystrix-threadPool 1-5] INFO c.c.d.h.HttpGetterCommand - req 9 fallback: 熔断
false, 直接失败 false
...
[hystrix-threadPool 2-4] INFO c.c.d.h.HttpGetterCommand - req 5 end:
{"respCode": 0,"respMsg": "操作成功...}
[hystrix-threadPool 2-2] INFO c.c.d.h.HttpGetterCommand - req 3 end:
{"respCode": 0,"respMsg": "操作成功...}
[hystrix-threadPool 2-3] INFO c.c.d.h.HttpGetterCommand - req 10 end:
{"respCode": 0,"respMsg": "操作成功...}
[hystrix-threadPool 2-1] INFO c.c.d.h.HttpGetterCommand - req 6 end:
{"respCode": 0,"respMsg": "操作成功...}
[hystrix-threadPool 2-5] INFO c.c.d.h.HttpGetterCommand - req 7 end:
{"respCode": 0,"respMsg": "操作成功...}
...
```

图 6-7 对 demo-provider 服务进行 RPC 调用的专用线程池

###### Hystrix 线程池隔离配置

在 Spring Cloud 微服务提供者中，如果需使用 Hystrix 线程池进行 RPC 隔离，可以在应用配置文件中进行
相应配置。下面是 demo-provider 的 RPC 线程池配置的实例：

对上面实例中用到的与 Hystrix 线程池有关的配置项介绍如下：

**（ 1 ）hystrix. threadpool. default. coreSize**

设值线程池的核心线程数。

**（ 2 ）hystrix. threadpool. default. maximumSize**

设值线程池的最大线程数，起作用的前提是 allowMaximumSizeToDrivergeFromCoreSize 的属性值为
true。maximumSize 属性值可以等于或者大于 coreSize 值，当线程池的线程不够用时，Hystrix 会创建
新的线程，直到线程数达到 maximumSize 的值，创建的线程为非核心线程。

```
hystrix:
threadpool:
default:
coreSize: 10 # 线程池核心线程数
maximumSize: 20 # 线程池最大线程数
allowMaximumSizeToDivergeFromCoreSize: true # 线程池 maximumSize 最大线程数是
否生效
keepAliveTimeMinutes： 10 # 设置可空闲时间，单位为分钟
command:
default: #全局默认配置
execution: #RPC隔离的相关配置
isolation:
strategy: THREAD #配置请求隔离的方式 ，这里采用线程池方式
thread:
timeoutInMilliseconds: 100000 #RPC执行的超时时间 ，默认为 1000 毫秒
interruptOnTimeout: true #发生超时后是否中断方法的执行 ，默认值为
true
```

**（ 3 ）hystrix. threadpool. default. allowMaximumSizeToDivergeFromCoreSize**

该属性允许 maximumSize 起作用。

**（ 4 ）hystrix. threadpool. default. keepAliveTimeMinutes**

该属性设置非核心线程的存活时间，如果某个非核心线程的空闲时间超过 keepAliveTimeMinutes 设置
的时间，非核心线程将被释放。其单位为分钟，默认值为 1 ，默认情况下非核心线程空闲 1 分钟后释放。

**（ 5 ）hystrix. command. default. execution. isolation. strategy**

该属性设置完成 RPC 远程调用 HystrixCommand 命令的隔离策略。它有两个可选值：THREAD、
SEMAPHORE，默认值为 THREAD。THREAD 表示使用线程池进行 RPC 隔离，SEMAPHORE 表示通过信
号量来进行 RPC 隔离和限制并发量。

**（ 6 ）hystrix. command. default. execution. isolation. thread. timeoutInMilliseconds**

设置调用者等待 HystrixCommand 命令执行的超时限制，超过此时间，HystrixCommand 被标记为
TIMEOUT，并执行回退逻辑。超时会作用在 HystrixCommand.queue ()，即使调用者没有调用 get () 去
获得 Future 对象。

以上的配置是 application 应用级别的默认线程池配置，覆盖的范围为系统中的所有 RPC 线程池。有时，
需要为特定的 Provider 微服务提供者做特殊的配置，比如当某一个 Provider 的接口访问的并发量非常
大，是其他 Provider 的几十倍时，则其远程调用需要更多的 RPC 线程，这时候，可以单独为它进行专门
的 RPC 线程池配置。作为示例，在 demo-Provider 中对 uaa-provider 的 RPC 线程池配置如下：

上面的配置中使用了 hystrix. threadpool. uaa-provider 配置项前缀，其中 uaa-provider 部分为 RPC 线程
池的 Thread Pool Key（线程池名称），也就是默认的 Command Group Key（命令组名）。

在调用处理器 HystrixInvocationHandler 的 invoke (...) 方法内打上断点，在调试时，通过查看
hystrixCommand 对象的值可以看出，demo-provider 中针对微服务提供者 uaa-provider 的 RPC 线程池
配置已经生效，如图 6-8 所示。

```
hystrix:
threadpool:
default:
coreSize: 10 # 线程池核心线程数
maximumSize: 20 # 线程池最大线程数
allowMaximumSizeToDivergeFromCoreSize: true # 线程池最大线程数是否有效
uaa-provider:
coreSize: 20 # 线程池核心线程数
maximumSize: 100 # 线程池最大线程数
allowMaximumSizeToDivergeFromCoreSize: true # 线程池最大线程数是否有效
```

图 6-8 针对 uaa-provider 的 RPC 线程池配置已经生效

###### Hystrix 信号量隔离

除了使用线程池进行资源隔离之外，Hystrix 还可以使用信号量机制完成资源隔离。信号量所起到的作用
就像一个开关，而信号量的值就是每个命令的并发执行数量，当并发数高于信号量的值时，就不再执行
命令。

比如，如果 Provider A 的 RPC 信号量大小为 10 ，那么它同时只允许有 10 个 RPC 线程来访问 Provider A，
其他的请求都会被拒绝，从而达到资源隔离和限流保护的作用。

Hystrix 信号量机制不提供专用的线程池，也不提供额外的线程，在获取信号量之后，执行
HystrixCommand 命令逻辑的线程还是之前 Web 容器的 IO 线程。

信号量可以细分为 run 执行信号量和 fallback 回退信号量。

IO 线程在执行 HystrixCommand 命令之前，需要抢到 run 执行信号量，成功之后才允许执行
HystrixCommand.run () 方法。如果争抢失败，就准备回退，但是在执行
HystrixCommand.getFallback () 回退方法之前，还需要争抢 fallback 回退信号量，成功之后才允许执行
HystrixCommand.getFallback () 回退方法。如果都获取失败，则操作直接终止。

在如图 6-9 所示的例子中，假设有 5 个 Web 容器的 IO 线程并发进行 RPC 远程调用，但是执行信号量的大小
为 3 ，也就是只有 3 个 IO 线程能够真正地抢到 run 执行信号量，争抢成功后这些线程才能发起 RPC 调用。
剩下的 2 个 IO 线程准备回退，去抢 fallback 回退信号量，争抢成功后执行
HystrixCommand.getFallback () 回退方法。


图 6-9 5 个 Web 容器的 IO 线程争抢信号量

下面是一个模拟 Web 容器进行 RPC 调用的演示程序，使用一个拥有 50 个线程的线程池模拟 Web 容器的 IO
线程池，并使用随书编写的 HttpGetterCommand 命令模拟 RPC 调用。实验之前，需要提前启动的
demo-provider 服务的 REST 接口/api/demo/hello/v 1。

为了演示信号量隔离，演示程序所设置的 run 执行信号量和 fallback 回退信号量都为 4 ，并且通过 IO 线程
池同时提交了 50 个模拟的 RPC 调用去争抢这些信号量，具体的演示程序如下：

```
package com. crazymaker. demo. hystrix;
```
```
//省略 import
```
```
@Slf 4 j
public class IsolationStrategyDemo
{
```
```
/**
* 测试: 信号量隔离
*/
@Test
public void testSemaphoreIsolationStrategy () throws Exception
{
/**
*命令属性实例
*/
HystrixCommandProperties. Setter commandProperties =
HystrixCommandProperties.Setter ()
.withExecutionTimeoutInMilliseconds ( 5000 )  //配置时间上限
.withExecutionIsolationStrategy (
```

在执行此演示程序之前，需要启动 crazydemo. com（指向 127.0.0.1）主机上的 demo-provider 微服务
提供者。demo-provider 启动之后，再执行上面的演示程序，运行的结果节选如下：

```
//隔离策略为信号量隔离
```
```
HystrixCommandProperties. ExecutionIsolationStrategy. SEMAPHORE
)
//HystrixCommand.run () 方法允许的最大请求数
.withExecutionIsolationSemaphoreMaxConcurrentRequests ( 4 )
//HystrixCommand.getFallback () 方法允许的最大请求数
.withFallbackIsolationSemaphoreMaxConcurrentRequests ( 4 );
```
```
/**
* 命令的配置实例
*/
HystrixCommand. Setter setter = HystrixCommand. Setter
.withGroupKey (HystrixCommandGroupKey.Factory.asKey ("group 1"))
.andCommandKey (HystrixCommandKey.Factory.asKey ("command 1"))
.andCommandPropertiesDefaults (commandProperties);
```
```
/**
* 模拟 Web 容器的 IO 线程池
*/
ExecutorService mock_IO_threadPool = Executors.newFixedThreadPool ( 50 );
```
```
/**
* 模拟 Web 容器的并发 50
*/
for (int j = 1 ; j <= 50 ; j++)
{
mock_IO_threadPool.submit (() ->
{
/**
* RPC 调用
*/
new HttpGetterCommand (HELLO_TEST_URL, setter)
.toObservable ()
.subscribe (s -> log.info (" result:{}", s));
});
}
Thread.sleep (Integer. MAX_VALUE);
}
}
```
```
[pool-2-thread-35] INFO c.c.d.h.HttpGetterCommand - req 3 fallback: 熔断 false, 直
接失败 true，失败次数 3
[pool-2-thread-45] INFO c.c.d.h.HttpGetterCommand - req 4 fallback: 熔断 false, 直
接失败 true，失败次数 4
[pool-2-thread-7] INFO c.c.d.h.HttpGetterCommand - req 2 fallback: 熔断 false, 直接
失败 true，失败次数 2
[pool-2-thread-15] INFO c.c.d.h.HttpGetterCommand - req 1 fallback: 熔断 false, 直
接失败 true，失败次数 1
[pool-2-thread-35] INFO c.c.d.h.IsolationStrategyDemo - result: req 3: 调用失败
...
[pool-2-thread-27] INFO c.c.d.h.HttpGetterCommand - req 7 begin...
[pool-2-thread-18] INFO c.c.d.h.HttpGetterCommand - req 6 begin...
[pool-2-thread-13] INFO c.c.d.h.HttpGetterCommand - req 5 begin...
```

通过结果可以看出：

1 ）执行 RPC 远程调用的线程就是模拟 IO 线程池中的线程。

2 ）虽然提交了 50 个 RPC 调用，但是只有 4 个 RPC 调用抢到了执行信号量，分别为 req 5、req 6、req 7、
req 8。

3 ）虽然失败了 46 个 RPC 调用，但是只有 4 个 RPC 调用抢到了回退信号量，分别为 req 1、req 2、req 3、
req 4。

使用信号量进行 RPC 隔离时，是有自身弱点的。由于最终 Web 容器的 IO 线程完成实际 RPC 远程调用，这
样就带来了一个问题：由于 RPC 远程调用是一种耗时的操作，如果 IO 线程被长时间占用，将导致 Web 容
器请求处理能力下降，甚至可能会在一段时间内由于 IO 线程被占满而造成 Web 容器无法对新的用户请求
及时响应，最终导致 Web 容器崩溃。因此，信号量隔离机制不适用于 RPC 隔离。但是，对于一些非网络
的 API 调用或者耗时很小的 API 调用，信号量隔离机制比线程池隔离机制的效率更高。

再来看信号量的配置，这一次使用代码的方式进行命令属性配置，涉及 Hystrix 命令属性配置器
HystrixCommandProperties.Setter () 的以下实例方法：

**（ 1 ）withExecutionIsolationSemaphoreMaxConcurrentRequests (int)**

此方法设置使用执行信号量的大小，也就是 HystrixCommand.run () 方法允许的最大请求数。如果达到
最大请求数，则后续的请求会被拒绝。

在 Web 容器中，抢占信号量的线程应该是容器（比如 Tomcat）IO 线程池的一小部分，所以信号量的数
量不能大于容器线程池大小，否则起不到保护作用。执行信号量大小的默认值为 10 。

如果使用属性配置而不是代码方式进行配置，则以上代码配置所对应的配置项为：

hystrix. command. default. execution. isolation. semaphore. maxConcurrentRequests

**（ 2 ）withFallbackIsolationSemaphoreMaxConcurrentRequests (int)**

此方法设置使用回退信号量的大小，也就是 HystrixCommand.getFallback () 方法允许的最大请求数。如
果达到最大请求数，则后续的回退请求会被拒绝。

如果使用属性配置而不是代码方式进行配置，则以上代码配置所对应的配置项为：

hystrix. command. default. fallback. isolation. semaphore. maxConcurrentRequests

###### 线程池与信号量区别

最后，介绍一下信号量隔离与线程池隔离的区别，分别从调用线程、开销、异步、并发量 4 个维度进行
对比，具体如表 6-1 所示。

表 6-1 调用线程、开销、异步、并发量 4 个维度的对比

```
[pool-2-thread-48] INFO c.c.d.h.HttpGetterCommand - req 8 begin...
[pool-2-thread-18] INFO c.c.d.h.HttpGetterCommand - req 6 end:
{"respCode": 0,"respMsg": "操作成功...}
[pool-2-thread-48] INFO c.c.d.h.HttpGetterCommand - req 8 end:
{"respCode": 0,"respMsg": "操作成功...}
[pool-2-thread-27] INFO c.c.d.h.HttpGetterCommand - req 7 end:
{"respCode": 0,"respMsg": "操作成功...}
[pool-2-thread-13] INFO c.c.d.h.HttpGetterCommand - req 5 end:
{"respCode": 0,"respMsg": "操作成功...}
[pool-2-thread-13] INFO c.c.d.h.IsolationStrategyDemo - result: req 5:
{"respCode": 0,"respMsg": "操作成...}
...
```

```
线程池隔离信号量隔离
```
```
调用
线程 RPC 线程与 Web 容器 IO 线程相互隔离 RPC 线程与 Web 容器 IO 线程相同
```
```
开销
```
```
存在请求排队、线程调度、线程上下文切
换等开销无线程切换，开销低
```
```
异步支持不支持
```
```
并发
量
```
```
最大线程池大小最大信号量上限，且最大信号量需要小于
IO 线程数
```
**适用场景** ：

```
线程池技术，适合绝大多数场景，比如说我们对依赖服务的网络请求的调用和访问、需要对调用的
timeout 进行控制（捕捉 timeout 超时异常）。
信号量技术，适合不是对外部依赖的访问，而是对内部的一些比较复杂的业务逻辑的访问，并且系
统内部的代码，其实不涉及任何的网络请求，那么只要做信号量的普通限流就可以了，因为不需要
去捕获 timeout 类似的问题。
```
#### Hystrix 熔断降级（过载保护）

熔断器的工作机制为：统计最近 RPC 调用发生错误的次数，然后根据统计值中的失败比例等信息，决定
是否允许后面的 RPC 调用继续，或者快速地失败回退。

熔断器的 3 种状态如下：

1 ）closed：熔断器关闭状态，这也是熔断器的初始状态，此状态下 RPC 调用正常放行。

2 ）open：失败比例到一定的阈值之后，熔断器进入开启状态，此状态下 RPC 将会快速失败，执行失败
回退逻辑。

3 ）half-open：在打开一定时间之后（睡眠窗口结束），熔断器进入半开启状态，小流量尝试进行 RPC
调用放行。如果尝试成功则熔断器变为 closed 状态，RPC 调用正常；如果尝试失败则熔断器变为 open 状
态，RPC 调用快速失败。

###### 断路器有 3 种状态：

```
CLOSED：默认状态。
```
断路器观察到请求失败比例没有达到阈值，断路器认为被代理服务状态良好。

```
OPEN：
```
断路器观察到请求失败比例已经达到阈值，断路器认为被代理服务故障，打开开关，请求不再到达被代
理的服务，而是快速失败。

```
HALF-OPEN：
```

断路器打开后，为了能自动恢复对被代理服务的访问，会切换到 HALF-OPEN 半开放状态，去尝试请求
被代理服务以查看服务是否已经故障恢复。如果成功，会转成 CLOSED 状态，否则转到 OPEN 状态。

断路器的状态切换图如下：

###### Hystrix 实现熔断机制

在 Spring Cloud 中，熔断机制是通过 Hystrix 实现的。

Hystrix 会监控微服务间调用的状况，当失败调用到一定比例时（例如 5 秒内失败 20 次），就会启动熔
断机制。
Hystrix 实现服务熔断的步骤如下：

```
1. 当服务的调用出错率达到或超过 Hystix 规定的比率（默认为 50%）后，熔断器进入熔断开启状
态。
2. 熔断器进入熔断开启状态后，Hystrix 会启动一个休眠时间窗，在这个时间窗内，该服务的降级逻
辑会临时充当业务主逻辑，而原来的业务主逻辑不可用。
3. 当有请求再次调用该服务时，会直接调用降级逻辑快速地返回失败响应，以避免系统雪崩。
4. 当休眠时间窗到期后，Hystrix 会进入半熔断转态，允许部分请求对服务原来的主业务逻辑进行调
用，并监控其调用成功率。
5. 如果调用成功率达到预期，则说明服务已恢复正常，Hystrix 进入熔断关闭状态，服务原来的主业
务逻辑恢复；否则 Hystrix 重新进入熔断开启状态，休眠时间窗口重新计时，继续重复第 2 到第 5
步。
```
熔断器状态之间相互转换的逻辑关系如图 6-10 所示。


```
参数描述
```
```
metrics. rollingStats. timeInMilliseconds 统计时间窗。
```
```
circuitBreaker. sleepWindowInMilliseconds
```
```
休眠时间窗，熔断开启状态持续一段时间后，熔
断器会自动进入半熔断状态，这段时间就被称为
休眠窗口期。
```
```
circuitBreaker. requestVolumeThreshold
```
```
请求总数阀值。在统计时间窗内，请求总数必须
到达一定的数量级，Hystrix 才可能会将熔断器
打开进入熔断开启转态，而这个请求数量级就是
请求总数阀值。Hystrix 请求总数阈值默认为
20 ，这就意味着在统计时间窗内，如果服务调用
次数不足 20 次，即使所有的请求都调用出错，
熔断器也不会打开。
```
图 6-10 熔断器状态之间的转换关系详细图

涉及到了 4 个与 Hystrix 熔断机制相关的重要参数，这 4 个参数的含义如下表。


```
参数描述
```
```
circuitBreaker. errorThresholdPercentage
```
```
错误百分比阈值。当请求总数在统计时间窗内超
过了请求总数阀值，且请求调用出错率超过一定
的比例，熔断器才会打开进入熔断开启转态，而
这个比例就是错误百分比阈值。错误百分比阈值
设置为 50 ，就表示错误百分比为 50%，如果服
务发生了 30 次调用，其中有 15 次发生了错误，
即超过了 50% 的错误百分比，这时候将熔断器
就会打开。
```
###### 熔断器状态变化的演示实例

为了观察熔断器的状态变化，通过继承 HystrixCommand 类，这里特别设计了一个能够设置运行时长的
自定义命令类 TakeTimeDemoCommand，通过设置其运行占用时间 takeTime 成员的值，可以控制其
运行过程中是否超时。

演示实例的代码如下：

```
package com. crazymaker. demo. hystrix;
//省略 import
```
```
@Slf 4 j
public class CircuitBreakerDemo
{
//执行的总次数，线程安全
private static AtomicInteger total = new AtomicInteger ( 0 );
```
```
/**
* 内部类：一个能够设置运行时长的自定义命令类
*/
static class TakeTimeDemoCommand extends HystrixCommand<String>
{
```
```
//run 方法是否执行
private boolean hasRun = false;
//执行的次序
private int index;
//运行的占用时间
long takeTime;
```
```
public TakeTimeDemoCommand (long takeTime, Setter setter)
{
super (setter);
this. takeTime = takeTime;
}
```
```
@Override
protected String run () throws Exception
{
hasRun = true;
index = total.incrementAndGet ();
```

Thread.sleep (takeTime);
HystrixCommandMetrics. HealthCounts hc =
super.getMetrics (). getHealthCounts ();
log.info ("succeed- req{}: 熔断器状态：{}, 失败率：{}%",
index, super.isCircuitBreakerOpen (),
hc.getErrorPercentage ());
return "req" + index + ": succeed";
}

@Override
protected String getFallback ()
{
//是否直接失败
boolean isFastFall = !hasRun;
if (isFastFall)
{
index = total.incrementAndGet ();
}
HystrixCommandMetrics. HealthCounts hc =
super.getMetrics (). getHealthCounts ();
log.info ("fallback- req{}: 熔断器状态：{}, 失败率：{}%",
index, super.isCircuitBreakerOpen (),
hc.getErrorPercentage ());
return "req" + index + ": failed";
}

}

/**
* 测试用例：熔断器熔断
*/

@Test
public void testCircuitBreaker () throws Exception
{
/**
* 命令参数配置
*/
HystrixCommandProperties. Setter propertiesSetter =
HystrixCommandProperties.Setter ()
//至少有 3 个请求，熔断器才达到熔断触发的次数阈值
.withCircuitBreakerRequestVolumeThreshold ( 3 )
//熔断器中断请求 5 秒后会进入 half-open 状态, 尝试放行
.withCircuitBreakerSleepWindowInMilliseconds ( 5000 )
//错误率超过 60%，快速失败
.withCircuitBreakerErrorThresholdPercentage ( 60 )
//启用超时
.withExecutionTimeoutEnabled (true)
//执行的超时时间，默认为 1000 毫秒，这里设置为 500 毫秒
.withExecutionTimeoutInMilliseconds ( 500 )
//可统计的滑动窗口内的 buckets 数量，用于熔断器和指标发布
.withMetricsRollingStatisticalWindowBuckets ( 10 )
//可统计的滑动窗口的时间长度
//这段时间内的执行数据用于熔断器和指标发布

.withMetricsRollingStatisticalWindowInMilliseconds ( 10000 );


在上面的演示中，有以下配置器的配置命令需要重点说明：

1 ）通过 withExecutionTimeoutInMilliseconds（int）方法将默认为 1000 毫秒的执行超时上限设置为
500 毫秒，也就是说，只要 TakeTimeDemoCommand.run () 的执行超过 500 毫秒就会触发 Hystrix 超时回
退。

2 ）通过 withCircuitBreakerRequestVolumeThreshold（int）方法将熔断器触发熔断的最少请求次数
的默认值 20 次改为了 3 次，这样更容易测试。

3 ）通过 withCircuitBreakerErrorThresholdPercentage（int）方法设置错误率阈值百分比的值为 60 ，
滑动窗口时间内当错误率超过此值时，熔断器进入 open 开启状态，所有请求都会触发失败回退
（fallback），错误率阈值百分比的默认值为 50 。

执行上面的演示实例，运行的结果节选如下：

```
HystrixCommand. Setter rpcPool = HystrixCommand. Setter
.withGroupKey (HystrixCommandGroupKey.Factory.asKey ("group-1"))
.andCommandKey (HystrixCommandKey.Factory.asKey ("command-1"))
```
```
.andThreadPoolKey (HystrixThreadPoolKey.Factory.asKey ("threadPool-1"))
.andCommandPropertiesDefaults (propertiesSetter);
```
```
/**
* 首先设置运行时间为 800 毫秒，大于命令的超时限制 500 毫秒
*/
long takeTime = 800 ;
for (int i = 1 ; i <= 10 ; i++)
{
```
```
TakeTimeDemoCommand command = new TakeTimeDemoCommand (takeTime,
rpcPool);
command.execute ();
```
```
//健康信息
HystrixCommandMetrics. HealthCounts hc =
command.getMetrics (). getHealthCounts ();
if (command.isCircuitBreakerOpen ())
{
/**
* 熔断之后，设置运行时间为 300 毫秒，小于命令的超时限制 500 毫秒
*/
takeTime = 300 ;
log.info ("============ 熔断器打开了，等待休眠期（默认 5 秒）结束");
```
```
/**
* 等待 7 秒之后，再一次发起请求
*/
Thread.sleep ( 7000 );
}
```
```
}
```
```
Thread.sleep (Integer. MAX_VALUE);
```
```
}
}
```

从上面的执行结果可知，在第四次请求 req 4 时，熔断器才达到熔断触发的次数阈值 3 ，由于前 3 次皆为
超时失败，失败率大于阈值 60%，因此第四次请求执行之后，熔断器状态为 open 熔断状态。

在命令的熔断器打开后，熔断器默认会有 5 秒的睡眠等待时间，在这段时间内的所有请求直接执行回退
方法； 5 秒之后，熔断器会进入 half-open 状态, 尝试放行一次命令执行，如果成功则关闭熔断器，状态
转成 closed，否则，熔断器回到 open 状态。

在上面的程序中，在熔断器熔断之后，演示程序将命令的运行时间 takeTime 改成了 300 毫秒，小于命令
的超时限制 500 毫秒。在等待 7 秒之后，演示程序再一次发起请求，从运行结果可以看到，第 5 次请求
req 5 执行成功了，这是一次 half-open 状态的尝试放行，请求成功之后，熔断器的状态转成了 open，后
续请求将继续放行。注意，演示程序第 5 次请求 req 5 后的熔断器状态值反映在第 6 次请求 req 6 的执行输
出中。

###### 熔断器和滑动窗口的配置属性

熔断器的配置包含了滑动窗口的配置和熔断器自身的配置。

Hystrix 的健康统计是通过滑动窗口来完成的，其熔断器的状态也是依据滑动窗口的统计数据来变化的，
所以这里先介绍滑动窗口的配置。

先看看两个概念：滑动窗口和时间桶。

**1. 滑动窗口**

可以这么来理解滑动窗口：一位乘客坐在正在行驶的列车的靠窗座位上，列车行驶的公路两侧种着一排
挺拔的白杨树，随着列车的前进，路边的白杨树迅速从窗口滑过，我们用每棵树来代表一个请求，用列
车的行驶代表时间的流逝，那么，列车上的这个窗口就是一个典型的滑动窗口，这个乘客能通过窗口看
到的白杨树的数量，就是滑动窗口要统计的数据。

**2. 时间桶**

时间桶是统计滑动窗口数据时的最小单位。同样类比列车窗口，在列车速度非常快时，如果每掠过一棵
树就统计一次窗口内树的数据，显然开销非常大，如果乘客将窗口分成 N 份，前进行时列车每掠过窗口
的 N 分之一就统计一次数据，开销就大大地减小了。简单来说，时间桶也就是滑动窗口的 N 分之一。

```
[HystrixTimer-1] INFO c.c.d.h.CircuitBreakerDemo - fallback- req 1: 熔断器状态：
false, 失败率：0%
[HystrixTimer-1] INFO c.c.d.h.CircuitBreakerDemo - fallback- req 2: 熔断器状态：
false, 失败率：100%
[HystrixTimer-2] INFO c.c.d.h.CircuitBreakerDemo - fallback- req 3: 熔断器状态：
false, 失败率：100%
[HystrixTimer-1] INFO c.c.d.h.CircuitBreakerDemo - fallback- req 4: 熔断器状态：
true, 失败率：100%
[main] INFO c.c.d.h.CircuitBreakerDemo - ============ 熔断器打开了，等待休眠期（默
认 5 秒）结束
[hystrix-threadPool-1-5] INFO c.c.d.h.CircuitBreakerDemo - succeed- req 5: 熔断器
状态：true, 失败率：100%
[hystrix-threadPool-1-6] INFO c.c.d.h.CircuitBreakerDemo - succeed- req 6: 熔断器
状态：false, 失败率：0%
[hystrix-threadPool-1-7] INFO c.c.d.h.CircuitBreakerDemo - succeed- req 7: 熔断器
状态：false, 失败率：0%
[hystrix-threadPool-1-8] INFO c.c.d.h.CircuitBreakerDemo - succeed- req 8: 熔断器
状态：false, 失败率：0%
[hystrix-threadPool-1-9] INFO c.c.d.h.CircuitBreakerDemo - succeed- req 9: 熔断器
状态：false, 失败率：0%
[hystrix-threadPool-1-10] INFO c.c.d.h.CircuitBreakerDemo - succeed- req 10: 熔断
器状态：false, 失败率：0%
```

代码方式下熔断器的设置可以使用 HystrixCommandProperties.Setter () 配置器来完成，参考 6.5.1 节的
实例，把自定义的 TakeTimeDemoCommand 中 Setter () 配置器的相关参数配置如下：

在以上配置中，与熔断器的滑动窗口相关的配置的具体含义为：

1 ）滑动窗口中，最少 3 个请求才会触发断路，默认值为 20 个。

2 ）错误率达到 60%时才可能触发断路，默认值为 50%。

3 ）断路之后的 5000 毫秒内，所有请求都直接调用 getFallback () 进行回退降级，不会调用 run () 方法；
5000 毫秒过后，熔断器变为 half-open 状态。

以上 TakeTimeDemoCommand 的熔断器滑动窗口的状态转换关系如图 6-11 所示。

图 6-11 TakeTimeDemoCommand 的熔断器健康统计滑动窗口的状态转换关系图

大家已经知道，Hystrix 熔断器的配置除了代码方式，还有 properties 文本属性配置的方式；

另外 Hystrix 熔断器相关的滑动窗口不止一个基础的健康统计滑动窗口，还包含一个百分比命令执行时间
统计滑动窗口，两个窗口都可以进行配置。

```
/**
* 命令参数配置
*/
HystrixCommandProperties. Setter propertiesSetter =
HystrixCommandProperties.Setter ()
//至少有 3 个请求，熔断器才达到熔断触发的次数阈值
.withCircuitBreakerRequestVolumeThreshold ( 3 )
//熔断器中断请求 5 秒后会进入 half-open 状态，进行尝试放行
.withCircuitBreakerSleepWindowInMilliseconds ( 5000 )
//错误率超过 60%，快速失败
.withCircuitBreakerErrorThresholdPercentage ( 60 )
//启用超时
.withExecutionTimeoutEnabled (true)
//执行的超时时间，默认为 1000 毫秒，这里设置为 500 毫秒
.withExecutionTimeoutInMilliseconds ( 500 )
//可统计的滑动窗口内的 buckets 数量，用于熔断器和指标发布
.withMetricsRollingStatisticalWindowBuckets ( 10 )
//可统计的滑动窗口的时间长度
//这段时间内的执行数据用于熔断器和指标发布
.withMetricsRollingStatisticalWindowInMilliseconds ( 10000 );
```

下面以文本属性配置方式为主，详细介绍 Hystrix 基础健康统计滑动窗口的配置：

**（ 1 ）hystrix. command. default. metrics. rollingStats. timeInMilliseconds**

设置健康统计滑动窗口的持续时间（以毫秒为单位），默认值为 10000 毫秒。熔断器的状态会根据滑
动窗口的统计值来计算，若滑动窗口时间内的错误率超过阈值，熔断器将进入 open 开启状态，滑动窗
口将被进一步细分为时间桶，滑动窗口的统计值等于窗口内所有时间桶的统计信息的累加，每个时间桶
的统计信息包含请求的成功（success）、失败（failure）、超时（timeout）、被拒（rejection）的次
数。

此选项通过代码方式配置时所对应的函数如下：

**（ 2 ）hystrix. command. default. metrics. rollingStats. numBuckets**

设置健康统计滑动窗口被划分为时间桶的数量，默认值为 10 。若滑动窗口的持续时间为默认的 10000 毫
秒，则一个时间桶（bucket）的时间即 1 秒。如果要做定制化的配置，则所设置的 numBuckets（时间
桶数量）值和 timeInMilliseconds（滑动窗口时长）值有关联关系，必须符合 timeInMilliseconds %
numberBuckets == 0 的规则，否则会抛出异常。例如二者的关联关系为 70000 （滑动窗口 70 秒）%
700 （桶数）==0 是可以的，但是 70000 （ 70 秒）% 600（桶数）== 400 将抛出异常。

此选项通过代码方式配置时所对应的函数如下：

**（ 3 ）hystrix. command. default. metrics. healthSnapshot. intervalInMilliseconds**

设置健康统计滑动窗口拍摄运行状况统计指标的快照的时间间隔。什么是拍摄运行状况统计指标的快照
呢？就是计算成功和错误百分比这些影响熔断器状态的统计数据。

拍摄快照的时间间隔的单位为毫秒，默认值为 500 毫秒。由于统计指标的计算是一个耗 CPU 的操作
（CPU 密集型操作），也就是说，高频率地计算错误百分比等健康统计数据会占用很多 CPU 资源，所
以，在高并发 RPC 流量大的场景下，可以适当调大拍摄快照的时间间隔。

此选项通过代码方式配置时所对应的函数如下：

Hystrix 熔断器相关的滑动窗口不止一个基础的健康统计滑动窗口，还包含一个“百分比命令执行时间”统
计滑动窗口。什么是“百分比命令执行时间”统计滑动窗口呢？该滑动窗口主要用于统计 1%、10%、
50%、90%、99%等一系列比例的命令执行平均耗时，主要用以生成统计图表。

带 hystrix. command. default. metrics. rollingPercentile 前缀的配置项，专门用于配置百分比命令执行时
间统计窗口。

下面以文本属性配置方式为主，详细介绍 Hystrix 执行时间百分比统计滑动窗口的配置：

**（ 1 ）hystrix. command. default. metrics. rollingPercentile. enabled：**

该配置项用于设置百分比命令执行时间统计窗口是否生效，命令的执行时间是否被跟踪，并且计算各个
百分比如 1%、10%、50%、90%、99.5% 等的平均时间。该配置项默认为 true。

**（ 2 ）hystrix. command. default. metrics. rollingPercentile. timeInMilliseconds**

```
HystrixCommandProperties.Setter (). withMetricsRollingStatisticalWindowInMilliseco
nds (int)
```
```
HystrixCommandProperties.Setter (). withMetricsRollingStatisticalWindowBuckets
(int)
```
```
HystrixCommandProperties.Setter (). withMetricsHealthSnapshotIntervalInMillisecond
s (int)
```

设置百分比命令执行时间统计窗口的持续时间（以毫秒为单位），默认值为 60000 毫秒，当然，此滑
动窗口也会被进一步细分为时间桶，以便提高统计的效率。

本选项通过代码方式配置时所对应的函数如下：

**（ 3 ）hystrix. command. default. metrics. rollingPercentile. numBuckets**

设置百分比命令执行时间统计窗口被划分为时间桶的数量，默认值为 6 。此滑动窗口的默认持续时间为
默认的 60000 毫秒，即默认情况下，一个时间桶的时间为 10 秒。如果要做定制化的配置，此窗口所设置
的 numBuckets（时间桶数量）值和 timeInMilliseconds（滑动窗口时长）值有关联关系，必须符合
timeInMilliseconds（滑动窗口时长）% numberBuckets == 0 的规则，否则将抛出异常。

此选项通过代码方式配置时所对应的函数如下：

**（ 4 ）hystrix. command. default. metrics. rollingPercentile. bucketSize**

设置百分比命令执行时间统计窗口的时间桶内最大的统计次数，如果 bucketSize 为 100 ，而桶的时长为
1 秒，若这 1 秒里有 500 次执行，则只有最后 100 次执行的信息会被统计到桶里去。增加此配置项的值会
导致内存开销及其他计算开销的上升，该配置项的默认值为 100 。

此选项通过代码方式配置时所对应的函数如下：

以上是 Hystrix 熔断器相关的滑动窗口的配置，接下来是熔断器本身的配置。

带 hystrix. command. default. circuitBreaker 前缀的配置项专门用于对熔断器本身进行配置。

下面以文本属性配置方式为主，对 Hystrix 熔断器的配置进行一下详细介绍：

**（ 1 ）hystrix. command. default. circuitBreaker. enabled**

该配置用来确定是否启用熔断器，默认值为 true。

此选项通过代码方式配置时所对应的函数如下：

**（ 2 ）hystrix. command. default. circuitBreaker. requestVolumeThreshold**

该配置用于设置熔断器触发熔断的最少请求次数。如果设为 20 ，那么当一个滑动窗口时间内（比如 10
秒）收到 19 个请求，即使 19 个请求都失败，熔断器也不会打开变成 open 状态。默认值为 20 。

此选项通过代码方式配置时所对应的函数如下：

**（ 3 ）hystrix. command. default. circuitBreaker. errorThresholdPercentage**

该配置用于设置错误率阈值，当健康统计滑动窗口的错误率超过此值时，熔断器进入 open 开启状态，
所有请求都会触发失败回退（fallback）。错误率阈值百分比的默认值为 50 。

```
HystrixCommandProperties.Setter (). withMetricsRollingPercentileWindowInMillisecon
ds (int)
```
```
HystrixCommandProperties.Setter (). withMetricsRollingPercentileWindowBuckets
(int)
```
```
HystrixCommandProperties.Setter (). withMetricsRollingPercentileBucketSize (int)
```
```
HystrixCommandProperties.Setter (). withCircuitBreakerEnabled (boolean)
```
```
HystrixCommandProperties.Setter (). withCircuitBreakerRequestVolumeThreshold (int)
```

此选项通过代码方式配置时所对应的函数如下：

**（ 4 ）hystrix. command. default. circuitBreaker. sleepWindowInMilliseconds**

此配置项指定了熔断器打开后经过多长时间允许一次请求尝试执行。熔断器打开时，Hystrix 会在经过一
段时间后就放行一条请求，如果这条请求执行成功了，说明此时服务很可能已经恢复了正常，那么就会
关闭熔断器；如果此请求执行失败，则认为目标服务依然不可用，熔断器继续保持打开状态。

该配置用于配置熔断器的睡眠窗口，具体指的是熔断器打开之后过多长时间才允许一次请求尝试执行，
默认值为 5000 毫秒，表示当熔断器开启（open）后， 5000 毫秒内会拒绝所有的请求， 5000 毫秒之后，
熔断器才会进行入 half-open 状态。

此选项通过代码方式配置时所对应的函数如下：

**（ 5 ）hystrix. command. default. circuitBreaker. forceOpen**

如果配置为 true，则熔断器将被强制打开，所有请求将被触发失败回退（fallback）。此配置的默认值
为 false。

此选项通过代码方式配置时所对应的函数如下：

下面是本书随书实例中 demo-provider 中的有关熔断器的配置，节选如下：

```
HystrixCommandProperties.Setter (). withCircuitBreakerErrorThresholdPercentage
(int)
```
```
HystrixCommandProperties.Setter (). withCircuitBreakerSleepWindowInMilliseconds
(int)
```
```
HystrixCommandProperties.Setter (). withCircuitBreakerForceOpen (boolean)
```
```
hystrix:
...
command:
...
default: #全局默认配置
circuitBreaker: #熔断器相关配置
enabled: true #是否启动熔断器 ，默认为 true
requestVolumeThreshold: 20 #启用熔断器功能窗口时间内的最小请求数
sleepWindowInMilliseconds: 5000 #指定熔断器打开后多长时间内允许一次请求尝
试执行
errorThresholdPercentage: 50 #窗口时间内超过50 %的请求失败后就会打开熔
断器
metrics:
rollingStats:
timeInMilliseconds: 6000
numBuckets: 10
UserClient #detail (Long): #独立接口配置 ，格式为： 类名 #方法名 （参数类型
列表）
circuitBreaker: #熔断器相关配置
enabled: true #是否使用熔断器 ，默认为 true
requestVolumeThreshold: 20 #窗口时间内的最小请求数
sleepWindowInMilliseconds: 5000 #打开后允许一次尝试的睡眠时间 ，默认配置为 5
秒
errorThresholdPercentage: 50 #窗口时间内熔断器开启的错误比例 ，默认配置
为 50
```

使用文本格式配置时，可以对熔断器的参数值做默认配置，也可以对特定的 RPC 接口做个性化配置。对
熔断器的参数值做默认配置时，使用 hystrix. command. default 默认前缀；对特定的 RPC 接口做个性化
配置时，使用 hystrix. command. FeignClient #Method格式的前缀 。上面的演示例子中，对远程客户端
Feign 接口 UserClient 中的 detail (Long) 方法做了个性化的熔断器配置，其配置项的前缀为：

hystrix. command. UserClient #detail (Long)

###### Hystrix 命令的执行流程

在获取 HystrixCommand 命令的执行结果时，无论是调用 execute () 和 toObservable () 方法，还是调用
observe () 方法，最终都会通过 HystrixCommand.toObservable () 订阅执行结果和返回。

在 Hystrix 内部，调用 toObservable () 方法返回一个观察的主题，当 Subscriber 订阅者订阅主题后，
HystrixCommand 会弹射一个事件，然后通过一系列的判断（顺序依次是缓存是否命中、熔断器是否打
开、线程池是否占满），开始执行实际的 HystrixCommand.run () 方法，该方法的实现主要为异步处理
的业务逻辑，如果这其中任何一个环节出现错误或者抛出异常，它都会回退到 getFallback () 方法进行服
务降级处理，当降级处理完成之后，它会将结果返回给实际的调用者。

HystrixCommand 的工作流程，总结起来大致如下：

1 ）判断是否使用缓存响应请求，若启用了缓存，且缓存可用，则直接使用缓存响应请求。Hystrix 支持
请求缓存，但需要用户自定义启动。

2 ）判断熔断器是否开启，如果熔断器处于 open 状态，则跳到第 5 步。

3 ）如果使用线程池进行请求隔离，则判断线程池是否已满，已满则跳到第 5 步；如果使用信号量进行请
求隔离，则判断信号量是否耗尽，耗尽则跳到第 5 步。

4 ）执行 HystrixCommand.run () 方法执行具体业务逻辑，如果执行失败或者超时，则跳到第 5 步，否则
跳到第 6 步。

5 ）执行 HystrixCommand.getFallback () 服务降级处理逻辑。

6 ）返回请求响应。

以上流程如图 6-12 所示。

图 6-12 HystrixCommand 的执行流程示意图

```
metrics:
rollingStats:
timeInMilliseconds: 10000 #滑动窗口时间
numBuckets: 10 #滑动窗口的时间桶数
```

```
名字说明触发 fallback
```
```
EMIT 值传递 NO
```
```
SUCCESS 执行完成，没有错误 NO
```
```
FAILURE 执行抛出异常 YES
```
```
TIMEOUT 执行开始，但没有在允许的时间内完成 YES
```
```
BAD_REQUEST 执行抛出 HystrixBadRequestException NO
```
```
SHORT_CIRCUITED 熔断器打开，不尝试执行 YES
```
```
THREAD_POOL_REJECTED 线程池拒绝，不尝试执行 YES
```
```
SEMAPHORE_REJECTED 信号量拒绝，不尝试执行 YES
```
什么场景下会触发 fallback 方法呢？请见表 6-2。

表 6-2 触发 fallback 方法的场景

#### Sentinel 限流降级

Sentinel 限流降级的流量控制 (Flow Control) 策略，原理是监控应用流量的 QPS 或并发线程数等指标，
当达到指定阈值时对流量进行控制，避免系统被瞬时的流量高峰冲垮，保障应用高可用性。

通过流控规则来指定允许该资源通过的请求次数，例如下面的代码定义了资源 HelloWorld 每秒最多只
能通过 20 个请求。

参考的规则定义如下：

一条限流规则主要由下面几个因素组成，我们可以组合这些元素来实现不同的限流效果：

```
resource：资源名，即限流规则的作用对象
count: 限流阈值
grade: 限流阈值类型（QPS 或并发线程数）
limitApp: 流控针对的调用来源，若为 default 则不区分调用来源
strategy: 调用关系限流策略
```
```
private static void initFlowRules (){
List<FlowRule> rules = new ArrayList<>();
FlowRule rule = new FlowRule ();
rule.setResource ("HelloWorld");
rule.setGrade (RuleConstant. FLOW_GRADE_QPS);
// Set limit QPS to 20.
rule.setCount ( 20 );
rules.add (rule);
FlowRuleManager.loadRules (rules);
}
```

```
controlBehavior: 流量控制效果（直接拒绝、Warm Up、匀速排队）
```
###### 基本的参数

**资源名** ：唯一名称，默认请求路径

**针对来源** ：Sentinel 可以针对调用者进行限流，填写微服务名，默认为 default (不区分来源)

**阈值类型/单机阈值：**

```
1. QPS：每秒请求数，当前调用该 api 的 QPS 到达阈值的时候进行限流
2. 线程数：当调用该 api 的线程数到达阈值的时候，进行限流
```
**是否集群** ：是否为集群

###### 流控的几种 strategy ：

```
1. 直接：当 api 大达到限流条件时，直接限流
2. 关联：当关联的资源到达阈值，就限流自己
3. 链路：只记录指定路上的流量，指定资源从入口资源进来的流量，如果达到阈值，就进行限流，
api 级别的限流
```
###### 直接失败模式限流

Sentinel 直接失败模式是指：在达到流量控制阈值后，直接拒绝请求，返回错误信息。

可以用于接口级别的流控，对来源进行限流，当达到限流条件时，直接限流。

**使用 API 进行资源定义**

```
/**
* 限流实现方式一: 抛出异常的方式定义资源
*
* @param orderId
* @return
*/
@ApiOperation (value = "纯代码限流")
@GetMapping ("/getOrder")
@ResponseBody
public String getOrder (@RequestParam (value = "orderId", required = false) String
orderId)
{
```
```
Entry entry = null;
// 资源名
String resourceName = "getOrder";
try
{
// entry 可以理解成入口登记
entry = SphU.entry (resourceName);
// 被保护的逻辑, 这里为订单查询接口
return "正常的业务逻辑 OrderInfo : " + orderId;
} catch (BlockException blockException)
```

**代码限流规则**

**网页限流规则配置**

选择 QPS，直接，快速失败，单机阈值为 2 。

配置

```
{
// 接口被限流的时候, 会进入到这里
log.warn ("---getOrder 1 接口被限流了---, exception: ", blockException);
return "接口限流, 返回空";
} finally
{
// SphU.entry (xxx) 需要与 entry.exit () 成对出现, 否则会导致调用链记录异常
if (entry != null)
{
entry.exit ();
}
}
}
```
```
//限流规则 QPS mode,
List<FlowRule> rules = new ArrayList<FlowRule>();
FlowRule rule 1 = new FlowRule ();
rule 1.setResource ("getOrder");
// QPS 控制在 2 以内
rule 1.setCount ( 2 );
// QPS 限流
rule 1.setGrade (RuleConstant. FLOW_GRADE_QPS);
rule 1.setLimitApp ("default");
rules.add (rule 1);
FlowRuleManager.loadRules (rules);
```

```
Field 说明默认值
```
```
resource 资源名，资源名是限流规则的作用对象
```
```
count 限流阈值
```
```
grade 限流阈值类型，QPS 或线程数模式 QPS 模式
```
```
limitApp 流控针对的调用来源
```
```
default，代表不
区分调用来源
```
```
strategy 判断的根据是资源自身，还是根据其它关联资源
(refResource)，还是根据链路入口
```
```
根据资源本身
```
```
controlBehavior 流控效果（直接拒绝 / 排队等待 / 慢启动模式） 直接拒绝
```
参数

**测试**


频繁刷新请求， 1 秒访问 2 次请求，正常，超过设置的阈值，将报默认的错误。

再次的 1 秒访问 2 次请求，访问正常。超过 2 次，访问异常

###### Sentinel 关联模式限流

调用关系包括调用方、被调用方；一个方法又可能会调用其它方法，形成一个调用链路的层次关系。

Sentinel 通过 NodeSelectorSlot 建立不同资源间的调用的关系，并且通过 ClusterBuilderSlot
记录每个资源的实时统计信息。

当两个资源之间具有资源争抢或者依赖关系的时候，这两个资源便具有了关联。

比如对数据库同一个字段的读操作和写操作存在争抢，读的速度过高会影响写得速度，写的速度过高会
影响读的速度。如果放任读写操作争抢资源，则争抢本身带来的开销会降低整体的吞吐量。

可使用关联限流来避免具有关联关系的资源之间过度的争抢.

举例来说，read_db 和 write_db 这两个资源分别代表数据库读写，我们可以给 read_db 设置限流
规则来达到写优先的目的。

具体的方法：

还有一个例子，电商的下订单和支付两个操作。

使用关联模式限流，如果需要优先保障支付，可以根据支付接口的流量阈值，来对订单接口进行限
制，从而保护支付的目的。

**使用注解进行资源定义**

添加 2 个请求

```
设置 `strategy` 为 `RuleConstant. STRATEGY_RELATE`
设置 `refResource` 为 `write_db`。
这样当写库操作过于频繁时，读数据的请求会被限流。
```
```
@SentinelResource (value = "test 1", blockHandler = "exceptionHandler")
@GetMapping ("/test 1")
public String test 1 ()
{
log.info (Thread.currentThread (). getName () + "\t" + "... test 1");
return "-------hello baby，i am test 1";
}
```

**代码配置关联限流规则**

**网页限流规则配置**

```
// Block 异常处理函数，参数最后多一个 BlockException，其余与原函数一致.
public String exceptionHandler (BlockException ex)
{
// Do some log here.
ex.printStackTrace ();
log.info (Thread.currentThread (). getName () + "\t" + "... exceptionHandler");
return String.format ("error: test 1 is not OK");
}
```
```
@SentinelResource (value = "test 1_ref")
@GetMapping ("/test 1_ref")
public String test 1_ref ()
{
log.info (Thread.currentThread (). getName () + "\t" + "... test 1_related");
return "-------hello baby，i am test 1_ref";
}
```
```
// 关联模式流控 QPS 控制在 1 以内
String refResource = "test 1_ref";
FlowRule rRule = new FlowRule ("test 1")
.setCount ( 1 )  // QPS 控制在 1 以内
.setStrategy (RuleConstant. STRATEGY_RELATE)
.setRefResource (refResource);
```
```
rules.add (rRule);
FlowRuleManager.loadRules (rules);
```

**测试**

选择 QPS，单机阈值为 1 ，选择关联，关联资源为/test_ref，这里用 Jmeter 模拟高并发，请求/test_ref。

在大批量线程高并发访问/test_ref，导致/test 失效了

链路类型的关联也类似，就不再演示了。多个请求调用同一微服务。

###### Warm up（预热）模式限流

当流量突然增大的时候，我们常常会希望系统从空闲状态到繁忙状态的切换的时间长一些。


即如果系统在此之前长期处于空闲的状态，我们希望处理请求的数量是缓步的增多，经过预期的时间以
后，到达系统处理请求个数的最大值。

Warm Up（冷启动，预热）模式就是为了实现这个目的的。

默认 coldFactor 为 3 ，即请求 QPS 从 threshold / 3 开始，经预热时长逐渐升至设定的 QPS 阈值。

**使用注解定义资源**

**代码限流规则**

**网页限流规则配置**

```
@SentinelResource (value = "testWarmUP", blockHandler =
"exceptionHandlerOfWarmUp")
@GetMapping ("/testWarmUP")
public String testWarmUP ()
{
log.info (Thread.currentThread (). getName () + "\t" + "... test 1");
return "-------hello baby，i am testWarmUP";
}
```
```
FlowRule warmUPRule = new FlowRule ();
warmUPRule.setResource ("testWarmUP");
warmUPRule.setCount ( 20 );
warmUPRule.setGrade (RuleConstant. FLOW_GRADE_QPS);
warmUPRule.setLimitApp ("default");
warmUPRule.setControlBehavior (RuleConstant. CONTROL_BEHAVIOR_WARM_UP);
warmUPRule.setWarmUpPeriodSec ( 10 );
```

先在单机阈值 10/3， 3 的时候，预热 10 秒后，慢慢将阈值升至 20 。刚开始刷/testWarmUP，会出现默认
错误，预热时间到了后，阈值增加，没超过阈值刷新，请求正常。

通常冷启动的过程系统允许通过的 QPS 曲线如下图所示：


```
Field 说明
```
```
默认
值
```
```
resource 资源名，即规则的作用对象
```
```
grade 熔断策略，支持慢调用比例/异常比例/异常数策略
```
```
慢调
用比
例
```
```
count 慢调用比例模式下为慢调用临界 RT（超出该值计为慢调
用）；异常比例/异常数模式下为对应的阈值
```
```
timeWindow 熔断时长，单位为 s
```
```
minRequestAmount
```
```
熔断触发的最小请求数，请求数小于该值时即使异常比率超出
阈值也不会熔断（1.7.0 引入）^5
```
```
statIntervalMs
```
```
统计时长（单位为 ms），如 60*1000 代表分钟级（1.8.0 引
入）
```
```
1000
ms
```
```
slowRatioThreshold 慢调用比例阈值，仅慢调用比例模式有效（1.8.0 引入）
```
如秒杀系统在开启瞬间，会有很多流量上来，很可能把系统打死，预热方式就是为了保护系统，可慢慢
的把流量放进来，慢慢的把阈值增长到设置的阈值。

#### sentinel 熔断降级

###### 什么是 sentinel 熔断降级

熔断降级对调用链路中不稳定的资源进行熔断降级是保障高可用的重要措施之一。

由于调用关系的复杂性，如果调用链路中的某个资源不稳定，最终会导致请求发生堆积。

Sentinel 熔断降级会在调用链路中某个资源出现不稳定状态时（例如调用超时或异常比例升高），对这
个资源的调用进行限制，让请求快速失败，避免影响到其它的资源而导致级联错误。

当资源被降级后，在接下来的降级时间窗口之内，对该资源的调用都自动熔断（默认行为是抛出
DegradeException）

###### sentinel 熔断降级规则

熔断降级规则包含下面几个重要的属性：

###### 几种降级策略

我们通常用以下几种降级策略：

```
平均响应时间 (DEGRADE_GRADE_RT)：
当资源的平均响应时间超过阈值（DegradeRule 中的 count，以 ms 为单位）之后，资源进入准
降级状态。如果接下来 1 s 内持续进入 5 个请求（即 QPS >= 5），它们的 RT 都持续超过这个阈
值，那么在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方法
的调用都会自动地熔断（抛出 DegradeException）。
```

```
注意 Sentinel 默认统计的 RT 上限是 4900 ms，超出此阈值的都会算作 4900 ms，若需要
变更此上限可以通过启动配置项 -Dcsp. sentinel. statistic. max. rt=xxx 来配置。
```
```
异常比例 (DEGRADE_GRADE_EXCEPTION_RATIO)：
当资源的每秒异常总数占通过量的比值超过阈值（DegradeRule 中的 count）之后，资源进入降
级状态，即在接下的时间窗口（DegradeRule 中的 timeWindow，以 s 为单位）之内，对这个方
法的调用都会自动地返回。
```
```
异常比率的阈值范围是 [0.0, 1.0]，代表 0% - 100%。
```
```
异常数 (DEGRADE_GRADE_EXCEPTION_COUNT)：
当资源近 1 分钟的异常数目超过阈值之后会进行熔断。
```
```
注意由于统计时间窗口是分钟级别的，若 timeWindow 小于 60 s，则结束熔断状态后仍可能
再进入熔断状态。
```
###### 熔断降级代码实现

可以通过调用 DegradeRuleManager.loadRules () 方法来用硬编码的方式定义流量控制规则。

```
具体源码，请参见疯狂创客圈 crazy-springcloud 源码工程
```
###### 控制台降级规则

配置

```
@PostConstruct
public void initSentinelRule ()
{
//熔断规则： 5 s 内调用接口出现异常次数超过 5 的时候, 进行熔断
List<DegradeRule> degradeRules = new ArrayList<>();
DegradeRule rule = new DegradeRule ();
rule.setResource ("queryGoodsInfo");
rule.setCount ( 5 );
```
```
rule.setGrade (RuleConstant. DEGRADE_GRADE_EXCEPTION_COUNT);//熔断规则
rule.setTimeWindow ( 5 );
degradeRules.add (rule);
DegradeRuleManager.loadRules (degradeRules);
}
```

```
Field 说明默认值
```
```
resource 资源名，即限流规则的作用对象
```
```
count 阈值
```
```
grade 降级模式，根据 RT 降级还是根据异常比例降级 RT
```
```
timeWindow 降级的时间，单位为 s
```
参数

#### Sentinel 与 Hystrix 对比

###### 1 、资源模型和执行模型上的对比

Hystrix 的资源模型设计上采用了命令模式，将对外部资源的调用和 fallback 逻辑封装成一个命令对象
HystrixCommand 或 HystrixObservableCommand，其底层的执行是基于 RxJava 实现的。每个
Command 创建时都要指定 commandKey 和 groupKey（用于区分资源）以及对应的隔离策略（线程
池隔离 or 信号量隔离）。线程池隔离模式下需要配置线程池对应的参数（线程池名称、容量、排队超
时等），然后 Command 就会在指定的线程池按照指定的容错策略执行；信号量隔离模式下需要配置
最大并发数，执行 Command 时 Hystrix 就会限制其并发调用。

Sentinel 的设计则更为简单。相比 Hystrix Command 强依赖隔离规则，Sentinel 的资源定义与规则配
置的耦合度更低。Hystrix 的 Command 强依赖于隔离规则配置的原因是隔离规则会直接影响
Command 的执行。在执行的时候 Hystrix 会解析 Command 的隔离规则来创建 RxJava Scheduler 并
在其上调度执行，若是线程池模式则 Scheduler 底层的线程池为配置的线程池，若是信号量模式则简单
包装成当前线程执行的 Scheduler。

而 Sentinel 则不一样，开发的时候只需要考虑这个方法/代码是否需要保护，置于用什么来保护，可以
任何时候动态实时的区修改。

从 0.1.1 版本开始，Sentinel 还支持基于注解的资源定义方式，可以通过注解参数指定异常处理函数和
fallback 函数。Sentinel 提供多样化的规则配置方式。除了直接通过 loadRules API 将规则注册到内存
态之外，用户还可以注册各种外部数据源来提供动态的规则。用户可以根据系统当前的实时情况去动态
地变更规则配置，数据源会将变更推送至 Sentinel 并即时生效。

###### 2 、隔离设计上的对比


隔离是 Hystrix 的核心功能之一。Hystrix 提供两种隔离策略：线程池隔离 Bulkhead Pattern 和信号量
隔离，其中最推荐也是最常用的是线程池隔离。

Sentinel 可以通过并发线程数模式的流量控制来提供信号量隔离的功能。并且结合基于响应时间的熔断
降级模式，可以在不稳定资源的平均响应时间比较高的时候自动降级，防止过多的慢调用占满并发数，
影响整个系统。

###### 3 、熔断降级的对比

Sentinel 和 Hystrix 的熔断降级功能本质上都是基于熔断器模式 Circuit Breaker Pattern。

Sentinel 与 Hystrix 都支持基于失败比率（异常比率）的熔断降级，在调用达到一定量级并且失败比率
达到设定的阈值时自动进行熔断，此时所有对该资源的调用都会被 block，直到过了指定的时间窗口后
才启发性地恢复。

此外，Sentinel 还支持基于平均响应时间的熔断降级，可以在服务响应时间持续飙高的时候自动熔断，
拒绝掉更多的请求，直到一段时间后才恢复。这样可以防止调用非常慢造成级联阻塞的情况。

#### Sentinel 与 Hystrix 的不足

无论是 Sentinel 与 Hystrix，都无法做到分层分级细粒度熔断限流，

所以，对于微信中的亿级 QPS 吞吐量规模过载场景, 没法直接使用 Sentinel 与 Hystrix 进行，没有办
法进行细粒度、高精准熔断保护（过载保护） 。

#### 分层分级细粒度、高精准熔断限流降级策略

###### 微信后台亿级 QPS 吞吐量的过载场景

微信作为当之无愧的国民级应用，系统复杂程度超乎想象：

```
其后台由三千多个移动服务构成，
每天需处理大约十的 10~11 次方个外部请求，
整体需要每秒处理大约几亿个请求！亿级 QPS 吞吐量规模
```
微服务采用统一的 RPC 框架搭建一个个独立的服务，服务之间互相调用，实现各种各样的功能，这也
是现代服务的基本架构。

微信的服务是分三层： **接入服务、逻辑服务、基础服务。**

大多数服务属于逻辑服务，接入服务如登录、发消息、支付服务，每日请求量在 10 亿-100 亿之间，入
口协议触发对逻辑服务和基础服务更多的请求，核心服务每秒要处理上亿次的请求，qps> 1 亿。


在大规模微服务场景下，过载会变得比较复杂。

如果是单体服务，一个事件只用一个请求。

但微服务下，一个事件可能要请求很多的服务，任何一个服务过载失败，就会造成其他的请求都是无效
的。

如下图所示：

比如在一个转账服务下，需要查询分别两者的卡号，再查询 A 时成功了，但查询 B 失败，对于查卡号这
个事件就算失败了，比如查询成功率只有 50%，那对于查询两者卡号这个成功率只有 50% * 50% =
25% 了，一个事件调用的服务次数越多，那成功率就会越低。

###### 微信后台如何判断过载

通常，判断过载的方式很多，比如：

```
使用吞吐量判断过载
使用访问延迟判断过载
使用 CPU 使用率判断过载
使用丢包率判断过载
使用失败率判断过载
```

```
使用待处理请求数判断过载
使用请求处理事件判断过载。
```
微信并没有使用以上的常用方式，而是使用一种特殊的方式：

```
请求在队列中的平均等待时间判断过载。
```
微信为啥不使用响应时间？

因为响应时间是跟服务相关的，很多微服务是链式调用，响应时间是不可控的，也是无法标准化的，很
难作为一个统一的判断依据。

为微信为啥也不使用 CPU 负载作为判断标准呢？

因为 **CPU 负载高不代表服务过载** ，一个服务请求处理及时，CPU 处于高位反而是比较良好的表现。

实际上 CPU 负载高，监控服务是会告警出来，但是并不会直接进入过载处理流程。

什么是请求在队列中的平均等待时间呢？

请求在队列中的等待时间就是从请求到达，到开始处理的时间。平均等待时间的计算范围，以时间
窗口（如 s）划分时间范围，或者以一定数量的请求划分范围（如每 2000 个请求）。

以超时时间为基础，腾讯微服务通过计算每秒或每 2000 个请求的平均等待时间是否超过 20 ms，判断
是否过载，这个 20 ms 是根据微信后台 5 年摸索出来的门槛值。默认的超时时间是 500 ms，

采用平均等待时间还有一个好处是：

**这个是独立于服务的，可以应用于任何场景，而不用关联于业务，可以直接在框架上进行改造。**

###### 微信后台的限流降级策略（过载保护策略）

当平均等待时间大于 20 ms 时，以一定的降速因子过滤调部分请求。开始进行限流降级。

如果判断平均等待时间小于 20 ms，则以一定的速率提升通过率。开始进行流量的恢复。

一般采用 **快降慢升** 的策略，防止大的服务波动。

整个策略相当于一个负反馈电路。


###### 分层分级细粒度、高精准熔断限流降级策略

一旦检测到服务过载，需要按照一定的策略对请求进行过滤。

那么，有哪些进行流量过滤的策略呢？

```
策略一：随机丢弃
策略二：分层分级细粒度过滤
```
对于链式调用的微服务场景，使用策略一进行随机丢弃请求，最终会导致整体服务的成功率很低。

所以，使用分层分级高精准细粒度限流降级策略，请求是按照优先级进行控制的，优先级低的请求会优
先丢弃。

什么是使用分层分级高精准细粒度限流降级策略？

具体来说：

```
业务分层
用户分级
```
**1 ）业务分层**

对于不同的业务场景优先的层级是不同的。

比如：登录场景是最重要的业务，也是最为核心的业务，如果不能登录，一切都白费。

另外：支付消息也比普通消息优先级高，因为用户对金钱是更敏感的。

再比如说：普通消息，又比朋友圈消息优先级高。

**所以在微信内是天然存在业务层级的。**

每个请求，从业务维度来说，都会分配一个业务层级。

在微服务的链式调用下，后端的请求业务层级，从请求链路的前段进行继承的。


比如我请求登录，那么后端的请求业务都是继承登录的业务层级。如检查账号密码等一系列的后续请求
都是继承登录优先级的，这就保证了业务层级的一致性。

用一个 hash 表维护重要性很高的 top N 的业务层级，每个后台服务维护了业务层级的 hash 表。

当然，微信的业务太多，并非每个业务都记录在 hash 表里，不在 hash 表里的业务就是低层级业务。限
流的时候，首先被限制。

hash 表中的业务，都是高层级业务。限流的时候，放在最后限制。

**2 ）用户分级**

每个业务的请求量很大，整块业务请求全部被限制，那一定会造成负载的大幅波动。

所以不可能因为负载高，丢弃或允许通过一整个业务的请求。

很明显，只基于业务层级的控制是不够的。

解决这个问题，可以引入 **用户分级** 。

实际上，很多网站的用户天然是分级的，VIP 用户的访问，需要优先保证。

微信如何对用户进行分级呢？

一个 10 亿级用户的 APP，从业务维度来说，用户分级的方案，非常复杂。

除了从业务维度分级完成之后，按照二八定律，普通人占 80%，这个依然是一个庞大的数字。

对于普通人来说，还需要继续进一步细分，这时候，可以通过 hash 用户唯一 ID，计算用户优先级。

**3 ）分层分级二维限流降级控制**

引入了用户优先级，那就和业务优先级组成了一个二维限流降级控制。

根据负载情况，决定这台服务器的准入优先级 (B, U)，二维限流降级控制具体为：

```
当过来的请求业务优先级大于 B，则通过
或者当过来的请求业务优先级不大于 B，但用户优先级高于 U 时，则通过，否则决绝。
```
两个条件，满足一个即可放行。


**4 ）RPC 组件客户端限流**

为了进一步减轻过载机器的压力，能不能在 upstream 后端过载的情况下，不把请求发到后端呢？

否则后端还是要接受请求、解包、丢弃请求，白白浪费带宽也加重了后端的负载。

为了实现这个能力，进行 RPC 组件客户端限流：

```
在每次请求后端（upstream 上游）服务时，后端把当前服务的准入优先级返回给前端，
RPC 组件客户端维护上游服务的准入优先级，如果发现请求优先级达不到上游服务的准入门槛，直
接丢弃，而不再请求 upstream 上游，进一步减轻 upstream 上游的压力。
```
###### 微信整个负载控制的流程

微信整个负载控制的流程如图所示：

当用户从微信发起请求，请求被路由到接入层服务，分配统一的业务和用户优先级，所有到的
upstream 上游子请求都继承相同的优先级。根据业务逻辑调用 1 个或多个 upstream 上游服务。

当服务收到请求，首先根据自身服务准入优先级判断请求是接受还是丢弃。

**服务本身根据负载情况周期性的调整准入优先级。**


当服务通过 RPC 客户端需要再向 upstream 上游发起请求时，判断本地记录的 upstream 上游服务准入优
先级。如果小于则丢弃，如果没有记录或优先级大于记录则向 upstream 上游发起请求。

upstream 上游服务返回需要的信息，并且在信息中携带自身准入优先级。downstream 下游接受到返
回后解析信息，并更新本地记录的 upstream 服务准入优先级。

#### 说在最后

**熔断，降级，防止雪崩，是面试的重点和高频点** 。

```
(1) 什么是熔断，降级？如何实现？
```
```
(2 ) 服务熔断，解决灾难性雪崩效应的有效利器
```
```
(3 ）说一下限流、熔断、高可用
```
```
等等等等.....
```
参照上文的答案，如果大家能对答如流，最终， **让面试官爱到 “不能自已、口水直流”** 。 offer，也就来
了。

学习过程中，如果有啥问题，大家可以来找 40 岁老架构师尼恩交流。加入社区的方式，请参见公众号
【技术自由圈】 。

#### 作者介绍：

**本文 1 作： Andy** ，资深架构师，《Java 高并发核心编程加强版》作者之 1 。

**本文 2 作： 尼恩** ， 41 岁资深老架构师，《Java 高并发核心编程加强版卷 1 、卷 2 、卷 3 》创世作者，
著名博主。《K 8 S 学习圣经》《Docker 学习圣经》《Go 学习圣经》等 11 个 PDF 圣经的作者。也是一
个 **架构转化导师** ，已经指导了大量小伙伴成功转型架构师，最高的年薪拿到近 100 W。

#### 参考文献：

[1] Overload Control for Scaling WeChat Microservices

[2] 罗神解读“Overload Control for Scaling WeChat Microservices”

[3] 2 W 台服务器、每秒数亿请求，微信如何不“失控”？

[4] DAGOR：微信微服务过载控制系统

[5] 月活 12.8 亿的微信是如何防止崩溃的？

[6] 微信朋友圈千亿访问量背后的技术挑战和实践总结

[7] QQ 18 年：解密 8 亿月活的 QQ 后台服务接口隔离技术

[8] 微信后台基于时间序的海量数据冷热分级架构设计实践

[9] 架构之道： 3 个程序员成就微信朋友圈日均 10 亿发布量》

[10] 快速裂变：见证微信强大后台架构从 0 到 1 的演进历程（一）

[11] 一份微信后台技术架构的总结性笔记》


https://juejin.cn/post/6844904006259572749

https://cloud.tencent.com/developer/article/1815254

https://blog.csdn.net/qq_27184497/article/details/119993725

https://blog.csdn.net/sh210106sh/article/details/116495124

## 滴滴太狠：千万级 qps 超高并发 ID，如何生

## 成？

#### 背景：

在 40 岁老架构师尼恩的读者社群（50+）中，很多小伙伴拿不到 offer，或者拿不到好的 offer。

尼恩经常给大家优化项目，优化简历，挖掘技术亮点。在指导简历的过程中， **高并发、分布式核心组
件是一项很重要的指导。**

在所有的高并发、分布式核心组件： **分布式 ID 是核心中的核心、重点中的重点** 。

分布式 ID 组件，是整个系统 **黄金链路上的关键组件、黄金组件** ，

如果分布式 ID 组件出现问题，整个黄金链路上关键动作都无法执行，这就会带来一场灾难，一定是 P 0
级大灾难。

对于架构师、高级开发来说，分布式 ID 的方案和架构，是重点中的重点，更是内功中的内功。

**分布式 ID，也是面试的重点和高频点** 。比如，近段时间尼恩社群中有很多小伙伴在面试滴滴、美团、网
易等大厂时候，就遇到很多类似问题：

```
(1) 一个分布式 ID 生成系统，如何实现？
```
```
(2) 分布式 ID 系统，如何实现高并发？
```
```
(3) 分布式 ID 系统，如何实现高可用？
等等等等.....
```
尼恩团队结合资深架构经验和行业案例，给大家梳理一个体系化、系统化的参考答案，

并且组成一个电子书 **《分布式 ID 学习圣经：1000 w 级 qps 高并发 ID 如何生成》PDF** 电子书，帮助大家顺
利通过面试，拿到心仪的 offer

并且最终顺利转型三栖架构师。

```
最新《尼恩架构笔记》《尼恩高并发三部曲》《尼恩面试宝典》的 PDF 文件，请关注公众号【技
术自由圈】领取，暗号：领电子书
```
#### 一：超高并发、超高性能分布式 ID 生成系统的要求

在复杂的超高并发、分布式系统中，往往需要对大量的数据和消息进行唯一标识。


如在高并发、分布式的金融、支付、餐饮、酒店、电影等产品的系统中，数据日渐增长，对数据分库分
表后需要有一个唯一 ID 来标识一条数据或消息，数据库的自增 ID 显然不能满足需求；特别一点的如订
单、骑手、优惠券也都需要有唯一 ID 做标识。

此时一个能够生成全局唯一 ID 的系统是非常必要的。

概括下来，那业务系统对 ID 号的要求有哪些呢？

主要有四点：

```
1. 全局唯一性 ：不能出现重复的 ID 号，既然是唯一标识，这是最基本的要求。
2. 趋势递增 ：在 MySQL InnoDB 引擎中使用的是聚集索引，由于多数 RDBMS 使用 B-tree 的数据结构
来存储索引数据，在主键的选择上面我们应该尽量使用有序的主键保证写入性能。
3. 单调递增 ：保证下一个 ID 一定大于上一个 ID，例如事务版本号、IM 增量消息、排序等特殊需求。
4. 信息安全 ：如果 ID 是连续的，恶意用户的扒取工作就非常容易做了，直接按照顺序下载指定 URL 即
可；如果是订单号就更危险了，竞对可以直接知道我们一天的单量。所以在一些应用场景下，会需
要 ID 无规则、不规则。
```
注意，上述 1234 对应不同的场景，

特别注意： **3 和 4 需求还是互斥的** ，无法使用同一个方案满足。

同时除了对 ID 号码自身的要求，业务还对 ID 号生成系统的可用性要求极高，并且处于业务的黄金链路
上，

想象一下，如果 ID 生成系统瘫痪，整个系统黄金链路上关键动作都无法执行，这就会带来一场灾难。

###### 超高并发、超高性能分布式 ID 生成系统三个超高

由此总结下一个 ID 生成系统应该做到如下三个超高：

```
1. 超低延迟 ：平均延迟和 TP 999 延迟都要尽可能低；
2. 超高可用 ：可用性 5 个 9 ；
3. 超高并发 ： 高 QPS。
```
超高并发，最好是 100 Wqps 以上，比如滴滴的 tinyid，就达到千万 QPS，具体见后文

**按照尼恩的架构哲学，咱们从最为基础的原理讲起，来看看一个基本的问题：**

```
什么是本地 ID 生成器？
什么是分布式 ID 生成器？
```
#### 二：什么是本地 ID 生成器、分布式 ID 生成器

本地 ID 生成器是指在本地环境中生成唯一标识符（ID）的工具或算法。

本地 ID 生成器是相对于分布式 ID 生成器而言的。二者的区分不是 ID 的用途，而是生产 ID 是否存在网络
IO 开销：

```
本地 ID 生成器在本地生产 ID，没有网络 IO 开销；
分布式 ID 生成器需要进行远程调用生产 ID，有网络 IO 开销；
```
总之，本地 ID 生成器所生产的 ID 并不是仅仅用于本地，也会用于分布式系统，拥有分布式系统中唯一标
识实体或资源，例如数据库记录、消息、文件等。

在设计本地 ID 生成器时，需要考虑以下几个方面：


```
1. 唯一性 ：生成的 ID 必须在整个系统中是唯一的，以避免冲突。
2. 可排序性 ：生成的 ID 应该具有可排序性，以便根据 ID 的顺序进行查询和排序操作。
3. 性能 ：ID 生成的过程应该高效，不应该成为系统的瓶颈。
4. 可读性 ：生成的 ID 可以是可读的，便于调试和理解。
5. 分布式支持 ：如果系统是分布式的，需要确保在多个节点上生成的 ID 也是唯一的。
```
###### 常见的本地 ID 生成器算法包括：

```
1. 自增 ID ：使用一个计数器，在每次生成 ID 时递增。这种方式简单高效，但在分布式环境中需要额
外的考虑，以避免冲突。
2. UUID （Universally Unique Identifier）：使用标准的 UUID 算法生成唯一的 128 位标识符。UUID
可以使用时间戳、MAC 地址等信息来保证唯一性，但不具备可排序性。
3. 雪花算法 （Snowflake）：雪花算法是 Twitter 开源的一种分布式 ID 生成算法。它使用一个 64 位的
整数，结合时间戳、机器 ID 和序列号来生成唯一的 ID。雪花算法具备可排序性和高性能，适用于
分布式环境。
```
###### 常见的分布式 ID 生成器算法包括：

```
数据库自增 id，如 Mysql 生产 ID
Redis 生成 ID
Mongdb 生产 ID
zookeeper 生产 ID
其他的分布式生产 ID
分布式雪花算法
分布式号段算法
```
#### 三：详解：常见的本地 ID 生成器算法

###### （一）uuid

UUID 是一种本地生成 ID 的方式，

UUID (Universally Unique Identifier) 的标准型式包含 32 个 16 进制数字，以连字号分为五段，形式为 8-
4-4-4-12 的 36 个字符。

UUID 的优点是：性能非常高，本地生成，没有网络消耗；

UUID 的缺点是：不易于存储，信息不安全

uuid 有两种包：

```
github. com/google/uuid ，仅支持 V 1 和 V 4 版本。
github. com/gofrs/uuid ，支持全部五个版本。
```
下面简单说下五种版本的区别：

```
Version 1，基于 mac 地址、时间戳。
Version 2，based on timestamp，MAC address and POSIX UID/GID (DCE 1.1)
Version 3，Hash 获取入参并对结果进行 MD 5。
Version 4，纯随机数。
Version 5，based on SHA-1 hashing of a named value。
```

**特点**

```
5 个版本可供选择。
定长 36 字节，偏长。
无序。
```
**参考案例：**

特别说明： 尼恩社区强调 **JAVA+GO+BIGDATA 三栖架构** ，后面的案例，会混用 go 和 java 两种语言。

下面是 go 版本的 uuid 算法实现。

###### （二）shortuuid

```
初始值基于 uuid Version 4；
第二步根据 alphabet 变量长度 (定长 57) 计算 id 长度 (定长 22)；
第三步依次用 DivMod（欧几里得除法和模）返回值与 alphabet 做映射，合并生成 id。
```
**特点**

```
基于 uuid，但比 uuid 的长度短，定长 22 字节。
```
特别说明： 尼恩社区强调 **JAVA+GO+BIGDATA 三栖架构** ，后面的案例，会混用 go 和 java 两种语言。

下面是 go 版本的 shortuuid 算法实现。

```
package mian
```
```
import (
"github. com/gofrs/uuid"
"fmt"
)
```
```
func main () {
// Version 1: 时间+Mac 地址
id, err := uuid. NewV 1 ()
if err != nil {
fmt.Printf ("uuid NewUUID err:%+v", err)
}
// id: f 0629 b 9 a-0 cee-11 ed-8 d 44-784 f 435 f 60 a 4 length: 36
fmt.Println ("id: ", id.String (), "length: ", len (id.String ()))
```
```
// Version 4: 是纯随机数, error 会在内部报 panic
id, err = uuid. NewV 4 ()
if err != nil {
fmt.Printf ("uuid NewUUID err:%+v", err)
}
// id: 3 b 4 d 1268-9150-447 c-a 0 b 7-bbf 8 c 271 f 6 a 7 length: 36
fmt.Println ("id: ", id.String (), "length: ", len (id.String ()))
}
```

###### （三）xid

XID（eXtended Identifier）是一个用于生成全局唯一标识符（GUID）的库。它是一个基于时间的、分
布式的 ID 生成算法，旨在提供高性能和唯一性。

XID 生成的 ID 是一个 64 位的整数，由以下部分组成：

```
1. 时间戳（ 40 位） ：使用 40 位存储纳秒级的时间戳，可以支持约 34 年的时间范围。与雪花算法不
同，XID 使用纳秒级时间戳，因此具有更高的时间分辨率。
2. 机器 ID（ 16 位） ：使用 16 位表示机器的唯一标识符。每个机器在分布式系统中应具有唯一的机器
ID，可以手动配置或通过自动分配获得。
3. 序列号（ 8 位） ：使用 8 位表示在同一纳秒内生成的序列号。如果在同一纳秒内生成的 ID 数量超过
了 8 位能够表示的范围，那么会等待下一纳秒再生成 ID。
```
xid 是由时间戳、进程 id、Mac 地址、随机数组成。

有序性来源于对随机数部分的原子+1。

```
package mian
```
```
import (
"github. com/lithammer/shortuuid/v 4"
"fmt"
)
```
```
func main () {
id := shortuuid.New ()
// id: iDeUtXY 5 JymyMSGXqsqLYX length: 22
fmt.Println ("id: ", id, "length: ", len (id))
```
```
// V 22 s 2 vag 9 bQEZCWcyv 5 SzL 固定不变
id = shortuuid.NewWithNamespace ("http://127.0.0.1.com")
// id: K 7 pnGHAp 7 WLKUSducPeCXq length: 22
fmt.Println ("id: ", id, "length: ", len (id))
```
```
// NewWithAlphabet 函数可以用于自定义的基础字符串，字符串要求不重复、定长 57
str := "12345#$%^&*67890 qwerty/;'~!@uiopasdfghjklzxcvbnm,. ()_+·><"
id = shortuuid.NewWithAlphabet (str)
// id: q 7! o_+y ('@;_&dyhk_in 9/ length: 22
fmt.Println ("id: ", id, "length: ", len (id))
}
```

**XID 特点**

```
长度短。
有序。
不重复。
时间戳这个随机数原子+1 操作，避免了时钟回拨的问题。
```
XID 生成的 ID 是趋势递增、唯一且可排序的，适用于分布式环境下的 ID 生成需求。与雪花算法相比，XID
具有更高的时间分辨率，但在唯一性方面稍微弱一些，因为它使用了较短的机器 ID 和序列号。

XID 库提供了生成 ID、解析 ID 和验证 ID 的功能。

以下是使用 Go 语言中的 XID 库生成 ID 的示例代码：

上述代码导入了 XID 库，并使用 xid.New () 函数生成一个新的 XID。通过调用 String () 方法，可以将
XID 转换为字符串形式进行打印输出。

总之，XID 是一个用于生成全局唯一标识符的库，基于时间和机器 ID 生成唯一的 ID。

###### （四）ksuid

KSUID（K-Sortable Unique Identifier）是一种用于生成全局唯一标识符（GUID）的算法和格式。它
是由 Segment. io 开发的一种分布式 ID 生成方案，旨在提供高性能、唯一性和可排序性。

KSUID 生成的 ID 是一个全局唯一的字符串，由以下部分组成：

```
1. 时间戳（ 32 位） ：使用 32 位存储秒级的时间戳，表示自协调世界时（UTC） 1970 年 1 月 1 日以来的
秒数。与传统的 UNIX 时间戳相比，KSUID 使用了更长的时间戳，可以支持更长的时间范围。
2. 随机字节（ 16 位） ：使用 16 位随机生成的字节，用于增加 ID 的唯一性。
3. 附加信息（可选） ：在 KSUID 的格式中，还可以包含附加的信息，例如节点 ID 或其他标识符。这部
分是可选的，可以根据需要进行使用。
```
KSUID 生成的 ID 是按照时间顺序排序的，因此可以方便地按照生成的顺序进行排序和比较。它具有全局
唯一性，并且不依赖于任何中央化的 ID 生成服务。

以下是使用 Go 语言中的 github. com/segmentio/ksuid 库生成 KSUID 的示例代码：

```
package main
```
```
import (
"fmt"
"github. com/rs/xid"
)
```
```
func main () {
// 生成一个新的 XID
id := xid.New ()
```
```
// 打印生成的 ID
fmt.Println (id.String ())
}
```
```
package main
```

上述代码导入了 github. com/segmentio/ksuid 库，并使用 ksuid.New () 函数生成一个新的 KSUID。
通过调用 String () 方法，可以将 KSUID 转换为字符串形式进行打印输出。

总之，KSUID 是一种用于生成全局唯一标识符的算法和格式。它具有高性能、唯一性和可排序性的特
点，适用于分布式系统中的 ID 生成需求。通过使用 github. com/segmentio/ksuid 库，可以方便地生
成和操作 KSUID。

###### （五）ulid

随机数和时间戳组成

###### （六）snowflake

大名鼎鼎的雪花算法，重点介绍。

Snowflake 是 Twitter 开源的一种分布式 ID 生成算法，用于在分布式系统中生成全局唯一的 ID。它的设计
目标是高性能、低延迟和趋势递增的 ID 生成。

Snowflake 生成的 ID 是一个 64 位的整数，由以下部分组成：

```
1. 时间戳（ 41 位） ：使用 41 位存储毫秒级的时间戳，表示自定义的起始时间（Epoch）到生成 ID 的
时间之间的毫秒数。
2. 节点 ID（ 10 位） ：用于标识不同的节点或机器。在分布式系统中，每个节点应具有唯一的节点
ID。
```
```
import (
"fmt"
"github. com/segmentio/ksuid"
)
```
```
func main () {
// 生成一个新的 KSUID
id := ksuid.New ()
```
```
// 打印生成的 ID
fmt.Println (id.String ())
}
```
```
package mian
```
```
import (
"github. com/oklog/ulid"
"fmt"
)
```
```
func main () {
t := time.Now (). UTC ()
entropy := rand.New (rand.NewSource (t.UnixNano ()))
id := ulid.MustNew (ulid.Timestamp (t), entropy)
// id: 01 G 902 ZSM 96 WV 5 D 5 DC 5 WFHF 8 WY length: 26
fmt.Println ("id: ", id.String (), "length: ", len (id.String ()))
}
```

```
3. 序列号（ 12 位） ：在同一毫秒内生成的序列号。如果在同一毫秒内生成的 ID 数量超过了 12 位能够
表示的范围，那么会等待下一毫秒再生成 ID。
```
Snowflake 生成的 ID 具有趋势递增的特点，因为高位部分是基于时间戳生成的。这样设计的目的是为了
在数据库索引中提供更好的性能，使新生成的 ID 更容易被插入到索引的末尾，减少索引的分裂和碎片
化。

以下是一个使用 Go 语言实现 Snowflake 算法的简单示例：

```
package main
```
```
import (
"fmt"
"sync"
"time"
)
```
```
const (
epoch = int 64 ( 1609459200000 ) // 起始时间戳，这里使用 2021 年 1 月 1 日的时间戳
nodeBits = 10 // 节点 ID 的位数
sequenceBits = 12 // 序列号的位数
)
```
```
// Snowflake 结构体
type Snowflake struct {
mu sync. Mutex
timestamp int 64
nodeID int 64
sequence int 64
}
```
```
// NewSnowflake 创建一个新的 Snowflake 实例
func NewSnowflake (nodeID int 64) *Snowflake {
return &Snowflake{
timestamp: 0 ,
nodeID:  nodeID,
sequence: 0 ,
}
}
```
```
// Generate 生成一个新的 ID
func (sf *Snowflake) Generate () int 64 {
sf.mu.Lock ()
defer sf.mu.Unlock ()
```
```
now := time.Now (). UnixNano () / 1 e 6
if now < sf. timestamp {
panic ("Invalid system clock")
}
```
```
if now == sf. timestamp {
sf. sequence = (sf. sequence + 1 ) & (( 1 << sequenceBits) - 1 )
if sf. sequence == 0 {
// 序列号用尽，等待下一毫秒
for now <= sf. timestamp {
now = time.Now (). UnixNano () / 1 e 6
}
```

上述示例代码实现了一个简单的 Snowflake 算法，通过调用 Generate () 方法生成一个新的 ID。在示例
中，我们使用当前时间戳作为时间基准，并传入节点 ID 作为参数。

总之，Snowflake 是一种分布式 ID 生成算法，用于在分布式系统中生成全局唯一的 ID。它具有高性能、
低延迟和趋势递增的特点，适用于需要在分布式环境下生成唯一 ID 的场景。

相对于 UUID 来说，雪花算法不会暴露 MAC 地址更安全、生成的 ID 也不会过于冗余。

雪花的一部分 ID 序列是基于时间戳的，那么时钟回拨的问题就来了。

snowflake 存在一个很大的问题：时钟回拨问题

**什么是时钟回拨问题**

服务器上的时间突然倒退回之前的时间：

```
可能是人为的调整时间；
也可能是服务器之间的时间校对。
```
具体来说，时钟回拨（Clock Drift）指的是系统时钟在某个时刻向回调整，即时间向过去移动。时钟回
拨可能发生在分布式系统中的某个节点上，这可能是由于时钟同步问题、时钟漂移或其他原因导致的。

时钟回拨可能对系统造成一些问题，特别是对于依赖于时间顺序的应用程序或算法。

在分布式系统中，时钟回拨可能导致以下问题：

```
1. ID 冲突 ：如果系统使用基于时间的算法生成唯一 ID（如雪花算法），时钟回拨可能导致生成的 ID
与之前生成的 ID 冲突，破坏了唯一性。
2. 数据不一致 ：时钟回拨可能导致不同节点之间的时间戳不一致，这可能影响到分布式系统中的时间
相关操作，如事件排序、超时判断等。数据的一致性可能会受到影响。
3. 缓存失效 ：时钟回拨可能导致缓存中的过期时间计算错误，使得缓存项在实际过期之前被错误地认
为是过期的，从而导致缓存失效。
```
为了应对时钟回拨问题，可以采取以下措施：

```
1. 使用时钟同步服务 ：通过使用网络时间协议（NTP）等时钟同步服务，可以将节点的时钟与参考时
钟进行同步，减少时钟回拨的可能性。
2. 引入时钟漂移校正 ：在分布式系统中，可以通过周期性地校正节点的时钟漂移，使其保持与其他节
点的时间同步。
```
```
}
} else {
sf. sequence = 0
}
```
```
sf. timestamp = now
id := (now-epoch)<<nodeBits | sf. nodeID<<sequenceBits | sf. sequence
return id
}
```
```
func main () {
// 创建一个 Snowflake 实例，传入节点 ID
sf := NewSnowflake ( 1 )
```
```
// 生成 ID 并打印
id := sf.Generate ()
fmt.Println (id)
}
```

```
3. 容忍时钟回拨 ：某些应用场景下，可以容忍一定范围的时钟回拨。在设计应用程序时，可以考虑引
入一些容错机制，以适应时钟回拨带来的影响。
```
总之，时钟回拨是分布式系统中需要关注的一个问题，可能对系统的时间相关操作、数据一致性和唯一
ID 生成等方面产生影响。

通过使用时钟同步服务、时钟漂移校正和容忍机制等方法，可以减少时钟回拨带来的问题。

关于时钟回拨，咱们在《10 Wqps 推送中台架构与实操》中，做了一个非常细致、详尽的介绍，这里
不做赘述。

#### 四、分布式 ID：数据库自增 ID

这里常规是指数据库主键自增索引。

特点如下：

```
架构简单容易实现。
ID 有序递增，IO 写入连续性好。
INT 和 BIGINT 类型占用空间较小。
由于有序递增，易暴露业务量。
受到数据库性能限制，对高并发场景不友好。
bigint 最大是 2^64-1，但是数据库单表肯定放不了这么多，那么就涉及到分表。如果业务量真的太
大了，主键的自增 id 涨到头了，会发生什么？报错：主键冲突。
```
#### 五、分布式 ID：Redis 生成 ID

通过 redis 的原子操作 INCR 和 INCRBY 获得 id。

相比数据库自增 ID，redis 性能更好、更加灵活。

不过架构强依赖 redis，redis 在整个架构中会产生单点问题。

在流量较大的场景下，网络耗时也可能成为瓶颈。

#### 六、分布式 ID：ZooKeeper 唯一 ID

ZooKeeper 是使用了 Znode 结构中的 Zxid 实现顺序增 ID。

Zookeeper 类似一个文件系统，每个节点都有唯一路径名 (Znode)，Zxid 是个全局事务计数器，每个节
点发生变化都会记录响应的版本 (Zxid)，这个版本号是全局唯一且顺序递增的。

这种架构还是出现了 ZooKeeper 的单点问题。

#### 七、分布式雪花算法

虽然 Snowflake 可以很容易扩展成为分布式架构

```
Snowflake + 机器固定编号
Snowflake +zookeeper 自增编号
Snowflake + 数据库自增编号
....
```

分布式雪花算法的代表作：百度的 UidGenerator

UidGenerator 是 Java 实现的, 基于 Snowflake 算法的唯一 ID 生成器。

UidGenerator 以组件形式工作在应用项目中, 支持自定义 workerId 位数和初始化策略, 从而适用于
docker 等虚拟化环境下实例自动重启、漂移等场景。

在实现上, UidGenerator 通过借用未来时间来解决 sequence 天然存在的并发限制; 采用 RingBuffer 来缓
存已生成的 UID, 并行化 UID 的生产和消费, 同时对 CacheLine 补齐，避免了由 RingBuffer 带来的硬件级
「伪共享」问题. 最终单机 QPS 可达 600 万。

```
40 岁老架构师尼恩提示：有关百度的 UidGenerator 的底层原理、具体使用，
```
```
稍后一点详细介绍。
```
#### 7.1 分布式雪花 ID 方案 1 ： 600 万 qps 的百度

#### UidGenerator

UidGenerator 是 Java 实现的, 基于 Snowflake 算法的唯一 ID 生成器。

UidGenerator 以组件形式工作在应用项目中, 支持自定义 workerId 位数和初始化策略, 从而适用于
docker 等虚拟化环境下实例自动重启、漂移等场景。

在实现上, UidGenerator 通过借用未来时间来解决 sequence 天然存在的并发限制; 采用 RingBuffer 来缓
存已生成的 UID, 并行化 UID 的生产和消费, 同时对 CacheLine 补齐，避免了由 RingBuffer 带来的硬件级
「伪共享」问题. 最终单机 QPS 可达 600 万。

依赖版本：

```
Java 8 及以上版本,
MySQL (内置 WorkerID 分配器, 启动阶段通过 DB 进行分配; 如自定义实现, 则 DB 非必选依赖）
```
###### 回顾 Snowflake 算法

Snowflake 算法描述：指定机器 & 同一时刻 & 某一并发序列，是唯一的。据此可生成一个 64 bits 的唯
一 ID（long）。

默认采用上图字节分配方式：

```
sign (1 bit)
```
固定 1 bit 符号标识，即生成的 UID 为正数。

```
delta seconds (28 bits)
当前时间，相对于时间基点"2016-05-20"的增量值，单位：秒，最多可支持约 8.7 年
```

```
worker id (22 bits)
机器 id，最多可支持约 420 w 次机器启动。内置实现为在启动时由数据库分配，默认分配策略为用
后即弃，后续可提供复用策略。
sequence (13 bits)
每秒下的并发序列，13 bits 可支持每秒 8192 个并发。
```
**以上参数均可通过 Spring 进行自定义**

###### CachedUidGenerator

RingBuffer 环形数组，数组每个元素成为一个 slot。RingBuffer 容量，默认为 Snowflake 算法中
sequence 最大值，且为 2^N。可通过 boostPower 配置进行扩容，以提高 RingBuffer
读写吞吐量。

Tail 指针、Cursor 指针用于环形数组上读写 slot：

```
Tail 指针
表示 Producer 生产的最大序号 (此序号从 0 开始，持续递增)。Tail 不能超过 Cursor，即生产者不能
覆盖未消费的 slot。当 Tail 已赶上 curosr，此时可通过 rejectedPutBufferHandler 指定
PutRejectPolicy
Cursor 指针
表示 Consumer 消费到的最小序号 (序号序列与 Producer 序列相同)。Cursor 不能超过 Tail，即不能
消费未生产的 slot。当 Cursor 已赶上 tail，此时可通过 rejectedTakeBufferHandler 指定
TakeRejectPolicy
```
CachedUidGenerator 采用了双 RingBuffer，Uid-RingBuffer 用于存储 Uid、Flag-RingBuffer 用于存储
Uid 状态 (是否可填充、是否可消费)

由于数组元素在内存中是连续分配的，可最大程度利用 CPU cache 以提升性能。但同时会带来「伪共
享」FalseSharing 问题，为此在 Tail、Cursor 指针、Flag-RingBuffer 中采用了 CacheLine 补齐方式。


**RingBuffer 填充时机**

```
初始化预填充
RingBuffer 初始化时，预先填充满整个 RingBuffer.
即时填充
Take 消费时，即时检查剩余可用 slot 量 (tail - cursor)，如小于设定阈值，则补全空闲 slots。阈
值可通过 paddingFactor 来进行配置，请参考 Quick Start 中 CachedUidGenerator 配置
周期填充
通过 Schedule 线程，定时补全空闲 slots。可通过 scheduleInterval 配置，以应用定时填充功
能，并指定 Schedule 时间间隔
```
###### UidGeneratorQuick Start

这里介绍如何在基于 Spring 的项目中使用 UidGenerator, 具体流程如下:

**步骤 1: 安装依赖**

先下载 Java 8, MySQL 和 Maven

**设置环境变量**

maven 无须安装, 设置好 MAVEN_HOME 即可. 可像下述脚本这样设置 JAVA_HOME 和 MAVEN_HOME, 如
已设置请忽略.

**步骤 2: 创建表 WORKER_NODE**

运行 sql 脚本以导入表 WORKER_NODE, 脚本如下:

```
export MAVEN_HOME=/xxx/xxx/software/maven/apache-maven-3.3.9
export PATH=$MAVEN_HOME/bin:$PATH
JAVA_HOME="/Library/Java/JavaVirtualMachines/jdk 1.8.0_91. jdk/Contents/Home";
export JAVA_HOME;
```

修改 mysql. properties 配置中, jdbc. url, jdbc. username 和 jdbc. password, 确保库地址, 名称, 端口号, 用
户名和密码正确.

**步骤 3: 修改 Spring 配置**

提供了两种生成器: DefaultUidGenerator、CachedUidGenerator。

如对 UID 生成性能有要求, 请使用 CachedUidGenerator

对应 Spring 配置分别为: https://github.com/baidu/uid-generator/blob/master/default-uid-
spring. xml、cached-uid-spring. xml

**DefaultUidGenerator 配置**

**CachedUidGenerator 配置**

```
DROP DATABASE IF EXISTS `xxxx`;
CREATE DATABASE `xxxx` ;
use `xxxx`;
DROP TABLE IF EXISTS WORKER_NODE;
CREATE TABLE WORKER_NODE
(
ID BIGINT NOT NULL AUTO_INCREMENT COMMENT 'auto increment id',
HOST_NAME VARCHAR ( 64 ) NOT NULL COMMENT 'host name',
PORT VARCHAR ( 64 ) NOT NULL COMMENT 'port',
TYPE INT NOT NULL COMMENT 'node type: ACTUAL or CONTAINER',
LAUNCH_DATE DATE NOT NULL COMMENT 'launch date',
MODIFIED TIMESTAMP NOT NULL COMMENT 'modified time',
CREATED TIMESTAMP NOT NULL COMMENT 'created time',
PRIMARY KEY (ID)
)
COMMENT='DB WorkerID Assigner for UID Generator', ENGINE = INNODB;
```
```
<!-- DefaultUidGenerator -->
<bean id="defaultUidGenerator"
class="com. baidu. fsg. uid. impl. DefaultUidGenerator" lazy-init="false">
<property name="workerIdAssigner" ref="disposableWorkerIdAssigner"/>
```
```
<!-- Specified bits & epoch as your demand. No specified the default value
will be used -->
<property name="timeBits" value="29"/>
<property name="workerBits" value="21"/>
<property name="seqBits" value="13"/>
<property name="epochStr" value="2016-09-20"/>
</bean>
```
```
<!-- 用完即弃的WorkerIdAssigner，依赖DB操作 -->
<bean id="disposableWorkerIdAssigner"
class="com. baidu. fsg. uid. worker. DisposableWorkerIdAssigner" />
```
```
<!-- CachedUidGenerator -->
<bean id="cachedUidGenerator" class="com.baidu.fsg.uid.impl.CachedUidGenerator">
<property name="workerIdAssigner" ref="disposableWorkerIdAssigner" />
```
```
<!-- 以下为可选配置, 如未指定将采用默认值 -->
<!-- Specified bits & epoch as your demand. No specified the default value
will be used -->
```

**Mybatis 配置**

mybatis-spring. xml 配置说明如下:

```
<property name="timeBits" value="29"/>
<property name="workerBits" value="21"/>
<property name="seqBits" value="13"/>
<property name="epochStr" value="2016-09-20"/>
```
```
<!-- RingBuffer size扩容参数, 可提高UID生成的吞吐量. -->
<!-- 默认:3， 原bufferSize=8192, 扩容后bufferSize= 8192 << 3 = 65536 -->
<property name="boostPower" value="3"></property>
```
```
<!-- 指定何时向RingBuffer中填充UID, 取值为百分比(0, 100), 默认为50 -->
<!-- 举例: bufferSize=1024, paddingFactor=50 -> threshold=1024 * 50 / 100 =
```
512. -->
<!-- 当环上可用UID数量 < 512时, 将自动对RingBuffer进行填充补全 -->
<property name="paddingFactor" value="50"></property>

```
<!-- 另外一种RingBuffer填充时机, 在Schedule线程中, 周期性检查填充 -->
<!-- 默认: 不配置此项, 即不实用 Schedule 线程. 如需使用, 请指定 Schedule 线程时间间隔, 单
位: 秒 -->
<property name="scheduleInterval" value="60"></property>
```
```
<!-- 拒绝策略: 当环已满, 无法继续填充时 -->
<!-- 默认无需指定, 将丢弃 Put 操作, 仅日志记录. 如有特殊需求, 请实现
RejectedPutBufferHandler 接口 (支持 Lambda 表达式) -->
<property name="rejectedPutBufferHandler" ref="XxxxYourPutRejectPolicy">
</property>
```
```
<!-- 拒绝策略: 当环已空, 无法继续获取时 -->
<!-- 默认无需指定, 将记录日志, 并抛出 UidGenerateException 异常. 如有特殊需求, 请实现
RejectedTakeBufferHandler 接口 (支持 Lambda 表达式) -->
<property name="rejectedTakeBufferHandler" ref="XxxxYourTakeRejectPolicy">
</property>
```
```
</bean>
```
```
<!-- 用完即弃的WorkerIdAssigner, 依赖DB操作 -->
<bean id="disposableWorkerIdAssigner"
class="com. baidu. fsg. uid. worker. DisposableWorkerIdAssigner" />
```
```
<!-- Spring annotation扫描 -->
<context:component-scan base-package="com.baidu.fsg.uid" />
```
```
<bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean">
<property name="dataSource" ref="dataSource" />
<property name="mapperLocations" value="classpath:/META-
INF/mybatis/mapper/M_WORKER*. xml" />
</bean>
```
```
<!-- 事务相关配置 -->
<tx:annotation-driven transaction-manager="transactionManager" order="1" />
```
```
<bean id="transactionManager"
class="org. springframework. jdbc. datasource. DataSourceTransactionManager">
<property name="dataSource" ref="dataSource" />
```

**步骤 4: 运行示例单测**

运行单测 CachedUidGeneratorTest, 展示 UID 生成、解析等功能

```
</bean>
```
```
<!-- Mybatis Mapper扫描 -->
<bean class="org.mybatis.spring.mapper.MapperScannerConfigurer">
<property name="annotationClass"
value="org. springframework. stereotype. Repository" />
<property name="basePackage" value="com.baidu.fsg.uid.worker.dao" />
<property name="sqlSessionFactoryBeanName" value="sqlSessionFactory" />
</bean>
```
```
<!-- 数据源配置 -->
<bean id="dataSource" parent="abstractDataSource">
<property name="driverClassName" value="${mysql.driver}" />
<property name="maxActive" value="${jdbc.maxActive}" />
<property name="url" value="${jdbc.url}" />
<property name="username" value="${jdbc.username}" />
<property name="password" value="${jdbc.password}" />
</bean>
```
```
<bean id="abstractDataSource" class="com. alibaba. druid. pool. DruidDataSource"
destroy-method="close">
<property name="filters" value="${datasource.filters}" />
<property name="defaultAutoCommit" value="${datasource. defaultAutoCommit}"
/>
<property name="initialSize" value="${datasource.initialSize}" />
<property name="minIdle" value="${datasource.minIdle}" />
<property name="maxWait" value="${datasource.maxWait}" />
<property name="testWhileIdle" value="${datasource.testWhileIdle}" />
<property name="testOnBorrow" value="${datasource.testOnBorrow}" />
<property name="testOnReturn" value="${datasource.testOnReturn}" />
<property name="validationQuery" value="${datasource.validationQuery}" />
<property name="timeBetweenEvictionRunsMillis"
value="${datasource. timeBetweenEvictionRunsMillis}" />
<property name="minEvictableIdleTimeMillis"
value="${datasource. minEvictableIdleTimeMillis}" />
<property name="logAbandoned" value="${datasource.logAbandoned}" />
<property name="removeAbandoned" value="${datasource.removeAbandoned}" />
<property name="removeAbandonedTimeout"
value="${datasource. removeAbandonedTimeout}" />
</bean>
```
```
<bean id="batchSqlSession" class="org.mybatis.spring.SqlSessionTemplate">
<constructor-arg index="0" ref="sqlSessionFactory" />
<constructor-arg index="1" value="BATCH" />
</bean>
```

#### 7.2 分布式雪花 ID 方案 2 ：美团 Leaf-snowflake

美团 Leaf-snowflake 方案，属于 Snowflake +zookeeper 自增编号的类型。

###### 美团 Leaf-snowflake 架构

```
用 Zookeeper 顺序增、全局唯一的节点版本号，替换了原有的机器地址。
强依赖 ZooKeeper 的缺点：强依赖 ZooKeeper、大流量下的网络下，存在网络瓶颈。
解决了时钟回拨的问题。运行时运行时，时差小于 5 ms 会等待时差两倍时间，如果时差大于 5 ms 报
警并停止启动。
通过缓存一个 ZooKeeper 文件夹，提高可用性。
```
```
@Resource
private UidGenerator uidGenerator;
```
```
@Test
public void testSerialGenerate () {
// Generate UID
long uid = uidGenerator.getUID ();
```
```
// Parse UID into [Timestamp, WorkerId, Sequence]
// {"UID": "180363646902239241","parsed":{ "timestamp": "2017-01-19
12:15:46", "workerId": "4", "sequence": "9" }}
System.out.println (uidGenerator.parseUID (uid));
}
```

Leaf-snowflake 方案完全沿用 snowflake 方案的 bit 位设计，即是“1+41+10+12”的方式组装 ID 号。

对于 workerID 的分配，当服务集群数量较小的情况下，完全可以手动配置。Leaf 服务规模较大，动手配
置成本太高。

所以使用 Zookeeper 持久顺序节点的特性自动对 snowflake 节点配置 wokerID。

Leaf-snowflake 是按照下面几个步骤启动的：


```
1. 启动 Leaf-snowflake 服务，连接 Zookeeper，在 leaf_forever 父节点下检查自己是否已经注册过
（是否有该顺序子节点）。
2. 如果有注册过直接取回自己的 workerID（zk 顺序节点生成的 int 类型 ID 号），启动服务。
3. 如果没有注册过，就在该父节点下面创建一个持久顺序节点，创建成功后取回顺序号当做自己的
workerID 号，启动服务。
```
###### 从强依赖 ZooKeeper 优化为弱依赖 ZooKeeper

除了每次会去 ZK 拿数据以外，也会在本机文件系统上缓存一个 workerID 文件。

当 ZooKeeper 出现问题，恰好机器出现问题需要重启时，能保证服务能够正常启动。

这样做到了对三方组件的弱依赖。

一定程度上提高了系统的可用性。

###### 解决时钟问题

因为这种方案依赖时间，如果机器的时钟发生了回拨，那么就会有可能生成重复的 ID 号，需要解决时钟
回退的问题。


参见上图整个启动流程图，服务启动时首先检查自己是否写过 ZooKeeper leaf_forever 节点：

```
1. 若写过，则用自身系统时间与 leaf_forever/${self}节点记录时间做比较，若小于
leaf_forever/${self}时间则认为机器时间发生了大步长回拨，服务启动失败并报警。
2. 若未写过，证明是新服务节点，直接创建持久节点 leaf_forever/${self}并写入自身系统时
间，接下来综合对比其余 Leaf 节点的系统时间来判断自身系统时间是否准确，具体做法是取
leaf_temporary 下的所有临时节点 (所有运行中的 Leaf-snowflake 节点) 的服务 IP：Port，然后通过
RPC 请求得到所有节点的系统时间，计算 sum (time)/nodeSize。
3. 若 abs ( 系统时间-sum (time)/nodeSize) < 阈值，认为当前系统时间准确，正常启动服务，同时
写临时节点 leaf_temporary/${self} 维持租约。
4. 否则认为本机系统时间发生大步长偏移，启动失败并报警。
5. 每隔一段时间 (3 s) 上报自身系统时间写入 leaf_forever/${self}。
```

由于强依赖时钟，对时间的要求比较敏感，在机器工作时 NTP 同步也会造成秒级别的回退，建议可以直
接关闭 NTP 同步。

要么在时钟回拨的时候直接不提供服务直接返回 ERROR_CODE，等时钟追上即可。

**或者做一层重试，然后上报报警系统，更或者是发现有时钟回拨之后自动摘除本身节点并报警** ，如下：

**从上线情况来看，在 2017 年闰秒出现那一次出现过部分机器回拨，由于 Leaf-snowflake 的策略保证，
成功避免了对业务造成的影响。**

#### 八、分布式 ID：号段模式

号段模式 ID 生成器是一种常见的本地 ID 生成器算法，也称为段号生成器或区间号生成器。它通过预分配
一段连续的 ID 号段，然后在本地使用这些号段来生成唯一的 ID。

具体的工作流程如下：

```
1. 预分配号段 ：在生成 ID 之前，首先预分配一段连续的 ID 号段。例如，可以预分配一个范围为
1,000,000 到 1,999,999 的号段。
2. 本地使用号段 ：在本地环境中，每次需要生成 ID 时，从预分配的号段中获取一个 ID。可以使用一
个计数器来记录当前使用的 ID，在获取一个 ID 后，将计数器递增。
3. 号段用尽时重新分配 ：当本地使用的号段用尽时，再次预分配一个新的号段。可以通过一种机制来
触发重新分配，例如当计数器超过当前号段的上限时。
4. 确保唯一性 ：在分布式环境中，可以为每个节点分配不同的号段，以确保生成的 ID 在整个分布式
系统中是唯一的。
```
号段模式 ID 生成器的优点是简单高效，生成的 ID 具备可排序性，并且可以在本地环境中生成唯一的 ID。
然而，需要注意的是，在分布式环境中，需要额外的机制来协调不同节点之间的号段分配，以避免冲突
和重复。

```
//发生了回拨，此刻时间小于上次发号时间
if (timestamp < lastTimestamp) {
```
```
long offset = lastTimestamp - timestamp;
if (offset <= 5 ) {
try {
//时间偏差大小小于 5 ms，则等待两倍时间
wait (offset << 1 );//wait
timestamp = timeGen ();
if (timestamp < lastTimestamp) {
//还是小于，抛异常并上报
throwClockBackwardsEx (timestamp);
}
} catch (InterruptedException e) {
throw e;
}
} else {
//throw
throwClockBackwardsEx (timestamp);
}
}
//分配 ID
```

主要的号段模式实现方案非常多，主要如下：

###### （一）Leaf-segment（叶段模式）

Leaf-segment（叶段）是一种分布式 ID 生成方案，它基于号段模式 ID 生成器的思想。

Leaf-segment 的设计目标是在分布式环境下生成高性能、可排序、唯一的 ID。

具体工作流程如下：

```
1. 预分配号段 ：Leaf-segment 将 ID 号段分为多个小段（segment），每个小段包含一定数量的 ID。
这些小段可以在分布式环境中的不同节点上进行分配，每个节点负责管理和生成自己分配到的小
段。
2. 本地使用号段 ：在每个节点上，本地维护一个当前号段（current segment）的指针，指向当前使
用的号段。当需要生成 ID 时，节点会从当前号段中获取一个 ID，并将指针递增。
3. 号段用尽时重新分配 ：当节点的当前号段用尽时，节点会向中心化的协调者（coordinator）请求
获取一个新的号段。协调者负责分配新的号段，并将新的号段分配给请求的节点。
4. 确保唯一性 ：通过将每个节点分配不同的号段，Leaf-segment 保证了在整个分布式系统中生成的
ID 是唯一的。
```
和数据库的自增主键相比，Leaf-segment（叶段）把数据库自增主键换成了计数法。

Leaf-segment（叶段） 每个业务分配一个 biz_tag、并记录各业务最大 id (max_id)、号段跨度 (step) 等数
据。

这样每次取号只需要更新 biz_tag 对应的 max_id，就可以拿到 step 个 id。


Leaf-segment 的优点是具备高性能、可排序和唯一性，并且可以在分布式环境中有效地生成 ID。它通
过将 ID 号段分配给每个节点，减少了节点之间的通信和协调开销，提高了生成 ID 的效率。

然而，Leaf-segment 也存在一些注意事项。首先，需要一个可靠的协调者来分配号段，并确保号段的
唯一性。其次，如果协调者发生故障或网络分区，可能会影响新号段的分配和节点的正常运行。因此，
在使用 Leaf-segment 时需要考虑容错和故障恢复机制。

总之，Leaf-segment 是一种可行的分布式 ID 生成方案，适用于需要在分布式环境中生成唯一 ID 的应用
场景。它提供了一种高性能、可排序、唯一的 ID 生成解决方案。

**优点**

```
除了拥有自增 ID 的优点之外，在性能上比自增 ID 更好
```

```
扩展灵活。
使用灵活、可配置性强。
缓存机制，突发状况下短时间内能保证服务正常运转。
```
**缺点**

```
id 是有序自增，容易暴露信息，不可用于订单。
在 leaf 的缓存 ID 用完再去获取新号段的间隙，性能会有波动。
强依赖 DB。
```
###### （二）增强版 Leaf-segment

增强版是对上面描述的缺点 2 进行的改进——双 cache，在 leaf 的 ID 消耗到一定百分比时，常驻的后台进
程会预先去号段服务获取新的号段并缓存。具体消耗百分比、及号段 step 根据业务消耗速度来定。

增强版 Leaf-segment 是对 Leaf-segment 方案的扩展和改进，旨在进一步提升分布式 ID 生成的性能和可
扩展性。

具体来说，增强版 Leaf-segment 在 Leaf-segment 的基础上引入了以下改进：

```
1. 分布式协调者 ：引入多个协调者节点，形成一个分布式的协调者集群。每个协调者负责管理一部分
号段，并协调节点之间的号段分配和归还。这样可以提高协调者的容错性和可用性，并减轻单个协
调者的负载压力。
2. 异步号段分配 ：将号段分配过程改为异步操作。当节点的当前号段用尽时，节点向协调者请求获取
新的号段，但不会阻塞等待结果。而是继续使用当前号段生成 ID，同时在后台等待协调者的响
应。这样可以减少节点的等待时间，提高 ID 生成的效率。
3. 号段预取 ：节点在本地维护一个号段缓存，提前预取一定数量的号段。当节点的当前号段用尽时，
可以直接从缓存中获取下一个号段，而无需立即向协调者请求新的号段。这样可以减少节点与协调
者的通信次数，降低延迟并提高吞吐量。
4. 动态调整号段大小 ：根据系统的负载情况和需求变化，动态调整号段的大小。例如，当系统负载较
低时，可以增加号段的大小，减少号段分配的频率；当系统负载较高时，可以减小号段的大小，提
高号段的利用率。
```

增强版 Leaf-segment 通过引入分布式协调者、异步号段分配、号段预取和动态调整号段大小等改进，
进一步提升了分布式 ID 生成的性能和可扩展性。它能够更好地适应高并发、大规模分布式系统的需求，
并提供可靠、高效的 ID 生成方案。

###### （三）滴滴 Tinyid 号段模式

和增强版 Leaf-segment 类似，也是号段模式，提前加载号段。

#### 8.1 美团 Leaf-segment

Leaf 这个名字是来自德国哲学家、数学家莱布尼茨的一句话： >There are no two identical leaves in
the world > “世界上没有两片相同的树叶”

###### Leaf-segment 数据库方案


美团 Leaf-segment 方案，在使用数据库的方案上，做了如下改变：

```
原方案每次获取 ID 都得读写一次数据库，造成数据库压力大。
```
改为利用 proxy server 批量获取，每次获取一个 segment (step 决定大小) 号段的值。用完之后再去数据
库获取新的号段，可以大大的减轻数据库的压力。

```
各个业务不同的发号需求用 biz_tag 字段来区分，每个 biz-tag 的 ID 获取相互隔离，互不影响。
如果以后有性能需求需要对数据库扩容，不需要上述描述的复杂的扩容操作，只需要对 biz_tag 分
库分表就行。
```
Leaf-segment 数据库数据库表设计如下：

重要字段说明：biz_tag 用来区分业务，max_id 表示该 biz_tag 目前所被分配的 ID 号段的最大值，step 表
示每次分配的号段长度。原来获取 ID 每次都需要写数据库，现在只需要把 step 设置得足够大，比如
1000 。

那么只有当 1000 个号被消耗完了之后才会去重新读写一次数据库。读写数据库的频率从 1 减小到了
1/step，大致架构如下图所示：

```
+-------------+--------------+------+-----+-------------------+-----------------
------------+
| Field | Type | Null | Key | Default | Extra
|
+-------------+--------------+------+-----+-------------------+-----------------
------------+
| biz_tag | varchar ( 128 ) | NO | PRI | |
|
| max_id | bigint ( 20 ) | NO | | 1 |
|
| step | int ( 11 ) | NO | | NULL |
|
| desc | varchar ( 256 ) | YES | | NULL |
|
| update_time | timestamp | NO | | CURRENT_TIMESTAMP | on update
CURRENT_TIMESTAMP |
+-------------+--------------+------+-----+-------------------+-----------------
------------+
```

test_tag 在第一台 Leaf 机器上是 1~1000 的号段，当这个号段用完时，会去加载另一个长度为 step=1000
的号段，假设另外两台号段都没有更新，这个时候第一台机器新加载的号段就应该是 3001~4000。

同时数据库对应的 biz_tag 这条数据的 max_id 会从 3000 被更新成 4000 ，更新号段的 SQL 语句如下：

这种模式有以下优缺点：

优点：

```
Leaf 服务可以很方便的线性扩展，性能完全能够支撑大多数业务场景。
ID 号码是趋势递增的 8 byte 的 64 位数字，满足上述数据库存储的主键要求。
容灾性高：Leaf 服务内部有号段缓存，即使 DB 宕机，短时间内 Leaf 仍能正常对外提供服务。
可以自定义 max_id 的大小，非常方便业务从原有的 ID 方式上迁移过来。
```
缺点：

```
ID 号码不够随机，能够泄露发号数量的信息，不太安全。
TP 999 数据波动大，当号段使用完之后还是会 hang 在更新数据库的 I/O 上，tg 999 数据会出现偶尔
的尖刺。
DB 宕机会造成整个系统不可用。
```
```
Begin
UPDATE table SET max_id=max_id+step WHERE biz_tag=xxx
SELECT tag, max_id, step FROM table WHERE biz_tag=xxx
Commit
```

ID 号码不够随机，能够泄露发号数量的信息，不太安全。比如某个竞争对手在两天中午 12 点分别下单，
通过订单 id 号相减就能大致计算出公司一天的订单量，这个是不能忍受的。面对这一问题，美团提供了
Leaf-snowflake 方案。

```
尼恩提示：美团提供了 Leaf-snowflake 方案，后面介绍。
```
###### 双 buffer 优化

对于第二个缺点，Leaf-segment 做了一些优化，简单的说就是：

Leaf 取号段的时机是在号段消耗完的时候进行的，也就意味着号段临界点的 ID 下发时间取决于下一次从
DB 取回号段的时间，并且在这期间进来的请求也会因为 DB 号段没有取回来，导致线程阻塞。如果请求
DB 的网络和 DB 的性能稳定，这种情况对系统的影响是不大的，但是假如取 DB 的时候网络发生抖动，或
者 DB 发生慢查询就会导致整个系统的响应时间变慢。

为此，我们希望 DB 取号段的过程能够做到无阻塞，不需要在 DB 取号段的时候阻塞请求线程，即当号段
消费到某个点时就异步的把下一个号段加载到内存中。而不需要等到号段用尽的时候才去更新号段。这
样做就可以很大程度上的降低系统的 TP 999 指标。详细实现如下图所示：

采用双 buffer 的方式，Leaf 服务内部有两个号段缓存区 segment。当前号段已下发 10%时，如果下一个
号段未更新，则另启一个更新线程去更新下一个号段。当前号段全部下发完后，如果下个号段准备好了
则切换到下个号段为当前 segment 接着下发，循环往复。

```
每个 biz-tag 都有消费速度监控，通常推荐 segment 长度设置为服务高峰期发号 QPS 的 600 倍（ 10 分
钟），这样即使 DB 宕机，Leaf 仍能持续发号 10-20 分钟不受影响。
每次请求来临时都会判断下个号段的状态，从而更新此号段，所以偶尔的网络抖动不会影响下个号
段的更新。
```
###### Leaf 高可用容灾

对于第三点“DB 可用性”问题，我们目前采用一主两从的方式，同时分机房部署，Master 和 Slave 之间采
用 **半同步方式[5]** 同步数据。同时使用公司 Atlas 数据库中间件（已开源，改名为 DBProxy）做主从切
换。

当然这种方案在一些情况会退化成异步模式，甚至在 **非常极端** 情况下仍然会造成数据不一致的情况，但
是出现的概率非常小。


如果你的系统要保证 100%的数据强一致，可以选择使用“类 Paxos 算法”实现的强一致 MySQL 方案，如
MySQL 5.7 前段时间刚刚 GA 的 MySQL Group Replication。但是运维成本和精力都会相应的增加，根据
实际情况选型即可。

同时 Leaf 服务分 IDC 部署，内部的服务化框架是“MTthrift RPC”。

服务调用的时候，根据负载均衡算法会优先调用同机房的 Leaf 服务。在该 IDC 内 Leaf 服务不可用的时候
才会选择其他机房的 Leaf 服务。

同时服务治理平台 OCTO 还提供了针对服务的过载保护、一键截流、动态流量分配等对服务的保护措
施。

#### 8.2 Tinyid：滴滴 1000 W 级 qps 的分布式 ID 生成器

Tinyid 是一个 ID 生成器服务，它提供了 REST API 和 Java 客户端等多种获取方式，

如果使用 Java 客户端获取方式的话，官方宣称能单实例能达到 1 kw QPS（Over **10 million QPS** per
single instance when using the java client.）

Tinyid 开源的 Github 地址：https://github.com/didi/tinyid。

###### 运行 Tinyid

将 Tinyid 源码下载到本地，并导入 idea 后，接下来准备把它运行起来。

###### 1. 导入 SQL

Tinyid 依赖的 SQL 脚本路径：tinyid/tinyid-server/db. sql，是 MySQL 数据库的脚本。

登陆 mysql 客户端并创建一个 tinyid 数据库后，执行命令 source /data/tinyid/tinyid-server/db. sql。

如果 show tables 后能看到两个表 **tiny_id_info** 和 **tiny_id_token** 表示创建成功。

并且脚本已经初始化了两条数据：

```
mysql> select id, token, biz_type from tiny_id_token;
```

###### 2. mysql 依赖

这里需要注意的是，tinyid 项目默认依赖 5. x 版本 MySQL 驱动包，Maven 坐标如下：

如果你的 MySQL 服务器是 8. x 版本（笔者本地就是 8. x 的 MySQL），可能会碰到在启动过程中报连接数据
库错误：

```
+----+----------------------------------+----------+
| id | token | biz_type |
+----+----------------------------------+----------+
| 1 | 0 f 673 adf 80504 e 2 eaa 552 f 5 d 791 b 644 c | test |
| 2 | 0 f 673 adf 80504 e 2 eaa 552 f 5 d 791 b 644 c | test_odd |
+----+----------------------------------+----------+
2 rows in set (0.08 sec)
```
```
mysql> select id, biz_type, begin_id, max_id, step, delta from tiny_id_info;
+----+----------+----------+--------+--------+-------+
| id | biz_type | begin_id | max_id | step | delta |
+----+----------+----------+--------+--------+-------+
| 1 | test | 1 | 1 | 100000 | 1 |
| 2 | test_odd | 1 | 1 | 100000 | 2 |
+----+----------+----------+--------+--------+-------+
2 rows in set (0.01 sec)
```
```
mysql> select id, token, biz_type from tiny_id_token;
+----+----------------------------------+----------+
| id | token | biz_type |
+----+----------------------------------+----------+
| 1 | 0 f 673 adf 80504 e 2 eaa 552 f 5 d 791 b 644 c | test |
| 2 | 0 f 673 adf 80504 e 2 eaa 552 f 5 d 791 b 644 c | test_odd |
+----+----------------------------------+----------+
2 rows in set (0.08 sec)
```
```
mysql> select id, biz_type, begin_id, max_id, step, delta from tiny_id_info;
+----+----------+----------+--------+--------+-------+
| id | biz_type | begin_id | max_id | step | delta |
+----+----------+----------+--------+--------+-------+
| 1 | test | 1 | 1 | 100000 | 1 |
| 2 | test_odd | 1 | 1 | 100000 | 2 |
+----+----------+----------+--------+--------+-------+
2 rows in set (0.01 sec)
```
```
Caused by: java. sql. SQLException: Unable to load authentication plugin
'caching_sha 2_password'.
at com.mysql.jdbc.SQLError.createSQLException (SQLError. java:868) ~[mysql-
connector-java-5.1.44. jar: 5.1.44]
at com.mysql.jdbc.SQLError.createSQLException (SQLError. java:864) ~[mysql-
connector-java-5.1.44. jar: 5.1.44]
at
com.mysql.jdbc.MysqlIO.proceedHandshakeWithPluggableAuthentication (MysqlIO. java:
1746) ~[mysql-connector-java-5.1.44. jar: 5.1.44]
at com.mysql.jdbc.MysqlIO.doHandshake (MysqlIO. java:1226) ~[mysql-connector-
java-5.1.44. jar: 5.1.44]
... ...
```

这样的话，需要将你的 MySQL 驱动升级到 8. x 版本（说明：如果你是其他 MySQL 版本，启动 tinyid 时碰
到类似的异常，那么 MySQL 驱动版本请视情况而定进行升级）：

###### 3. 修改配置

接下来需要更新配置 application. properties 文件。主要更新数据库相关配置，具体值根据你的 MySQL
环境而定：

###### 4. 启动 tinyid

tinyid 项目基于 Springboot 开发的，所以启动非常简单。

只需要运行主类 TinyIdServerApplication. java 即可。

运行后如果能看到如下日志，表示启动成功：

###### 5. 获取唯一 ID

接下来可以尝试通过 REST API 获取分布式唯一 ID，请求实例如下，bizType 和 token 的值请参考
tiny_id_token 表：

###### Client 集成

tinyid 还支持 Client 集成模式，只需要引入如下 Maven 坐标：

```
<dependency>
<groupId>mysql</groupId>
<artifactId>mysql-connector-java</artifactId>
<version>8.0.11</version>
</dependency>
```
```
datasource. tinyid. primary. driver-class-name=com. mysql. jdbc. Driver
datasource. tinyid. primary. url=jdbc:mysql://localhost: 3306/tinyid?
autoReconnect=true&useUnicode=true&characterEncoding=UTF-8
datasource. tinyid. primary. username=root
datasource. tinyid. primary. password= 123456
```
```
00 :20:55,761 [main] [INFO] o.s.b.c.e.t.TomcatEmbeddedServletContainer - Tomcat
started on port (s): 9999 (http)
00 :20:55,767 [main] [INFO] c.x.u.t.s.TinyIdServerApplication - Started
TinyIdServerApplication in 5 .092 seconds (JVM running for 6 .29)
00 :21:00,001 [pool-3-thread-1] [INFO] c.x.u.t.s.s.i.TinyIdTokenServiceImpl -
refresh token begin
00 :21:00,002 [pool-3-thread-1] [INFO] c.x.u.t.s.s.i.TinyIdTokenServiceImpl -
tinyId token init begin
00 :21:00,006 [pool-3-thread-1] [INFO] c.x.u.t.s.s.i.TinyIdTokenServiceImpl -
tinyId token init success, token size:2
00 :22:00,001 [pool-3-thread-1] [INFO] c.x.u.t.s.s.i.TinyIdTokenServiceImpl -
refresh token begin
。。。。。。
```
```
http://localhost:9999/tinyid/id/nextId?
bizType=test&token=0 f 673 adf 80504 e 2 eaa 552 f 5 d 791 b 644 c
```

然后在你的 classpath 路径下创建配置文件 tinyid_client. properties，内容如下，这两个参数就是
IdGeneratorFactoryClient. java 中 tinyid 服务端请求地址"http://{0}/tinyid/id/nextSegmentIdSimple?
token={1}&bizType="的第一个和第二个参数：

```
tinyid. server 还支持多个地址配置，多个地址之间以英文逗号隔开，例如：
tinyid. server=host1:9999, tinyid. server=host2:9999。
```
接下来，就能简单的通过调用 tinyid 封装的 API 获取分布式 ID，实例代码如下，test 就是 bizType 的值：

通过配置可知，tinyid-client 本质上还是依赖 tinyid-server，只不过它封装了对 tinyid-server 的 HTTP 请
求，然后暴露最简单的 API 给用户使用而已。它对 tinyid-server 的 HTTP 请求封装在 TinyIdHttpUtils. java
中，依赖 JDK 原生的 HttpURLConnection，居然没有使用其他第三方优秀的 HTTP Client 包例如 okhttp！

###### tinyid 原理

tinyid 的原理非常简单，就是经典的 **segment** 模式，和美团的 leaf 原理几乎一致。

首先，回顾一下生成全局唯一 ID 有如下三个思路

```
1. 基于数据库生成；
2. 基于分布式集群协调器生成（ZooKeeper， Consul ，Etcd 等）；
3. 划分命名空间并行生成（Snowflake 为代表
```
Tinyid 借鉴和吸纳第一种思路，进行优化和改进，然后生成全局唯一 ID。

纯粹的第一种思路，基于数据库生产 id，核心问题如下：

```
纯粹的第一种思路，使用 db 的 auto_increment，虽然实现简单、但性能比较差。
并且，纯粹的第一种思路，对 db 访问比较频繁，db 的压力会比较大。
```
tinyid 原理如何改进呢？ 三个优化手段

```
优化手段一：号段
优化手段二：双缓存
优化手段三：多 db 支持
优化手段四：分布式部署
```
**优化手段一：号段**

Tinyid 解决了该问题，主要实现思路为一批 id，可以看成是一个 id 范围，例如 (1000,2000]，这个 1000 到
2000 也可以称为一个"号段"，

```
<dependency>
<groupId>com. xiaoju. uemc. tinyid</groupId>
<artifactId>tinyid-client</artifactId>
<version>${tinyid. version}</version>
</dependency>
```
```
tinyid. server=localhost:9999
tinyid. token=0 f 673 adf 80504 e 2 eaa 552 f 5 d 791 b 644 c
```
```
// 单个分布式 ID 获取
Long id = TinyId.nextId ("test");
// 多个分布式 ID 批量获取
List<Long> ids = TinyId.nextId ("test", 10 );
```

```
id biz_type max_id step version
```
```
1 1000 2000 1000 0
```
我们一次向 db 申请一个号段，加载到内存中，然后采用自增的方式来生成 id，这个号段用完后，再次向
db 申请一个新的号段，这样对 db 的压力就减轻了很多，同时内存中直接生成 id，性能则提高了很多。

所以 Tinyid 数据库表设计时，只需要满足能存储一个范围即可，一个端点（Tinyid 使用右端点）和一个
步长可以确定一个范围。

```
biz_type ：业务类型，不同业务的 id 隔离
max_id ：当前号段最大可用 id，即右端点
step ：步长，根据每个业务的 qps 来设置一个合理的长度
version ：当前版本，用于实现乐观锁，每次更新都加上 version，能够保证并发更新的正确性
```
以上是获取号段代码，基于 CAS（Compare and Swap）思想。

这里比较值得注意一点是该方法事务的隔离级别设置为 READ_COMMITTED（提交读），主要为了考虑
以下两点：

```
1. Transactional 标记保证 query 和 update 使用的是同一连接。
```
```
@Override
@Transactional (isolation = Isolation. READ_COMMITTED)
public SegmentId getNextSegmentId (String bizType) {
// 获取 nextTinyId 的时候，有可能存在 version 冲突，需要重试
for (int i = 0 ; i < Constants. RETRY; i++) {
// select id, biz_type, begin_id, max_id, step, delta, remainder,
create_time, update_time, version
// from tiny_id_info where biz_type =?
TinyIdInfo tinyIdInfo = tinyIdInfoDAO.queryByBizType (bizType);
if (tinyIdInfo == null) {
throw new TinyIdSysException ("can not find biztype: " + bizType);
}
Long newMaxId = tinyIdInfo.getMaxId () + tinyIdInfo.getStep ();
Long oldMaxId = tinyIdInfo.getMaxId ();
// update tiny_id_info set max_id= ?, update_time=now (),
version=version+1
// where id=? and max_id=? and version=? and biz_type=?
// CAS
int row = tinyIdInfoDAO.updateMaxId (tinyIdInfo.getId (), newMaxId,
oldMaxId, tinyIdInfo.getVersion (),
tinyIdInfo.getBizType ());
if (row == 1 ) {
tinyIdInfo.setMaxId (newMaxId);
SegmentId segmentId = convert (tinyIdInfo);
logger.info ("getNextSegmentId success tinyIdInfo:{} current:{}",
tinyIdInfo, segmentId);
return segmentId;
} else {
logger.info ("getNextSegmentId conflict tinyIdInfo:{}", tinyIdInfo);
}
}
throw new TinyIdSysException ("get next segmentId conflict");
}
```

```
2. MySQL 默认事务隔离级别为 REPEATABLE_READ（可重复读， MySQL 底层使用 MVCC），保证同
一个事务中读到的 version 字段相同（循环调用 tinyIdInfoDAO.queryByBizType (bizType) 获取
的结果是没有变化的），感知不到其他事务对 version 字段的改变，可能会导致 CAS 失败。
```
**优化手段二：双缓存**

在一个号段用完后，需要向数据库申请下一个号段，此时客户端需要等待，造成性能波动。

有没有解决方案呢？

Tinyid 使用双缓存（重数据库加载到内存中的号段）解决这个问题，在号段用到一定程度（默认 20%）
的时候，就去异步加载下一个号段，保证内存中始终有可用号段，则可避免性能波动。

```
nextId () 方法用于从缓存中获取一个 id。
```
loadCurrent () 加载当前号段，使用 synchronized 关键字保证线程安全。有两个地方可能用到这个
方法，一个是初始化时懒加载当前号段，另一个是当前号段缓存的 id 用尽，使用下一号段替换当前号
段。

```
protected SegmentIdService segmentIdService;
protected volatile SegmentId current;  // 当前号段
protected volatile SegmentId next;  // 下一号段
private volatile boolean isLoadingNext;  // 是否正在加载下一号段
private Object lock = new Object ();
private ExecutorService executorService = Executors.newSingleThreadExecutor (new
NamedThreadFactory ("tinyid-generator"));  // 加载下一号段的异步线程池
```
```
@Override
public Long nextId () {
while (true) {
if (current == null) {
// 懒加载，申请当前号段
loadCurrent ();
continue;
}
// 从当前号段缓存中获取一个 id
Result result = current.nextId ();
// 当前号段缓存的 id 用尽
if (result.getCode () == ResultCode. OVER) {
loadCurrent ();
} else {
// 当前号段用到一定程度，触发异步加载下一号段
if (result.getCode () == ResultCode. LOADING) {
loadNext ();
}
return result.getId ();
}
}
}
```

```
id biz_type max_id step delta remainder version
```
```
1 1000 2000 1000 2 0 0
```
当前号段用到一定程度，调用 loadNext () 方法异步加载下一号段。

**优化手段三：多 db 支持**

只有一个数据库时，可用性难以保证，当主库挂了会造成申请号段不可用。

另外扩展性差，性能有上限，因为写入是单点，数据库主库的写性能决定 ID 的生成性能上限，并且难以
扩展。

为了解决此问题，Tinyid 可以增加主库，避免写入单点。为了保证各主库生成的 ID 不重复，需要为每个
主库设置不同的 auto_increment 初始值，以及相同的增长步长。

例如，有三个主库 DB-0，DB-1，DB-2，将 auto_increment 初始值分别设置为 0,1,2，步长都为 3 ，则库
DB-0 生成 0,3,6,9...，库 DB-1 生成 1,4,7,10，库 DB-2 生成 2,5,8,11...；

但数据库需要增加两个字段 delta 和 remainder，分别表示增长步长和 auto_increment 初始值。

```
public synchronized void loadCurrent () {
if (current == null || !current.useful ()) {
if (next == null) {
// 从数据库中查询一个号段
SegmentId segmentId = querySegmentId ();
this. current = segmentId;
} else {
// 用下一号段替换当前号段
current = next;
next = null;
}
}
}
```
```
public void loadNext () {
// double check
if (next == null && !isLoadingNext) {
synchronized (lock) {
if (next == null && !isLoadingNext) {
isLoadingNext = true;
executorService.submit (new Runnable () {
@Override
public void run () {
try {
// 无论获取下个 segmentId 成功与否，都要将 isLoadingNext 赋值
为 false
next = querySegmentId ();
} finally {
isLoadingNext = false;
}
}
});
}
}
}
}
```

但是这里有个问题，比如从申请到号段 (1000,2000]后，如果 delta=3, remainder=0，则这个号段从哪
个 id 开始分配，肯定不是 1001 ，所以这里就需要计算。

设置好初始 id 之后，就以 delta 的方式递增分配。因为会先递增，所以会浪费一个 id，所以做了一次减
delta 的操作，实际会从 999 开始增，第一个 id 还是 1002 。

在决定数据源时，使用一下方法

```
public Result nextId () {
init ();
// 先自增
long id = currentId.addAndGet (delta);
if (id > maxId) {
return new Result (ResultCode. OVER, id);
}
if (id >= loadingId) {
return new Result (ResultCode. LOADING, id);
}
return new Result (ResultCode. NORMAL, id);
}
```
```
public void init () {
if (isInit) {
return;
}
// double check
synchronized (this) {
if (isInit) {
return;
}
long id = currentId.get ();
if (id % delta == remainder) {
isInit = true;
return;
}
for (int i = 0 ; i <= delta; i++) {
id = currentId.incrementAndGet ();
if (id % delta == remainder) {
// 避免浪费减掉系统自己占用的一个 id
currentId.addAndGet ( 0 - delta);
isInit = true;
return;
}
}
}
}
```

从上面可以看出，如果有多个数据源，则随机选择一个，所有生成的 id 不是严格单调递增的，而是趋势
递增，能满足大部分业务场景。

**优化手段四：分布式部署**

虽然数据库单点问题解决了，但是还是单个服务选择多个数据库，服务挂了怎么办？

服务单点问题并没有解决。

一个简单的解决方案就是将服务部署到多个机房的多台机器。但是问题又随之而来，多个服务之间怎么
协调？What？

在 Spring Cloud 中微服务多实例部署，可以将其注册到服务注册中心，然后在客户端使用负载均衡算法
访问服务。或者在服务端使用反向代理，为多实例做负载均衡。

但是 Tinyid 作为一个独立服务部署，引入这些组件将增加维护成本，所以呢，Tinyid 提供了 SDK，在
SDK 中做了客户端负载均衡（随机算法)。

最后，附上 Tinyid 系统架构图

```
@Override
protected Object determineCurrentLookupKey () {
// 只有一个数据源时
if (dataSourceKeys.size () == 1 ) {
return dataSourceKeys.get ( 0 );
}
// 多个数据源时，随机选择一个
Random r = new Random ();
return dataSourceKeys.get (r.nextInt (dataSourceKeys.size ()));
}
```
```
private String chooseService (String bizType) {
List<String> serverList = TinyIdClientConfig.getInstance (). getServerList ();
String url = "";
if (serverList != null && serverList.size () == 1 ) {
url = serverList.get ( 0 );
} else if (serverList != null && serverList.size () > 1 ) {
// 多实例部署时，随机选择一个服务
Random r = new Random ();
url = serverList.get (r.nextInt (serverList.size ()));
}
url += bizType;
return url;
}
```

#### 说在最后

**分布式 ID，也是面试的重点和高频点** 。

```
(1) 一个分布式 ID 生成系统，如何实现？
```
```
(2) 分布式 ID 系统，如何实现高并发？
(3) 分布式 ID 系统，如何实现高可用？
```
```
等等等等.....
```
参照上文的答案，如果大家能对答如流，最终， **让面试官爱到 “不能自已、口水直流”** 。 offer，也就来
了。

#### 作者介绍：

**本文 1 作： Andy** ，资深架构师，《Java 高并发核心编程加强版》作者之 1 。

**本文 2 作： 尼恩** ， 41 岁资深老架构师，《Java 高并发核心编程加强版卷 1 、卷 2 、卷 3 》创世作者，
著名博主。《K 8 S 学习圣经》《Docker 学习圣经》《Go 学习圣经》等 11 个 PDF 圣经的作者。也是一
个超级 **架构转化导师** ，已经指导了大量小伙伴成功转型架构师， **指导的最高年薪近 100 W** 。

#### 推荐阅读


《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》


## 腾讯太狠： 10 亿 QPS 的 IM，如何实现？

#### 前言

在 40 岁老架构师尼恩的 **读者交流群 (50+)** 中，很多小伙伴拿高薪，完成架构的升级，进入架构师赛道，
**打开薪酬天花板** 。

然后，在架构师的面试过程中，常常会遇到 IM 架构的问题：

```
如果要你从 0 到 1 做 IM 架构，需要从哪些方面展开？
```
```
你是怎么做项目的 IM 架构的？
10 亿级以上 qps 的高并发 IM，该如何架构？
```
现在， 40 岁老架构师尼恩，站在腾讯企业 IM 的巨人肩膀，给大家提供一份比较全面的参考答案。使得
大家可以充分展示一下大家雄厚的 “技术肌肉”， **让你的面试官爱到 “不能自已、口水直流”** 。

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 90 版本，供后面的小伙伴参考，
提升大家的 3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，最新尼恩架构笔记、面试题的 PDF 文件，请关注公众号【技术自由
圈】领取，暗号：领电子书
```
#### 1 、超高并发：核心接口峰值达到 10 亿级 QPS

企业微信作为一款 Tob 场景的聊天 im 工具，用于工作场景的沟通，有着较为明显的高峰效应。

工作时间上午9:00~12:00，下午14:00~18:00，是聊天的高峰，消息量剧增。

**核心接口，峰值达到 10 亿级 QPS**

以上仅仅是核心接口。


在消息的 ID 生产模块，也有 1000 WQps 以上。

#### 2 、企业微信的业务场景分析

企业微信是一款收费产品，消息系统的稳定性、可靠性、安全性尤其重要。

与 TC 的微信不同，而且针对 toB 场景的消息系统，需要支持更为复杂的业务场景。

**针对 toB 场景的特有业务有** ：

```
1 ） 消息鉴权 ：关系类型有群关系、同企业同事关系、好友关系、集团企业关系、圈子企业关系。
收发消息双方需存在至少一种关系才允许发消息；
2 ） 回执消息 ：每条消息都需记录已读和未读人员列表，涉及频繁的状态读写操作；
3 ） 撤回消息 ：支持 24 小时的有效期撤回动作；
4 ） 消息存储 ：云端存储时间跨度长，最长可支持 180 天消息存储，数百 TB 用户消息需优化，减少
机器成本；
5 ） 万人群聊 ：群人数上限可支持 10000 人，一条群消息就像一次小型的 DDoS 攻击；
6 ） 微信互通 ：两个异构的 im 系统直接打通，可靠性和一致性尤其重要。
```
#### 3 、企业微信的架构分层


如上所示，整体架构分层如下。

**1 ）接入层** ：

接收客户端的请求，根据类型转发到对应的安全分发层。

支持两种连接类型： 客户端可以通过长连或者短连接。

```
优先用长连接发起请求，
如果长连失败，则选用短连重试。
```
**2 ）安全分发层** ：

http 类型的 WEB 服务，

安全分发层接收接入的的数据包，校验用户的 session 状态，

进行安全校验，并用后台派发的秘钥去解包，如解密失败则拒绝请求。

如果解密成功，则解密为明文包体，然后进行分发，转发到后端逻辑层对应的 svr。

**3 ）逻辑层** ：

各种业务微服务和异步处理服务，使用自研的 rpc 框架（类似 dubbo）通信。

逻辑进行数据整合和逻辑处理。

和外部系统的通信，通过 http 协议，包括微信互通、手机厂商的推送平台等。

**4 ）存储层** ：

使用 kv 类型的存储组件：采用的是基于 levelDB 模型开发 msgkv。

消息的 key 为消息的全局有序编号，使用 SeqSvr 序列号生成器，保证派发的 seq 单调递增不回退。

消息的 key 也用于消息的收发协议

#### 4 、号段模式 seqsvr 消息序列号架构

**微信服务器端为每一份需要与客户端同步的数据（例如消息）都会赋予一个唯一的、递增的序列号（后
文称为 sequence），作为这份数据的版本号。**

在客户端与服务器端同步的时候，客户端会带上已经同步下去数据的最大版本号，后台会根据客户端最
大版本号与服务器端的最大版本号，计算出需要同步的增量数据，返回给客户端。这样不仅保证了客户
端与服务器端的数据同步的可靠性，同时也大幅减少了同步时的冗余数据。

这里不用乐观锁机制来生成版本号，而是使用了一个独立的 seqsvr 来处理序列号操作，

```
一方面因为业务有大量的 sequence 查询需求——查询已经分配出去的最后一个 sequence，而基于
seqsvr 的查询操作可以做到非常轻量级，避免对存储层的大量 IO 查询操作；
另一方面微信用户的不同种类的数据存在不同的 Key-Value 系统中，使用统一的序列号有助于避免
重复开发，同时业务逻辑可以很方便地判断一个用户的各类数据是否有更新。
```
从 seqsvr 申请的、用作数据版本号的 sequence，具有两种基本的性质：

```
递增的 64 位整型变量
每个用户都有自己独立的 64 位 sequence 空间
```

举个例子，小明当前申请的 sequence 为 100 ，那么他下一次申请的 sequence，可能为 101 ，也可能是
110 ，总之一定大于之前申请的 100 。

而小红呢，她的 sequence 与小明的 sequence 是独立开的，假如她当前申请到的 sequence 为 50 ，然后
期间不管小明申请多少次 sequence 怎么折腾，都不会影响到她下一次申请到的值（很可能是 51 ）。

这里用了每个用户独立的 64 位 sequence 的体系，而不是用一个全局的 64 位（或更高位）sequence，很
大原因是全局唯一的 sequence 会有非常严重的申请互斥问题，不容易去实现一个高性能高可靠的架
构。对微信业务来说，每个用户独立的 64 位 sequence 空间已经满足业务要求。

微信目前拥有数亿的活跃用户，每时每刻都会有海量 sequence 申请，这对 seqsvr 的设计也是个极大的
挑战。

那么，既要 sequence 可靠递增，又要能顶住海量的访问，要如何设计 seqsvr 的架构？

我们先从 seqsvr 的架构原型说起。

###### 号段模式的分布式 ID 总体架构

什么是号段模式的分布式 ID 总体架构？ 请参见下面的博文文章，介绍得非常详细

滴滴太狠：分布式 ID，如何达到 1000 Wqps？

不考虑 **号段模式的话** ，分布式 ID 应该是一个巨大的 64 位数组，而我们每一个微信用户，都在这个大数
组里独占一格 8 bytes 的空间，这个格子就放着用户已经分配出去的最后一个 sequence：cur_seq。

每个用户来申请 sequence 的时候，只需要将用户的 cur_seq+=1，保存回数组，并返回给用户。

图 1. 小明申请了一个 sequence，返回 101

任何一件看起来很简单的事，在海量的访问量下都会变得不简单。

前文提到，seqsvr 需要保证分配出去的 sequence 递增（数据可靠），还需要满足海量的访问量（每天
接近万亿级别的访问）。

满足数据可靠的话，我们很容易想到把数据持久化到硬盘，但是按照目前每秒千万级的访问量（~10^7
QPS），基本没有任何硬盘系统能扛住。

后台架构设计很多时候是一门关于权衡的哲学，针对不同的场景去考虑能不能降低某方面的要求，以换
取其它方面的提升。仔细考虑我们的需求，我们只要求递增，并没有要求连续，也就是说出现一大段跳
跃是允许的（例如分配出的 sequence 序列：1,2,3,10,100,101）。于是我们实现了一个简单优雅的策
略：

```
1. 内存中储存最近一个分配出去的 sequence：cur_seq，以及分配上限：max_seq
2. 分配 sequence 时，将 cur_seq++，同时与分配上限 max_seq 比较：如果 cur_seq > max_seq，
将分配上限提升一个步长 max_seq += step，并持久化 max_seq
3. 重启时，读出持久化的 max_seq，赋值给 cur_seq
```

图 2. 小明、小红、小白都各自申请了一个 sequence，但只有小白的 max_seq 增加了步长 100

这样通过增加一个预分配 sequence 的中间层，在保证 sequence 不回退的前提下，大幅地提升了分配
sequence 的性能。

实际应用中每次提升的步长为 10000 ，那么持久化的硬盘 IO 次数从之前~10^7 QPS 降低到~10^3
QPS，处于可接受范围。

在正常运作时分配出去的 sequence 是顺序递增的，只有在机器重启后，第一次分配的 sequence 会产
生一个比较大的跳跃，跳跃大小取决于步长大小。

###### 分号段共享存储架构:

请求带来的硬盘 IO 问题解决了，可以支持服务平稳运行，但该模型还是存在一个问题：重启时要读取
大量的 max_seq 数据加载到内存中。

我们可以简单计算下，以目前 uid（用户唯一 ID）上限 2^32 个、一个 max_seq 8 bytes 的空间，数据
大小一共为 32 GB，从硬盘加载需要不少时间。

另一方面，出于数据可靠性的考虑，必然需要一个可靠存储系统来保存 max_seq 数据，重启时通过网
络从该可靠存储系统加载数据。如果 max_seq 数据过大的话，会导致重启时在数据传输花费大量时
间，造成一段时间不可服务。

为了解决这个问题，我们引入号段 Section 的概念，uid 相邻的一段用户属于一个号段，而同个号段内
的用户共享一个 max_seq，这样大幅减少了 max_seq 数据的大小，同时也降低了 IO 次数。

图 3. 小明、小红、小白属于同个 Section，他们共用一个 max_seq。在每个人都申请一个 sequence
的时候，只有小白突破了 max_seq 上限，需要更新 max_seq 并持久化

目前 seqsvr 一个 Section 包含 10 万个 uid，max_seq 数据只有 300+KB，为我们实现从可靠存储系统
读取 max_seq 数据重启打下基础。

#### 5 、消息收发模型架构

企业微信的消息收发模型采用了推拉结合架构，这种方式可靠性高，设计简单。

**以下是消息推拉的时序图** ：


如上图所示，

第一步：后台推入接收方存储

发送方请求后台，把消息写入到接收方的存储，然后 push 通知接收方。

第二步：接收方收到通知后拉取消息

接受方收到 push，主动上来后台收消息。

**不重、不丢、及时触达，这三个是消息系统的核心指标** ：

```
1 ） 实时触达 ：客户端通过与后台建立长连接，保证消息 push 的实时触达；
2 ） 及时通知 ：如果客户端长连接不在，进程被 kill 了，利用手机厂商的推送平台，推送通知，或者
直接拉起进程进行收消息；
3 ） 消息可达 ：假如遇到消息洪峰，后台的 push 滞后，客户端有轮训机制进行兜底，保证消息可
达；
4 ） 消息防丢 ：为了防止消息丢失，只要后台逻辑层接收到请求，保证消息写到接收方的存储，失
败则重试。如果请求在 CGI 层就失败，则返回给客户端出消息红点；
5 ） 消息排重 ：客户端在弱网络的场景下，有可能请求已经成功写入存储，回包超时，导致客户端
重试发起相同的消息，那么就造成消息重复。为了避免这种情况发生，每条消息都会生成唯一的
appinfo，后台通过建立索引进行排重，相同的消息直接返回成功，保证存储只有一条。
```

#### 6 、群聊消息写扩散架构

###### 读扩散与写扩散

所谓 **读扩散，** 就是: 存储一次，多次读。

所谓 **写扩散** ，就是: 存储多次，各自读。

放到群聊的场景里说

**读扩散** ，群里的每条消息只存储一份，群成员读取同一份数据。

优点：

```
数据实时性高；
写入逻辑简单；
节约存储空间。
```
缺点：

```
数据读取会存在热点问题；
需要维护离线群成员与未读消息的关系。
```
**写扩散** ，群里发一条消息，给每个群成员都存储一份，群成员各自读自己的那一份。


优点：

```
控制逻辑与数据读取逻辑简单；
用户数据独立，满足更多的业务场景，比如：回执消息、云端删除等等；
一个数据点丢失，不影响其他用户的数据点。
```
缺点：

```
存储空间的增加；
写扩散需要专门的扩散队列；
先写扩散后读，实时性差。
```
###### 企业微信的写扩散架构

每条消息存多份，每个群聊成员在自己的存储都有一份。

**优点** ：

```
① 只需要通过一个序列号就可以增量同步所有消息，收消息协议简单；
```

```
② 读取速度快，前端体验好；
③ 满足更多 ToB 的业务场景：回执消息、云端删除。
```
同一条消息，在每个人的视角会有不同的表现。例如：回执消息，发送方能看到已读未读列表，接受方
只能看到是否已读的状态。云端删除某条群消息，在自己的消息列表消失，其他人还是可见。

**缺点** ：存储容量的增加。

企业微信采用了扩散写的方式，消息收发简单稳定。存储容量的增加，可以通过冷热分离的方案解决，
冷数据存到廉价的 SATA 盘，扩散读体验稍差，协议设计也相对复杂些。

**下图是扩散写的协议设计** ：

**如上图所示** ：

```
1 ）每个用户只有一条独立的消息流。同一条消息多副本存在于每个用户的消息流中；
2 ）每条消息有一个 seq，在同个用户的消息流中，seq 是单调递增的；
3 ）客户端保存消息列表中最大 seq，说明客户端已经拥有比该 seq 小的所有消息。若客户端被
push 有新消息到达，则用该 seq 向后台请求增量数据，后台把比此 seq 大的消息数据返回。
```
#### 7 、系统架构异步解耦

**总的方案** ：

```
企业微信的消息系统，会依赖很多外部模块，甚至外部系统。
与外部系统的交互，全设计成异步化。
```
为了避免外部系统或者外部模块出现故障，拖累消息系统，导致耗时增加，则需要系统解耦。

解耦之后，进行通过异步 mq，去异步重试去保证成功，主流程不受影响。


**例如 ImUnion 异步化** ：

与微信消息互通时，通过外部系统 ImUnion 进行权限判断，调用耗时较长。

如何异步化：先让客户端成功，如果 ImUnion 异步失败，则回调客户端使得出红点。

**再如消息审计功能异步化** ：

金融版的消息审计功能，需要把消息同步到审计模块，增加 rpc 调用。

异步化策略：消息审计功能是非主流程，则异步重试机制，去保证成功，主流程不受影响。

**再如 crm 模块异步** ：

客户服务的单聊群聊消息，需要把消息同步到 crm 模块，增加 rpc 调用。

异步化策略：crm 模块异步功能是非主流程，则异步重试机制，去保证成功，主流程不受影响。

#### 8 、业务隔离架构设计

**企业微信的消息类型有多种** ：

```
1 ） 单聊群聊 ：基础聊天，优先级高；
2 ） api 消息 ：企业通过 api 接口下发的消息，有频率限制，优先级中；
3 ） 应用消息 ：系统应用下发的消息，例如公告，有频率限制，优先级中；
4 ） 控制消息 ：不可见的消息。例如群信息变更，会下发控制消息通知群成员，优先级低。
```
**群聊按群人数，又分成 3 类** ：

```
1 ） 普通群 ：小于 100 人的群，优先级高；
2 ） 大群 ：小于 2000 人的群，优先级中；
3 ） 万人群 ：优先级低。
```
**业务繁多** ：如果不加以隔离，那么其中一个业务的波动有可能引起整个消息系统的瘫痪。

**重中之重** ：需要保证核心链路的稳定，就是企业内部的单聊和 100 人以下群聊，因为这个业务是最基础
的，也是最敏感的，稍有问题，投诉量巨大。


**其余的业务** ：互相隔离，减少牵连。按照优先级和重要程度进行隔离，对应的并发度也做了调整，尽量
保证核心链路的稳定性。

**解耦和隔离的效果图** ：

#### 9 、过载保护架构设计

关于过载保护的系统化介绍文章，请参见

10 亿级用户，如何做熔断降级架构？微信和 hystrix 的架构对比

###### 服务过载问题

上一小结中过载保护策略所带来的问题就是：系统过载返回失败，前端发消息显示失败，显示红点，会
严重影响产品体验。

发消息是 im 系统的最基础的功能，可用性要求达到几乎 100%，所以这个策略肯定需要优化。

###### 解决方案

**解决方案思路就是** ：尽管失败，也返回前端成功，后台保证最终成功。

为了保证消息系统的可用性，规避高峰期系统出现过载失败导致前端出红点，做了很多优化。

**具体策略如下** ：

```
1 ）逻辑层 hold 住失败请求，返回前端成功，不出红点，后端异步重试，直至成功；
2 ）为了防止在系统出现大面积故障的时候，重试请求压满队列，只 hold 住半小时的失败请求，半
小时后新来的请求则直接返回前端失败；
3 ）为了避免重试加剧系统过载，指数时间延迟重试；
4 ）复杂的消息鉴权（好友关系，企业关系，集团关系，圈子关系），耗时严重，后台波动容易造
成失败。如果并非明确鉴权不通过，则幂等重试；
```

```
5 ）为了防止作恶请求，限制单个用户和单个企业的请求并发数。例如，单个用户的消耗 worker 数
超过 20%，则直接丢弃该用户的请求，不重试。
```
优化后，后台的波动，前端基本没有感知。

**以下是优化前后的流程对比** ：

#### 10 、万人大群的架构优化

###### 10.1 技术背景

企业微信的群人数上限是 10000 ，只要群内每个人都发一条消息，那么扩散量就是 **10000 * 10000 = 1 亿**
次调用，非常巨大。

10000 人投递完成需要的耗时长，影响了消息的及时性。

###### 10.2 问题分析

既然超大群扩散写量大、耗时长，那么自然会想到：超大群是否可以单独拎出来做成扩散读呢。

**下面分析一下超大群设计成单副本面临的难点** ：

```
① 一个超大群，一条消息流，群成员都同步这条流的消息；
② 假如用户拥有多个超大群，则需要同步多条流，客户端需维护每条流的 seq；
③ 客户端卸载重装，并不知道拥有哪些消息流，后台需存储并告知；
④ 某个超大群来了新消息，需通知所有群成员，假如 push 没触达，客户端没办法感知有新消息，
不可能去轮训所有的消息流。
```
**综上所述** ：单副本的方案代价太大。


以下将介绍我们针对万人群聊扩散写的方案，做的一些优化实践。

###### 10.3 优化 1 ：并发限制

万人群的扩散量大，为了是消息尽可能及时到达，使用了多协程去分发消息。但是并不是无限制地加大
并发度。

为了避免某个万人群的高频发消息，造成对整个消息系统的压力，消息分发以群 id 为维度，限制了单个
群的分发并发度。

消息分发给一个人的耗时是 8 ms，那么万人的总体耗时是 80 s，并发上限是 5 ，那么消息分发完成需要
16 s。16 s 的耗时，在产品角度来看还、是可以接受的，大群对及时性不敏感。同时，并发度控制在合理
范围内。

除了限制单个群 id 的并发度，还限制了万人群的总体并发度。单台机，小群的 worker 数为 250 个，万人
群的 worker 数为 30 。

###### 10.4 优化 2 ：合并插入

工作场景的聊天，多数是在小群完成，大群用于管理员发通知或者老板发红包。

**大群消息有一个常见的规律** ：平时消息少，会突然活跃。例如：老板在群里发个大红包，群成员起哄，
此时就会产生大量的消息。

消息量上涨、并发度被限制、任务处理不过来，那么队列自然就会积压。积压的任务中可能存在多条消
息需要分发给同一个群的群成员。

**此时** ：可以将这些消息，合并成一个请求，写入到消息存储，消息系统的吞吐量就可以成倍增加。

在日常的监控中，可以捕获到这种场景，高峰可以同时插入 20 条消息，对整个系统很友善。

###### 10.5 优化 3 ：业务降级

**比如** ：群人员变更、群名称变动、群设置变更，都会在群内扩散一条不可见的控制消息。群成员收到此
控制消息，则向后台请求同步新数据。

**举个例子** ：一个万人群，由于消息过于频繁，对群成员造成骚扰，部分群成员选择退群来拒绝消息，假
设有 1000 人选择退群。那么扩散的控制消息量就是 1000 w，用户收到控制消息就向后台请求数据，则
额外带来 1000 w 次的数据请求，造成系统的巨大压力。

控制消息在小群是很有必要的，能让群成员实时感知群信息的变更。

**但是在大群** ：群信息的变更其实不那么实时，用户也感觉不到。所以结合业务场景，实施降级服务，控
制消息在大群可以直接丢弃、不分发，减少对系统的调用。

#### 11 、回执消息架构设计

###### 11.1 技术背景

回执消息是办公场景经常用到的一个功能，能看到消息接受方的阅读状态。

一条回执消息的阅读状态会被频繁修改，群消息被修改的次数和群成员人数成正比。每天上亿条消息，
读写频繁，请求量巨大，怎么保证每条消息在接受双方的状态是一致的是一个难点。

###### 11.2 实现方案


消息的阅读状态的存储方式两个方案。

**方案一** ：

**思路** ：利用消息存储，插入一条新消息指向旧消息，此新消息有最新的阅读状态。客户端收到新消息，
则用新消息的内容替换旧消息的内容展示，以达到展示阅读状态的效果。

**优点** ：复用消息通道，增量同步消息就可以获取到回执状态，复用通知机制和收发协议，前后端改造
小。

**缺点** ：

```
① 存储冗余，状态变更多次，则需插入多条消息；
② 收发双方都需要修改阅读状态（接收方需标志消息为已读状态），存在收发双方数据一致性问
题。
```
**方案二** ：

**思路** ：独立存储每条消息的阅读状态，消息发送者通过消息 id 去拉取数据。

**优点** ：状态一致。

**缺点** ：

```
① 构建可靠的通知机制，通知客户端某条消息属性发生变更；
② 同步协议复杂，客户端需要准确知道哪条消息的状态已变更；
③ 消息过期删除，阅读状态数据也要自动过期删除。
```
**企业微信采用了方案一去实现，简单可靠、改动较小** ：存储冗余的问题可以通过 LevelDB 落盘的时候
merge 数据，只保留最终状态那条消息即可；一致性问题下面会介绍如何解决。

**上图是协议流程** （referid：被指向的消息 id，senderid：消息发送方的 msgid）：

```
1 ）每条消息都有一个唯一的 msgid，只在单个用户内唯一，kv 存储自动生成的；
2 ）接收方 b 已读消息，客户端带上 msgid=b 1 请求到后台；
3 ）在接受方 b 新增一条消息，msgid=b 2，referid=b 1，指向 msgid=b 1 的消息。并把 msgid=b 2 的
消息内容设置为消息已读。msgid=b 1 的消息体，存有发送方的 msgid，即 senderid=a 1；
4 ）发送方 a，读出 msgid=a 1 的消息体，把 b 加入到已读列表，把新的已读列表保存到消息体中，
生成新消息 msgid=a 2，referid=a 1，追加写入到 a 的消息流；
5 ）接收方 c 已读同一条消息，在 c 的消息流走同样的逻辑；
6 ）发送方 a，读出 msgid=a 1 的消息体，把 c 加入到已读列表，把新的已读列表保存到消息体中，
生成新消息 msgid=a 3，referid=a 1，追加写入到 a 的消息流。a 3>a 2，以 msgid 大的 a 3 为最终状
态。
```
###### 11.3 优化 1 ：异步化


接受方已读消息，让客户端同步感知成功，但是发送方的状态没必要同步修改。因为发送方的状态修改
情况，接受方没有感知不到。

那么，可以采用异步化的策略，降低同步调用耗时。

**具体做法是** ：

```
1 ）接受方的数据同步写入，让客户端马上感知消息已读成功；
2 ）发送方的数据异步写入，减少同步请求；
3 ）异步写入通过重试来保证成功，达到状态最终一致的目的。
```
###### 11.4 优化 2 ：合并处理

客户端收到大量消息，并不是一条一条消息已读确认，而是多条消息一起已读确认。为了提高回执消息
的处理效率，可以对多条消息合并处理。

**如上图所示** ：

```
1 ）X>>A：表示 X 发了一条消息给 A；
2 ）A 合并确认 3 条消息，B 合并确认 3 条消息。那么只需要处理 2 次，就能标志 6 条消息已读；
3 ）经过 mq 分发，相同的发送方也可以合并处理。在发送方，X 合并处理 2 条消息，Y 合并处理 2 条
消息，Z 合并处理 2 条消息，则合并处理 3 次就能标志 6 条消息。
```
经过合并处理，处理效率大大提高。


###### 11.5 读写覆盖解决

发送方的消息处理方式是先把数据读起来，修改后重新覆盖写入存储。接收方有多个，那么就会并发写
发送方数据，避免不了出现覆盖写的问题。

**流程如下** ：

```
1 ）发送方某条消息的已读状态是 X；
2 ）接收方 a 确认已读，已读状态修改为 X+a；
3 ）接收方 b 确认已读，已读状态修改为 X+b；
4 ）接收方 a 的状态先写入，接受方 b 的状态后写入。这最终状态为 X+b；
5 ）其实正确的状态是 X+a+b。
```
处理这类问题，无非就一下几种办法。

**方案一** ：因为并发操作是分布式，那么可以采用分布式锁的方式保证一致。操作存储之前，先申请分布
式锁。这种方案太重，不适合这种高频多账号的场景。

**方案二** ：带版本号读写。一个账号的消息流只有一个版本锁，高频写入的场景，很容易产生版本冲突，
导致写入效率低下。

**方案三** ：mq 串行化处理。能避免覆盖写问题，关键是在合并场景起到很好的作用。同一个账号的请求
串行化，就算出现队列积压，合并的策略也能提高处理效率。

企业微信采用了方案三，相同 id 的用户请求串行化处理，简单易行，逻辑改动较少。

#### 12 、撤回消息的架构设计

###### 12.1 技术难点

“ **撤回消息** ”相当于更新原消息的状态，是不是也可以通过 referid 的方式去指向呢？

**回执消息分析过** ：通过 referid 指向，必须要知道原消息的 msgid。

**区别于回执消息** ：撤回消息需要修改所有接收方的消息状态，而不仅仅是发送方和单个接收方的。消息
扩散写到每个接收方的消息流，各自的消息流对应的 msgid 是不相同的，如果沿用 referid 的方式，那就
需要记录所有接收方的 msgid。

###### 12.2 解决方案

**分析** ：撤回消息比回执消息简单的是，撤回消息只需要更新消息的状态，而不需要知道原消息的内容。
接收方的消息的 appinfo 都是相同的，可以通过 appinfo 去做指向。

**协议流程** ：

```
1 ）用户 a、b、c，都存在同一条消息，appinfo=s，sendtime=t；
2 ）a 撤回该消息，则在 a 的消息流插入一条撤回的控制消息，消息体包含
{appinfo=s, sendtime=t}；
3 ）客户端 sync 到撤回的控制消息，获取到消息体的 appinfo 与 sendtime，把本地 appinfo=s 且
sendtime=t 的原消息显示为撤回状态，并删除原消息数据。之所以引入 sendtime 字段，是为了防
止 appinfo 碰撞，加的双重校验；
4 ）接收方撤回流程和发送方一致，也是通过插入撤回的控制消息。
```
该方案的优点明显，可靠性高，协议简单。

**撤回消息的逻辑示意图** ：


#### 说在最后：有问题可以找老架构取经

架构之路，充满了坎坷。

架构和高级开发不一样，架构的问题是 open 的，开发式的，没有标准答案的。

在做架构过程中，或者在转型过程中，如果遇到复杂的场景，确实不知道怎么做架构方案，确实找不到
有底的方案，怎么办？ 可以来找 40 岁老架构尼恩求助。

上次一个小伙伴，他们要进行 **电商网站的黄金链路架构** ，开始找不到思路，但是经过尼恩 10 分钟语音
指导，一下就豁然开朗。

关于 IM 架构，后面尼恩会出一个系列的视频，帮助大家彻底掌握，从而开启自己的架构师之路。

如果需要把 IM、推送平台、秒杀平台等优质项目，写人简历，也可以找尼恩指导。

下面是昨晚尼恩指导的 13 年经验小伙伴，经过 1 小时指导后，简历金光闪闪、脱胎换骨：


#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》


《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》

## 1000 Wqps 生产级 IM，怎么架构？

#### 前言

在 40 岁老架构师尼恩的 **读者交流群 (50+)** 中，很多小伙伴拿高薪，完成架构的升级，进入架构师赛道，
**打开薪酬天花板** 。

然后，在架构师的面试过程中，常常会遇到 IM 架构的问题：

```
如果要你从 0 到 1 做 IM 架构，需要从哪些方面展开
```
```
你是怎么做项目的 IM 架构的？
1 亿级以上 qps 的高并发 IM，改如何架构？
```
前几天， 40 岁老架构师尼恩，站在腾讯企业 IM 的巨人肩膀，给大家提供一份比较全面的参考答案。具
体的文章链接为


```
CPU 内存操作系统数量
```
```
Intel (R) Xeon (R) CPU E 5-2630 v 2 @
2.60 GHz
```
```
DDR 3 32 GB Debian GNU/Linux 8 1
```
腾讯太狠： 10 亿 QPS 的 IM，如何实现？

今天天， 40 岁老架构师尼恩，站在 B 站 1000 Wqps 生产级 IM 服务框架的巨人肩膀，再给大家提供一份比
较全面的参考答案。就是本文。

通过这些企业级、工业级、生产级案例，大家可以在面试的时候，对比进行介绍，综合介绍。

从而给面试官展示自己雄厚的技术实力、开阔的技术视野，从而在面试的时候，可以充分展示一下大家
雄厚的 “技术肌肉”， **让你的面试官爱到 “不能自已、口水直流”** 。

这里，尼恩也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 74 版本，供后面的小
伙伴参考，提升大家的 3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，最新尼恩架构笔记、面试题的 PDF 文件，请从这里获取：码云
```
#### B 站 1000 Wqps 生产级 IM 服务框架

goim 是 bilibili 公司技术总监毛剑创作，使用 go 语言开发，用于 B 站生产线上的 IM 服务框架（聊天室），

官网：https://goim.io/

下面是官方的 3590 万 QPS 超高吞吐压测

#### 3590 万 QPS 超高吞吐压测

###### 服务端配置

###### 压测参数

```
不同 UID 同房间在线人数: 1,000,000
持续推送时长: 15 分钟
持续推送数量: 40 条/秒
推送内容: {“test”: 1}
推送类型: 单房间推送
到达计算方式: 1 秒统计一次, 共 30 次
```
###### 资源使用

```
每台服务端 CPU 使用: 2000%~2300%(刚好满负载)
每台服务端内存使用: 14 GB 左右
GC 耗时: 504 毫秒左右
流量使用: Incoming (450 MBit/s), Outgoing (4.39 GBit/s)
```
###### 压测结果

```
推送到达: 3590 万/秒左右;
```
其框架原理图如下：下面是官方的架构图


接下来，尼恩首先给大家介绍 goim 的实操，再介绍底层架构、核心源码、高性能架构设计。

#### goim 搭建

###### 基于 docker 安装 zookeeper、redis、kafka

zookeeper

redis：

kafka：

```
使用尼恩地表最强环境中现成服务
```
```
使用尼恩地表最强环境中现成服务
```
```
version: '3.5'
services:
kafka:
image: 'bitnami/kafka: 2.8.0'
ports:
```
- '9092:9092'
- '9999:9999'
environment:
- KAFKA_BROKER_ID=1
- KAFKA_CFG_LISTENERS=PLAINTEXT://:9092
# 客户端访问地址，更换成自己的主机 IP （如果要外网访问就是服务器 IP）
- KAFKA_CFG_ADVERTISED_LISTENERS=PLAINTEXT://192.168.56.121:9092
- KAFKA_CFG_ZOOKEEPER_CONNECT=192.168.56.121:2181
# 允许使用 PLAINTEXT 协议 (镜像中默认为关闭, 需要手动开启)
- ALLOW_PLAINTEXT_LISTENER=yes
# 关闭自动创建 topic 功能
- KAFKA_CFG_AUTO_CREATE_TOPICS_ENABLE=false
# 全局消息过期时间 6 小时 (测试时可以设置短一点)
- KAFKA_CFG_LOG_RETENTION_HOURS=6
# 开启 JMX 监控


###### 设置 env 环境变量

###### 启动 discovery

两步：

```
拉取 discovery
启动 discovery
```
拉取 discovery

启动 discovery

- JMX_PORT=9999
#volumes :
#- ./kafka:/bitnami/kafka
# Web 管理界面 （用 KnowStreaming 可以不用下面的）
kafka_manager:
image: 'hlebalbau/kafka-manager: latest'
ports:
- "9000:9000"
environment:
ZK_HOSTS: "192.168.56.121:2181"
APPLICATION_SECRET: letmein
depends_on:
- kafka
# docker network create base-env-network
networks:
base-env-network:
external:
name: "base-env-network"

```
export REGION=sh
export ZONE=sh 001
export DEPLOY_ENV=dev
REGION=sh; ZONE=sh 001; DEPLOY_ENV=dev
```
```
[ root@centos1 discovery]# vi /etc/profile
[ root@centos1 discovery]# source /etc/profile
```
```
cd /usr/local
git clone https://github.com/bilibili/discovery.git
```
```
cd /usr/local/discovery/cmd/discovery
go run main. go -conf discovery. toml
```

```
具体实操效果，请参见配套视频
```
###### 启动 comet

启动效果

```
cd goim/cmd/comet
go run main. go -conf comet-example. toml
```
```
-conf D:\virtual\centos-8.2\go\src\goim\cmd\comet\comet-example. toml
```
```
REGION=sh; ZONE=sh 001; DEPLOY_ENV=dev
```

###### 启动 logic

```
go 命令启动 logic
idea 启动 logic
解决 gcc 没有找到的问题
```
```
cd goim/cmd/logic
go run main. go -conf logic-example. toml
```
```
REGION=sh; ZONE=sh 001; DEPLOY_ENV=dev
```
```
-conf D:\virtual\centos-8.2\go\src\goim\cmd\logic\logic-example. toml
```

###### 解决 exec: “gcc“: executable file not found in %PATH%问题

原因：系统没有安装 gcc 编译器

解决方法：安装 MinGW-w 64

什么是 gcc？ GCC（GNU Compiler Collection）是由 GNU 开发的编程语言编译器。 GCC 最初代表
“GNU C Compiler”，当时只支持 C 语言。后来又扩展能够支持更多编程语言，包括 C++、Fortran 和
Java 等。因此，GCC 也被重新定义为“GNU Compiler Collection”，成为历史上最优秀的编译器，其执
行效率与一般的编译器相比平均效率要高 20%~30%。

**一、什么是 MinGW-w 64 ？**

什么是 MinGW-w 64 ？

MinGW 的全称是：Minimalist GNU on Windows 。

一句话来概括：MinGW 就是 GCC 的 Windows 版本。

MinGW 是将经典的开源 C 语言编译器 GCC 移植到了 Windows 平台下，并且包含了 Win 32 API ，因此
可以将源代码编译为可在 Windows 中运行的可执行程序。

而且还可以使用一些 Windows 不具备的，Linux 平台下的开发工具。

MinGW-w 64 与 MinGW 的区别在于 MinGW 只能编译生成 32 位可执行程序，而 MinGW-w 64 则可以编
译生成 64 位或 32 位可执行程序。

正因为如此，MinGW 现已被 MinGW-w 64 所取代，且 MinGW 也早已停止了更新，内置的 GCC 停滞在
了 4.8.1 版本，而 MinGW-w 64 内置的 GCC 则更新到了 6.2.0 版本。

**二、为什么使用 MinGW-w 64 ？**

```
1. MinGW-w 64 是开源软件，可以免费使用。
2. MinGW-w 64 由一个活跃的开源社区在持续维护，因此不会过时。
3. MinGW-w 64 支持最新的 C 语言标准。
4. MinGW-w 64 使用 Windows 的 C 语言运行库，因此编译出的程序不需要第三方 DLL ，可以直接在
Windows 下运行。
5. 那些著名的开源 IDE 实际只是将 MinGW-w 64 封装了起来，使它拥有友好的图形化界面，简化了
操作，但内部核心仍然是 MinGW-w 64。
MinGW-w 64 是稳定可靠的、持续更新的 C/C++ 编译器，使用它可以免去很多麻烦，不用担心跟
不上时代，也不用担心编译器本身有 bug，可以放心的去编写程序。
```
**三、MinGW-w 64 适合做什么？**

对于熟悉 MinGW-w 64 的高手而言，它可以编译任何 C 语言程序。

但对于一般人来说，MinGW-w 64 太过简陋，连图形用户界面都没有。这让习惯使用鼠标的人，感到很
痛苦。虽然也可以通过一些配置，让 MinGW-w 64 拥有图形用户界面，但那个过程非常麻烦。

除此之外，编译复杂的程序时，还需要你会编写 Makefile ，否则只能一个文件一个文件的编译，可想
而知会多么辛苦。
但对于初学 C 语言的人来说，MinGW-w 64 是正合适的编译器，至少黑色的命令提示符界面很有编程的
气氛，感觉很酷。

在刚开始学 C 语言时，所有代码通常都写在一个文件中，只要输入几个简单的命令，就能用 MinGW-
w 64 编译成可执行文件。


虽然 VS 2015 等编译器，只要点击下鼠标就可以完成编译，但它会自动生成一大堆工程文件，让初学者
摸不着头脑。

而 MinGW-w 64 则只会生成一个可执行文件。

如果对 MinGW-w 64 和 VS 2015 等编译器进行一下形容，那么 MinGW-w 64 是手动的，而 VS 2015 等编
译器则是自动的。

因此 MinGW-w 64 的编译过程更加直观容易理解，也比较适合 C 语言学习。

总而言之，对于一般人来说，MinGW-w 64 适合学习 C 语言时使用，真正工作还是用 VS 2015 更好。

当然如果您是在 Linux 下工作，那么 Code:: Blocks 可能是一个选择，不过最大的可能是您必须习惯使用
GCC 来编译程序。

**四、下载和安装 MinGW-w 64**

1. 到官网下载 MinGW，下载地址：

MinGW-w 64 - for 32 and 64 bit Windows download | SourceForge. net

也可以使用尼恩的网盘版本 exe 文件

2. 下载完成后安装，

Architecture 选项中如果是 32 位系统就选择 i 686.

如果是 64 位系统就选择 x 86_64.

下一步安装路径可以自己选择。


如果出现报错 cc 1. exe: sorry, unimplemented: 64-bit mode not compiled in 就说明你安装的是 32 位
的，需要重新安装 64 位的才可以。

3. 安装完成后将自己的安装路径下的 mingw 64\bin 目录添加到环境变量 PATH，

例如默认的安装目录是 C:\Program Files\mingw-w 64\x 86_64-8.1.0-posix-seh-rt_v 6-
rev 0\mingw 64\bin

C:\Program Files\mingw-w 64\x 86_64-8.1.0-posix-seh-rt_v 6-rev 0

d:\Program Files\mingw-w 64\x 86_64-8.1.0-win 32-seh-rt_v 6-rev 0

4. cmd 执行 gcc -v 看看是否安装成功，如果成功重启你的编辑器重新运行就不报错了

**五：安装失败**

**1. 问题背景**


```
安装 MinGW 的原因是要搭建一个 C++的环境阅读 JVM 的 HotSpot 源码，笔者后面转用虚拟机的
CentOS 系统安装，能成功搭好 C++环境。此文仅为帮助有需要安装 MinGW 的小伙伴。
```
```
今天使用 exe 在线安装器安装 MinGW-w 64 时弹出下面报错的提示框
```
**2. 报错原因**

因为文件资源是托管在 sourceforge 上面的，因此在线安装器需要从该网站上下载文件。99%都是网络
不好导致下载失败，有能力者可以科学上网解决。没办法科学上网的同学可以使用下面的解决方案，很
简单。

**3. 解决方案**

```
前往 MinGW-w 64 的 sourceforge 页面，直接下载完整的包即可，如下图所示：
```

版本这里根据各自的电脑选择，我的电脑是 64 位，所以选择 **x 86_64** ；

电脑是 windows 系统，所以选择 **win 32** ； **seh** 是先进的异常处理模式技术，支持 64 位操作系统。

其他硬件情况可以参考 MinGW-w 64 安装教程——著名 C/C++编译器 GCC 的 Windows 版本。

```
下载完成后，配置环境变量：
首先看我解压出来后存放目录：
```

```
点击进入 bin 目录，等下配置的环境变量路径就是下图的这个路径：
```
```
配置环境变量：
```
以上文件不好找，直接在尼恩的视频配套网盘资源文件夹里边获取。

###### 启动 job

###### 启动 goim 的 example

修改：

也可以在 idea 里边直接修改：

```
cd goim/cmd/logic
go run main. go -conf job-example. toml
```
```
REGION=sh; ZONE=sh 001; DEPLOY_ENV=dev
```
```
go run main. go -conf D:\virtual\centos-8.2\go\src\goim\cmd\job\job-example. toml
```
```
vim goim/example/javascript/client. js
```
```
var ws = new WebSocket ('ws://127.0.0.1:3102/sub');
```

执行

浏览器打开
[http://127.0.0.1:1999](http://127.0.0.1:1999)

然后发送数据

#### 源码解读

本文的重点，主要梳理了 GOIM 的架构，消息流转和消息处理。

本文没有提到 Comet 的具体逻辑，套接字编程和 RingBuffer 等，但是 Comet 的复杂度远高于其他两个网
元，因此强烈建议阅读 Comet 源码，应该会对 Go 网络编程有更多认识。

GOIM 是 Go 实现的消息推送的分布式服务，易于扩容伸缩，使用了 bilibili/discovery 来支持服务发现。

相较于我之前用 Socket. IO 做的信令服务，优点在于更优雅的扩容，将连接层和逻辑层分离，职责更清
晰。

```
cd goim/example/javascript
```
```
go run main. go
```
```
go run main. go -conf D:\virtual\centos-8.2\go\src\goim\examples\javascript
```
```
curl -d 'mid message' 'http://192.168.56.1:3111/goim/push/mids?
operation=1000&mids=123'
```
```
-d/–data HTTP POST 方式传送数据
```

当然缺点也有（没有和具体实现解耦，如 MQ 的选型，导致不够灵活；客户端非全双工通信，TCP 利用
率偏低，这点并不全是缺点，好处是：消息流转清晰，职责非常明确），这部分可以自己做定制（最后
的参考文献 2 中讲很多）。

###### 核心依赖库

核心的依赖库：

```
grpc
redis
kafka
```
```
//配置文件操作
github. com/BurntSushi/toml v 0.3.1
//kafka 相关
github. com/Shopify/sarama v 1.19.0 // indirect
//discovery 依赖
github. com/bilibili/discovery v 1.0.1
//kafka 相关
github. com/bsm/sarama-cluster v 2.1.15+incompatible
github. com/davecgh/go-spew v 1.1.1 // indirect
github. com/eapache/go-resiliency v 1.1.0 // indirect
github. com/eapache/go-xerial-snappy v 0.0.0- 20180814174437 - 776 d 5712 da 21 //
indirect
github. com/eapache/queue v 1.1.0 // indirect
//http 请求处理库
github. com/gin-gonic/gin v 1.3.0
//grpc 数据序列化库
github. com/gogo/protobuf v 1.1.1
github. com/golang/glog v 0.0.0- 20160126235308 - 23 def 4 e 6 c 14 b
github. com/golang/protobuf v 1.2.0
github. com/golang/snappy v 0.0.0- 20180518054509 - 2 e 65 f 85255 db // indirect
//redis 操作
github. com/gomodule/redigo v 2.0.0+incompatible
github. com/google/uuid v 1.0.0
github. com/issue 9/assert v 1.0.0
github. com/pierrec/lz 4 v 2.0.5+incompatible // indirect
github. com/pkg/errors v 0.8.0
github. com/rcrowley/go-metrics v 0.0.0- 20181016184325 - 3113 b 8401 b 8 a // indirect
github. com/smartystreets/assertions v 0.0.0- 20180927180507 - b 2 de 0 cb 4 f 26 d //
indirect
github. com/smartystreets/goconvey v 0.0.0- 20180222194500 - ef 6 db 91 d 284 a
github. com/stretchr/testify v 1.3.0
github. com/thinkboy/log 4 go v 0.0.0- 20160303045050 - f 91 a 411 e 4 a 18
github. com/ugorji/go/codec v 0.0.0- 20190204201341 - e 444 a 5086 c 43
github. com/zhenjl/cityhash v 0.0.0- 20131128155616 - cdd 6 a 94144 ab
golang. org/x/net v 0.0.0- 20181011144130 - 49 bb 7 cea 24 b 1
//远程服务调用相关 rpc 库
google. golang. org/grpc v 1.16.0
//kafka 相关库
gopkg. in/Shopify/sarama. v 1 v 1.19.0
gopkg. in/yaml. v 2 v 2.2.2 // indirect
```

#### GOIM 网元架构

总的来说，整个应用的架构如下

下面是官方的架构图

```
Comet 负责建立和维持客户端的长连接；
Job 负责消息的分发；
Logic 提供三种纬度的消息（全局，ROOM，用户）投递，还包括业务逻辑，Session 管理。
```
来一个细致点的架构图


在整个架构中，系统被分成 Comet, Logic, Job, Router 四大模块，主要的功能为：

```
Comet 程序是连接层，暴露给公网，
内网所有的业务处理推给 Logic 模块，通过 RPC 通信。
各个模块通过 RPC 同步通信+ MQ 异步通讯结合交互，
```
从消息的发送和接收的流程视角来说，四大模块之间的关系为：

```
1. logic 启动 http 服务器，接受 http 请求，用于将数据推送到 kafka 以及获取在线用户信息，
websocket 身份校验
2. comet 组件起动 webdocket/tcp 服务，管理连接，并负责将数据推送至指定连接
3. job 组件订阅指定 kafka 指定频道的消息信息, 开启管道监听（将获得的数据推送到 comet 当中某个
链接上）从 discovery 当中找到 comet 组件
4. discovery 负责监控以上组件的活动状态
```
###### comet

comet 属于接入层，非常容易扩展，直接开启多个 comet 节点，修改配置文件中的 base 节点下的
server. id 修改成不同值（注意一定要保证不同的 comet 进程值唯一），前端接入可以使用 LVS 或者 DNS
来转发

###### logic

logic 属于无状态的逻辑层，可以随意增加节点，使用 nginx upstream 来扩展 http 接口，内部 rpc 部分，
可以使用 LVS 四层转发

###### kafka

kafka 可以使用多 broker，或者多 partition 来扩展队列

###### router

router 属于有状态节点，logic 可以使用一致性 hash 配置节点，增加多个 router 节点

目前还不支持动态扩容，所以，提前预估好在线和压力情况

###### job

job 根据 kafka 的 partition 来扩展多 job 工作方式，具体可以参考下 kafka 的 partition 负载

###### 如何进行高并发伸缩

comet 属于接入层，非常容易扩展，直接开启多个 comet 节点，前端接入可以使用 LVS 或者 DNS 来转
发。

logic 属于无状态的逻辑层，可以随意增加节点，使用 nginx upstream 来扩展 http 接口，内部 rpc 部
分，可以使用 LVS 四层转发。

job 用于解耦 comet 和 logic。

系统使用 kafka 作为消息队列，可以通过 kafka 使用多个 broker 或者多个 partition 来扩展队列。


使用 redis 作为元数据、节点心跳信息等维护

#### 几个重要的结构体

Bucket 管理者 Rooms 和 Channel，都是以 map 数据结构保存，

room 是以 rid (roomId) 为 key，room 实体指针为 value，Channel 是 subkey 为 key，channel 实体指针为
value。

**一个 channel 维护着一个长链接用户，对应着唯一的 room，而同一个 room 拥有多条 channel**

**Bucket:**

每个 Comet 程序拥有若干个 Bucket,

一个 Bucket 可以理解为 Session Map,

一个 Bucket 保存着当前 Comet 服务于哪些 Room 和 Channel.

一个 Channel 长连接具体分布在哪个 Bucket 上呢？根据 SubKey 一致性 Hash 来选择。

**Room:**

Room 房间，可以理解为群组或是一个 Group.

这个房间内维护 N 个 Channel, 即长连接用户。

在该 Room 内广播消息，会发送给房间内的所有 Channel.

**Channel:**

维护一个长连接用户，只能对应一个 Room.

推送的消息可以在 Room 内广播，也可以推送到指定的 Channel.

**Proto:**

消息结构体，存放版本号，操作类型，消息序号和消息体。

###### Bucket 结构体

定义很明了，维护当前消息通道和房间的信息，


一个 Comet Server 默认开启 1024 Bucket, 这样做的好处是减少锁 ( Bucket. cLock ) 争用，在大并发业
务上尤其明显。

Bucket 方法也很简单，加减 Channel 和 Room.

```
// Put put a channel according with sub key.
func (b *Bucket) Put (rid string, ch *Channel) (err error) {
var (
room *Room
ok bool
)
b.cLock.Lock ()
// close old channel
if dch := b.chs[ch. Key]; dch != nil {
dch.Close ()
}
b.chs[ch. Key] = ch
if rid != "" {
if room, ok = b.rooms[rid]; !ok {
room = NewRoom (rid)
b.rooms[rid] = room
}
ch. Room = room
}
b.ipCnts[ch. IP]++
b.cLock.Unlock ()
if room != nil {
err = room.Put (ch)
}
return
}
```

###### Room 结构

Room 结构体稍显复杂一些，

Room 不但要维护所属的消息通道 Channel, 还要消息广播的合并写，即 Batch Write,

Room 如果不合并写，每来一个小的消息都通过长连接写出去，系统 Syscall 调用的开销会非常大，
Pprof 的时候会看到网络 Syscall 是大头。

Logic Server 通过 RPC 调用，将广播的消息发给 Room. Push, 数据会被暂存在 proto 这个结构体里，
每个 Room 在初始化时会开启一个 groutine 用来处理暂存的消息，达到 Batch Num 数量或是延迟一
定时间后，将消息批量 Push 到 Channel 消息通道。

```
// Del delete the channel by sub key.
func (b *Bucket) Del (dch *Channel) {
...
}
```
```
// Channel get a channel by sub key.
func (b *Bucket) Channel (key string) (ch *Channel) {
b.cLock.RLock ()
ch = b.chs[key]
b.cLock.RUnlock ()
return
}
```

###### Channel 结构

Channel 是一个通道。

Channe 的 Writer/Reader 就是对网络 Conn 的封装，

cliProto 是一个 Ring Buffer，保存 Room 广播或是直接发送过来的消息体。

###### 消息结构

**1. 任务队列消息**

不管是个人消息，还是房间消息和广播消息，都是用的如下结构；

其中 Op 和 Type 可以帮助 Job 单元可以针对消息上做差异化的处理。

**2. GOIM 消息协议**

```
type PushMsg struct {
Type PushMsg_Type // 消息类型，个人，房间广播，广播
Operation int 32 // 指令 goim/api/comet/grpc/operation. go
Speed int 32 // 广播时用 TODO:
Server string // Comet 的 Hostname, 个人消息时指定
Room string // 房间号
Keys []string // bucket key
Msg []byte // 消息体
}
```

区别于任务队列消息，这个条消息是客户端实际收到的消息

其中只有 Op 和 Body 是从 Logic 单元传递过来的，其他字段很大一部分用于消息路由，定位 Comet/
Bucket/ Room/ Channel，

#### 消息流转

###### 生成消息

Logic 提供了 HTTP 接口以支持消息发送能力，业务消息（除鉴权/心跳等基础数据包外）生成都是由
Logic 完成第一手处理，

主要有三个纬度：用户，房间，全应用广播：

用户消息的 demo

房间消息的 demo

全应用广播消息的 demo

###### 消息的投递

从架构图中可以知道，消息的投递分为三棒：

第一棒： 消息是通过 HTTP 调用 Logic 服务，然后用 MQ 来存储削峰；

```
type Proto struct {
Ver int 32 // 版本号
Op int 32 // 消息类型，如 Ping，Pong, Text
Seq int 32 // 序列号 TODO:
Body []byte // 消息体等于 PushMsg. Msg
}
```
```
curl -d 'mid message' http://api.goim.io:3111/goim/push/mids?
operation= 1000 &mids= 123
```
```
curl -d 'broadcast message' http://api.goim.io:3111/goim/push/all?
operation= 1000
```
```
curl -d 'broadcast message' http://api.goim.io:3111/goim/push/all?
operation= 1000
```

第二棒：Job 成员都从给队列中消费消息，投递给一个或者多个 Comet，

第三棒：由 Comet 将消息发送给客户端。

#### 第一棒：Logic 服务的消息消峰

###### logic

logic 处理 http 请求（启用 http 服务，rpc 服务，供其他组件进行调用）

logic 模块是 comet 模块调用的，接受 comet 模块的命令，然后进行处理，再发送的消息的 kafka 队列
上，同时链接 router 模块，记录用户的 uid server room 等信息。同时获得 router 模块的信息。


cmd/logic/main. go

```
func main () {
flag.Parse ()
if err := conf.Init (); err != nil {
panic (err)
}
log.Infof ("goim-logic [version: %s env: %+v] start", ver, conf. Conf. Env)
// grpc register naming
dis := naming.New (conf. Conf. Discovery)
resolver.Register (dis)
// logic
srv := logic.New (conf. Conf)
//启动 http 监听服务，监听来自客户端的 http 请求
httpSrv := http.New (conf. Conf. HTTPServer, srv)
//启动 grpc 服务，监听来自其他组件的 rpc 调用
```

###### http 服务

internal/logic/http/server. go

###### rpc 服务

internal/logic/grpc/server. go

```
rpcSrv := grpc.New (conf. Conf. RPCServer, srv)
...
}
```
```
func New (c *conf. HTTPServer, l *logic. Logic) *Server {
engine := gin.New ()
engine.Use (loggerHandler, recoverHandler)
go func () {
if err := engine.Run (c.Addr); err != nil {
panic (err)
}
}()
s := &Server{
engine: engine,
logic:  l,
}
//初始化路由（测试例子当中的请求 uri 就是这边设置映射的）
s.initRouter ()
return s
}
...
//初始化 http 路由
func (s *Server) initRouter () {
group := s.engine.Group ("/goim")
group.POST ("/push/keys", s.pushKeys)
group.POST ("/push/mids", s.pushMids)
group.POST ("/push/room", s.pushRoom)
group.POST ("/push/all", s.pushAll)
group.GET ("/online/top", s.onlineTop)
group.GET ("/online/room", s.onlineRoom)
group.GET ("/online/total", s.onlineTotal)
group.GET ("/nodes/weighted", s.nodesWeighted)
group.GET ("/nodes/instances", s.nodesInstances)
}
```
```
func New (c *conf. RPCServer, l *logic. Logic) *grpc. Server {
keepParams := grpc.KeepaliveParams (keepalive. ServerParameters{
MaxConnectionIdle: time.Duration (c.IdleTimeout),
MaxConnectionAgeGrace: time.Duration (c.ForceCloseWait),
Time: time.Duration (c.KeepAliveInterval),
Timeout:  time.Duration (c.KeepAliveTimeout),
MaxConnectionAge: time.Duration (c.MaxLifeTime),
})
//创建 rpc 服务
```

###### MQ 消费处理

在 Logic 服务中会通过处理，将消息处理成 ** #消息格式 #任务队列消息 ** 的格式，然后投递到 MQ中。

其中三种纬度的消息处理稍有不同：

**用户消息**

**房间消息**

没什么特别的处理

```
srv := grpc.NewServer (keepParams)
//注册 rpc 服务（做一些路由映射..)
pb.RegisterLogicServer (srv, &server{l})
lis, err := net.Listen (c.Network, c.Addr)
if err != nil {
panic (err)
}
go func () {
if err := srv.Serve (lis); err != nil {
panic (err)
}
}()
return srv
}
```
```
// goim/internal/logic/push. go
// mid => []PushMsg{op, server, keys, msg}
func (l *Logic) PushMids (c context. Context, op int 32, mids []int 64, msg []byte)
(err error) {
// 根据用户 ID 获取所有的 key: server 对应关系；在 redis 中是一个 hash
keyServers, _, err := l.dao.KeysByMids (c, mids)
// ...
keys := make (map[string][]string)
for key, server := range keyServers {
// ...
keys[server] = append (keys[server], key)
}
for server, keys := range keys {
// 通过 DAO 组装 PushMsg 投递给 MQ
if err = l.dao.PushMsg (c, op, server, keys, msg); err != nil {
return
}
}
return
}
```
```
// goim/internal/logic/push. go
func (l *Logic) PushRoom (c context. Context, op int 32, typ, room string, msg
[]byte) (err error) {
return l.dao.BroadcastRoomMsg (c, op, model.EncodeRoomKey (typ, room), msg)
}
```

**广播消息**

没什么特别的处理

小结：

```
针对用户单发时，会获取到具体的 sever 和 keys 组装到 PushMsg
房间消息，没有 server 和 keys, 但是多一个 room 是通过 typ 和 roomID 组装而成的 “live://1000”
广播消息，除了消息体之外，另外有一个 speed 字段
```
```
// // goim/internal/logic/dao
func (d *Dao) BroadcastRoomMsg (c context. Context, op int 32, room string, msg
[]byte) (err error) {
pushMsg := &pb. PushMsg{
Type:  pb. PushMsg_ROOM,
Operation: op,
Room:  room,
Msg: msg,
}
b, err := proto.Marshal (pushMsg)
// ...
```
```
if err := d.nsqProducer.Publish (d.c.Nsq. Topic, b); err != nil {
log.Errorf ("PushMsg.send (push pushMsg:%v) error (%v)", pushMsg, err)
}
return
}
```
```
// goim/internal/logic/push. go
func (l *Logic) PushAll (c context. Context, op, speed int 32, msg []byte) (err
error) {
return l.dao.BroadcastMsg (c, op, speed, msg)
}
```
```
// goim/internal/logic/dao
func (d *Dao) BroadcastMsg (c context. Context, op, speed int 32, msg []byte) (err
error) {
pushMsg := &pb. PushMsg{
Type:  pb. PushMsg_BROADCAST,
Operation: op,
Speed: speed, // 这里需要去到 Job 才知道 speed 的具体功效
Msg: msg,
}
b, err := proto.Marshal (pushMsg)
if err != nil {
return
}
```
```
if err := d.nsqProducer.Publish (d.c.Nsq. Topic, b); err != nil {
log.Errorf ("PushMsg.send (push pushMsg:%v) error (%v)", pushMsg, err)
}
return
}
```

#### 第二棒：传输消息

由 Logic 处理好的消息会放在 MQ 中，然后到了第二棒：Job 成员都从给队列中消费消息，投递给一个或
者多个 Comet

第二棒的 Job 任务怎么和 Comet 单元或者网元通讯呢？ 通过 gRPC 调用 Comet 单元。

第二棒的 Job 任务通过 gRPC 调用 Comet 单元的方式，push 到相关的 comet 服务器上。用户就接受到了
消息。

相比其他两个网元，Job 就简单多了。

###### job 组件

job 组件创建 kafka 订阅服务，对 comet 组件进行监听

internal/job/job. go 具体实现

```
func main () {
flag.Parse ()
if err := conf.Init (); err != nil {
panic (err)
}
log.Infof ("goim-job [version: %s env: %+v] start", ver, conf. Conf. Env)
// grpc register naming
dis := naming.New (conf. Conf. Discovery)
resolver.Register (dis)
// job
j := job.New (conf. Conf)
go j.Consume ()
...
}
```
```
func New (c *conf. Config) *Job {
j := &Job{
c:  c,
consumer: newKafkaSub (c.Kafka),
rooms:  make (map[string]*Room),
}
j.watchComet (c.Discovery)
return j
}
```

###### job 发送消息（普通消息，房间消息，广播）

从 MQ 中消费到消息后会调用c.job.push (ctx, pushMsg)。

```
// job 发送消息（普通消息，房间消息，广播）
func (j *Job) push (ctx context. Context, pushMsg *pb. PushMsg) (err error) {
switch pushMsg. Type {
case pb. PushMsg_PUSH:
err = j.pushKeys (pushMsg. Operation, pushMsg. Server, pushMsg. Keys,
pushMsg. Msg)
case pb. PushMsg_ROOM:
// 获取一个 job 中的 Room 缓存，用于房间内“定时，定量”发送消息，减少请求次数
// 这里调用的 Push 并不会立即发送，而是放在 Room. proto 这个 channel 中
// 实际放松是由 Room. pushproc 来定时
err = j.getRoom (pushMsg. Room). Push (pushMsg. Operation, pushMsg. Msg)
case pb. PushMsg_BROADCAST:
err = j.broadcast (pushMsg. Operation, pushMsg. Msg, pushMsg. Speed)
default:
err = fmt.Errorf ("no match push type: %s", pushMsg. Type)
}
return
}
```
```
// 根据 serverID 发送给特定的 Comet 服务，避免广播
// cometServers 是由 discovery 服务发现维护的 comet 列表。
func (j *Job) pushKeys (operation int 32, serverID string, subKeys []string, body
[]byte) (err error) {
buf := bytes.NewWriterSize (len (body) + 64 )
p := &comet. Proto{
Ver: 1 ,
Op: operation,
Body: body,
}
p.WriteTo (buf)
p.Body = buf.Buffer ()
p.Op = comet. OpRaw
var args = comet. PushMsgReq{
Keys:  subKeys,
ProtoOp: operation,
Proto: p,
}
if c, ok := j.cometServers[serverID]; ok {
if err = c.Push (&args); err != nil {
log.Errorf ("c.Push (%v) serverID:%s error (%v)", args, serverID, err)
}
log.Infof ("pushKey:%s comets:%d", serverID, len (j.cometServers))
}
return
}
```
```
// 处理成一个 BroadcastReq, 并广播给所有的 Comet
func (j *Job) broadcast (operation int 32, body []byte, speed int 32) (err error) {
// ... 与 pushKeys 一致，生成一个 p
comets := j.cometServers
// 如 speed = 64, len (comets) = 2, speed = 32
```

**房间消息处理** ：

```
speed /= int 32 (len (comets))
var args = comet. BroadcastReq{
ProtoOp: operation,
Proto: p,
Speed: speed, // 是被传递给 Comet 处理，继续跟踪
}
for serverID, c := range comets {
if err = c.Broadcast (&args); err != nil {
log.Errorf ("c.Broadcast (%v) serverID:%s error (%v)", args, serverID,
err)
}
}
log.Infof ("broadcast comets:%d", len (comets))
return
}
```
```
getRoom (roomID) -> room.Push () -> p -> room. proto
|
|---> NewRoom (batch, duration)
|
|---> go room.pushproc () -> p <- room. proto
// goim/internal/job/room. go
type Room struct {
c *conf. Room // 关于房间的配置
job *Job // 绑定 job，为了追溯 Room 所属的 Job
id string // 房间 ID
proto chan *comet. Proto // 有缓冲 channel
}
```
```
// pushproc merge proto and push msgs in batch.
// 默认 batch = 20, sigTime = 1 s
func (r *Room) pushproc (batch int, sigTime time. Duration) {
var (
n int
last time. Time
p *comet. Proto
buf = bytes.NewWriterSize (int (comet. MaxBodySize)) // 4096 B = 4 KB
)
```
```
// 设置了一个定时器, 在一定时间后往 room. proto 放送一个 roomReadyProto 信号。
td := time.AfterFunc (sigTime, func () {
select {
case r.proto <- roomReadyProto:
default:
}
})
defer td.Stop ()
```
```
for {
if p = <-r.proto; p == nil {
// 如果创建了 room，但是读到空包
break // exit
} else if p != roomReadyProto {
// 读取 room. proto 如果是正常的数据包，则合并到 buf 中去, 如果满了怎么办？
p.WriteTo (buf)
```

###### goroutine 和 channel 实现高并发架构

Job 中也充分利用 goroutine 和 channel，在 Job 中，每个 comet 区分不同的消息推送通道。

```
1. pushChan ：推送单聊消息的通道，分为 N 组，依次将消息推送的 N 组中，每个组有自己的
goroutine, 来提高并发性
2. roomChan ：推送群聊消息的通道，分为 N 组，依次将消息推送的 N 组中，每个组有自己的
goroutine, 来提高并发性
3. broadcastChan ：广播消息
4. 开启 N 个 goroutine，每个 goroutine，接收单聊、群聊和广播消息。
```
```
// 如果是第一个数据包，则重置定时器，并继续读取后续数据包
if n++; n == 1 {
last = time.Now ()
td.Reset (sigTime)
continue
} else if n < batch {
// 后续的数据包，不会重置定时器，但是如果时间仍在第一个数据包的 sigTime 时
间间隔内
// 简单说，定时器还没到时间
if sigTime > time.Since (last) {
continue
}
}
// 累计的数据包数量已经超过了 batch, 执行发送动作
} else {
// 定时器到读到了 roomReadyProto
// 如果 buf 已经被重置了，则跳出循环执行清理动作；否则执行发送消息
if n == 0 {
break
}
}
```
```
// 发送房间内的消息
_ = r.job.broadcastRoomRawBytes (r.id, buf.Buffer ())
buf = bytes.NewWriterSize (buf.Size ())
n = 0
```
```
// 如果配置了房间最大闲置时间，则重新设定定时器
// 也就是说，如果房间被创建后，处理完了该房间的消息，并不是直接跳出循环清理房间
// 而是，会阻塞等待下一次的消息再来，如果在 “1 m / r.c.Idle” 时间内没有来，则会跳出
循环清理掉该房间
// 如果在 “1 m / r.c.Idle” 内有消息，则会重新设定定时器为 sigTime，并为 proto 计数
if r.c.Idle != 0 {
td.Reset (time.Duration (r.c.Idle)) // 默认 15 分钟
} else {
td.Reset (time. Minute)
}
}
```
```
// 清理动作
r.job.delRoom (r.id)
}
```

```
具体请参见配套视频里边的源码解读。
```
###### 队列缓存+批量写入高并发架构

在 job 推送 room 消息时，并非在收到消息的时候就推送到 comet，是是通过一定的策略实现批量推
送，来提高读写性能。

对于某个 room 消息而言，会开启一个 goroutine 来处理并开启了写缓冲机制，按批次进行发送 (消息
个数)。接收到消息之后，不是马上发送，而是进行缓冲，等待一段时间，看看还有没有消息。

推送的条件一是已经达到了最大批次数，二是超时。如果长时间没有消息，会销毁这个 room。

具体参考 internal/job/room. go pushproc 实现。

###### Job 处理房间消息小结：

```
针对用户单发时，会直接发送到对应的 comet 服务，根据 key 再去给特定的 channel 发送消息
房间消息，这个会特殊一些，Job 持有一个特殊的 Room 结构，用于合并发送到该房间的消息，定
时定量发送房间消息（好处是，减少了 gRPC 调用次数降低系统负载，缺点增加时消息延迟）
广播消息，将消息封装到 BroadcastPushReq 中，然后直接发送给所有的 Comet
```
#### 第三棒：由 Comet 将消息发送给客户端

###### Comet（彗星）的主要功能

comet 模块是在最前端，主要负责和 client 的链接保持，同时接受，发送消息，通知到客户端。检查链
接是否断开。


###### Comet 处理的 main 方法

```
func main () {
flag.Parse ()
//配置初始化
if err := conf.Init (); err != nil {
panic (err)
}
rand.Seed (time.Now (). UTC (). UnixNano ())
runtime.GOMAXPROCS (runtime.NumCPU ())
log.Infof ("goim-comet [version: %s env: %+v] start", ver, conf. Conf. Env)
// register discovery
dis := naming.New (conf. Conf. Discovery)
resolver.Register (dis)
// new comet server
srv := comet.NewServer (conf. Conf)
if err := comet.InitWhitelist (conf. Conf. Whitelist); err != nil {
panic (err)
}
//初始化 TCP 服务
if err := comet.InitTCP (srv, conf. Conf. TCP. Bind, runtime.NumCPU ()); err !=
nil {
```

cmd/comet/main. go 代码中可以看到, 启用 tcp 与 websocket 监听服务

Goim 支持 Tcp, Http, WebSocket, TLS WebSocket. 非常强大，底层原理一样，下面的分析都是基于
Tcp 协议。

###### Comet 如何管理用户端的长连接

Comet 接收到 Job 单元的 gRPC 调用之后，会将消息通过 Websocket 套接字按照 GOIM 约定的协议格式发
送给指定客户端。

从 Job 那边传输过来的消息，依旧是分为用户消息，房间消息，全局消息。

这里得先说明下 Comet 是如何管理用户端的长连接，如下图：

```
panic (err)
}
//初始化 websocket 服务
if err := comet.InitWebsocket (srv, conf. Conf. Websocket. Bind,
runtime.NumCPU ()); err != nil {
panic (err)
}
```
```
//使用 tls 传输方式的 websocket 验证
if conf. Conf. Websocket. TLSOpen {
if err := comet.InitWebsocketWithTLS (srv, conf. Conf. Websocket. TLSBind,
conf. Conf. Websocket. CertFile, conf. Conf. Websocket. PrivateFile,
runtime.NumCPU ()); err != nil {
panic (err)
}
}
```
```
// new grpc server
rpcSrv := grpc.New (conf. Conf. RPCServer, srv)
}
```

###### Comet 如何进行 channel 管理

Bucket 是一个管理 Channel 和 Room 的数据结构，

Bucket 的作用在于使用了 hash 来将 Channel 做分片管理，相较于集中管理，这样 channel 分布在不同的
bucket 中而不是一个 map，可以降低冲突，减小锁的粒度。

有了上述结构，那么消息发送在忽略传输层的情况下：

**针对用户单发**

调用链路为：

这里 Push 也只是将 proto 放在了 channel 的队列中（ 10 缓冲），消息的下发在

**房间消息**

在 Comet 内部遍历 Buckets 并调用 Bucket.BroadcastRoom ()，但是这里也只是把消息放到了“某处”，并
没有直接发送。

```
comet.Bucket (key). Channel (key). Push (proto)
```
```
goim/internal/comet/server_websocket. go #dispatchWebsocket
```

实际发送代码在 goim/internal/comet/bucket. go #roomproc 。

**广播消息**

在 Comet 内部遍历 Buckets 并向 Bucket 中的所有 Channel 发送消息。

这里终于用到了 speed，上文提到过，如果设定 speed = 64， len (comets) = 2, 那么这里用到的 speed
= 32。

```
// BroadcastRoom broadcast a message to specified room
func (b *Bucket) BroadcastRoom (arg *grpc. BroadcastRoomReq) {
// 这里取模选中一个 goroutine 来执行任务
num := atomic. AddUint 64 (&b.routinesNum, 1 ) % b.c.RoutineAmount
// b.routines 是 b.c.RoutineAmount 数量的有 b.c.RoutineSize 缓冲大小的 chan
*grpc. BroadcastRoomReq
b.routines[num] <- arg
}
```
```
// 在创建 Bucket 时，便开启了 goroutine 来处理
func (b *Bucket) roomproc (c chan *grpc. BroadcastRoomReq) {
for {
arg := <-c
if room := b.Room (arg. RoomID); room != nil {
room.Push (arg. Proto)
}
}
}
```
```
// 遍历房间内的 channel 的链表，将消息放到 channel 的发送队列中，又回到了 channel 消息单发的逻
辑。
func (r *Room) Push (p *grpc. Proto) {
r.rLock.RLock ()
for ch := r.next; ch != nil; ch = ch. Next {
_ = ch.Push (p)
}
r.rLock.RUnlock ()
}
```
```
// Broadcast broadcast msg to all user.
func (s *server) Broadcast (ctx context. Context, req *pb. BroadcastReq)
(*pb. BroadcastReply, error) {
if req. Proto == nil {
return nil, errors. ErrBroadCastArg
}
```
```
go func () {
for _, bucket := range s.srv.Buckets () {
bucket.Broadcast (req.GetProto (), req. ProtoOp)
if req. Speed > 0 {
//该 bucket
// 有 0 个 channel 时，t = 0 / 32 = 0
// 有 2 个 channel 时, t = 2 / 32 = 0.0625
// 有 32 个 channel 时, t = 32 / 32 = 1
// 有 64 个 channel 时，t = 64 / 32 = 2
// 由此可得，（comet）speed 的含义是每个 bucket 每秒最多发送的消息数量
t := bucket.ChannelCount () / int (req. Speed)
time.Sleep (time.Duration (t) * time. Second)
```

小结：

```
针对用户单发时，直接利用 key 定位到 Bucket 和 Channel，将消息放到队列中。
房间消息，将消息分配到房间协程之一的队列中，在该协程中会持续不断的消费消费消息并处理，
处理动作是将消息分发到 Channel 的消息队列（buffered chan）上。
广播消息，直接使用了 bucket 的 chs 遍历，来为每一个 Channel 推送一条消息到消息队列上。
```
###### 锁分段的架构

一个 Comet Server 默认开启 1024 Bucket, 这样做的好处是减少锁 ( Bucket. cLock ) 争用，在大并发业
务上尤其明显。

comet 模块进行锁分段的架构，将全局的 TCP 链接管理，根据 subKey 进行 bucket 分段

通过 bucket 来拆分 TCP 链接，每个 TCP 链接根据一定的规则划分到不同的 bucket 中进行管理，而不
是集中到单个大而全 bucket 中，这样锁的粒度更小，资源竞争几率就更低，性能也能更好的提升，不
需要将时间花费的等锁上。

```
}
}
}()
return &pb. BroadcastReply{}, nil
}
```
```
// 广播，直接从 bucket. chs 中遍历
func (b *Bucket) Broadcast (p *grpc. Proto, op int 32) {
var ch *Channel
b.cLock.RLock ()
for _, ch = range b.chs {
// 如果不在该 channel 的监听队列中，那么该消息不会发给该客户端
// 这个监听队列，是在建立连接是发送的 “accepts” 字段中取得的
// 譬如 accpets = [1000, 1001, 1002], 但是 op = 1003，那么就不会发送
//
// 值得注意的是，这个 op 是从 BroadcastReq. ProtoOp 取得，BroadcastReq. ProtoOp 又是
从 pushMsg. Operation 取得
// 也就是说 op = grpc. BroadcastReq. ProtoOp = proto. Op = PushMsg. Operation
= 从发送消息接口产生。
//
if !ch.NeedPush (op) {
continue
}
_ = ch.Push (p)
}
b.cLock.RUnlock ()
}
```
```
//internal/comet/server. go
//初始化 Server，生成多个 bucket.
func NewServer (c *conf. Config) *Server {
....
s.buckets = make ([]*Bucket, c.Bucket. Size)
s.bucketIdx = uint 32 (c.Bucket. Size)
for i := 0 ; i < c.Bucket. Size; i++ {//生成多个 bucket
s.buckets[i] = NewBucket (c.Bucket)
```

###### goroutine 和 channel 实现高并发

比如 comet 对于推送 room 消息，每个 bucket 将推送通道分成 32 个，每个通道 1024 长度。

每个通道由一个 goroutine 进行消费处理。

推送 room 消息的时候，依次推送到这 32 个通道中。

这样做提高 bucket 内部的并发度，不至于一个通道堵塞，导致全部都在等待。

```
}
...
}
//根据 subKey 获取 bucket，将不同的 TCP 分配到不同的 bucket 进行管理。
func (s *Server) Bucket (subKey string) *Bucket {
idx := cityhash. CityHash 32 ([]byte (subKey), uint 32 (len (subKey))) %
s.bucketIdx
if conf. Conf. Debug {
log.Infof ("%s hit channel bucket index: %d use cityhash", subKey, idx)
}
return s.buckets[idx]
}
/*
广播消息通过循环 Bukets, 每个 bucket 有自己的锁，通过拆分锁的粒度，来减少锁的竞态，挺高性
能。
*/
func (s *server) Broadcast (ctx context. Context, req *pb. BroadcastReq)
(*pb. BroadcastReply, error) {
....
go func () {
for _, bucket := range s.srv.Buckets () {
bucket.Broadcast (req.GetProto (), req. ProtoOp)
if req. Speed > 0 {
t := bucket.ChannelCount () / int (req. Speed)
time.Sleep (time.Duration (t) * time. Second)
}
}
}()
...
}
```
```
//internal/comet/bucket. go
//每个 bucket 生成 RoutineAmount 个 Channel , 每个 Channel 由一个 roomproc 处理。
func NewBucket (c *conf. Bucket) (b *Bucket) {
b.routines = make ([]chan *pb. BroadcastRoomReq, c.RoutineAmount)
for i := uint 64 ( 0 ); i < c.RoutineAmount; i++ {
c := make (chan *pb. BroadcastRoomReq, c.RoutineSize)
b.routines[i] = c
go b.roomproc (c)
}
return
}
func (b *Bucket) roomproc (c chan *pb. BroadcastRoomReq) {
for {
arg := <-c
if room := b.Room (arg. RoomID); room != nil {
```

具体请参见配套视频里边的源码解读。

###### 高性能池化架构

在 comet 模块中，在 round (internal/comet/round. go) 中，会一次性申请足够的读缓冲和写缓存以及
定时器，通过一个空闲链表中进行维护。

每个 TCP 链接需要的时候，从这些空闲链表获得，使用完之后放回去。

对于 TCP 读 goroutine 中，每个 TCP 有一个 proto 缓冲 (ring)，通过环形数组实现。

```
room.Push (arg. Proto)
}
}
}
```
```
//将消息轮询发送到 routines 中。
func (b *Bucket) BroadcastRoom (arg *pb. BroadcastRoomReq) {
num := atomic. AddUint 64 (&b.routinesNum, 1 ) % b.c.RoutineAmount
b.routines[num] <- arg
}
```
```
//internal/comet/server. go
//NewRound 根据配置，提前申请各种数据类型，以备使用。
func NewServer (c *conf. Config) *Server {
s := &Server{
c: c,
round: NewRound (c),
rpcClient: newLogicClient (c.RPCClient),
}
...
}
//每个 tcp 连接从 round 获取一个 Timer、Reader、Writer
func serveTCP (s *Server, conn *net. TCPConn, r int) {
var (
tr = s.round.Timer (r)
rp = s.round.Reader (r)
wp = s.round.Writer (r)
...
)
s.ServeTCP (conn, rp, wp, tr)
}
```
```
//每个 tcp 连接通过 ring (internal/comet/ring. go) 生成一个 proto 类型的环形数组，用于读
取数据。
func (s *Server) ServeTCP (conn *net. TCPConn, rp, wp *bytes. Pool, tr
*xtime. Timer) {
...
var (
ch = NewChannel (s.c.Protocol. CliProto, s.c.Protocol. SvrProto) //环形数组
)
...
//读取数据过程，先从环形数组中获得一个 proto，然后将数据写入 proto
if p, err = ch.CliProto.Set (); err != nil {
break
}
```

具体请参见配套视频里边的源码解读。

#### Redis 与 Session 结构

Session 由 Redis 管理，维持了客户端 MID，Server，Key 的关系，

这部分是在 Logic 中 gRPC 服务的 Connect 方法中设置。

如下图所示：

```
if err = p.ReadTCP (rr); err != nil {
break
}
}
```
```
//internal/comet/round. go
type Round struct {
readers []bytes. Pool
writers []bytes. Pool
timers []time. Timer
options RoundOptions
}
```
```
func NewRound (c *conf. Config) (r *Round) {
....
// reader
r.readers = make ([]bytes. Pool, r.options. Reader) //生成 N 个缓存池
for i = 0 ; i < r.options. Reader; i++ {
r.readers[i]. Init (r.options. ReadBuf, r.options. ReadBufSize)
}
// writer
r.writers = make ([]bytes. Pool, r.options. Writer)
for i = 0 ; i < r.options. Writer; i++ {
r.writers[i]. Init (r.options. WriteBuf, r.options. WriteBufSize)
}
// timer
r.timers = make ([]time. Timer, r.options. Timer)
for i = 0 ; i < r.options. Timer; i++ {
r.timers[i]. Init (r.options. TimerSize)
}
...
}
```
```
// goim/internal/logic/conn. go
func (l *Logic) Connect (c context. Context, server, cookie string, token []byte)
(mid int 64, key, roomID string, accepts []int 32, hb int 64, err error) {
var params struct {
Mid int 64 `json: "mid"` // 用户 ID
Key string `json: "key"` // 客户端标识别，如果为空则自动生成 UUID
```

从 AddMapping 方法中，总结下得到：

```
RoomID string `json: "room_id"` // 客户端加入房间
Platform string `json: "platform"`// 客户端所在平台
Accepts []int 32 `json: "accepts"` // 监听房间
}
if err = json.Unmarshal (token, &params); err != nil {
log.Errorf ("json.Unmarshal (%s) error (%v)", token, err)
return
}
mid = params. Mid
roomID = params. RoomID
accepts = params. Accepts
hb = int 64 (l.c.Node. Heartbeat) * int 64 (l.c.Node. HeartbeatMax)
if key = params. Key; key == "" {
key = uuid.New (). String ()
}
if err = l.dao.AddMapping (c, mid, key, server); err != nil {
log.Errorf ("l.dao.AddMapping (%d,%s,%s) error (%v)", mid, key, server,
err)
}
log.Infof ("conn connected key:%s server:%s mid:%d token:%s", key, server,
mid, token)
return
}
```
```
// goim/internal/logic/dao/redis. go
//
func (d *Dao) AddMapping (c context. Context, mid int 64, key, server string) (err
error) {
// ...
if mid > 0 {
if err = conn.Send ("HSET", keyMidServer (mid), key, server); err != nil {
log.Errorf ("conn.Send (HSET %d,%s,%s) error (%v)", mid, server, key,
err)
return
}
if err = conn.Send ("EXPIRE", keyMidServer (mid), d.redisExpire); err !=
nil {
log.Errorf ("conn.Send (EXPIRE %d,%s,%s) error (%v)", mid, key, server,
err)
return
}
// ...
}
if err = conn.Send ("SET", keyKeyServer (key), server); err != nil {
log.Errorf ("conn.Send (HSET %d,%s,%s) error (%v)", mid, server, key, err)
return
}
if err = conn.Send ("EXPIRE", keyKeyServer (key), d.redisExpire); err != nil {
log.Errorf ("conn.Send (EXPIRE %d,%s,%s) error (%v)", mid, key, server,
err)
return
}
// ...
}
```

也就是说，同一个用户可以在多个地方同时连入系统；

同时也能看出来，Session 管理并不包括用户所在的房间，用户需要接受哪些房间的消息，这部分是在
是在 Logic. Connect 处理好了之后通过 gRPC 响应，交给 Comet 处理的。

```
如果 (mid=1, key=69 dafe 8 b 58066478 aea 48 f 3 d 0 f 384820, server=comet. 001)
mid_1 = {69 dafe 8 b 58066478 aea 48 f 3 d 0 f 384820: comet. 001}
key_69 dafe 8 b 58066478 aea 48 f 3 d 0 f 384820 = "comet. 001"
```
```
// goim/internal/comet/server_websocket. go
func (s *Server) ServeWebsocket (conn net. Conn, rp, wp *bytes. Pool, tr
*xtime. Timer) {
// ...
if p, err = ch.CliProto.Set (); err == nil {
if ch. Mid, ch. Key, rid, accepts, hb, err = s.authWebsocket (ctx, ws, p,
req.Header.Get ("Cookie")); err == nil {
ch.Watch (accepts...) // 监听房间列表
b = s.Bucket (ch. Key) // 根据用户 key 选择一个 bucket (对 key 做 cityhash 再取
模)
err = b.Put (rid, ch) // 将用户 ID 和连接 Channel 维护到 Bucket 中
if conf. Conf. Debug {
log.Infof ("websocket connnected key:%s mid:%d proto:%+v",
ch. Key, ch. Mid, p)
}
}
}
// ...
}
```
```
// auth for goim handshake with client, use rsa & aes.
func (s *Server) authWebsocket (ctx context. Context, ws *websocket. Conn, p
*grpc. Proto, cookie string) (mid int 64, key, rid string, accepts []int 32, hb
time. Duration, err error) {
for {
if err = p.ReadWebsocket (ws); err != nil {
return
}
if p.Op == grpc. OpAuth {
break
} else {
log.Errorf ("ws request operation (%d) not auth", p.Op)
}
}
// rid roomID
if mid, key, rid, accepts, hb, err = s.Connect (ctx, p, cookie); err != nil {
return
}
p.Op = grpc. OpAuthReply
p.Body = nil
if err = p.WriteWebsocket (ws); err != nil {
return
}
err = ws.Flush ()
return
}
```

#### 服务发现

服务发现可以帮助整个应用发现 Comet 单元和 Logic 单元，而 Job 单元并不需要注册自己（不需要被发
现）。

当然可以没有服务发现功能，直接在代码和配置中配置好（Comet/Logic）服务地址，但是也就失去了
动态扩容的能力。

另外，如果是 K 8 S 部署，这里的服务发现功能就有点冗余了，因此需要做一些调整再用 K 8 S 部署，调整
包括（服务注册和发现抽象即于 discovery 结耦，可选开启；

对于 Comet 的 gRPC 调用，在针对用户单发消息时，需要从定向单播变成广播。

#### GOIM 的高并发架构

一是分段架构：尽可能进行分段锁架构，的拆分锁的粒度，来减少资源竞争。

二是池化架构：在内存管理方面，通过申请一个大内存，然后拆成所需的数据类型，自己进行管理，来
减少频繁申请与销毁内存操作对性能的损耗。

三是队列缓存+批量处理异步架构：充分利用 goroutine 和 channel 实现高并发。

#### GOIM 的总结

```
GOIM 将整个应用职责，分配给三个单个独立网元来承担相应的工作，让流程更清晰，应用也易于
扩展（动态）。
在用户和长连接的映射上，使用了 Key 来区别应用用户和业务用户，得以支持单个用户同时登陆
（多平台）的场景；另外 key 也作为了 Comet 网元定位用户的唯一标识；利用了 bucket + cityhash
来降低竞争，加速用户定位并发送消息。
在房间消息的处理上，出于消息频繁和业务场景的考虑：在 Job 上为房间消息增加了数据包合并机
制；在 Comet 层为每一个 Bucket 都创建了一定数量的 goroutine 来持续处理房间消息。这两个动
作，都能提高整个应用对于房间消息处理能力，提升吞吐量。
从 Job 端将消息分发到 Comet 时，除了单个用户的消息能够指定 Comet 以外，其他的消息都只能广
播给所有的 Comet 处理。
```
#### 参考文档

官网：https://goim.io/

```
https://github.com/Terry-Mao/goim
https://juejin.im/post/5cd12fa16fb9a0320b40ec32
```
#### 说在最后：有问题可以找老架构尼恩取经

架构之路，充满了坎坷

转架构很难，按照 8020 原则， **80%的人，在这里是转不过去的** 。


这是一场竞争，哪怕走在前面半步就比较容易获取胜利，叫做 **强者愈来愈强** 。

架构和高级开发不一样，

架构的问题是 open 的，开发式的，没有标准答案的

在做架构过程中，如果遇到复杂的场景，确实不知道怎么做架构方案，

或者在转型过程中，确实找不到有底的方案，怎么办？ 可以来找 40 岁老架构尼恩求助.

上次一个小伙伴，他们要进行 **电商网站的黄金链路架构** ，开始找不到思路，但是经过尼恩 10 分钟语音
指导，一下就豁然开朗。

关于 IM 架构，后面尼恩会出一个系列的视频，帮助大家彻底掌握，从而开启自己的架构师之路。

#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》


## 大厂必面：你们系统 qps 多少，怎么部署的？

## 假设每天有几千万请求，该如何部署？

#### 前言

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，很多小伙伴要拿高薪，这就要面大厂、面架构，拿高薪。

在高级开发面试、大厂面试、架构师的面试过程中，常常会遇到下面的问题：

```
你们系统 qps 多少？怎么部署的？
假设每天有几千万请求，你的系统如何部署？
```
```
.....
```
尼恩在指导简历、指导面试的过程中，很多小伙伴，都有遇到这个问题。

**可以说是一个面试的高频题目，极致的高频题目** 。

**大家一定要把此文收藏起来，好好背熟悉，并且，在面试之前，都翻出好好复习一下** 。


40 岁老架构师尼恩，不知道做过多少架构方案。目前尼恩已经专门从事架构师转型辅导 2 年了，也不知
道指导了多少开发完成了架构师的华丽转身。现在，给大家提供一份比较全面的参考答案。使得大家可
以充分展示一下大家雄厚的 “技术肌肉”， **让你的主管、同事爱到 “不能自已、口水直流”** 。

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 94 版本，供后面的小伙伴参考，
提升大家的 3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，最新尼恩架构笔记、面试题的 PDF 文件，请关注本公众号【技术自
由圈】获取
```
#### 尴尬的面试现场：

首先，给大家复盘一下，很多小伙伴尴尬的面试现场

于是面试官和候选人可能会展开如下一系列的问题：

**面试官** ：你说说，你们项目目前有多少注册用户？

**候选人** ：这个。。。。好像大概几万？

**面试官** ：好吧，那你说一下你们系统每天日活是多少？

**候选人** ：这个。。。。还真的没统计过啊。。大概可能有几千或者几万个人？

**面试官** ：好吧，那你们的系统高峰期 QPS 有多大呢？

**候选人** ：这个。。。。也没统计过，大概 500 吧！

**面试官** ：好吧，那这样吧，假设每天几千万请求，如何进行 qps 评估？ 然后，如何进行部署架构？

**候选人** ：嗯嗯....... 这个... 我真的不知道啊。。。

**面试官** ：咦？你怎么支支吾吾的，难道你项目线上如何部署，也不清楚？

**候选人** ：............

候选人卒

接下来，咱们从基础概念入手，一步一步，给出上面的面试题答案。

#### 一、什么是 QPS？

**QPS** Queries Per Second 是每秒查询率 ,

是 **一台服务器** 每秒能够相应的查询次数，

是对一个特定的查询服务器 **在规定时间内** 所处理流量多少的衡量标准, 即每秒的响应请求数，也即是最
大吞吐能力。


#### 二、什么是 TPS？

**TPS** Transactions Per Second 也就是事务数/秒。

什么是事务？

一个事务是指一个客户机向服务器发送一起完整的开始 start 请求，内部各种 ACID 事务属性的并发数
据操作，最后提交一个 commit 操作结束整个 Transaction 的过程。

所以从上面可以看出来，一个事务包含明确的三阶段：开始，处理，commit/rollback。

一个事务的中间环节，会包含多个并行的 sql 的操作。

本质上事务是对 **多个并发操作进行数据一致性** 的管理，事务的 ACID 规则如下：

spring 框架有本身自带的事务传播性，数据库也有事务，

数据库事务包含事务的 start，数据操作，事务 commit 等非常清晰的阶段。当数据库开启事务后，当前
线程改变数据库数据，并未提交当前事务，那其他线程读数据库的时候会出现脏读，幻读。

在 web 服务器领域来说，事务可以指用户的一次完整的交互处理，这次交互处理里边，包含了多次的服
务端 api 调用。

一个 web 服务器包含包含多次 api 请求，多次 api 响应。

比如，在尼恩指导做过的《亿级数据搜索中台》中，用户执行一次搜索操作，浏览器 client 通过 vue 框
架要调用后端的上 10 个 api 接口，类似如下：


#### 三、QPS 和 TPS 的关系

1 、 **Tps** 即每秒处理事务数，从 web 应用的角度来说，包括了

1 ）用户通过 client 工具，开始发起请求

2 ）client 工具执行 N 个服务端的 API 调用

3 ）client 进行 API 结果的聚合再渲染，最后呈现给用户

这三个过程组成一个事务，每秒能够完成 N 事务，Tps 也就是 N；

2 、 **Qps** Queries Per Second 是每秒查询率，从 web 应用的角度来说，就是单次 api 的调用

Qps 基本类似于 Tps，

但是不同的是：

```
用户通过 client 工具完成一个页面的一次访问，形成一个 Tps；
如果一次页面请求，产生多次对服务器的 api 请求，这个 Tps 包含多个 qps。
如果一次页面请求，产生 1 次对服务器的 api 请求，这个 Tps 包含 1 个 qps。也就是 tps=qps
```
#### 四、什么是 RT，响应时间

响应时间：执行一个请求从开始到最后收到响应数据所花费的总体时间。

RT 即从客户端发起请求到收到服务器响应结果的时间。

响应时间 RT (Response-time)，是一个系统最重要的指标之一，它的数值大小直接反应了系统的快慢。

**单节点 QPS 公式：QPS=1000 ms/RT**

假设一个节点 RT 是 10 ms, 则可以很容易的计算出 QPS, QPS = 1000/10 = 100

对同一个分布式系统而言，支持的节点数越多，QPS 越高。

多节点场景，如果把节点提升到 2 ，那么整个系统的 QPS 则为 2*（1000/10） = 200,

可见 QPS 随着节点横向扩展、节点的增加而线性增长，

当然，那 QPS 上不去就加节点，听起来很有道理，但是往往现实并非如此，

为啥：一个请求的处理链路上受影响的环节很多，不能只解决某一层的吞吐量，而是需要所有的层都要
同步提升。

#### 五、什么是并发数？


并发数（并发度）：指系统同时能处理的请求数量，同样反应了系统的负载能力。

并发数： 系统同时处理的 request/事务数

这个是一个理论的并发数。

注意，这个并发数，和 jemeter 的并发数不一样。jmeter 中的并发数，就是同时启动的线程数

线程组设置为 100 个线程，运行过程中未出现任何异常，满足 100 个线程并发操作需求，那么并发数就
是 100

#### 六、吐吞量

系统的吞吐量（承压能力）与 request 对 CPU 的消耗、外部接口、IO 等等紧密关联。

单个 request 对 CPU 消耗越高，IO 速度越慢，那么，系统吞吐能力越低，

反之越高。

系统吞吐量几个重要参数：QPS（TPS）、并发数、响应时间。

```
1. QPS（TPS）：（Query Per Second）每秒钟 request/事务数量
2. 并发数： 系统同时处理的 request/事务数
3. 响应时间： 一般取平均响应时间
```
理解了上面三个要素的意义之后，就能推算出它们之间的关系：

#### 七：什么是 PV、UV、DAU、MAU

还有一些相关的概念

###### PV

**PV** （Page View）：页面访问量，即页面浏览量或点击量，用户每次刷新即被计算一次。

可以统计服务一天的访问日志得到。

###### UV

**UV** （Unique Visitor）：独立访客，统计 1 天内访问某站点的用户数。

可以统计服务一天的访问日志并根据用户的唯一标识去重得到。

响应时间（RT）：响应时间是指系统对请求作出响应的时间，一般取平均响应时间。

可以通过 Nginx、Apache 之类的 Web Server 得到。

###### DAU

```
并发数 = QPS*平均响应时间
```
```
QPS（TPS）= 并发数/平均响应时间
```
```
并发数 = QPS*平均响应时间
```

**DAU** （Daily Active User）：日活跃用户数量。

常用于反映网站、互联网应用或网络游戏的运营情况。

DAU 通常统计一日（统计日）之内，登录或使用了某个产品的用户数（去除重复登录的用户），与 UV
概念相似

###### MAU

**MAU** （Month Active User）：月活跃用户数量，指网站、app 等去重后的月活跃用户数量

#### 八、最佳线程数量

刚好消耗完服务器的瓶颈资源的临界线程数，公式如下

```
在尼恩《Java 高并发核心编程卷 2 加强版》一书中，对以上公式进行了细致的介绍。
```
```
无论 io 密集型线程池、cpu 密集型线程池，都满足上面的公式。
```
特性：

```
在达到最佳线程数的时候，线程数量继续递增，则 QPS 不变，而响应时间变长，持续递增线程数
量，则 QPS 开始下降。
每个系统都有其最佳线程数量，但是不同状态下，最佳线程数量是会变化的。
瓶颈资源可以是 CPU，可以是内存，可以是锁资源，IO 资源：超过最佳线程数-导致资源的竞争，
超过最佳线程数-响应时间递增。
```
#### 九、统吞吐量评估

比较关键的关键的问题来了：

```
假设你的项目的用户量有百万级，然后每天有几千万请求，高峰期每秒有好几千请求。
```
```
每个服务会有多高的 QPS？
```
那么这个时候，你的服务会有多高的 QPS？

按二八定律来看，如果每天 80% 的访问集中在 20% 的时间里，这 20% 时间就叫做峰值时间。

```
公式：( 总 PV 数 * 80% ) / ( 每天秒数 * 20% ) = 峰值时间每秒请求数 (QPS)
机器：峰值时间每秒 QPS / 单台机器的 QPS = 需要的机器
```
**1 、每天 300 w PV 的在单台机器上，这台机器需要多少 QPS？**

( 3000000 * 0.8 ) / (86400 * 0.2 ) = 139 (QPS)

**2 、如果一台机器的 QPS 是 58 ，需要几台机器来支持？**
139 / 58 = 3

#### 十、每天有几千万请求，你的系统如何部署？

```
最佳线程数量=（（线程等待时间+线程 cpu 时间）/线程 cpu 时间）* cpu 数量
```

最后的问题，也是最为关键的问题来了：

```
假设你的项目的用户量有百万级，然后每天有几千万请求，高峰期每秒有好几千请求。
```
```
你的系统如何部署？
```
那么这个时候，每个服务需要部署多少台机器才可以保证不雪崩？ 这些服务器的配置是多高？

项目中涉及的 MySQL、Redis、ES、RocketMQ 中间件，的如何做 **高并发架构？**

项目中涉及的 MySQL、Redis、ES、RocketMQ 中间件，的如何做 **高可用架构？**

以上组件的架构方案，可以参照尼恩的《价值 10 W 架构师知识图谱》，

在《价值 10 W 架构师知识图谱》里边，有 MySQL、Redis、ES、RocketMQ、Nginx 等中间件的核心吞
吐量性能指标，然后再结合自己的项目，简单的规划一下，就可以了。

```
注意，这里没有标准答案。一定要再结合自己的项目去规划，
```
```
其实，只要简单的规划一下，就可以了。
可以参照《价值 10 W 架构师知识图谱》，一路从网关接入层，进入到服务层、缓存、DB 层、消
峰解耦层等等，一层一层的进行系统的部署架构。
```
《价值 10 W 架构师知识图谱》是一个庞大的架构师的 **知识地图** ，具体的链接，可以找尼恩获取。

#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》


## 字节二面：10 Wqps 会员系统，如何设计？

#### 说在前面

在尼恩的（50+）读者社群中，经常遇到一个非常、非常高频的一个面试题，但是很不好回答，类似如
下：

```
千万级数据，如何做系统架构？
亿级数据，如何做系统架构？
千万级流量，如何做系统架构？
亿级流量，如何做系统架构？
高并发系统，如何架构？
```
**最近，有个小伙伴字节二面，又遇到了这个问题。**

其实，尼恩一直想梳理一个教科书式的答案，

咱们一直心心念念的 “千万级数据，如何做性能优化？” 的教科书式的答案，其实就藏着在这个行业案例
里边。


这里有一个新的行业案例《同程艺龙会员系统的高并发架构》，尼恩从面试维度，对这个方案，进行二
次重构和梳理，现在把其作为参考答案，收入咱们的《尼恩 Java 面试宝典 PDF》 V 96 版本

下面的内容，是尼恩是结合自己的 3 高架构笔记，以及尼恩的 3 高架构知识体系（ 3 高架构宇宙）做的二
次分析。

#### 同程艺龙会员系统的业务场景

同程艺龙是同程旅游集团旗下的同程网络与艺龙旅行网在 2017 年 12 月 29 日共同成立的公司，新公司将
整合双方的交通、酒店等优势资源，打造更为领先的旅行服务平台。

2018 年 6 月 21 日，同程艺龙在港交所提交招股书，联席保荐人为摩根士丹利、摩根大通、招银国际。

2018 年 11 月 26 日，同程艺龙正式在港交所挂牌。

同程艺龙为机场、酒店、目的地等旅行行业产业链上下游提供技术赋能，加速产业数智化进程。终端用
户应用包括：

```
同程 APP
艺龙 APP
同程微信小程序
艺龙微信小程序
```
2021 年第三季度，同程艺龙平均月活达到 2.77 亿人，同比增长 12.7%；平均月付费用户达到 3360 万
人，同比增长 12.8%。

截至 2021 年 9 月 30 日的 12 个月里，同程艺龙付费用户同比增加 29.6%至 1.96 亿人。

在同程艺龙内部，会员系统是一种 **基础系统** 。

这种基础系统，跟公司所有业务线的下单主流程密切相关。

在同程艺龙平台的内部，如果会员系统出故障，会导致用户无法下单。

也就是说，如果会员系统出故障，影响范围不仅仅是会员系统本身，而是全公司所有业务线。

所以，会员系统必须保证高性能、高可用、高并发，为大的业务平台，提供稳定、高效的基础服务。

随着同程和艺龙两家公司的合并，越来越多的系统需要打通同程 APP、艺龙 APP、同程微信小程序、艺
龙微信小程序等多平台会员体系。

例如微信小程序的交叉营销，用户买了一张火车票，此时想给他发酒店红包，这就需要查询该用户的统
一会员关系。

因为火车票用的是同程会员体系，酒店用的是艺龙会员体系，只有查到对应的艺龙会员卡号后，才能将
红包挂载到该会员账号。

除了了交叉营销场景之外，还有许多、许多的业务场景需要查询统一会员关系。

例如订单中心、会员等级、里程、红包、常旅、实名，以及各类营销活动等等。

所以，会员系统的请求量越来越大，并发量越来越高。

2022 年五一小长假的秒并发 TPS 甚至超过 2 万多。

在如此大流量的冲击下，会员系统是如何做到高性能和高可用的呢？

#### 会员数据异构存储架构方案

同程艺龙内部，会员系统采用的是 mysql 集群+ES 集群结合的异构存储架构


具体如下图所示

```
1. 为什么使用 mysql
目前最火的关系型数据库，支持事务，支持 B+树结构高性能索引，数据低延迟（写入即可查）
但是有两大缺点：
（ 1 ）不宜全文搜索，如果非索引全文搜索，会出现全表搜索，性能低
（ 2 ）使用 mysql 需要分库分表，这种时候，没法做全表关联
2. 为什么使用 elsaticsearch
es 在搜索方面天生具有优势，
（ 1 ）倒排索引，天生的全文检索
（ 2 ）支持大表、宽表、非结构数据。不像关系型数据库那样一个简单的搜索就需要跨表联
表、跨库关联
3. mysql+elasticsearch 的好处
以 mysql 存取数据，es 作为搜索引擎，保证性能
```
#### MySQL 会员主库的：高可用+高并发架构

上述讲到，全平台会员的绑定关系数据存在 ES，而会员的注册明细数据存在关系型数据库。

最早，会员使用的数据库是 SQL Server，

直到有一天，单台 SQL Server 数据库已经存储了十多亿的会员数据，服务器已达到物理极限，不能再扩
展了。

按照当然的增长趋势，过不了多久，整个 SQL Server 数据库就崩了。

大家想想，SQL Server 数据库崩了，那是一种什么样的灾难场景：

```
会员数据库崩了，会员系统就崩了；
会员系统崩了，全公司所有业务线就崩了。
```
想想就不寒而栗，酸爽无比，同城艺龙团队立刻开启了迁移 DB 的工作。


###### MySQL 双中心 Partition 集群方案

经过调研，团队选择了双中心分库分表的 MySQL 集群方案，

###### mysql 分表架构

会员一共有十多亿的数据，团队把会员主库分了 1000 多个分片。

从单个分片的维度来说，平分到 **每个分片大概百万的量级** ，单个分片不到千万级，足够使用了。

###### mysql 主从架构

整个 MySQL 集群采用 1 主 3 从的架构。

主库放在机房 A，从库放在机房 B，两个机房之间通过专线同步数据，延迟在 1 毫秒内。

###### mysql 流量路由架构

```
写入的路由：写数据都路由到 master 节点所在的机房 A，
读取的路由：读数据都路由到本地机房，就近访问，减少网络延迟。
```
会员系统通过 DBRoute 读写数据，DBRoute 是一个统一的数据库访问 sdk 组件，可以根据流量开关，
进行流量的切流。

具体的架构图，如下图所示：


这样，采用双中心的 MySQL 集群架构，极大提高了可用性，即使机房 A 整体都崩了，还可以将机房 B 的
Slave 升级为 Master，继续提供服务。

双中心 MySQL 集群搭建好后，团队进行了压测，测试下来，秒并发能达到 2 万多，平均耗时在 10 毫秒
内，性能达标。

###### 会员主库平滑迁移方案

接下来的工作，就是把会员系统的底层存储从 SQL Server 切到 MySQL 上，这是个风险极高的工作，主
要有以下几个难点：

```
会员系统是一刻都不能停机的，要在不停机的情况下完成 SQL Server 到 MySQL 的切换，就像是在
给高速行驶的汽车换轮子。
会员系统是由很多个系统和接口组成的，毕竟发展了 10 多年，由于历史原因，遗留了大量老接
口，逻辑错综复杂。这么多系统，必须一个不落的全部梳理清楚，DAL 层代码必须重写，而且不能
出任何问题，否则将是灾难性的。
数据的迁移要做到无缝迁移，不仅是存量 10 多亿数据的迁移，实时产生的数据也要无缝同步到
MySQL。另外，除了要保障数据同步的实时性，还要保证数据的正确性，以及 SQL Server 和
MySQL 数据的一致性。
```
基于以上痛点，团队设计了“ **全量同步、增量同步、实时流量灰度切换** ”的技术方案。

首先，为了保证数据的无缝切换，采用实时双写的方案。

因为业务逻辑的复杂，以及 SQL Server 和 MySQL 的技术差异性，在双写 MySQL 的过程中，不一定会写
成功，而一旦写失败，就会导致 SQL Server 和 MySQL 的数据不一致，这是绝不允许的。

所以，团队采取的策略是，在试运行期间，主写 SQL Server，然后通过线程池异步写 MySQL，

如果写失败了， **重试三次，如果依然失败，则记日志，然后人工排查原因，解决后，继续双写** ，直到运
行一段时间，没有双写失败的情况。


通过上述策略，可以确保在绝大部分情况下，双写操作的正确性和稳定性，即使在试运行期间出现了
SQL Server 和 MySQL 的数据不一致的情况，也可以基于 SQL Server 再次全量构建出 MySQL 的数据，因
为团队在设计双写策略时，会确保 SQL Server 一定能写成功，也就是说，SQL Server 中的数据是全量最
完整、最正确的。

如下图所示：

讲完了双写，接下来团队看一下“读数据”如何灰度。

整体思路是，通过 A/B 平台逐步灰度流量，刚开始 100%的流量读取 SQL Server 数据库，然后逐步切流量
读取 MySQL 数据库，先 1%，如果没有问题，再逐步放流量，最终 100%的流量都走 MySQL 数据库。

在逐步灰度流量的过程中，需要有验证机制，只有验证没问题了，才能进一步放大流量。

那么这个验证机制如何实施呢？

方案是，在一次查询请求里，通过异步线程，比较 SQL Server 和 MySQL 的查询结果是否一致，如果不
一致，记日志，再人工检查不一致的原因，直到彻底解决不一致的问题后，再逐步灰度流量。

如下图所示：


所以，整体的实施流程如下：

首先，在一个夜黑风高的深夜，流量最小的时候，完成 SQL Server 到 MySQL 数据库的全量数据同步。

接着，开启双写，

此时，如果有用户注册，就会实时双写到两个数据库。

那么，在全量同步和实时双写开启之间，两个数据库还相差这段时间的数据，所以需要再次增量同步，
把数据补充完整，以防数据的不一致。

剩下的时间，就是各种日志监控，看双写是否有问题，看数据比对是否一致等等。

这段时间是耗时最长的，也是最容易发生问题的，

如果有的问题比较严重，导致数据不一致了，就需要从头再来，

再次基于 SQL Server 全量构建 MySQL 数据库，然后重新灰度流量，直到最后，100%的流量全部灰度到
MySQL，此时就大功告成了，下线灰度逻辑，所有读写都切到 MySQL 集群。

###### MySQL 和 ES 主备集群方案

做到这一步，感觉会员主库应该没问题了，可 dal 组件的一次严重故障改变了团队的想法。

那次故障很恐怖，公司很多应用连接不上数据库了，创单量直线往下掉，

这让团队意识到，即使数据库是好的，但 dal 组件异常，依然能让会员系统挂掉。

所以，团队再次异构了会员主库的数据源，双写数据到 ES，如下所示：

如果 dal 组件故障或 MySQL 数据库挂了，可以把读写切到 ES，

等 MySQL 恢复了，再把数据同步到 MySQL，最后把读写再切回到 MySQL 数据库。

如下图所示：


#### ES 高可用方案

###### ES 双中心主备集群架构

同程和艺龙两家公司融合后，全平台所有体系的会员总量是十多亿。

在这么大的数据体量下，业务线的查询维度也比较复杂。

有的业务线基于手机号，有的基于微信 unionid，也有的基于艺龙卡号等查询会员信息。

这么大的数据量，又有这么多的查询维度，基于此，团队选择 ES 用来存储统一会员关系。

ES 集群在整个会员系统架构中非常重要，那么如何保证 ES 的高可用呢？

首先团队知道，ES 集群本身就是保证高可用的，如下图所示：


当 ES 集群有一个节点宕机了，会将其他节点对应的 Replica Shard 升级为 Primary Shard，继续提供服
务。

但即使是这样，还远远不够。

例如 ES 集群都部署在机房 A，现在机房 A 突然断电了，怎么办？

例如服务器硬件故障，ES 集群大部分机器宕机了，怎么办？

或者突然有个非常热门的抢购秒杀活动，带来了一波非常大的流量，直接把 ES 集群打死了，怎么办？

面对这些情况，让运维兄弟冲到机房去解决？

这个非常不现实，因为会员系统直接影响全公司所有业务线的下单主流程，故障恢复的时间必须非常
短，如果需要运维兄弟人工介入，那这个时间就太长了，是绝对不能容忍的。

那 ES 的高可用如何做呢？

团队的方案是 ES 双中心主备集群架构。


团队有两个机房，分别是机房 A 和机房 B。

团队把 ES 主集群部署在机房 A，把 ES 备集群部署在机房 B。

会员系统的读写都在 ES 主集群，通过 MQ 将数据同步到 ES 备集群。

此时，如果 ES 主集群崩了，通过统一配置，将会员系统的读写切到机房 B 的 ES 备集群上，这样即使 ES 主
集群挂了，也能在很短的时间内实现故障转移，确保会员系统的稳定运行。

最后，等 ES 主集群故障恢复后，打开开关，将故障期间的数据同步到 ES 主集群，等数据同步一致后，再
将会员系统的读写切到 ES 主集群。

如下图所示：

###### ES 流量隔离三集群架构

双中心 ES 主备集群做到这一步，感觉应该没啥大问题了，但去年的一次恐怖流量冲击让团队改变了想
法。

那是一个节假日，某个业务上线了一个营销活动，

在用户的一次请求中，循环 10 多次调用了会员系统，导致会员系统的 TPS 暴涨，差点把 ES 集群打爆。


这件事让团队后怕不已，它让团队意识到，一定要对调用方进行优先级分类，实施更精细的隔离、熔
断、降级、限流策略。

首先，团队梳理了所有调用方，分出两大类请求类型。

第一类是跟用户的下单主流程密切相关的请求，这类请求非常重要，应该高优先级保障。

第二类是营销活动相关的，这类请求有个特点，他们的请求量很大，TPS 很高，但不影响下单主流程。

基于此，团队又构建了一个 ES 集群，专门用来应对高 TPS 的营销秒杀类请求，这样就跟 ES 主集群隔离开
来，不会因为某个营销活动的流量冲击而影响用户的下单主流程。如下图所示：

###### ES 集群深度优化提升

讲完了 ES 的双中心主备集群高可用架构，接下来团队深入讲解一下 ES 主集群的优化工作。

有一段时间，团队特别痛苦，就是每到饭点，ES 集群就开始报警，搞得每次吃饭都心慌慌的，生怕 ES 集
群一个扛不住，就全公司炸锅了。

那为什么一到饭点就报警呢？

因为流量比较大，导致 ES 线程数飙高，CPU 直往上窜，查询耗时增加，并传导给所有调用方，导致更大
范围的延时。

那么如何解决这个问题呢？

通过深入 ES 集群，团队发现了以下几个问题：

```
ES 负载不合理，热点问题严重。ES 主集群一共有几十个节点，有的节点上部署的 shard 数偏多，有
的节点部署的 shard 数很少，导致某些服务器的负载很高，每到流量高峰期，就经常预警。
ES 线程池的大小设置得太高，导致 CPU 飙高。团队知道，设置 ES 的 threadpool，一般将线程数设
置为服务器的 CPU 核数，即使 ES 的查询压力很大，需要增加线程数，那最好也不要超过“cpu core
* 3 / 2 + 1”。如果设置的线程数过多，会导致 CPU 在多个线程上下文之间频繁来回切换，浪费大量
CPU 资源。
shard 分配的内存太大，100 G，导致查询变慢。团队知道，ES 的索引要合理分配 shard 数，要控制
一个 shard 的内存大小在 50 G 以内。如果一个 shard 分配的内存过大，会导致查询变慢，耗时增
加，严重拖累性能。
string 类型的字段设置了双字段，既是 text，又是 keyword，导致存储容量增大了一倍。会员信息
的查询不需要关联度打分，直接根据 keyword 查询就行，所以完全可以将 text 字段去掉，这样就能
节省很大一部分存储空间，提升性能。
```

```
ES 查询，使用 filter，不使用 query。因为 query 会对搜索结果进行相关度算分，比较耗 CPU，而会
员信息的查询是不需要算分的，这部分的性能损耗完全可以避免。
节约 ES 算力，将 ES 的搜索结果排序放在会员系统的 JVM 内存中进行。
增加 routing key。团队知道，一次 ES 查询，会将请求分发给所有 shard，等所有 shard 返回结果后
再聚合数据，最后将结果返回给调用方。如果团队事先已经知道数据分布在哪些 shard 上，那么就
可以减少大量不必要的请求，提升查询性能。
```
经过以上优化，成果非常显著，ES 集群的 CPU 大幅下降，查询性能大幅提升。ES 集群的 CPU 使用率：

会员系统的接口耗时：


#### 会员 Redis 缓存方案

一直以来，会员系统是不做缓存的，原因主要有两个：

```
第一个，前面讲的 ES 集群性能很好，秒并发 3 万多， 99 百分位耗时 5 毫秒左右，已经足够应付各种
棘手的场景。
第二个，有的业务对会员的绑定关系要求实时一致，而会员是一个发展了 10 多年的老系统，是一
个由好多接口、好多系统组成的分布式系统。
```
所以，只要有一个接口没有考虑到位，没有及时去更新缓存，就会导致脏数据，进而引发数据不一致的
问题，

例如：

```
用户在 APP 上看不到微信订单
APP 和微信的会员等级、里程等没合并
微信和 APP 无法交叉营销等等。
```
那后来为什么又要做缓存呢？


是因为今年机票的盲盒活动，它带来的瞬时并发太高了。

虽然会员系统安然无恙，但还是有点心有余悸，稳妥起见，最终还是决定实施缓存方案。

**ES 近一秒延时导致的 Redis 缓存数据不一致问题的解决方案**

在做会员缓存方案的过程中，遇到一个 ES 引发的问题，该问题会导致缓存数据的不一致。

团队知道，ES 操作数据是近实时的，往 ES 新增一个 Document，此时立即去查，是查不到的，需要等待
1 秒后才能查询到。

如下图所示：

ES 的近实时机制为什么会导致 Redis 缓存数据不一致呢？

具体来讲，假设一个用户注销了自己的 APP 账号，此时需要更新 ES，删除 APP 账号和微信账号的绑定关
系。

而 ES 的数据更新是近实时的，也就是说， 1 秒后你才能查询到更新后的数据。

而就在这 1 秒内，有个请求来查询该用户的会员绑定关系，它先到 Redis 缓存中查，发现没有，然后到 ES
查，查到了，但查到的是更新前的旧数据。

最后，该请求把查询到的旧数据更新到 Redis 缓存并返回。

就这样， 1 秒后，ES 中该用户的会员数据更新了，但 Redis 缓存的数据还是旧数据，导致了 Redis 缓存跟
ES 的数据不一致。如下图所示：


面对该问题，如何解决呢？

团队的思路是，在更新 ES 数据时，加一个 2 秒的 Redis 分布式并发锁，为了保证缓存数据的一致性，接着
再删除 Redis 中该会员的缓存数据。

如果此时有请求来查询数据，先获取分布式锁，发现该会员 ID 已经上锁了，说明 ES 刚刚更新的数据尚未
生效，那么此时查询完数据后就不更新 Redis 缓存了，直接返回，这样就避免了缓存数据的不一致问
题。

如下图所示：

上述方案，乍一看似乎没什么问题了，但仔细分析，还是有可能导致缓存数据的不一致。

例如，在更新请求加分布式锁之前，恰好有一个查询请求获取分布式锁，而此时是没有锁的，所以它可
以继续更新缓存。

但就在他更新缓存之前，线程 block 了，此时更新请求来了，加了分布式锁，并删除了缓存。当更新请
求完成操作后，查询请求的线程活过来了，此时它再执行更新缓存，就把脏数据写到缓存中了。

发现没有？主要的问题症结就在于“删除缓存”和“更新缓存”发生了并发冲突，只要将它们互斥，就能解
决问题。

如下图所示：


实施了缓存方案后，经统计，缓存命中率 90%+，极大缓解了 ES 的压力，会员系统整体性能得到了很大
提升。

###### Redis 双中心多集群架构

接下来，团队看一下如何保障 Redis 集群的高可用。

如下图所示：

关于 Redis 集群的高可用，团队采用了双中心多集群的模式。

在机房 A 和机房 B 各部署一套 Redis 集群。

更新缓存数据时，双写，只有两个机房的 Redis 集群都写成功了，才返回成功。

查询缓存数据时，机房内就近查询，降低延时。

这样，即使机房 A 整体故障，机房 B 还能提供完整的会员服务。

#### 展望：更精细化的流控和降级策略

任何一个系统，都不能保证百分之一百不出问题，所以团队要有面向失败的设计，那就是更精细化的流
控和降级策略。

###### 更精细化的流控策略

```
热点控制。针对黑产刷单的场景，同一个会员 id 会有大量重复的请求，形成热点账号，当这些账号
的访问超过设定阈值时，实施限流策略。
基于调用账号的流控规则。这个策略主要是防止调用方的代码 bug 导致的大流量。例如，调用方在
一次用户请求中，循环很多次来调用会员接口，导致会员系统流量暴增很多倍。所以，要针对每个
调用账号设置流控规则，当超过阈值时，实施限流策略。
全局流控规则。团队会员系统能抗下 TPS 3 万多的秒并发请求量，如果此时，有个很恐怖的流量打
过来，TPS 高达 10 万，与其让这波流量把会员数据库、ES 全部打死，还不如把超过会员系统承受范
围之外的流量快速失败，至少 TPS 3 万内的会员请求能正常响应，不会让整个会员系统全部崩溃。
```

###### 更精细化的降级策略

```
基于平均响应时间的降级。会员接口也有依赖其他接口，当调用其他接口的平均响应时间超过阈
值，进入准降级状态。如果接下来 1 s 内进入的请求，它们的平均响应时间都持续超过阈值，那么
在接下的时间窗口内，自动地熔断。
基于异常数和异常比例的降级。当会员接口依赖的其他接口发生异常，如果 1 分钟内的异常数超过
阈值，或者每秒异常总数占通过量的比值超过阈值，进入降级状态，在接下的时间窗口之内，自动
熔断。
```
目前，团队最大的痛点是会员调用账号的治理。公司内，想要调用会员接口，必须申请一个调用账号，
团队会记录该账号的使用场景，并设置流控、降级策略的规则。

但在实际使用的过程中，申请了该账号的同事，可能异动到其他部门了，此时他可能也会调用会员系
统，为了省事，他不会再次申请会员账号，而是直接沿用以前的账号过来调用，这导致团队无法判断一
个会员账号的具体使用场景是什么，也就无法实施更精细的流控和降级策略。所以，接下来，团队将会
对所有调用账号进行一个个的梳理，这是个非常庞大且繁琐的工作，但无路如何，硬着头皮也要做好。

#### 33 章视频：10 Wqps 高并发 Netty 网关架构与实操

本文内容，尼恩会放到《 33 章：10 Wqps 高并发 Netty 网关架构与实操》项目介绍。

并且提供配套的简历模板，帮助大家进行简历的亮点重建和升级，最终帮助大家进大厂、做架构、拿高
薪。

#### 所以，以上才是“教科书式” 答案

结合 B 站的方案，大家回到前面的面试题：

```
千万级数据，如何做系统架构？
亿级数据，如何做做系统架构？
千万级流量，如何做系统架构？
亿级流量，如何做做系统架构？
高并发系统，如何架构？
```

以上的方案，才是完美的答案，才是“教科书式” 答案。

后续，尼恩会给大家结合行业案例，分析出更多，更加劲爆的答案。

当然，如果遇到这类问题，可以找尼恩求助。

#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》


## 亿级短视频，如何架构？

#### 说在前面

在尼恩的（50+）读者社群中，经常指导大家面试架构，拿高端 offer。

前几天，指导一个年薪 100 W 小伙伴，拿到字节面试邀请。

遇到一个非常、非常高频的一个面试题，但是很不好回答，类似如下：

```
短视频系统，如何做系统架构？
短视频 APP，如何做系统架构？
```
**最近，有个网易二面，又遇到了这个问题。**

其实，尼恩一直想梳理一个教科书式的答案，

这里有一个新的行业案例《字节跳动亿级视频处理系统高可用架构实践》，尼恩从面试维度，对这个方
案，进行二次重构和梳理，现在把其做为参考答案，收入咱们的《尼恩 Java 面试宝典 PDF》 V 97 版本

下面的内容，是尼恩是结合自己的 3 高架构笔记，以及尼恩的 3 高架构知识体系（ 3 高架构宇宙）做的二
次分析。


#### 短视频系统（如 TikTok、Instagram Reel、YouTube

#### Shorts）的宏观业务架构

以短视频点播为代表的流媒体技术应用在移动互联网时代实现了快速扩张。

现在，短视频内容已成为新趋势，每个人都在从 TikTok、Instagram、YouTube 等平台上消费这些内
容。让我们看看如何为 TikTok 创建一个系统。

在互联网内容趋于多元化的今天，短视频迅速替代了传统的文字图片，席卷了人们的视野和生活，成为
信息传播的重要渠道。

这样的应用程序看起来很小，但在后台有很多事情正在进行。

以下是相关的挑战：

```
由于该应用程序在全球范围内使用，将会有大量的请求发送到服务器。这最终会增加服务器的负
载。
将视频上传到后台将是一个巨大的任务，这将增加服务器的负载并阻塞。
流畅地播放视频，无缓冲。
一个基于用户兴趣推荐视频的推荐系统。
```
让我们逐一了解每个部分。我将其分为三个部分：

```
与用户相关的子系统
与视频发布相关的子系统
与点赞和评论相关的子系统
推荐子系统
```
###### 1 ）与用户相关的子系统

这是一个包含与用户相关服务的服务，如下所示：

```
注册： 用户将在应用程序中注册。
登录： 它将对凭证进行身份验证，并向应用程序发送响应。
登出： 用户将从应用程序中注销。
关注： 如果用户想要关注或取消关注其他用户，则可以通过此服务完成。
```
为了存储与用户相关的数据，我们将使用基于 SQL 的数据库，如 **MYSQL** 或 **PostgreSQL** ，因为与用户相
关的数据（例如追踪关注者）将会是关联数据，所以这是一个适当的选择。

为了优化数据库性能，我们将使用主从架构。主数据库用于执行写操作，从数据库用于执行读操作。要
了解有关此内容的更多信息，可以阅读文章 **如何优化数据库性能并扩展它** ？[3]

现在让我们讨论用户服务的流程。应用程序将发出 API 调用，API Gateway 将管理这些 API。

它将为用户服务路由请求。

请求将通过负载均衡器进行，负载均衡器下将有多个用户服务实例。


根据负载，它将决定哪个实例将处理请求。

一旦请求被处理，负载均衡器将将响应发送回 API 网关，然后再发送回应用程序。

###### 2 ）与视频发布相关的子系统

一般包含视频上传、存储、处理、播放等流程及相应的流程管理与审核。

核心的操作如下所示：

```
上传视频： 将视频上传到后台服务器。
发布： 如果用户想要创建、编辑或删除帖子，则可以通过此服务完成。
```
与视频发布相关的子系统的技术要点：

```
如何安全可靠地存储 PB 级海量数据，并实现视频数据的快速存取；
如何支持多种场景下的视频上传；
如何保障稳定流畅的拉流播放；
以及如何满足视频转码、水印等基本处理需求都成为构建一个视频点播平台需要考虑和解决的技术
难题。
```
核心的核心，就是短视频的存储。

为了存储与帖子相关的数据，我们将使用基于 NoSQL 的数据库，如 **MiniO** 。

对于每个用户，可能会有成千上万的帖子，这将导致大量数据。

为了实现最佳性能，扩展数据库可能会很困难。NoSQL 数据库支持水平分片，这有助于我们在不影响性
能的情况下扩展数据库。

现在让我们讨论视频服务的流程。

应用程序将发出 API 调用，API Gateway 将管理这些 API。它将为视频服务路由请求。


请求将通过负载均衡器进行，负载均衡器下将有多个视频服务实例。

根据负载，它将决定哪个实例将处理请求。一旦请求被处理，负载均衡器将将响应发送回 API 网关，然
后再发送回应用程序。

**如何使文件在全球范围内可访问而不增加下载时间？**

视频文件将上传到 NOSQL，如 MiniO。

现在，如果我们想在世界范围内任何地方访问文件而没有任何延迟，那么该文件将发送到 **内容分发网络
(CDN)** ，它将将媒体文件更新到世界各地的不同数据云存储中。

**我们能进一步优化以减少下载时间吗？**

还有一个挑战需要解决，即原始视频的大小可能较大，因此如果将大文件发送回客户端，则下载时间会
更长，这会影响用户体验。

文件一旦上传到云存储，您可以在数据库中存储文件路径。

然后将帖子/视频详细信息发送到 **消息队列系统** ，如 **Kafka** 或 **RockerMq** 。

为了使用户体验流畅，我们需要压缩视频并为不同设备创建不同分辨率的视频。

视频处理工作者将从 **消息队列系统** 接收视频详细信息，然后从

云存储中提取文件并进行处理。处理完成后，这些新的视频文件将发送到 **CDN** 。

**如何访问压缩的视频文件？**

现在您可能会想，应用程序如何知道上述讨论中压缩的视频的文件路径？由于压缩文件将存储在分类文
件夹中，因此可以根据分辨率和文件名轻松查找文件。

视频发布 API 只会返回文件名，而要访问文件，应用程序将在 URL 本身中添加分辨率细节，例
如/media//mediaID/xxxx。

当访问此 URL 时，它将经过 API 网关，并从 URL 中提取分辨率和文件名详细信息。

然后它将在缓存系统（Redis） **中检查，如果文件不可用，则将访问 CDN** 并通过它获取文件。然后将其
添加到缓存中，以便如果再次请求相同文件，则不必从 **CDN** 获取。

###### 3 ）点赞和评论相关子系统

这是一个包含与视频点赞和评论相关服务的服务。正如名称所示，通过此服务，我们可以为特定帖子更
新点赞和评论。与上面讨论的其他流程相同。

###### 4 ）推荐子系统

通过此服务，基于用户偏好推荐一系列帖子。幕后有很多其他事情正在进行。让我们看看幕后运行的流
程。


然后，创建一个帖子后，它将被发送到 **消息队列系统** ，然后消费者将提取数据并将数据更新到 **大数据
（Hadoop）** 中。

将为机器学习服务（如 **PyTorch** 和 **Tensorflow** ）设置单独的服务器，在这里它将从大数据中提取数据
并训练模型。

推荐服务将使用此 AI 模型为给定用户推荐帖子。

#### 技术选型：常见的 NOSQL 存储框架选型

当前存储从逻辑上一般可分为三类，即块存储、文件存储和对象存储。

```
块存储一般指常见的卷或硬盘存储，以及相应的磁盘阵列、NAS、SAN 等存储方式，操作对象是磁
盘，使用逻辑块编号寻址，数据按字节方式访问，读写速度快。
文件存储则将数据以不同应用程序要求的结构方式组成不同类型的文件，可对文件进行创建、查
找、修改、删除等操作，易于实现数据共享。
对象存储将文件以对象的方式进行存储（一个对象包含属性以及内容），通常实现方式为多台分布
式服务器内置大容量硬盘，通过对象存储软件组建集群，对外提供读写访问功能。
```
业内较为主流的开源存储框架 MinIO、Ceph、SeaweedFS，从开源协议、扩展性、成本等多方面进行
对比如下表：


由于对象存储结合了块存储读写效率快、存储空间可扩展以及文件存储方便共享的优点，同时结合短视
频平台数据存储与视频点播需求，建议选取对象存储框架作为短视频点播平台的存储逻辑。

进一步考虑到短视频点播平台数据规模、存储动态不宕机扩容、在线 HTTP 多媒体播放以及学习运维成
本等需求，通过以上对比，建议选用 MinIO 开源框架作为短视频存储与点播基础框架。

###### 重点介绍：MinIO 对象存储框架

对象存储的出现是为解决了存储海量大数据的问题，如存储海量的视频、图片，并进行数据归档、数据
备份、大数据分析等操作。

对象存储一般采用 key-object 的扁平化存储架构，使用方便，调用 API 就可进行数据的多样化读写。其大
容量、动态扩展、数据灾备等性能，是传统文件存储和 NAS 无法比拟的。

MinIO 是一套基于 Apache License V 2.0 协议的轻量级、高性能开源对象存储框架，适用于图片、视频、
镜像等海量非结构化数据存储。

MinIO 采用 Golang 实现，客户端支持 Java、Python、JavaScript、Golang 语言，兼容亚马逊 S 3 云存储服
务接口，方便与其他应用结合。

**1 ）存储机制**

MinIO 使用纠删码（erasure code）和校验和（checksum）来保护数据免受硬件故障和无声数据损
坏，可保证 N/2 节点损坏的情况下数据的正常访问。

**2 ）扩展性**

极简性和扩展性是 MinIO 集群的两个重要设计理念。

MinIO 支持对等扩容和联邦扩容两种扩容方式。对等扩容，即通过增加对等的集群节点和磁盘以扩充集
群，例如，原集群包含 4 个节点 4 块磁盘，则扩容时可同样增加 4 个节点 4 个磁盘（或其倍数），以此保证
系统可维持相同的数据冗余 SLA，降低扩展的复杂性。

联邦扩容，其基本原理是引入 etcd 作为统一命名空间，将多个 MinIO 集群组成一个联邦，可在原有联邦
的基础上，向联邦中增加新集群，此扩容方式理论可实现无限扩展，且可以实现在原联邦服务不中断的
情况下扩容。

**3 ）对外服务**


MinIO 完全兼容 S 3 标准接口，客户端和服务端之间通过 http/https 进行通信。MinIO 提供客户端
mc（MinIO Client）以支持 UNIX 命令，同时支持多语言的客户端 SDK。此外，其存储后端除使用磁盘
外，还可通过网关对接其他存储系统与资源。具体如下表所示。

**4 ）多媒体拉流支持**

MinIO 对于多媒体文件，支持 HTTP-Range 的方式在线拉流播放与音视频进度条拖拽。

如下图，使用浏览器以流的形式访问存储于 MinIO 的多媒体文件时，每拖动一次进度条，则会向 MinIO
服务端发送一条 Http-Request 请求，请求 Headers 中包含 Range 字段，其内容是当前请求视频进度的开
始字节数及缓存结束字节数。

这种形式使 MinIO 天生支持多媒体文件的拉流播放与进度拖拽。

图 MinIO 多媒体在线播放支持

#### 基于 MinIO 实现简单的短视频系统


出于集群存储可动态扩展性、支持 HTTP 流式播放、运营成本等因素，

建议使用 MinIO 对象存储作为底层存储，开发部署短视频点播地址映射、地址动态代理等服务，实现一
套短视频存储点播平台。

其实现框架如下图：

图基于 MinIO 的短视频点播平台架构

点播平台大致可分为存储层、服务层与应用层。

```
存储层主要部署 MinIO 对象存储系统及关系数据库，MinIO 用来存储视频对象，关系数据库用来存
储视频元数据；
服务层提供各类存储访问服务接口，如文件上传下载、视频播放地址生成、对象地址映射等；
应用层为前端提供应用功能，包括视频上传、查询、播放等功能。
```
基于 MinIO 对象存储的点播平台数据访问流程如下图所示：

图基于 MinIO 的短视频点播平台数据访问流程图

###### 1 ）视频上传与转码


统一采用 mp 4 格式作为视频存储和点播格式，为了兼容多种格式视频文件上传，需开发转码模块将其转
码成 mp 4 格式进行存储，将其首先存入本地磁盘缓存。

###### 2 ）直播录制

在直播的过程中开启录制，将录制的文件首先存入本地磁盘缓存。

###### 3 ）上传文件

视频转码完成或录制完成后，调用 MinIO 文件上传接口，将视频文件上传至 MinIO 集群/联邦，由 etcd 对
MinIO 集群提供注册发现服务。

###### 4 ）点播地址映射

服务端部署点播地址映射服务模块，实现 MinIO 视频点播地址与视频 ID 的映射，使存储介质的改变不影
响视频点播拉流。

###### 5 ）地址动态代理服务

出于系统安全性考虑，我们不希望暴露 MinIO 存储地址与存储细节，希望增加一层网关进行媒体流的转
发或地址的代理，对外提供统一的服务地址，使用地址动态代理，可以根据点播请求的视频 ID 不同，动
态代理至不同的视频播放地址，实现视频存储细节与服务地址的解耦。

###### 6 ）拉流播放

客户端或浏览器使用 HTTP 协议流式拉取视频文件并播放。

###### 7 ）总结

选用 MinIO 开源存储框架，快速设计并搭建出一套支持海量短视频上传、存储、点播等功能的视频点播
平台，

为当下不断涌现的短视频点播平台及相关应用提供了一定技术选型与设计参考。

#### 短视频架构的核心要点：CDN 缓存

除此 minio 存储之外，短视频对 CDN 分发也是有很高要求的，

跟传统的长视频相比的话，因为长视频会进行预取刷新的操作，会预先将文件分发到 CDN 节点上去，

但是短视频内容因为是 UGC，而且视频上传完成之后页面马上就要发布出去，进行播放，所以往往不能
像长视频那样，提前预取到各个 CDN 节点，进行预热，这对视频云平台内部的分发能力是有要求的。


###### 就近上传

用户拍完一段视频，需要立即上传。

CDN 厂商一般全国各地有多个数据中心，“从基础资源能力上来讲，要求 CDN 网络有条件为客户提供就
近上传的功能”。

如何实现？


通过一套 SDK，开发者将这套 SDK 嵌入到他们 APP 里面去，最终用户在将视频上传的时候，会通过 HTTP
DNS 的调度去获取离他最近的或者是当前网络中最佳的一个数据中心节点，并且实现这个文件的上传功
能。

#### 亿级视频处理系统架构实践

字节跳动火山引擎视频中台支撑了多个亿级应用的视频全生命周期管理：

```
火山引擎视频的相关 ToB 业务
支持了字节跳动抖音
西瓜视频等产品
```
全部视频生命周期：

```
视频生产
视频下发
视频播放等
```
###### 视频处理整体的生命周期

视频从拍摄到播放的整个过程可以分为四个主要阶段：

```
端侧生产 ：视频制作者使用设备拍摄（手机或其他设备），并可对视频增强和编辑。通过使用上传
工具，将视频上传到云服务器。
云端生产 ：云端包含两个关键环节：视频后期处理和审核。这两个环节同时进行。
云端分发 ：完成上述两个环节后，视频就可以供用户观看，进入云端分发阶段。
在此阶段，点播服务负责提供视频的播放链接（包括相关的元数据），视频内容通过 CDN 进行分
发。
视频播放 ：此阶段由播放工具负责在用户终端进行视频的处理和展示。
```
在整个过程中，视频处理系统是云端生产的核心阶段。

接下来，我们探讨一下字节跳动在视频处理方面所面临的几个挑战。

```
庞大的规模 ：如今，字节跳动每天处理的视频数量已经达到亿级别，由于每个视频都有不同层次、
不同格式的需求，实际上生产的视频数量近十亿级别。这对系统整体稳定性和性能的要求很高，同
时，对计算和存储资源造成极大的消耗。
```

```
多样化的业务 ：字节跳动的视频业务涵盖广泛，涉及教育、游戏等不同垂直行业，包括点播、直
播、RTC，以及长视频、中视频、短视频等相关业务。
复杂的资源环境 ：除了常规的 CPU 资源外，还有许多弹性资源，如其他的硬件转码设备，
CPU/GPU/FPGA 等。
大型活动的峰值和业务高速增长 ：字节跳动每年都有许多大型活动，给系统带来巨大的压力。此
外，每年处理的视频数量都以至少翻倍的速度增长。
```
###### 视频处理系统的目标

面临以上这些挑战，视频处理系统要实现哪些目标呢？

大家可以看上图，这张图更偏逻辑的关系。

在实现视频处理系统的主要目标时，我们需要关注三个重要方面：首先，满足各种业务需求，例如支持
短视频、长视频等不同类型的视频业务以及满足各行业的需求；其次，提升用户体验，通过优化画质、
流畅性等方面，让用户获得更好的观看体验；最后，降低成本，特别是考虑到字节跳动庞大的业务量所
带来的计算、存储以及 CDN 成本。

为达成这些目标，视频处理系统需要具备多种处理能力，例如转码、编辑、分析和图片处理等。这些处
理能力都是视频应用的重要组成部分。以转码应用为例，我们需要采用新的编码器、自适应转码等技术
来降低码率，同时通过增强技术提高画质等。

此外，所有这些处理能力都依赖于一个高可用性、高可扩展性和高效运维开发效率的基础处理系统。这
个系统是整个视频处理系统的核心，为我们提供了各种视频处理能力的支持。


总之，视频处理系统是一个复杂的系统，它以底层系统为支撑，构建了各种视频处理能力，形成了多种
视频应用，从而满足了业务需求、提升了用户体验并降低了成本。

###### 视频处理系统架构

为了实现这些目标，视频处理系统的结构如图所示，可分为外部和内部两个部分。

在外部部分，系统被划分为三个层次：

```
1. 数据平面 ：系统每天产生大量数据，这些数据可用于分析以指导系统优化，同时也用于计量、计费
和监控等方面。
2. 控制平面 ：服务于开发人员、运维人员和支持人员，他们负责操作和控制系统，并在系统出现问题
时进行管理和应急处理。
3. 用户平面 ：主要关注用户如何与系统互动，以及如何使用系统功能。
```
中间的四层分别是：

```
1. BMF ：动态多媒体处理框架，旨在插件化管理所有多媒体处理原子能力，从而提高系统的可扩展
性、开发和运维效率。
2. Lambda ：这是一个高可用的函数计算平台，主要负责管理底层海量资源，实现资源的高效调度
和任务执行。
3. 工作流系统 ：旨在协调异步、分布式的媒体处理流程。
4. 服务层 ：主要负责处理鉴权、任务队列管理、上层模板管理和策略控制等任务。
```
下面将为大家详细介绍几个核心层。

#### 服务层和工作流系统


###### 系统服务层介绍

在服务层中，有几个关键组件值得关注：

```
服务网关 ：它能够进行跨数据中心的流量调度，并负责接口认证和接口层的流量控制。
弹性队列 ：它可以隔离业务方面的资源。它的功能包括：队列资源设置（例如任务的 QPS 和最大
并发任务数量 MRT）、队列管理和弹性资源的管理。
管理服务 ：它具有两个功能，首先是对整个视频处理系统的元数据进行管理，例如任务队列、模板
和工作流信息等；另外是启动底层工作流的执行，并管理整个工作流的生命周期状态。
```
###### 媒体工作流介绍

在服务层的下方，有一个媒体工作流引擎，负责组织一系列视频处理的操作，这些操作以 DAG 的形式
排列。例如，在西瓜视频上传一个视频后，需要提取视频封面并进行无水印转码，还需要进行各种编码
格式的转换。


这些处理视频的流程都属于细粒度的任务。一个可行的方法是将这些单独的流程整合成一个工作流。工
作流解决了以下问题：

```
首先，它简化了复杂业务的调用过程。如果没有工作流，处理一个视频需要进行多次调用。
其次，工作流有助于管理视频处理流程之间的依赖关系。在实际处理过程中，前后流程之间存在依
赖关系，例如画质增强流程，需要先对原片进行增强，然后进行普通转码，或者通过分片转码功能
对视频预先切片，接着对每个切片进行转码，最后将它们拼接在一起。这些都可以通过工作流实
现。
最后，工作流提供了任务超时、错误重试等高可用能力，降低了业务使用成本。
```
下面看一下工作流内部是怎样的结构。

工作流内部主要包括以下几个组件：

```
VWorker ：作为上层与下层的连接层，将上层的业务模板转换为底层可执行的函数任务参数。
Scheduler ：对于每个工作流中的节点，可以进行细粒度的任务调度。
Engine ：管理所有工作流的运行状态。
Gate ：负责处理流量调度和授权验证。
```
工作流的核心部分如图中所示，位于绿色区域。

服务层位于顶部，而下面要介绍的是函数计算平台。


###### 任务执行

视频处理系统是一个批处理系统，每个任务都需要执行几十秒、几分钟甚至更长时间。

因此，最关键的是确保每个任务都能最终被执行，并且保持一致性。

为了实现这一目标，系统需要有 **at least once** 的保证。

此外，任务还需要满足幂等的要求。

任务幂等有两个意义：

```
首先，无论任务在何时执行多少次，最终结果都应保持一致，并且对业务方来说透明。
其次，在一定时间内，如果同一个视频进行相同处理并提交多次，系统需要具备去重机制，只执行
一次。对调用者而言，这个过程也应透明，这能在某些场景下提高系统效率。
```
为了确保任务幂等，我们在视频 meta 信息关联和视频存储方面做了大量工作。同时，为了实现 at
least once，我们在工作流和节点层面都设置了超时检测和重试机制。

###### 任务执行的难点 1 ：快速响应和恢复

视频处理系统的下游包括计算资源和存储资源。

一旦计算资源和存储资源出现问题，很难有一个完美的方案对上层业务做到完全无影响，所以要尽量减
少损失，降低对业务的冲击。

为此，可以采取以下两个重要措施：

```
多级限流 ：限流是一种常用方法，但视频处理有一个任务筛选过程，需要确保在有限资源内，所有
重要任务得到优先执行。
例如，假设底层计算资源突然减少一半，如何降低对业务的影响？
首先，在工作流层面，需要将一些对任务延迟不敏感的工作流任务进行推迟，这需要一些策略的预
设置。
此外，在同一个工作流中，需要对不同节点进行优先级配置，比如视频需要转出五个档位，其中两
个档位消费概率最高，需要优先转出，其他档位则可以延迟处理。这整体涉及到分级限流以及限流
策略配置的能力。
批量重转 ：假设昨天底层同事上线了一个有问题的功能，但今天才发现。这时需要把昨天这个功能
上线后所影响的视频全部筛选出来，快速进行重新处理，且不能影响目前正在运行的业务。
这有两个问题需要解决：
第一，如何准确地从某个时间点到另一个时间点，将这一批视频全部挑选出来。
第二，如何快速重新处理，且不影响线上业务。因此，需要一个单独的子系统来负责批量任务的查
找和重新处理。
```

###### 任务执行的难点 2 ：系统维度

从系统层面来说，我们采取了若干措施，主要包括中间件备份以及对下游异常进行监测。一旦发现某些
实例出现问题，我们会立即对这些实例进行隔离和剔除。此外，系统具备较为完善的流量切换策略，因
为系统已经经历了多次大型活动考验，同时拥有全面的压测和预案，这些对于确保系统的高可用至关重
要。

###### 函数计算平台

上面介绍了工作流的系统。下面介绍一下它的下层函数计算平台。

首先，让我们来了解一下函数的概念。

函数在媒体工作流中代表一个节点，同时也对应着一个细粒度的视频处理任务。换句话说，函数就是一
个可执行的程序段。

那么，这个函数计算平台需要具备哪些能力呢？

```
首先，也是最关键的，平台需要为视频处理程序提供大规模水平扩展能力，以便轻松地为线上业务
提供稳定服务。
其次，平台需要管理多种类型的庞大资源，并且具备高效的资源调度能力。
最后，平台还需要具备处理各种异常情况和容灾等的高可用能力。
```
上图是这个函数计算平台的基本架构。

在图中的左侧部分，有一个控制平面，开发者可以编写一个函数并通过管理用户界面将其注册到函数计
算平台上。

接着，我们看到图中的右侧部分展示了整个函数调用过程。首先，该过程会通过函数计算平台的网关，
进入集群级别的调度。随后，过程会进入一个独立的集群，而这个集群内部包含了我们自主研发的中心
调度系统 Order。


Order 系统拥有一个中心调度器，它会将任务分配到一个具体的节点上执行。这个节点会获取整个函数
的可执行包，然后运行该函数。

###### 高可用性：多集群

在多集群层面，

```
首先，我们做了流量的一键切换，多集群的容灾；
其次，我们也会根据预设配置进行流量的自动调节。
```
上图是简单的多机房示意图。

图中左右两侧均为机房，每个机房包含多个集群。

每个机房设有一个集群级调度器模块，而多个机房之间还有一个负责同步各机房资源状况的模块，包括
资源总量和使用情况等。

###### 高可用性：单集群

我们的单集群采用中心调度系统，其中心调度器名为 Server，另有一个执行单元称为 Client。Server
具有多实例、无状态的特点，能够平稳、动态地进行升级。

在 Server 和 Client 之间，有状态检测机制以及对问题节点的熔断和任务重试等措施。

通常情况下，Server 通过心跳检测来判断节点是否正常运行。除此之外，Server 还会关注节点的整体
状态，例如任务超时较多或失败率较高等情况。当出现这些情况时，也会对节点执行熔断策略。

###### 控制面——服务治理

之前我们提到过函数计算平台分为几层，分别是网关层、集群调度层和机器内部调度层。

这些层次均为多实例服务。因此，每个上游都会对下游进行异常检测和隔离，这意味着所有组件都具备
单点异常处理能力。此外，还有一些中间件熔断策略。

###### 动态多媒体框架 BMF

BMF，即 ByteDance Media Framework，是字节跳动自主研发的多媒体处理框架。

我们决定开发一个视频处理框架，是因为发现传统的视频处理框架存在一定的局限性。

```
首先，传统的框架通常使用 C/C++ 进行开发和扩展，这导致扩展的门槛较高，且扩展后需要重新
编译。在一个大型系统中，这是非常麻烦的。
```

```
其次，随着越来越多的人参与框架的开发和维护，框架的依赖关系会变得越来越复杂，最终降低开
发和运维的效率。
另外，传统的视频处理流程较为固定，例如视频转码，传统框架都可以支持。但在一些更为复杂的
场景下，如视频编辑或 AI 分析，传统框架在灵活性上存在限制。
最后，传统框架在性能方面也存在瓶颈。以 ffmpeg 为例，filter graph 是单线程执行的。如果在
filter graph 中加入一个 GPU 的 filter，执行效率会大幅降低，同时 GPU 的利用率也不会很高。
```
为了解决上述问题，我们研发了 BMF 多媒体处理框架，其目标包括：

```
通过一套框架支持各种复杂的应用场景，具备较高的灵活性。
屏蔽底层硬件差异。随着业务越来越多地使用不同异构硬件，如 GPU，我们希望这个框架能原生
支持这些硬件。
通过该框架将所有视频处理的原子能力模块化，并实现动态管理和复用，以解决大规模协同开发的
问题。同时，也能使这些能力在不同场景和业务上得到较好的复用。
降低视频应用开发的成本，使应用开发标准化。
```
上图展示了 BMF 框架的总体结构。

在最上层，即应用层，每一模块都代表一个视频应用，例如前面提及的视频转码、视频编辑、图片处理
等。在下层，是模块层，其中的每个模块都代表视频处理的一个细粒度原子功能，如进行视频编解码或
ROI 检测等。

应用层和模块层通过中间的框架层连接在一起。

框架层的核心是一个引擎，它向上提供一套通用、简洁的流式接口，便于开发者容易地构建视频处理应
用。此接口支持多种语言，包括 C++、Python 和 Go。向下，它提供一套完整的模块开发 SDK，同样
支持这几种语言。


在核心引擎周围，我们还开发了一些相关服务和工具集，主要用于管理模块的版本、依赖等信息。

这种架构的最大 **优点** 在于， **它为开发者提供了一个较好的划分** 。

不同模块的开发者可以专注于自己模块的开发，并选择熟悉的编程语言。

模块开发完成后，可以将整个模块注册到系统中。上层的应用开发支持业务，业务无需了解底层模块的
实现方式以及所使用的编程语言。只需利用框架提供的接口，就可以无缝连接并使用这些模块。

上图进一步展示了 BMF 的动态开发模式。

以实际情境为例，算法开发者负责研究视频处理算法。

```
首先，算法优化人员会对算法进行优化。优化完成后，算法将形成一个模型。
接下来，算法优化人员会将模型注册到系统中，而模块开发人员会将模型封装成具体模块，并注册
到系统中。这些模块代表着具体的原子能力。
然后，函数开发者，即业务开发人员，可以将模块串联成具体的视频处理应用，并将函数注册到函
数管理平台，然后进行灰度测试和上线。
```
在整个流程中，各个团队的分工非常明确，独立开发协作效率大大提高。

此外，流程中的所有模块原子能力都是可重复使用的。且流程不会涉及任何编译依赖，全部都是动态进
行的。

#### 亿级视频处理宏观流程


上图展示了视频转码的完整流程示例。当用户上传一个视频后，该视频将首先进入服务端的存储，从而
触发转码流程，即提交一个工作流任务。此任务将首先经过转码服务，然后被放入弹性队列；接下来，
任务将从弹性队列出队，进入工作流引擎执行；工作流引擎将拆分任务为细粒度的子任务，并将它们发
送到函数计算平台执行。每一个函数都将采用前面介绍的 BMF 动态开发方式进行构建。最终，在所有
细粒度节点任务完成后，整个工作流程也将完成，然后转码或视频处理流程将完成，并逐步返回。

在此，让我们回顾一下本文的一些关键点：

首先，视频处理系统需要满足几个重要要求，包括高可用性（系统稳定性）、高可扩展性（在支持众多
业务场景时，可扩展性对整体高可用性具有重大影响）以及开发和运维效率。

总的架构可以概括为媒体工作流、函数计算平台以及动态多媒体框架 BMF 这三个核心部分。在高可用
性方面，服务层将提供任务幂等、多级限流和批量重传；平台层将实现多机房、多集群的切流策略、单
集群内部的冗余、上下游的异常检测等。最后，底层的动态多媒体框架虽然并未直接提高系统的高可用
性，但提升了系统的可扩展性、开发和运维效率，因此也对系统起到了至关重要的作用。

未来，系统将朝着更智能化的方向发展。我们希望构建一种分布式调度执行平台，用户只需关注处理流
程，而平台的拆分、资源调度和执行方式将由平台自行决定。

#### 参考文献：

https://blog.csdn.net/weixin_37604985/article/details/132179317

https://zhuanlan.zhihu.com/p/381259391

https://blog.csdn.net/csdnnews/article/details/117915142

#### 所以，以上才是“教科书式” 答案：

结合字节的方案，大家回到前面的面试题：

```
短视频系统，如何做系统架构？
短视频 APP，如何做系统架构？
```

以上的方案，才是完美的答案，才是“教科书式” 答案。

后续，尼恩会给大家结合行业案例，分析出更多，更加劲爆的答案。

当然，如果遇到这类问题，可以找尼恩求助。

#### 视频预告： 33 章，10 Wqps 高并发 Netty 网关架构与实操

为了大家拿高端 offer，拿架构 offer，即将发布：

```
《第 32 章视频：超高并发、超高可用 1000 W 级 ID 组件架构与实操》。
《第 33 章视频：10 Wqps 高并发 Netty 网关架构与实操》。
```
并且提供配套的简历模板，帮助大家进行简历的亮点重建和升级，最终帮助大家进大厂、做架构、拿高
薪。

#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》


## 美团 2 面： 5 个 9 高可用 99.999%，如何实现？

#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，最近有小伙伴拿到了一线互联网企业如网易、有赞、希
音、百度、网易、滴滴的面试资格，遇到一几个很重要的面试题：

```
问题 1 ：你们系统，高可用怎么实现？
```
```
问题 2 ： 4 个 9 高可用 99.99%，如何实现？
```
注意，最近一个小伙伴美团 2 面，又遇到了这个问题： 5 个 9 高可用 99.999%，如何实现？

**尼恩提示，高可用的问题，是架构的核心知识，又是线上的重点难题。**

所以，这里尼恩给大家做一下系统化、体系化的线程池梳理，使得大家可以充分展示一下大家雄厚的
“技术肌肉”， **让面试官爱到 “不能自已、口水直流”** 。


也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 101 版本，供后面的小伙伴参
考，提升大家的 3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，最新尼恩架构笔记、面试题的 PDF 文件，请从公众号 【技术自由
圈】获取。
```
#### 架构设计的 3 高原则

现如今，开发一个软件系统，对其要求越来越高，如果你了解一些「架构设计」的要求，就知道一个好
的软件架构应该遵循以下 3 个原则：

```
1. 高性能
2. 高并发
3. 高可用
```
**高性能** 意味着系统拥有更大流量的处理能力，更低的响应延迟。

例如 1 秒可处理 10 W 并发请求，接口响应时间 5 ms 等等。

**高并发** 表示系统在迭代新功能时，能以最小的代价去扩展，系统遇到流量压力时，可以在不改动代码的
前提下，去扩容系统。

**高可用** 通常用 2 个指标来衡量：

```
平均故障间隔 MTBF （Mean Time Between Failure）：表示两次故障的间隔时间，也就是系统
「正常运行」的平均时间，这个时间越长，说明系统稳定性越高
故障恢复时间 MTTR （Mean Time To Repair）：表示系统发生故障后「恢复的时间」，这个值越
小，故障对用户的影响越小
```
可用性与这两者的关系：

```
可用性（Availability）= MTBF / (MTBF + MTTR) * 100%
```
这个公式得出的结果是一个「比例」，通常我们会用「N 个 9 」来描述一个系统的可用性。

从这张图你可以看到，要想达到 4 个 9 以上的可用性，一年的不可以时间为 52 分钟，平均每天故障时
间必须控制在 10 秒以内。

系统发生故障其实是不可避免的，尤其是规模越大的系统，发生问题的概率也越大。

#### 3 个 9 的架构--通用架构

在阿里云平台上，对于中小型企业，业务量不是特别大，对异地容灾要求不是特别强烈，


则可采用以下高可用方案（如下图：图六），

可以在同一地域下选择购买云产品。

建议在 VPC 网络环境下，选择同一可用区或者同地域不同可用区的云产品。

同时建议 ECS 服务器至少两台，避免单点故障，在前端购买 SLB，提供负载功能，这样当后端 ECS 资源使
用紧张时可以直接横向扩展，对业务无影响。

另外，数据库业务尽量不要和应用服务部署在同一台 ECS 上。

防止不同服务之间资源抢占，同时方便日常管理和后期扩容。数据库服务器推荐直接购买 RDS 产品，数
据安全有保障，同时也不需要花太多精力去运维管理。


###### 高可用 SLB 组件介绍

阿里云 SLB 组件使用开源软件 LVS＋keeplived 实现 4 层的负载均衡。

7 层采用淘宝的 Tengine 实现 7 层的负载均衡。

所有负载均衡均采用集群部署，集群之间实时会话同步，以消除服务器单点，提升冗余，保证服务稳
定。在各个地域采用多物理机房部署，实现同城容灾。

SLB 在整体设计上让其可用性高达 99.99%。

且能够根据应用负载进行弹性扩容，在任意一台 SLB 故障或流量波动等情况下都能做到不中断对外服
务。

###### 什么是多可用区？

云产品的可用区指的是一套独立的基础设施，不同的可用区之间基础设施（网络，电力和空调等）相互
独立，即一个可用区出现基础设施故障不影响另外一个可用区。

为了向广大用户提供更加稳定可靠的负载均衡服务，阿里云负载均衡已在各地域（Region）部署了多可
用区以实现同地域下的跨机房。


当主可用区的机房故障或不可用时，负载均衡仍然有能力在非常短的时间内（约 30 秒）切换到另外一个
备可用区的机房并恢复服务的能力；当主可用区恢复时，负载均衡同样会自动切换到主可用区的机房提
供服务。

关于负载均衡主备可用区，请注意：

```
SLB 支持跨可用区挂载后端 ECS，即只要 ECS 和 SLB 实例在同一个地域即可。SLB 可以同时将流量分
发至不同可用区的 ECS 上。
正常情况下，备可用区的 SLB 实例处于待机状态。您不可以手动切换 SLB 实例的主备工作状态，只
有当阿里云检测到整个可用区不可用时如如机房整体断电、机房出口光缆中断等，负载均衡才会切
换到备可用区。而并非某个实例出现故障，就切换到备可用区。
SLB 和 ECS 是不同的集群。可用区 A 的 SLB 不可用时，ECS 并不一定不可用，因此如果仅因为 SLB 集
群故障导致的 SLB 主备倒换，备可用区的 SLB 依然可以将流量分发至不同可用区的 ECS。但当整个
可用区的所有集群断电或光缆中断时，那么可用区的所有服务（包括但不限于 SLB、ECS 等）就都
无法正常工作了。
```
###### 主备可用区列表

下表列举了阿里云各地域的主备可用区，您也可以通过 DescribeZones 接口查询可用的主备可用区。

下表列举了各地域的主备可用区，您也可以通过 DescribeZones 接口查询可用的主备可用区。


#### 4 个 9 的高可用架构—同城容灾

对中大型用户来说，希望业务系统要求具备同城容灾的能力，可以考虑在同城不同可用区之间对原有应
用架构做一套完整的备份。

如果某个可以去出现像 IDC 机房断电或者火灾等故障时，可以通过前端切换 DNS 来及时恢复业务。

如下图：


#### 5 个 9 的高可用架构—异地容灾

对于一些大型企业在业务安全全性、服务可用性和数据可靠性方面既要求具备同城容灾又要求具备异地
容灾时，可以采用这种容灾架构方式既可以解决单机房故障也可以应对像地震等灾难性故障。

不同地域之间可以采用阿里云的高速通道进行私网通信，保障数据库之间的数据实时同步，将数据传输
延迟降到最低。

故障发生时可以通过前端 DNS 实现秒级切换，及时恢复业务。

如下图：


###### 虚拟专用网络（VPC）进行实现不同地域互通

**当 ECS 位于不同地域时，如何实现它们之间的内网互通呢？**

首先，ECS 之间的内网互通可以通过虚拟专用网络（VPC）进行实现。

VPC 是阿里云提供的一种高度可定制化的网络隔离环境，用户可以在 VPC 内创建自己的私有网络，并通
过 VPC 内网连接不同地域的 ECS 和 RDS 实例。

其次，用户可以通过 VPC 间对等连接方式实现地域之间的内网互通。通过创建对等连接，不同地域的
VPC 可以直接通信，从而使得位于不同地域的 ECS 和 RDS 实例能够通过内网进行互访。对等连接提供了
低延迟、高带宽的网络通信，保障了数据的安全和速度。

除了 VPC 对等连接，用户还可以选择使用阿里云的内网专线接入（VBR）服务。通过 VBR，用户可以自
建专线连接不同地域的私有网络，实现 ECS 和 RDS 之间的内网互通。这种方式适用于需要大量数据传输
或对网络可靠性有更高要求的场景。

另外，为了加强内网互通的安全性，用户可以使用安全组和访问控制列表（ACL）进行网络访问控制。

安全组可以定义入站和出站规则，控制对 ECS 和 RDS 的访问权限；ACL 可以根据源和目标 IP 地址、协议及
端口号等信息，精细控制子网和 VPC 之间的流量。

总的来说，ECS 和 RDS 位于不同地域时，可以通过 VPC 的对等连接或者内网专线接入等方式实现内网互
通。这些方法都提供了安全可靠的云上网络环境，满足了用户在分布式架构中对内网通信的需求。

**注意跨地域的延迟**

异地多活面临的主要挑战是网络延迟，以北京到上海 1468 公里，即使是光速传输，一个来回也需要接
近 10 ms，在实际测试的过程中，发现上海到北京的网络延迟，一般是 30 ms。

###### 参考案例：阿里云关系型数据库 RDS 高可用介绍

阿里云关系型数据库（简称 RDS）：是一种稳定可靠、可弹性伸缩的在线数据库服务。

RDS 默认采用主备架构（备用实例正常情况下对用户不可见），两个实例位于不同服务器，自动同步数
据。主实例不可用时，系统会自动将数据库连接切换至备用实例。切换是分钟级别，而且不需要人工介
入，全部由系统自动完成，应用系统也无需任何变更。这种架构足以满足 90% 用户的高可用需求。


如下图：

用户如果对系统可用性有更高的要求，希望可以做到机房容灾，

阿里云 RDS 可以选择购买多可用区 RDS，多可用区是在单可用区的级别上，将同一地域的多个单可用区
组合成的物理区域。

相对于单可用区 RDS 实例，多可用区 RDS 例可以承受更高级别的灾难，如下图：


图四：RDS 同城容灾架构

除了同城容灾之外，对于数据可靠性有强需求用户，比如是有监管需求的金融业务场景，RDS 提供异地
灾备实例，帮助用户提升数据可靠性。

RDS 通过数据传输服务（DTS）实现主实例和异地灾备实例之间的实时同步。

主实例和灾备实例均搭建主备高可用架构，当主实例所在区域发生突发性自然灾害等状况，主节点
（Master）和备节点（Slave）均无法连接时，可将异地灾备实例切换为主实例，在应用端修改数据库
链接地址后，即可快速恢复应用的业务访问。

如下图：


图：RDS 异地容灾架构

#### 异地多活数据一致性：DTS 组件

异地多活架构中，为了支持业务流量在各个地域之间的灵活切换，必须解决各个业务中心之间的数据同
步问题。

阿里云数据传输服务 DTS 支持 RDS 实例之间的双向同步，实现业务中心之间的数据同步，保证数据全局
一致，从而实现异地多活技术架构的快速复制。

数据传输服务 DTS 从 2013 年起，已连续 4 年平稳支撑了阿里巴巴异地多活 (3 个业务中心) 底层的全局数据
同步。

自 2014 年在阿里云为用户提供服务以来，DTS 已经为上万用户提供可靠、稳定的数据流服务。

DTS 支持异地多活架构中数据层之间的数据同步，实现数据全局一致。下面是一个简单的异地多活业务
架构图：


如上图所示，业务按照某个维度将流量切分到各个业务中心 (亦称单元)。

切分维度的选择要遵循如下原则：

(1) 拆分后，需要实现业务的单点写。例如按照会员切分，那么同一个会员的访问只能在某个业务中心
单点写。

(2) 拆分维度要能够尽量保证业务在单元内封闭，即所有的业务请求都能够在单元内完成，以减少跨地
域的访问调用。

对于用户分布比较广的业务，可以根据用户分布进行业务中心部署区域的选择。

例如国际化业务，可以选择中国、欧洲、北美等多点进行业务中心的部署，区域附近的用户的业务请求
直接落在就近区域，以最大程度降低用户访问延迟，从而有效提升用户体验。

当流量切分到各个单元后，各个单元的数据层均会有数据写入，通过 DTS 进行数据层的数据双向同步，
实现数据全局一致。当某个业务中心 (单元) 出现故障时，可以修改流量切分规则将流量秒级切换到其他
单元，从而有效得保证了业务的持续可用，完美得避免了故障造成的经济损失及对公司品牌的影响。

#### 说在最后


高可用相关面试题，是非常常见的面试题。以上的内容，如果大家能对答如流，如数家珍，基本上面试
官会被你震惊到、吸引到。

最终， **让面试官爱到 “不能自已、口水直流”** 。offer，也就来了。

学习过程中，如果有啥问题，大家可以来找 40 岁老架构师尼恩交流。

#### 参考文献

https://zhuanlan.zhihu.com/p/549472160

https://zhuanlan.zhihu.com/p/96917394

#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》


## 阿里 2 面：你们部署多少节点？1000 W 并发，

## 当如何部署？

#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，最近有小伙伴拿到了一线互联网企业如阿里、网易、有
赞、希音、百度、网易、滴滴的面试资格，遇到一几个很重要的面试题：

```
1000 W 并发，需部署多少个节点？
如何觉得部署多少个节点，是怎么预估以及部署的？
```
**尼恩提示，部署架构、节点规划相关的问题，是架构的核心知识，又是线上的重点难题。**

所以，这里尼恩给大家做一下系统化、体系化的线程池梳理，使得大家可以充分展示一下大家雄厚的
“技术肌肉”， **让面试官爱到 “不能自已、口水直流”** 。

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 102 版本，供后面的小伙伴参
考，提升大家的 3 高架构、设计、开发水平。

```
最新《尼恩架构笔记》《尼恩高并发三部曲》《尼恩 Java 面试宝典》的 PDF，请关注本公众号
【技术自由圈】获取，回复：领电子书
```

大家先思考一个问题，这也是在面试过程中经常遇到的问题。

```
如果你们公司现产品是卖口罩的，平时能够支持 10 W 用户访问，
```
```
遇到突发的情况，如疫情来了，
```
```
预计在 1 个月后用户量会达到 1000 W，如果这个任务交给你，你应该怎么做？
```
#### 如何分析 1000 W 用户并发的问题

对于如何支持 1000 万用户的问题，实际上是一个相当抽象的问题。

对于技术开发者来说，需要量化。

什么是量化？就是需要一个明确的性能指标数据，以便在执行关键业务时进行参考。

例如，在高峰时段，系统的事务响应时间、并发用户数量、每秒查询率（QPS）、成功率等。

量化的基本要求，就是各项指标，必须清晰明了。

只有这样，才能有效地指导整个架构的改进和优化。

因此，如果你面临这样的问题，首先需要找到问题的核心，也就是了解一些可以量化的数据指标。

```
如果你有相关的历史业务交易数据，那么你应该尽可能地参考这些数据，并处理这些收集来的原始
数据（日志），以分析出高峰时段和该时段的交易行为、规模等信息，以便更清楚地了解需求细
节。
如果你没有相关的数据指标可以参考，那么你就需要依靠经验来进行分析。例如，你可以参考一些
类似行业的成熟业务交易模型（如银行业的日常交易活动或交通行业的售检票交易活动），或者直
接采用“2/8”原则和“2/5/8”原则来开始实践。
当用户能在 2 秒内得到系统的响应时，他们会觉得系统响应迅速；
在 2-5 秒内得到响应时，他们会觉得系统响应速度尚可；
在 5-8 秒内得到响应时，他们会觉得系统响应速度较慢，但仍能接受；
然而，当用户在超过 8 秒后仍未得到响应时，他们会感到系统性能极差，或者认为系统已经无法
响应，从而选择离开网站，或者发起第二次请求。
```
在估算关键指标如响应时间、并发用户数量、每秒查询率（QPS）、成功率的同时，你也需要关注具体
的业务功能需求。

每个业务功能都有其独特的特点。例如：

```
在某些场景下，可以不需要同步返回明确的执行结果；
而在某些业务场景下，可以接受返回“系统忙，请等待！”这样的提示信息，以避免过大的处理流量
导致系统大规模瘫痪。
```
因此，学会平衡这些指标之间的关系是必要的。

###### 服务等级协议

在大多数情况下，最好为这些指标设定一个优先级顺序，并尽可能只关注几个高优先级的指标要求。

```
SLA ：Service-Level Agreement 的缩写，意思是服务等级协议。
服务的 SLA 是服务提供者对服务消费者的正式承诺，是衡量服务能力等级的关键项。
```
```
服务 SLA 中定义的项必须是可测量的，有明确的测量方法。
```

```
SLA 项含义测量方法示例
```
```
服
务
级
别
```
```
接
口
级
别
```
```
请求成
功率
```
```
测量周期内服务成功应答的请求占总请求
数的百分比
```
```
(成功应答请
求数/总请
求)*100
```
```
>99% 是否
```
```
可用性
```
```
测量周期内，服务可用时间所占百分比，
可用性分三个等级。
1.99.999%-99.9999%，这个是可用性最高
的服务，一年累计不可用时间为 5.256 分
钟-31.536 秒，这类服务不可用会影响到用
户使用，比如登录
2.99.99%%-99.999%，一年累计不可用时
间为 52.56 分钟-5.256 分钟，出现不可用时
会影响用户的操作，间接面向用户的服务
```
3. 99.9%-99.99%，一年累计不可用时间为
8.76 小时-52.56 分钟，出现服务不可用时不
会影响用户的使用。

```
(服务在线时
间/统计周期
总时
间)*100
```
```
Level
1 是否
```
```
数据一
致性
```
```
服务消费者调用服务接口写入数据后马上
调用服务接口读取，是否可以读到写入的
数据内容，包含三个等级
1. 强一致
2. 弱一致
3. 最终一致
```
```
调用资源创
建接口，调
用资源查询
接口获取创
建的数据
```
```
最终一
致是否
```
```
吞吐量
```
```
每秒钟处理的请求数，对于服务集群建议
给出总体吞吐量的计算方式，比如集群吞
吐量=吞吐量*服务实例数，如果难以给
出，则至少要给出典型的集群实例数情况
总体吞吐量
```
```
统计服务每
秒处理的请
求数量
```
```
200 是
```
```
可
选
```
```
TP 50
请求延
迟
```
```
服务运行周期内 50%的请求延时地域定义
的值
```
```
使用百分位
计算方式 100 ms 是
```
```
可
选
```
```
TP 99.9
请求延
迟
```
```
服务运行周期内 99.9%的请求延迟地域定义
的值
```
```
使用百分位
计算方式
```
```
200 ms 是可
选
```
#### 1 、并发中相关概念的解释

在深入探讨上述问题之前，我想先向大家介绍一下与系统相关的一些关键评估指标:

```
qps
tps
```

```
dau
pv
uv
```
这些 **关键概念** ，尼恩写过专门的文章介绍过，具体请参见下面的文章：

你们系统 qps 多少，怎么部署的？假设每天有几千万请求，该如何部署？

#### 2 、按照二八法则来推算 1000 w 用户的访问量

让我们回归最初的问题：1000 W 并发，需部署多少个节点？

假设我们没有历史数据可以参考，我们可以采用 **二八定律** 来进行估算。

```
假设有 1000 W 用户，每天访问网站的用户占比为 20%，那么每天大约有 200 W 用户访问。
假设每个用户平均点击 50 次，那么总的页面浏览量 PV=1 亿。
一天有 24 小时，根据二八定律，每天大部分用户活跃的时间点集中在 (24 * 0.2) 约等于 5 个小时
以内，而大部分用户指的是（ 1 亿点击 * 80%）约等于 8000 W（PV），意味着在 5 个小时以内，
大概会有 8000 W 点击进来，也就是每秒大约有 4500 (8000 W/5 小时) 个请求。
4500 只是一个平均数值。在这 5 小时内，请求量并不一定均匀，可能会出现大量用户集中访问的
情况（比如像淘宝这样的网站，日访问量高峰时间段集中在下午 14:00 和晚上 21:00，其中 21:00
是一天中访问量的最高峰）。通常情况下，访问量高峰时段的请求量是平均请求量的 3 到 4 倍
（这是一个经验值），我们按照 4 倍来计算。那么在这 5 小时内，可能会出现每秒 18000 个请求
的情况。因此，问题由原本的支撑 1000 W 用户，变成了一个具体的问题，就是服务器端需要能够
支撑每秒 18000 个请求 （QPS=18000）
```
#### 3 、服务器压力预估

在大致估算了后端服务器需要承受的最高并发峰值之后，我们需要从整个系统架构的角度进行压力测
试，然后合理配置服务器数量和架构。

首先，我们需要了解一台服务器能承受多大的并发量，那么该如何进行分析呢？

由于我们的应用部署在 Tomcat 上，因此我们需要从 Tomcat 的性能入手。

以下是一个描述 Tomcat 工作原理的图表，图表说明如下：

```
LimitLatch 是连接控制器，它负责控制 Tomcat 能同时处理的最大连接数。在 NIO/NIO 2 模式
下，默认值为 10000 ；而在 APR/native 模式下，默认值为 8192 。
```

```
Acceptor 是一个独立线程，它在 run 方法中的 while 循环里调用 socket. accept 方法接收客户端
的连接请求。每当有新的请求到来时，accept 会返回一个 Channel 对象，然后将该 Channel 对
象交给 Poller 处理。
Poller 本质上是一个 Selector，它也实现了线程。Poller 在内部维护一个 Channel 数组，并在一
个死循环中不断检测 Channel 的数据就绪状态。一旦有 Channel 可读，它将生成一个
SocketProcessor 任务对象并交给 Executor 处理。
SocketProcessor 实现了 Runnable 接口。当线程池执行 SocketProcessor 任务时，它会通过
Http 11 Processor 处理当前请求。Http 11 Processor 读取 Channel 的数据以生成 ServletRequest
对象。
Executor 是线程池，负责运行 SocketProcessor 任务。SocketProcessor 的 run 方法会调用
Http 11 Processor 读取和解析请求数据。我们知道，Http 11 Processor 是应用层协议的封装，它
会调用容器获取响应，然后将响应通过 Channel 写出。
```
从这个图中我们可以得知，影响 Tomcat 请求数量的因素主要有四个方面。

###### 3.1 Tomcat 影响因素 1 ：当前服务器系统资源

我想可能大家遇到过类似“Socket/File：Can't open so many files”的异常，这就是 Linux 系统中文件句
柄限制的表示。

在 Linux 操作系统中，每一个 TCP 连接都会占用一个文件描述符（fd），当文件描述符超过 Linux 系
统当前的限制时，就会弹出这个错误提示。

我们可以通过以下命令来查看一个进程能够打开的文件数量上限。

open files （-n） 1024 是 linux 操作系统对一个进程打开的文件句柄数量的限制（也包含打开的套接
字数量）

这里只是对用户级别的限制，其实还有个是对系统的总限制，查看系统总线制：

```
ulimit -a 或者 ulimit -n
```
```
cat /proc/sys/fs/file-max
```

file-max 是设定系统所有进程总共可以打开的文件数量。

同时，部分程序可以通过 setrlimit 调用，设置每个进程的限制。如果收到大量文件句柄使用完毕的错误
信息，那么我们应该考虑增加这个数值。

当遇到上述错误时，我们可以通过以下方式进行修改（针对单个进程的文件打开数量限制）

```
*代表所有用户、root 表示 root 用户。
noproc 表示最大进程数量
nofile 代表最大文件打开数量。
soft/hard，前者当达到阈值时，制作警告，后者会报错。
```
另外，还需要确保针对进程级别的文件打开数量限制是小于或等于系统的总限制，如果不是，那么我们
需要修改系统的总限制。

TCP 连接对于系统资源最大的开销在于内存。

由于 TCP 连接需要双方进行数据接收和发送，因此需要设置读取缓冲区和写入缓冲区。

在 Linux 系统中，这两个缓冲区的最小大小为 4096 字节，可以通过查
看/proc/sys/net/ipv 4/tcp_rmem 和/proc/sys/net/ipv 4/tcp_wmem 来获取相关信息。

因此，一个 tcp 连接最小占用内存为 4096+4096 = 8 k，那么对于一个 8 G 内存的机器，如果不考虑其
他限制，其最大并发数约为：8 * 1024 * 1024/8 约等于 100 万。

这个数字是理论上的最大值，在实际应用中，受到 Linux 内核对部分资源的限制以及程序业务处理的影
响，8 GB 内存很难达到 100 万连接。

当然，我们可以通过增加内存来提高并发数。

###### 3.2 Tomcat 影响因素 2 ：Tomcat 依赖的 JVM 的配置

我们都知道，Tomcat 是一个 Java 程序，运行在 JVM 上，

因此，对 JVM 进行优化也是提高 Tomcat 性能的关键。下面简单介绍一下 JVM 的基本情况，如下图所
示。

```
vi /etc/security/limits. conf
root soft nofile 65535
root hard nofile 65535
* soft nofile 65535
* hard nofile 65535
```
```
vi /proc/sys/fs/file-max
```

在 JVM 里，内存被划分为堆、程序计数器、本地方法栈、方法区（元空间）和虚拟机栈。

**3.2.1 堆空间说明**

堆内存是 JVM 内存中最大的一个区域，绝大多数的对象和数组都会被分配在此，它供所有线程共享。堆
空间被划分为新生代和老年代，新生代进一步被划分为 Eden 和 Survivor 区，如下图所示。

新生代和老年代的比例为 1:2，也就是说新生代占堆空间的 1/3，而老年代占 2/3。

另外，在新生代中，空间分配比例为 Eden: Survivor 0: Survivor 1=8:1:1。

举例来说，如果 Eden 区的内存大小是 40 M，那么两个 Survivor 区的内存分别占 5 M，新生代的总内存
就是 50 M，进而计算出老年代的内存大小为 100 M，也就是说堆空间的总内存大小是 150 M。

```
可以通过 java -XX: PrintFlagsFinal -version 查看默认参数
```
```
InitialSurvivorRatio: 新生代 Eden/Survivor 空间的初始比例
```
```
NewRatio ： Old 区/Young 区的内存比例
```
堆内存的具体工作机制如下：

```
uintx InitialSurvivorRatio  = 8
uintx NewRatio  = 2
```

```
绝大多数对象在创建后会被放置在 Eden 区，当 Eden 区满时，会触发 YGC（Young GC），大部
分对象会被回收，仍有存活的对象会被复制到 Survivor 0，此时 Eden 区被清空。
如果再次触发 YGC，存活的对象会从 Eden+Survivor 0 区复制到 Survivor 1 区，此时 Eden 和
Survivor 0 区被清空。
再次触发 YGC，Eden+Survivor 1 中的对象会被复制到 Survivor 0 区，如此循环，直到对象的年龄
达到阈值，则会被移至老年代。（这样的设计是因为 Eden 区的大多数对象会被回收）。
Survivor 区无法容纳的对象会直接进入老年代。
当老年代满时，会触发 Full GC。
```
```
GC 标记-清除算法在执行过程中暂停其他线程??
```
**3.2.2 程序计数器**

程序计数器用于记录各个线程执行的字节码地址等信息，在线程发生上下文切换时，依赖它来记录当前
执行位置，以便在下次恢复执行时能够从上次执行位置继续执行。

**3.2.3 方法区**

方法区是一个逻辑概念，在 HotSpot 虚拟机的 1.8 版本中，它的具体实现就是元空间。

方法区主要用来存储已经被虚拟机加载的类相关信息，包括类元信息、运行时常量池、字符串常量池，
类信息又包括类的版本、字段、方法、接口和父类信息等。

方法区和堆空间相似，它是一个共享内存区域，因此方法区是线程共享的。


本地方发栈和虚拟机栈

Java 虚拟机栈是线程私有的内存空间，当创建一个线程时，会在虚拟机中分配一个线程栈，用于存储方
法的局部变量、操作数栈、动态链接方法等信息。每次调用一个方法，都会伴随着栈帧的入栈操作，当
方法返回后，就是栈帧的出栈操作。

本地方法栈与虚拟机栈类似，本地方法栈用于管理本地方法的调用，也就是 native 方法。

JVM 内存设置方法

在了解上述基本知识后，我们来探讨一下 JVM 内存应该如何设置，以及有哪些参数可以用来设置。

在 JVM 中，需要配置的核心参数包括：

- Xms，Java 堆内存大小
- Xmx，Java 最大堆内存大小
- Xmn，Java 堆内存中的新生代大小，扣除新生代剩下的就是老年代内存
新生代内存设置过小会频繁触发 Minor GC，频繁触发 GC 会影响系统的稳定性
- XX: MetaspaceSize，元空间大小， 128 M
- XX: MaxMetaspaceSize，最大云空间大小 （如果没有指定这两个参数，元空间会在运行时根据
需要动态调整。） 256 M
一个新系统的元空间，基本上没办法有一个测算的方法，一般设置几百兆就够用，因为这里面主要
存放一些类信息。
- Xss，线程栈内存大小，这个基本上不需要预估，设置 512 KB 到 1 M 就行，因为值越小，能够分
配的线程数越多。

JVM 内存的大小受到服务器配置的影响，例如，一台拥有 2 个核心和 4 G 内存的服务器，分配给 JVM 进
程的内存大约为 2 G。

这是因为服务器本身也需要内存，并且还需要为其他进程预留内存。这 2 G 内存还需要分配给栈内存、
堆内存和元空间，因此，堆内存可用的大约为 1 G。

然后，堆内存还需要划分为新生代和老年代。

###### 3.3 Tomcat 影响因素 3 ：Tomcat 本身的配置

tomcat 核心配置如下：

```
Apache Tomcat 8 Configuration Reference (8.0.53) - The HTTP Connector
```
```
The maximum number of request processing threads to be created by this Connector ,
which therefore determines the maximum number of simultaneous requests that can be
handled. If not specified, this attribute is set to 200. If an executor is associated with this
connector, this attribute is ignored as the connector will execute tasks using the executor
rather than an internal thread pool. Note that if an executor is configured any value set for
this attribute will be recorded correctly but it will be reported (e.g. via JMX) as - 1 to make
clear that it is not used.
```

```
accept-count ：这是最大等待数，当 HTTP 请求数量达到 Tomcat 的最大线程数时，如果有新的
HTTP 请求到达，Tomcat 会将该请求放入等待队列中。这个 acceptCount 就是指能够接受的最大
等待数，默认值为 100 。如果等待队列也被填满，那么新的请求将会被 Tomcat 拒绝
（connection refused）。
maxThreads ：这是最大线程数，每当一个 HTTP 请求到达 Web 服务时，Tomcat 都会创建一个
线程来处理该请求。maxThreads 决定了 Web 服务容器能同时处理多少个请求。maxThreads 默
认值为 200 ，建议增加。然而，增加线程会有成本，更多的线程不仅会带来更多的线程上下文切换
成本，还会消耗更多的内存。JVM 默认在创建新线程时会分配大小为 1 M 的线程栈，因此，更多
的线程意味着需要更多的内存。线程数的经验值为： 1 核 2 g 内存为 200 ，线程数经验值 200 ； 4
核 8 g 内存，线程数经验值 800 。
maxConnections ：这是最大连接数，这个参数指定了在同一时间内，Tomcat 能够接受的最大
连接数。对于 Java 的阻塞式 BIO，默认值是 maxthreads 的值；如果在 BIO 模式下使用自定义的
Executor 执行器，默认值将是执行器中 maxthreads 的值。对于 Java 新的 NIO 模式，
maxConnections 默认值是 10000 。对于 Windows 上的 APR/native IO 模式，maxConnections
默认值为 8192 。
如果设置为-1，则禁用 maxconnections 功能，表示不限制 tomcat 容器的连接数。
maxConnections 和 accept-count 的关系为：当连接数达到最大值 maxConnections 后，系
统会继续接收连接，但不会超过 acceptCount 的值。
```
###### 3.4 Tomcat 影响因素 4 ：应用带来的压力

在我们之前的分析中，我们了解到当 NIOEndPoint 接收到客户端的请求连接后，会生成一个
SocketProcessor 任务并将其提交给线程池处理。

SocketProcessor 中的 run 方法会调用 HttpProcessor 组件来解析应用层的协议，并生成 Request 对
象。

最后，调用 Adapter 的 Service 方法将请求传递到容器中。

容器主要负责处理内部的请求，即当前置的连接器通过 Socket 获取到信息后，将获得一个 Servlet 请
求，而容器则负责处理这个 Servlet 请求。

Tomcat 使用 Mapper 组件将用户请求的 URL 定位到一个具体的 Serlvet，然后 Spring 中的
DispatcherServlet 拦截到该 Servlet 请求后，基于 Spring 自身的 Mapper 映射定位到我们具体的
Controller 中。

当请求到达 Controller 后，对于我们的业务来说，才算是请求的真正开始。

Controller 调用 Service、Service 调用 dao，完成数据库操作后将请求原路返回给客户端，完成一次整
体的会话。

因此， **Controller 中的业务逻辑处理时间** ，会对整个容器的并发性能产生影响。

```
server:
tomcat:
uri-encoding: UTF-8
#最大工作线程数 ，默认 200, 4 核 8 g 内存，线程数经验值 800
#操作系统做线程之间的切换调度是有系统开销的 ，所以不是越多越好。
max-threads: 1000
# 等待队列长度，默认 100 ，
accept-count: 1000
max-connections: 20000
# 最小工作空闲线程数，默认 10, 适当增大一些，以便应对突然增长的访问量
min-spare-threads: 100
```

#### 4 、服务器数量评估

简单的数学计算一下：

**假设一个 Tomcat 节点的 QPS 为 500 ，如果要支持高峰时期的 QPS 为 18000 ，那么需要 40 台服务
器。**

这 40 台服务器需要通过 Nginx 软件负载均衡进行请求分发。

Nginx 的性能很好，官方说明其处理静态文件的并发能力可达 5 W/s。

由于 Nginx 不能单点，我们可以采用 LVS 对 Nginx 进行负载均衡，LVS（Linux VirtualServer）采用 IP
负载均衡技术实现负载均衡。

通过这样的一组架构，我们当前服务端是能够同时承接 QPS=18000，但还不够。我们回到之前提到的
两个公式。

```
QPS=并发量/平均响应时间
并发量=QPS * 平均响应时间
```
假设我们的 RT 为 3 s，那么服务器端的并发数=18000 * 3=54000，即同时有 54000 个连接打到服务器
端。因此，服务端需要同时支持的连接数为 54000 。

如果 RT 越大，意味着积压的连接越多，这些连接会占用内存资源/CPU 资源等，容易造成系统崩溃。


同时，当连接数超过阈值时，后续的请求无法进入，用户会得到一个请求超时的结果，这不是我们希望
看到的。因此，我们必须缩短 RT 的值。

#### 5 、如何降低 RT 的值？

继续看上面这个图，一个请求需要等待 Tomcat 容器中的应用执行完成后才能返回。

在执行过程中，请求会进行哪些操作呢？

```
查询数据库
访问磁盘数据
进行内存运算
调用远程服务
```
这些操作都会消耗时间，客户端请求需要等待这些操作完成后才能返回。

因此，降低响应时间的方法就是优化业务逻辑处理。

###### 5.1 数据库的优化

当 18000 个请求进入服务端并被接收后，开始执行业务逻辑处理，必然会涉及到数据库查询。

每个请求至少执行一次数据库查询操作，多的需要查询 3~5 次以上。

假设按照 3 次计算，那么每秒会对数据库形成 54000 个请求。

假设一台数据库服务器每秒支持 10000 个请求（影响数据库请求数量的因素有很多，如数据库表的数
据量、数据库服务器的系统性能、查询语句的复杂度），那么需要 6 台数据库服务器才能支持每秒
10000 个请求。

除此之外，数据库层面还有其他优化方案。

```
首先是 MySQL 的最大连接数设置。当访问量过高时，可能会遇到 MySQL: ERROR 1040: Too
many connections 的问题，原因就是连接数耗尽。如果服务器的并发连接请求量较大，建议调高
此值，以增加并行连接数量。但需要考虑到机器的承载能力，因为连接数越多，每个连接提供的连
接缓冲区会占用越多的内存，所以要适当调整该值，不能盲目提高设值。
引入缓存组件。数据表数据量过大，例如达到几千万甚至上亿。这种情况下，SQL 优化已经意义
不大，因为这么大的数据量查询必然会涉及到计算。可以通过缓存解决读请求并发过高的问题。一
般来说，数据库的读写请求遵循二八法则。在每秒 54000 个请求中，大约有 43200 个是读请求，
这些读请求中大约 90% 都可以通过缓存解决。
```
```
将 MySQL 数据库中的数据放入 Redis 缓存中可以提升性能的原因如下：
```
```
1. Redis 存储的是 Key-Value 格式的数据，其查找时间复杂度为 O (1)（常数阶），而 MySQL
引擎底层实现是 B+Tree，时间复杂度为 O (logn)（对数阶）。因此，Redis 相较于 MySQL
具有更快的查询速度。
2. MySQL 数据存储在表中，查找数据时需要对表进行全局扫描或根据索引查找，这涉及到磁
盘查找。而 Redis 则无需这么复杂，因为它直接根据数据在内存中的位置进行查找。
3. Redis 是单线程的多路复用 IO，避免了线程切换的开销和 IO 等待的开销，从而在多核处理
器下提高了处理器的使用效率。
```
```
分库分表，减少单表数据量，单表数据量少了，查询性能自然得到有效提升。
```

```
读写分离，避免事务操作对查询操作带来的性能影响。写操作本身耗费资源，数据库写操作为 IO
写入，写入过程中通常会涉及唯一性校验、建索引、索引排序等操作，对资源消耗较大。一次写操
作的响应时间往往是读操作的几倍甚至几十倍。锁争用，写操作很多时候需要加锁，包括表级锁、
行级锁等。这类锁都是排他锁，一个会话占据排它锁后，其他会话不能读取数据，这会极大影响数
据读取性能。因此，MySQL 部署通常采用读写分离方式，主库用来写入数据及部分时效性要求很
高的读操作，从库用来承接大部分读操作，这样数据库整体性能能够得到大幅提升。
sql+nosql 异构存储。针对不同特性的数据采用不同的存储库，例如 MongoDB（NoSQL 文档化存
储）、Redis（NoSQL Key-Value 存储）、HBase（NoSQL 列式存储），这些数据库在某种程度
上与 Key-Value 数据库相似。nosql 具有很高的扩展性，适合管理大量非结构化数据。
```
```
客户端池化技术，减少频繁创建数据库连接的性能损耗。在每次进行数据库操作之前，先建立连
接，然后进行数据库操作，最后释放连接。这个过程涉及到网络通信的延时，以及频繁创建和销毁
连接对象的性能开销。当请求量较大时，这种性能损耗会变得非常明显。通过使用连接池技术，可
以重用已创建的连接，降低这种性能损耗。
```
###### 5.2 磁盘数据访问优化

对于磁盘操作，主要包括读取和写入。例如，在交易系统场景中，通常需要对账文件进行解析和写入。
针对磁盘操作的优化方法有：

```
利用磁盘缓存，通过缓存 I/O，充分利用系统缓存，以降低实际 I/O 的次数。
采用顺序读写，用追加写代替随机写，减少寻址开销，提高 I/O 写入速度。
```

```
使用 SSD 代替 HDD，固态硬盘的 I/O 效率远高于机械硬盘。
在频繁读写相同磁盘空间时，可以使用 mmap（内存映射）代替 read/write，减少内存拷贝次
数。
在需要同步写入的场景中，尽量合并写请求，而不是让每个请求都同步写入磁盘，可以使用
fsync () 代替 O_SYNC。
```
###### 5.3 合理利用内存

充分利用内存缓存，将经常访问的数据和对象保存在内存中，以避免重复加载或减少数据库访问带来的
性能损耗。

###### 5.4 调用远程服务

远程服务调用会影响到 I/O 性能，主要包括：

```
远程调用等待返回结果的阻塞
异步通信
网络通信的耗时
内网通信
增加网络带宽
远程服务通信的稳定性
```
###### 5.5 异步化架构

在微服务中，针对处理时间长、逻辑复杂的情况，高并发时可能导致服务线程耗尽，无法创建新线程处
理请求。

针对这种情况，除了在程序层面优化（如数据库调优、算法调优、缓存等），还可以考虑在架构上进行
调整，如先返回结果给客户端，让用户可以继续使用客户端的其他操作，然后将服务端的复杂逻辑处理
模块进行异步化处理。

这种异步化处理方式适用于客户端对处理结果不敏感、不要求实时的场景，如群发邮件、群发消息等。

异步化设计的解决方案有：

```
多线程、
消息队列（MQ）。
```
#### 6 、应用服务的拆分

除了上述手段外，将业务系统拆分为微服务也十分必要，原因包括：

```
业务发展导致应用程序复杂度增加，产生熵增现象。
业务系统功能越来越多，参与开发迭代的人员也越来越多，维护一个庞大的项目容易出现问题。
单个应用系统难以实现横向扩容，服务器资源有限，可能导致所有请求集中请求到某个服务器节
点，造成资源消耗过大，系统不稳定。
测试、部署成本逐渐增加。
.....
```
最重要的是，单个应用在性能上的瓶颈难以突破。

例如，要支持 18000 QPS，单个服务节点肯定无法支撑。因此，服务拆分的好处在于可以利用多台计算
机组成一个大规模的分布式计算网络，通过网络通信完成整个业务逻辑。


###### 6.1 如何拆分服务

关于如何拆分服务，虽然看起来简单，但实际操作时会遇到一些边界问题。

例如，有些数据模型既适用于 A 模块，也适用于 B 模块，如何划分界限呢？此外，服务拆分的粒度应
该如何确定呢？

通常，服务拆分是按照业务进行的，并根据领域驱动设计（DDD）来指导微服务的边界划分。

**领域驱动设计是一套方法论，通过定义领域模型，从而确定业务边界和应用边界，以保证业务模型和代
码模型的一致性** 。

无论是 DDD 还是微服务，都需要遵循软件设计的基本原则： **高内聚低耦合** 。

服务内部应具有高内聚性，服务之间应具有低耦合性。

实际上，一个领域服务对应了一个功能集合，这些功能具有一定共性。

例如，订单服务包括创建订单、修改订单、查询订单列表等功能，领域边界越清晰，功能内聚性越强，
服务之间的耦合性就越低。


服务拆分还需要根据当前技术团队和公司状况来进行。

对于初创团队，不应过分追求微服务，以免导致业务逻辑过于分散，技术架构过于复杂，再加上基础设
施尚不完善，可能导致交付时间延长，对公司发展产生较大影响。因此，在进行服务拆分时，还需要考
虑以下因素：

```
公司业务所处领域的市场性质，如果是市场敏感项目，应先推出产品，然后再进行迭代和优化。
开发团队的成熟度，团队技术能否承接。
基础能力是否足够，如 DevOps、运维、测试自动化等基础能力。团队是否有能力支持大量服务实
例运行带来的运维复杂度，是否可以做好服务监控。
测试团队的执行效率，如果测试团队不能支持自动化测试、自动回归、压力测试等手段来提高测试
效率，那必然会导致测试工作量显著增加，从而导致项目上线周期延期。
```
对于旧系统改造，可能涉及的风险和问题更多。在开始改造之前，需要考虑以下几个步骤：拆分前准备
阶段、设计拆分改造方案、实施拆分计划。

```
在开始分解之前，需要先对当前的整体架构以及各个模块之间的依赖关系有一个清晰的理解，同
时，在准备阶段，主要需要弄明白依赖关系和接口。这样可以在分解时知道如何操作，比如应该在
哪里进行第一次切割，以便将一个复杂的单体系统迅速变为两个较小的系统，同时，也要尽量减少
对系统现有业务的影响。要避免构建出一个分布式的单体应用，这种应用包含了许多互相之间紧密
耦合的服务，却又必须一起部署，这被称为所谓的分布式系统。如果没有进行深入的分析就强行分
解，可能会不小心切断重要的依赖，导致出现 A 类大故障，后果不堪设想。
在不同的阶段，分解的重点是不同的，每个阶段都有其需要关注的核心问题。分解本身可以分为三
个阶段：核心业务和非业务部分的分解、核心业务的调整设计、核心业务内部的分解。在第一个阶
段，需要将核心业务精简，将非核心部分剥离，以减小需要处理的系统规模；在第二个阶段，需要
按照微服务的设计理念重新构建核心业务部分；在第三个阶段，需要将核心业务部分的重构设计实
施。分解的方式也有三种：代码分解、部署分解、数据分解。
```
另外，每个阶段需要集中精力在一到两个具体的目标上，如果目标过多，反而可能会一事无成。例如，
某个系统的微服务分解，制定了如下几个目标：

```
1. 性能指标（吞吐量和延迟）：核心交易的吞吐量提升一倍以上（TPS：1000->10000），A 业务的
延迟减少一半（Latency：250 ms->125 ms），B 业务的延迟减少一半（Latency：70 ms-
>35 ms）。
2. 稳定性指标（可用性，故障恢复时间）：可用性>=99.99%，A 类故障恢复时间<=15 分钟，一个季
度内的故障次数<=1 次。
3. 质量指标：编写完整的产品需求文档、设计文档、部署运维文档，核心交易部分代码 90% 以上单
测覆盖率和 100% 的自动化测试用例和场景覆盖，实现可持续的性能测试基准环境和长期持续性
能优化机制。
4. 扩展性指标：完成代码、部署、运行时和数据多个维度的合理分解，对于核心系统重构后的各块业
务和交易模块、以及对应的各个数据存储，都可以随时通过增加机器资源实现伸缩扩展。
5. 可维护性指标：建立全面完善的监控指标、特别是全链路的实时性能指标数据，覆盖所有关键业务
和状态，缩短监控报警响应处置时间，配合运维团队实现容量规划和管理，出现问题时可以在一分
钟内拉起系统或者回滚到上一个可用版本（启动时间<=1 分钟）。
6. 易用性指标：通过重构实现新的 API 接口既合理又简单，极大地满足各个层面用户的使用需求，
客户满意度持续上升。
7. 业务支持指标：对于新的业务需求功能开发，在保障质量的前提下，开发效率提升一倍，开发资源
和周期降低一半。
```
当然，不要期望一次性完成所有目标，每一个阶段可以选择一两个优先级高的目标进行执行。


###### 6.2 微服务化之后，如何进行服务治理？

微服务架构首先表现为一种分布式架构，其次，我们需要展现和提供业务服务能力，接着，我们要考虑
与这些业务能力相关的各种非功能性能力。这些分散在不同位置的服务需要被统一管理，同时对服务的
调用方保持透明，这样就产生了服务注册和发现的功能需求。

同样地，每个服务可能会部署在多台机器上的多个实例，因此，我们需要具备路由和寻址的能力，实现
负载均衡，以提高系统的扩展性。面对这么多对外提供的服务接口，我们需要一种机制来统一接入控
制，并将一些非业务策略应用到这个接入层，例如权限相关的策略，这就是服务网关的作用。同时，我
们发现随着业务的发展和特定运营活动（如秒杀、大促等）的进行，流量可能会激增十倍以上，这时候
我们就需要考虑系统容量、服务间的强弱依赖关系，实施服务降级、熔断和系统过载保护等措施。

以上由于微服务带来了这些复杂性，应用配置和业务配置都被分散到各个地方，因此，分布式配置中心
的需求也随之产生。

最后，系统在分散部署后，所有的调用都涉及到跨进程，我们还需要一套能够在线进行链路跟踪和性能
监控的技术，以便随时了解系统内部的状态和指标，使我们能够随时对系统进行分析和干预。


###### 6.3 整体架构图

通过从微观到宏观的全面分析，我们可以基本上构建出一个完整的架构图。

```
接入层，这是外部请求进入内部系统的门户，所有的请求都必须通过 API 网关。
应用层，也被称为聚合层，它为相关业务提供聚合接口，并调用中台服务进行组合。
原子服务，包括就是原子技术服务，原子业务服务，根据业务需求提供相关的接口。
```
原子服务为整个架构提供可复用的能力，

例如，评论服务作为一项原子服务，在 B 站的视频、文章、社区都需要，那么为了提高复用性，评论服
务就可以独立为原子服务，不能与特定需求紧密耦合。

在这种情况下, 评论服务，需要供一种可以适应不同场景的复用能力。

类似的，文件存储、数据存储、推送服务、身份验证服务等功能，都会沉淀为原子服务，业务开发人
员，在原子服务基础上，进行编排、配置、组合，可以快速构建业务应用。


#### 7 、 3 高到底如何量化，如何度量？

3 高到底如何量化，如何度量？

高并发没有一个确切的定义，它主要描述的是在短时间内面临大量流量的情况。

当你在面试或者工作中，你的领导或者面试官询问你如何设计一个能承受千万级别流量的系统时，你可
以按照我提供的步骤进行分析。

```
首先，你需要确立一些可以量化的数据指标，例如每秒查询率（QPS）、每日活跃用户数
（DAU）、总用户数、每秒事务数（TPS）以及访问峰值。
然后，根据这些数据，你开始设计系统的架构方案。
接着落地执行
```
###### 7.1 高并发中的宏观指标

一个能满足高并发需求的系统，并不是单纯地追求性能，而是需要至少满足三个宏观目标：

```
高性能，这是系统并行处理能力的体现。在有限的硬件投入下，提高性能就意味着节约成本。同
时，性能也关乎用户体验，响应时间是 100 毫秒还是 1 秒，用户的感受是完全不同的。
高可用，这是系统能正常提供服务的时间。一个全年无故障、不停机的系统，和一个经常出故障、
宕机的系统，用户肯定会选择前者。另外，如果系统的可用性只能达到 90%，也会对业务造成重
大影响。
高扩展，这是系统的扩展能力，即在流量高峰期是否能在短时间内完成扩容，以更稳定地承受峰值
流量，例如双 11 活动、明星离婚等热点事件。
```

###### 7.2 微观指标

**性能指标**

通过性能指标，我们可以衡量当前的性能问题，并作为优化性能的评估依据。通常，我们会把一段时间
内的接口响应时间作为衡量标准。

```
1. 平均响应时间：这是最常用的衡量方式，但它的缺点是对于慢请求不敏感。例如， 1 万次请求中，
有 9900 次是 1 毫秒，有 100 次是 100 毫秒，那么平均响应时间就是 1.99 毫秒。尽管平均耗时仅
增加了 0.99 毫秒，但 1% 的请求的响应时间已经增加了 100 倍。
2. TP 90、TP 99 等分位值：这是将响应时间按照从小到大排序后的指标，TP 90 表示排在第 90 分位
的响应时间，分位值越大，对慢请求越敏感。
```

**可用性指标**

高可用性是指系统具有较高的无故障运行能力，可用性 = 平均故障时间 / 系统总运行时间，通常我们用
几个 9 来描述系统的可用性。

对于高并发系统，最低要求是保证 3 个 9 或者 4 个 9 。原因很直观，如果你只能做到 2 个 9 ，意味着有
1% 的故障时间，对于一些大公司每年千亿级别的 GMV 或收入，1% 的故障时间将导致十亿级别的业务
影响。

**可扩展性指标**

在面对突发流量时，我们不能临时改造架构，所以增加机器以线性提高系统的处理能力是最快的方式。

对于业务集群或基础组件，扩展性 = 性能提升比例 / 机器增加比例，理想的扩展能力是：资源增加几
倍，性能提升几倍。通常来说，扩展能力要保持在 70% 以上。

然而，从高并发系统的整体架构角度看，扩展的目标不仅仅是把服务设计成无状态，因为当流量增加
10 倍，业务服务可以快速扩容 10 倍，但数据库可能会成为新的瓶颈。

像 MySQL 这样的有状态存储服务通常是扩展的技术难点，如果架构上没有提前规划（垂直和水平拆
分），就可能涉及到大量数据的迁移。

因此，高扩展性需要考虑：服务集群、数据库、缓存和消息队列等中间件、负载均衡、带宽、依赖的第
三方等，当并发达到某一个量级后，上述每个因素都可能成为扩展的瓶颈点。

###### 7.3 实践方案

通用设计方法

**纵向扩展（scale-up）**

它的目标是提升单机的处理能力，方案又包括：

```
1. 提升单机的硬件性能：通过增加内存、CPU 核数、存储容量、或将磁盘升级成 SSD 等方式来提
升。
2. 提升单机的软件性能：使用缓存减少 IO 次数，使用并发或异步的方式增加吞吐量。
```
**横向扩展（scale-out）**

由于单机性能总有极限，所以最终还需要引入横向扩展，通过集群部署以进一步提高并发处理能力，包
括以下两个方向：

```
1. 做好分层架构：这是横向扩展的基础，因为高并发系统通常业务复杂，通过分层处理可以简化复杂
问题，更容易做到横向扩展。
2. 各层进行水平扩展：无状态水平扩容，有状态做分片路由。业务集群通常能设计成无状态的，而数
据库和缓存往往是有状态的，因此需要设计分区键做好存储分片，当然也可以通过主从同步、读写
分离的方案提升读性能。
```
**7.3.1 高性能实践方案**

```
1. 分布式部署，通过负载均衡分担单机压力。
```

```
2. 多层次缓存，包括静态数据使用 CDN、本地缓存、分布式缓存等，以及处理缓存场景中的热点
key、缓存穿透、缓存并发、数据一致性等问题。
3. 数据库和索引优化，以及利用搜索引擎解决复杂查询问题。
4. 考虑使用 NoSQL 数据库，如 HBase、TiDB 等，但团队需熟悉这些组件并具备强大的运维能力。
5. 异步处理，将次要流程通过多线程、消息队列、甚至延时任务进行异步处理。
6. 流量控制，考虑业务是否允许限流（如秒杀场景），包括前端限流、Nginx 接入层限流、服务端限
流。
7. 流量削峰填谷，通过消息队列接收流量。
8. 并发处理，通过多线程将串行逻辑并行化。
9. 预计算，如抢红包场景，可提前计算红包金额并缓存，发红包时直接使用。
10. 缓存预热，通过异步任务提前将数据预热到本地缓存或分布式缓存中。
11. 减少 IO 次数，如数据库和缓存的批量读写、RPC 的批量接口支持、或通过冗余数据减少 RPC 调
用。
12. 减少 IO 时的数据包大小，包括采用轻量级通信协议、合适的数据结构、去除接口中多余字段、减
少缓存 key 大小、压缩缓存 value 等。
13. 优化程序逻辑，如将高概率阻断执行流程的判断逻辑前置、For 循环计算逻辑优化，或采用更高效
算法。
14. 使用各种池化技术，如 HTTP 请求池、线程池（考虑 CPU 密集型或 IO 密集型设置核心参数）、
数据库和 Redis 连接池等。
15. JVM 优化，包括新生代和老年代的大小、GC 算法选择等，以减少 GC 频率和耗时。
16. 锁策略选择，读多写少场景使用乐观锁，或考虑通过分段锁减少锁冲突。
```
**7.3.2 高可用实践方案**

```
1. 节点故障转移，Nginx 和服务治理框架支持故障节点切换到另一个节点。
2. 非对等节点的故障转移，通过心跳检测并实施主备切换（如 Redis 哨兵模式或集群模式、MySQL
主从切换等）。
3. 设置接口层的超时、重试策略和幂等设计。
4. 降级处理，保证核心服务，牺牲非核心服务，必要时进行熔断；或核心链路出问题时，有备选链
路。
5. 流量控制，对超过系统处理能力的请求直接拒绝或返回错误码。
6. 消息队列的可靠性保证，包括生产者端的重试机制、消息代理的持久化、消费者端的 ack 机制
等。
7. 灰度发布，支持按机器维度进行小流量部署，观察系统日志和业务指标，运行稳定后再推全量。
8. 监控报警，包括基础 CPU、内存、磁盘、网络监控，以及 Web 服务器、JVM、数据库、各类中间
件监控和业务指标监控。
9. 灾备演练，类似当前的“混沌工程”，对系统进行破坏性手段，观察局部故障是否会引起可用性问
题。
```
高可用方案主要从冗余、取舍、系统运维三个方向考虑，同时需有配套的值班机制和故障处理流程，当
出现线上问题时，可及时跟进处理。

**7.3.3 高扩展的实践方案**

```
1. 合理的分层架构，例如互联网最常见的分层架构，还可以进一步按照数据访问层、业务逻辑层对微
服务进行更细粒度的分层（但需评估性能，会存在网络多一跳的情况）。
2. 存储层拆分，按照业务维度进行垂直拆分、按照数据特征维度进行水平拆分（分库分表）。
3. 业务层拆分，最常见的是按照业务维度拆（如电商场景的商品服务、订单服务等），也可以按照核
心接口和非核心接口拆，还可以按照请求去拆（如 To C 和 To B，APP 和 H 5）。
```

#### 说在最后

部署架构、节点规划相关面试题，是非常常见的面试题。

以上的内容，如果大家能对答如流，如数家珍，基本上面试官会被你震惊到、吸引到。

最终， **让面试官爱到 “不能自已、口水直流”** 。offer，也就来了。

学习过程中，如果有啥问题，大家可以来找 40 岁老架构师尼恩交流。

#### 参考文献

https://zhuanlan.zhihu.com/p/422165687

#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》


## 消息推送架构设计

#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，最近有小伙伴拿到了一线互联网企业如阿里、网易、有
赞、希音、百度、网易、滴滴的面试资格，遇到一几个很重要的面试题：

```
企业级消息通知系统有哪些需求？如何满足？
企业级消息通知系统，该如何做架构设计？
```
**尼恩提示，系统架构相关的问题，是架构的核心知识，又是线上的重点难题。**

所以，这里尼恩给大家做一下系统化、体系化的梳理，使得大家可以充分展示一下大家雄厚的 “技术肌
肉”， **让面试官爱到 “不能自已、口水直流”** 。

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 103 版本，供后面的小伙伴参
考，提升大家的 3 高架构、设计、开发水平。

```
最新《尼恩架构笔记》《尼恩高并发三部曲》《尼恩 Java 面试宝典》的 PDF，请关注本公众号
【技术自由圈】获取，回复：领电子书
```

#### 架构目标：

构建企业级统一基础推送服务，支持通过多渠道推送，能够统一集成的电子邮件、短信、聊天、钉钉、
企业微信和其他公共社交应用：

```
聊天 - 微信 Wechat/QQ
站内推送通知（移动设备和 Web 浏览器）
站外推送通知（移动设备，APP 没有开启）
短信（如登录密码、营销活动）
电子邮件
钉钉
企业微信
```
企业级统一基础推送服务，是一个通用特性，适用于所有现代分布式应用，无论采用何种编程语言和技
术。

#### 推送能力的演进

###### 第一阶段（模块化）：各自为政、各自封装

企业内部，早期业务量比较少，各系统基本都是有自己的推送模块，类型也是五花八门：

```
聊天模块
短信模块
电子邮件模块
websocket 模块
```
各自封装模块比较简单，但是实现分散、各系统模块的质量也很难统一保证。

###### 第二阶段（框架化）：集成框架

为了减少重复性设计、开发成本，设计了统一的推送框架

同一套微服务框架，共用一个统一的推送框架

为了解决上述分散实现的问题，企业内部统一实现了一个综合各类推送功能的基础库，供业务方统一调
用。

```
聊天基础 starter
短信基础 starter
电子邮件基础 starter
websocket 基础 starter
```
于是，我们把 springboot-starter 的逻辑封装到了 **服务治理框架内** ，微服务服务启动时，每一个服务对
各种的 starter 进行运维管理、配置管理。

###### 第三阶段（服务化）：推送服务

集成到框架，每一套服务，都需要重复性的解决 3 高问题。


```
推送服务，数据量大，需要解决跨库查询问题
推送服务，性能要求高，需要解决高并发问题
```
大数据量、并发量高，意味着：

```
硬件资源投入大
运维成本高
```
这样的基础服务，需要进行沉淀，剥离，集中成统一的、基础服务，由专门团队负责维护、迭代、运
维。降低重复投入、重复建设成本，真正的降本增效。

**于是，推送框架演进为推送服务**

#### 推送服务在业务系统中的位置

一个业务应用，基本上有很多原子服务编排、整合而来，最终构建出一个完整的架构图。

```
接入层，这是外部请求进入内部系统的门户，所有的请求都必须通过 API 网关。
应用层，也被称为聚合层，它为相关业务提供聚合接口，并调用中台服务进行组合。
原子服务，包括就是原子技术服务，原子业务服务，根据业务需求提供相关的接口。原子服务为整
个架构提供可复用的能力。
```
例如，在 B 站视频网站平台上，评论服务作为一项原子服务，在 B 站的视频、文章、社区都需要，那么为
了提高复用性，评论服务就可以独立为原子服务，不能与特定需求紧密耦合。

在这种情况下, 评论服务，需要供一种可以适应不同场景的复用能力。

```
注意：请点击图像以查看清晰的架构图！
```
类似的，文件存储、数据存储、推送服务、身份验证服务等功能，都会沉淀为原子服务，业务开发人
员，在原子服务基础上，进行编排、配置、组合，可以快速构建业务应用。


当然，本文仅仅聚焦推送服务。其他的原子服务， 40 岁老架构师尼恩，会以其他的文章进行专文介
绍，具体请大家持续关注尼恩的公众号，技术自由圈。

#### 推送服务功能要求：

```
发送通知
对通知进行优先级排序
根据客户的保存偏好发送通知
支持单个/简单的通知消息和批量通知消息
各种通知的分析用例
通知消息的报告
```
#### 推送非功能性需求（NFR）：

```
高性能 ： qps > 1 W
高可用性 （HA）： 99.99%
低延迟 ： TP 99 在 10 ms 以下
高扩展 ： 可扩展/可插拔的设计，以便添加更多适配器和提供商，与所有通知模块的 API 集成以及
与客户端和服务提供商/供应商的外部集成
跨平台 ：支持 Android/iOS 移动设备和桌面/笔记本电脑的 Web 浏览器
自伸缩 ：可在本地（VMware Tanzu）和 AWS、GCP 或 Azure 等公共云服务上扩展负载
```
#### 推送系统设计架构：

```
注意：请点击图像以查看清晰的架构图！
```
这些解决方案设计的考虑因素和组件包括：


###### 1. 通知客户端：

这些客户端通过 API 调用请求单个和批量消息。它们将向简单和批量通知服务发送通知消息。

```
简单通知客户端 ：专门用于发送单个通知的客户端，负责向用户发送单一通知。这些客户端通常用
于向特定用户发送重要通知，例如密码找回或账户异常提醒。
批量通知客户端 ：专门用于发送批量通知的客户端，负责向用户批量推送通知。这些客户端通常用
于需要通知大量用户的场景，例如企业内部通知或营销活动。
```
###### 2. 通知服务：

作为入口点的这些服务，通过暴露 REST API 与客户端互动。

它们负责构建通知消息，通过调用"模板服务"。这些消息将使用"验证服务"进行验证。

```
简单通知服务 ：该服务将提供 API，主要负责处理简单通知请求，提供与后端服务集成的 API，以
便将通知发送给用户。这种服务通常用于处理较少的通知请求，例如针对特定用户或事件的简单通
知。
批量通知服务 ：该服务将提供 API，主要负责处理批量通知请求，提供与后端服务集成的 API，以
便批量发送通知。这种服务通常用于处理大量的通知请求，例如企业内部的批量通知或营销活动的
批量推送。
```
此服务还将管理通知消息。它将发送的消息持久化到数据库并维护活动日志。

可以使用这些服务的 API 重新发送同一条消息。

它将提供添加/更新/删除和查看旧消息和新消息的 API。

它还将提供 Web 仪表板，该仪表板应具有筛选选项，以根据不同的条件（如日期范围、优先级、模块
用户、用户组等）筛选消息。

###### 3. 模板服务：

此服务主要负责所有可用的一次性密码（OTP）、短信、电子邮件、聊天以及其他推送通知消息的模板
管理。

它还提供了 REST API，以便创建、更新、删除和管理模板。

除此之外，它还将提供一个用户界面（UI）的仪表板页面，使用户能从网络控制台检查和管理各种消息
模板。

###### 4. 消息分发服务

```
定时分发服务：
```
该服务将提供 API 来安排立即或指定时间的通知。可以是以下任何一种：

```
秒
分钟
每小时
每天
每周
```

```
每月
每年
自定义频率等。
```
还可能有其他自动触发的服务，基于预定时间进行消息触发。

```
消息验证服务：
```
此服务全权负责根据业务规定和预期格式对通知信息进行核实。批量通知需由授权的系统管理员同意。

```
消息优先级服务：
```
该服务负责对通知进行优先级排序，分为高、中、低三个等级。

通知信息具有较高的优先级和有时间限制的到期时间，它们将始终以较高优先级发送。

"通用出口处理器"会接收消息并根据相同的优先级从高、中和低三个不同的队列中发送和处理。

在非工作时间，可以以低优先级发送批量通知。

在交易过程中的应用程序通知可以发送到中优先级，如电子邮件等。企业可以根据通知的重要性确定优
先级。

###### 5. 事件优先级队列（消息队列）：

此服务提供事件中心功能，负责接收通知服务的高、中、低三个优先级的信息。

它会根据业务的优先级来发送和接收通知。企业可以根据通知的重要性来设定优先级。

服务内部包含三个主题，用于根据业务优先级接收和发送通知：

```
低优先级 ：主要用于在非工作时间发送批量通知。
中优先级 ：适用于在交易过程中发送的应用程序通知，如电子邮件等。
高优先级 ：通知信息具有较高的优先级和有时间限制的到期时间，它们将始终以较高优先级发送。
```
###### 6. 通用出站处理程序：

该服务通过轮询事件优先级队列来接收事件中心中的通知信息，并根据其优先级进行处理。

高优先级的通知会优先处理"高"队列，依次类推。

最后，它通过事件中心将通知信息发送到特定的适配器。

此外，该服务还从用户选择服务中获取目标用户/应用程序，以便进行通知的分发。

在处理过程中，通用出口处理器会根据事件的优先级进行相应的操作，确保重要事件得到优先处理。

这样，企业可以根据通知的优先级来确定处理顺序，从而提高通知的处理效率。

除此之外，通用出站处理程序，还能进行消息的进一步按照通道类型进行分发：

该服务将消息发送到各种支持的适配器。

这些适配器会根据不同的设备（如桌面/移动设备）和通知类型（如短信/OTP/电子邮件/聊天/推送通
知）进行转换。


###### 7. 通知适配器：

这些转换器将从消息队列（rocketmq）接收传入信息并根据其所支持的格式传递给外部合作伙伴。

以下是一些转换器，根据需求可以增加更多：

```
QQ 通知适配器服务
微信 Wechat 聊天通知适配器服务
应用内通知适配器服务
电子邮件适配器服务
短信适配器服务
OTP 适配器服务
```
###### 8. 通道供应商：

这些是外部的 SAAS（云上/本地）服务提供商，利用它们的基础设施和技术实现实际的通知传递。

它们可能是像 AWS SNS、MailChimp 等的付费推送通道服务。

```
QQ 供应商集成服务
微信 Wechat 供应商集成服务
应用推送通知供应商集成服务
电子邮件供应商集成服务
短信供应商集成服务
```
###### 9. 用户选择服务：

该服务提供选择目标用户和各种应用程序模块的功能。

这可能包括将批量消息发送到特定的用户组或不同的应用程序模块。

可能是 AD/IAM/eDirectory/用户数据库/用户组，具体取决于客户的偏好。

在服务内部，它将使用"用户配置文件服务"API 来消费和检查客户的通知偏好。

###### 10. 用户配置文件服务：

此服务提供各种功能，包括管理用户配置文件及其偏好设置。

还管理内部用户标识，和外部通道标识之间的关联关系

```
钉钉用户标识和用户标识关联关系
企业微信用户标识和用户标识关联关系
用户和邮箱的关联关系
等等
```
它还将提供取消订阅通知以及通知接收频率等功能。


"通知服务"将依赖于此服务，以便根据用户的通知偏好来发送通知。

此外，该服务还可以用于统计和分析用户对通知的偏好，以帮助企业优化通知策略。

###### 11. 分析服务

该处理器将负责执行所有的分析工作，识别通知使用情况、趋势并生成报告。

它将从分析数据库（Cassandra）和通知数据库中提取所有最终的通知信息，用于分析和报告目的。

以下是一些用例：

```
每天/每秒的总通知数
哪个通知系统使用最频繁
消息的平均大小和频率
基于优先级过滤消息等等...
```
###### 12. 通知跟踪器

此服务将持续监视事件中心队列并跟踪所有发送的通知。

它捕获通知的元数据，如传输时间、传送状态、通信渠道、消息类型等。

###### 13. 通知数据库：Mysql 数据库集群

通知数据库，用于存储库用于存储所有通知信息，包括发送时间、状态等。

它包括一个数据库集群，其中领导者用于执行所有写操作，读取操作则在读取副本/跟随者上进行。

这个数据库群集将持久化所有通知，供分析和报告使用。

它基于“写入更多，读取更少”的理念。

它能提供良好的性能和低延迟，适应大量的通知，因为它内部处理大量的写操作，并与其他数据库节点
同步，保持高可用性和可靠性的冗余数据/消息。

在任何节点崩溃的情况下，消息将始终可用。

当然，也可以是 nosql 集群型数据库。

#### 说在最后

推送服务等基础技术的相关面试题，是非常常见的面试题。

以上的内容，如果大家能对答如流，如数家珍，基本上面试官会被你震惊到、吸引到。

最终， **让面试官爱到 “不能自已、口水直流”** 。offer，也就来了。

学习过程中，如果有啥问题，大家可以来找 40 岁老架构师尼恩交流。


#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》


## 百亿级访问，如何做缓存架构

#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，最近有小伙伴拿到了一线互联网企业如阿里、网易、有
赞、希音、百度、网易、滴滴的面试资格，遇到一几个很重要的面试题：：

```
分布式缓存系统，如何架构？
百亿级访问，如何做缓存架构？
```
**最近，有个小伙伴微博一面，又遇到了这个问题：百亿级访问，如何做缓存架构？**

接下来，尼恩借助微博 Cache 架构的设计实践案例，为大家揭晓这个问题的答案。

本文非常重要。大家可以收藏起来，慢慢消化和掌握。


为啥呢？在现代互联网应用中，分布式缓存已经成为了应用性能优化的标配。一个好的缓存系统需要具
有高可用性、高性能，并且能够保证数据的一致性和容错性。

本文将介绍如何设计高可用的分布式缓存架构，包括架构基础知识、整体架构设计、实现原理、一致性
模型以及故障处理。

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典 PDF》V 101 版本，供后面的小伙伴
参考，提升大家的 3 高架构、设计、开发水平。

```
最新《尼恩架构笔记》《尼恩高并发三部曲》《尼恩 Java 面试宝典》的 PDF，请关注本公众号
【技术自由圈】获取
```
#### 分布式缓存系统架构基础知识

在分布式系统中，缓存系统的构建是关键一环，其基础架构主要包括以下几个重要部分：

```
数据分片
```
为了防止单一节点压力过大，导致系统崩溃，我们需要对缓存数据进行分片。这样，不同的缓存节点就
可以分别管理不同的数据片，并负责处理相关的读写请求。这种分片的方式，既可以有效地分散数据压
力，也能提高系统的响应速度。

```
负载均衡
```
当客户端发起请求时，我们需要选取一个适当的缓存节点来处理。这就需要负载均衡算法的介入，该算
法可以根据当前系统的负载情况、网络拓扑结构等因素，来选择最适合处理该请求的节点。这样，既可
以保证客户端请求的及时响应，也能避免某个节点压力过大，影响系统的整体运行。

```
容错处理
```
在分布式环境下，由于网络通信等问题，可能会导致缓存节点间的故障。为了提高系统的可用性，我们
需要设计一些容错机制。例如，数据备份可以防止数据丢失，故障转移可以确保即使某个节点出现问
题，系统也能继续运行。这些容错机制，可以有效地提高系统的稳定性和可靠性。

```
数据一致性
```
由于数据在多个节点上进行分布存储，因此需要确保数据的一致性。为了实现这一目标，我们需要采用
一些协议和算法来处理并发读写操作。例如，我们可以使用分布式事务协议来确保数据的原子性和一致
性，或者使用乐观锁算法来避免并发写操作的冲突。这些手段，都可以有效地保证数据的一致性，确保
系统的正确运行。

###### 整体架构设计

在构建一个具有高可用性和高并发能力的分布式缓存系统时，以下几个方面是必须要考虑的：

```
缓存服务节点
```
一个缓存服务节点负责处理对应的数据分片，同时提供各类缓存操作的接口。通过使用多个缓存服务节
点，我们可以构建一个缓存集群，从而提升系统的可扩展性和可用性。

```
共享存储设备
```
共享存储设备用于存放缓存数据和元数据，这些数据能够被多个缓存服务节点所共享。常见的共享存储
设备包括分布式文件系统、分布式块存储以及分布式对象存储等。

```
负载均衡设备
```
负载均衡设备的作用是将客户端的请求分发到适当的缓存服务节点，并且可以根据缓存服务节点的负载
状况进行动态调整。


```
配置服务
```
配置服务负责维护和管理缓存系统的元数据信息，包括节点信息、分片信息、负载均衡规则以及故障转
移设置等。

###### 实现原理

一个分布式缓存系统的实现需要涉及到很多技术，如数据分片算法、负载均衡算法、容错处理算法、一
致性算法等。

###### 数据分片算法

在分布式缓存系统中，数据分片算法是一项关键技术。常见的数据分片算法包括哈希算法、范围算法、
顺序算法以及随机算法等。哈希算法作为最常用的分片算法之一，它能够通过哈希函数将数据的键值映
射为一个数字，进而根据这个数字进行分片。

```
负载均衡算法
```
负载均衡策略在缓存系统中起着至关重要的作用。它需要综合考虑缓存节点的负载状况、网络拓扑以及
客户端请求等多个因素。常见的负载均衡策略包括轮询策略、最少连接数策略、IP 哈希策略以及加权轮
询策略等。

```
一致性算法
```
在分布式环境下，数据一致性是一个核心问题。当多个客户端同时对同一个键值进行读写操作时，需要
确保数据的一致性。

常见的一致性算法包括 Paxos 算法、Raft 算法以及 Zab 算法等。

```
强一致性和最终一致性的区别
```
强一致性是指所有客户端在读取同一个键值时，都能得到相同的结果。而最终一致性是指，如果客户端
在缓存节点中写入了数据，那么在未来的某个时间点，所有的缓存节点最终会拥有相同的数据。

强一致性可以通过复制数据来实现，但这可能会对系统的性能和可用性产生影响。最终一致性则可以通
过异步复制和协议算法来实现，从而在一定程度上提高系统的性能和可用性。

```
如何处理故障和异常
```
在分布式缓存系统中，故障和异常是不可避免的。为了确保系统的可用性，我们需要采取一系列措施来
处理故障和异常，如数据备份、故障转移、数据恢复以及监控告警等。同时，还需要定期对系统进行维
护和优化，以确保系统的高可用性和高性能。

###### 分布式缓存系统架构总结

本文详细介绍了如何构建高可用的分布式缓存系统，包括架构基础知识、整体架构设计、实现原理、一
致性模型以及故障处理等方面。一个优秀的缓存系统需要具备高可用性、高性能，并能保证数据的一致
性和容错性。

#### 百亿级访问，微博如何做缓存架构？

微博作为拥有 1.6 亿 + 日活跃用户，每日访问量达百亿级的大型社交平台，其高效且不断优化的缓存体
系在支撑庞大用户群的海量访问中起到了至关重要的作用。

首先是微博在运行过程中的数据挑战，然后是 Feed 系统架构，


接下来会着重分析 Cache 架构及演进，最后是总结、展望。

###### 微博的访问流量挑战

###### 微博 Feed 平台系统架构


整个系统可以分为五个层次，最顶层是终端层，例如 Web 端、客户端（包括 iOS 和安卓设备）、开放
平台以及第三方接入的接口。接下来是平台接入层，主要是为了将优质资源集中分配给关键核心接口，
以便在突发流量时具备更好的弹性服务能力，提高服务稳定性。再往下是平台服务层，主要包括 Feed
算法、关系等。然后是中间层，通过各种中间介质提供服务。最底层是存储层，整个平台架构大致如
此。

**1. Feed timeline**

```
构建流程
```
当我们在日常生活中使用微博时，例如在主页或客户端刷新一下，会看到最新的十到十五条微博。那么
这个过程是如何实现的呢？

刷新操作会获取到用户的关注关系，例如 1000 个关注，就会获取这 1000 个 ID，根据这 1000 个 UID，
获取每个用户发布的微博，同时会获取这个用户的 Inbox，就是她收到的特殊的一些消息。

比如分组的一些微博，群的微博，下面她的关注关系，她关注人的微博列表，获取这一系列微博列表之
后进行集合、排序，从而获取需要的微博 ID，再对这些 ID 去取每一条微博 ID 对应的微博内容。

如果这些微博是转发的，还会获取原微博，并根据原微博获取用户信息，通过原微博取用户信息，进一
步根据用户的过滤词对这些微博进行过滤，过滤掉用户不想看到的微博，留下这些微博后，再进一步来
看，用户对这些微博有没有收藏、赞，做一些 flag 设置，还会对这些微博各种计数，转发、评论、赞数
进行组装，最后才把这十几条微博返回给用户的各种端。


这样看，用户一次请求会得到十几条记录，后端服务器需要对几百甚至几千条数据进行实时处理并返回
给用户，整个过程对 Cache 体系强度依赖。因此，Cache 架构设计优劣会直接影响微博系统的表现。

**2. Feed Cache 架构**

然后我们看一下 Cache 架构，它主要分为六层：

```
第一层 Inbox ，这部分主要包括分组微博和群主微博，Inbox 的数量相对较少，主要采用推送方
式。
第二层 Outbox ，每个用户都会发布常规微博，这些微博都会存储在 Outbox 中，根据存储的 ID
数量，实际上被划分为多个缓存，通常情况下大约有 200 多，如果是长的大概是 2000 条。
第三层 Social Graph ，就是一些关系，包括关注、粉丝和用户。
第四层 Content ，是内容，每条微博的一些内容都存储在这里。
第五层 Existence ，是存在性判断，例如微博中，某条微博是否被点赞过，有些明星曾经表示自己
在某条微博上点赞了，但实际上没有，这会引起一些新闻，实际上是因为她在某个时刻点赞后忘记
了。
第六层 Counter ，是计数，包括微博的评论、转发等计数，以及用户的关注数、粉丝数等数据。
```
###### 微博 Cache 架构及演进

**1. 简单 KV 数据类型**


接下来，我们会重点讨论微博 Cache 架构演进过程，在微博刚上线时，我们把它作为一个简单的 KV 键值
对数据类型来存储，我们主要采取哈希分片存储在 MC 池中，而，上线几个月后，我们发现了一些问
题，比如由于某些节点机器宕机或其他原因，大量的请求会穿透 Cache 层达到 DB 上去，从而导致整个请
求速度变慢，甚至 DB 僵死。

为了解决这个问题，我们迅速对系统进行了改造，增加了一个高可用（HA）层。这样，即使主层出现
某些节点宕机或无法正常运行的情况，请求也会进一步穿透到 HA 层，而不会穿透到 DB 层，这样可以确
保在任何情况下，系统的命中率都不会降低，从而显著提高系统服务的稳定性。

目前，这种做法在业界得到了广泛应用。然而，有些人直接使用哈希技术，这其实是有一些风险的。例
如，如果一个节点（如节点 3 ）宕机了，主层会将其摘除，并将节点 3 的一些请求分配给其他节点。如
果这个业务量不是很大，数据库可以承受住这种压力。但是，如果节点 3 恢复后重新加入，它的访问量
会回来，如果因为网络或其他原因再次宕机，节点 3 的请求又会分配给其他节点。这时就可能会出现问
题，之前分配给其他节点的请求已经没有人更新，如果没有被及时删除，就会出现数据混乱的情况。


微信和微博之间存在很大差异。实际上，微博更像是一个开放的广场型业务。例如，在突发事件或某明
星恋情曝光等情况下，瞬间流量可能会激增至 30%。在这种情况下，大量的请求会集中出现在某些节点
上，使得这些节点变得异常繁忙，即使使用 MC 也无法满足如此巨大的请求量。这时，整个 MC 层就会
成为瓶颈，导致整个系统变慢。为了解决这个问题，我们引入了 L 1 层，它实际上是一个主关系池。每
个 L 1 层的大小约为 Main 层的六分之一、八分之一或十分之一，具体取决于请求量。在请求量较大
时，我们会增加 4 到 8 个 L 1 层。这样，当请求到来时，首先会访问 L 1 层。如果 L 1 层命中，请求就会
直接访问；如果没有命中，请求会继续访问 Main-HA 层。在突发流量情况下，L 1 层可以承受大部分热
请求，从而减轻微博的内存压力。对于微博来说，新数据会变得越来越热门，而只需要增加很少的内
存，就可以应对更大的请求量。

```
Key Point
Memcached 为主
层内 HASH 节点不漂移，miss 则穿透
多组 L 1 读取性能升峰值流量成本降读写策略
Write：多写
Read：逐层穿透，miss 回写
Json/xml --> Protocol Buffer
QuickLZ 压缩
```
总结一下，我们通过简单的 KV 数据类型存储，主要以 MC 为主，层内 HASH 节点不漂移，Miss 则穿
透到下一层读取。通过多组 L 1 读取性能提升，可以应对峰值和突发流量，同时降低成本。对于读写策
略，我们采用多写，读的话采用逐层穿透，如果 Miss 就进行回写。对于存储的数据，我们最初采用
Json/xml， 2012 年后直接采用 Protocol|Buffer 格式，对于较大的数据，我们使用 QuickL 进行压缩。

**2. 集合类数据**

```
业务特点
部分修改
分页获取
资源计算：联动计算
类型：关注，粉丝，分组，共同关注，XX 也关注
方案：Redis
Hash 分布，MS，cache/storage
30+T 内存，2-3 万亿 rw/day
```
关于简单的 QA 数据，我们已经知道如何处理。但是对于复杂的集合类数据，例如关注了 2000 个人，
新增一个人就涉及到部分修改。有一种方式是把 2000 个 ID 全部拿下来进行修改，这样会带来更大的
带宽和机器压力。还有一些分页获取的需求，例如我只需要取其中的第几页，比如第二页，也就是第十
到第二十个，能否不要全量把所有数据取回去。还有一些资源的联动计算，例如关注某些人里面的 ABC
也关注了用户 D，这种涉及到部分数据的修改、获取和计算，对于 MC 来说，它实际上并不擅长。所有
的关注关系都存在 Redis 里面，通过 Hash 分布和储存，一组多存的方式来进行读写分离。现在 Redis
的内存大概有 30 个 T，每天都有 2-3 万亿的请求。


```
Redis 扩展 (Longset)
Long 型开放数组，Double Hash 寻址
Client 构建数据结构，elements 单次写入
Lsput：填充率过高，由 client 重建
Lsgetall --> Lsdump
少量而超热数据：mc 抗读
```
在使用 Redis 的过程中，我们还是遇到了一些其他问题。例如，从关注关系来看，我关注了 2000 个
UID，有一种方式是全量存储，但是微博有大量的用户，有些用户登陆比较少，有些用户特别活跃，这
样全部放在内存里面成本开销是比较大的。所以我们就把 Redis 使用改成 Cache，只存活跃的用户，如
果你最近一段时间没有活跃，会把你从 Redis 里面踢掉，再次有访问到你的时候再把你加进来。但是，
Redis 的工作机制是单线程模式，如果它加某一个 UV，关注 2000 个用户，可能扩展到两万个 UID，两
万个 UID 塞回去基本上 Redis 就卡住了，没办法提供其他服务。因此，我们扩展了一种新的数据结构，
两万个 UID 直接开了端，写的时候直接依次把它写到 Redis 里面去，读写的整个效率就会非常高，它的
实现是一个 long 型的开放数组，通过 Double Hash 进行寻址。

```
Redis 其他扩展
热升级: 10+分钟>毫秒级
AOF : Rotate
RDB : Pos of AOF
全增量复制
落地/同步速控
```

对于 Redis，我们还进行了一些其他的扩展。例如，之前的一些分享中，大家可以在网上看到，我们把
数据放到公共变量里面，整个升级过程，我们测试 1 G 的话加载要 10 分钟，10 G 大概要十几分钟以
上，现在是毫秒级升级。对于 AOF，我们采用滚动的 AOF，每个 AOF 是带一个 ID 的，达到一定的量再
滚动到下一个 AOF 里面去。对于 RDB 落地的时候，我们会记录构建这个 RDB 时，AOF 文件以及它所
在的位置，通过新的 RDB、AOF 扩展模式，实现全增量复制。

**3. 其他数据类型-计数**

```
业务特点
单 key 有多计数 (微博/用户多种计数)
Value size 较小 (2-8 个字节)
每日新增记录近十亿级，总记录千亿级
单次请求多条 kv
```
接下来，我们将讨论其他一些数据类型，例如计数。实际上，在互联网公司的每个领域，计数都是必不
可少的。对于一些中小型业务，MC 和 Redis 已经足够满足需求。然而，在微博中，计数具有一些特殊
性，例如一条微博可能有多个计数，包括转发数、评论数和点赞数。此外，一个用户可能有粉丝数、关
注数等各种数字。由于计数的特性，其 Value size 通常较小，大约为 2-8 个字节，最常见的是 4 个字
节。每天新增的微博大约有十亿条记录，总的记录数量则更为庞大。在一次请求中，可能需要返回数百
条计数。

```
选型 1 ：Memcached
MC 剔除，重启数据丢失
大量计数为 0 ，如何存
选型 2 ：Redis
内存有效负荷低
访问性能
最终方案：自研 CounterService
Shema 支持多列，按 bit 分配
Tables 预分配，double-hash 寻址
内存降为 1/5-1/15 以下
冷热分离，SSD 存放老数据，老热数据入 LRU
落地 RDB + AOF 全增量复制
单机：热数据百亿级，冷数据千亿级
```
**4. 计数器-Counter Service**

最初，我们选择使用 Memcached，但它存在一个问题，即当计数超过其容量时，会导致部分计数被剔
除，或在宕机或重启后计数将丢失。此外，有许多计数为零，此时如何存储，是否需要存储，以及如何
避免占用大量内存等问题需要考虑。微博每天有十亿计数，仅存储零值就会占用大量内存。如果不存
储，可能会导致穿透到数据库层，从而影响服务性能。


从 2010 年开始，我们转向使用 Redis 进行访问。然而，随着数据量的不断增加，我们发现 Redis 的内
存利用率相对较低。一条 KV 大约需要 65 个字节，但实际上我们只需要 8 个字节来存储一个计数，加
上 Value 的 4 个字节，实际有效存储只有 12 个字节。其余的 40 多个字节被浪费。这还只是单个 KV 的
情况，如果一个 Key 有多个计数，浪费的空间会更多。例如，四个计数，一个 Key 占 8 个字节，每个
计数占 4 个字节，总共需要 16 个字节，但实际上只用了 26 个字节。

然而，使用 Redis 存储需要约 200 个字节。后来，我们通过自主研发 Counter Service，将内存使用量
降低到 Redis 的五分之一至十五分之一以下。同时，我们实现了冷热数据分离，将热数据存储在内存
中，将冷数据放入 LRU 中。当冷数据重新变热时，将其放到 RDB 和 AOF 中，实现全增量复制。通过
这种方式，单机可以存储百亿级的热数据和千亿级的冷数据。

整个存储架构的概述如下：顶部是内存，底部是 SSD。内存中预先划分为 N 个 Table，每个 Table 根据
ID 的指针序列分配一定范围。当有新的 ID 过来时，首先找到它所在的 Table，然后进行增加或减少操
作。当内存不足时，将一个小 Table 导出到 SSD 中，并保留新的位置以供新的 ID 使用。

有人可能会有疑问，如果在某个范围内，ID 的计数原本设定为 4 个字节，但由于微博的热度，计数超
过了 4 个字节，变成了很大的一个计数，这种情况如何处理？对于超过限制的计数，我们将其存放在
Aux dict 中。对于存储在 SSD 中的 Table，我们有专门的 IndAux 进行访问，并通过 RDB 方式进行复
制。

**5. 其他数据类型-存在性判断**

```
业务类型需求
检查是否存在 (阅读赞)
单条记录量小，value 1 bit (0/1)
总数据量巨大，大量 value 为 0
每日新增数量大千亿级
```

除了计数之外，微博还有一些业务，如存在性判断。例如，一条微博是否已获得点赞、阅读或推荐。如
果用户已经阅读过该微博，就不再向其显示。这类数据的特点是，虽然每条记录非常小（例如，Value
只需 1 个 bit），但总数据量巨大。例如，微博每天发布约 1 亿条新微博，阅读量可能达到上百亿、上
千亿。如何存储这些数据是一个大问题。而且其中许多存在性为 0 。前面提到的问题再次出现： 0 是否
需要存储？如果存储，每天将存储上千亿条记录；如果不存储，大量请求将穿透 Cache 层到达 DB 层，
任何 DB 都无法承受如此大的流量。

```
选型 1 ：Redis
单条 kv：65 bytes
每日新增内存 6 T (不考虑 HA)
选型 2 ：CounterService
单条 kv：9 bytes
每日新增内存 900 G (不考虑 HA)
```
我们也进行了一些选型，首先直接考虑我们能不能用 Redis，单条 KV 65 个字节，一个 KV 可以 8 个字节的
话，Value 只有 1 个 bit，这样算下来我每日新增内存有效率是非常低的。第二种我们新开发的 Counter
Service，单条 KV Value 1 个 bit，我就存 1 个 byt，总共 9 个 byt 就可以了，这样每日新增内存 900 G，存的
话可能就只能存最新若干天的，存个三天差不多快 3 个 T 了，压力也挺大，但比 Redis 已经好很多。

```
最终方案：自研 Phantom
Table 分段预分配，段内 bloomfilter
每条 kv：1.2 bytes (1%误判)
每日新增内存：120 G < 800 G < 6 T
```
我们最终方案采用自己开发 Phantom，先采用把共享内存分段分配，最终使用的内存只用 120 G 就可
以，算法很简单，对每个 Key 可以进行 N 次哈希，如果哈希的某一个位它是 1 ，如果进行 3 次哈希，三个
数字把它设为 1 ，把 X 2 也进行三次哈希，后面来判断 X 1 是否存在的时候，进行三次哈希来看，如果都为
1 就认为它是存在的，如果某一个哈希 X 3，它的位算出来是 0 ，那就百分百肯定不存在的。


```
Phantom 系统架构
数据存放共享内存，重启不丢失数据
落地 RDB+AOF
兼容 Redis 协议
```
它的实现架构比较简单，把共享内存预先拆分到不同 Table 里面，在里面进行开方式计算，然后读写，
落地的话采用 AOF+RDB 的方式进行处理。整个过程因为放在共享内存里面，进程要升级重启数据也不
会丢失。对外访问的时候，建 Redis 协议，它直接扩展新的协议就可以访问我们这个服务了。

**6. 小结**

```
关注点
集群内高可用
集群内扩展性
组件高性能
存储成本
```

小结一下，到目前为止，关注 Cache 集群内高可用、它的扩展性，包括它的性能，还有一个特别重要就
是存储成本，还有一些我们没有关注到，比如 21 运维性如何，微博现在已经有几千差不多上万台服务器
等等。

**7. 进一步优化**

面向资源/组件管理

```
如何简化运维？
```
本地配置模式

```
如何快速变更？
```
常规峰值、突发流量

```
如何快捷、低成本应对？
```
业务数据分类多

```
如何独立管控 SLA？
```
业务关联资源太多

```
如何简化开发？
```
**8. 服务化**

```
本地 Confs --> 配置服务化
configServer 管理配置/服务，避免频繁重启
资源/服务管理 API 化
变更方式：script 修改，smart client 异步更新
```
采取的方案首先就是对整个 Cache 进行服务化管理，对配置进行服务化管理，避免频繁重启，另外如果
配置发生变更，直接用一个脚本修改一下。

```
Cache 访问
Proxy 化
IDC 数据一致性
Collecting/replication
```

```
ClusterManager
脚本化 --> Web 界面化
服务校验业务 SLA
面向服务管控资源
服务治理
扩容、缩容
SLA 保障
监控报警
故障处理
简化开发
屏蔽 Cache 资源细节
单行配置访问
```
服务化还引入 Cluster Manager，实现对外部的管理，通过一个界面来进行管理，可以进行服务校验。
服务治理方面，可以做到扩容、缩容，SLA 也可以得到很好保障。另外对于开发来说，现在就可以屏蔽
Cache 资源。

#### 总结与展望


最后简单总结一下，对于微博 Cache 架构来说，从它数据架构、性能、储存成本、服务化不同方面进行
优化增强。

#### 参考文献

https://blog.csdn.net/java_cpp_/article/details/130663371

https://blog.csdn.net/k6T9Q8XKs6iIkZPPIFq/article/details/108271182

#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》


《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》

## 多级缓存架构设计

#### 说在前面

在 40 岁老架构师尼恩的 **读者社区** (50+) 中，很多小伙伴拿到一线互联网企业如阿里、网易、有赞、希
音、百度、网易、滴滴的面试资格，多次遇到一个很重要的面试题：

```
20 w 的 QPS 的场景下，服务端架构应如何设计？
10 w 的 QPS 的场景下，缓存架构应如何设计？
```

尼恩提示， **缓存架构、缓存规划、缓存淘汰、多级缓存的数据一致性** 相关的问题，是架构的核心知识，
又是线上的重点难题。

另外，尼恩一直給大家指导简历，辅导架构转型。前几天指导美团一个超级大佬 L 9 的简历，也谈到了
缓存的这些难题，需要提供一些解决方案，给他作为：

```
第一：学习材料
第二：架构轮子。
```
基于以上原因，尼恩基于《京东服务端应用多级缓存架构方案》以及《有赞透明多级缓存解决方案
（TMC）》，给大家做一下系统化、体系化的梳理。从而，再面试的时候，使得大家可以充分展示一下
大家雄厚的 “技术肌肉”， **让面试官爱到 “不能自已、口水直流”** 。

也一并把这个题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》V 105 版本，供后面的小伙伴参
考，提升大家的 3 高架构、设计、开发水平。

```
《尼恩架构笔记》《尼恩高并发三部曲》《尼恩 Java 面试宝典》的 PDF，请到公号【技术自由
圈】获取
```
#### 高并发场景分析

一般来说，如果 10 Wqps，或者 20 Wqps ，可使用分布式缓存来抗。

比如 redis 集群， 6 主 6 从：主提供读写，从作为备，从不提供读写服务。

6 主 6 从架构下， 1 台平均抗 3 w-4 W 并发，还可以抗住 18 Wqps -24 Wqps。

并且，如果 QPS 达到 100 w，通过增加 redis 集群中的机器数量，可以扩展缓存的容量和并发读写能力。 6
主 6 从的架构，可以扩容到 30 主 30 从

同时，缓存数据对于应用来讲都是共享的，主从架构，实现高可用。

**问题：如何解决缓存热点（热 key）问题？**

一旦出现缓存热点现象，例如有 10 w 流量访问同一 Key，并集中于某一个 Redis 实例，可能会导致该
实例的 CPU 负载过高。

这种情况下，即便增加 Redis 集群数量，也无法根本解决问题。那么解决热 key 问题的有效手段，到
底是什么呢？ 非常有效的手段之一，本地缓存。其主要原因是： 本地缓存避免了 Redis 单个缓存服务
器的高负载。同时，本地内存缓存拥有更快的访问速度，因为数据直接存储在应用程序的内存中，无需
通过网络传输数据。

本地缓存的实质： **是多副本，空间换时间** 。通过复制多份缓存副本，将请求分散，可以缓解由缓存热
点引发的单个缓存服务器压力。

凡事，有利必有弊。

那么，引入本地缓存又会带来哪些问题呢？ 主要问题有：

```
数据一致性问题
本地缓存数据污染问题
```
关于以上两个问题，尼恩之前的文章： 《场景题：假设 10 W 人突访，你的系统如何做到不雪崩？》，
基于有赞透明多级缓存解决方案（TMC），給大家做过一个全面的梳理。

但是，咱们作为未来超级架构师，需要采蜜百家之长，极度开阔自己的技术视野。


所以，这里基于《京东服务端应用多级缓存架构方案》，給大家再梳理一篇。原文的京东服务端应用多
级缓存架构方案｜京东云技术团队。

#### 通用多级缓存方案

京东服务端应用多级缓存架构方案，其实是一种常用的 2 级缓存的架构方案：

（ 1 ）L 1 一级缓存：本地缓存 guava

（ 2 ）L 2 二级缓存：分布式缓存 redis

2 级缓存的架构方案的缓存访问流程：

```
请求优先打到应用本地缓存
本地缓存不存在，再去 redis 集群拉取，同时缓存到本地
```
以上流程，类似于 cache aside 旁路缓存模式。具体的缓存访问流程，大致如下：

有关 DB 与 Redis 缓存之间的 cache aside 旁路缓存模式的数据一致性问题，具体请阅读尼恩的《Java
高并发核心编程卷 3 加强版》。

那么，引入本地缓存又会带来哪些问题呢？ 主要问题有：

```
数据一致性问题
本地缓存数据污染问题
```
#### 多级缓存数据一致性问题


如何解决多级缓存数据一致性问题呢？ 主要是多级缓存同。主要使用发布订阅模式、或者底层组件
RPC 通讯机制，完成本地 cache 与 Redis 缓存的数据同步。

```
京东采用的是发布订阅模式。
有赞采用的底层组件 RPC 通讯机制
J 2 cache 采用的是发布订阅模式。
```
首先看看发布订阅，深入下去，也有两种模式：

```
推送模式：每个频道都维护着一个客户端列表，当发送消息时，会遍历该列表并将消息推送给所有
订阅者。
拉取模式：发送者将消息放入一个邮箱中，所有订阅该邮箱的客户端可以随时去收取。在确保所有
客户端都成功收取完整邮件后，才会删除该邮件。
```
首先，来看看京东的数据一致性问题：多级缓存同步方案

```
1. 运营后台保存数据，写入 Redis 缓存，同时利用 Redis 的发布订阅功能发布信息。
2. 业务应用集群作为消息订阅者，接收到运营数据消息后，删除本地缓存，
3. 当 C 端流量请求到达时，若本地缓存不存在，则从 Redis 中加载缓存至本地缓存。
4. 防止极端情况下，Redis 缓存失效，通过定时任务，将数据重新加载到 Redis 缓存。
```
其次，再看看有赞的数据一致性问题： **使用通信模块实现每个节点之间的数据一致性** 。

具体的介绍，请参见尼恩二次创作文章： 《场景题：假设 10 W 人突访，你的系统如何做到不雪
崩？》，基于有赞透明多级缓存解决方案（TMC），給大家做过一个全面的梳理。


另外，行业内有部分成熟的二级缓存中间件，主要使用消息队列 rocketmq /kafka，实现本地缓存与分
布式缓存之间的数据一致性。这种架构方案，具体可以参见尼恩的架构视频《100 Wqps 三级缓存组件
实操》

#### 京东发布订阅缓存同步组件选型

京东使用 redis 的 channel（频道）机制，完成本地 cache 与 Redis 缓存的数据同步。在 Redis 的
channel（频道）机制，发布订阅模式是一种推送模式。

```
通过使用 SUBSCRIBE 命令，可以订阅一个或多个频道，以便在相关频道发布消息时接收到通知。
PUBLISH 命令则用于向一个或多个频道发送消息。当某个频道有消息发布时，所有订阅该频道的
客户端都会收到相应的通知。
```
另外，Redis 的发布订阅模式是异步的。当有消息发布到某个频道时，Redis 会异步地将消息推送给所
有订阅该频道的客户端。这就意味着，客户端不会因为等待消息而阻塞，而是继续执行其他任务，仅在
需要接收消息时才去获取。这种异步方式有助于提高系统的并发性和效率。

#### 什么是缓存污染问题？

引入本地缓存又会带来哪些问题呢？ 主要问题有：

```
数据一致性问题
本地缓存数据污染问题
```
前面咱们看了数据一致性问题。再来看看，缓存污染问题。

缓存污染问题指的是留存在缓存中的数据，实际不会再被访问了，但是又占据了缓存空间。

如果这样的数据体量很大，甚至占满了缓存，每次有新数据写入缓存时，还需要把这些数据逐步淘汰出
缓存，就会增加缓存操作的时间开销。

因此，要解决缓存污染问题，最关键的技术就是能 **识别出这些只访问一次或是访问次数很少的数据** ，在
淘汰数据时，优先把他们筛选出来淘汰掉。所以，解决缓存污染的核心策略，叫做

缓存中主要常用的缓存淘汰策略：

```
random 随机
lru
lfu
```
（ 1 ） random 随机： 是随机选择数据进行淘汰主要包括 volatile-random 和 allkeys-random。随机淘
汰，比如 volatile-random 和 allkeys-random ，无法把不再访问的数据筛选出来，可能会造成缓存污
染。

（ 2 ）LRU：LRU 算法的基本思想是，当缓存空间不足时，要淘汰最近最少使用的缓存项，即淘汰访问时
间最长的数据项。这样可以保证最常用的数据项始终保留在缓存中，从而提高系统的响应速度和吞吐
量。由于 LRU 策略只考虑数据的访问时效，对于只访问一次的数据来说，LRU 策略无法很快将其筛选出
来。

（ 3 ）LFU 策略再 LRU 策略基础上进行了优化，在筛选数据时，首先会筛选并淘汰访问次数少的数据，然
后针对访问次数相同的数据，再筛选并淘汰访问时间最久的数据。


在实际业务应用中，LRU 和 LFU 两个策略都有应用。

LRU 和 LFU 两种策略关注的数据访问特征各有侧重， **LRU 策略更加关注数据的时效性，而 LFU 策略更加
关注数据的访问频次** 。

通常情况下，实际应用的负载具有 **较好的时间局部性** ，所以 LRU 策略的应用会更加广泛。

但是，在扫描式查询的应用场景中，LFU 策略就可以很好地应对缓存污染问题了，建议你优先使用。

京东本地缓存用的是 guava，那么策略是 LRU，LRU 策略更加关注数据的时效性，具有 **较好的时间局部
性** ，使用于大部分数据场景。

大部分本地缓存用的建议使用 caffeine，那么策略是 LRU+LFU，既具有 **较好的时间局部性** ，使用于大部
分数据场景。也具有关注数据的访问频次，避免扫描式查询的应用场景中数据污染问题。具体的原
理，请参见尼恩的《100 Wqps 三级缓存组件》视频，里边对 caffeine 内部原理和架构，做了深入介
绍，而且 caffeine 的性能也比 guava 高。

#### 多级缓存架构的注意事项

```
1. 由于本地缓存会占用 Java 进程的 JVM 内存空间，因此不适合存储大量数据，需要对缓存大小进行
评估。
2. 如果业务能够接受短时间内的数据不一致，那么本地缓存更适用于读取场景。
3. 在缓存更新策略中，无论是主动更新还是被动更新，本地缓存都应设置有效期。
4. 考虑设置定时任务来同步缓存，以防止极端情况下数据丢失。
5. 在 RPC 调用中，需要避免本地缓存被污染，可以通过合理的缓存淘汰策略，来解决这个问题。
6. 当应用重启时，本地缓存会失效，因此需要注意加载分布式缓存的时机。
7. 通过发布/订阅解决数据一致性问题时，如果发布/订阅模式不持久化消息数据，如果消息丢失，本
地缓存就会删除失败。所以，要解决发布订阅消息的高可用问题。
8. 当本地缓存失效时，需要使用 synchronized 进行加锁，确保由一个线程加载 Redis 缓存，避免并
发更新。
```
#### 说在最后：有问题可以找老架构取经

架构之路，充满了坎坷

架构和高级开发不一样，架构问题是 open/开发式的，架构问题是没有标准答案的

正由于这样，很多小伙伴，尽管耗费很多精力，耗费很多金钱，但是，遗憾的是， **一生都没有完成架构
升级** 。

所以，在架构升级/转型过程中，确实找不到有效的方案，可以来找 40 岁老架构尼恩求助.

昨天一个小伙伴，他们要进行 **电商网站的黄金链路架构** ，开始找不到思路，但是经过尼恩 10 分钟语音
指导，一下就豁然开朗。

#### 参考文献

https://it.sohu.com/a/696701644_121438385

https://blog.csdn.net/crazymakercircle/article/details/128533821


#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》


## 日流量 200 亿，携程网关的架构设计

#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，很多小伙伴拿到一线互联网企业如阿里、网易、有赞、希
音、百度、滴滴的面试资格。

就在昨天，尼恩指导一个小伙伴简历，写了一个《 **高并发 Netty 网关项目** 》，此项目帮这个小伙拿到
字节/阿里/微博/汽车之家面邀，所以说，这是一个牛逼的项目。

为了帮助大家拿到更多面试机会，拿到更多大厂 offer，尼恩决定： 9 月份給大家出一章视频，来介绍这
个项目的架构和实操，也就是《 33 章: 10 Wqps 高并发 Netty 网关架构与实操》，预计月底发布。并且
提供一对一的简历指导，保证简历金光闪闪、脱胎换骨。

海报如下：



配合尼恩的视频，会梳理几个工业级、生产级 **网关案例** ，作为架构素材、设计的素材。

此文，就是携程网关的架构设计。就是一个非常牛逼的工业级、生产级 **网关案例** 。

#### 日流量 200 亿，携程网关的架构设计

方案的作者：Butters，携程软件技术专家，专注于网络架构、API 网关、负载均衡、Service Mesh 等
领域。

#### 一、概述

类似于许多企业的做法，携程 API 网关是伴随着微服务架构一同引入的基础设施，其最初版本于 2014
年发布。随着服务化在公司内的迅速推进，网关逐步成为应用程序暴露在外网的标准解决方案。后续的
“ALL IN 无线”、国际化、异地多活等项目，网关都随着公司公共业务与基础架构的共同演进而不断发
展。截至 2021 年 7 月，整体接入服务数量超过 3000 个，日均处理流量达到 200 亿。

在技术方案方面，公司微服务的早期发展深受 NetflixOSS 的影响，网关部分最早也是参考了 Zuul 1.0
进行的二次开发，其核心可以总结为以下四点：

```
server 端：Tomcat NIO + AsyncServlet
业务流程：独立线程池，分阶段的责任链模式
client 端：Apache HttpClient，同步调用
核心组件：Archaius（动态配置客户端），Hystrix（熔断限流），Groovy（热更新支持）
```
```
注意：请点击图像以查看清晰的视图！
```
众所周知，同步调用会阻塞线程，系统的吞吐能力受 IO 影响较大。


作为行业的领先者，Zuul 在设计时已经考虑到了这个问题：通过引入 Hystrix，实现资源隔离和限流，
将故障（慢 IO）限制在一定范围内；结合熔断策略，可以提前释放部分线程资源；最终达到局部异常
不会影响整体的目标。

然而，随着公司业务的不断发展，上述策略的效果逐渐减弱，主要原因有两方面：

```
业务出海：网关作为海外接入层，部分流量需要转回国内，慢 IO 成为常态
服务规模增长：局部异常成为常态，加上微服务异常扩散的特性，线程池可能长期处于亚健康状态
```
全异步改造是携程 API 网关近年来的一项核心工作，本文也将围绕此展开，探讨我们在网关方面的工作
与实践经验。

重点包括：性能优化、业务形态、技术架构、治理经验等。

#### 二、高性能网关核心设计

###### 2.1. 异步流程设计

全异步 = server 端异步 + 业务流程异步 + client 端异步

对于 server 与 client 端，我们采用了 Netty 框架，其 NIO/Epoll + Eventloop 的本质就是事件驱动的设
计。

我们改造的核心部分是将业务流程进行异步化，常见的异步场景有：

```
业务 IO 事件：例如请求校验、身份验证，涉及远程调用
自身 IO 事件：例如读取到了报文的前 xx 字节
请求转发：包括 TCP 连接，HTTP 请求
```
从经验上看，异步编程在设计和读写方面相比同步会稍微困难一些，主要包括：

```
流程设计&状态转换
异常处理，包括常规异常与超时
上下文传递，包括业务上下文与 trace log
线程调度
流量控制
```
特别是在 Netty 上下文内，如果对 ByteBuf 的生命周期设计不完善，很容易导致内存泄漏。

围绕这些问题，我们设计了对应外围框架，最大努力对业务代码抹平同步/异步差异，方便开发；同时
默认兜底与容错，保证程序整体安全。

在工具方面，我们使用了 RxJava，其主要流程如下图所示。


```
注意：请点击图像以查看清晰的视图！
```
```
Maybe
RxJava 的内置容器类，表示正常结束、有且仅有一个对象返回、异常三种状态
响应式，便于整体状态机设计，自带异常处理、超时、线程调度等封装
Maybe.empty ()/Maybe.just (T)，适用同步场景
工具类 RxJavaPlugins，方便切面逻辑封装
Filter
代表一块独立的业务逻辑，同步&异步业务统一接口，返回 Maybe
异步场景（如远程调用）统一封装，如涉及线程切换，通过 maybe.obesrveOn (eventloop)
切回
异步 filter 默认增加超时，并按弱依赖处理，忽略错误
```
public interface Processor<T> {
ProcessorType getType ();

int getOrder ();

boolean shouldProcess (RequestContext context);

//对外统一封装为 Maybe
Maybe<T> process (RequestContext context) throws Exception;
}

public abstract class AbstractProcessor implements Processor {
//同步&无响应，继承此方法
//场景：常规业务处理
protected void processSync (RequestContext context) throws Exception {}

//同步&有响应，继承此方法，健康检测
//场景：健康检测、未通过校验时的静态响应
protected T processSyncAndGetReponse (RequestContext context) throws
Exception {
process (context);
return null;
};

//异步，继承此方法
//场景：认证、鉴权等涉及远程调用的模块
protected Maybe<T> processAsync (RequestContext context) throws Exception


```
整体流程
沿用责任链的设计，分为 inbound、outbound、error、log 四阶段
各阶段由一或多个 filter 组成
filter 顺序执行，遇到异常则中断，inbound 期间任意 filter 返回 response 也触发中断
```
{
T response = processSyncAndGetReponse (context);
if (response == null) {
return Maybe.empty ();
} else {
return Maybe.just (response);
}
};

@Override
public Maybe<T> process (RequestContext context) throws Exception {
Maybe<T> maybe = processAsync (context);
if (maybe instanceof ScalarCallable) {
//标识同步方法，无需额外封装
return maybe;
} else {
//统一加超时，默认忽略错误
return maybe.timeout (getAsyncTimeout (context),
TimeUnit. MILLISECONDS,
Schedulers.from (context.getEventloop ()),
timeoutFallback (context));
}
}

protected long getAsyncTimeout (RequestContext context) {
return 2000 ;
}

protected Maybe<T> timeoutFallback (RequestContext context) {
return Maybe.empty ();
}
}

public class RxUtil{
//组合某阶段（如 Inbound）内的多个 filter（即 Callable<Maybe<T>>）
public static <T> Maybe<T> concat (Iterable<? extends Callable<Maybe<T>>>
iterable) {
Iterator<? extends Callable<Maybe<T>>> sources = iterable.iterator ();
while (sources.hasNext ()) {
Maybe<T> maybe;
try {
maybe = sources.next (). call ();
} catch (Exception e) {
return Maybe.error (e);
}
if (maybe != null) {
if (maybe instanceof ScalarCallable) {
//同步方法


T response = ((ScalarCallable<T>) maybe). call ();
if (response != null) {
//有 response，中断
return maybe;
}
} else {
//异步方法
if (sources.hasNext ()) {
//将 sources 传入回调，后续 filter 重复此逻辑
return new ConcattedMaybe (maybe, sources);
} else {
return maybe;
}
}
}
}
return Maybe.empty ();
}
}

public class ProcessEngine{
//各个阶段，增加默认超时与错误处理
private void process (RequestContext context) {
List<Callable<Maybe<Response>>> inboundTask = get (ProcessorType. INBOUND,
context);
List<Callable<Maybe<Void>>> outboundTask = get (ProcessorType. OUTBOUND,
context);
List<Callable<Maybe<Response>>> errorTask = get (ProcessorType. ERROR,
context);
List<Callable<Maybe<Void>>> logTask = get (ProcessorType. LOG, context);

RxUtil.concat (inboundTask)  //inbound 阶段
.toSingle ()  //获取 response
.flatMapMaybe (response -> {
context.setOriginResponse (response);
return RxUtil.concat (outboundTask);
})  //进入 outbound
.onErrorResumeNext (e -> {
context.setThrowable (e);
return RxUtil.concat (errorTask). flatMap (response -> {
context.resetResponse (response);
return RxUtil.concat (outboundTask);
});
})  //异常则进入 error，并重新进入 outbound
.flatMap (response -> RxUtil.concat (logTask))  //日志阶段
.timeout (asyncTimeout.get (), TimeUnit. MILLISECONDS,
Schedulers.from (context.getEventloop ()),
Maybe.error (new ServerException ( 500 , "Async-Timeout-
Processing"))
)  //全局兜底超时
.subscribe (  //释放资源
unused -> {
logger.error ("this should not happen, " + context);
context.release ();
},
e -> {
logger.error ("this should not happen, " + context, e);


###### 2.2. 流式转发&单线程

以 HTTP 为例，报文可划分为 initial line/header/body 三个组成部分。

在携程，网关层业务不涉及请求体 body。

因为无需全量存，所以解析完请求头 header 后可直接进入业务流程。

同时，如果收到请求体 body 部分：

①若已向 upstream 转发请求，则直接转发；

②否则，需要将其暂时存储，等待业务流程处理完毕后，再将其与 initial line/header 一并发送；

③对 upstream 端响应的处理方式亦然。

对比完整解析 HTTP 报文的方式，这样处理：

```
更早进入业务流程，意味着 upstream 更早接收到请求，可以有效地降低网关层引入的延迟
body 生命周期被压缩，可降低网关自身的内存开销
```
尽管性能有所提升，但流式处理也大大增加了整个流程的复杂性。

```
context.release ();
},
() -> context.release ()
);
}
}
```

```
注意：请点击图像以查看清晰的视图！
```
在非流式场景下，Netty Server 端编解码、入向业务逻辑、Netty Client 端的编解码、出向业务逻辑，各
个子流程相互独立，各自处理完整的 HTTP 对象。而采用流式处理后，请求可能同时处于多个流程中，
这带来了以下三个挑战：

```
线程安全问题：如果各个流程使用不同的线程，那么可能会涉及到上下文的并发修改；
多阶段联动：比如 Netty Server 请求接收一半遇到了连接中断，此时已经连上了 upstream，那么
upstream 侧的协议栈是走不完的，也必须随之关闭连接；
边缘场景处理：比如 upstream 在请求未完整发送情况下返回了 404/413，是选择继续发送、走完
协议栈、让连接能够复用，还是选择提前终止流程，节约资源，但同时放弃连接？再比如，
upstream 已收到请求但未响应，此时 Netty Server 突然断开，Netty Client 是否也要随之断开？等
等。
```
为了应对这些挑战，我们采用了单线程的方式，核心设计包括：

```
上线文绑定 Eventloop，Netty Server/业务流程/Netty Client 在同个 eventloop 执行；
异步 filter 如因 IO 库的关系，必须使用独立线程池，那在后置处理上必须切回；
流程内资源做必要的线程隔离（如连接池）；
```

单线程方式避免了并发问题，在处理多阶段联动、边缘场景问题时，整个系统处于确定的状态下，有效
降低了开发难度和风险；此外，减少线程切换，也能在一定程度上提升性能。然而，由于 worker 线程
数较少（一般等于 CPU 核数），eventloop 内必须完全避免 IO 操作，否则将对系统的吞吐量造成重大
影响。

###### 2.3 其他优化

```
内部变量懒加载
```
对于请求的 cookie/query 等字段，如果没有必要，不提前进行字符串解析

```
堆外内存&零拷贝
```
结合前文的流式转发设计，进一步减少系统内存占用。

```
ZGC
```
由于项目升级到 TLSv 1.3，引入了 JDK 11（JDK 8 支持较晚，8 u 261 版本，2020.7.14），同时也尝试了
新一代的垃圾回收算法，其实际表现确实如人们所期待的那样出色。尽管 CPU 占用有所增加，但整体
GC 耗时下降非常显著。

```
注意：请点击图像以查看清晰的视图！
```
```
定制的 HTTP 编解码
```
由于 HTTP 协议的历史悠久及其开放性，产生了很多“不良实践”，轻则影响请求成功率，重则对网站安
全构成威胁。

```
流量治理
```
对于请求体过大（ 413 ）、URI 过长（ 414 ）、非 ASCII 字符（ 400 ）等问题，一般的 Web 服务器会选
择直接拒绝并返回相应的状态码。由于这类问题跳过了业务流程，因此在统计、服务定位和故障排查方
面会带来一些麻烦。通过扩展编解码，让问题请求也能完成路由流程，有助于解决非标准流量的管理问
题。

```
请求过滤
```
例如 request smuggling（Netty 4.1.61. Final 修复，2021.3.30 发布）。通过扩展编解码，增加自定义
校验逻辑，可以让安全补丁更快地得以应用。


#### 三、网关业务形态

作为独立的、统一的入向流量收口点，网关对企业的价值主要展现在三个方面：

```
解耦不同网络环境：典型场景包括内网&外网、生产环境&办公区、IDC 内部不同安全域、专线
等；
天然的公共业务切面：包括安全&认证&反爬、路由&灰度、限流&熔断&降级、监控&告警&排障
等；
```
```
注意：请点击图像以查看清晰的视图！
```
```
高效、灵活的流量控制
```
这里展开讲几个细分场景：

```
私有协议
```
在收口的客户端（APP）中，框架层会拦截用户发起的 HTTP 请求，通过私有协议（SOTP）的方式传送
到服务端。

选址方面：①通过服务端分配 IP，防止 DNS 劫持；②进行连接预热；③采用自定义的选址策略，可以
根据网络状况、环境等因素自行切换。

交互方式上：①采用更轻量的协议体；②统一进行加密与压缩与多路复用；③在入口处由网关统一转换
协议，对业务无影响。

```
链路优化
```
关键在于引入接入层，让远程用户就近访问，解决握手开销过大的问题。同时，由于接入层与 IDC 两端
都是可控的，因此在网络链路选择、协议交互模式等方面都有更大的优化空间。


```
异地多活
```
与按比例分配、就近访问策略等不同，在异地多活模式下，网关（接入层）需要根据业务维度的
shardingKey 进行分流（如 userId），防止底层数据冲突。

```
注意：请点击图像以查看清晰的视图！
```
#### 四、网关治理

下所示的图表概括了网上网关的工作状态。纵向对应我们的业务流程：各种渠道（如 APP、H 5、小程
序、供应商）和各种协议（如 HTTP、SOTP）的流量通过负载均衡分配到网关，通过一系列业务逻辑处
理后，最终被转发到后端服务。经过第二章的改进后，横向业务在性能和稳定性方面都得到了显著提
升。

```
注意：请点击图像以查看清晰的视图！
```
另一方面，由于多渠道/协议的存在，网上网关根据业务进行了独立集群的部署。早期，业务差异（如
路由数据、功能模块）通过独立的代码分支进行管理，但是随着分支数量的增加，整体运维的复杂性也
在不断提高。在系统设计中，复杂性通常也意味着风险。因此，如何对多协议、多角色的网关进行统一
管理，如何以较低的成本快速为新业务构建定制化的网关，成为了我们下一阶段的工作重点。


解决方案已经在图中直观地呈现出来，一是在协议上进行兼容处理，使网上代码在一个框架下运行；二
是引入控制面，对网上网关的差异特性进行统一管理。

###### 4.1 多协议兼容

多协议兼容的方法并不新颖，可以参考 Tomcat 对 HTTP/1.0、HTTP/1.1、HTTP/2.0 的抽象处理。尽管
HTTP 在各个版本中增加了许多新特性，但在进行业务开发时，我们通常无法感知到这些变化，关键在
于 HttpServletRequest 接口的抽象。

在携程，网上网关处理的都是请求 - 响应模式的无状态协议，报文结构也可以划分为元数据、扩展头、
业务报文三部分，因此可以方便地进行类似的尝试。相关工作可以用以下两点来概括：

```
协议适配层：用于屏蔽不同协议的编解码、交互模式、对 TCP 连接的处理等
定义通用中间模型与接口：业务面向中间模型与接口进行编程，更好地关注到协议对应的业务属性
上
```
```
注意：请点击图像以查看清晰的视图！
```

###### 4.2 路由模块

路由模块是控制面的两个主要组成部分之一，除了管理网关与服务之间的映射关系外，服务本身可以用
以下模型来概括：

###### 4.3 模块编排

模块调度是控制面的另一个关键组成部分。我们在网关处理流程中设置了多个阶段（图中用粉色表
示）。除了熔断、限流、日志等通用功能外，运行时，不同网关需要执行的业务功能由控制面统一分
配。这些功能在网关内部有独立的代码模块，而控制面则额外定义了这些功能对应的执行条件、参数、
灰度比例和错误处理方式等。这种调度方式也在一定程度上保证了模块之间的解耦。

```
{
//匹配方式
"type": "uri",
```
```
//HTTP 默认采用 uri 前缀匹配，内部通过树结构寻址；私有协议（SOTP）通过服务唯一标识定位。
"value": "/hotel/order",
"matcherType": "prefix",
```
```
//标签与属性
//用于 portal 端权限管理、切面逻辑运行（如按核心/非核心）等
"tags": [
"owner_admin",
"org_framework",
"appId_123456"
],
"properties": {
"core": "true"
},
```
```
//endpoint 信息
"routes": [{
//condition 用于二级路由，如按 app 版本划分、按 query 重分配等
"condition": "true",
"conditionParam": {},
"zone": "PRO",
```
```
//具体服务地址，权重用于灰度场景
"targets": [{
"url": "http://test.ctrip.com/hotel",
"weight": 100
}
]
}]
}
```

```
注意：请点击图像以查看清晰的视图！
```
{
//模块名称，对应网关内部某个具体模块
"name": "addResponseHeader",

//执行阶段
"stage": "PRE_RESPONSE",

//执行顺序
"ruleOrder": 0 ,

//灰度比例
"grayRatio": 100 ,

//执行条件
"condition": "true",
"conditionParam": {},

//执行参数
//大量${}形式的内置模板，用于获取运行时数据
"actionParam": {
"connection": "keep-alive",
"x-service-call": "${request. func. remoteCost}",
"Access-Control-Expose-Headers": "x-service-call",
"x-gate-root-id": "${func. catRootMessageId}"
},

//异常处理方式，可以抛出或忽略
"exceptionHandle": "return"
}


#### 五、总结

网关在各种技术交流平台上一直是备受关注的话题，有很多成熟的解决方案：易于上手且发展较早的
Zuul 1.0、高性能的 Nginx、集成度高的 Spring Cloud Gateway、日益流行的 Istio 等等。

最终的选型还是取决于各公司的业务背景和技术生态。

因此，在携程，我们选择了自主研发的道路。

技术在不断发展，我们也在持续探索，包括公共网关与业务网关的关系、新协议（如 HTTP 3）的应用、
与 ServiceMesh 的关联等等。

#### 说在最后：有问题可以找老架构取经

架构之路，充满了坎坷

架构和高级开发不一样，架构问题是 open/开放式的，架构问题是没有标准答案的

正由于这样，很多小伙伴，尽管耗费很多精力，耗费很多金钱，但是，遗憾的是， **一生都没有完成架构
升级** 。

**所以，在架构升级/转型过程中，确实找不到有效的方案，可以来找 40 岁老架构尼恩求助.**

前段时间一个小伙伴，他是跨专业来做 Java，现在面临转架构的难题，但是经过尼恩几轮指导，顺利拿
到了 **Java 架构师+大数据架构师 offer** 。所以，如果遇到职业不顺，找老架构师帮忙一下，就顺利多
了。

#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》


《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》

## 千万级连接，知乎如何架构长连接网关？

#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，很多小伙伴拿到一线互联网企业如阿里、网易、有赞、希
音、百度、滴滴的面试资格。

最近，尼恩指导一个小伙伴简历，写了一个《 **高性能长连接网关项目** 》，此项目帮这个小伙拿到 **字节/
阿里/微博/汽车之家** 面邀，所以说，这是一个牛逼的项目。

为了帮助大家拿到更多面试机会，拿到更多大厂 offer，

尼恩决定： 9 月份給大家出一章视频介绍这个项目的架构和实操，《 33 章: 10 Wqps 高并发 Netty 网关架
构与实操》，预计月底发布。然后，提供一对一的简历指导，这里简历金光闪闪、脱胎换骨。

《 33 章: 10 Wqps 高并发 Netty 网关架构与实操》海报如下：



配合《 33 章: 10 Wqps 高并发 Netty 网关架构与实操》，尼恩会梳理几个工业级、生产级 **网关案例** ，作
为架构素材、设计的素材。

前面梳理了《日流量 200 亿，携程网关的架构设计》。

这里又是一个漂亮的生产级案例：《 **知乎千万级并发的高性能长连接网关技术实践** 》，又一个非常牛逼
的工业级、生产级 **网关案例** 。

```
《尼恩架构笔记》《尼恩高并发三部曲》《尼恩 Java 面试宝典》的 PDF，请到公号【技术自由
圈】获取
```
#### 1 、知乎千万级并发的高性能长连接网关技术实践

作者：知乎技术团队

几乎每个互联网公司都有一套长连接系统，它们在消息提示、实时通信、推送、直播弹幕、游戏、共享
定位、股票行情等场景中得到应用。

随着公司规模的扩大和业务场景的复杂化，多个业务可能都需要同时使用长连接系统。

分别为各个业务设计长连接将会导致研发和维护成本大幅上升、资源浪费、增加客户端能耗、无法重复
利用现有经验等问题。

共享长连接系统则需要协调不同系统间的认证、授权、数据隔离、协议扩展、消息送达保证等需求，在
迭代过程中协议需要保持向前兼容，同时由于不同业务的长连接汇聚到一个系统，容量管理的难度也会
相应增大。

经过一年多的开发和演进，我们面对内外部的多个 App、接入十几个需求和形态各异的长连接业务、数
百万设备同时在线、突发大规模消息发送等场景，提炼出了一个长连接系统网关的通用解决方案，解决
了多业务共用长连接时遇到的各种问题。

知乎长连接网关专注于业务数据解耦、消息高效分发、解决容量问题，同时提供一定程度的消息可靠性
保证。

#### 2 、我们怎么设计通讯协议？

###### 2.1 业务解耦

支持多业务的长连接网关需要同时与多个客户端和多个业务后端进行对接，形成多对多的关系，他们之
间仅依赖一条长连接进行通信。


在设计这种多对多的系统时，需要避免过度耦合。业务逻辑是动态调整的，如果将业务协议和逻辑与网
关实现紧密结合，将会导致所有业务相互关联，协议升级和维护变得极其困难。

因此，我们尝试采用经典的发布订阅模型来实现长连接网关与客户端和业务后端的解耦，他们之间只需
约定主题，便可自由地发布和订阅消息。传输的消息为纯二进制数据，网关无需关心业务方的具体协议
规范和序列化方式。

###### 2.2 如何进行客户端的权限控制？

我们采用发布订阅的方式解耦了网关与业务方的实现，然而，我们还需要控制客户端对主题（Topic）
的发布订阅权限，防止数据污染或越权访问，无论是有意还是无意的。


比如，当一个讲师在知乎 Live 的 165218 频道进行演讲，客户端进入房间并尝试订阅 165218 频道的
Topic 时，知乎 Live 的后端就需要判断当前用户是否已经付费。在这种情况下，权限是非常灵活的，用
户付费后才能订阅，否则就不能订阅。

关于权限的状态，只有知乎 Live 业务后端知道，网关无法独立作出判断。

因此，我们在 ACL 规则中设计了一个基于回调的鉴权机制，可以配置 Live 相关 Topic 的订阅和发布动
作都通过 HTTP 回调给知乎 Live 的后端服务进行判断。

同时，根据我们对内部业务的观察，大部分场景下，业务只需要一个当前用户的私有主题来接收服务端
下发的通知或消息。在这种情况下，如果让业务都设计回调接口来判断权限，将会非常繁琐。

因此，我们在 ACL 规则中设计了 Topic 模板变量，以降低业务方的接入成本。我们为业务方配置允许订
阅的 Topic 中包含连接的用户名变量标识，表示只允许用户订阅或发送消息到自己的 Topic。

在这种情况下，网关可以在不与业务方通信的情况下，独立快速判断客户端是否有权限订阅或向 Topic
发送消息。

###### 2.3 消息如何实现高可靠传输？

作为信息传输的关键节点，网关连接业务后端和客户端，转发信息时，必须确保传输过程中的可靠性。


尽管 TCP 可以确保传输的顺序和稳定性，但在 TCP 状态异常、客户端接收逻辑异常或发生了 Crash 等
情况下，传输的信息可能会丢失。

为了确保下发或上传的信息能被对方正确处理，我们实现了回执和重传功能。在客户端收到并正确处理
重要业务的信息后，需要发送回执，而网关会暂时保存客户端未接收的信息，并根据客户端的接收状况
尝试重新发送，直至收到客户端的正确回执。

在面对服务端业务的高流量场景时，如果服务端给网关的每条信息都采用发送回执的方式，效率会较
低。因此，我们也提供了基于消息队列的接收和发送方式，将在介绍发布订阅实现时作详细说明。

在设计通讯协议时，我们参照了 MQTT 规范，加强了认证和授权设计，实现了业务信息的隔离和解耦，
确保了传输的可靠性。同时，保持了与 MQTT 协议一定程度上的兼容性，以便我们直接使用 MQTT 的
各种客户端实现，降低业务方的接入成本。

#### 3 、我们怎么设计系统架构？

**在设计项目整体架构时，我们优先考虑的是：**

```
1 ）可靠性；
2 ）水平扩展能力；
3 ）依赖组件成熟度；
4 ）简单才值得信赖。
```
为了保证可靠性，我们没有考虑像传统长连接系统那样将内部数据存储、计算、消息路由等等组件全部
集中到一个大的分布式系统中维护，这样增大系统实现和维护的复杂度。我们尝试将这几部分的组件独
立出来，将存储、消息路由交给专业的系统完成，让每个组件的功能尽量单一且清晰。

同时我们也需要快速地水平扩展能力。互联网场景下各种营销活动都可能导致连接数陡增，同时发布订
阅模型系统中下发消息数会随着 Topic 的订阅者的个数线性增长，此时网关暂存的客户端未接收消息的
存储压力也倍增。

将各个组件拆开后减少了进程内部状态，我们就可以将服务部署到容器中，利用容器来完成快速而且几
乎无限制的水平扩展。

**最终设计的系统架构如下图：**


**系统主要由四个主要组件组成：**

```
1 ）接入层使用 OpenResty 实现，负责连接负载均衡和会话保持；
2 ）长连接 Broker，部署在容器中，负责协议解析、认证与鉴权、会话、发布订阅等逻辑；
3 ）Redis 存储，持久化会话数据；
4 ）Kafka 消息队列，分发消息给 Broker 或业务方。
```
其中 Kafka 和 Redis 都是业界广泛使用的基础组件，它们在知乎都已平台化和容器化，它们也都能完成
分钟级快速扩容。


#### 4 、如何构建长连接网关？

###### 4.1 接入层

OpenResty 是业界使用非常广泛的支持 Lua 的 Nginx 拓展方案，灵活性、稳定性和性能都非常优异，
我们在接入层的方案选型上也考虑使用 OpenResty。

**接入层是最靠近用户的一侧，在这一层需要完成两件事：**

```
1 ）负载均衡，保证各长连接 Broker 实例上连接数相对均衡；
2 ）会话保持，单个客户端每次连接到同一个 Broker，用来提供消息传输可靠性保证。
```
负载均衡其实有很多算法都能完成，不管是随机还是各种 Hash 算法都能比较好地实现，麻烦一些的是
会话保持。

常见的四层负载均衡策略是根据连接来源 IP 进行一致性 Hash，在节点数不变的情况下这样能保证每次
都 Hash 到同一个 Broker 中，甚至在节点数稍微改变时也能大概率找到之前连接的节点。

**之前我们也使用过来源 IP Hash 的策略，主要有两个缺点：**

```
1 ）分布不够均匀，部分来源 IP 是大型局域网 NAT 出口，上面的连接数多，导致 Broker 上连接数
不均衡；
2 ）不能准确标识客户端，当移动客户端掉线切换网络就可能无法连接回刚才的 Broker 了。
```
所以我们考虑七层的负载均衡，根据客户端的唯一标识来进行一致性 Hash，这样随机性更好，同时也
能保证在网络切换后也能正确路由。常规的方法是需要完整解析通讯协议，然后按协议的包进行转发，
这样实现的成本很高，而且增加了协议解析出错的风险。

最后我们选择利用 Nginx 的 preread 机制实现七层负载均衡，对后面长连接 Broker 的实现的侵入性
小，而且接入层的资源开销也小。

Nginx 在接受连接时可以指定预读取连接的数据到 preread buffer 中，我们通过解析 preread buffer
中的客户端发送的第一个报文提取客户端标识，再使用这个客户端标识进行一致性 Hash 就拿到了固定
的 Broker。

###### 4.2 内部消息传输的枢纽如何架构？

我们引入了业界广泛使用的消息队列 Kafka 来作为内部消息传输的枢纽。

**前面提到了一些这么使用的原因：**

```
1 ）减少长连接 Broker 内部状态，让 Broker 可以无压力扩容；
2 ）知乎内部已平台化，支持水平扩展。
```
**还有一些原因是：**

```
1 ）使用消息队列削峰，避免突发性的上行或下行消息压垮系统；
2 ）业务系统中大量使用 Kafka 传输数据，降低与业务方对接成本。
```

其中利用消息队列削峰好理解，下面我们看一下怎么利用 Kafka 与业务方更好地完成对接。

###### 4.3 海量数据如何发布？

连接 Broker 会根据路由配置将消息发布到 Kafka Topic，同时也会根据订阅配置去消费 Kafka 将消息下
发给订阅客户端。

路由规则和订阅规则是分别配置的，那么可能会出现四种情况。

**情况一：** 消息路由到 Kafka Topic，但不消费，适合数据上报的场景，如下图所示。

**情况二：** 消息路由到 Kafka Topic，也被消费，普通的即时通讯场景，如下图所示。

**情况三：** 直接从 Kafka Topic 消费并下发，用于纯下发消息的场景，如下图所示。


**情况四：** 消息路由到一个 Topic，然后从另一个 Topic 消费，用于消息需要过滤或者预处理的场景，如
下图所示。

这套路由策略的设计灵活性非常高，可以解决几乎所有的场景的消息路由需求。同时因为发布订阅基于
Kafka，可以保证在处理大规模数据时的消息可靠性。

###### 4.4 订阅

当长连接 Broker 从 Kafka Topic 中消费出消息后会查找本地的订阅关系，然后将消息分发到客户端会
话。

我们最开始直接使用 HashMap 存储客户端的订阅关系。当客户端订阅一个 Topic 时我们就将客户端的
会话对象放入以 Topic 为 Key 的订阅 Map 中，当反查消息的订阅关系时直接用 Topic 从 Map 上取值就
行。

因为这个订阅关系是共享对象，当订阅和取消订阅发生时就会有连接尝试操作这个共享对象。为了避免
并发写我们给 HashMap 加了锁，但这个全局锁的冲突非常严重，严重影响性能。

最终我们通过分片细化了锁的粒度，分散了锁的冲突。

本地同时创建数百个 HashMap，当需要在某个 Key 上存取数据前通过 Hash 和取模找到其中一个
HashMap 然后进行操作，这样将全局锁分散到了数百个 HashMap 中，大大降低了操作冲突，也提升
了整体的性能。

###### 4.5 如何进行会话持久化？

当消息被分发给会话 Session 对象后，由 Session 来控制消息的下发。


Session 会判断消息是否是重要 Topic 消息，需要的话，将消息标记 QoS 等级为 1 ，同时将消息存储到
Redis 的未接收消息队列，并将消息下发给客户端。等到客户端对消息的 ACK 后，再将未确认队列中的
消息删除。

有一些业界方案是在内存中维护了一个列表，在扩容或缩容时这部分数据没法跟着迁移。也有部分业界
方案是在长连接集群中维护了一个分布式内存存储，这样实现起来复杂度也会变高。

我们将未确认消息队列放到了外部持久化存储中，保证了单个 Broker 宕机后，客户端重新上线连接到
其他 Broker 也能恢复 Session 数据，减少了扩容和缩容的负担。

###### 4.6 如何使用滑动窗口进行 QoS 保障？

在发送消息时，每条 QoS 1 的消息需要被经过传输、客户端处理、回传 ACK 才能确认下发完成，路径
耗时较长。如果消息量较大，每条消息都等待这么长的确认才能下发下一条，下发通道带宽不能被充分
利用。

为了保证发送的效率，我们参考 TCP 的滑动窗口设计了并行发送的机制。我们设置一定的阈值为发送的
滑动窗口，表示通道上可以同时有这么多条消息正在传输和被等待确认。

我们应用层设计的滑动窗口跟 TCP 的滑动窗口实际上还有些差异。

TCP 的滑动窗口内的 IP 报文无法保证顺序到达，而我们的通讯是基于 TCP 的所以我们的滑动窗口内的
业务消息是顺序的，只有在连接状态异常、客户端逻辑异常等情况下才可能导致部分窗口内的消息乱
序。

因为 TCP 协议保证了消息的接收顺序，所以正常的发送过程中不需要针对单条消息进行重试，只有在客
户端重新连接后才对窗口内的未确认消息重新发送。消息的接收端同时会保留窗口大小的缓冲区用来消
息去重，保证业务方接收到的消息不会重复。

我们基于 TCP 构建的滑动窗口保证了消息的顺序性同时也极大提升传输的吞吐量。

#### 5 、总结

知乎长连接网关由基础架构组 (Infra) 开发和维护，主要贡献者是@faceair、@安江泽。

基础架构组负责知乎的流量入口和内部基础设施建设，对外我们奋斗在直面海量流量的的第一战线，对
内我们为所有的业务提供坚如磐石的基础设施，用户的每一次访问、每一个请求、内网的每一次调用都
与我们的系统息息相关。

#### 说在最后：有问题可以找老架构取经

架构之路，充满了坎坷


架构和高级开发不一样，架构问题是 open/开放式的，架构问题是没有标准答案的

正由于这样，很多小伙伴，尽管耗费很多精力，耗费很多金钱，但是，遗憾的是， **一生都没有完成架构
升级** 。

**所以，在架构升级/转型过程中，确实找不到有效的方案，可以来找 40 岁老架构尼恩求助.**

前段时间一个小伙伴，他是跨专业来做 Java，现在面临转架构的难题，但是经过尼恩几轮指导，顺利拿
到了 **Java 架构师+大数据架构师 offer** 。所以，如果遇到职业不顺，找老架构师帮忙一下，就顺利多
了。

#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》


## 日 200 亿调用，喜马拉雅网关的架构设计

#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，很多小伙伴拿到一线互联网企业如阿里、网易、有赞、希
音、百度、滴滴的面试资格。

最近，尼恩指导一个小伙伴简历，写了一个《 **API 网关项目** 》，此项目帮这个小伙拿到 **字节/阿里/微
博/汽车之家** 面邀，所以说，这是一个牛逼的项目。

为了帮助大家拿到更多面试机会，拿到更多大厂 offer，

尼恩决定： 9 月份給大家出一章视频介绍这个项目的架构和实操，《 33 章: 10 Wqps 高并发 Netty 网关架
构与实操》，预计月底发布。然后，提供一对一的简历指导，这里简历金光闪闪、脱胎换骨。

《 33 章: 10 Wqps 高并发 Netty 网关架构与实操》海报如下：



配合《 33 章: 10 Wqps 高并发 Netty 网关架构与实操》，尼恩会梳理几个工业级、生产级 **网关案例** ，作
为架构素材、设计的素材。

前面梳理了

```
《日流量 200 亿，携程网关的架构设计》
《千万级连接，知乎如何架构长连接网关？》
```
这里又是一个漂亮的生产级案例：《 **喜马拉雅自研亿级 API 网关技术实践** 》，又一个非常牛逼的工业
级、生产级 **网关案例** 。

```
《尼恩架构笔记》《尼恩高并发三部曲》《尼恩 Java 面试宝典》的 PDF，请到公号【技术自由
圈】获取
```
#### 喜马拉雅自研亿级 API 网关技术实践

网关作为一种发展较为完善的产品，各大互联网公司普遍采用它作为中间件，以应对公共业务需求的不
断浮现，并能迅速迭代更新。

如果没有网关，要更新一个公共特性，就得推动所有业务方都进行更新和发布，这无疑是效率极低的。
然而，有了网关之后，这一切都不再是问题。

喜马拉雅也如此，用户数量已增长到 6 亿级别，Web 服务数量超过 500 个，目前我们的网关每天处理
超过 200 亿次的调用，单机 QPS 峰值可达 4 w+。

除了实现基本的反向代理功能，网关还具备许多公共特性，如黑白名单、流量控制、身份验证、熔断、
API 发布、监控和报警等。根据业务方的需求，我们还实现了流量调度、流量复制、预发布、智能升
级、流量预热等相关功能。

**从技术上来说，喜马拉雅 API 网关的技术演进路线图大致如下** ：

```
注意：请点击图像以查看清晰的视图！
```
本文将介绍在喜马拉雅 API 网关面临亿级流量的情况下，我们如何进行技术演进，以及我们的实践经验
总结。

#### 1 、第 1 版：Tomcat NIO+Async Servlet

在架构设计中，网关的关键之处在于接收到请求并调用后端服务时，不能发生阻塞（Block），否则网
关的处理能力将受到限制。


这是因为最耗时的操作就是远程调用后端服务这个过程。

如果此处发生阻塞，Tomcat 的工作线程会被全部 block 住了，等待后端服务响应的过程中无法处理其
他请求，因此这里必须采用异步处理。

**架构图如下** ：

```
注意：请点击图像以查看清晰的视图！
```
在这个版本中，我们实现了一个单独的 Push 层，用于在网关接收到响应后，响应客户端，并通过此层
实现与后端服务的通信。

该层使用的是 HttpNioClient，支持业务功能包括黑白名单、流量控制、身份验证、API 发布等。

然而，这个版本仅在功能上满足了网关的要求，处理能力很快成为瓶颈。当单机 QPS 达到 5 K 时，会频
繁发生 Full GC。

通过分析线上堆，我们发现问题在于 Tomcat 缓存了大量 HTTP 请求。因为 Tomcat 默认会缓存 200 个
requestProcessor，每个处理器都关联一个 request。

另外，Servlet 3.0 的 Tomcat 异步实现可能会导致内存泄漏。后来我们通过减少这个配置，效果明显。

然而，这种调整会导致性能下降。总结一下，基于 Tomcat 作为接入端存在以下问题：

**Tomcat 自身的问题** ：

```
1 ）缓存过多，Tomcat 使用了许多对象池技术，在有限内存的情况下，流量增大时很容易触发
GC；
2 ）内存 Copy，Tomcat 的默认内存使用堆内存，因此数据需要从堆内读取，而后端服务是
Netty，使用堆外内存，需要经过多次 Copy；
3 ）Tomcat 还有个问题是读 body 是阻塞的, Tomcat 的 NIO 模型和 reactor 模型不同，读 body
是 block 的。
```
**这里再分享一张 Tomcat buffer 的关系图** ：


```
注意：请点击图像以查看清晰的视图！
```
从上图中，我们能够明显观察到，Tomcat 的封装功能相当完善，但在内部默认设置下，会有三次
copy。

**HttpNioClient 的问题** ：在获取和释放连接的过程中都需要进行加锁，针对类似网关这样的代理服务场
景，会导致频繁地建立和关闭连接，这无疑会对性能产生负面影响。

鉴于 Tomcat 存在的这些难题，我们在后续对接入端进行了优化，采用 Netty 作为接入层和服务调用
层，也就是我们的第二版，成功地解决了上述问题，实现了理想的性能。

#### 2 、第 2 版：Netty+全异步

基于 Netty 的优势，我们构建了全异步、无锁、分层的架构。

**先看下我们基于 Netty 做接入端的架构图** ：

```
注意：请点击图像以查看清晰的视图！
```
###### 2.1 接入层


Netty 的 IO 线程主要负责 HTTP 协议的编解码工作，同时也监控并报警协议层面的异常情况。

我们对 HTTP 协议的编解码进行了优化，并对异常和攻击性请求进行了监控和可视化处理。

例如，我们对 HTTP 请求行和请求头的大小都有限制，而 Tomcat 是将请求行和请求头一起计算，总大
小不超过 8 K，而 Netty 是分别对两者设置大小限制。

如果客户端发送的请求超过了设定的阀值，带有 cookie 的请求很容易超过这个限制，一般情况下，
Netty 会直接响应 400 给客户端。

在优化后，我们只取正常大小的部分，并标记协议解析失败，这样在业务层就可以判断出是哪个服务出
现了这类问题。

对于其他攻击性的请求，例如只发送请求头而不发送 body 或者只发送部分内容，都需要进行监控和报
警。

###### 2.2 业务逻辑层

这一层负责实现一系列支持业务的公共逻辑，包括 API 路由、流量调度等，采用责任链模式，这一层不
会进行 IO 操作。

在业界和大型企业的网关设计中，业务逻辑层通常都被设计成责任链模式，公共的业务逻辑也在这一层
实现。

**在这一层，我们也执行了相似的操作，并支持以下功能** ：

```
1 ）用户认证和登录验证，支持接口级别的配置；
2 ）黑白名单：包括全局和应用的黑白名单，以及 IP 和参数级别的限制；
3 ）流量控制：提供自动和手动控制，自动控制可拦截过大流量，通过令牌桶算法实现；
4 ）智能熔断：在 Histrix 的基础上进行改进，支持自动升降级，我们采用全自动方式，也支持手
动配置立即熔断，即当服务异常比例达到设定值时，自动触发熔断；
5 ）灰度发布：对于新启动的机器的流量，我们支持类似于 TCP 的慢启动机制，为机器提供一段预
热时间；
6 ）统一降级：我们对所有转发失败的请求都会执行统一降级操作，只要业务方配置了降级规则，
都会进行降级，我们支持将降级规则细化到参数级别，包括请求头中的值，非常细粒度，此外，我
们还会与 varnish 集成，支持 varnish 的优雅降级；
7 ）流量调度：支持业务根据筛选规则，将流量分配到对应的机器，也支持仅让筛选的流量访问该
机器，这在排查问题/新功能发布验证时非常有用，可以先通过小部分流量验证，再大面积发布上
线；
8 ）流量 copy：我们支持根据规则对线上原始请求 copy 一份，将其写入 MQ 或其他 upstream，
用于线上跨机房验证和压力测试；
9 ）请求日志采样：我们对所有失败的请求都会进行采样并保存到磁盘，以供业务方排查问题，同
时也支持业务方根据规则进行个性化采样，我们采样了整个生命周期的数据，包括请求和响应相关
的所有数据。
```
上述提到的所有功能都是对流量进行管理，我们每个功能都作为一个 filter，处理失败都不会影响转发
流程，而且所有这些规则的元数据在网关启动时就会全部初始化好。

在执行过程中，不会进行 IO 操作，目前有些设计会对多个 filter 进行并发执行，由于我们的操作都是在
内存中进行，开销并不大，所以我们目前并未支持并发执行。

另外，规则可能会发生变化，所有需要进行规则的动态刷新。

我们在修改规则时，会通知网关服务，进行实时刷新，我们对内部自己的这种元数据更新请求，通过独
立的线程处理，防止 IO 操作时影响业务线程。


###### 2.3 服务调用层

服务调用对于代理网关服务非常关键，这个环节，性能必须很高：必须采用异步方式，

我们利用 Netty 实现了这一目标，同时也充分利用了 Netty 提供的连接池，实现了获取和释放的无锁操
作。

**2.3.1 异步 Push**

在发起服务调用后，网关允许工作线程继续处理其他请求，而无需等待服务端返回。

在这个设计中，我们为每个请求创建一个上下文，发送请求后，将该请求的 context 绑定到相应的连接
上，当 Netty 收到服务端响应时，会在连接上执行 read 操作。

解码完成后，再从连接上获取相应的 context，通过 context 可以获取到接入端的 session。

这样，push 通过 session 将响应写回客户端，这个设计基于 HTTP 连接的独占性，即连接和请求上下
文绑定。

**2.3.2 连接池**

**连接池的原理如下图** ：

```
注意：请点击图像以查看清晰的视图！
```
服务调用层除了异步发起远程调用外，还需要管理后端服务的连接。

HTTP 与 RPC 不同，HTTP 连接是独占的，所以在释放连接时需要特别小心，必须等待服务端响应完成
后才能释放，此外，连接关闭的处理也需要谨慎。

**总结如下几点** ：

```
1 ）Connection: close；
2 ）空闲超时，关闭连接；
3 ）读超时关闭连接；
4 ）写超时，关闭连接；
5 ）Fin、Reset。
```

上面几种需要关闭连接的场景，下面主要说下 _Connection: close_ 和空闲写超时两种，其他情况如读超
时、连接空闲超时、收到 fin、reset 码等都比较常见。

**2.3.3 Connection:close**

后端服务采用的是 Tomcat，它对连接的重用次数有规定，默认为 100 次。

当达到 100 次限制时，Tomcat 会在响应头中添加 _Connection: close_ ，要求客户端关闭该连接，否则再
次使用该连接发送请求会出现 400 错误。

还有就是如果前端的请求带了 _Connection: close_ ，那 Tomcat 就不会等待该连接重用满 100 次，即一次
就关闭连接。

在响应头中添加 _Connection: close_ 后，连接变为短连接。

在与 Tomcat 保持长连接时，需要注意这一点，如果要利用该连接，需要主动移除 close 头。

**2.3.4 写超时**

首先，网关在何时开始计算服务的超时时间？

如果从调用 writeAndFlush 开始计算，实际上包含了 Netty 对 HTTP 的编码时间和从队列中发送请求即
flush 的时间，这样对后端服务不公平。

因此，需要在真正 flush 成功后开始计时，这样最接近服务端，当然还包含了网络往返时间和内核协议
栈处理时间，这是无法避免的，但基本稳定。

因此，我们在 flush 成功回调后启动超时任务。

**需要注意的是** ：如果 flush 不能快速回调，例如遇到一个大的 POST 请求，body 部分较大，而 Netty
发送时默认第一次只发送 1 k 大小。

如果尚未发送完毕，会增大发送大小继续发送，如果在 Netty 发送 16 次后仍未发送完成，将不再继续
发送，而是提交一个 flushTask 到任务队列，待下次执行后再发送。

此时，flush 回调时间较长，导致此类请求无法及时关闭，后端服务 Tomcat 会一直阻塞在读取 body
部分，基于上述分析，我们需要设置写超时，对于大的 body 请求，通过写超时及时关闭连接。

#### 3 、全链路超时机制


```
注意：请点击图像以查看清晰的视图！
```
**上图是我们在整个链路超时处理的机制** ：

```
1 ）协议解析超时；
2 ）等待队列超时；
3 ）建连超时；
4 ）等待连接超时；
5 ）写前检查是否超时；
6 ）写超时；
7 ）响应超时。
```
#### 4 、监控报警

对于网关的业务方来说，他们能看到的是监控和警报功能，我们能够实现秒级的报警和监控，将监控数
据定时上传到我们的管理系统，由管理系统负责汇总统计并存储到 InfluxDB 中。

我们对 HTTP 协议进行了全面的监控和警报，涵盖了协议层和服务层的问题。

**协议层** ：

```
1 ）针对攻击性请求，只发送头部，不发送或只发送部分 body，我们会进行采样并记录，还原现
场，并触发警报；
2 ）对于 Line 或 Head 或 Body 过大的请求，我们会进行采样记录，还原现场，并及时发出警报。
```
**应用层** ：

```
1 ）监控耗时：包括慢请求，超时请求，以及 tp 99，tp 999 等；
2 ）监控 OPS：并及时发出警报；
```

```
3 ）带宽监控和报警：支持对请求和响应的行，头，body 单独监控；
4 ）响应码监控：特别是 400 ，和 404 ；
5 ）连接监控：我们对接入端的连接，以及与后端服务的连接，以及后端服务连接上待发送字节大
小都进行了监控；
6 ）失败请求监控；
7 ）流量抖动报警：这是非常必要的，流量抖动可能是出现问题，或者是问题即将出现的预兆。
```
**总体架构** ：

```
注意：请点击图像以查看清晰的视图！
```
#### 5 、性能优化实践

###### 5.1 对象池技术

针对高并发系统，不断地创建对象不仅会占用内存资源，还会对垃圾回收过程产生压力。

为了解决这个问题，我们在实现过程中会对诸如线程池的任务、StringBuffer 等频繁使用的对象进行重
用，从而降低内存分配的开销。

###### 5.2 上下文切换

在高并发系统中，通常会采用异步设计。异步化后，线程上下文切换的问题必须得到关注。

**我们的线程模型如下** ：


```
注意：请点击图像以查看清晰的视图！
```
我们的网关没有涉及 I/O 操作，但在业务逻辑处理方面仍然采用了 Netty 的 I/O 编解码线程异步方式。

**这主要有两个原因** ：

```
1 ）防止开发人员编写的代码出现阻塞现象；
2 ）在突发情况下，业务逻辑可能会产生大量的日志记录，我们允许在推送线程时使用 Netty 的
I/O 线程作为替代。这种做法可以减少 CPU 上下文切换的次数，从而提高整体吞吐量。我们不能
仅仅为了异步而异步，Zuul 2 的设计理念与我们的做法相似。
```
###### 5.3 GC 优化

在高并发系统中，垃圾回收 GC 的优化是必不可少的。

我们采用了对象池技术和堆外内存，使得对象很少进入老年代，同时年轻代的设置较大，SurvivorRatio
设置为 2 ，晋升年龄设置最大为 15 ，以尽量让对象在年轻代就被回收。

但监控发现老年代的内存仍在缓慢增长。通过 dump 分析，我们每个后端服务创建一个链接，都时有一
个 socket，socket 的 AbstractPlainSocketImpl，而 AbstractPlainSocketImpl 就重写了 Object 类的
finalize 方法。

**实现如下** ：

是为了我们没有主动关闭链接，做的一个兜底，在 gc 回收的时候，先把对应的链接资源给释放了。

由于 finalize 的机制是通过 JVM 的 Finalizer 线程处理的，其优先级不高，默认为 8 。它需要等待
Finalizer 线程把 ReferenceQueue 的对象对应的 finalize 方法执行完，并等到下次垃圾回收时，才能回
收该对象。这导致创建链接的这些对象在年轻代不能立即回收，从而进入了老年代，这也是老年代持续
缓慢增长的原因。

###### 5.4 日志

```
/**
* Cleans up if the user forgets to close it.
*/
protected void finalize () throws IOException {
close ();
}
```

在高并发系统中，尤其是 Netty 的 I/O 线程，除了执行 I/O 读写操作外，还需执行异步任务和定时任
务。如果 I/O 线程处理不过队列中的任务，可能会导致新进来的异步任务被拒绝。

在什么情况下可能会出现这种情况呢？异步读写问题不大，主要是多耗点 CPU。最有可能阻塞 I/O 线程
的是日志记录。目前 Log 4 j 的 ConsoleAppender 日志 immediateFlush 属性默认为 true，即每次记录
日志都是同步写入磁盘，这对于内存操作来说，速度较慢。

同时，AsyncAppender 的日志队列满了也会阻塞线程。Log 4 j 默认的 buffer 大小是 128 ，而且是阻塞
的。即当 buffer 大小达到 128 时，会阻塞写日志的线程。在并发写日志量较大且堆栈较深的情况下，
Log 4 j 的 Dispatcher 线程可能会变慢，需要刷盘。这样 buffer 就不能快速消费，很容易写满日志事
件，导致 Netty I/O 线程被阻塞。因此，在记录日志时，我们需要注意精简。

#### 6 、未来规划

目前，我们都在使用基于 HTTP/1 的协议。

相对于 HTTP/1，HTTP/2 在连接层面实现了服务，即在一个连接上可以发送多个 HTTP 请求。

这就意味着 HTTP 连接可以像 RPC 连接一样，建立几个连接即可，完全解决了 HTTP/1 连接无法复用导
致的重复建连和慢启动的开销。

我们正在基于 Netty 升级到 HTTP/2，除了技术升级外，我们还在不断优化监控报警，以便为业务方提
供准确无误的报警。此外，我们还在作为统一接入网关与业务方实施全面的降级措施，以确保全站任何
故障都能通过网关第一时间降级，这也是我们的重点工作。

#### 说在最后：有问题可以找老架构取经

架构之路，充满了坎坷

架构和高级开发不一样，架构问题是 open/开放式的，架构问题是没有标准答案的

正由于这样，很多小伙伴，尽管耗费很多精力，耗费很多金钱，但是，遗憾的是， **一生都没有完成架构
升级** 。

**所以，在架构升级/转型过程中，确实找不到有效的方案，可以来找 40 岁老架构尼恩求助.**

前段时间一个小伙伴，他是跨专业来做 Java，现在面临转架构的难题，但是经过尼恩几轮指导，顺利拿
到了 **Java 架构师+大数据架构师 offer** 。所以，如果遇到职业不顺，找老架构师帮忙一下，就顺利多
了。

#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》


《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》

## 100 万级连接，爱奇艺 WebSocket 网关如何

## 架构


#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，很多小伙伴拿到一线互联网企业如阿里、网易、有赞、希
音、百度、滴滴的面试资格。

最近，尼恩指导一个小伙伴简历，写了一个《 **高并发网关项目** 》，此项目帮这个小伙拿到 **字节/阿里/
微博/汽车之家** 面邀，所以说，这是一个牛逼的项目。

为了帮助大家拿到更多面试机会，拿到更多大厂 offer，

尼恩决定： 9 月份给大家出一章视频介绍这个项目的架构和实操，《 33 章：10 Wqps 高并发 Netty 网关
架构与实操》，预计月底发布。然后，提供一对一的简历指导，这里简历金光闪闪、脱胎换骨。

《 33 章：10 Wqps 高并发 Netty 网关架构与实操》海报如下：



配合《 33 章：10 Wqps 高并发 Netty 网关架构与实操》，尼恩会梳理几个工业级、生产级 **网关案例** ，作
为架构素材、设计的素材。

前面梳理了

```
《日流量 200 亿，携程网关的架构设计》
《千万级连接，知乎如何架构长连接网关？》
《日 200 亿次调用，喜马拉雅网关的架构设计》
```
除了以上的三个案例，这里，尼恩又找到一个漂亮的生产级案例：

《 **爱奇艺 WebSocket 实时推送网关技术实践** 》，

注意，这又一个非常牛逼的工业级、生产级 **网关案例** 。

这些案例，并不是尼恩的原创。这些案例，仅仅是尼恩在《 33 章：10 Wqps 高并发 Netty 网关架构与实
操》备课的过程中，在互联网查找资料的时候，收集起来的，供大家学习和交流使用。

```
《尼恩架构笔记》《尼恩高并发三部曲》《尼恩 Java 面试宝典》的 PDF，请到公号【技术自由
圈】获取
```
#### 100 W 级连接，爱奇艺 WebSocket 推送网关架构

原文作者： 爱奇艺技术团队

HTTP 协议属于一种无状态、基于 TCP 的请求/响应模式的协议，

HTTP 协议中，只有客户端能发起请求，由服务端进行回应。

虽然，在许多情况下，这种请求/响应的拉取模式能够满足需求。

然而，在特定情况下，例如 **实时通知** （如 IM 中的离线消息推送最为典型）和 **消息推送** 等应用场景，需
要将数据实时推到客户端，这就要求服务端具备主动推送数据的能力。

如何推呢？

传统的 Web 服务端推送技术，包括短轮询、长轮询等，虽然能在一定程度上解决问题，但也存在如时
效性、资源浪费等问题。

HTML 5 标准推出的 **WebSocket 规范** 基本改变了这种状况，已经成为当前服务端消息推送技术的主
流。

本文将分享爱奇艺在基于 Netty 实现 WebSocket 长连接实时推送网关过程中的实践经验和总结。

#### 1 、旧方案存在的技术痛点

爱奇艺号作为我们内容生态的关键部分，作为前端系统，对用户体验有着较高的要求，这直接影响着创
作者的创作热情。

**当前，爱奇艺号在多个业务场景中应用了 WebSocket 实时推送技术，包括** ：


1 ） **用户评论** ：实时地将评论消息推送至浏览器；

2 ） **实名认证** ：在合同签署前，需要对用户进行实名认证，用户扫描二维码后进入第三方的认证页面，
认证完成后异步通知浏览器认证状态；

3 ） **活体识别** ：类似于实名认证，当活体识别完成后，异步将结果通知浏览器。

在实际业务开发中，我们发现 WebSocket 实时推送技术在使用过程中存在一些问题。

**这些问题是** ：

1 ） **首先** ：WebSocket 技术栈不统一，既有基于 Netty 实现的，也有基于 Web 容器实现的，给开发和
维护带来困难；

2 ） **其次** ：WebSocket 实现分散在各个工程中，与业务系统紧密耦合，如果有其他业务需要集成
WebSocket，将面临重复开发的困境，浪费成本、效率低下；

3 ） **第三** ：WebSocket 是有状态协议，客户端连接服务器时只与集群中一个节点连接，数据传输过程中
也只与这一节点通信。WebSocket 集群需要解决会话共享的问题。如果只采用单节点部署，虽然可以
避免这一问题，但无法水平扩展以支持更高的负载，存在单点故障风险；

4 ） **最后** ：最后：缺乏监控与报警，虽然可以通过 Linux 的 Socket 连接数大致评估 WebSocket 长连接
数，但数字并不准确，也无法得知用户数等具有业务含义的指标数据；无法与现有的微服务监控整合，
实现统一监控和报警。

#### 2 、新方案的技术目标

如上所述，为了解决旧方案中存在的问题，我们需要实现统一的 WebSocket 长连接实时推送网关。

**这套新的网关需要具备以下特点** ：

1 ） **集中实现长连接管理和推送能力** ：采用统一的技术栈，将长连接作为基础功能进行沉淀，以便于功
能的迭代和维护；

2 ） **与业务解耦** ：将业务逻辑与长连接通信分离，使得业务系统无需关心通信细节，避免了重复开发，
节约了研发成本；

3 ） **使用简单** ：提供 HTTP 推送通道，便于各种开发语言的接入。业务系统只需进行简单的调用，便可
实现数据推送，从而提高研发效率；

4 ） **分布式架构** ：构建多节点的集群，支持水平扩展以应对业务增长带来的挑战；节点故障不会影响服
务的整体可用性，确保高可靠性；

5 ） **多端消息同步** ：允许用户使用多个浏览器或标签页同时登录在线，确保消息同步发送；

6 ） **多维度监控与报警** ：将自定义监控指标与现有的微服务监控系统连接，当出现问题时可以及时报
警，保证服务的稳定性。

#### 3 、新方案的技术选型

在众多的 WebSocket 实现中，经过对性能、扩展性、社区支持等各方面的权衡，我们最终确定了
Netty。


```
方案优点缺点
```
```
注册中
心
```
```
会话映射关系清晰，集群规模较大时更
合适
```
```
实现复杂，强依赖注册中心，有额外运维
成本
```
```
事件广
播实现简单更加轻量
```
```
节点较多时，所有节点均被广播，资源浪
费
```
```
方案优点缺点
```
```
基于 RocketMQ 吞吐量高、高可用、保证可靠实时性不如 Redis
```
```
基于 Redis 实时性高、实现简单不保证可靠
```
```
基于 ZooKeeper 实现简单写入性能较差，不适合频繁写入场景
```
Netty 是一个高性能、事件驱动、异步非阻塞的网络通信框架，已在许多知名的开源项目中得到广泛应
用。

WebSocket 具有状态特性，这与 HTTP 的无状态特性不同，因此无法像 HTTP 一样通过集群方式实现
负载均衡。在长连接建立后，它会与服务端的某个节点保持会话，所以在集群环境下，要确定会话属于
哪个节点会有些困难。

**解决以上问题一般有两种技术方案** ：

1 ）一种是使用类似于微服务注册中心的技术来维护全局的会话映射关系；

2 ）另一种是使用事件广播，由各节点自行判断是否持有会话。这两种方案的对比如下表所示。

**WebSocket 集群方案** ：

考虑到实现成本和集群规模，我们选择了轻量级的事件广播方案。

实现广播的方法有多种，如基于 RocketMQ 的消息广播、基于 Redis 的 Publish/Subscribe、基于
ZooKeeper 的通知等。

这些方案的优缺点对比如下表所示。在考虑到吞吐量、实时性、持久化和实现难易程度等因素后，我们
最终选择了 RocketMQ。

**广播的实现方案对比** ：

#### 4 、新方案的实现思路

###### 4.1 系统架构

**网关的整体架构如下图所示** ：


```
注意：请点击图像以查看清晰的视图！
```
**网关的整体流程如下** ：

**1 ）** 客户端与网关的任何一个节点建立长连接，节点会将其加入到内存中的长连接队列。客户端会定期
向服务端发送心跳消息，若超过设定时间还未收到心跳，则认为客户端与服务端的长连接已断开，服务
端会关闭连接，清理内存中的会话。

**2 ）** 当业务系统需要向客户端推送数据时，通过网关提供的 **HTTP 接口** 将数据发送至网关。

**3 ）** 在收到推送请求后，网关会将消息 **写入 RocketMQ** 。

**4 ）** 网关作为消费者，以 **广播模式** 消费消息，所有节点都能收到消息。

**5 ）** 节点在收到消息后会判断推送的消息目标是否在其内存中维护的长连接队列里，如果 **存在则通过长
连接推送数据** ，否则直接忽略。

网关通过多节点构成集群，每个节点负责一部分长连接，实现负载均衡。当面临大量连接时，也可以通
过增加节点来分散压力，实现水平扩展。

同时，当节点出现故障时，客户端会尝试与其他节点重新建立长连接，确保服务的整体可用性。

###### 4.2 会话管理

在 WebSocket 长连接建立后，会话信息会保存在各个节点的内存中。

SessionManager 组件负责管理会话，它内部使用哈希表来维护 UID 与 UserSession 的关联。

UserSession 表示用户层面的会话，一个用户可能同时拥有多个长连接，因此 UserSession 内部同样使
用哈希表来维护 Channel 与 ChannelSession 的关联。

为了防止用户无休止地创建长连接，当 UserSession 内部的 ChannelSession 超过一定数量时，它会关
闭最早建立的 ChannelSession，以减少服务器资源的占用。

SessionManager、UserSession、ChannelSession 的关系如下图所示。

**SessionManager 组件** ：


```
注意：请点击图像以查看清晰的视图！
```
###### 4.3 监控与报警

为了掌握集群中建立的长连接数量和包含的用户数量，网关提供了基本的监控和报警功能。

网关接入了 Micrometer，将连接数和用户数作为自定义指标暴露，供 Prometheus 进行采集，从而实现
了与现有的微服务监控系统打通。

在 Grafana 中，可以方便地查看连接数、用户数、JVM、CPU、内存等指标数据，了解网关当前的服务
能力和压力。报警规则也可以在 Grafana 中配置，当数据异常时触发奇信（内部报警平台）报警。

#### 5 、新方案的性能压测

**压测准备** ：

```
1 ）选择两台配置为 4 核 16 G 的虚拟机，分别作为服务器和客户端；
2 ）在压力测试时，为网关开放 20 个端口，同时启动 20 个客户端；
3 ）每个客户端使用一个服务器端口建立 5 万个连接，从而可以同时创建百万个连接。
```
**连接数（百万级）与内存使用情况如下图所示** ：

```
[ root@sy-dev-1de4f0c2a target]# ss -s ; free -h
Total: 1002168 (kernel 1002250 )
TCP: 1002047 (estab 1002015 , closed 4 , orphaned 0 , synrecv 0 , timewait 4 /0),
ports 0
Transport Total IP IPv 6
* 1002250 - -
RAW 0 0 0
UDP 4 2 2
TCP 1002043 1002041 2
INET 1002047 1002043 4
FRAG 0 0 0
```
```
total used free shared buff/cache available
Mem: 15 G 4 .5 G 4 .5 G 232 K 6 .5 G 8 .2 G
Swap: 4 .0 G 14 M 4 .0 G
```

给百万个长连接同时发送一条消息，采用单线程发送，服务器发送完成的平均耗时在 10 s 左右，如下图
所示。

**服务器推送耗时** ：

一般同一用户同时建立的长连接都在个位数。

以 10 个长连接为例，在并发数 600 、持续时间 120 s 条件下压测，推送接口的 TPS 大约在 1600+，如下图
所示。

**长连接 10 、并发 600 、持续时间 120 s 的压测数据** ：

当前的性能指标已满足我们的实际业务场景，可支持未来的业务增长。

#### 6 、新方案的实际应用案例

为了更形象地展示优化效果，文章最后，我们以封面图添加滤镜效果为例，介绍了一个爱奇艺号采用新
WebSocket 网关方案的实例。

爱奇艺号自媒体在发布视频时，可以选择为封面图添加滤镜效果，引导用户提供更高质量的封面。

当用户选择封面图后，会提交一个异步的后台处理任务。

一旦异步任务完成，通过 WebSocket 将不同滤镜效果处理后的图片返回给浏览器，业务场景如下图所
示。

```
2021 -01-25 20 :51:02.614 INFO [mp-tcp-
gateway, 54 d 52 e 7 e 4240 b 65 a, 54 d 52 e 7 e 4240 b 65 a, false]
[ 600ebeb62@2559f4507adee3b316c571 /507 adee 3 b 316 c 571] 89558 --- [nio-8080-exec-6]
c.i.m.t.g.controller. NotifyController: [] [UID:] send message ...
2021 -01-25 20 :51:11.973 INF 0 [mp-tcp-
gateway, 54 d 52 e 7 e 4240 b 65 a, 54 d 52 e 7 e 4240 b 65 a, false]
[ 1600ebeb62@2559f4507adee3b316c571 /507 adee 3 b 316 c 571] 89558 --- [nio-8080-exec-6]
c.i.m.t.g.controller. NotifyController: [] [UID:] send message to 1001174
channels
```

从研发效率的角度来看，如果在业务系统中集成 WebSocket，至少需要 1-2 天的开发时间。

而直接使用新的 WebSocket 网关的推送功能，只需简单的接口调用就能实现数据推送，将开发时间降
低到分钟级别，大幅提高研发效率。

从运维成本的角度来看，业务系统不再包含与业务逻辑无关的通信细节，代码的可维护性更强，系统架
构变得更简单，运维成本大幅降低。

#### 7 、总结

WebSocket 是实现服务端推送的主流技术，适当使用可以有效提升系统响应能力，增强用户体验。

通过 WebSocket 长连接网关，可以迅速为系统增加数据推送能力，有效降低运维成本，提高开发效
率。

**长连接网关的价值在于** ：

```
1 ）它封装了 WebSocket 通信细节，与业务系统解耦，使得长连接网关与业务系统可独立优化迭
代，避免重复开发，便于开发与维护；
2 ）网关提供了简单易用的 HTTP 推送通道，支持多种开发语言接入，便于系统集成和使用；
3 ）网关采用了分布式架构，可以实现服务的水平扩容、负载均衡与高可用；
4 ）网关集成了监控与报警，当系统异常时能及时预警，确保服务的健康和稳定。
```
目前，新的 WebSocket 长连接实时网关已在爱奇艺号图片滤镜结果通知、MCN 电子签章等多个业务场
景中得到应用。

未来还有许多方面需要探索，例如消息的重发与 ACK、WebSocket 二进制数据的支持、多租户的支持
等。

#### 说在最后：有问题可以找老架构取经

架构之路，充满了坎坷

架构和高级开发不一样，架构问题是 open/开放式的，架构问题是没有标准答案的

正由于这样，很多小伙伴，尽管耗费很多精力，耗费很多金钱，但是，遗憾的是， **一生都没有完成架构
升级** 。


**所以，在架构升级/转型过程中，确实找不到有效的方案，可以来找 40 岁老架构尼恩求助.**

前段时间一个小伙伴，他是跨专业来做 Java，现在面临转架构的难题，但是经过尼恩几轮指导，顺利拿
到了 **Java 架构师+大数据架构师 offer** 。所以，如果遇到职业不顺，找老架构师帮忙一下，就顺利多
了。

#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》


## 亿级连接，淘宝接入层网关的架构设计

#### 说在前面

在 40 岁老架构师尼恩的 **读者交流群** (50+) 中，很多小伙伴拿到一线互联网企业如阿里、网易、有赞、希
音、百度、滴滴的面试资格。

最近，尼恩指导一个小伙伴简历，写了一个《 **高并发网关项目** 》，此项目帮这个小伙拿到 **字节/阿里/
微博/汽车之家** 面邀，所以说，这是一个牛逼的项目。

为了帮助大家拿到更多面试机会，拿到更多大厂 offer，

尼恩决定： 9 月份给大家出一章视频介绍这个项目的架构和实操，《 33 章：10 Wqps 高并发 Netty 网关
架构与实操》，预计月底发布。然后，提供一对一的简历指导，这里简历金光闪闪、脱胎换骨。

《 33 章：10 Wqps 高并发 Netty 网关架构与实操》海报如下：



配合《 33 章：10 Wqps 高并发 Netty 网关架构与实操》，尼恩会梳理几个工业级、生产级 **网关案例** ，作
为架构素材、设计的素材。

前面梳理了

```
《日流量 200 亿，携程网关的架构设计》
《千万级连接，知乎如何架构长连接网关？》
《日 200 亿次调用，喜马拉雅网关的架构设计》
《 100 万级连接，爱奇艺 WebSocket 网关如何架构》
```
除了以上的 4 个案例，在梳理学习案例的过程中，尼恩又找到一个漂亮的生产级案例：《 **亿级连接，淘
宝接入层网关的架构设计** 》，

注意，这又一个非常牛逼、非常顶级的工业级、生产级 **网关案例** 。

这些案例，并不是尼恩的原创。

这些案例，仅仅是尼恩在《 33 章：10 Wqps 高并发 Netty 网关架构与实操》视频备课的过程中，在互联
网查找资料的时候，收集起来的，供大家学习和交流使用。

```
《尼恩架构笔记》《尼恩高并发三部曲》《尼恩 Java 面试宝典》的 PDF，请到公号【技术自由
圈】获取
```
#### 亿级连接，淘宝接入层网关的架构设计

原文作者：手淘团队

架构之路，充满了坎坷。

架构之路，是迭代式，演进式的。

以手机淘宝为例，从早期的 HTTP API 网关，到后来在双十一活动中承担主要流量的自研高性能、全双
工、安全的阿里云通道服务 ACCS，在基础架构进化、网络优化、协议改进、异地多活、网络调度等方
面，都积累了丰富的经验，本文借此机会总结了整个技术演进过程。

#### 1 、技术背景

回顾移动电商在双十一业务启动之初，当时双十一当天的移动成交额达到 243 亿，占总成交额 571 亿
的 42.6%。

业务的快速发展，需要更多的主动推送以触达用户，

一些新的互动形式和玩法需要连接买家与买家、买家与卖家、买家与达人。

和其他的著名系统一样，早期的推送，是轮询模式的。

由于缺乏有效的通道能力，早期业务采取的是不断轮询服务器。

轮询方式，不仅给服务器带来不必要的压力，也对用户手机的电量和流量造成了巨大的浪费。

在双十一等大型促销活动期间，过多的不必要请求，可能会导致后端集群限流，从而影响用户体验。


#### 2 、移动网络环境的挑战性一直都存在

随着 3 G、4 G、5 G 移动网络的广泛应用，网速得到了显著提升。

然而，网络环境的多样性和差异性使得移动网络环境变得更加复杂，双十一等高峰期常常出现移动网络
劫持等问题。

解决这类问题的效率很低，需要追踪用户、再现现场，甚至联系网络工程师和运营商进行排查，耗时较
长。

在我们的舆情反馈中，用户经常反映“某个页面加载缓慢、页面无法打开、请求速度慢、某个功能打开
速度慢”等问题。

过去我们应对这些问题的办法不多，只能逐一排查，非常被动。很多网络问题偶发性较强，一旦错过就
难以追踪。

**诸如此类的问题，背后的原因很多** ：

```
1 ）运营商问题；
2 ）机房部署原因；
3 ）客户端 SDK Bug；
4 ）弱网和网络抖动；
5 ）DNS 劫持和数据篡改。
```
在 PC 时代，我们访问网站的网络条件相对稳定，因此在开发过程中很少考虑网络对用户体验的影响。

然而，移动 APP 的情况就不同了，尤其在我国，基础移动网络环境尚不完善，很多用户在地铁、公交
车等移动环境下访问，移动基站的频繁切换进一步加剧了网络不稳定性。

从手机淘宝的数据来看，我们每天活跃用户中有很大一部分来自网络环境较差的地区。如果端到云的连
接不稳定、延迟高，那么用户体验就无从谈起。

基础网络效率就像一辆火车，时延是火车的速度（启动时间），带宽是火车的车厢容量，整个传输物理
链路就像是火车的铁轨。

在当前复杂的移动网络环境下，我们的目标是让所有用户都能在手机淘宝享受到流畅的体验。

下面这张图能帮助大家更直观地了解我国移动网络环境。

它描述了从用户到 IDC 的端到端路由情况，数据传输耗时长、丢包率高，同时安全性也较差，DNS 劫
持、内容劫持等问题在我国相当普遍。


因此，在网络通道优化方面，我们有很多工作可以去做，去探索如何突破运营商基础网络的局限，为用
户打造完美的购物体验。

#### 3 、整体技术架构

为了满足移动电商业务迅速发展的需求，我们决定构建一个世界一流的网络接入服务，打造一个无线网
络下的“水、电、煤”基础设施。

**这样一个基础设施需要做到的四个目标** ：

```
1 ）全双工；
2 ）低延时；
3 ）高安全；
4 ）开放。
```
在这四个目标之上，是围绕这个接入服务配套的运维体系，旨在帮助最终用户获得良好的终端体验，同
时协助开发者快速构建自己的业务。


**如上图所示，在整个接入服务上我们划分为两层** ：

```
1 ） 接入网关 ：负责保持连接、解析和分发消息；
2 ） 应用网关 ：实现各种应用层协议，如 API、SYNC、RPC、PUSH 等，应用网关背后是具体的业
务系统。
```
同时，我们采用了统一调度服务而非传统的 DNS，调度服务作为我们的控制中心，可以有效地指挥客户
端，并避免受到 DNS 污染的影响。

与服务端的分层架构相对应的是客户端的 SDK，最底层的统一网络库 SDK 汇集了我们的网络优化策
略，并为各个应用网关技术的 SDK 提供 API。

基于这种开放架构，业务方可以选择直接开放具体的后端服务，对接不同的应用网关，无需了解网络背
后的细节，并通过应用网关（如 API 网关）提供的开发工具快速生成客户端代码。

业务方也可以基于这个接入层设计自己的协议。

统一接入层集中管理了用户的设备和在线状态，并提供信息双向传递能力。

**如下图所示** ：


网关将致力于解决中间网络的通讯问题，为上层服务提供高品质的双向通信能力。

#### 4 、稳定性与容灾

稳定性与容灾是服务端中间件始终关注的问题，统一接入层汇聚了网关的利益与风险，

一旦入口出现问题，受影响的用户范围将无法想象，如何实现更高稳定性，是一项巨大的挑战。

###### 4.1 网关架构的优化

对于一个统一网关而言，不同业务网关的信息传递特性各异。

大部分业务全天较为平稳，但某些营销类业务会在短时间内发布大量信息，这种信息发布会占用网关大
量资源，对用户正常访问产生影响。

**举个例子** ：push 服务需要通过网关推送 2 亿条消息，这些消息需在短时间内全部发送完毕。同时，网
关还在为正常用户交互提供服务，大量信息推送与正常用户交互争夺资源，最终可能导致正常用户交互
失败，对业务而言，这是不能接受的。

**基于上面的情况，整个网关在布署上分为两个集群** ：

```
1 ）一个集群处理常态的在线用户访问；
2 ）一个集群处理海量信息的推送。
```
如下图所示，通过这种部署方式，避免了不同业务形态对统一网关的冲击，实现了不同业务形态的隔
离。


###### 4.2 异地多活

在异地多活的整体方案中，统一网关承担了快速引导流量的职责，这是确保该方案成功执行的重要环
节。

异地多活是一个多机房的整体方案，

异地多活架构，主要是在多个地区同时存在对等的多个机房，以用户维度划分，多机房共同承担全量用
户的流量；

在单个机房发生故障时，故障机房的流量可以快速的被迁引到可用机房，从而缩短故障恢复的时间。

**4.2.1 无线接入层单元化的协商机制：**

先看一下 web 端在这异地多活中的实现方式：

从上图中我们可以看出，浏览器的业务请求会被发送至 CDN，然后根据 CDN 上保存的分发规则，将流
量分发至后续的站点。

无线端也这样做吗？

```
1 ）客户端具有强大的能力，能够更加灵活地处理；
2 ）CDN 的分发节点会增加更多的硬件成本；
3 ）对于需要双向通信能力的客户端，信息传递会更加复杂。
```
这些都是我们在考虑与 web 不同的地方，我们是否能做出一些不同的选择呢？


如上图所示，我们借助了客户端的强大能力，利用协商的机制来完成用户的请求正确被分配到不同的单
元。

**含以下几点** ：

```
1 ）客户端的请求需包含当前用户所属单元的信息；
2 ）当请求抵达服务端时，服务端会判断用户所属单元是否正确，若不正确则将用户重新定向至正
确单元；
3 ）当前请求在服务端上通过网关进行跨单元调用，以确保业务正确性；
4 ）当客户端所属单元发生更新后，后续请求将发送至正确单元。
```
**4.2.2 无线接入层单元化的旁路调度：**

协商机制看起来很不错，这里一个重磅炸弹丢过来了，机房的入口网络断了！


如上图，当外网不可用时，协商的机会都没有，故障单元的用户无法恢复，此时，旁路调度服务登场。

如上图，我们设计的调度中心这时又承担了单元化的旁路调度职责，

当 app 访问的单元无法访问的时候，app 会访问不同单元的调度中心，询问用户的归属单元。

通过这种方式取得可用的单元节点，将用户切到正确的单元。

此方案同样适用于单机房接入层网关无法使用的情况。

**4.2.3 应用层网关不可用：**

某个单元机房的应用层网关不可用，这时等待应用网关排查问题需要的时间比较久，为了达到最快的故
障恢复，我们通过开关把修改接入层的转发规则，将流量切到可用的单元。

如下图所示：


#### 5 、端到端网络优化

###### 5.1 统一网络库

在网络优化的初期，我们的目标是创建一个通用的网络库，该库包含策略、httpDNS、SPDY 协议等所
有系统网络优化所需的各个方面。

上层 api 网关请求逻辑、推送逻辑、上传下载逻辑对于这样一个通用网络库来说都是业务。

在分层上将通用网络库和上层应用逻辑区分开、完全解耦，对于长期持续优化网络是非常必要的。

**如下图所示架构** ：


这样架构上分离，可以让我们更专注更系统化去做无线网络优化。

**统一网络接入库的几个重要特性** ：

```
1 ）灵活控制客户端网络行为策略（建连、超时处理、请求协议、是否加密）；
2 ）包含 HTTPDNS；
3 ）支持异地多活；
4 ）更细粒度控制和调度 (域名级和域名下参数级)。
```
1 、 2 、 3 、 4 均由网络调度中心的集群控制，我们希望这个可以做到与业务无关，去掉一些阿里的业务属
性后，这个模块大家可以理解为 HTTPDNS，可以理解我们在 HTTPDNS 之外做了大量网络优化的端到端
的工作。

###### 5.2 就近就快接入

基于网络库，我们实现了一套智能学习的网络策略。

这个策略可以根据客户端在不同网络环境下的连接策略进行智能学习，当用户重新回到这个网络环境
时，会给出最优的策略进行快速连接，并定期更新或淘汰本地缓存的历史最优网络策略。

为了实现更快速的穿透各自网络并提供更好的接入性能，接入服务器支持了多种协议和端口，客户端在
建立连接时可以实现高速接入网络。

我们关注的一个重要指标是在客户端打开 30 秒内的网络请求成功率，这是为了提供更快的连接速度，
以提高用户体验。

基于调度中心，我们构建了一个智能大数据分析平台，

智能大数据分析平台收集客户端在网络请求过程中的重要数据，如：

```
连接时间、
首包接收时间、
整包接收时间、
SSL 握手时间等。
```

通过分析这些数据，我们可以确定网络异常区域，调整我们的近距离高速接入规则，甚至推动 IDC 建设
和 CDN 布局的优化。

###### 5.3 弱网优化和抗抖动

在弱网优化上，我们尝试了 QUIC 协议，发现在网络延迟较高和丢包严重的情况下，其表现优于 TCP。

经过线上手机淘宝灰度版本的实测，切换到 QUIC 后，平均 RT 收益提高了近 20%。

但考虑到 QUIC 在移动网络可能存在穿透性问题，未来我们计划采取 SPDY 为主，QUIC 为辅的方式来
完善我们的网络连接策略。

```
“SPDY”(发音同 “speedy”) 是谷歌正在开发一种新的网络协议，以最小化网络延迟，提升网络速
度，优化用户的网络使用体验。
```
```
SPDY 并不是一种用于替代 HTTP 的协议，而是对 HTTP 协议的增强。新协议的功能包括数据流的
多路复用、请求优先级，以及 HTTP 包头压缩。谷歌已经开发一个网络服务器原型机，以及支持
SPDY 协议的 Chrome 浏览器版本。
```
```
谷歌表示，引入 SPDY 协议后，在实验室测试中页面加载速度比原先快 64%。这一数据基于对全
球 25 大网站的下载测试。目前 SPDY 团队已经开发了一个可使用的原型产品，谷歌决定开放这一
项目，希望 “网络社区能积极参与、提供反馈及帮助”。
```
在网络环境较差的情况下，我们采用了长短链接结合的策略。

当长链接遇到请求超时或穿透性较差的情况时，我们利用短链接 HTTP 去请求数据（在移动网络环境
下，HTTP 协议尤其是 HTTP 1.0 的穿透性较好），从而在极端情况下最大限度地保证用户体验。

**数据如下图** ：


网络切换和网络抖动情况下的技术优化也是一个很重要的方面，我们经常遇到移动设备网络切换和信号
不稳定的情况，在这种情况我们怎么保证用户的体验？

针对这种情况我们的思路是有策略合理增加重试。

我们对一个网络请求以是否发送到 socket 缓冲区作为分割，将网络请求生命周期划分为“请求开始到发
送到 socket 缓冲区”和“已经发送到 socket 缓冲区到请求结束”两个阶段。

在阶段一内请求失败了，会根据业务需求帮助业务请求去做重试。阶段二请求失败只针对读操作提供重
试能力。

**设想一个场景** ：

用户在进入电梯时发起一个刷新数据请求，由于网络抖动，电梯内的网络连接断开。

在这种情况下，我们可以采取合理的策略进行重试。

这样，当用户离开电梯时，网络请求很可能已经重试成功，帮助用户获取所需的数据，从而提升用户体
验和客户端的网络抗抖动能力。

###### 5.4 加密传输 1 秒钟法则

众所周知，传统的 HTTPS 握手流程较为繁琐，在网络质量较差的情况下，可能导致连接速度缓慢，用
户体验较差，甚至无法完成安全握手。

然而，从安全的角度考虑，我们需要一个安全的传输通道来保护用户的隐私数据。

面对安全与网络体验的冲突，我们需要在技术上取得突破。

因此，我们开发了一套 slight-ssl 技术，参考了 TLS 1.3 协议，通过合并请求、优化加密算法、使用
session-ticket 等策略，最终在安全和体验之间找到了平衡点。

在基本不牺牲用户体验的前提下，实现了安全传输的目标，同时还显著提升了服务端的性能。

通过技术创新，我们实现了无线网络加密传输下的 1 秒钟法则。

#### 说在最后：有问题可以找老架构取经

架构之路，充满了坎坷。架构和高级开发不一样：

```
架构问题是 open/开放式的，
架构问题是没有标准答案的。
```
正由于这样，很多小伙伴在转型之路上耗费很多精力，耗费很多金钱，但遗憾的是， **一生都没有完成架
构升级** 。

**所以，在架构升级/转型过程中，确实找不到有效的方案，可以来找 40 岁老架构尼恩求助.**

前段时间一个 17 年经验小伙伴，跨专业来做 Java，也是面临转架构的难题，几个月没有 offer，焦虑不
以。

但是经过尼恩几轮指导，顺利拿到了 **Java 架构师+大数据架构师 offer** 。

所以，如果遇到职业不顺，自己又一个人搞不定的情况下，可以找尼恩帮忙一下，就顺利多了。


#### 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》



```
技术自由圈
```
## 未来职业，如何突围：三栖架构师


```
技术自由圈
```
### 成功案例： 2 年翻 3 倍， 35 岁卷王成功转型为架构师

详情：http://topcoder.cloud/forum.php?mod=forumdisplay&fid=43&page=1


技术自由圈


技术自由圈


技术自由圈


```
技术自由圈
```
### 硬核推荐：尼恩 Java 硬核架构班

详情：https://www.cnblogs.com/crazymakercircle/p/9904544.html


技术自由圈


```
技术自由圈
```
##### 架构班（社群 VIP）的起源：

最初的视频，主要是给读者加餐。很多的读者，需要一些高质量的实操、理论视频，所以，我就围绕书，和底层，做了几个
实操、理论视频，然后效果还不错，后面就做成迭代模式了。

##### 架构班（社群 VIP）的功能：^

提供高质量实操项目整刀真枪的架构指导、快速提升大家的:
⚫ 开发水平
⚫ 设计水平
⚫ 架构水平
弥补业务中 CRUD 开发短板，帮助大家尽早脱离具备 3 高能力，掌握：
⚫ 高性能
⚫ 高并发
⚫ 高可用
作为一个高质量的架构师成长、人脉社群，把所有的卷王聚焦起来，一起卷：
⚫ 卷高并发实操
⚫ 卷底层原理
⚫ 卷架构理论、架构哲学
⚫ 最终成为顶级架构师，实现人生理想，走向人生巅峰

##### 架构班（社群 VIP）的目的：^

⚫ 高质量的实操，大大提升简历的含金量，吸引力，增强面试的召唤率
⚫ 为大家提供九阳真经、葵花宝典，快速提升水平
⚫ 进大厂、拿高薪
⚫ 一路陪伴，提供助学视频和指导，辅导大家成为架构师
⚫ 自学为主，和其他卷王一起，卷高并发实操，卷底层原理、卷大厂面试题，争取狠卷 3 月成高手，狠卷 3 年成为顶级架
构师


```
技术自由圈
```
##### N 个超高并发实操项目：简历压轴、个顶个精彩


```
技术自由圈
```
【样章】第 17 章：横扫全网 Rocketmq 视频第 2 部曲: 工业级 rocketmq 高可用（HA）底层原
理和实操

工业级 rocketmq 高可用底层原理，包含：消息消费、同步消息、异步消息、单向消息等不同消息的底层原理和源码实现；
消息队列非常底层的主从复制、高可用、同步刷盘、异步刷盘等底层原理。
工业级 rocketmq 高可用底层原理和搭建实操，包含：高可用集群的搭建。
解决以下难题：
1 、技术难题：RocketMQ 如何最大限度的保证消息不丢失的呢？RocketMQ 消息如何做到高可靠投递？
2 、技术难题：基于消息的分布式事务，核心原理不理解
3 、选型难题： kafka or rocketmq ，该娶谁？
下图链接：https://www.processon.com/view/6178e8ae0e3e7416bde9da19


```
技术自由圈
```
### 简历优化后的成功涨薪案例（ VIP 含免费简历优化）


技术自由圈


技术自由圈


技术自由圈


技术自由圈


技术自由圈


技术自由圈


技术自由圈


```
技术自由圈
```
### 修改简历找尼恩（资深简历优化专家）

⚫ 如果面试表达不好，尼恩会提供简历优化指导

⚫ 如果项目没有亮点，尼恩会提供项目亮点指导

⚫ 如果面试表达不好，尼恩会提供面试表达指导

作为 40 岁老架构师，尼恩长期承担技术面试官的角色：

⚫ 从业以来，“阅历”无数，对简历有着点石成金、改头换面、脱胎换骨的指导能力。

⚫ 尼恩指导过刚刚就业的小白，也指导过 P 8 级的老专家，都指导他们上岸。

如何联系尼恩。尼恩微信，请参考下面的地址：

语雀：https://www.yuque.com/crazymakercircle/gkkw8s/khigna
码云：https://gitee.com/crazymaker/SimpleCrayIM/blob/master/疯狂创客圈总目录.md


