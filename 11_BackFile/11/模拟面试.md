```
技术自由圈
```
# 牛逼的职业发展之路

40 岁老架构尼恩用一张图揭秘: Java 工程师的高端职业发展路径，走向食物链顶端的之路

链接：https://www.processon.com/view/link/618a2b62e0b34d73f7eb3cd


```
技术自由圈^
```
# 史上最全：价值 10 W 的架构师知识图谱

此图梳理于尼恩的多个 3 高生产项目：多个亿级人民币的大型 SAAS 平台和智慧城市项目

链接：https://www.processon.com/view/link/60fb9421637689719d


```
技术自由圈
```
# 牛逼的架构师哲学

40 岁老架构师尼恩对自己的 20 年的开发、架构经验总结

链接：https://www.processon.com/view/link/616f801963768961e9d9aec


```
技术自由圈
```
# 牛逼的 3 高架构知识宇宙

尼恩 3 高架构知识宇宙，帮助大家穿透 3 高架构，走向技术自由，远离中年危机

链接：https://www.processon.com/view/link/635097d2e0b34d40be778ab


```
技术自由圈
```
# 尼恩 Java 面试宝典

40 个专题（卷王专供+ 史上最全 + 2023 面试必备）
详情：https://www.cnblogs.com/crazymakercircle/p/13917138.html


```
技术自由圈^
```
# 未来职业，如何突围：三栖架构师


## 专题 41 ：大厂面试真题 （史上最全、定期更

## 新）

#### 本文版本说明：V

```
由于社群很多小伙伴，在面试，不断的交流最新的面试难题，所以，《尼恩Java面试宝典》， 后
面会不断升级，迭代。
本专题，作为 《尼恩Java面试宝典》专题之一， 《尼恩Java面试宝典》一共 41 个面试专题，后
续还会增加
```
###### 《尼恩 Java 面试宝典》升级的规划为：

后续基本上， **每一个月，都会发布一次** ，最新版本，可以关注公众号【技术自由圈】，扫描扫架构师尼
恩个人微信，发送 “领电子书” 获取。

尼恩的微信二维码在哪里呢 ？ 请参见文末

###### 历史版本：

**V 95 升级说明（2023-08-06）：**

炸裂，靠“吹牛”过京东一面，月薪 40 k

**V 93 升级说明（2023-07-29）：**

太猛了，靠“吹牛”过顺丰一面，月薪 30 k

**V 83 升级说明（2023-07-08）：**

炸裂了... 京东一面索命 40 问，过了就 50 W+

**V 78 升级说明（2023-06-10）：**

问麻了... 阿里一面索命 27 问，过了就 60 W+

**V 72 升级说明（2023-06-03）：**

百度狂问 3 小时，大厂 offer 到手，小伙真狠！

**V 71 升级说明（2023-06-01）：**

饿了么太狠：面个高级 Java，抖这多硬活、狠活

**V 69 升级说明（2023-05-30）：**

字节狂问 1 小时，小伙 offer 到手，太狠了！

**V 56 升级说明（2023-03-03）：**

收个滴滴 Offer：从小伙三面经历，看看需要学点啥？

###### 面试问题交流说明：


如果遇到面试难题，或者职业发展问题，或者中年危机问题，都可以来疯狂创客圈社群交流，

加入交流群，加尼恩微信即可

## 收个滴滴 Offer：从小伙三面经历，看看需要

## 学点啥？

#### 说在前面

在尼恩的（50+） **读者社群** 中，经常有小伙伴，需要面试大厂。

后续结合一些大厂的面试真题，给大家梳理一下学习路径，看看大家需要学点啥？

这里也一并把题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》，供后面的小伙伴参考，提升大家
的 3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，相关尼恩 架构笔记、面试题 的PDF文件，请从这里获取：码云
```
#### 一面 (45 min)

###### 1 、自我介绍

###### 2 、工作解决过什么技术难题？

除了 _crud_ ，最好能做一个、两个有高价值的轮子项目，这里可以结合轮子项目，介绍自己遇到的技术难
题。

如果找不到好的轮子项目，可以来咨询尼恩。

###### 3 、JAVA 中常用的集合，有什么区别

在 java 中集合主要分为：List，Set，Map 三种，其中 List 与 Set 是继承自 Collection，而 Map 不是。

List 与 Set 的区别：List 中的元素有存放顺序，并且可以存放重复元素，检索效率高，插入删除效率低，
Set 没有存放顺序，而且不可以存放重复元素，后来的元素会把前面重复的元素替换掉，检索效率低，
插入删除效率高。（Set 存储位置是由它的 HashCode 码决定的，所以它存储的对象必须有 equals () 方
法，而且 Set 遍历只能用迭代，因为它没有下标。）

###### 4 、string, stringbuff, StringBuilder 他们之间的区别，谁快


```
String ：不可变的字符序列；底层使用 byte[] 存储。
StringBuffer ：可变的字符序列；线程安全的，效率低；底层使用 byte[] 存储。
StringBuilder ：可变的字符序列；jdk5.0新增的，线程不安全的，效率高；底层使用 byte[] 存
储。
```
效率从高到底依次是：StringBuilder>StringBuffer>String

###### 5 、List 遍历中删除元素会有什么问题？那应该怎么遍历

遍历删除 List 中符合条件的元素主要有以下几种方法：

```
1. 普通for循环
2. 增强for循环 foreach
3. 迭代器iterator
4. removeIf 和 方法引用 (一行代码搞定)
```
其中使用普通 for 循环容易造成遗漏元素的问题，
使用增强 for 循环 foreach 会报 java. util. ConcurrentModificationException 并发修改异常。

所以推荐使用迭代器 iterator，或者 JDK 1.8 以上使用 lambda 表达式进行 List 的遍历删除元素操作。

以下是上述几种方法的具体分析：

**普通 for 循环**

由于在循环中删除元素后，list 的索引会自动变化，list.size () 获取到的 list 长度也会实时更新，所以会造
成漏掉被删除元素后一个索引的元素。

比如循环到第 2 个元素时你把它删了，接下来去访问第 3 个元素，实际上访问到的是原来 list 的第 4 个元
素，因为原来的第 3 个元素变成了现在的第 2 个元素。这样就造成了元素的遗漏。

**增强 for 循环 foreach**

```
/**
* 普通for循环遍历删除元素
*/
List<Student> students = this.getStudents();
for (int i= 0 ; i<students.size(); i++) {
if (students.get(i).getId()% 3 == 0 ) {
Student student = students.get(i);
students.remove(student);
}
}
```

使用 foreach 遍历循环删除符合条件的元素，不会出现普通 for 循环的遗漏元素问题，但是会产生
java. util. ConcurrentModificationException 并发修改异常的错误。

报 ConcurrentModificationException 错误的原因：

先来看一下 JDK 源码中 ArrayList 的 remove 源码是怎么实现的：

一般情况下程序的执行路径会走到 else 路径下最终调用 fastRemove 方法：

在 fastRemove 方法中，可以看到第 2 行把 modCount 变量的值加一，但在 ArrayList 返回的迭代器会做迭
代器内部的修改次数检查：

而 foreach 写法是对实际的 Iterable、hasNext、next 方法的简写，因为上面的 remove (Object) 方法修改
了 modCount 的值，所以才会报出并发修改异常。

```
/**
* 增强for循环遍历删除元素
*/
List<Student> students = this.getStudents();
for (Student stu : students) {
if (stu.getId() == 2 )
students.remove(stu);
}
```
```
public boolean remove(Object o) {
if (o == null) {
for (int index = 0 ; index < size; index++)
if (elementData[index] == null) {
fastRemove(index);
return true;
}
} else {
for (int index = 0 ; index < size; index++)
if (o.equals(elementData[index])) {
fastRemove(index);
return true;
}
}
return false;
}
```
```
private void fastRemove(int index) {
modCount++;
int numMoved = size - index - 1 ;
if (numMoved > 0 )
System.arraycopy(elementData, index+ 1 , elementData, index,
numMoved);
elementData[--size] = null; // clear to let GC do its work
}
```
```
final void checkForComodification() {
if (modCount != expectedModCount)
throw new ConcurrentModificationException();
}
```

要避免这种情况的出现则在使用迭代器迭代时（显式或 for-each 的隐式）不要使用 List 的 remove，改为
用 Iterator 的 remove 即可。

**迭代器 iterator**

由上述 foreach 报错的原因，注意要使用迭代器的 remove 方法，而不是 List 的 remove 方法。

**removeIf 和方法引用**

在 JDK 1.8 中，Collection 以及其子类新加入了 removeIf 方法，作用是按照一定规则过滤集合中的元素。

方法引用是也是 JDK 1.8 的新特性之一。方法引用通过方法的名字来指向一个方法，使用一对冒号 :: 来完
成对方法的调用，可以使语言的构造更紧凑简洁，减少冗余代码。

使用 removeIf 和方法引用删除 List 中符合条件的元素：

作为 removeIf 的条件，为 true 时就删除元素。

使用 removeIf 和方法引用，可以将原本需要七八行的代码，缩减到一行即可完成，使代码的构造更紧
凑简洁，减少冗余代码。

###### 6 、jvm 运行时数据区介绍

参考尼恩《 _Java_ 面试宝典》 _JVM_ 专题，有好几百页，非常细致

###### 7 、java 中如何直接访问内存

Java 最初被设计为一种安全的受控环境。尽管如此，Java HotSpot 还是包含了一个“后门”，提供了一些
可以直接操控内存和线程的低层次操作。

```
/**
* 迭代器iterator
*/
List<Student> students = this.getStudents();
System.out.println(students);
Iterator<Student> iterator = students.iterator();
while (iterator .hasNext()) {
Student student = iterator .next();
if (iterator.getId() % 2 == 0 )
iterator.remove();
//这里要使用Iterator的remove方法移除当前对象，
// 如果使用List的remove方法，则同样会出现ConcurrentModificationException
}
```
```
List<String> urls = this.getUrls();
```
```
// 使用方法引用删除urls中值为"null"的元素
urls.removeIf("null"::equals);
```

这个后门类——sun. misc. Unsafe——被 JDK 广泛用于自己的包中，如 java. nio 和 java. util. concurrent。

这个类在 JDK 中有广泛的应用，例如，java. nio 和 java. util. concurrent、Netty、Caffeine。

但是丝毫不建议随意使用这个后门。因为这个 API 十分不安全、不轻便、而且不稳定。很难想象在日常
开发中使用这些危险的，不可移植和未经校验的 API。

然而, Unsafe 提供一种简单的方法来观察 HotSpot JVM 内部的一些技巧。

获取 Unsafe

sun. misc. Unsafe 这个类的访问是受限的，它的构造方法是私有的，相应的工厂方法要求必须被
Bootloader 载入才能使用，也就是说，只有 JDK 内部分才能使用这个工厂方法来构造 Unsafe 对象。

幸运地是，有一个 theUnsafe 属性可以被利用来检索 Unsafe 实例，我们可以见到的写一个反射方法，来
获取 Unsafe 实例：

下面将看看一些 Unsafe 的方法。

1. 对直接内存进行读写。

2. 另一个类似的方法对直接内存进行读写，将 C 语言的结构体和 Java 对象进行转换。

3. 分配内存，可以看做是 C 语言的 malloc () 函数的一种包装

```
public final class Unsafe {
```
```
...
```
```
private Unsafe() {}
```
```
private static final Unsafe theUnsafe = new Unsafe();
...
public static Unsafe getUnsafe() {
Class cc = sun.reflect.Reflection.getCallerClass( 2 );
if (cc.getClassLoader() != null)
throw new SecurityException(“Unsafe”);
return theUnsafe;
```
```
}
...
```
```
}
```
```
public static Unsafe getUnsafe() {
try {
Field f = Unsafe.class.getDeclaredField(“theUnsafe”);
f.setAccessible(true);
return (Unsafe)f.get(null);
} catch (Exception e) { /* ... */ }
}
```
```
long getAddress(long address) 和void putAddress(long address, long x)
```
```
int getInt(Object o, long offset) , void putInt(Object o, long offset, int x)
```

具体请去看 NIO 的源码，尼恩在《高性能葵花宝典》中，有详细的介绍。

sun. misc. Unsafe 提供了几乎是不受限制的监控和修改虚拟机运行时数据结构的能力。

尽管这些能力几乎是和 Java 开发本身不相干的，但是对于想要学习 HotSpot 虚拟机但是没有 C++代码调
试，或者需要去创建特别的分析工具的人来说，Unsafe 是一个伟大的工具。

###### 8 、类加载器，双亲委派机制

参考《尼恩 Java 面试宝典》 JVM 专题，有好几百页，非常细致

###### 9 、java 线程状态，之间如何转换

参考《尼恩 Java 面试宝典》多线程专题，那个专题，对线程的状态，做了超乎寻常的介绍，有好几百
页，非常细致

###### 10 、sleep 和 wait 的区别

sleep 方法和 wait 方法都是用来将线程进入休眠状态的，并且 sleep 和 wait 方法都可以响应 interrupt
中断，也就是线程在休眠的过程中，如果收到中断信号，都可以进行响应并中断，且都可以抛出
InterruptedException 异常，那 sleep 和 wait 有什么区别呢？

**区别一：语法使用不同**

wait 方法必须配合 synchronized 一起使用，不然在运行时就会抛出 IllegalMonitorStateException 的
异常，

而 sleep 可以单独使用，无需配合 synchronized 一起使用。

**区别二：所属类不同**

wait 方法属于 Object 类的方法，而 sleep 属于 Thread 类的方法，

**区别三：唤醒方式不同**

sleep 方法必须要传递一个超时时间的参数，且过了超时时间之后，线程会自动唤醒。

而 wait 方法可以不传递任何参数，不传递任何参数时表示永久休眠，直到另一个线程调用了 notify 或
notifyAll 之后，休眠的线程才能被唤醒。

也就是说 **sleep 方法具有主动唤醒功能，而不传递任何参数的 wait 方法只能被动的被唤醒** 。

**区别四：释放锁资源不同**

**wait 方法会主动的释放锁，而 sleep 方法则不会** 。

###### 11 、数据库中有哪些方法何以删除表数据, 有什么区别

truncate, delete, drop

**truncate、delete、drop 区别概述**

它们的区别如下表所示：

```
long allocateMemory(long bytes)
```

```
区别点 drop truncate delete
```
```
执行速
度 快 较快 慢
```
```
命令分
类 DDL（数据定义语言） DDL（数据定义语言） DML（数据操作语言）
```
```
删除对
象
```
```
删除整张表和表结构，
以及表的索引、约束和
触发器。
```
```
只删除表数据，表的结
构、索引、约束等会被
保留。
```
```
只删除表的全部或部分数
据，表结构、索引、约束等
会被保留。
```
```
删除条
件
(where)
```
```
不能用 不能用 可使用
```
```
回滚 不可回滚 不可回滚 可回滚
```
```
自增初
始值 - 重置 不重置
```
truncate、drop 和 delete 的区别主要有以下 6 点：

```
执行速度：drop > truncate > detele。
delete 和 truncate 只删除表数据，而 drop 会删除表数据和表结构以及表的索引、约束和触发
器。
delete 可以加 where 条件实现部分数据删除，而 truncate 和 drop 不能加 where 条件是整体删
除。
truncate 和 drop 是立即执行，且不能恢复；而 delete 会走事务，可以撤回和恢复。
truncate 会重置自增列为 1 ，而 delete 不会重置自增列。
truncate 和 drop 是 DDL 语句，而 delete 是 DML 语句。
```
###### 12 、为什么 delete 相对比较慢

简单来说

delete 是逐行执行的，并且在执行时会把操作日志记录下来，以备日后回滚使用，所以 delete 的执行
速度是比较慢的；而 truncate 的操作是先复制一个新的表结构，再把原先的表整体删除，所以它的执
行速度居中，而 drop 的执行速度最快。

往深入说，为什么 delete 相对比较慢，原因复杂：

1 、查询的表，没有加索引

写了一个查询 sql，结果查询的条件字段没有索引，导致需要全表扫描，查找数据，这是大家遇到最
多，也是最容易理解的。

这种，一般，在表数据量比较少时，如低于十万级，不会觉得慢，但是，当表中数据量达到或超过十万
级时，就会体现出查询时间特别长了。

2 、查询的索引，无效

知道索引很重要，所以，一般建表的时候，都会加上一些索引，但是，有了索引，并不代表查询速度就
一定会快，因为，还要看能否正确使用索引。


```
查询条件，没有索引字段
查询条件使用 or， 选择式过滤条件，导致索引无效
查询条件使用like，且从头部开始模糊匹配，导致索引无效
查询条件不满足复合索引的最左匹配原则，导致索引无效
查询条件，索引列使用了隐式类型转换，导致索引无效
查询条件，索引列使用了聚合函数，导致索引无效
查询条件，索引列使用了算术运算(+、-、...)，导致索引无效
查询条件，索引列使用了逻辑运算(!=、<>、is null、 is not null ...)，导致索引无效
左右关联时，字段类型不一致，导致索引无效
```
3 、查询使用了临时表

临时表可能大家不知道，但是回表查询，大家可能听说过，就是说一次查询不满足，还需要再查一次，
查两次才能出结果，这当然就会慢啦。

哪临时表一般都是怎么产生的呢？

通过一次查询返回的数据，要进行下一步的过滤、显示时，发现返回的数据中不满足过滤条件，或者没
有显示的字段，又要回头查一次原表，从原表中获取满足条件的数据，这些数据，就放在临时表中。

本来，回头查一次，就已经消耗了时间了，奈何，临时表还有空间大小限制，占用内存空间，还可能空
间不够用，存放不下所有数据。所以，一般，只要出现使用了临时表，这个 sql 的性能都很差。

4 、join 或子查询，太多

关联查询，在实际工作中，非常场景，关联的表越多，那么，数据过滤筛选就越来复杂，时间自然就会
越长了。所以，一般而言，关联表不建议超过 3 个，而且数据量小的表放左边，大的表放在右边。

5 、查询结果数据量，太大了

查询结果数据量太大，常见的有两种，

第 1 种，就是直查的表数据量太大，如千万级。一张表千万级，即使建了索引，索引文件也会很大，深
度也会很深，查询速度，自然就会很慢了。

第 2 种，就是联表笛卡尔积量太大。对于第一种，优化建议，一般是对表采用分表分区了。而第二种，
就简单粗暴的 sql 拆分优化。

6 、锁竞争

现在 MySQL 的表一般都是 InnoDB 存储引擎，这种引擎的表是行锁，每次锁定一行。即，如果有一个事
务在操作某一行数据，就会锁定这一行的操作行为，其他事务不能操作，直到前一个事务操作完成，
commit 数据变更之后，后面的事务才能获取操作。这就会出现，一个事务，做变更，没有结束，后面
的所有事务操作就得等待，如果此时又有多个事务在排队等待，当前一事务操作结束，等待的事务就会
竞争抢锁，这种‘你不仁，我不义’，一旦发生，SQL 的性能就会很慢了。

7 、limit 分页，太深

有些时候，我们需要偏移一定量数据之后，获取某些数据，就很容易想到用 limit，但是，如果偏移量很
大时，就会发现 SQL 执行起来非常非常慢了，因为，偏移量会分页读取到 buffpool 中，数据量大，占用
的 buffpool 空间就会大，而这个空间大小是配置的，一般不会很大，所以，导致了慢 sql。对于这个问
题的优化，建议写一个过滤条件，再与 limit 结合实现。

8 、配置参数，不合理

我们很多时候使用数据库，都是安装了之后，就直接用，不会对数据库配置参数进行过多了解和设置。
比如 buff 相关的参数这就是数据库中一类非常重要的配置参数，在 mysql 中，有很多带有 buff、
cache、size、length、max、min、limit 等字样的配置参数，都是非常重要的配置参数。这些配置参
数，是直接关系数据库的性能的。如果，你数据库安装在一个配置很高的机器上，但是，这些配置参数
却不知道修改，都用默认值。哪也就只能哀怨“这么高的硬件配置，性能怎么还是这么差？


9 、频繁刷脏页

脏页，是内存数据页和磁盘数据页不一致。这个一般发生在数据更新操作中。更新数据，需要先把数据
读取出来，然后再内存中更新，然后再生成日志文件，再回放日志文件，实现表数据更新。而当更新数
据量大，buffpool 写满，或者是后续生成的回放日志文件写满，都会导致这个操作过程变慢。对于这种
问题优化，一般建议是少批量修改，多次提交。

10 、系统资源，不够用数据库，使用来存储数据的，要频繁进行磁盘操作，所以，一般，我们都会选择
磁盘 IO 性能比较好的机器作为数据库服务器。同时，数据库还要经常进行数据交换，所以，也需要有足
够的内存，所以，内存也会相应要求高些。而这些硬件，仅仅只是作为数据库服务器硬件选择的基本要
求；数据库也是一个软件，软件也是安装在操作系统中的，所以，也会受操作系统的参数的一些限制，
所以，当硬件资源不够用，或者达到了系统参数限制值时，也是会导致操作变慢的。

等等等等，回答到这里，面试官一定是五体投地了。

###### 13 、group by 需要注意什么

_oderby_ ， _group by_ 的底层原理和调优，非常重要，内容非常多

请参考尼恩《 _Java_ 面试宝典》 _Mysql_ 专题，有好几百页，非常细致

###### 14 、redis 数据类型

请参考尼恩《 _Java_ 面试宝典》 _redis_ 专题，有好几百页，非常细致

###### 15 、redis 单线程为什么快

请参考尼恩《 _Java_ 面试宝典》 _redis_ 专题，有好几百页，非常细致

###### 16 、什么是 IO 多路复用？为什么有 IO 多路复用机制？

请参考尼恩《 _Java_ 高并发核心编程卷 _2_ 加强版》对 _IO_ 多路复用加密过程做了抓包分析，非常细致

###### 17 、算法：两个数组，找出其中相同的数返回

算法，请参见尼恩社群（ _50+_ 群）的算法资料

#### 二面（35 min）

###### 1 、自我介绍

###### 2 、TCP, UDP 区别


请参考尼恩《 _Java_ 面试宝典》 _tcp_ 、 _ip_ 专题，有好几百页，非常细致

###### 3 、TCP 中的连接有什么意义，它是逻辑上的还是物理上的

请参考尼恩《 _Java_ 面试宝典》 _tcp_ 、 _ip_ 专题，有好几百页，非常细致

###### 4 、TCP 如何保证可靠性

请参考尼恩《 _Java_ 面试宝典》 _tcp_ 、 _ip_ 专题，有好几百页，非常细致

###### 5 、三次握手，四次挥手，为什么握手是三次，挥手是四次

请参考尼恩《 _Java_ 面试宝典》 _tcp_ 、 _ip_ 专题，有好几百页，非常细致

###### 6 、https 加密过程

请参考尼恩《 _Java_ 高并发核心编程卷 _2_ 加强版》对 _https_ 加密过程做了抓包分析，非常细致

###### 7 、cpu 在什么情况下会发生指令重排序

指令重排序是编译器处于性能考虑,在不影响程序 (单线程程序) 正确性的条件下进行重新排序。

指令重排序不是必然发生的, 指令重排序会导致线程安全问题。

请参考尼恩《 _Java_ 高并发核心编程卷 _2_ 加强版》对 _https_ 加密过程做了抓包分析，非常细致

###### 8 、volatile 原理，怎样保证可见性

请参考尼恩《 _Java_ 高并发核心编程卷 _2_ 加强版》对 _https_ 加密过程做了抓包分析，非常细致

###### 9 、cms 中为什么需要重新标记这一步？

实际场景中，很多小伙伴以为 CMS 垃圾回收器早就过时了，现在都流行 G 1、ZGC 垃圾回收器了！学这
个东西一点用都没有！

实际上 CMS 垃圾回收器于 JDK 1.5 时期推出，在 JDK 9 中被废弃，在 JDK 14 中被移除。

而用来替换 CMS 垃圾回收器的便是我们常说的 G 1 垃圾回收器。但 G 1 垃圾回收器也是在 CMS 的基础
上进行改进的，因此简单了解下 CMS 垃圾回收器也是有必要的。

**CMS（Concurrent Mark Sweep）垃圾回收器是第一个关注 GC 停顿时间的垃圾收集器。** 在这之前的
垃圾回收器，要么就是串行垃圾回收方式，要么就是关注系统吞吐量。


这样的垃圾回收器对于强交互的程序很不友好，而 CMS 垃圾回收器的出现，则打破了这个尴尬的局
面。因此，CMS 垃圾回收器诞生之后就受到了大家的欢迎，导致现在还有非常多的应用还在继续使用
它。

对于 CMS 垃圾回收器来说，其实通过「标记 - 清除」算法实现的，它的运行过程分为 4 个步骤，包
括：

```
初始标记
并发标记
重新标记
并发清除
```
**初始标记，指的是寻找所有被 GCRoots 引用的对象，该阶段需要「Stop the World」。** 这个步骤仅
仅只是标记一下 GC Roots 能直接关联到的对象，并不需要做整个引用的扫描，因此速度很快。

**并发标记，指的是对「初始标记阶段」标记的对象进行整个引用链的扫描，该阶段不需要「Stop the
World」。** 对整个引用链做扫描需要花费非常多的时间，因此通过垃圾回收线程与用户线程并发执行，
可以降低垃圾回收的时间，从而降低系统响应时间。这也是 CMS 垃圾回收器能极大降低 GC 停顿时间
的核心原因，但这也带来了一些问题，即：并发标记的时候，引用可能发生变化，因此可能发生漏标
（本应该回收的垃圾没有被回收）和多标（本不应该回收的垃圾被回收）了。

**重新标记，指的是对「并发标记」阶段出现的问题进行校正，该阶段需要「Stop the World」。**

为啥需要重新标记呢？

正如并发标记阶段说到的，由于垃圾回收算法和用户线程并发执行，虽然能降低响应时间，但是会发生
漏标和多标的问题。所以对于 CMS 回收器来说，它需要这个阶段来做一些校验，解决并发标记阶段发
生的问题。

**并发清除，指的是将标记为垃圾的对象进行清除，该阶段不需要「Stop the World」。** 在这个阶段，
垃圾回收线程与用户线程可以并发执行，因此并不影响用户的响应时间。

从上面的描述步骤中我们可以看出： **CMS 之所以能极大地降低 GC 停顿时间，本质上是将原本冗长的引
用链扫描进行切分。通过 GC 线程与用户线程并发执行，加上重新标记校正的方式，减少了垃圾回收的
时间。**

###### 10. cms 的并发清除阶段，如果之前被标记为垃圾的对象又被重新引

###### 用了怎么办？

可达性分析算法，标记死亡的已不可达。不会被引用


###### 11. IO 多路复用 select, poll, epoll 的区别

尼恩在《高性能葵花宝典》中，有详细的介绍。

###### 12. epoll 水平触发（LT）与边缘触发（ET）的区别？

尼恩在《高性能葵花宝典》中，有详细的介绍。

13. 算法：自己实现一个平方根函数
14. 算法：线程 A, B 交替打印自然数

算法，请参见 **尼恩社群** （ _50+_ 群）的算法资料

#### 三面（30 min）

###### 1 、自我介绍

###### 2 、问项目

除了 _crud_ ，最好能做一个、两个有高价值的轮子项目，这里可以结合轮子项目，介绍自己遇到的技术难
题。

如果找不到好的轮子项目，可以来咨询尼恩。

###### 3 、因为项目里面有用到 RocketMQ，问了一些 mq 的东西

请参考尼恩《 _Java_ 面试宝典》消息队列专题，有好几百页，非常细致

###### 4 、类加载过程

请参考尼恩《 _Java_ 面试宝典》 _jvm_ 专题，有好几百页，非常细致

###### 5 、类加载器

请参考《尼恩 _Java_ 面试宝典》 _jvm_ 专题，有好几百页，非常细致

###### 6 、索引建立原则，什么字段适合建立索引

请参考《尼恩 _Java_ 面试宝典》 _mysql_ 专题，有好几百页，非常细致


###### 7 、synchronized 和 lock 有什么区别？什么场景下用 lock

请参考尼恩《 _Java_ 高并发核心编程卷 _2_ 加强版》 _synchronized VS lock_ 做了详细的介绍，非常细致

###### 8 、单例里面用的什么锁，为什么用 synchronized，单例解决了什么

###### 问题，会有什么问题

请参考尼恩《 _Java_ 高并发核心编程卷 _2_ 加强版》高并发设计模式做了详细的介绍，非常细致

###### 9 、如何保证 java 共享变量的安全

请参考尼恩《 _Java_ 高并发核心编程卷 _2_ 加强版》高并发设计模式做了详细的介绍，非常细致

###### 10 、详细介绍五种 IO 模型，都有什么区别？

请参考尼恩《 _Java_ 高并发核心编程卷 _2_ 加强版》对五大 _io_ 模型做了详细的介绍，非常细致

###### 11 、为什么需要这些 IO 模型

请参考尼恩《 _Java_ 高并发核心编程卷 _2_ 加强版》对五大 _io_ 模型做了详细的介绍，非常细致

###### 12 、redis 中主从复制的原理

请参考《尼恩 _Java_ 面试宝典》 _redis_ 专题，有好几百页，非常细致

## 字节狂问一小时，小伙 offer 到手，太狠了！

#### 前言：

在尼恩的（50+） **读者社群** 中，经常有小伙伴，需要面试头条、美团、阿里、京东等大厂。

下面是一个小伙伴成功拿到通过过飞书一小时拷问的面试经历，就两个字：

```
深： 问的很深
宽： 范围很宽
```
总之，就是头条的面试官，功底还是挺牛的。

但是，咱们的候选人，也不是吃素的。


下面，从小伙的面试经历看看，收个飞书 Offer 需要学点啥？当然，这个小伙伴是中间开发，但是对于
中高级开发来说，这些面试题，也有参考意义。

这里也把题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》，供后面的小伙伴参考，提升大家的 3
高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，相关尼恩 架构笔记、面试题 的PDF文件，请从这里获取：码云
```
#### 飞书面试正题：

###### 1 、什么是 Spring 循环依赖？ Spring 是怎么解决的？

Spring 循环依赖是指两个或多个 Bean 之间相互依赖，形成一个环形依赖的情况。例如，Bean A 依赖于
Bean B，而 Bean B 又依赖于 Bean A，这样就形成了一个循环依赖。

Spring 解决循环依赖的方式是使用“提前暴露”和“三级缓存”机制。

具体来说，Spring 在创建 Bean 时，会将正在创建的 Bean 先放入“一级缓存”中，然后检查这个 Bean 是否
有依赖其他 Bean，如果有，Spring 会将这个 Bean 的依赖关系放入“二级缓存”中，并且创建这些依赖的
Bean。

如果依赖的 Bean 中又有依赖当前 Bean 的，Spring 会将这些依赖关系放入“三级缓存”中，并且创建这些
依赖的 Bean。

当所有 Bean 都创建完成后，Spring 会将这些 Bean 从“三级缓存”中取出，并且将它们注入到相应的 Bean
中，完成循环依赖的解决。

此外，Spring 还提供了多种解决方案来避免循环依赖问题，例如使用构造函数注入、使用 setter 方法注
入、使用@Lazy 注解等。

需要注意的是，Spring 解决循环依赖的机制并不是完美的，因为它需要使用“三级缓存”机制，会占用一
定的内存空间。

同时，如果循环依赖的 Bean 中存在复杂的依赖关系，可能会导致 Spring 无法解决循环依赖的问题，从
而导致程序出现异常。因此，在编写代码时，应该尽量避免循环依赖的情况。


###### 2 、怎么样高性能的计算最小公共字符串

最小公共字符串问题是一个经典的计算问题，其目标是在两个字符串中找到最短的子字符串，该子字符
串同时出现在两个字符串中。这个问题可以用多种算法来解决，其中一些算法可以实现高性能的计算。

其中一种高性能算法是 **后缀树算法** 。

后缀树是一种特殊的数据结构，它可以用来表示一个字符串的所有后缀。在后缀树中，每个节点表示一
个字符串的后缀，而每个边表示一个字符。

通过在后缀树中搜索两个字符串的公共子串，可以找到最小公共字符串。

另一种高性能算法是 **基于动态规划的算法** 。

这种算法使用一个二维数组来记录两个字符串的所有子串的公共长度。通过在这个数组中搜索最小公共
字符串，可以找到最小公共字符串。

无论使用哪种算法，都可以通过使用并行计算来提高性能。

例如，可以将字符串分成多个子串，并在多个处理器上并行计算子串之间的公共字符串。这种方法可以
大大提高计算速度，并且可以很好地扩展到处理大量数据的情况。

最小公共字符串问题可以用以下步骤解决：

```
1. 统计字符串集合中每个字符串出现的次数，保存到一个字典中。
2. 对于每个字符串，找到它最长的公共前缀，即其他字符串的最小公共字符串。
3. 如果当前字符串和它的最长公共前缀相同，则增加它的出现次数，否则更新最长公共前缀。
4. 最终得到的最小公共字符串即为所有字符串中最长的公共前缀。
```
以下是一个使用后缀树算法实现最小公共字符串的 Java 代码示例：

```
public class SuffixTree {
private final Node root;
```
```
public SuffixTree(String s) {
root = new Node();
for (int i = 0 ; i < s.length(); i++) {
insertSuffix(s.substring(i), i);
}
}
```
```
private void insertSuffix(String suffix, int index) {
Node node = root;
for (char ch : suffix.toCharArray()) {
if (!node.containsKey(ch)) {
node.put(ch, new Node());
}
node = node.get(ch);
}
node.addIndex(index);
}
```
```
public String findLCS(String s1, String s2) {
String lcs = "";
Node node = root;
int i = 0 , j = 0 ;
while (i < s1.length() && j < s2.length()) {
char ch1 = s1.charAt(i);
```

使用这个后缀树实现类，可以通过以下方式找到两个字符串的最小公共字符串：

```
char ch2 = s2.charAt(j);
if (node.containsKey(ch1) && node.containsKey(ch2)) {
node = node.get(ch1);
i++;
j++;
} else {
break;
}
if (node.hasMultipleIndexes()) {
String candidate = findLCS(s1.substring(i -
node.getIndexList().get( 0 ), i), s2.substring(j - node.getIndexList().get( 0 ),
j));
if (candidate.length() > lcs.length()) {
lcs = candidate;
}
}
}
return lcs;
}
```
```
private static class Node {
private final Map<Character, Node> children = new HashMap<>();
private final List<Integer> indexList = new ArrayList<>();
```
```
public void put(char ch, Node node) {
children.put(ch, node);
}
```
```
public boolean containsKey(char ch) {
return children.containsKey(ch);
}
```
```
public Node get(char ch) {
return children.get(ch);
}
```
```
public void addIndex(int index) {
indexList.add(index);
}
```
```
public boolean hasMultipleIndexes() {
return indexList.size() > 1 ;
}
```
```
public List<Integer> getIndexList() {
return indexList;
}
}
}
```
```
String s1 = "abcdefg";
String s2 = "bcdefgh";
SuffixTree suffixTree = new SuffixTree(s1 + "#" + s2);
String lcs = suffixTree.findLCS(s1, s2);
System.out.println(lcs); // 输出 "bcdef"
```

这个算法的时间复杂度为 O (m+n)，其中 m 和 n 分别是两个字符串的长度。由于后缀树的构建和搜索都可
以使用高效的算法实现，因此这个算法可以实现高性能的计算。

###### 3 、说说 RPC 框架

**1 ）什么是 RPC 框架？RPC 框架中， RPC 通讯协议怎么设计的**

RPC（Remote Procedure Call）是一种远程调用协议，它允许一个计算机程序调用另一个计算机程序
的子程序，而不需要程序员显式编写远程调用的代码。RPC 框架是一种实现 RPC 协议的软件框架，它提
供了一种简单的方法来实现跨网络的通信。

在 RPC 框架中，RPC 通讯协议的设计通常包括以下几个方面：

```
1. 传输协议：RPC框架需要选择一种可靠的传输协议来保证数据的传输。常用的传输协议有TCP和
UDP。
2. 序列化协议：RPC框架需要选择一种序列化协议来将数据序列化为二进制格式，以便在网络上传
输。常用的序列化协议有JSON、XML、Protobuf等。
3. 服务注册与发现：RPC框架需要提供服务注册与发现的功能，以便客户端可以找到可用的服务提供
者。常用的服务注册与发现工具有Zookeeper、Consul等。
4. 负载均衡：RPC框架需要提供负载均衡的功能，以便将请求均衡地分配给不同的服务提供者。常用
的负载均衡算法有轮询、随机等。
5. 安全认证：RPC框架需要提供安全认证的功能，以确保通信的安全性。常用的安全认证方式有
SSL、Token认证等。
6. 对等节点：RPC框架通常需要支持多个对等节点，每个节点都可以提供远程服务。节点之间可以通
过网络通信来交互消息，并在对等节点之间传递响应。
7. 调用流程：RPC框架通常提供一组调用流程，以便程序员方便地进行远程调用。调用流程通常包括
请求、响应和错误处理等部分。
```
在设计 RPC 通讯协议时，需要考虑通信的可靠性、效率和安全性等因素，同时需要根据具体的应用场景
选择合适的协议。


**2 ）设计一个 RPC 框架，需要考虑哪些问题**

设计一个 RPC 框架需要考虑以下问题：

```
1. 通信协议：选择一种合适的通信协议来实现客户端和服务端之间的通信，常用的通信协议包括
HTTP、TCP、UDP等，以及序列化协议，例如JSON或是Protobuf。
2. 服务注册与发现：需要实现服务注册与发现机制，使得客户端可以自动发现可用的服务提供者。
3. 负载均衡：需要实现负载均衡机制，确保请求能够均衡地分配给不同的服务提供者。常用的负载均
衡算法包括轮询、随机和最少连接数等。
4. 安全认证：为了保证系统的安全性，需要对请求进行身份验证和权限控制，以防止恶意攻击和非法
操作。常用的安全认证方式包括基于令牌的身份验证和基于SSL/TLS的加密通信等。
5. 异常处理：需要考虑异常处理机制，例如网络异常、超时等情况的处理方式。
6. 高可用性：需要考虑如何保证系统的高可用性，例如实现服务降级、容错等机制。
7. 性能优化：在高并发的情况下，需要对RPC框架进行性能优化，以确保请求能够快速响应。常用的
性能优化方式包括缓存、异步处理和线程池等机制。
8. 日志与监控：需要实现日志记录和监控机制，以便及时发现和解决问题。
9. 兼容性：需要考虑不同语言、不同平台之间的兼容性问题，例如实现跨语言调用的机制。
10. 扩展性：需要考虑如何实现系统的扩展性，例如支持动态添加和删除服务提供者。
```
**3 ）RPC 框架中，序列化算法的对比与优缺点分析**

在 RPC 框架中，序列化算法是非常重要的一环，它直接影响到系统的性能和可扩展性。下面是几种常见
的序列化算法的对比分析：

**1. Java 原生序列化：** 是 Java 自带的序列化方式，可以将对象序列化为字节流，也可以将字节流反序列化
为对象。

优点

```
使用方便，不需要额外的依赖
```
缺点

```
序列化后的字节流较大，序列化和反序列化的性能较差
只能在Java平台上使用
```
**2. JSON 序列化：** 是一种轻量级的数据交换格式，可以将对象序列化为 JSON 字符串，也可以将 JSON 字符
串反序列化为对象。

优点：

```
JSON是一种轻量级的数据交换格式，序列化后的数据较小，易于阅读和编写。
JSON支持嵌套对象和数组，方便表示复杂的数据结构。
JSON可以通过HTTP协议进行传输，适用于Web应用程序。
```
缺点：

```
序列化和反序列化的性能较差，不支持二进制数据，只能序列化JavaBean等简单的数据结构。
JSON的解析速度相对较慢，对于大量数据的处理可能会有性能问题。
```

**3. XML 序列化：** XML 序列化是一种基于 XML 格式的序列化方式，可以将对象序列化为 XML 字符串，也可
以将 XML 字符串反序列化为对象。

优点：

```
XML是一种通用的数据格式，可以用于多种应用程序之间的数据交换。
序列化后的数据易于阅读和调试，支持复杂的数据结构
XML支持命名空间和属性，方便表示复杂的数据结构。
XML可以通过HTTP协议进行传输，适用于Web应用程序。
```
缺点：

```
XML相对于JSON来说较为冗长，数据较大，序列化和反序列化的效率较低。
XML不支持二进制数据，无法直接序列化和反序列化二进制数据。
```
**4. Protobuf 序列化：** Protobuf 是一种高效的二进制序列化协议，可以将对象序列化为二进制数据，也
可以将二进制数据反序列化为对象。

优点：

```
Protobuf支持快速序列化和反序列化数据，性能非常高，序列化后的数据较小。
Protobuf支持多种编程语言，包括C++、Java、Python等，支持跨语言调用。
Protobuf可以定义自定义的消息类型，方便表示复杂的数据结构。
```
缺点：

```
Protobuf相对于JSON和XML来说较为复杂，学习和使用成本较高。
Protobuf不支持HTML和XML这样的标记语言，无法直接在Web应用程序中使用。
需要定义IDL文件，不支持动态添加字段等操作
```
综上所述，不同的序列化算法各有优缺点，需要根据具体的应用场景选择适合的序列化算法。

如果需要高性能的序列化和反序列化化二进制数据，可以选择 Protobuf；

如果需要易于阅读和调试的序列化格式，可以选择 JSON 或 XML；

如果需要在 Web 应用程序中使用 RPC 框架，可以选择 JSON；

如果需要在多种应用程序之间进行数据交换，XML 可能更适合；

如果需要 Java 平台原生支持的序列化方式，可以选择 Java 原生序列化。

**4 ）了解过 gRPC 吗？gRPC 的原理是什么**

gRPC 是一个高性能、开源和通用的 RPC 框架，由 Google 开发。

它使用 Protocol Buffers 作为接口描述语言，可以在多种语言中使用，包括 Java、Python、C++等。
gRPC 支持多种传输协议和序列化协议，可以在不同的环境中使用，如云、移动设备、浏览器等。


grpc 的原理是基于 HTTP/2 和 protobuf 协议，利用 protobuf 序列化和反序列化技术，实现远程过程调
用。

protobuf 是一种轻量级、高效、可扩展的数据序列化格式，由谷歌开发并开源。它允许在不同的平台和
语言之间传递和解析数据，支持类型定义和版本控制，具有数据压缩效率高和序列化和反序列化速度快
的优点。

gRPC 通过在客户端和服务器之间建立一个 protobuf 序列化/反序列化通道，实现远程过程调用。客户端
将请求序列化为字节流并发送到服务器，服务器将响应反序列化为字节流并发送给客户端。gRPC 还支
持负载均衡、服务发现机制、认证和授权、监控和日志等功能，提高了 RPC 框架的可靠性和可扩展性。

###### 4 、了解过 Dubbo 吗？Dubbo 的原理是什么

Dubbo 是一种高性能、轻量级的分布式服务框架，由阿里巴巴集团开发。

它采用了分布式服务框架的核心理念，提供了基于 RPC (远程过程调用) 的分布式服务治理解决方案，支
持多种协议和注册中心，可以方便地实现微服务架构，帮助开发者快速构建分布式应用。

Dubbo 的原理是基于 Java 的远程调用框架，使用了 Java 的反射机制和动态代理技术。

它采用了基于 SOA（面向服务架构）的思想，将业务逻辑封装成服务，然后通过 RPC 协议进行远程调
用。基于 RPC 协议，采用了一种简化的序列化和反序列化方式，即基于字节数组的序列化和反序列化方
式。它通过在网络中建立一个负载均衡器，将请求分发到多个提供者，并通过一组超时机制和重试策略
来保证高可用和稳定性。

Dubbo 还提供了多种负载均衡策略和路由策略，可以根据不同的场景进行配置。

Dubbo 还支持多种注册中心，包括 Zookeeper、Redis 和 Multicast 等，可以实现服务的自动注册和发
现。此外，Dubbo 还提供了丰富的监控和管理功能，可以方便地对服务进行监控和管理。

Dubbo 的原理可以概括为：

```
1. 定义接口：使用Java接口定义服务接口，包括请求和响应的消息格式、参数和返回值类型等信息。
2. 生成代码：使用Dubbo插件将Java接口转换为Dubbo接口，并生成对应的Dubbo服务接口文件。
3. 实现服务：在服务端实现服务接口，并根据需要添加错误处理和其他功能。
4. 配置注册中心：配置Dubbo的注册中心，如Zookeeper或Nacos等，用于管理服务的注册和发
现。
5. 启动服务提供者：在服务提供者上启动Dubbo服务，监听指定的端口，等待客户端的请求。
6. 发送请求：客户端调用服务接口的方法，并将请求消息发送给Dubbo服务器。
7. 负载均衡：Dubbo会根据一定的负载均衡策略选择合适的服务提供者进行处理。
8. 解析请求：Dubbo服务器接收到请求后，将其解析为相应的方法调用，并将请求消息转发给服务
提供者。
9. 执行方法：服务提供者执行相应的方法，并将结果消息发送给Dubbo服务器。
10. 解析响应：Dubbo服务器接收到响应后，将其解析为相应的结果消息，并将响应消息转发给客户
端。
```
由于 Dubbo 使用了高效的通信协议和负载均衡算法，因此具有较高的性能和可靠性。此外，Dubbo 还
支持集群部署、动态代理等功能，可以满足不同场景下的需求。

###### 5 、简单介绍一下 Hystrix 原理，他如何实现熔断的

Hystrix 是一个开源的、容错和延迟容忍的库，由 Netflix 开发。


它提供了一种可以在高并发场景中使用的限流框架。它通过在系统中添加一些额外的组件，例如限流器
和令牌桶，来避免系统因为过度的并发而崩溃。它可以帮助开发者处理分布式系统中的延迟和故障问
题，提高系统的可用性和稳定性。

Hystrix 的原理是基于断路器模式，它可以监控服务调用的延迟和错误率，并根据预设的阈值进行自动熔
断。

当服务调用失败或超时时，Hystrix 会自动切换到备用的服务或者返回预设的默认值，避免了服务的级联
故障。Hystrix 还提供了实时的监控和统计功能，可以帮助开发者了解系统的运行状况和性能瓶颈。

Hystrix 实现熔断的过程如下：

```
1. 当服务调用失败或超时时，Hystrix会记录这个事件，并根据预设的阈值进行判断。
2. 如果失败或超时的事件达到了预设的阈值，Hystrix会自动打开断路器，停止对该服务的调用。
3. 在断路器打开的状态下，Hystrix会自动切换到备用的服务或者返回预设的默认值。
4. 在一段时间内，Hystrix会定期地尝试调用服务，如果调用成功，则会关闭断路器，否则继续保持
打开状态。
```
通过熔断机制，Hystrix 可以避免服务的级联故障，提高系统的可用性和稳定性。

由于 Hystrix 使用了高效的通信协议和负载均衡算法，因此具有较高的性能和可靠性。此外，Hystrix 还
支持集群部署、动态代理等功能，可以满足不同场景下的需求。

###### 6 、如果让你去设计一个熔断器，你会怎么去设计他的熔断逻辑

设计一个熔断器的熔断逻辑需要考虑以下几个方面：

**1. 熔断门限：** 熔断器的门限应该是可配置的，可以根据系统的实际情况来设定一个合理的阈值。这个阈
值应该可以根据系统的压力动态调整。

1 ）定义熔断条件：熔断器需要定义触发熔断的条件，例如：错误率达到一定阈值、请求超时率达到一
定阈值等等。


2 ）熔断器状态：熔断器需要有三种状态：关闭、开启和半开状态。关闭状态下，请求会正常通过；开
启状态下，请求会被熔断器拦截；半开状态下，熔断器会尝试发送一部分请求，如果请求成功，则熔断
器进入关闭状态，否则进入开启状态。

**2. 熔断时间：** 熔断器应该能够在规定的时间内快速响应，这个时间应该足够短，以保证系统能够快速恢
复正常。

1 ）熔断器的熔断时间：熔断器需要定义一个熔断时间，在这段时间内，所有请求都会被熔断器拦截，
直到熔断时间结束。在熔断时间内，熔断器会记录所有失败的请求，以便后续分析和处理。

2 ）熔断器的恢复时间：熔断器需要定义一个恢复时间，在这段时间内，熔断器处于半开状态。在半开
状态下，熔断器会尝试发送一部分请求，如果请求成功，则熔断器进入关闭状态，否则进入开启状态。
恢复时间结束后，熔断器会重新进入关闭状态。

**3. 判断是否熔断：** 在服务端接收到请求后，先检查当前请求是否在熔断范围内。如果是，则直接返回预
设的错误信息或者默认的响应结果；如果不是，则继续执行后续操作。

**4. 熔断方式：** 熔断器应该能够以多种方式触发熔断，例如超过阈值、超过指定时间等。

**5. 监控与报警：** 通过监控系统对服务的可用性和性能进行实时监测，一旦发现服务出现异常或者负载过
高，立即触发熔断机制，并向管理员发送报警信息。

**6. 熔断重试：** 熔断器应该支持熔断后的自动重试，以便系统能够尽快恢复正常。如果服务正常运行，但
是由于网络等原因导致请求失败，可以设置一个重试机制。当请求失败时，可以尝试重新发送请求，直
到成功为止。

**7. 错误处理：** 熔断器应该能够处理错误，例如当系统出现异常时，熔断器应该能够自动退出并进行错误
处理，而不是简单地将请求重新路由到另一个系统。

**8. 可靠性：** 熔断器应该是可靠的，即使系统出现异常，熔断器也应该能够正常工作，避免系统的崩溃。

**9. 动态调整：** 根据系统的实际情况和用户反馈，动态调整阈值和重试机制等参数，以提高系统的稳定性
和可靠性。

熔断器只是一种保护机制，不能完全替代容错和恢复能力。

因此，在设计熔断器的同时，还需要考虑其他方面的优化措施，如增加缓存、优化算法等，以提高系统
的性能和可靠性。

###### 7 、说说什么是 Redis 的缓存穿透、击穿、雪崩，该如何去解决？

Redis 缓存穿透、缓存击穿和缓存雪崩都是缓存常见的问题，需要针对不同的问题采取不同的解决方
案。

```
1. 缓存穿透
```
缓存穿透是指查询一个不存在的数据，由于缓存中没有该数据，导致请求穿透到数据库，从而对数据库
造成压力。解决缓存穿透问题的方法有：

```
布隆过滤器：使用布隆过滤器对请求进行过滤，如果请求的数据不存在，则直接返回，避免请求穿
透到数据库。
缓存空对象：将不存在的数据缓存起来，设置过期时间，下次请求时直接从缓存中返回空数据，避
免请求穿透到数据库。
```
```
2. 缓存击穿
```

缓存击穿是指一个热点数据在缓存中过期或者被清除，导致大量请求同时访问数据库，从而对数据库造
成压力。解决缓存击穿问题的方法有：

```
热点数据永不过期：将热点数据设置为永久不过期，避免缓存失效导致请求穿透到数据库。
加锁：在缓存失效的时候，使用分布式锁或者互斥锁，避免大量请求同时访问数据库。
限流：使用限流算法对请求进行限制，避免大量请求同时访问数据库。
```
```
3. 缓存雪崩
```
缓存雪崩是指缓存中大量的数据在同一时间失效，导致大量请求同时访问数据库，从而对数据库造成压
力。解决缓存雪崩问题的方法有：

```
数据过期时间随机：将缓存数据的过期时间设置为随机时间，避免大量缓存同时失效。
数据预热：在系统启动时，将热点数据加载到缓存中，避免缓存失效时大量请求访问数据库。
分布式部署：将缓存部署在多个节点上，避免某个节点失效导致缓存雪崩。
```
总之，为了解决 Redis 缓存的故障问题，需要综合考虑多个因素，包括缓存设计、访问模式、数据结
构、算法等等。在实际应用中，可以根据具体情况选择合适的技术和方案进行优化和调整。

###### 8 、说说 Redis 分布式锁如何实现 ？ 需要考虑哪些问题

Redis 分布式锁的实现可以通过使用 setnx（set if not exists）命令和 expire 命令来实现。

具体来说，可以利用 Redis 的单线程特性，通过 setnx 命令设置一个锁，如果返回值是 1 ，则表示成功获
取到锁，否则表示锁已经被其他客户端获取。然后可以使用 expire 命令设置锁的过期时间，以防止锁一
直被占用而不被释放。

需要考虑的问题包括：

```
1. 锁的粒度：锁的粒度应该尽量小，以避免出现锁竞争的情况，同时也要避免出现死锁的情况。
2. 锁的超时时间：锁的超时时间应该根据业务需求来设置，以避免锁一直被占用而不被释放。
3. 锁的可重入性：如果在同一个线程中多次获取同一个锁，应该保证可以成功获取锁，而不是一直等
待。
4. 锁的释放：在释放锁的时候，应该先判断锁是否属于当前客户端，以避免误释放其他客户端的锁。
5. 锁的容错性：在获取锁的时候，应该考虑到网络延迟等因素，避免因为一次获取锁失败就导致整个
业务流程失败。
6. 锁的实现方式：Redis分布式锁的实现方式有多种，如使用Lua脚本实现、使用Redlock算法实现
等，需要根据实际情况选择最合适的实现方式。
7. 分布式环境下的数据一致性：在分布式环境下，多个节点可能会同时请求锁，因此需要保证分布式
锁的实例在分布式环境下仍然能够正确地工作，并确保分布式环境下的数据一致性。
8. 高并发性：分布式锁需要支持高并发的访问，并确保在高并发的情况下仍然能够正确地工作。
9. 死锁风险：在分布式环境下，由于多个节点可能会互相请求锁，因此需要考虑如何避免死锁的发
生。
10. 授权控制：分布式锁需要支持授权控制，即能够控制哪些节点能够获得锁，并能够在授权控制的基
础上实现锁的撤销。
11. 故障恢复：分布式锁需要支持故障恢复，即在节点故障或网络异常的情况下，锁能够自动恢复正常
工作。
12. 性能：分布式锁需要考虑性能问题，例如锁的响应时间、锁的粒度等。
```
综上所述，实现 Redis 分布式锁需要考虑多个方面的问题，包括数据一致性、高并发性、死锁风险、可
重入性、授权控制、故障恢复和性能等。


###### 9 、Zookeeper 除了注册中心还有什么其他的用处

除了作为注册中心之外，Zookeeper 还有以下的用处：

```
1. 配置管理：可以使用Zookeeper来存储和管理应用程序的配置信息，当配置发生变化时，可以通过
Zookeeper通知应用程序进行相应的更新。
2. 分布式锁：可以使用Zookeeper来实现分布式锁，避免多个客户端同时访问共享资源的问题。
3. 分布式队列：可以使用Zookeeper来实现分布式队列，用于协调多个节点之间的任务调度。
4. 集群管理：可以使用Zookeeper来管理集群中的节点信息，如节点的状态、健康状况等。
5. 分布式协调：可以使用Zookeeper来实现分布式协调，如选举算法、分布式事务等。
6. 存储状态信息： Zookeeper 可以用于存储状态信息，例如订单的状态、库存的数量等。
7. 实现服务发现： Zookeeper 可以用于实现服务发现，例如在分布式系统中，可以使用 Zookeeper
来查找服务的地址。
8. 支持动态添加和删除节点： Zookeeper 可以支持动态添加和删除节点，这使得它成为了一个非常
灵活和可扩展的工具。
9. 支持负载均衡： Zookeeper 可以用于实现简单的负载均衡，例如在分布式系统中，可以使用
Zookeeper 来实现对不同服务的负载均衡。
10. 命名服务：Zookeeper可以提供全局唯一的命名服务，使得不同的应用程序可以通过名称来访问相
同的资源。
```
总之，Zookeeper 作为一个分布式协调服务，可以用于解决分布式系统中的各种协调问题，提高系统的
可用性、可靠性和可扩展性。

###### 10 、Zookeeper 的分布式锁是如何实现的？

Zookeeper 的分布式锁是基于一种叫做 "Zookeeper Watch" 的机制实现的。

在 Zookeeper 中，一个节点可以注册一个 Watch 监听其他节点的变化。当一个节点的状态发生变化
时，该节点会通知所有注册了该 Watch 的节点，这样就可以保证所有节点都能够及时地获取到变化的
信息。

在 Zookeeper 的分布式锁中，节点会使用一个 Watch 监听其他节点的状态，如果发现其他节点的状态
发生变化，就可以认为该节点已经被其他节点获取了。

一旦一个节点获取了锁，其他节点就无法再获取锁了。

Zookeeper 实现分布式锁的过程可以分为以下几个步骤：

```
1. 创建一个临时有序节点：每个客户端在Zookeeper上创建一个临时有序节点，节点的名称为lock，
例如/lock/lock-0001。
2. 获取所有的子节点：客户端通过Zookeeper的API获取/lock节点下的所有子节点，并按照节点名称
的序号从小到大进行排序。
3. 判断自己是否获得锁：如果客户端创建的节点是所有子节点中序号最小的节点，则表示客户端获得
了锁，可以执行相应的业务逻辑；否则，客户端需要监听比自己序号小的节点的删除事件，当比自
己序号小的节点被删除时，再次执行步骤 2 和步骤 3 ，直到获得锁。
4. 释放锁：当客户端执行完业务逻辑后，需要删除自己创建的节点，以释放锁。
```
需要注意的是，Zookeeper 实现分布式锁还需要考虑以下问题：


```
1. 节点名称的唯一性：如果多个客户端同时创建了相同名称的节点，可能会导致锁的竞争，需要保证
节点名称的唯一性。
2. 节点删除的时机：如果客户端在执行业务逻辑时，节点被意外删除，可能会导致其他客户端获取到
了锁，需要考虑节点删除的时机。
3. 网络延迟和故障：如果网络延迟或者Zookeeper节点故障，可能会导致客户端无法获取到锁，需要
考虑如何处理这些异常情况。
```
Zookeeper 的分布式锁机制是非常可靠和安全的，因为在获取锁的过程中，需要对所有节点进行验
证，只有满足一定条件的节点才能够获取锁。同时，Zookeeper 的分布式锁也支持动态加锁和解锁，这
使得它成为了一个非常灵活和可扩展的分布式锁工具。

总之，Zookeeper 实现分布式锁的过程相对比较复杂，需要考虑多种情况，但是通过 Zookeeper 实现分
布式锁可以避免多个客户端同时访问共享资源的问题，提高系统的可用性和稳定性。

###### 11 、说说 AQS 原理

AQS（AbstractQueuedSynchronizer）是一种分布式锁算法，是由 Eric Brewer 等人在 2000 年提出
的。

AQS 能够保证分布式系统中多个节点对共享资源的访问是有序的和互斥的，即要么所有节点都可以访问
共享资源，要么所有节点都不能访问共享资源。

AQS 是 Java 中用于实现锁和同步器的基础框架，它提供了一种实现阻塞锁和相关同步器的通用机制，如
ReentrantLock、CountDownLatch、Semaphore 等。

AQS 的核心是一个双向链表，用于存储等待线程。每个节点代表一个等待线程，节点中包含了线程的状
态、等待时间、前驱节点和后继节点等信息。AQS 通过 CAS（Compare and Swap）操作来实现对状态
的原子更新和线程的阻塞和唤醒。

AQS 的状态是一个 int 类型的变量，它表示了同步器的状态。在 Lock 实现中，状态通常表示锁的持有者或
者锁的重入次数。在 CountDownLatch 和 Semaphore 等同步器中，状态表示可用资源的数量。

AQS 提供了两种模式：独占模式和共享模式。独占模式只允许一个线程获取锁，共享模式允许多个线程
同时获取锁。在独占模式下，AQS 使用一个 FIFO 队列来存储等待线程，在共享模式下，AQS 使用一个
CLH 队列来存储等待线程。

AQS 的实现基于模板方法设计模式，它定义了一些抽象方法，如 tryAcquire、tryRelease、
tryAcquireShared、tryReleaseShared 等，这些方法由具体的同步器实现。在使用 AQS 实现同步器时，
我们只需要继承 AQS 类，实现这些抽象方法即可。

**AQS 的基本思想是：**

在分布式系统中，每个节点都维护一个计数器，这个计数器表示该节点对共享资源的请求的状态。当一
个节点对共享资源进行请求时，该节点会将计数器递增 1 。当某个节点成功地获得了共享资源时，该节
点会将计数器递减 1 。

AQS 中有三个重要的概念：节点、资源和状态。

```
节点是分布式系统中的一个独立的计算机实例，它可以是任何类型的计算机实例，例如服务器、工
作站等。
资源是共享的资源，例如共享文件、共享数据库连接等。
状态是指资源的当前状态，例如一个文件的读取状态、一个数据库连接的空闲状态等。
```
在 AQS 中，节点之间通过异步方式进行通信，节点不会直接访问其他节点。


节点请求资源时，会将请求信息发送到其他节点，这些节点会对请求进行处理，并返回请求结果。如果
所有节点都可以访问共享资源，则节点会将请求信息转发给所有节点，并等待所有节点对该请求的响应
都返回。

如果有节点不能访问共享资源，则节点会将请求信息放入一个队列中，等待其他节点可以访问共享资源
时再处理该请求。

AQS 中有一些重要的操作，例如获取锁、释放锁、尝试获取锁等。

```
获取锁是指一个节点请求获得对共享资源的访问权限。
释放锁是指一个节点释放已经获得的对共享资源的访问权限。
尝试获取锁是指一个节点请求获得对共享资源的访问权限，如果获取锁失败，则尝试获取锁的节点
会释放已经获得的访问权限。
```
AQS 是一种非常可靠和安全的分布式锁算法，它可以在分布式系统中实现多个节点对共享资源的有序和
互斥访问。

总之，AQS 是 Java 中用于实现锁和同步器的基础框架，它提供了一种通用的机制来实现阻塞锁和相关同
步器。AQS 的核心是一个双向链表，通过 CAS 操作来实现对状态的原子更新和线程的阻塞和唤醒。AQS
提供了独占模式和共享模式，以及一些抽象方法，可以方便地实现各种同步器。

###### 12 、说说 JUC 中，公平锁和非公平锁如何实现

在 JUC（Java Util Concurrent）中，公平锁和非公平锁的实现方式不同。

公平锁是指多个线程按照申请锁的顺序来获取锁。也就是先来先得的原则，线程获取锁的顺序是按照线
程加锁的顺序来分配的。

公平锁的实现方式是通过维护一个 FIFO 队列来实现的。在公平锁的实现中，当一个线程请求获取锁时，
如果发现队列中已经有等待的线程，那么当前线程就会被加入到队列的末尾，等待前面的线程获取锁并
释放后再尝试获取锁。

公平锁的实现方式虽然保证了锁的公平性，但是由于加锁和释放锁的操作需要频繁地操作队列，因此在
高并发场景下，公平锁的性能会比非公平锁低。

非公平锁是指多个线程获取锁的顺序是不确定的，有可能后申请的线程比先申请的线程先获取到锁。

非公平锁的实现方式是在锁释放时，直接将锁分配给当前申请的线程，而不是先将线程加入到等待队列
中。这种方式可以减少线程上下文切换的次数，提高锁的性能。但是由于非公平锁的获取顺序是不确定
的，因此有可能会导致某些线程一直获取不到锁，出现“饥饿”现象。

Java 内置的锁（synchronized）是一种非公平锁机制，即所有线程都会获得相同的锁。如果多个线程
同时请求同一个锁，那么只有一个线程能够获得锁，而其他线程则需要等待。这种锁机制无法保证对共
享资源的访问是有序和互斥的，也就是说，多个线程可能会同时访问同一个共享资源，导致数据不一致
性。 Java 中还提供了一些其他的锁机制，包括 ReentrantLock（重入锁）、ReadWriteLock（读写
锁）等，这些锁机制可以更好地保证数据的正确性和多线程的同步访问。

下面我们以 ReentrantLock（重入锁）为例，介绍 JUC 中的公平锁和非公平锁的实现。

公平锁：


在 ReentrantLock 中，实现了 lock () 和 unlock () 方法。当一个线程需要获得锁时，首先判断锁是否被
其他线程获得（isLocked），如果是则等待（wait ()），直到锁可用为止。获得锁后，将锁的持有者
（lockedBy）设置为当前线程，并唤醒其他等待线程（notify ()）。

非公平锁：

在 NonfairLock 中，实现了 lock () 和 unlock () 方法。当一个线程需要获得锁时，直接调用 wait () 方
法，直到锁可用为止。获得锁后，将锁的持有者设置为当前线

需要注意的是，公平锁模式可能会导致线程饥饿问题，因为某些线程可能会一直等待其他线程释放锁。
因此，在选择公平锁模式时需要仔细考虑应用程序的需求和性能要求。

总之，公平锁和非公平锁的实现方式不同。公平锁通过维护一个 FIFO 队列来保证锁的公平性，而非公平
锁则直接将锁分配给当前申请的线程，不保证锁的公平性。公平锁的性能较低，但保证了锁的公平性；
非公平锁的性能较高，但可能会导致某些线程“饥饿”。在实际应用中，我们需要根据实际情况选择合适
的锁类型。

```
public class ReentrantLock {
private boolean isLocked = false;
private Thread lockedBy = null;
private int waitCount = 0 ;
```
```
public synchronized void lock() throws InterruptedException {
Thread callingThread = Thread.currentThread();
while (isLocked && lockedBy != callingThread) {
wait();
}
isLocked = true;
lockedBy = callingThread;
}
```
```
public synchronized void unlock() {
if (Thread.currentThread() == lockedBy) {
isLocked = false;
notify();
}
}
}
```
```
public class NonfairLock {
private boolean isLocked = false;
private Thread lockedBy = Thread.currentThread();
```
```
public void lock() throws InterruptedException {
while (isLocked) {
wait();
}
isLocked = true;
lockedBy = Thread.currentThread();
}
```
```
public void unlock() {
isLocked = false;
}
}
```

## 饿了么太狠：面个高级 Java，抖这多硬活、狠

## 活

#### 前言：

在 40 岁老架构师尼恩的（50+） **读者社群** 中，经常有小伙伴需要面试饿了么、头条、美团、阿里、京东
等大厂。有很多的小伙伴，完成了人生的逆袭，拿到了高端的 offer。

**最近一个 6 年经验的小伙伴，年薪拿到 60 W，非常牛掰。**

下面是一个小伙伴成功拿到饿了么 **高级 Java 的 offer** ，其面试经历，还是两个字：

```
深： 问的很深
宽： 范围很宽
```
下面，从小伙的面试正题看看，收个饿了么 Offer 需要学点啥？

下面的这些面试题，对于面试其他的高级 java 岗位，也很有参考意义。

这里也把题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》，供后面的小伙伴参考，提升大家的 3
高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，相关尼恩 架构笔记、面试题 的PDF文件，请从这里获取：码云
```
#### 饿了么面试正题：

###### 1 、说说数据库事务的隔离级别？

数据库事务的隔离级别是指在并发访问数据库时，各个事务之间隔离程度的不同。常见的隔离级别有以
下四种：

```
1. 读未提交（Read Uncommitted） ：这是最低的隔离级别，一个事务可以读取另一个未提交事务
的数据，可能会导致脏读、不可重复读和幻读问题。
适用于读多写少的场景，可以提高并发性能。但是，如果一个事务读取了未提交的数据，其他事务
可能会受到影响，因此需要谨慎使用。
2. 读已提交（Read Committed） ：这是一种较高的隔离级别，一个事务只能读取另一个已提交事
务的数据，可以避免脏读问题，但是仍可能出现不可重复读和幻读问题。
适用于读多写少的场景，可以保证数据的一致性，但可能会降低并发性能。
3. 可重复读（Repeatable Read） ：这是一种更高的隔离级别，一个事务在执行过程中，多次读取
同一数据会得到相同结果，可以避免脏读和不可重复读问题，但是仍可能出现幻读问题。
```

```
隔离级别 读数据一致性 脏读 不可重复读 幻读
```
```
读未提交 最低级别，只能保证不读取物理上损坏的数据 是 是 是
```
```
读已提交 语句级 否 是 是
```
```
可重复读 事务级 否 否 是
```
```
串行化 最高级别，事务级 否 否 否
```
```
适用于需要保证数据一致性的场景，如银行交易、订单处理等。但是，由于需要在事务执行期间锁
定数据，可能会降低并发性能。
4. 串行化（Serializable） ：最高的隔离级别，所有事务串行执行，可以避免脏读、不可重复读和幻
读问题，但是对性能有较大影响。
适用于对数据一致性要求非常高的场景，如金融交易、医疗诊断等。但是，由于串行执行，可能会
降低并发性能。
```
在实际开发中，根据具体的业务需求和性能要求，可以选择不同的隔离级别来平衡数据一致性和并发性
能。

表中列出了四种常见的数据库事务隔离级别，以及它们对于脏读、不可重复读和幻读的处理情况。其
中，脏读指的是一个事务读取到了另一个事务尚未提交的数据；不可重复读指的是一个事务多次读取同
一数据，但是由于其他事务的修改，每次读取的结果都不同；幻读指的是一个事务多次读取同一范围的
数据，但是由于其他事务的插入或删除，每次读取的结果都不同。

###### 2 、说说事务的几大特性，并谈一下实现原理

事务是指作为单个逻辑工作单元执行的一系列操作，要么全部执行，要么全部不执行。

**ACID**

事务具有四个关键特性，即 ACID：

```
1. 原子性（Atomicity） ：事务中的所有操作要么全部成功，要么全部失败回滚，不允许只执行其中
的一部分操作。
2. 一致性（Consistency） ：事务执行前后，数据库的状态必须保持一致，即满足所有的约束条件。
3. 隔离性（Isolation） ：事务之间是相互隔离的，一个事务的执行不应该影响其他事务的执行。每
个事务都应该认为它是唯一在执行的事务，每个事务都应该感觉不到其他事务的存在。
4. 持久性（Durability） ：事务一旦提交，对数据库中的数据修改就是永久性的，即使系统崩溃也不
会丢失。
```
**实现原理**

事务的实现需要数据库管理系统支持，通常通过日志记录和锁机制来实现。

**日志记录** ：在事务执行过程中，数据库管理系统会将所有的操作记录在日志中，如果事务执行失败，可
以通过日志进行回滚，保证数据的一致性。


**锁机制** ：为了保证事务之间的隔离性，数据库管理系统会使用锁机制，对事务进行隔离。当一个事务对
某个数据进行修改时，会对该数据进行加锁，其他事务需要等待该事务释放锁后才能对该数据进行修
改。

###### 3 、如何用 redis 实现消息的发布订阅？

Redis 可以通过发布订阅 (Pub/Sub) 模式来实现消息的发布和订阅。

**原理**

Redis 是使用 C 实现的，可以通过分析 Redis 源码里的 pubsub. c 文件，了解发布和订阅机制的底层实现

Redis 通过 PUBLISH，SUBSCRIBE 和 PSUBSCRIBE 等命令实现发布和订阅功能

通过 SUBSCRIBE 命令订阅某频道后，redis-server 里维护了一个字典，字典的键就是一个频道，字典的
值则是一个链表，链表中保存了所有订阅这个频道的客户端。SUBSCRIBE 命令的关键，就是将客户端添
加到给定频道的订阅链表中。

通过 PUBLISH 命令向订阅者发送消息，redis-server 会使用给定频道作为键，在它维护的频道字典中查
找记录了订阅这个频道的所有客户端的链表，将消息发布给所有订阅者

Pub 和 Sub 从字面上理解就是发布（Publish）和订阅（Subscribe），在 redis 中，可以设定对某一个
key 值进行消息发布及消息订阅，当一个 key 值上进行了消息发布后，所有订阅它的客户端都会收到相应
的信息，这一功能最明显的用法就是实时消息系统，比如普通的即时聊天，群聊等功能。

**具体步骤**

**1. 创建订阅者集合**

首先，需要在 Redis 中创建一个订阅者集合，用于存储所有订阅者的相关信息。可以使用 Redis 中的 SET
命令创建一个集合，其中键为订阅者的名字，值为该订阅者的 ID。

**2. 发布消息**

然后，使用 Redis 的 PUBLISH 命令向指定的主题发布一条消息。主题是一个字符串，可以是任意名称，
用于标识要发布的消息。可以使用 Redis 的 JSON 格式来表示消息内容，例如：

**3. 订阅消息**

```
PUBLISH topic "Hello World"
```

接下来，订阅者可以使用 Redis 的 SUBSCRIBE 命令订阅指定的主题。同样，主题也是一个字符串，可以
是任意名称。订阅后，Redis 会返回一个包含当前订阅者集合信息的响应。可以使用 Redis 的
PSUBSCRIBE 命令来订阅多个主题，例如：

**4. 处理消息**

当有消息发布到指定的主题时，Redis 会自动将消息发送给所有已订阅该主题的订阅者。订阅者可以使
用 Redis 的 LPUSH、RPUSH 等命令来接收并处理消息，例如：

以上代码将消息发布到名为"my-subscriber-channel"的频道中，并传递了一个 JSON 格式的消息对象。
其他订阅者可以使用相同的方式接收并处理该消息。

```
更多详细内容，请 参考 尼恩《 Java高并发核心编程 卷 1 加强版：NIO、Netty、Redis、
ZooKeeper 》 做了 详细的介绍，非常细致
```
###### 4 、java 为什么要在内存结构中设计自己的程序计数器，为什么不使

###### 用内核的？

Java 中的程序计数器（Program Counter Register）是一块内存区域，用于存储当前线程正在执行的字
节码指令地址。Java 虚拟机之所以要在内存结构中设计自己的程序计数器，而不使用内核的程序计数
器，主要有以下原因：

```
1. 内核提供的程序计数器是一个内核态的计数器，它只能简单地记录线程的执行次数，而不能像Java
程序计数器一样可以动态地修改计数器的值。如果使用内核的程序计数器，由于多个线程可能同时
访问内核，会导致竞争和冲突，从而导致程序出现错误或崩溃。
2. Java程序计数器可以更好地支持多线程并发。在Java中，线程之间的切换是通过内核态的上下文切
换来实现的，而程序计数器正是上下文切换的一个重要参数。当线程执行完一段代码后，需要将计
数器的值加 1 ，以便下次执行该代码时可以恢复到之前的状态。如果没有程序计数器，就无法实现
这种动态的上下文切换。
3. Java中的程序计数器可以通过内存屏障(Memory Barrier)等机制来保证线程之间的可见性和原子
性，从而实现高效的并发执行。
```
另外，Java 中的程序计数器还有以下优点：

```
1. 跨平台性 ：Java的设计目标之一是实现跨平台性，即Java程序可以在不同的操作系统和硬件平台上
运行。为了实现这一目标，Java虚拟机需要自己实现程序计数器，而不依赖于操作系统提供的程序
计数器。
2. 线程私有性 ：Java虚拟机中的程序计数器是线程私有的，每个线程都有自己的程序计数器。线程切
换时，虚拟机会将当前线程的程序计数器保存起来，并恢复下一个线程的程序计数器。如果使用操
作系统的程序计数器，就无法实现线程私有性。
3. 快速访问 ：程序计数器是Java虚拟机执行引擎中的一个重要组成部分，用于指示当前线程正在执行
的字节码指令地址。如果使用操作系统的程序计数器，就需要进行系统调用和内核态的切换，会影
```
```
PSUBSCRIBE "topic1", "topic2"
```
```
LPUSH "my-subscriber-channel" '{"message": "Hello World"}'
```

```
响性能。而Java虚拟机中的程序计数器是直接访问内存，速度更快。
```
综上所述，Java 使用自己的程序计数器是为了支持多线程并发执行，并且通过内存结构来进行管理，以
提高程序的稳定性和可靠性。Java 虚拟机需要在内存结构中设计自己的程序计数器，以实现跨平台性、
线程私有性和快速访问。

###### 5 、说说分布式事务 2 PC 的过程？

分布式事务是指在分布式系统中，多个事务操作涉及到多个数据库或资源，需要保证这些事务操作要么
全部成功，要么全部失败。2 PC（Two-Phase Commit）是一种分布式事务协议，用于协调分布式事务
的提交和回滚。其过程主要分为两个阶段：

**准备阶段（Prepare Phase）**

在这个阶段，协调者（Coordinator）向所有参与者（Participant）发送“准备”请求，询问它们是否可
以执行事务，并将其执行结果保存在日志中。参与者执行事务，并将执行结果反馈给协调者。如果所有
参与者都可以执行事务，则协调者发送“提交”请求，否则发送“回滚”请求。

**提交阶段（Commit Phase）**

在这个阶段，如果协调者发送的是“提交”请求，则所有参与者执行事务，并将执行结果提交。如果协调
者发送的是“回滚”请求，则所有参与者撤销事务，并将执行结果回滚。最后，协调者向所有参与者发送
“完成”请求，表示事务已经完成。

**优点**


在 2 PC 的过程中，协调者是必须是强一致性的，即它需要对所有参与者的数据进行一致性检查，以确保
所有参与者的数据都能正确地被提交或回滚。

2 PC 协议的优点是可以保证事务的原子性和一致性，即要么全部提交，要么全部回滚。

**缺点**

它也存在一些缺点，如：

```
1. 性能问题 ：2PC需要进行多次网络通信和等待，会影响性能。
2. 单点故障问题 ：协调者是2PC协议的关键，如果协调者出现故障，整个系统将无法正常工作。
3. 同步阻塞问题 ：在准备阶段，所有参与者都需要等待协调者的响应，如果协调者响应时间过长，将
会导致参与者的阻塞。
```
因此，在实际应用中，需要根据具体业务场景选择合适的分布式事务方案，如 TCC、Saga 等。

###### 6 、redis 是单线程的，为什么会这么快？

Redis 之所以能够高效地处理请求，主要是因为它采用了以下几种优化措施：

```
1. 基于内存 ：Redis将所有数据存储在内存中，这样可以避免了磁盘I/O操作的开销，从而提高了数据
读写的速度。
2. 单线程模型 ：Redis采用单线程模型，避免了多线程之间的竞争和锁的开销，从而减少了上下文切
换的开销。然 Redis 是单线程的，但是它使用了事件驱动机制和异步 I/O 技术，通过将任务分解为
多个小任务，并行执行来提高并发能力。此外，Redis 还使用了多路复用技术，可以同时处理多个
客户端请求。
3. 异步非阻塞 ：Redis采用异步非阻塞的方式处理客户端请求，当客户端发起请求后，Redis会立即
响应并将请求放入队列中，然后再异步地处理请求，这样可以避免了线程的阻塞和等待。
4. 数据结构优化 ：Redis内置了多种数据结构，如哈希表、有序集合等，这些数据结构经过了优化，
可以快速地进行数据的存储和检索。
5. 高效的编码和解码 ：Redis 使用了一些高效的编码和解码算法，如 Deflate、Snappy、LZ4 等，可
以压缩和解压缩数据，减少网络传输的数据量。
```
综合上述优化措施，使得 Redis 能够在单线程的情况下，处理大量的请求，并且保持高效的性能。

###### 7 、谈谈 NIO 的实现，以及 Netty 是如何设计的？

**NIO 的实现**

NIO（Non-blocking I/O）是 Java 提供的一种新的 I/O 模型，它支持非阻塞式的、基于事件驱动的 I/O 操
作。相比于传统的阻塞式 I/O 模型，NIO 能够更好地处理高并发的网络请求，提高系统的吞吐量和响应速
度。

NIO 的实现主要依赖于两个类：Channel 和 Buffer。

```
Channel 表示一个连接到某个端口的实体，它可以与另一个 Channel 或服务端通信；
Buffer 则表示一种数据结构，用于存储读入的数据，并提供了一些方法来处理这些数据。
```

NIO 通过 Selector（选择器）来实现事件驱动。它可以同时监听多个 Channel 的状态变化，并在有
数据可读或可写时通知应用程序进行处理。Selector 会不断地轮询注册在其上的 Channel，当
Channel 有数据可读或者可写时，Selector 会通知应用程序进行相应的处理。在 NIO 中，可以使用
Channel 和 Buffer 来进行数据的读写操作，而且可以使用单线程来处理多个 Channel 的读写操作，从
而避免了多线程之间的竞争和锁的开销。

**Netty 是如何设计的**

Netty 是一个基于 NIO 的客户端/服务器框架，它提供了高度可定制化的网络编程 API，可以帮助开发者快
速地构建高性能、高可靠性的网络应用程序。Netty 的设计思路是基于“Reactor 模式”，它采用了线程
池、缓冲区池、内存池等技术来优化网络通信的性能，同时提供了丰富的编解码器和协议支持，使得开
发者可以轻松地实现各种协议的数据交换。

Netty 主要的设计思想包括：

```
1. 可扩展性 ：Netty 的组件化设计使得它非常容易扩展和定制。用户可以根据自己的需求选择合适的
组件，并通过组合使用来实现复杂的功能。
2. 高性能 ：Netty 采用了一些优化策略，如事件驱动模型、零拷贝技术、内存池等，从而提高了系统
的吞吐量和响应能力。
3. 可移植性 ：Netty 支持多种操作系统和平台，如 Windows、Linux、Unix、MacOS 等，并且可以
在不同的语言中使用，如 Java、Scala、Python、Golang 等。
4. 可维护性 ：Netty 的代码结构清晰、易于理解，同时提供了丰富的文档和示例代码，使得开发人员
可以轻松地维护和修改代码。
```
Netty 的核心组件包括 Channel、EventLoop、ChannelFuture、ChannelHandler 等。

```
Channel是Netty的核心概念，它代表了一个网络连接，可以进行数据的读写操作；
EventLoop是Netty的事件循环组件，它负责处理所有的I/O事件，并将事件分发给对应的
Channel进行处理；
ChannelFuture是Netty的异步操作结果的封装类，可以用来获取异步操作的结果；
ChannelHandler是Netty的数据处理器，它负责对Channel中的数据进行编解码、处理和转发。
```
总之，NIO 和 Netty 的实现都是基于事件驱动的异步非阻塞模型，能够更好地处理高并发的网络请求，
提高系统的吞吐量和响应速度。

```
更多详细内容，请 参考 尼恩《 Java高并发核心编程 卷 1 加强版：NIO、Netty、Redis、
ZooKeeper 》 做了 详细的介绍，非常细致
```
###### 8 、微服务化的时候，什么时候应该拆分，什么情况应该合并

微服务架构的拆分和合并需要考虑多个因素，如业务复杂度、团队规模、技术栈、可维护性、性能等。

**什么时候拆分微服务**

```
1. 业务复杂度高 ：当业务逻辑十分复杂时，可以考虑将其拆分成多个微服务，每个微服务专注于某个
子领域的业务逻辑。
2. 团队规模大 ：当团队规模较大时，可以将团队拆分成多个小团队，每个小团队负责维护一个微服
务，以提高开发效率和质量。
3. 技术栈不同 ：当不同的微服务使用不同的技术栈时，可以将其拆分成多个微服务，以便于团队专注
于自己擅长的技术栈。
4. 可维护性差 ：当某个微服务的代码难以维护时，可以将其拆分成多个微服务，以便于团队更好地维
护和管理代码。
```

**什么时候合并微服务**

```
1. 业务逻辑简单 ：当业务逻辑较为简单时，可以将多个微服务合并成一个，以减少系统的复杂度和维
护成本。
2. 性能问题 ：当多个微服务之间的调用频繁时，可以将其合并成一个微服务，以减少网络延迟和提高
性能。
3. 数据共享 ：当多个微服务需要共享同一份数据时，可以将其合并成一个微服务，以便于数据的管理
和维护。
```
需要注意的是，微服务的拆分和合并需要谨慎考虑，应该根据具体情况进行决策。

###### 9 、什么时候应该使用消息，什么时候适合接口调用？

在微服务架构中，我们可以使用消息队列或接口调用来实现不同微服务之间的通信。

**什么时候使用消息队列**

```
1. 异步通信 ：当两个微服务之间需要异步通信时，可以使用消息队列。例如，当一个微服务需要将某
个事件通知给其他微服务时，可以使用消息队列来实现异步通信。
2. 解耦 ：当两个微服务之间需要解耦时，可以使用消息队列。例如，当一个微服务需要将某个任务交
给其他微服务处理时，可以使用消息队列来实现任务的解耦。
3. 流量控制 ：当两个微服务之间的流量需要控制时，可以使用消息队列。例如，当一个微服务需要将
大量数据传输给其他微服务时，可以使用消息队列来控制流量。
```
**什么时候使用接口调用**

```
1. 同步通信 ：当两个微服务之间需要同步通信时，可以使用接口调用。例如，当一个微服务需要获取
其他微服务的数据时，可以使用接口调用来实现同步通信。
2. 高性能 ：当两个微服务之间的通信需要高性能时，可以使用接口调用。例如，当一个微服务需要频
繁地调用其他微服务时，可以使用接口调用来提高性能。
3. 数据安全 ：当两个微服务之间的通信需要保证数据安全时，可以使用接口调用。例如，当一个微服
务需要传输敏感数据时，可以使用接口调用来保证数据的安全性。
```
需要注意的是，消息队列和接口调用各有优缺点，应该根据具体情况选择合适的通信方式。同时，在实
际应用中，我们也可以将消息队列和接口调用结合起来使用，以实现更加灵活和高效的通信方式。

###### 10 、分库分表中如果让你设计全局 id，如何设计？百度对雪花算法的

###### 优化了解过没？

**雪花算法**

在分库分表中，为了避免不同的数据库中出现相同的 ID，需要设计全局唯一的 ID。一种常见的方案是使
用雪花算法 (SnowFlake) 生成全局唯一 ID。


Snowflake 算法是 Twitter 开源的一个分布式 ID 生成算法，它可以保证在分布式环境下生成唯一的 ID。
Snowflake 算法生成的 ID 是一个 64 位的整数，其中 1 位是符号位， 41 位是时间戳， 10 位是工作机器 ID，
12 位是序列号。

Snowflake 算法的 ID 生成规则如下：

```
1. 第一位是符号位 ，始终为 0 ，表示生成的是正整数
2. 接下来的 41 位是时间戳 ，精确到毫秒级别，可以使用当前时间减去一个固定的起始时间，得到一
个相对时间戳
3. 接下来的 10 位是机器标识符 ，可以根据需要自行设计，比如可以使用IP地址、MAC地址、数据中
心ID等信息来生成
4. 最后的 12 位是序列号 ，可以使用计数器来实现，每次生成ID时自增，当序列号达到最大值时，可
以等待下一毫秒再继续生成
```
使用 Snowflake 算法生成的 ID 具有以下优点：

```
1. 全局唯一 ，可以在分布式系统中生成唯一的ID
2. 时间戳有序 ，可以根据ID的时间戳来进行排序，方便数据库的查询和分析
3. 高性能 ，生成ID的速度非常快，可以支持高并发的场景
4. 易于实现 ，Snowflake算法的实现比较简单，可以使用Java等语言来实现
```
需要注意的是，在分库分表的场景下，如果使用 Snowflake 算法生成 ID，需要保证每个分库分表的机器
标识符不同，否则可能会导致生成重复的 ID。可以考虑使用数据中心 ID 和机器 ID 来生成机器标识符，以
保证每个分库分表的机器标识符不同。

以下是 Java 实现 Snowflake 算法生成全局唯一 ID 的示例代码：

```
public class SnowflakeIdGenerator {
// 起始的时间戳
private final static long START_TIMESTAMP = 1480166465631L;
```
```
// 每一部分占用的位数
private final static long SEQUENCE_BIT = 12 ; // 序列号占用的位数
private final static long MACHINE_BIT = 10 ; // 机器标识占用的位数
private final static long DATACENTER_BIT = 1 ; // 数据中心占用的位数
```
```
// 每一部分的最大值
private final static long MAX_DATACENTER_NUM = - 1L ^ (-1L <<
DATACENTER_BIT);
private final static long MAX_MACHINE_NUM = - 1L ^ (-1L << MACHINE_BIT);
private final static long MAX_SEQUENCE = - 1L ^ (-1L << SEQUENCE_BIT);
```
```
// 每一部分向左的位移
private final static long MACHINE_LEFT = SEQUENCE_BIT;
private final static long DATACENTER_LEFT = SEQUENCE_BIT + MACHINE_BIT;
private final static long TIMESTAMP_LEFT = DATACENTER_LEFT + DATACENTER_BIT;
```

使用示例：

```
private long datacenterId; // 数据中心
private long machineId; // 机器标识
private long sequence = 0L; // 序列号
private long lastTimestamp = - 1L; // 上一次时间戳
```
```
public SnowflakeIdGenerator(long datacenterId, long machineId) {
if (datacenterId > MAX_DATACENTER_NUM || datacenterId < 0 ) {
throw new IllegalArgumentException("datacenterId can't be greater
than MAX_DATACENTER_NUM or less than 0");
}
if (machineId > MAX_MACHINE_NUM || machineId < 0 ) {
throw new IllegalArgumentException("machineId can't be greater than
MAX_MACHINE_NUM or less than 0");
}
this.datacenterId = datacenterId;
this.machineId = machineId;
}
```
```
public synchronized long nextId() {
long timestamp = timeGen();
```
```
if (timestamp < lastTimestamp) {
throw new RuntimeException("Clock moved backwards. Refusing to
generate id");
}
```
```
if (timestamp == lastTimestamp) {
sequence = (sequence + 1 ) & MAX_SEQUENCE;
if (sequence == 0L) {
timestamp = tilNextMillis(lastTimestamp);
}
} else {
sequence = 0L;
}
```
```
lastTimestamp = timestamp;
```
```
return ((timestamp - START_TIMESTAMP) << TIMESTAMP_LEFT) |
(datacenterId << DATACENTER_LEFT) |
(machineId << MACHINE_LEFT) |
sequence;
}
```
```
private long tilNextMillis(long lastTimestamp) {
long timestamp = timeGen();
while (timestamp <= lastTimestamp) {
timestamp = timeGen();
}
return timestamp;
}
```
```
private long timeGen() {
return System.currentTimeMillis();
}
}
```

这里的 datacenterId 和 machineId 可以根据实际情况进行设定，比如可以使用 Zookeeper 来管理
datacenterId 和 machineId 的分配。

**百度对雪花算法的优化**

Snowflake 算法是一种常用的分布式 ID 生成算法，但是在高并发场景下，可能会出现 ID 重复的问题，这
会导致数据的错误和不一致。为了解决这个问题，百度在 Snowflake 算法的基础上进行了一些优化，使
得生成的 ID 更加稳定和唯一。

百度对 Snowflake 算法的优化主要有以下几点：

**1. 增加数据中心 ID 和机器 ID 的位数**

原始的 Snowflake 算法中，数据中心 ID 和机器 ID 的位数分别为 5 位和 5 位，总共 10 位。百度将数据中心 ID
和机器 ID 的位数分别增加到了 8 位和 8 位，总共 16 位。这样可以支持更多的数据中心和机器，也可以减少
ID 重复的可能性。

**2. 使用 Zookeeper 来管理数据中心 ID 和机器 ID**

在原始的 Snowflake 算法中，数据中心 ID 和机器 ID 是静态配置的，需要在每个应用程序中进行配置。这
样会带来一些问题，比如在扩容或缩容时需要修改配置文件，容易出错，而且不够灵活。为了解决这个
问题，百度使用 Zookeeper 来管理数据中心 ID 和机器 ID。每个应用程序在启动时，都会向 Zookeeper 注
册自己的 ID，Zookeeper 会分配一个唯一的 ID 给应用程序。这样可以避免手动配置的问题，也可以支持
动态扩容和缩容。

**3. 改进哈希函数**

百度使用了 MurmurHash 3 哈希函数来存储雪花序列。MurmurHash 3 哈希函数是一种高效的哈希函
数，可以快速地将一组数字映射到一个固定的数组位置。

使用线程安全的哈希表：在生成全局唯一标识符时，需要在多个线程中同时使用哈希表来存储雪花序
列。为了保证哈希表的线程安全性，百度使用了 C++11 的标准库中提供的线程安全的哈希表。

增加哈希表的大小：为了提高哈希表的效率，百度在实际应用中增加了哈希表的大小。当哈希表的大小
达到一定程度时，就会自动扩容，以保证哈希表的性能和稳定性。

**4. 时间戳精度**

在雪花算法中，时间戳的精度为毫秒级别。为了进一步提高时间戳的精度，百度对雪花算法进行了优
化，将时间戳的精度提高到了微秒级别。这样可以更好地支持分布式系统中的时间同步和时序控制。

**5. 序列号范围** ：

在雪花算法中，序列号的范围是 0 到 4095 。为了支持更大的并发量和更高的性能，百度对雪花算法进行
了优化，将序列号的范围扩展到了 1 到 4096 。这样可以更好地支持高并发场景下的数据写入和查询操
作。

**6. 机器标识码** ：

在雪花算法中，机器标识码用于表示当前机器的唯一标识符。为了避免机器标识码冲突，百度对雪花算
法进行了优化，将机器标识码的范围从 0 到 32 位扩展到了 128 位。这样可以更好地支持多台机器之间的
唯一标识符冲突问题。

**7. 并发控制** ：

```
SnowflakeIdGenerator idGenerator = new SnowflakeIdGenerator( 1 , 1 );
long id = idGenerator.nextId();
System.out.println(id);
```

在雪花算法中，为了保证并发写入时的正确性，百度对雪花算法进行了优化，引入了写入锁和读锁等机
制。这样可以更好地支持高并发场景下的写入操作，并且可以避免写入冲突和数据丢失的问题。

通过以上优化，百度实现了一个更加稳定和可靠的分布式 ID 生成算法，可以在高并发场景下生成唯一的
ID，保证数据的正确性和一致性。

###### 11 、redis 如何进行单机热点数据的统计？

Redis 可以通过以下几种方式进行单机热点数据的统计：

```
1. 使用INFO命令查看Redis实例的各种性能指标，如内存使用情况、连接数、执行命令数等。INFO
命令是Redis自带的一个命令，可以在任何Redis客户端中使用。
1 ）使用INFO命令获取Redis服务器的统计信息。
2 ）解析统计信息，获取内存使用情况相关的数据。
3 ）根据内存使用情况，计算出每个key的内存占用情况。
4 ）对所有key的内存占用情况进行排序，获取前N个内存占用最大的key，即为热点数据。
2. 使用MONITOR命令实时监测Redis实例的性能指标，并将结果输出到标准输出流。MONITOR命令
可以设置监控周期和输出格式，非常灵活。
3. 使用Redis集群中的CLUSTER INFO命令查看集群中各个节点的性能指标，包括内存使用情况、连
接数、执行命令数等。CLUSTER INFO命令只能在Redis集群中使用。
4. 在应用程序中集成Redis监控工具，如New Relic、Datadog等。这些工具可以帮助你实时监测
Redis实例的性能指标，并提供详细的报告和警报功能。
```
###### 12 、redis 集群中新加节点以后，如何给新节点分配数据？

在 Redis 集群中，当新加入一个节点时，需要将集群中的数据进行重新分片，以保证各个节点负载均
衡。具体步骤如下：

```
1. 确定新节点的插槽范围 。在Redis集群中，数据被分成 16384 个插槽，每个插槽都有一个编号，从 0
到 16383 。新节点需要被分配一定范围的插槽，可以根据当前集群中的节点数量和插槽数量来计
算。
2. 将新节点加入集群 。可以使用Redis的CLUSTER MEET命令将新节点加入集群，例如：
```
```
3. 将新节点分配插槽 。可以使用Redis的CLUSTER ADDSLOTS命令将一定范围的插槽分配给新节点，
例如：
```
```
CLUSTER MEET <new_node_ip> <new_node_port>
```
```
CLUSTER ADDSLOTS 0 1 2 3 4 ... 100
```

其中，0 1 2 3 4 ... 100 表示要分配的插槽编号。

```
4. 等待集群重新分片 。当新节点加入集群并分配了插槽后，集群会自动进行重新分片，将相应的数据
迁移到新节点上。这个过程需要一定的时间，可以使用CLUSTER INFO命令来查看集群状态，直到
集群状态为ok。
5. 重复上述步骤 ，直到所有节点都加入集群并分配了插槽。
```
需要注意的是，Redis 集群具有自动平衡数据的功能，当某个节点的插槽数量过多或过少时，集群会自
动将一些插槽迁移到其他节点上，以保持各个节点的负载均衡。因此，在进行节点的添加和删除时，可
以让集群自动进行数据迁移，以减少手动操作的复杂性。

###### 13 、如何从含有 100 亿个整数的文件中找出其中最大的 100 个？

答案是：分别可以用分治法、堆排序、快速选择算法、BitMap 算法，

下面是用 java 写出几种算法的代码

**1. 使用分治法**

分治法的思路是将大问题分解为小问题，然后分别解决小问题，最后将小问题的解合并起来得到大问题
的解。在找出 100 亿个整数中最大的 100 个数时，可以将整个数据集分成若干个小数据集，分别找出每
个小数据集中最大的 100 个数，然后将这些最大的 100 个数合并起来，再找出其中最大的 100 个数即可。

Java 代码实现如下：

```
import java.io.*;
import java.util.*;
```
```
public class Top100NumbersByDivideAndConquer {
private static final int MAX_NUMBERS = 1000000000 ; // 最多处理 10 亿个数
private static final int MAX_NUMBERS_PER_FILE = 10000000 ; // 每个文件最多处理 1
千万个数
private static final int MAX_NUMBERS_PER_GROUP = 1000000 ; // 每个小数据集最多处
理 100 万个数
private static final int MAX_GROUPS = MAX_NUMBERS / MAX_NUMBERS_PER_GROUP;
// 最多分成 10000 个小数据集
private static final int MAX_TOP_NUMBERS = 100 ; // 找出最大的 100 个数
```
```
public static void main(String[] args) throws Exception {
// 生成随机数文件
generateRandomNumbersFile("numbers.txt", MAX_NUMBERS);
```
```
// 将随机数文件分成若干个小文件
List<String> files = splitNumbersFile("numbers.txt",
MAX_NUMBERS_PER_FILE);
```
```
// 找出每个小文件中最大的 100 个数
List<List<Integer>> topNumbersPerFile = new ArrayList<>();
for (String file : files) {
List<Integer> numbers = readNumbersFromFile(file);
```

List<Integer> topNumbers = findTopNumbersByHeapSort (numbers,
MAX_TOP_NUMBERS);
topNumbersPerFile.add (topNumbers);
}

// 将每个小文件中最大的 100 个数合并起来
List<Integer> topNumbers = mergeTopNumbers (topNumbersPerFile,
MAX_TOP_NUMBERS);

// 输出最大的 100 个数
System.out.println ("Top " + MAX_TOP_NUMBERS + " numbers: ");
for (int i = 0 ; i < MAX_TOP_NUMBERS; i++) {
System.out.println (topNumbers.get (i));
}
}

// 生成随机数文件
private static void generateRandomNumbersFile (String fileName, int count)
throws Exception {
Random random = new Random ();
BufferedWriter writer = new BufferedWriter (new FileWriter (fileName));
for (int i = 0 ; i < count; i++) {
writer.write (String.valueOf (random.nextInt ()));
writer.newLine ();
}
writer.close ();
}

// 将随机数文件分成若干个小文件
private static List<String> splitNumbersFile (String fileName, int
maxNumbersPerFile) throws Exception {
List<String> files = new ArrayList<>();
BufferedReader reader = new BufferedReader (new FileReader (fileName));
String line;
int count = 0 ;
int fileIndex = 0 ;
BufferedWriter writer = new BufferedWriter (new FileWriter ("numbers_" +
fileIndex + ". txt"));
while ((line = reader.readLine ()) != null) {
writer.write (line);
writer.newLine ();
count++;
if (count >= maxNumbersPerFile) {
writer.close ();
files.add ("numbers_" + fileIndex + ". txt");
fileIndex++;
writer = new BufferedWriter (new FileWriter ("numbers_" +
fileIndex + ". txt"));
count = 0 ;
}
}
writer.close ();
files.add ("numbers_" + fileIndex + ". txt");
reader.close ();
return files;
}

// 从文件中读取数字


**2. 使用堆排序算法**

堆排序算法的思路是使用一个小根堆来存储当前已经找到的最大的 k 个数，然后遍历剩余的数，如果比
堆顶元素大，则将堆顶元素替换为该数，然后重新调整堆。

Java 代码实现如下：

```
private static List<Integer> readNumbersFromFile (String fileName) throws
Exception {
List<Integer> numbers = new ArrayList<>();
BufferedReader reader = new BufferedReader (new FileReader (fileName));
String line;
while ((line = reader.readLine ()) != null) {
numbers.add (Integer.parseInt (line));
}
reader.close ();
return numbers;
}
```
```
// 使用堆排序算法找出最大的 k 个数
private static List<Integer> findTopNumbersByHeapSort (List<Integer> numbers,
int k) {
PriorityQueue<Integer> heap = new PriorityQueue<>(k);
for (int number : numbers) {
if (heap.size () < k) {
heap.offer (number);
} else if (number > heap.peek ()) {
heap.poll ();
heap.offer (number);
}
}
List<Integer> topNumbers = new ArrayList<>(heap);
Collections.sort (topNumbers, Collections.reverseOrder ());
return topNumbers;
}
```
```
// 合并每个小文件中最大的 k 个数
private static List<Integer> mergeTopNumbers (List<List<Integer>>
topNumbersPerFile, int k) {
PriorityQueue<Integer> heap = new PriorityQueue<>(k);
for (List<Integer> topNumbers : topNumbersPerFile) {
for (int number : topNumbers) {
if (heap.size () < k) {
heap.offer (number);
} else if (number > heap.peek ()) {
heap.poll ();
heap.offer (number);
}
}
}
List<Integer> topNumbers = new ArrayList<>(heap);
Collections.sort (topNumbers, Collections.reverseOrder ());
return topNumbers;
}
}
```
```
import java. io.*;
```

import java. util.*;

public class Top 100 NumbersByHeapSort {
private static final int MAX_NUMBERS = 1000000000 ; // 最多处理 10 亿个数
private static final int MAX_TOP_NUMBERS = 100 ; // 找出最大的 100 个数

public static void main (String[] args) throws Exception {
// 生成随机数文件
generateRandomNumbersFile ("numbers. txt", MAX_NUMBERS);

// 找出最大的 100 个数
List<Integer> numbers = readNumbersFromFile ("numbers. txt");
List<Integer> topNumbers = findTopNumbersByHeapSort (numbers,
MAX_TOP_NUMBERS);

// 输出最大的 100 个数
System.out.println ("Top " + MAX_TOP_NUMBERS + " numbers: ");
for (int i = 0 ; i < MAX_TOP_NUMBERS; i++) {
System.out.println (topNumbers.get (i));
}
}

// 生成随机数文件
private static void generateRandomNumbersFile (String fileName, int count)
throws Exception {
Random random = new Random ();
BufferedWriter writer = new BufferedWriter (new FileWriter (fileName));
for (int i = 0 ; i < count; i++) {
writer.write (String.valueOf (random.nextInt ()));
writer.newLine ();
}
writer.close ();
}

// 从文件中读取数字
private static List<Integer> readNumbersFromFile (String fileName) throws
Exception {
List<Integer> numbers = new ArrayList<>();
BufferedReader reader = new BufferedReader (new FileReader (fileName));
String line;
while ((line = reader.readLine ()) != null) {
numbers.add (Integer.parseInt (line));
}
reader.close ();
return numbers;
}

// 使用堆排序算法找出最大的 k 个数
private static List<Integer> findTopNumbersByHeapSort (List<Integer> numbers,
int k) {
PriorityQueue<Integer> heap = new PriorityQueue<>(k);
for (int number : numbers) {
if (heap.size () < k) {
heap.offer (number);
} else if (number > heap.peek ()) {
heap.poll ();
heap.offer (number);
}


**3. 使用快速选择算法**

快速选择算法的思路是使用快速排序的思路，将数据集分成两部分，然后只对包含最大的 k 个数的那一
部分继续递归，直到找到最大的 k 个数。

Java 代码实现如下：

```
}
List<Integer> topNumbers = new ArrayList<>(heap);
Collections.sort (topNumbers, Collections.reverseOrder ());
return topNumbers;
}
}
```
```
import java. io.*;
import java. util.*;
```
```
public class Top 100 NumbersByQuickSelect {
private static final int MAX_NUMBERS = 1000000000 ; // 最多处理 10 亿个数
private static final int MAX_TOP_NUMBERS = 100 ; // 找出最大的 100 个数
```
```
public static void main (String[] args) throws Exception {
// 生成随机数文件
generateRandomNumbersFile ("numbers. txt", MAX_NUMBERS);
```
```
// 找出最大的 100 个数
List<Integer> numbers = readNumbersFromFile ("numbers. txt");
List<Integer> topNumbers = findTopNumbersByQuickSelect (numbers,
MAX_TOP_NUMBERS);
```
```
// 输出最大的 100 个数
System.out.println ("Top " + MAX_TOP_NUMBERS + " numbers: ");
for (int i = 0 ; i < MAX_TOP_NUMBERS; i++) {
System.out.println (topNumbers.get (i));
}
}
```
```
// 生成随机数文件
private static void generateRandomNumbersFile (String fileName, int count)
throws Exception {
Random random = new Random ();
BufferedWriter writer = new BufferedWriter (new FileWriter (fileName));
for (int i = 0 ; i < count; i++) {
writer.write (String.valueOf (random.nextInt ()));
writer.newLine ();
}
writer.close ();
}
```
```
// 从文件中读取数字
private static List<Integer> readNumbersFromFile (String fileName) throws
Exception {
List<Integer> numbers = new ArrayList<>();
BufferedReader reader = new BufferedReader (new FileReader (fileName));
String line;
while ((line = reader.readLine ()) != null) {
numbers.add (Integer.parseInt (line));
```

**4. 使用 BitMap 算法**

BitMap 算法的思路是使用一个 BitMap 来记录每个数是否出现过，然后遍历 BitMap，找出出现次数最多
的 k 个数。

Java 代码实现如下：

```
}
reader.close ();
return numbers;
}
```
```
// 使用快速选择算法找出最大的 k 个数
private static List<Integer> findTopNumbersByQuickSelect (List<Integer>
numbers, int k) {
int left = 0 ;
int right = numbers.size () - 1 ;
while (left <= right) {
int pivotIndex = partition (numbers, left, right);
if (pivotIndex == k) {
break;
} else if (pivotIndex < k) {
left = pivotIndex + 1 ;
} else {
right = pivotIndex - 1 ;
}
}
List<Integer> topNumbers = new ArrayList<>(numbers.subList ( 0 , k));
Collections.sort (topNumbers, Collections.reverseOrder ());
return topNumbers;
}
```
```
private static int partition (List<Integer> numbers, int left, int right) {
int pivotIndex = left;
int pivotValue = numbers.get (pivotIndex);
swap (numbers, pivotIndex, right);
int storeIndex = left;
for (int i = left; i < right; i++) {
if (numbers.get (i) > pivotValue) {
swap (numbers, i, storeIndex);
storeIndex++;
}
}
swap (numbers, storeIndex, right);
return storeIndex;
}
```
```
private static void swap (List<Integer> numbers, int i, int j) {
int temp = numbers.get (i);
numbers.set (i, numbers.get (j));
numbers.set (j, temp);
}
}
```
```
import java. io.*;
import java. util.*;
```

public class Top 100 NumbersByBitMap {
private static final int MAX_NUMBERS = 1000000000 ; // 最多处理 10 亿个数
private static final int MAX_TOP_NUMBERS = 100 ; // 找出最大的 100 个数

public static void main (String[] args) throws Exception {
// 生成随机数文件
generateRandomNumbersFile ("numbers. txt", MAX_NUMBERS);

// 找出最大的 100 个数
List<Integer> numbers = readNumbersFromFile ("numbers. txt");
List<Integer> topNumbers = findTopNumbersByBitMap (numbers,
MAX_TOP_NUMBERS);

// 输出最大的 100 个数
System.out.println ("Top " + MAX_TOP_NUMBERS + " numbers: ");
for (int i = 0 ; i < MAX_TOP_NUMBERS; i++) {
System.out.println (topNumbers.get (i));
}
}

// 生成随机数文件
private static void generateRandomNumbersFile (String fileName, int count)
throws Exception {
Random random = new Random ();
BufferedWriter writer = new BufferedWriter (new FileWriter (fileName));
for (int i = 0 ; i < count; i++) {
writer.write (String.valueOf (random.nextInt ()));
writer.newLine ();
}
writer.close ();
}

// 从文件中读取数字
private static List<Integer> readNumbersFromFile (String fileName) throws
Exception {
List<Integer> numbers = new ArrayList<>();
BufferedReader reader = new BufferedReader (new FileReader (fileName));
String line;
while ((line = reader.readLine ()) != null) {
numbers.add (Integer.parseInt (line));
}
reader.close ();
return numbers;
}

// 使用 BitMap 算法找出最大的 k 个数
private static List<Integer> findTopNumbersByBitMap (List<Integer> numbers,
int k) {
int[] bitMap = new int[Integer. MAX_VALUE / 32 + 1 ];
for (int number : numbers) {
int index = number / 32 ;
int bit = number % 32 ;
bitMap[index] |= ( 1 << bit);
}
List<Integer> topNumbers = new ArrayList<>();
while (topNumbers.size () < k) {
int maxCount = 0 ;
int maxNumber = 0 ;


以上四种算法都可以用来解决从 100 亿个整数的文件中找出其中最大的 100 个数的问题。其中，分治法
和 BitMap 算法适用于分布式环境下的数据处理，而堆排序算法和快速选择算法则适用于单机环境下的
数据处理。

## 百度狂问 3 小时，大厂 offer 到手，小伙真狠！

```
for (int i = 0 ; i < bitMap. length; i++) {
for (int j = 0 ; j < 32 ; j++) {
if ((bitMap[i] & ( 1 << j)) != 0 ) {
int number = i * 32 + j;
int count = countNumberInList (numbers, number);
if (count > maxCount) {
maxCount = count;
maxNumber = number;
}
}
}
}
topNumbers.add (maxNumber);
removeNumberFromList (numbers, maxNumber);
}
return topNumbers;
}
```
```
private static int countNumberInList (List<Integer> numbers, int number) {
int count = 0 ;
for (int n : numbers) {
if (n == number) {
count++;
}
}
return count;
}
```
```
private static void removeNumberFromList (List<Integer> numbers, int number)
{
for (Iterator<Integer> iterator = numbers.iterator ();
iterator.hasNext ();) {
if (iterator.next () == number) {
iterator.remove ();
}
}
}
}
```

#### 前言：

在 40 岁老架构师尼恩的（50+） **读者社群** 中，经常有小伙伴，需要面试百度、头条、美团、阿里、京东
等大厂。

下面是一个小伙伴成功拿到通过了百度三次技术面试，小伙伴通过三个多小时技术拷问，最终拿到
offer。

**从这些题目来看：百度的面试，偏重底层知识和原理，大家来看看吧。**

现在把面试真题和参考答案收入咱们的宝典，大家看看， **收个百度 Offer 需要学点啥？**

当然对于中高级开发来说，这些面试题，也有参考意义。

这里把题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》 V 72，供后面的小伙伴参考，提升大家的
3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，相关尼恩架构笔记、面试题的 PDF 文件，请从这里获取：码云
```
#### 一面（69 min）

###### 1 、说说 cookie 和 session

Cookie 和 Session 是 Web 开发中常用的两种技术，它们都可以用来在客户端和服务端之间传递数据。

但是它们的作用范围、实现方式以及使用场景等方面有很大的区别。

**Cookie 与使用场景**

Cookie 是一种浏览器存储技术，注意，这里强调的是客户端。

Cookie 可以为用户在客户端 （主要是浏览器）存储一些键值对数据，以便在用户下次访问同一网站时
发送给服务器。

Cookie 可以设置过期时间，也可以设置 HttpOnly 属性，从而保护用户的隐私安全。

Cookie 的使用场景：

```
网站登录：通过在客户端存储一个唯一的标识符来验证用户身份，实现单点登录。
网站跟踪：通过在客户端存储一些统计信息来了解用户的行为习惯，从而优化网站的性能。
网站设置：通过在客户端存储一些偏好设置来实现个性化推荐等功能。
```

Cookie 是在 HTTP 协议下，服务器或脚本可以维护客户工作站上信息的一种方式。

Cookie 是由 Web 服务器保存在用户浏览器内存或用户本地硬盘（客户端）上的小文本文件 (内容通常
经过加密)，它可以包含有关用户的信息。

无论何时用户链接到服务器，Web 站点都可以访问 Cookie 信息

**Session 与使用场景**

Session 是一种服务器端存储技术，注意，这里强调的是服务器端。

Session 可以在同一台服务器上为每个用户创建一个独立的会话，从而实现用户的不同请求之间的数据
共享。
Session 可以存储一些键值对数据，也可以设置过期时间。

Session 的使用场景：

```
购物车功能：当用户将商品添加到购物车中时，将商品信息存储在 Session 中，以便用户在下一
次访问购物车页面时能够继续使用之前的操作。
会员系统：当用户注册成为会员时，将用户的信息存储在 Session 中，以便在后续的访问中能够
识别用户身份并提供相应的服务。
论坛系统：当用户发表帖子或回复帖子时，将用户的信息存储在 Session 中，以便在后续的访问
中能够显示用户的发帖记录或回复记录。
其他需要为同一用户共享数据的场景
```
**Cookie 和 Session 的区别**

```
作用范围不同：Cookie 是浏览器存储技术，只能在客户端存储数据；Session 是服务器端存储技
术，只能在同一台服务器上为每个用户创建一个独立的会话。
实现方式不同：Cookie 是浏览器自动发送给服务器的数据；Session 是服务器端创建的一个对
象，可以通过编程的方式进行管理。
安全性不同：Cookie 可以设置 HttpOnly 属性来保护用户的隐私安全；Session 可以设置加密算法
来保护用户的敏感信息安全。
数据大小限制不同：Cookie 的大小限制为 4 KB; Session 的大小限制没有明确的限制，但是受到服
务器内存和硬盘空间的限制。
过期时间控制不同：Cookie 可以设置过期时间来控制数据的有效期；Session 可以设置过期时间
来控制会话的有效期。
使用场景不同：Cookie 可以用于网站登录、网站跟踪、网站设置等场景；Session 可以用于购物
车功能、会员系统、论坛系统等场景。
```

Session 机制如何实现用户的多个请求，或者多次请求，能共享数据呢？

服务器收到请求，首先检查这个客户端里的请求里是否已包含了一个 session 标识–sessionID，如果已
经包含一个 sessionID，则说明以前已经为此客户端创建过 session，服务器就按照 sessionID 把这个
session 检索出来使用（检索不到，可能会新建一个），

如果客户端请求不包含 sessionID，则为此客户端创建一个 session 并且声称一个与此 session 相关联的
sessionID，sessionID 的值应该是一个既不会重复，又不容易被找到规律以仿造的字符串 (服务器会自动
创建), 这个 sessionID 将被在本次响应中返回给客户端保存。

###### 2 、说说 redis 有哪些数据结构？ 以及 redis 持久化方式？

Redis 支持多种数据结构，包括字符串、哈希表、列表、集合和有序集合等。

具体的说明如下：

```
1. 字符串类型：Redis 中最基本的数据类型，它可以存储字符串、散列、列表、集合和有序集合等。
2. Hash 类型：Redis 中的哈希表，它使用哈希表的数据结构来存储键值对，其中每个键都是唯一
的。
3. List 类型：Redis 中的列表，它使用链表的数据结构来存储一系列的值。
4. Set 类型：Redis 中的集合，它使用集合的数据结构来存储一系列不重复的值。
5. Sorted Set 类型：Redis 中的有序集合，它使用集合的数据结构来存储一系列有序的值。
```
字符串是最基本的数据类型，可以存储任何类型的数据，包括二进制数据。

哈希表可以看作是字符串到字符串值的映射，

列表是一个有序的字符串列表，

集合是一个无序的字符串集合，而有序集合则是一个有序的字符串集合，其中每个字符串都关联着一个
分值。


Redis 支持两种持久化方式：RDB 和 AOF。

**RDB 持久化：**

RDB 是一种快照持久化方式，可以将 Redis 的数据保存到硬盘上，以便在 Redis 重启时恢复数据。

RDB 持久化的优点是文件体积较小，但缺点是需要定期执行备份操作，且在备份期间无法对数据库进行
读写操作。

**RDB 持久化配置**

Redis 会将数据集的快照 dump 到 dump. rdb 文件中。

此外，我们也可以通过配置文件来修改 Redis 服务器 dump 快照的频率，在打开 6379. conf 文件之后，我
们搜索 save，可以看到下面的配置信息：

**AOF 持久化：**

AOF 则是一种追加式日志持久化方式，可以将 Redis 的所有写操作以追加的方式写入一个日志文件中，
以便在 Redis 重启时重新执行这些写操作来恢复数据。

将每次对数据库的操作以日志的形式记录下来，可以在服务器重启时以日志文件的方式恢复数据集。

AOF 持久化的优点是可以实现实时备份，不需要定期执行备份操作，但缺点是文件体积较大，写入性能
较低。

**AOF 持久化配置**

在 Redis 的配置文件中存在三种同步方式，它们分别是：

两种持久化方式各有优缺点，可以根据具体的应用场景选择合适的方式。

###### 3 、linux 了解吗？ 说说常用的 shell 命令

Linux 是一种自由和开放源代码的类 Unix 操作系统，它被广泛用于服务器、桌面电脑、移动设备等各
种场合。Linux 的核心思想是“一切皆文件”，这意味着所有的硬件设备、文件系统、应用程序都可以用
文件的形式进行访问和管理。

```
save 900 1 #在 900 秒 (15 分钟) 之后，如果至少有 1 个 key 发生变化，则 dump 内存快照。
```
```
save 300 10 #在 300 秒 (5 分钟) 之后，如果至少有 10 个 key 发生变化，则 dump 内存快照。
```
```
save 60 10000 #在 60 秒 (1 分钟) 之后，如果至少有 10000 个 key 发生变化，则 dump 内存快照。
```
```
appendfsync always #每次有数据修改发生时都会写入AOF文件 。
```
```
appendfsync everysec #每秒钟同步一次 ，该策略为 AOF 的缺省策略。
```
```
appendfsync no #从不同步 。高效但是数据不会被持久化。
```

Linux 是其主要特点包括：

```
1. 开放源代码：Linux 的源代码可以在互联网上自由获取和修改，这使得用户可以根据自己的需求对
其进行定制和修改。
2. 免费使用：Linux 是一种免费的操作系统，用户可以在不用支付任何费用的情况下使用和分发。
3. 稳定可靠：Linux 经过了长时间的实践和测试，已经被证明是一种非常稳定可靠的操作系统，适用
于各种环境下的应用。
4. 安全性高：Linux 具有严格的权限管理和安全机制，可以有效地保护系统不受恶意攻击和非法访
问。
5. 应用广泛：Linux 可以运行在各种硬件平台上，从服务器到桌面都可以使用，同时也有大量的开源
应用程序和工具可供使用。
```
Linux 的应用范围非常广泛，包括但不限于：

```
1. 服务器操作系统：Linux 是最流行的服务器操作系统之一，广泛应用于各种互联网服务和应用。
2. 桌面操作系统：Linux 也可以作为桌面操作系统使用，例如 Ubuntu、KDE 等。
3. 嵌入式系统：Linux 可以用于各种嵌入式设备，如物联网设备、机器人等。
4. 工作站和个人计算机：Linux 也可以用于个人计算机和工作站，作为操作系统和工具使用。
```
常用的 shell 命令:

mkdir

cd

ls

pwd

ps -ef

jps

....

太多了，具体请参见尼恩的《Linux 命令大全：2 W 多字，一次实现 Linux 自由》

###### 4 、说一下消息中间件的作用?

消息中间件是一种用于在分布式系统中传递消息的中间件软件。

它的作用是将消息从一个应用程序传递到另一个应用程序，同时提供了异步通信、解耦、可靠性、消息
持久化、消息分发等功能。

通过消息中间件，应用程序可以实现解耦，即发送者和接收者不需要知道彼此的存在，从而提高系统的
可维护性和扩展性。

消息中间件的作用：


```
1. 解耦系统：
消息中间件可以将不同应用程序之间的通信解耦，使得它们可以独立地扩展和部署。这意味着一个
应用程序的故障不会影响到其他应用程序的正常运行。
2. 异步调用：
消息中间件支持异步调用，这意味着发送方和接收方可以在不等待对方响应的情况下继续执行自己
的代码。这种方式可以提高系统的吞吐量和性能。
3. 可靠性保证：
消息中间件提供了一些机制来保证消息的可靠性，例如消息持久化、消息重试、消息确认等。这些
机制可以确保消息不会丢失或被错误处理。
4. 灵活性：
消息中间件通常具有高度的灵活性，可以与不同的编程语言和操作系统集成。此外，它们还提供了
一些高级功能，例如主题、队列、路由等，以满足不同的应用场景。
```
**着重介绍一下异步调用**

**在了解中间件之前，先介绍一下什么是同步？**

首先我们想一下，两个公司之间如果有互相调用接口的业务需求，如果没有引入中间件技术，是怎么实
现的呢？

用户发起请求给系统 A，系统 A 接到请求直接调用系统 B，系统 B 返回结果后，系统 A 才能返回结果给用
户，这种模式就是同步调用。

所谓同步调用就是各个系统之间互相依赖，一个系统发送请求，其他系统也会跟着依次进行处理，只有
所有系统处理完成后对于用户来讲才算完成了一次请求。只要其他系统出现故障，就会报错给用户。

**那么引入中间件后，是如何做到异步调用的呢？**

用户发起请求给系统 A，此时系统 A 发送消息给 MQ，然后就返回结果给用户，不去管系统 B 了。然后系
统 B 根据自己的情况，去 MQ 中获取消息，获取到消息的时候可能已经过了 1 分钟甚至 1 小时，再根据消
息的指示执行相应的操作。

那么想一想，系统 A 和系统 B 互相之间是否有通信？这种调用方式是同步调用吗？


系统 A 发送消息给中间件后，自己的工作已经完成了，不用再去管系统 B 什么时候完成操作。而系统 B 拉
去消息后，执行自己的操作也不用告诉系统 A 执行结果，所以整个的通信过程是异步调用的。

说到这里，我们可以做个总结，消息中间件到底是什么呢？

其实消息中间件就是一个独立部署的系统。可以实现各个系统之间的异步调用。当然它的作用可不止这
些，通过它可以解决大量的技术痛点，我们接下来会进行介绍。

消息中间件，总结起来作用有三个： **异步化提升性能、降低耦合度、流量削峰** 。

**异步化提升性能**

先来说说异步化提升性能，上边我们介绍中间件的时候已经解释了引入中间件后，是如何实现异步化
的，但没有解释具体性能是怎么提升的，我们来看一下下边的图。

没有引入中间件的时候，用户发起请求到系统 A，系统 A 耗时 20 ms，接下来系统 A 调用系统 B，系统 B 耗
时 200 ms，带给用户的体验就是，一个操作全部结束一共耗时 220 ms。

如果引入中间件之后呢？看下边的图。

用户发起请求到系统 A，系统 A 耗时 20 ms，发送消息到 MQ 耗时 5 ms，返回结果一共用了 25 ms，用户体
验一个操作只用了 25 ms，而不用管系统 B 什么时候去获取消息执行对应操作，这样比较下来，性能自然
大大提高

**再详细介绍一下，消息中间件具体如何降低耦合度**

再来聊聊解耦的场景，看下图。

如果没有引入中间件，那么系统 A 调用系统 B 的时候，系统 B 出现故障，导致调用失败，那么系统 A 就会
接到异常信息，接到异常信息后肯定要再处理一下，返回给用户失败请稍后再试，这时候就得等待系统
B 的工程师解决问题，一切都解决好后再告知用户可以了，再重新操作一次吧。

这样的架构，两个系统耦合再一起，用户体验极差。


那么我们引入中间件后是什么样的场景呢，看下面的流程：

对于系统 A，发送消息后直接返回结果，不再管系统 B 后边怎么操作。

而系统 B 故障恢复后重新到 MQ 中拉取消息，重新执行未完成的操作，这样一个流程，系统之间没有影
响，也就实现了解耦。

**最后详细介绍一下，什么是流量削峰**

下面我们再聊聊最后一个场景，流量削峰

假如我们的系统 A 是一个集群，不连接数据库，这个集群本身可以抗下 1 万 QPS

系统 B 操作的是数据库，这个数据库只能抗下 6000 QPS，这就导致无论系统 B 如何扩容集群，都只能抗
下 6000 QPS，它的瓶颈在于数据库。

假如突然系统 QPS 达到 1 万，就会直接导致数据库崩溃，那么引入 MQ 后是怎么解决的呢，见下图：

引入 MQ 后，对于系统 A 没有什么影响，给 MQ 发送消息可以直接发送 1 万 QPS。

此时对于系统 B，可以自己控制获取消息的速度，保持在 6000 QPS 一下，以一个数据库能够承受的速度
执行操作。这样就可以保证数据库不会被压垮。

当然，这种情况 MQ 中可能会积压大量消息。


但对于 MQ 来说，是允许消息积压的，等到系统 A 峰值过去，恢复成 1000 QPS 时，系统 B 还是在以
6000 QPS 的速度去拉取消息，自然 MQ 中的消息就慢慢被释放掉了。

这就是流量削峰的过程。

在电商秒杀、抢票等等具有流量峰值的场景下可以使用这么一套架构。

尼恩提示，消息中间件在架构当中，非常重要。

所以，尼恩也给大家准备了 _rocketmq_ 四部曲，带大家从底层原理，和核心原理，精通 _rocketmq_ 消息中
间件。

###### 5 、如何设计一个高并发高可用的方案？

设计高并发高可用的方案需要考虑多个方面，包括硬件基础设施、网络架构、应用软件架构和中间件高
可用高并发架构等。

**硬件基础设施**

**1. 服务器选择**

为了实现高可用性，我们需要使用多台服务器。

首先，我们需要选择服务器的配置。服务器的配置应该足够强大，以处理高并发请求。

我们建议使用至少 8 核 CPU 和 16 GB 内存的服务器，并且每台服务器应该有至少 2 个网卡。

此外，我们建议使用固态硬盘（SSD）而不是机械硬盘，因为 SSD 可以提供更快的读写速度。

**2. 负载均衡器**

为了分发请求并提高系统的可用性，我们需要使用负载均衡器。

负载均衡器可以将请求分发到多个服务器上，以实现负载均衡。我们建议使用硬件负载均衡器，因为它
可以提供更好的性能和可靠性。如果使用云服务提供商的负载均衡器，则需要考虑其性能和可靠性。

**3. 虚拟化技术**

为了实现快速部署和扩展，我们建议使用虚拟化技术。

虚拟化技术可以将一台物理服务器划分为多个虚拟服务器，每个虚拟服务器都可以运行独立的操作系统
和应用程序。这使得我们可以快速部署和扩展服务器，同时提高了资源的利用率。

**网络架构**

**1. CDN**

为了加速静态资源的传输并减轻服务器的负担，我们建议使用 CDN（内容分发网络）。CDN 可以将静态
资源缓存到离用户更近的节点上，以提高资源的传输速度。我们建议使用全球性的 CDN 服务提供商，例
如阿里云 CDN、腾讯云 CDN 等。

**2. 防火墙和 DDoS 防护系统**

为了保障网络安全，我们需要使用防火墙和 DDoS 防护系统。防火墙可以阻止未经授权的访问，保护系
统免受攻击。DDoS 防护系统可以识别和阻止 DDoS 攻击，保障系统的可用性。我们建议使用专业的防火
墙和 DDoS 防护系统，例如阿里云安全组、腾讯云安全组等。


**应用高可用架构**

为了实现应用高可用，一般会集群化部署。

当然所谓的集群化部署，在初期用户量很少的情况下，其实一般也就是部署两台应用服务器而已，然后
前面会放一台服务器部署负载均衡设备，比如说 LVS，均匀的把用户请求打到两台应用服务器上去。

如果此时某台应用服务器故障了，还有另外一台应用服务器是可以使用的，这样就避免了单点故障问
题。

如下图所示：

**应用微服务的高并发架构**

这个假设这个网站预估的用户数是 1000 万，那么根据 28 法则，每天会来访问这个网站的用户占到
20%，也就是 200 万用户每天会过来访问。

通常假设平均每个用户每次过来会有 30 次的点击，那么总共就有 6000 万的点击（PV）。

每天 24 小时，根据 28 法则，每天大部分用户最活跃的时间集中在（ 24 小时 * 0.2）≈ 5 小时内，而大部
分用户指的是（ 6000 万点击 * 0.8 ≈ 5000 万点击）

也就是说，在 5 小时内会有 5000 万点击进来。

换算下来，在那 5 小时的活跃访问期内，大概每秒钟会有 3000 左右的请求量，然后这 5 小时中可能又会
出现大量用户集中访问的高峰时间段。

比如在集中半个小时内大量用户涌入形成高峰访问。

根据线上经验，一般高峰访问是活跃访问的 2~3 倍。假设我们按照 3 倍来计算，那么 5 小时内可能有短暂
的峰值会出现每秒有 10000 左右的请求。

大概知道了高峰期每秒钟可能会有 1 万左右的请求量之后，来看一下系统中各个服务器的压力预估。

一般来说一台虚拟机部署的应用服务器，上面放一个 Tomcat，也就支撑最多每秒几百的请求。

按每秒支撑 500 的请求来计算，那么支撑高峰期的每秒 1 万访问量，需要部署 20 台应用服务。


而且应用服务器对数据库的访问量又是要翻几倍的，因为假设一秒钟应用服务器接收到 1 万个请求，但
是应用服务器为了处理每个请求可能要涉及到平均 3~5 次数据库的访问。

按照 3 次数据库访问来算，那么每秒会对数据库形成 3 万次的请求。

按照一台数据库服务器最高支撑每秒 5000 左右的请求量，此时需要通过 6 台数据库服务器才能支撑每秒
3 万左右的请求。

图片服务器的压力同样会很大，因为需要大量的读取图片展示页面，这个不太好估算，但是大致可以推
算出来每秒至少也会有几千次请求，因此也需要多台图片服务器来支撑图片访问的请求。

**业务垂直拆分**

一般来说在这个阶段要做的第一件事儿就是业务的垂直拆分

因为如果所有业务代码都混合在一起部署，会导致多人协作开发时难以维护。

在网站到了千万级用户的时候，研发团队一般都有几十人甚至上百人。

所以这时如果还是在一个单块系统里做开发，是一件非常痛苦的事情，此时需要做的就是进行业务的垂
直拆分，把一个单块系统拆分为多个业务系统，然后一个小团队 10 个人左右就专门负责维护一个业务系
统。

如下图

**中间件的高可用高并发架构**

**分布式缓存高可用高并发架构**

这个时候应用服务器层面一般没什么大问题，因为无非就是加机器就可以抗住更高的并发请求。

现在估算出来每秒钟是 1 万左右的请求，部署个二三十台机器就没问题了。

但是目前上述系统架构中压力最大的，其实是数据库层面，因为估算出来可能高峰期对数据库的读写
并发会有 3 万左右的请求。

此时就需要引入分布式缓存来抗下对数据库的读请求压力了，也就是引入 Redis 集群。

一般来说对数据库的读写请求也大致遵循 28 法则，所以每秒 3 万的读写请求中，大概有 2.4 万左右是读请
求


这些读请求基本上 90%都可以通过分布式缓存集群来抗下来，也就是大概 2 万左右的读请求可以通过
Redis 集群来抗住。

我们完全可以把热点的、常见的数据都在 Redis 集群里放一份作为缓存，然后对外提供缓存服务。

在读数据的时候优先从缓存里读，如果缓存里没有，再从数据库里读取。这样 2 万读请求就落到 Redis 上
了， 1 万读写请求继续落在数据库上。

Redis 一般单台服务器抗每秒几万请求是没问题的，所以 Redis 集群一般就部署 3 台机器，抗下每秒 2 万读
请求是绝对没问题的。如下图所示：

**数据库主从架构做读写分离**

对于数据库服务器而言，此时一般也会使用主从架构，部署一台从库来从主库同步数据，

如下图：


这样一旦主库出现问题，可以迅速使用从库继续提供数据库服务，避免数据库故障导致整个系统都彻底
故障不可用。

此时数据库服务器还是存在每秒 1 万的请求，对于单台服务器来说压力还是过大。

但是数据库一般都支持主从架构，也就是有一个从库一直从主库同步数据过去。此时可以基于主从架构
做读写分离。

也就是说，每秒大概 6000 写请求是进入主库，大概还有 4000 个读请求是在从库上去读，这样就可以把 1
万读写请求压力分摊到两台服务器上去。

这么分摊过后，主库每秒最多 6000 写请求，从库每秒最多 4000 读请求，基本上可以勉强把压力给抗
住。如下图：


**总结**

大型网站架构中共涉及的技术远远不止这些，还包括了 MQ、CDN、静态化、分库分表、NoSQL、搜
索、分布式文件系统、反向代理，等等很多话题，但是本文不能一一涉及，

后面 _40_ 岁老架构师尼恩会通过公号《技术自由圈》持续的写架构文章，还请大家持续关注。

###### 6 、说说限流算法，漏桶、令牌桶和计数

**40 岁老架构师尼恩提示**

限流是面试中的常见的面试题（尤其是大厂面试、高 P 面试）

非常常见、非常常见

社群里边，很多小伙伴在面试大厂时，遇到了

下面一个小伙伴，反馈他在阿里三面的时候，也遇到了

**为什么要限流**

```
简单来说：
```

```
限流在很多场景中用来限制并发和请求量，比如说秒杀抢购，保护自身系统和下游系统不被巨型
流量冲垮等。
```
以微博为例，例如某某明星公布了恋情, 访问从平时的 50 万增加到了 500 万，系统的规划能力，最多可以
支撑 **200 万访问** ,那么就要执行限流规则, 保证是一个可用的状态, 不至于 **服务器崩溃** ，所有请求不可用。

**限流的思想**

```
在保证可用的情况下尽可能多增加进入的人数, 其余的人在排队等待, 或者返回友好提示, 保证里面
的进行系统的用户可以正常使用，防止系统雪崩。
```
**日常生活中, 有哪些需要限流的地方?**

像我旁边有一个国家景区, 平时可能根本没什么人前往, 但是一到五一或者春节就人满为患, 这时候景区管
理人员就会实行一系列的政策来限制进入人流量,
为什么要限流呢?

假如景区能容纳一万人, 现在进去了三万人, 势必摩肩接踵, 整不好还会有事故发生, 这样的结果就是所有人
的体验都不好，如果发生了事故景区可能还要关闭, 导致对外不可用，这样的后果就是所有人都觉得体验
糟糕透了。

**限流的算法**

限流算法很多, 常见的有三类, 分别是计数器算法、漏桶算法、令牌桶算法, 下面逐一讲解。

限流的手段通常有计数器、漏桶、令牌桶。注意限流和限速（所有请求都会处理）的差别，视
业务场景而定。

（ 1 ）计数器：

在一段时间间隔内（时间窗/时间区间），处理请求的最大数量固定，超过部分不做处理。

（ 2 ）漏桶：

漏桶大小固定，处理速度固定，但请求进入速度不固定（在突发情况请求过多时，会丢弃过多的请
求）。

（ 3 ）令牌桶：

令牌桶的大小固定，令牌的产生速度固定，但是消耗令牌（即请求）速度不固定（可以应对一些某些时
间请求过多的情况）；每个请求都会从令牌桶中取出令牌，如果没有令牌则丢弃该次请求。

**计数器算法**

**计数器限流定义：**

在一段时间间隔内（时间窗/时间区间），处理请求的最大数量固定，超过部分不做处理。

简单粗暴, 比如指定线程池大小，指定数据库连接池大小、nginx 连接数等, 这都属于计数器算法。

计数器算法是限流算法里最简单也是最容易实现的一种算法。

举个例子, 比如我们规定对于 A 接口，我们 1 分钟的访问次数不能超过 100 个。

那么我们可以这么做：

```
在一开始的时候，我们可以设置一个计数器 counter，每当一个请求过来的时候，counter 就加
1 ，如果 counter 的值大于 100 并且该请求与第一个请求的间隔时间还在 1 分钟之内，那么说明请求
数过多, 拒绝访问；
```

```
如果该请求与第一个请求的间隔时间大于 1 分钟，且 counter 的值还在限流范围内，那么就重置
counter, 就是这么简单粗暴。
```
**计算器限流的实现**

```
package com. crazymaker. springcloud. ratelimit;
```
```
import lombok. extern. slf 4 j. Slf 4 j;
import org. junit. Test;
```
```
import java. util. concurrent. CountDownLatch;
import java. util. concurrent. ExecutorService;
import java. util. concurrent. Executors;
import java. util. concurrent. atomic. AtomicInteger;
import java. util. concurrent. atomic. AtomicLong;
```
```
// 计速器限速
@Slf 4 j
public class CounterLimiter
{
```
```
// 起始时间
private static long startTime = System.currentTimeMillis ();
// 时间区间的时间间隔 ms
private static long interval = 1000 ;
// 每秒限制数量
private static long maxCount = 2 ;
//累加器
private static AtomicLong accumulator = new AtomicLong ();
```
```
// 计数判断, 是否超出限制
private static long tryAcquire (long taskId, int turn)
{
long nowTime = System.currentTimeMillis ();
//在时间区间之内
if (nowTime < startTime + interval)
{
long count = accumulator.incrementAndGet ();
```
```
if (count <= maxCount)
{
return count;
} else
{
```

return - count;
}
} else
{
//在时间区间之外
synchronized (CounterLimiter. class)
{
log.info ("新时间区到了, taskId{}, turn {}..", taskId, turn);
// 再一次判断，防止重复初始化
if (nowTime > startTime + interval)
{
accumulator.set ( 0 );
startTime = nowTime;
}
}
return 0 ;
}
}

//线程池，用于多线程模拟测试
private ExecutorService pool = Executors.newFixedThreadPool ( 10 );

@Test
public void testLimit ()
{

// 被限制的次数
AtomicInteger limited = new AtomicInteger ( 0 );
// 线程数
final int threads = 2 ;
// 每条线程的执行轮数
final int turns = 20 ;
// 同步器
CountDownLatch countDownLatch = new CountDownLatch (threads);
long start = System.currentTimeMillis ();
for (int i = 0 ; i < threads; i++)
{
pool.submit (() ->
{
try
{

for (int j = 0 ; j < turns; j++)
{

long taskId = Thread.currentThread (). getId ();
long index = tryAcquire (taskId, j);
if (index <= 0 )
{
// 被限制的次数累积
limited.getAndIncrement ();
}
Thread.sleep ( 200 );
}

} catch (Exception e)
{


**计数器限流的严重问题**

这个算法虽然简单，但是有一个十分致命的问题，那就是临界问题，我们看下图：

从上图中我们可以看到，假设有一个恶意用户，他在0:59时，瞬间发送了 100 个请求，并且1:00又瞬间
发送了 100 个请求，那么其实这个用户在 1 秒里面，瞬间发送了 200 个请求。

我们刚才规定的是 1 分钟最多 100 个请求（规划的吞吐量），也就是每秒钟最多 1.7 个请求，用户通过在
时间窗口的重置节点处突发请求，可以瞬间超过我们的速率限制。

用户有可能通过算法的这个漏洞，瞬间压垮我们的应用。

```
e.printStackTrace ();
}
//等待所有线程结束
countDownLatch.countDown ();
```
```
});
}
try
{
countDownLatch.await ();
} catch (InterruptedException e)
{
e.printStackTrace ();
}
float time = (System.currentTimeMillis () - start) / 1000 F;
//输出统计结果
```
```
log.info ("限制的次数为：" + limited.get () +
", 通过的次数为：" + (threads * turns - limited.get ()));
log.info ("限制的比例为：" + (float) limited.get () / (float) (threads *
turns));
log.info ("运行的时长为：" + time);
}
```
```
}
```

**漏桶算法**

漏桶算法限流的基本原理为：水（对应请求）从进水口进入到漏桶里，漏桶以一定的速度出水（请求放
行），当水流入速度过大，桶内的总水量大于桶容量会直接溢出，请求被拒绝，如图所示。
大致的漏桶限流规则如下：
（ 1 ）进水口（对应客户端请求）以任意速率流入进入漏桶。
（ 2 ）漏桶的容量是固定的，出水（放行）速率也是固定的。
（ 3 ）漏桶容量是不变的，如果处理速度太慢，桶内水量会超出了桶的容量，则后面流入的水滴会溢
出，表示请求拒绝。

**漏桶算法原理**

漏桶算法思路很简单：

```
水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会超过桶可接纳的容量
时直接溢出。
```
可以看出漏桶算法能强行限制数据的传输速率。

漏桶算法其实很简单，可以粗略的认为就是注水漏水过程，往桶中以任意速率流入水，以一定速率流出
水，当水超过 **桶容量（capacity）** 则丢弃，因为桶容量是不变的，保证了整体的速率。

以一定速率流出水，


**削峰** : 有大量流量进入时, 会发生溢出, 从而限流保护服务可用

**缓冲** : 不至于直接请求到服务器, 缓冲压力

消费速度固定因为计算性能固定

**漏桶算法实现**

```
package com. crazymaker. springcloud. ratelimit;
```
```
import lombok. extern. slf 4 j. Slf 4 j;
import org. junit. Test;
```
```
import java. util. concurrent. CountDownLatch;
import java. util. concurrent. ExecutorService;
import java. util. concurrent. Executors;
import java. util. concurrent. atomic. AtomicInteger;
```
```
// 漏桶限流
@Slf 4 j
public class LeakBucketLimiter {
```
```
// 计算的起始时间
private static long lastOutTime = System.currentTimeMillis ();
// 流出速率每秒 2 次
```

private static int leakRate = 2 ;

// 桶的容量
private static int capacity = 2 ;

//剩余的水量
private static AtomicInteger water = new AtomicInteger ( 0 );

//返回值说明：
// false 没有被限制到
// true 被限流
public static synchronized boolean isLimit (long taskId, int turn) {
// 如果是空桶，就当前时间作为漏出的时间
if (water.get () == 0 ) {
lastOutTime = System.currentTimeMillis ();
water.addAndGet ( 1 );
return false;
}
// 执行漏水
int waterLeaked = ((int) ((System.currentTimeMillis () - lastOutTime) /
1000 )) * leakRate;
// 计算剩余水量
int waterLeft = water.get () - waterLeaked;
water.set (Math.max ( 0 , waterLeft));
// 重新更新 leakTimeStamp
lastOutTime = System.currentTimeMillis ();
// 尝试加水, 并且水还未满，放行
if ((water.get ()) < capacity) {
water.addAndGet ( 1 );
return false;
} else {
// 水满，拒绝加水，限流
return true;
}

}

//线程池，用于多线程模拟测试
private ExecutorService pool = Executors.newFixedThreadPool ( 10 );

@Test
public void testLimit () {

// 被限制的次数
AtomicInteger limited = new AtomicInteger ( 0 );
// 线程数
final int threads = 2 ;
// 每条线程的执行轮数
final int turns = 20 ;
// 线程同步器
CountDownLatch countDownLatch = new CountDownLatch (threads);
long start = System.currentTimeMillis ();
for (int i = 0 ; i < threads; i++) {
pool.submit (() ->
{
try {


**漏桶的问题**

漏桶的出水速度固定，也就是请求放行速度是固定的。

网上抄来抄去的说法：

```
漏桶不能有效应对突发流量，但是能起到平滑突发流量（整流）的作用。
```
实际上的问题：

```
漏桶出口的速度固定，不能灵活的应对后端能力提升。
比如，通过动态扩容，后端流量从 1000 QPS 提升到 1 WQPS，漏桶没有办法。
```
**令牌桶限流**

令牌桶算法以一个设定的速率产生令牌并放入令牌桶，每次用户请求都得申请令牌，如果令牌不足，则
拒绝请求。
令牌桶算法中新请求到来时会从桶里拿走一个令牌，如果桶内没有令牌可拿，就拒绝服务。当然，令牌
的数量也是有上限的。令牌的数量与时间和发放速率强相关，时间流逝的时间越长，会不断往桶里加入

```
for (int j = 0 ; j < turns; j++) {
```
```
long taskId = Thread.currentThread (). getId ();
boolean intercepted = isLimit (taskId, j);
if (intercepted) {
// 被限制的次数累积
limited.getAndIncrement ();
}
Thread.sleep ( 200 );
}
```
```
} catch (Exception e) {
e.printStackTrace ();
}
//等待所有线程结束
countDownLatch.countDown ();
```
```
});
}
try {
countDownLatch.await ();
} catch (InterruptedException e) {
e.printStackTrace ();
}
float time = (System.currentTimeMillis () - start) / 1000 F;
//输出统计结果
```
```
log.info ("限制的次数为：" + limited.get () +
", 通过的次数为：" + (threads * turns - limited.get ()));
log.info ("限制的比例为：" + (float) limited.get () / (float) (threads *
turns));
log.info ("运行的时长为：" + time);
}
}
```

越多的令牌，如果令牌发放的速度比申请速度快，令牌桶会放满令牌，直到令牌占满整个令牌桶，如图
所示。

令牌桶限流大致的规则如下：
（ 1 ）进水口按照某个速度，向桶中放入令牌。
（ 2 ）令牌的容量是固定的，但是放行的速度不是固定的，只要桶中还有剩余令牌，一旦请求过来就能
申请成功，然后放行。
（ 3 ）如果令牌的发放速度，慢于请求到来速度，桶内就无牌可领，请求就会被拒绝。

总之，令牌的发送速率可以设置，从而可以对突发的出口流量进行有效的应对。

**令牌桶算法**

令牌桶与漏桶相似, 不同的是令牌桶桶中放了一些令牌, 服务请求到达后, 要获取令牌之后才会得到服务, 举
个例子, 我们平时去食堂吃饭, 都是在食堂内窗口前排队的, 这就好比是漏桶算法, 大量的人员聚集在食堂内
窗口外, 以一定的速度享受服务, 如果涌进来的人太多, 食堂装不下了, 可能就有一部分人站到食堂外了, 这就
没有享受到食堂的服务, 称之为溢出, 溢出可以继续请求, 也就是继续排队, 那么这样有什么问题呢?

如果这时候有特殊情况, 比如有些赶时间的志愿者啦、或者高三要高考啦, 这种情况就是突发情况, 如果也
用漏桶算法那也得慢慢排队, 这也就没有解决我们的需求, 对于很多应用场景来说，除了要求能够限制数
据的平均传输速率外，还要求允许某种程度的突发传输。这时候漏桶算法可能就不合适了，令牌桶算法
更为适合。如图所示，令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要
被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。


**令牌桶算法实现**

```
package com. crazymaker. springcloud. ratelimit;
```
```
import lombok. extern. slf 4 j. Slf 4 j;
import org. junit. Test;
```
```
import java. util. concurrent. CountDownLatch;
import java. util. concurrent. ExecutorService;
import java. util. concurrent. Executors;
import java. util. concurrent. atomic. AtomicInteger;
```
```
// 令牌桶限速
@Slf 4 j
public class TokenBucketLimiter {
// 上一次令牌发放时间
public long lastTime = System.currentTimeMillis ();
// 桶的容量
public int capacity = 2 ;
// 令牌生成速度 /s
public int rate = 2 ;
```

// 当前令牌数量
public AtomicInteger tokens = new AtomicInteger ( 0 );
;

//返回值说明：
// false 没有被限制到
// true 被限流
public synchronized boolean isLimited (long taskId, int applyCount) {
long now = System.currentTimeMillis ();
//时间间隔, 单位为 ms
long gap = now - lastTime;

//计算时间段内的令牌数
int reverse_permits = (int) (gap * rate / 1000 );
int all_permits = tokens.get () + reverse_permits;
// 当前令牌数
tokens.set (Math.min (capacity, all_permits));
log.info ("tokens {} capacity {} gap {} ", tokens, capacity, gap);

if (tokens.get () < applyCount) {
// 若拿不到令牌, 则拒绝
// log.info ("被限流了.." + taskId + ", applyCount: " + applyCount);
return true;
} else {
// 还有令牌，领取令牌
tokens.getAndAdd ( - applyCount);
lastTime = now;

// log.info ("剩余令牌.." + tokens);
return false;
}

}

//线程池，用于多线程模拟测试
private ExecutorService pool = Executors.newFixedThreadPool ( 10 );

@Test
public void testLimit () {

// 被限制的次数
AtomicInteger limited = new AtomicInteger ( 0 );
// 线程数
final int threads = 2 ;
// 每条线程的执行轮数
final int turns = 20 ;

// 同步器
CountDownLatch countDownLatch = new CountDownLatch (threads);
long start = System.currentTimeMillis ();
for (int i = 0 ; i < threads; i++) {
pool.submit (() ->
{
try {

for (int j = 0 ; j < turns; j++) {


**令牌桶的好处**

令牌桶的好处之一就是可以方便地应对突发出口流量（后端能力的提升）。

比如，可以改变令牌的发放速度，算法能按照新的发送速率调大令牌的发放数量，使得出口突发流量能
被处理。

**Guava RateLimiter**

Guava 是 Java 领域优秀的开源项目，它包含了 Google 在 Java 项目中使用一些核心库，包含集合
(Collections)，缓存 (Caching)，并发编程库 (Concurrency)，常用注解 (Common annotations)，String
操作，I/O 操作方面的众多非常实用的函数。 Guava 的 RateLimiter 提供了令牌桶算法实现：平滑突
发限流 (SmoothBursty) 和平滑预热限流 (SmoothWarmingUp) 实现。

```
long taskId = Thread.currentThread (). getId ();
boolean intercepted = isLimited (taskId, 1 );
if (intercepted) {
// 被限制的次数累积
limited.getAndIncrement ();
}
```
```
Thread.sleep ( 200 );
}
```
```
} catch (Exception e) {
e.printStackTrace ();
}
//等待所有线程结束
countDownLatch.countDown ();
```
```
});
}
try {
countDownLatch.await ();
} catch (InterruptedException e) {
e.printStackTrace ();
}
float time = (System.currentTimeMillis () - start) / 1000 F;
//输出统计结果
```
```
log.info ("限制的次数为：" + limited.get () +
", 通过的次数为：" + (threads * turns - limited.get ()));
log.info ("限制的比例为：" + (float) limited.get () / (float) (threads *
turns));
log.info ("运行的时长为：" + time);
}
```
```
}
```

```
RateLimiter 的类图如上所示，
```
**Nginx 漏桶限流**

**Nginx 限流的简单演示**

**每六秒才处理一次请求, 如下**

**这是从请求参数里边，提前参数做限流**

这是从请求参数里边，提前参数，进行限流的次数统计 key。

在 http 块里边定义限流的内存区域 zone。

在 location 块中使用限流 zone，参考如下：

```
limit_req_zone  $arg_sku_id zone=skuzone: 10 m  rate=6 r/m;
limit_req_zone  $http_user_id zone=userzone: 10 m  rate=6 r/m;
limit_req_zone  $binary_remote_addr zone=perip: 10 m  rate=6 r/m;
limit_req_zone  $server_name zone=perserver: 1 m rate=6 r/m;
```
```
limit_req_zone  $arg_sku_id zone=skuzone: 10 m  rate=6 r/m;
limit_req_zone  $http_user_id zone=userzone: 10 m  rate=6 r/m;
limit_req_zone  $binary_remote_addr zone=perip: 10 m  rate=6 r/m;
limit_req_zone  $server_name zone=perserver: 1 m rate=10 r/s;
```

测试

**从 Header 头部提前参数**

1 、nginx 是支持读取非 nginx 标准的用户自定义 header 的，但是需要在 http 或者 server 下开启 header 的
下划线支持:

underscores_in_headers on;

2 、比如我们自定义 header 为 X-Real-IP, 通过第二个 nginx 获取该 header 时需要这样:

$http_x_real_ip; (一律采用小写，而且前面多了个 http_)

```
# ratelimit by sku id
location  = /ratelimit/sku {
limit_req  zone=skuzone;
echo "正常的响应";
}
```
```
[ root@cdh1 ~]# /vagrant/LuaDemoProject/sh/linux/openresty-restart. sh
shell dir is: /vagrant/LuaDemoProject/sh/linux
Shutting down openrestry/nginx: pid is 13479 13485
Shutting down succeeded!
OPENRESTRY_PATH:/usr/local/openresty
PROJECT_PATH:/vagrant/LuaDemoProject/src
nginx: [alert] lua_code_cache is off; this will hurt performance in
/vagrant/LuaDemoProject/src/conf/nginx-seckill. conf:90
openrestry/nginx starting succeeded!
pid is 14197
```
```
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
正常的响应
root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
正常的响应
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
限流后的降级内容
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
限流后的降级内容
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
限流后的降级内容
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
限流后的降级内容
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
限流后的降级内容
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
正常的响应
```
```
underscores_in_headers on;
```
```
limit_req_zone  $http_user_id zone=userzone: 10 m  rate=6 r/m;
server {
listen 80 default;
server_name nginx. server *. nginx. server;
default_type 'text/html';
charset utf-8;
```

测试

**Nginx 漏桶限流的三个细分类型，即 burst、nodelay 参数详解**

**每六秒才处理一次请求, 如下**

**不带缓冲队列的漏桶限流**

limit_req zone=limti_req_zone;

```
严格依照在 limti_req_zone 中配置的 rate 来处理请求
超过 rate 处理能力范围的，直接 drop
```
```
# ratelimit by user id
location  = /ratelimit/demo {
limit_req  zone=userzone;
echo "正常的响应";
}
```
```
location = /50 x. html{
echo "限流后的降级内容";
}
```
```
error_page 502 503 = 200 /50 x. html;
```
```
}
```
```
[ root@cdh1 ~]# curl -H "USER-ID: 1" http://cdh1/ratelimit/demo
正常的响应
[ root@cdh1 ~]# curl -H "USER-ID: 1" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]# curl -H "USER-ID: 1" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]# curl -H "USER-ID: 1" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]# curl -H "USER-ID: 1" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]# curl -H "USER-ID: 1" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]# curl -H "USER-ID: 1" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]# curl -H "USER_ID: 2" http://cdh1/ratelimit/demo
正常的响应
[ root@cdh1 ~]# curl -H "USER_ID: 2" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]#
[ root@cdh1 ~]# curl -H "USER_ID: 2" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]# curl -H "USER-ID: 3" http://cdh1/ratelimit/demo
正常的响应
[ root@cdh1 ~]# curl -H "USER-ID: 3" http://cdh1/ratelimit/demo
限流后的降级内容
```
```
limit_req_zone  $arg_user_id zone=limti_req_zone: 10 m  rate=10 r/m;
```

```
表现为对收到的请求无延时
```
```
假设 1 秒内提交 10 个请求，可以看到一共 10 个请求， 9 个请求都失败了, 直接返回 503 ，
```
接着再查看 /var/log/nginx/access. log，印证了只有一个请求成功了，其它就是都直接返回了 503 ，即
服务器拒绝了请求。

**带缓冲队列的漏桶限流**

limit_req zone=limti_req_zone burst=5;

```
依照在 limti_req_zone 中配置的 rate 来处理请求
同时设置了一个大小为 5 的缓冲队列，在缓冲队列中的请求会等待慢慢处理
超过了 burst 缓冲队列长度和 rate 处理能力的请求被直接丢弃
表现为对收到的请求有延时
```
```
假设 1 秒内提交 10 个请求，则可以发现在 1 s 内，在服务器接收到 10 个并发请求后，先处理 1 个请
求，同时将 5 个请求放入 burst 缓冲队列中，等待处理。而超过（burst+1）数量的请求就被直接
抛弃了，即直接抛弃了 4 个请求。 burst 缓存的 5 个请求每隔 6 s 处理一次。
```
接着查看 /var/log/nginx/access. log 日志

**带瞬时处理能力的漏桶限流**

limit_req zone=req_zone burst=5 nodelay;

**如果设置 nodelay，会在瞬时提供处理 (burst + rate) 个请求的能力** ，请求数量超过 **（burst + rate）**
的时候就会直接返回 503 ，峰值范围内的请求， **不存在请求需要等待的情况** 。

```
假设 1 秒内提交 10 个请求，则可以发现在 1 s 内，服务器端处理了 6 个请求（峰值速度：burst＋10 s
内一个请求）。对于剩下的 4 个请求，直接返回 503 ，在下一秒如果继续向服务端发送 10 个请求，
服务端会直接拒绝这 10 个请求并返回 503 。
```
接着查看 /var/log/nginx/access. log 日志

**可以发现在 1 s 内，服务器端处理了 6 个请求（峰值速度：burst＋原来的处理速度）。对于剩下的 4 个请
求，直接返回 503 。**

```
但是，总数额度和速度时间保持一致，就是额度用完了，需要等到一个有额度的时间段，才开始
接收新的请求。如果一次处理了 5 个请求，相当于占了 30 s 的额度， 6 5=30。因为设定了 6 s 处理 1 个
请求，所以直到 30
s 之后，才可以再处理一个请求，即如果此时向服务端发送 10 个请求，会返回 9 个 503 ，一个 200
```

**分布式限流组件**

**why**

```
但是 Nginx 的限流指令只能在同一块内存区域有效，而在生产场景中秒杀的外部网关往往是多节点
部署，所以这就需要用到分布式限流组件。
```
高性能的分布式限流组件可以使用 Redis+Lua 来开发，京东的抢购就是使用 Redis+Lua 完成的限流。并
且无论是 Nginx 外部网关还是 Zuul 内部网关，都可以使用 Redis+Lua 限流组件。

理论上，接入层的限流有多个维度：

（ 1 ）用户维度限流：在某一时间段内只允许用户提交一次请求，比如可以采取客户端 IP 或者用户 ID 作
为限流的 key。

（ 2 ）商品维度的限流：对于同一个抢购商品，在某个时间段内只允许一定数量的请求进入，可以采取
秒杀商品 ID 作为限流的 key。

什么时候用 nginx 限流：

用户维度的限流，可以在 ngix 上进行，因为使用 nginx 限流内存来存储用户 id，比用 redis 的 key，来存
储用户 id，效率高。

什么时候用 redis+lua 分布式限流：

商品维度的限流，可以在 redis 上进行，不需要大量的计算访问次数的 key，另外，可以控制所有的接入
层节点的访问秒杀请求的总量。

**redis+lua 分布式限流组件**

```
--- 此脚本的环境： redis 内部，不是运行在 nginx 内部
```
```
---方法：申请令牌
--- -1 failed
--- 1 success
--- @param key key 限流关键字
--- @param apply 申请的令牌数量
local function acquire (key, apply)
local times = redis.call ('TIME');
-- times[1] 秒数 -- times[2] 微秒数
local curr_mill_second = times[ 1 ] * 1000000 + times[ 2 ];
curr_mill_second = curr_mill_second / 1000 ;
```
```
local cacheInfo = redis.pcall ("HMGET", key, "last_mill_second",
"curr_permits", "max_permits", "rate")
--- 局部变量：上次申请的时间
local last_mill_second = cacheInfo[ 1 ];
--- 局部变量：之前的令牌数
local curr_permits = tonumber (cacheInfo[ 2 ]);
--- 局部变量：桶的容量
local max_permits = tonumber (cacheInfo[ 3 ]);
--- 局部变量：令牌的发放速率
local rate = cacheInfo[ 4 ];
--- 局部变量：本次的令牌数
local local_curr_permits = 0 ;
```
```
if (type (last_mill_second) ~= 'boolean' and last_mill_second ~= nil) then
-- 计算时间段内的令牌数
```

local reverse_permits = math.floor (((curr_mill_second -
last_mill_second) / 1000 ) * rate);
-- 令牌总数
local expect_curr_permits = reverse_permits + curr_permits;
-- 可以申请的令牌总数
local_curr_permits = math.min (expect_curr_permits, max_permits);
else
-- 第一次获取令牌
redis.pcall ("HSET", key, "last_mill_second", curr_mill_second)
local_curr_permits = max_permits;
end

local result = - 1 ;
-- 有足够的令牌可以申请
if (local_curr_permits - apply >= 0 ) then
-- 保存剩余的令牌
redis.pcall ("HSET", key, "curr_permits", local_curr_permits - apply);
-- 为下次的令牌获取，保存时间
redis.pcall ("HSET", key, "last_mill_second", curr_mill_second)
-- 返回令牌获取成功
result = 1 ;
else
-- 返回令牌获取失败
result = - 1 ;
end
return result
end
--eg
-- /usr/local/redis/bin/redis-cli -a 123456 --eval
/vagrant/LuaDemoProject/src/luaScript/redis/rate_limiter. lua key , acquire 1 1

-- 获取 sha 编码的命令
-- /usr/local/redis/bin/redis-cli -a 123456 script load "$(cat
/vagrant/LuaDemoProject/src/luaScript/redis/rate_limiter. lua)"
-- /usr/local/redis/bin/redis-cli -a 123456 script exists
"cf 43613 f 172388 c 34 a 1130 a 760 fc 699 a 5 ee 6 f 2 a 9"

-- /usr/local/redis/bin/redis-cli -a 123456 evalsha
"cf 43613 f 172388 c 34 a 1130 a 760 fc 699 a 5 ee 6 f 2 a 9" 1 "rate_limiter:seckill: 1" init 1 1
-- /usr/local/redis/bin/redis-cli -a 123456 evalsha
"cf 43613 f 172388 c 34 a 1130 a 760 fc 699 a 5 ee 6 f 2 a 9" 1 "rate_limiter:seckill: 1" acquire 1

--local rateLimiterSha = "e 4 e 49 e 4 c 7 b 23 f 0 bf 7 a 2 bfee 73 e 8 a 01629 e 33324 b";

---方法：初始化限流 Key
--- 1 success
--- @param key key
--- @param max_permits 桶的容量
--- @param rate 令牌的发放速率
local function init (key, max_permits, rate)
local rate_limit_info = redis.pcall ("HMGET", key, "last_mill_second",
"curr_permits", "max_permits", "rate")
local org_max_permits = tonumber (rate_limit_info[ 3 ])
local org_rate = rate_limit_info[ 4 ]

if (org_max_permits == nil) or (rate ~= org_rate or max_permits ~=
org_max_permits) then


```
在 redis 中，为了避免重复发送脚本数据浪费网络资源，可以使用 script load 命令进行脚本数据缓
存，并且返回一个哈希码作为脚本的调用句柄，
```
```
每次调用脚本只需要发送哈希码来调用即可。
```
**分布式令牌限流实战**

**可以使用 redis+lua，实战一票下边的简单案例：**

令牌按照 1 个每秒的速率放入令牌桶，桶中最多存放 2 个令牌，那系统就只会允许持续的每秒处理 2 个请
求，

或者每隔 2 秒，等桶中 2 个令牌攒满后，一次处理 2 个请求的突发情况，保证系统稳定性。

**商品维度的限流**

当秒杀商品维度的限流，当商品的流量，远远大于涉及的流量时，开始随机丢弃请求。

Nginx 的令牌桶限流脚本 getToken_access_limit. lua 执行在请求的 access 阶段，但是，该脚本并没有实
现限流的核心逻辑，仅仅调用缓存在 Redis 内部的 rate_limiter. lua 脚本进行限流。

getToken_access_limit. lua 脚本和 rate_limiter. lua 脚本的关系，具体如图 10-17 所示。

```
redis.pcall ("HMSET", key, "max_permits", max_permits, "rate", rate,
"curr_permits", max_permits)
end
return 1 ;
end
--eg
-- /usr/local/redis/bin/redis-cli -a 123456 --eval
/vagrant/LuaDemoProject/src/luaScript/redis/rate_limiter. lua key , init 1 1
-- /usr/local/redis/bin/redis-cli -a 123456 --eval
/vagrant/LuaDemoProject/src/luaScript/redis/rate_limiter. lua
"rate_limiter:seckill: 1" , init 1 1
```
```
---方法：删除限流 Key
local function delete (key)
redis.pcall ("DEL", key)
return 1 ;
end
--eg
-- /usr/local/redis/bin/redis-cli --eval
/vagrant/LuaDemoProject/src/luaScript/redis/rate_limiter. lua key , delete
```
```
local key = KEYS[ 1 ]
local method = ARGV[ 1 ]
if method == 'acquire' then
return acquire (key, ARGV[ 2 ], ARGV[ 3 ])
elseif method == 'init' then
return init (key, ARGV[ 2 ], ARGV[ 3 ])
elseif method == 'delete' then
return delete (key)
else
--ignore
end
```

图 10-17 getToken_access_limit. lua 脚本和 rate_limiter. lua 脚本关系

什么时候在 Redis 中加载 rate_limiter. lua 脚本呢？

和秒杀脚本一样，该脚本是在 Java 程序启动商品秒杀时，完成其在 Redis 的加载和缓存的。

还有一点非常重要，Java 程序会将脚本加载完成之后的 sha 1 编码，去通过自定义的 key（具体
为"lua: sha 1: rate_limiter"）缓存在 Redis 中，以方便 Nginx 的 getToken_access_limit. lua 脚本去获取，
并且在调用 evalsha 方法时使用。

注意：使用 redis 集群，因此每个节点都需要各自缓存一份脚本数据

**常见的限流组件**

redission 分布式限流采用令牌桶思想和固定时间窗口，trySetRate 方法设置桶的大小，利用 redis key 过
期机制达到时间窗口目的，控制固定时间窗口内允许通过的请求量。

spring cloud gateway 集成 redis 限流, 但属于网关层限流

**参考链接**

系统架构知识图谱（一张价值 10 w 的系统架构知识图谱）

https://www.processon.com/view/link/60fb9421637689719d246739

秒杀系统的架构

https://www.processon.com/view/link/61148c2b1e08536191d8f92f

```
/**
* 由于使用 redis 集群，因此每个节点都需要各自缓存一份脚本数据
* @param slotKey 用来定位对应的 slot 的 slotKey
*/
public void storeScript (String slotKey){
if (StringUtils.isEmpty (unlockSha 1) || !jedisCluster.scriptExists (unlockSha 1,
slotKey)){
//redis 支持脚本缓存，返回哈希码，后续可以继续用来调用脚本
unlockSha 1 = jedisCluster.scriptLoad (DISTRIBUTE_LOCK_SCRIPT_UNLOCK_VAL,
slotKey);
}
}
```

#### 一面总结

问题不多，也就 6 道题目，但是都是硬核题目

小伙伴的回答也到位了，足足回答了 69 分钟

最后，一面顺利通过

#### 二面（ 1 小时）

###### 1 、说说，面向对象的优点有哪些?

面向对象是一种编程方法论，它通过将数据和行为封装在对象中，使得代码更易于理解、扩展和维护。

在面向对象的方法中，程序被视为对象的集合，对象之间互相通信和协作，实现系统的功能。

面向对象方法与传统的结构化方法有着显著区别。该思想提倡运用人类的思维方式，从现实世界中存在
的事物出发来构造软件系统，

面向对象方法建立在“对象”概念基础上，以对象为中心，以类和继承为构造机制来设计和构造软件系
统。

面向对象的优点有：

1. 可重用性好

面向对象方法具有的继承性和封装性支持软件复用。有两种方法可以重复使用一个对象类。一是创建
类的实例，从而直接使用它；二是从它派生出一个满足需要的新类，子类可以重用其父类的数据结构和
程序代码，并且可以在父类的基础上方便地修改和扩充，而且子类的修改并不影响父类的使用。

2. 可扩展性好：

面向对象的程序可以随着需求的增加而扩展，因为对象可以添加新的属性和方法来满足新的需求。

3. 与人类习惯的思维方法一致

传统的结构化软件开发方法是面向过程的，以算法为核心，数据和过程作为相互独立的部分，数据和
过程分离，忽略了数据和操作之间的内在的联系，问题空间和解空间并不是一致的。

面向对象的方法是以对象为核心，尽可能接近人类习惯的抽象思维方法，并尽量一致地描述问题空间
和解空间，从而自然而然地解决问题。

4. 系统的稳定性好

面向对象方法用对象模拟问题域中的实体，以对象间的联系刻画实体间联系。当系统的功能需求变化
时，不会引起软件结构的整体变化，仅需做一些局部的修改。

由于现实世界中的实体是相对稳定的，因此，以对象为中心构造的软件系统也会比较稳定。


5. 较易于开发大型软件产品

用面向对象方法开发大型软件时，把大型软件产品看作是一系列相互独立的小产品，采用 RUP（统一
开发过程）的迭代开发模型，可以降低开发时的技术难度和开发工作管理的难度。

6. 可维护性好

由于面向对象的软件稳定性比较好，容易修改、容易理解、易于测试和调试，因而软件的可维护性就
会比较好。

###### 2 、聊一下数据结构，记得哪些数据结构

数据结构是计算机科学中用于组织、存储和操作数据的方法。在编程中，选择正确的数据结构可以极大
地提高代码的效率和性能。常见的数据结构包括：

```
1. 数组 (Array): 线性结构，通过下标访问元素。
2. 链表 (Linked List): 线性结构，通过指针连接元素。
3. 栈 (Stack): 线性结构，先进后出 (LIFO) 的数据结构。
4. 队列 (Queue): 线性结构，先进先出 (FIFO) 的数据结构。
5. 树 (Tree): 非线性结构，由节点和边组成。
6. 图 (Graph): 非线性结构，由节点和边组成。
7. 堆 (Heap): 非线性结构，可以快速找到最大或最小值的数据结构。
8. 哈希表 (Hash Table):根据关键码值 (Key Value) 进行访问的数据结构。
9. 散列表 (Hash Map):根据关键码值 (Key Value) 进行访问并且可以自动排序的数据结构。
10. 元组树 (Trie Tree): 用于字符串搜索和匹配的数据结构。
```
###### 3 、说一下数组、链表的特点和使用场景

数组和链表是常见的数据结构，它们在很多编程语言中都有着广泛的应用。下面分别简述它们的特点和
应用场景。

**数组**

数组是一种线性数据结构，它由一组按顺序排列的元素组成。

数组中的每个元素都有一个唯一的索引，可以使用索引来访问和修改该元素。

数组通常用于数值计算、图像处理等需要高效地访问和操作元素的场景。

数组是一种线性数据结构，它是由同一种数据类型组成的一系列元素的集合。

数组的大小是在定义时确定的，一旦大小确定，就不能再改变。

数组的主要特点包括：

```
固定大小：数组的大小是在定义时确定的，一旦大小确定，就不能再改变。
随机访问：数组中的元素可以通过一个唯一的索引值来访问，因此可以进行随机访问。
简单高效：数组的操作比较简单，例如插入、删除、查找等操作都可以在 O (1) 的时间复杂度内完
成。
```

下面是一个简单的数组实现：

**数组的优缺点:**

```
1. 插入数据：时间复杂度 O (1)，当我们在数组某个位置需要插入元素时，首先我们可以查询到数组的
第一个元素的内存地址，由于内存地址是连续的，比如我们需要在第 8 个位置插入，则可以直接找
到索引为 8 的内存地址即可，但是如果是在中间插入则需要把后面的数据向后移动，比较耗时
2. 查询第几个数据：时间复杂度 O (1)，和插入的原理一致，基于第一个内存地址即可快速查询
3. 查询某个值的数据：时间复杂度 O (n), 查询某个值的数据时，只能从头到尾遍历数据再进行对比，
需要遍历所有数据
```
**链表**

链表也是一种线性数据结构。

链表是一种动态数据结构，它由一系列节点组成，每个节点包含一个数据元素和一个指向下一个节点的
指针。
链表可以在任意位置插入和删除节点，因此它非常灵活。链表通常用于实现程序的数据结构、网络编程
等场景。

链表的主要特点包括：

```
javaCopy codepublic class Array {
private int size;
private int[ ] data;
```
```
public Array (int size) {
this. size = size;
this. data = new int[size];
}
```
```
public int get (int index) {
if (index < 0 || index >= size) {
throw new IndexOutOfBoundsException ("Index out of range");
}
return data[index];
}
```
```
public void set (int index, int value) {
if (index < 0 || index >= size) {
throw new IndexOutOfBoundsException ("Index out of range");
}
data[index] = value;
}
```
```
public int length () {
return size;
}
}
```

```
动态大小：链表的大小是在运行时确定的，可以随时添加或删除节点。
插入删除方便：链表的操作相对于数组来说更加灵活，例如插入、删除、查找等操作都可以在
O (1) 的时间复杂度内完成。
内存占用相对较大：由于链表需要额外的指针来指向下一个节点，因此它的内存占用相对较大。
```
总之，数组和链表都有各自的优缺点，在实际应用中需要根据具体情况选择合适的数据结构。

下面是一个简单的链表实现：

```
javaCopy codepublic class LinkedList {
private Node head;
```
```
public LinkedList () {
this. head = null;
}
```
```
public void append (int value) {
Node newNode = new Node (value);
if (head == null) {
head = newNode;
return;
}
Node current = head;
while (current. next != null) {
current = current. next;
}
current. next = newNode;
}
```
```
public void prepend (int value) {
Node newNode = new Node (value);
newNode. next = head;
head = newNode;
}
```
```
public void insertAfterNode (Node prevNode, int value) {
if (prevNode == null) {
System.out.println ("Previous node is not in the list");
return;
}
Node newNode = new Node (value);
newNode. next = prevNode. next;
prevNode. next = newNode;
}
```
```
public void deleteNode (int value) {
Node curNode = head;
if (curNode == null) {
System.out.println ("Previous node is not in the list");
return;
}
while (curNode. next != null) {
curNode = curNode. next;
}
if (curNode. value == value) {
curNode. next = curNode. next. next;
return;
```

**链表的优缺点**

```
1. 插入数据: 时间复杂度 O (1), 比如在某个数据后面插入数据，则需要把插入前数据的指针指向要插入
的数据，把要插入的数据的指针指向下一个数据即可，不需要数据进行移动
2. 查询第几个数据: 时间复杂度 O (n), 需要遍历链表查询，因为内存地址是不连续的
3. 查询某个值的数据: 时间复杂度 O (n), 需要遍历链表查询
```
**总体来说，二者的区别是：**

```
数组适合用于需要高效地访问和操作元素的场景，如数值计算、图像处理等；
而链表适合用于需要频繁插入和删除元素的场景，如网络编程等。
在实际编写代码时，需要根据具体的场景和需求选择合适的数据结构。
```
###### 4 、说一下 hashMap，以及 Hashmap 中的红黑树

此题的内容太多，具体请参考尼恩 Java 面试宝典专题 31 PDF

**《专题 31 ：Hash 连环炮面试题（卷王专供+ 史上最全 + 2023 面试必备）》PDF**

```
}
Node prevNode = null;
while (curNode != null) {
if (curNode. value == value) {
prevNode = curNode;
curNode = curNode. next;
} else {
prevNode = curNode;
curNode = curNode. next;
}
}
if (prevNode != null) {
prevNode. next = curNode. next;
} else {
head = curNode. next;
}
}
}
```

红黑树的内容也太多，具体请参考尼恩 Java 面试宝典专题 33 PDF

**《专题 33 ：BST、AVL、RBT 红黑树、三大核心数据结构（卷王专供+ 史上最全 + 2023 面试必备）》
PDF**

###### 5 、hashMap 是线程安全的吗？哪个 hashMap 是线程安全的

此题的内容太多，具体请参考尼恩 Java 面试宝典专题 31 PDF

**《专题 31 ：Hash 连环炮面试题（卷王专供+ 史上最全 + 2023 面试必备）》PDF**


###### 6 、说一下锁

包括了硬件层的锁

操作系统层的锁

JVM 内置锁

JUC 显示锁

分布式锁

内容太多，每一个锁展开，都可以讲 10 分钟。


前面的四个锁：

```
硬件层的锁
操作系统层的锁
JVM 内置锁
JUC 显示锁
```
请参考清华大学出版社出版的，尼恩《 Java 高并发核心编程卷 2 加强版》

后面的分布式锁：

请参考尼恩的尼恩 Java 面试宝典专题：

**《专题 15 ：分布式锁面试题（卷王专供+ 史上最全 + 2023 面试必备）》PDF**

###### 7 、说一下线程池

线程池 (Thread Pool) 是一种多线程处理方式，它可以提高程序的并发性和效率。线程池中维护着一组已
经创建好的线程，当有任务需要执行时，直接从线程池中取出一个空闲的线程来执行任务，如果没有空
闲的线程可用，则将任务放入任务队列中等待执行。

Java 中可以通过 Executor 框架实现线程池，具体步骤如下：

```
1. 创建一个 ExecutorService 对象，可以使用 Executors 工厂类的静态方法获取一个具有指定线程数的
ExecutorService 对象。
2. 将任务提交给 ExecutorService 对象，可以使用 submit () 方法将 Runnable 或 Callable 对象提交给
ExecutorService 对象。
3. 使用 ExecutorService 对象的 execute () 方法执行任务，该方法会返回一个 Future 对象，通过该
Future 对象可以获取任务执行的结果。
4. 当不再需要使用 ExecutorService 对象时，调用 shutdown () 方法关闭线程池。
```
Java 中常用的线程池实现类有 ThreadPoolExecutor 和 ScheduledThreadPoolExecutor。

ThreadPoolExecutor 是一个基于线程池的执行器，它可以存储和重用线程，并且可以设置线程的优先
级、队列大小、拒绝策略等。

ScheduledThreadPoolExecutor 是一个支持延时或周期性执行任务的线程池。它可以设置任务的延时时
间、执行周期和执行次数等。

通过使用这些线程池实现类，可以轻松地创建和管理线程池，并执行任务。以下是一个使用
ThreadPoolExecutor 实现简单计算器的示例代码：

```
javaCopy codeimport java. util. concurrent. ExecutorService;
import java. util. concurrent. Executors;
```
```
public class Calculator {
public static void main (String[] args) {
ExecutorService executor = Executors.newFixedThreadPool ( 5 );
for (int i= 0 ; i< 5 ; i++) {
executor.execute (new CalculatorTask ());
}
executor.shutdown ();
```

这个示例创建了一个包含 5 个线程的线程池，并使用 submit () 方法将 5 个 CalculatorTask 对象提交到线程
池中执行。每个线程执行完毕后，线程池会自动调用 shutdown () 方法，以关闭线程池。这样就可以轻松
地实现一个简单的计算器了。

**关于线程池的更多知识，具体请参考清华大学出版社出版的，尼恩《 Java 高并发核心编程卷 2 加强
版》**

###### 8 、说一下 mysql 索引

**一、索引简介**

**1 、索引是什么?**

MySQL 官方对索引的定义：索引（Index）是帮助 MySQL 高效获取数据的数据结构, 这些数据结构以某
种方式引用（指向）数据。索引的本质是：数据结构。可以简单理解为“排好序的快速查找数据结构”

一个非常恰当的比喻就是书的目录页与书的正文内容之间的关系，为了方便查找书中的内容，通过对内
容建立索引形成目录。因此，首先你要明白的一点就是，索引它也是一个文件，它是要占据物理空间
的。

比如对于 MyISAM 存储引擎来说:

对于 InnoDB 存储引擎来说:

因此，当你对一张表建立索引时，索引文件的大小也会改变，当你数据表中的数据因为增删改变化时，
索引文件也会变化的，只不过 MySQL 会自动维护索引，这个过程不需要你介入，这也是为什么不恰当的
索引会影响 MySQL 性能的原因。

下面是一种可能的索引方式示例：

```
}
}
```
```
class CalculatorTask implements Runnable {
public void run () {
int num 1 = 5 ;
int num 2 = 10 ;
int sum = num 1 + num 2;
System.out.println ("The sum of " + num 1 + " and " + num 2 + " is " +
sum);
}
}
```
```
.frm 后缀的文件存储的是表结构。
.myd 后缀的文件存储的是表数据。
.myi 后缀的文件存储的就是索引文件。
```
```
.frm 后缀的文件存储的是表结构。
.ibd 后缀的文件存放索引文件和数据 (需要开启 innodb_file_per_table 参数)
```

左边是数据表，最左边是数据记录的物理地址。

为了加快 Col 2 的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对
应数据记录物理地址的指针。这样就可以运用二叉查找在一定复杂度内找到相应的数据，从而快速的检
索出符合条件的记录。

**2 、索引的优点和缺点**

优势：

```
1. 建立索引可以大大提高检索的数据, 以及减少表的检索行数
2. 在表连接的连接条件可以加速表与表直接的相连
```
劣势：

```
1. 索引存在于磁盘中，会占据物理空间。
2. 提高了查询速度，同时却会降低更新表的速度，如对表进行 UPDATE、INSERT 和 DELETE。因为更
新表的时候 MySQL 不仅要保存数据，还要更新索引文件每次更新添加了索引列的字段。
```
**3 、不同表中的索引名可以重复建立**

mysql 中不同表的相同字段索引是可以重名的，因为索引文件一表一个；

命名规则：

```
1. 索引是按照特定查找算法的数据结构把数据表中的数据放在索引文件中，以便于快速查找；
2. 索引存在于磁盘中，会占据物理空间。
```
```
普通索引：idx_字段名
```
```
唯一索引：ux_字段名
```

我们平时说的索引，如果没有特别指明，都是 B 树（多路搜索树，并不一定是二叉的）结构组织的索
引。其中聚簇索引，覆盖索引，复合索引，前缀索引，唯一索引默认都是使用 B+树索引，统称索引。
当然，除了 B+树这种类型的索引外，还有哈希索引（hash index）等。

**二、索引分类**

**1 、普通索引**

这是这基本的索引，它没有任何限制，MyISAM 中默认的 B-tree 类型的索引，基本的索引类型，没有
唯一性的限制，允许为 NULL 值。

**2 、唯一索引**

与普通索引一致，不同的是索引值必须唯一，允许有空值

**3 、全文索引**

FULLTEXT 索引仅 MyISAM 引擎支持他们可以从 CHAR、VARCHAR 或 TEXT 列中作为 CREATE TABLE 语句
的一部分被创建，或是随后使用 ALTER TABLE 或 CREATE INDEX 被添加，不过切记对于大容量的数据
表，生成全文索引是一个非常消耗时间非常消耗硬盘空间的做法

**4 、组合索引（最左前缀, 不属于分类）**

```
# 直接创建索引
CREATE INDEX index_name ON table (column (length))
```
```
# 修改表结构的方式添加索引
ALTER TABLE table_name ADD INDEX index_name (column (length))
```
```
# 创建表的时候同时创建索引
CREATE TABLE table_name ( \*, INDEX index_name title (length))
```
```
# 删除索引
DROP INDEX index_name ON table
```
```
# 直接创建索引
CREATE UNIQUE INDEX index_name ON table (column (length))
```
```
# 修改表结构的方式添加索引
ALTER TABLE table_name ADD UNIQUE INDEX index_name (column (length))
```
```
# 创建表的时候同时创建索引
CREATE TABLE table_name ( \*, UNIQUE index_name title (length))
```
```
# 直接创建索引
CREATE FULLTEXT INDEX index_content ON article (content)
```
```
# 修改表结构的方式添加索引
ALTER TABLE article ADD FULLTEXT index_content (content)
```
```
# 创建表的时候同时创建索引
CREATE TABLE table_name ( \*, FULLTEXT (content))
```

平时用的 SQL 查询语句一般都有比较多的限制条件，所以为了进一步榨取 MySQL 的效率，就要考虑建立
组合索引。

建立这样的组合索引，其实是相当于分别建立了下面两组组合索引： –title, time–title

**5 、主键索引（不属于分类）**

数据列不允许重复，不允许为 NULL，一个表只能有一个主键。

**三、查看索引**

**四、索引的类型**

上面说到，索引文件时按照不同的数据结构来存储的，数据结构的不同也产生了不同的索引类型，常见
的索引类型包括

B-Tree 索引、哈希索引、空间数据索引 (R-Tree) 、全文索引

**1 、B-tree 索引**

B-Tree 索引是最常用的一种索引，如果没有指定特定的类型，那么多半就是 B-Tree 索引，事实上，很
多搜索引擎使用的是它的变种 B+Tree，这是对 B-Tree 的一个优化

绝大多数的存储引擎，比如 MyISAM 和 InnoDB 都支持这种索引，因此说它是应用最广泛，最常用的一
种索引方式，但是不同的存储引擎在具体实现时会稍有不同，比如 MyISAM 会使用前缀压缩的方式对索
引进行压缩，InnoDB 则不会。B-tree 系统, 可理解为”排好序的快速查找结构”.

下图展示了 B-Tree 索引是如何存储被索引的数据的:

```
ALTER TABLE article ADD INDEX index_titme_time (title ( 50 ), time ( 10 ))
ALTER TABLE `table_name` ADD INDEX index_name ( `column 1`, `column 2`, `column 3`
)
```
```
ALTER TABLE `table_name` ADD PRIMARY KEY ( `column` )
```
```
show index from 表名
show keys from 表名
desc 表名
```

说明:

左图是一个包含三列的数据表，右图则展示了数据是如何被索引的。

可以看出 B-Tree 是对索引列是按照顺序存储的，每个叶子节点指向被索引的数据，这也是 B-Tree 索引支
持范围查找数据的原因。

**2 、hash 索引**

相比于 B-Tree 索引，哈希索引的实现就比较简单了，它是基于哈希表来实现的，对于要索引的列，存储
引擎会计算出一一对应的哈希码，然后把哈希码存放在哈希表中作为 key，value 值是指向该行数据的指
针。

下图是简单的原理展示:

说明:

左边紫色图表示一个二列的数据表。

中间表示对 fname 列进行哈希索引，计算出哈希值。

右边绿色图表示把生成的哈希值存放于哈希表中。

当我们执行以下查询时:

MySQL 会首先计算查询条件 mary 的哈希值，然后到哈希表中去找该哈希值，如果找到了根据对应的指
针也就找到了需要寻找的数据行。

哈希表的优势与限制:

```
优势
```
在 memory 表里, 默认是 hash 索引, 只需比对哈希值，因此速度非常快，理论查询时间复杂度为 O (1)，性
能优势明显；

```
限制
```
```
1. 不支持任何范围查询，比如 where price > 150，因为是基于哈希计算，支持等值比较。
2. 哈希表是无序存储的，因此索引数据无法用于排序。
3. 主流存储引擎不支持该类型，比如 MyISAM 和 InnoDB。哈希索引只有 Memory, NDB 两种引擎支
持。
4. 必须回行. 就是说通过索引拿到数据位置, 必须回到表中取数据
```
```
select * from testTable where fname = "mary";
```

因此，哈希索引虽然速度快，但其实使用很受限，只适用于某些特殊的场合。

**3 、空间数据索引 (R-Tree)**

空间索引可用于地理数据存储，它需要 GIS 相关函数的支持，由于 MySQL 的 GIS 支持并不完善，所以该
索引方式在 MySQL 中很少有人使用。

**4 、索引总结**

```
1. B-Tree 索引使用最广泛，主流引擎都支持。
2. 哈希索引性能高，适用于特殊场合。
3. R-Tree 不常用。
4. 全文索引 fulltext 适用于海量数据的关键字模糊搜索, 不可能使用 like 吧，不过对中文貌似没有什么
效果，可以使用专业的搜索引擎比如 Sphinx 或 Solr。
```
**五、索引和存储引擎之间的关系**

在 MySQL 中，索引是在存储引擎中实现的，并不是所有的存储引擎都支持所有的索引类型，比如哈希索
引，MyISAM 和 InnoDB 是不支持的；同样，即使对于同一类型的索引，不同的存储引擎实现的方式也可
能是不同的，比如 MyISAM 和 InnoDB 对 B-Tree 索引，具体的实现是有差别的。

总结:

```
1. 不同的存储引擎可能支持不同的索引类型；
2. 不同的存储引擎对同一中索引类型可能有不同的实现方式。
```
###### 9 、说说索引底层原理 （哈希索引和 B+树）

索引底层原理是指数据库如何实现索引的过程。在 MySQL 中，常见的索引类型有 B-Tree 索引和哈希索
引。

B-Tree 索引是一种平衡树形结构，它通过将数据分成多个块来存储索引信息。每个节点都包含一个键值
和指向子节点的指针。B-Tree 索引可以保证查询时沿着树形结构向下遍历即可找到目标数据行，因此具
有较好的查询性能。

哈希索引则是一种基于哈希表的数据结构，它通过将键值映射到哈希表中的一个位置来存储索引信息。
哈希索引适用于等值查询，即查询条件只涉及到键的值而不涉及键的顺序。由于哈希表的查找时间复杂
度为 O (1), 因此哈希索引具有非常快的查询性能。但是，哈希索引不支持范围查询和排序操作，因此在
实际应用中需要根据具体需求进行选择。

无论是 B-Tree 索引还是哈希索引，它们都是通过在内存中创建一个索引结构来加速数据的检索操作。
在查询时，数据库会首先检查缓存中的索引结构是否存在，如果存在则直接返回结果；如果不存在，则
需要从磁盘中读取数据文件并构建索引结构，然后再进行查询操作。

需要注意的是，索引会对插入、更新和删除操作的性能产生影响。因此，在创建索引时需要根据具体的
业务需求和数据特点进行权衡和选择。同时，也需要定期维护索引，删除不必要的索引以及重建不再使
用的索引等操作。


###### 10 、说说 B+树和红黑树时间复杂度

B+树和红黑树都是常用的数据结构，用于实现索引。它们都具有平衡性，可以保证在进行插入、删除、
查找等操作时的复杂度为 O (logn)。

下面分别介绍 B+树和红黑树的时间复杂度：

**B+树**

B+树是一种多路搜索树，它通过将数据分成多个块来存储索引信息。每个节点都包含一个键值和指向子
节点的指针。B+树的查询、插入和删除操作的时间复杂度均为 O (logn), 其中查询操作的时间复杂度为
O (logn), 因为 B+树的叶子节点之间有指针相连，可以沿着指针逐个遍历到叶子节点，然后再进行查找操
作；插入和删除操作的时间复杂度也为 O (logn), 因为 B+树的节点会根据关键字的大小自动排序，插入或
删除操作时需要调整树的结构，以保持平衡性。

**红黑树**

红黑树也是一种自平衡二叉搜索树，它通过旋转和变色等操作来保持树的平衡性。红黑树的插入、删除
和查找操作的时间复杂度均为 O (logn), 其中查找操作的时间复杂度为 O (logn), 因为红黑树的节点会根据关
键字的大小自动排序，插入或删除操作时需要调整树的结构，以保持平衡性。

需要注意的是，B+树和红黑树的具体实现方式可能会影响它们的性能表现。例如，B+树中每个节点可
以存储多个键值和指针，而红黑树中每个节点只存储一个键值。此外，B+树通常适用于范围查询和排序
操作，而红黑树适用于单点查询和有序集合。因此，在实际应用中需要根据具体需求选择合适的数据结
构。

###### 11 、了解 mysql 存储引擎吗，说一下

为了管理方便，人们把连接管理、查询缓存、语法解析、查询优化这些并不涉及真实数据存储的功能划
分为 MySQL Server 的功能，把真实存取数据的功能划分为存储引擎的功能。所以在 MySQL Server 完成
了查询优化后，只需按照生成的执行计划调用底层存储引擎提供的 API，获取到数据后返回给客户端就
好了。

MySQL 中提到了存储引擎的概念。简而言之，存储引擎就是指表的类型。其实存储引擎以前叫做表处理
器，后来改名为存储引擎，它的功能就是接收上层传下来的指令，然后对表中的数据进行提取或写入操
作。

**一、MySQL 支持的引擎**

**我们可以通过如下命令查看当前数据库服务器支持的存储引擎：**

```
show engines
```

```
Engine Support Comment Transactions XA Savepoints
```
```
InnoDB DEFAULT
```
```
Supports
transactions, row-
level locking, and
foreign keys
```
```
YES YES YES
```
```
MRG_MYISAM YES
```
```
Collection of
identical MyISAM
tables
```
```
NO NO NO
```
```
MEMORY YES
```
```
Hash based, stored
in memory, useful
for temporary
tables
```
```
NO NO NO
```
```
BLACKHOLE YES
```
```
/dev/null storage
engine (anything
you write to it
disappears)
```
```
NO NO NO
```
```
MyISAM YES MyISAM storengine age NO NO NO
```
```
CSV YES CSV storage engine NO NO NO
```
```
ARCHIVE YES Archive storengine age NO NO NO
```
```
PERFORMANCE_SCHEMA YES PerformanceSchema NO NO NO
```
```
FEDERATED NO Federstorage engineated MySQL
```
XA 就是 X/Open DTP 定义的交易中间件与数据库之间的接口规范（即接口函数）。交易中间件用它来
通知数据库事务的开始、结束以及提交、回滚等。 XA 接口函数由数据库厂商提供，可以理解 XA 指标表
示是否支持分布式事务。

**查看当前服务器的存储引擎**

如果在创建表的语句中没有显示指定表的存储引擎的话，那就回默认使用 InnoDB 作为表的存储引擎。
如果我们想改变表的默认存储引擎的话，可以这样写启动服务器的命令行：

或者修改 my. cnf 文件：

```
show variables like '%storage_engine%'
```
```
set DEFAULT_STORAGE_ENGINE=InnoDB
```

**1 ）InnoDB 引擎**

具备外键支持功能的事务存储引擎。MySQL 从 3.23.34 a 开始就包含 InnoDB 存储引擎，5.5 之后，默认采
用 InnoDB 引擎。

Innodb 引擎提供了对数据库 ACID 事务的支持。并且还提供了行级锁和外键的约束。InnoDB 是 MySQL
的默认事务型引擎，它被设计用来处理大量的短期 (short-lived) 事务。可以确保事务的完整提交
(Commit) 和回滚 (Rollback)。

**数据文件结构** ：

```
表名. frm 存储表结构（MySQL 8 时合并在表名. ibd 中）
表名. ibd 存储数据和索引
```
**InnoDB 是为处理巨大数据量的最大性能设计** 。在以前的版本中，字典数据以元数据文件、非事务表等
来存储。现在这些元数据文件被删除了，比如. frm .par .trn .isl .db .opt 等都在 MySQL 8 中不
存在了。

对于 MyISAM 的存储引擎，InnoDB 写的处理效率差一些，并且会占用更多的磁盘空间以保持数据和索
引。

MyISAM 只缓存索引，不缓存真实数据。InnoDB 不仅缓存索引还要缓存真实数据，对内存要求较高，而
且内存大小对性能有决定性的影响。

**总结：** 除了增加和查询外，还需要更新、删除操作那么应该优先选择 InnoDB 存储引擎。

**2 ）MyISAM 引擎**

主要的非事务处理存储引擎，其是 5.5 之前默认的存储引擎。

MyISAM 提供了大量的特性，包括全文索引、压缩、空间函数（GIS）等，但 MyISAM 不支持事务、行级
锁、外键，有一个毫无疑问的缺陷就是崩溃后无法安全恢复。

优势是访问的速度快，对事务完整性没有要求或者以 select、insert 为主的应用 (只读应用或以读为主的
业务)。

针对数据统计有额外的常数存储，故而比如 count (*) 的查询效率很高。

**数据文件结构：**

```
表名. frm 存储表结构 (MySQL 8 中为表名. sdi)
表名. MYD 存储数据
表名. MYI 存储索引
```
**3 ）Archive 引擎**

用于数据存档。archive 是归档的意思，仅仅支持插入和查询两种功能（行被插入后不能再修改）。在
MySQL 5.5 以后支持索引功能。

拥有很好的压缩机制，使用 zlib 压缩库，在记录请求的时候实时的进行压缩，经常被用来作为仓库使
用。创建 ARCHIVE 表时，存储引擎会创建名称以表名开头的文件，数据文件的扩展名为. ARZ。

根据英文的测试结论来看，同样数据量下，Archive 表比 MyISAM 表要小大约 75%，比支持事务处理的
InnoDB 表小大于 83%。

Archive 存储引擎采用了行级锁。该引擎支持 AUTO_INCREMENT 列属性。AUTO_INCREMENT 列可以具有
唯一索引或非唯一索引。尝试在任何其他列创建所以会导致错误。

```
default-storage-engine=InnoDB
```

```
特质支持
```
```
B 树索引 NO
```
```
备份/时间点恢复 (在服务器中实现，而不是在存储引擎中) Yes
```
```
集群数据库支持 No
```
```
聚集索引 No
```
```
压缩数据 Yes
```
```
数据缓存 No
```
```
加密数据 (加密功能在服务器中实现) Yes
```
```
外键 No
```
```
全文索引 No
```
```
地理空间数据类型 Yes
```
```
地理空间索引 No
```
```
哈希索引 No
```
```
索引缓存 No
```
```
锁粒度行锁
```
```
MVCC No
```
```
存储限制没有任何限制
```
```
事务 No
```
```
更新数据字典的统计信息 Yes
```
Archive 表适合日志和数据采集（档案）类应用，适合存储大量的独立的作为历史记录的数据。拥有很
高的插入速度，但是对查询的支持较差。

**4 ）Blackhole 引擎**

丢弃写操作，读操作会返回空内容。Blackhole 引擎没有实现任何存储机制，它会丢弃所有插入的数
据，不做任何保证。但服务器会记录 Blackhole 表的日志，所以可以用于复制数据到备库，或者简单地
记录到日志。但这种应用方式会碰到很多问题，不推荐。

**5 ）CSV 引擎**

存储数据时，以逗号分隔各个数据项。CSV 引擎可以将普通的 CSV 文件作为 MySQL 的表来处理，但不支
持索引。其可以作为一种数据交换的机制，存储的数据直接可以在操作系统里，用文本编辑器或者
Excel 读取。对于数据的快速导入、导出是有明显优势的。

创建 CSV 表时，服务器会创建一个纯文本数据文件，其名称以表名开头并带有. CSV 扩展名。当你将数
据存储到表中时，存储引擎将其以逗号分隔值格式保存到数据文件中。

**6 ）Memory 引擎**

置于内存的表。Memory 采用的逻辑介质是内存，响应速度很快，但是当 mysqld 守护进程崩溃的时候数
据会丢失。另外，要求存储的数据是数据长度不变的格式，比如 blob/text 类型的数据不可用。


**Memory 同时支持哈希（HASH）索引和 B+树索引**

```
哈希索引对于等值查询很快，但是对于范围查询慢；
默认使用哈希索引
```
Memory 表至少要比 MyISAM 表要快一个数量级。

memory 表的大小是受到限制的。表的大小主要取决于两个参数，分别是 max_rows 和
max_heap_table_size 。其中，max_rows 可以在创建表时指定，max_heap_table_size 的大小
默认为 16 MB，可以按需要进行扩大。

**Memory 的数据文件和索引文件是分开存储的。**

```
每个基于 Memory 存储引擎的表实际对应一个磁盘文件，该文件的文件名与表名相同，类型为
.frm ，该文件中只存储表的结构，而其数据文件都是存储在内存中的。
优点是有利于数据的快速处理，提高整个表的处理效率；
缺点是数据易丢失，生命周期短。
```
**Federated 引擎** ，访问远程表。该引擎是访问其他 MySQL 服务器的一个代理，尽管该引擎看起来提供
了一种很好的跨服务器的灵活性，但也经常带来问题，因此默认是禁用的。

**Merge 引擎** ，管理多个 MyISAM 表构成的表集合。

NDB 引擎，MySQL 集群专用存储引擎。也叫做 NDB Cluster 存储引擎，主要用于 MySQL Cluster 分布式
集群环境，类似于 Oracle 的 RAC 集群。

**二、MyISAM 与 InnoDB 区别**

MySQL 5.5 之前的默认存储引擎是 MyISAM，5.5 之后修改为了 InnoDB。

首先对于 InnoDB 存储引擎，提供了良好的事务管理、崩溃修复能力和并发控制。因为 InnoDB 存储引擎支
持事务，所以对于要求事务完整性的场合需要选择 InnoDB，比如数据操作除了插入和查询以外还包含
有很多更新、删除操作像财务系统等。缺点是读写效率较差，占用的数据空间相对比较大。

其次对于 MyISAM 存储引擎，如果是小型应用，系统以读操作和插入操作为主，只有很少的更新、删除
操作，并且对事务的要求没有那么高，则可以选择这个存储引擎。MyISAM 存储引擎的优势在于占用空间
小，处理速度快。缺点是不支持事务的完整性和并发性。


```
\ MyISAM InnoDB
```
```
缓存只缓存索引，不缓存真实数据
```
```
不仅缓存索引，还缓存真实数据，对内
存要求较高。而且内存大小对性能有决
定性影响。
```
```
外键不支持支持
```
```
事务不支持支持
```
```
锁表级锁定
```
```
行级锁定、表级锁定，锁定力度小并发
能力高
```
```
索引
的实
现
```
```
B+树索引，myisam 是堆表 B+树索引，Innodb 是索引组织表
```
```
哈希
索引
```
```
不支持支持
```
```
全文
索引
```
```
支持不支持
```
```
记录
存储
顺序
```
```
按记录插入顺序保存按主键大小有序插入
```
```
存储
空间
```
```
MyISAM 可被压缩，存储空间较小
```
```
InnoDB 的表需要更多的内存和存储，
它会在主内存中建立其专用的缓冲池用
于高速缓冲数据和索引
```
```
可移
植
性、
备份
及恢
复
```
```
由于 MyISAM 的数据是以文件的形式存储，
所以在跨平台的数据转移中会很方便。在备
份和恢复时可单独针对某个表进行操作
```
```
免费的方案可以是拷贝数据文件、备份
binlog，或者用 mysqldump，在数据
量达到几十 G 的时候就相对痛苦了
```
**1 ）在索引上的区别**

```
InnoDB 索引是聚簇索引，MyISAM 索引是非聚簇索引。
InnoDB 的主键索引的叶子节点存储着行数据，因此主键索引非常高效。
MyISAM 索引的叶子节点存储的是行数据地址，需要再寻址一次才能得到数据。
InnoDB 非主键索引的叶子节点存储的是主键和其他带索引的列数据，因此查询时做到覆盖索引会
非常高效。
InnoDB 的数据文件本身就是主键索引文件，这样的索引被称为“聚簇索引”
```
InnoDB 中 primary index (主键索引或者聚簇索引) 是和 row data 存放在一起的，而 secondary index (辅
助索引) 则是单独存放，然后有个指针指向 primary key。primary key 则主要在扫描索引同时要返回 row
data 时的作用较大。

**2 ）表/行锁差异**

MyISAM 只支持表级锁，用户在操作 myisam 表时，select，update，delete，insert 语句都会给表自动
加锁，如果加锁以后的表满足 insert 并发的情况下，可以在表的尾部插入新的数据。


InnoDB 支持事务和行级锁，是 innodb 的最大特色。行锁大幅度提高了多用户并发操作的新能。但是
InnoDB 的行锁，是在索引上生效的。如果没有命中索引，则锁表。

MyISAM 锁的粒度是表级，而 InnoDB 支持行级锁定。简单来说就是, InnoDB 支持数据行锁定，而 MyISAM 不
支持行锁定，只支持锁定整个表。

MyISAM 同一个表上的读锁和写锁是互斥的，MyISAM 并发读写时如果等待队列中既有读请求又有写请
求，默认写请求的优先级高，即使读请求先到，所以 MyISAM 不适合于有大量查询和修改并存的情况，
那样查询进程会长时间阻塞。因为 MyISAM 是锁表，所以某项读操作比较耗时会使其他写进程饿死。

**3 ）表主键**

**MyISAM：** 允许没有任何索引和主键的表存在，索引都是保存行的地址。

**InnoDB：** 如果没有设定主键或者非空唯一索引，就会自动生成一个 6 字节的主键 (用户不可见)，行数据
是主键索引的一部分，二级索引则是单独存放，然后有个指针指向 primary key。InnoDB 的主键范围更
大，最大是 MyISAM 的 2 倍。

**4 ）行数统计 count**

没有 where 的 count () 使用 MyISAM 要比 InnoDB 快得多。因为 MyISAM 内置了一个计数器，count () 时它
直接从计数器中读，而 InnoDB 必须扫描全表。

所以在 InnoDB 上执行 count () 时一般要伴随 where，且 where 中要包含主键以外的索引列。为什么这里
特别强调“主键以外”？

因为 InnoDB 中主键索引是和行数据存放在一起的，而二级索引则是单独存放，然后有个指针指向
primary key。所以只是 count () 的话使用 secondary index 扫描更快，而 primary key 则主要在扫描索引
同时要返回 row data 时的作用较大。

**三、InnoDB 的优势**

InnoDB 存储引擎在实际应用中拥有诸多优势，比如操作便利、提高了数据库的性能、维护成本低等。
如果由于硬件或软件的原因导致服务器崩溃，那么在重启服务器之后不需要进行额外的操作。InnoDB
崩溃恢复功能自动将之前提交的内容定型，然后撤销没有提交的进程，重启之后继续从崩溃点开始执
行。

InnoDB 存储引擎在主内存中维护缓冲池，高频率使用的数据将在内存中直接被处理。这种缓存方式应
用于多种信息，加速了处理进程。

在专用服务器上，物理内存中高达 80%部分被应用于缓冲池。插入、更新和删除操作通过做改变缓冲自
动机制进行优化。InnoDB 不仅支持当前读写，也会缓冲改变的数据到数据流磁盘。

如果需要将数据插入不同的表中，可以设置外键加强数据的完整性。更新或者删除数据，关联数据将会
被自动更新或删除。如果试图将数据插入从表，但在主表中没有对应的数据，插入的数据将被自动移
除。

如果磁盘或内存中的数据出现崩溃，在使用脏数据之前，校验和机制会发出警告。当每个表的主键都设
置合理时，与这些列有关的操作会被自动优化。

InnoDB 的性能优势不只存在于长时运行查询的大型表。在同一列多次被查询时，自适应哈希索引会提高
查询的速度。使用 InnoDB 可以压缩表和相关索引，可以在不影响性能和可用性的情况下创建或删除索
引。

对于大型文本和 BLOB 数据，使用动态行形式，这种存储布局更高效。即使有些操作系统限制文件大小
为 2 GB，InnoDB 仍然可以处理。当处理大数据量时，InnoDB 兼顾 CPU 以达到最大性能。

在同一个语句中，InnoDB 表可以与其他存储引擎表混用。

**四、InnoDB 和 ACID 模型**


ACID 模型是一系列数据库设计规则，这些规则着重强调可靠性，而可靠性对于商业数据和任务关键型应
用非常重要。MySQL 包含类似 InnoDB 存储引擎的组件，与 ACID 模型紧密相连，这样出现意外时，数据
不会崩溃，结果不会失真。

如果依赖 ACID 模型，可以不使用一致性检查和崩溃恢复机制。如果拥有额外的软件保护，极可靠的硬件
或者应用可以容忍一小部分的数据丢失和不一致，可以将 MySQL 设置调整为只依赖部分 ACID 特性，以
达到更高的性能。下面给出 InnoDB 存储引擎和 ACID 模型相同作用的四个方面。

**1 ）原子方面**

ACID 的原子方面主要涉及 InnoDB 事务，与 MySQL 相关的特性主要包括：

```
自动提交设置
Commit 语句
rollBack 语句
操作 INFORMATION_SCHEMA 库中的表数据
```
**2 ）一致性方面**

ACID 模型的一致性主要涉及保护数据不崩溃的内部 InnoDB 处理过程，与 MySQL 相关的特性主要包括：

```
InnoDB 双写缓存
InnoDB 崩溃恢复
```
**3 ）隔离方面**

隔离是应用于事务的级别，与 MySQL 相关的特性主要包括：

```
自动提交设置
SET ISOLATION LEVEL 语句
InnoDB 锁的低级别信息
```
**4 ）耐久性 (持久性) 方面**

ACID 模型的耐久性主要涉及与硬件配置相互影响的 mysql 软件特性。由于硬件复杂度多样化，耐久性方
面没有具体的规则可循。与 MySQL 相关的特性有：

```
InnoDB 双写缓存，通过 innodb_doublewrite 配置项配置；
配置项 innodb_flush_log_at_trx_commit
配置项 sync_binlog
配置项 innodb_file_per_table
存储设备的写入缓存
存储设备的备用电池缓存
运行 MySQL 的操作系统
持续的电力供应
备份策略
对分布式或托管的应用，最主要的在于硬件设备的地点及网络情况
```
**五、InnoDB 架构**

**1 ）缓冲池**

缓冲池是主内存中的一部分空间，用来缓存已使用的表和索引数据。缓冲池使得经常被使用的数据能够
直接在内存中获得，从而提高速度。

**2 ）更改缓存**

更改缓存是一个特殊的数据结构，当受影响的索引页不在缓存中时，更改缓存会缓存辅助索引页的更
改。索引页被其他读取操作时会加载到缓存池，缓存的更改内容就会被合并。不同于集群索引，辅助索
引并非独一无二的。


当系统大部分闲置时，清除操作会定期运行，将更新的索引页刷入磁盘。更新缓存合并期间，可能会大
大降低查询的性能。在内存中，更新缓存占用一部分 InnoDB 缓冲池。在磁盘中，更新缓存是系统表空
间的一部分。更新缓存的数据类型由 innodb_change_buffering 配置项管理。

**3 ）自适应哈希索引**

自适应哈希索引将负载和足够的内存结合起来，使得 InnoDB 像内存数据库一样运行，不需要降低事务
上的性能或可靠性。这个特性通过 innodb_adaptive_hash_index 选项配置，或者通过 --skip-
innodb_adaptive_hash_index 命令行在服务器启动时关闭。

**4 ）重做日志缓存**

重做日志缓存存放要放入重做日志的数据。重做日志缓存大小通过 innodb_log_buffer_size 配置项配
置。重做日志缓存会定期地将日志文件刷入磁盘。大型的重做日志缓存使得大型事务能够正常运行而不
需要写入磁盘。

**5 ）系统表空间**

系统表空间包括 InnoDB 数据字典、双写缓存、更新缓存和撤销日志，同时也包括表和索引数据。多表
共享，系统表空间被视为共享表空间。

**6 ）双写缓存**

双写缓存位于系统表空间中，用于写入从缓存池刷新的数据页。只有在刷新并写入双写缓存后，
InnoDB 才会将数据页写入合适的位置。

**7 ）撤销日志 (Undo log)**

撤销日志是一系列与事务相关的撤销记录的集合，包含如何撤销事务最近的更改。

如果其他事务要查询原始数据，可以从撤销日志记录中追溯未更改的数据。撤销日志存在于撤销日志片
段中，这些片段包含于回滚片段中。

**8 ）独立表空间**

也就是每个表一个文件的表空间，即每个单独的表空间创建在自身的数据文件中，而不是系统表空间
中。这个功能通过 innodb_file_per_table 配置项开启。每个表空间由一个单独的 .ibd 数据文件
代表，该文件默认被创建在数据库目录中。

**9 ）通用表空间**

使用 CREATE TABLESPACE 语法创建共享的 InnoDB 表空间。通用表空间可以创建在 MySQL 数据目录之
外能够管理多个表并支持所有行格式的表。

**10 ）撤销表空间**

撤销表空间由一个或多个包含撤销日志的文件组成，撤销表空间的数量是由 innodb_undo_tablespace
配置项配置。

**11 ）临时表空间**

用户创建的临时表空间和基于磁盘的内部临时表都创建于临时表空间。
innodb_temp_data_file_path 配置项定义了相关的路径、名称、大小和属性。如果该值为空，默认
会在 innodb_data_home_dir 变量指定的目录下创建一个自动扩展的数据文件。

**12 ）重做日志 (Redo log)**

重做日志是基于磁盘的数据结构，在崩溃恢复期间使用，用来修复数据。正常操作期间，重做日志会将
请求数据进行编码，这些请求会改变 InnoDB 表数据。遇到意外崩溃后，未完成的更改会自动在初始化
期间重新进行。


###### 12 、说说 mysql 集群原理

**一、什么是 MySQL 集群**

MySQL 集群是一个无共享的 (shared-nothing)、分布式节点架构的存储方案，其目的是提供容错性和高
性能。

数据更新使用读已提交隔离级别（read-committedisolation) 来保证所有节点数据的一致性，使用两阶
段提交机制（two-phasedcommit) 保证所有节点都有相同的数据 (如果任何一个写操作失败，则更新失
败）。

无共享的对等节点使得某台服务器上的更新操作在其他服务器上立即可见。传播更新使用一种复杂的通
信机制，这一机制专用来提供跨网络的高吞吐量。

通过多个 MySQL 服务器分配负载，从而最大程序地达到高性能，通过在不同位置存储数据保证高可用性
和冗余。

**二、架构图**

**三、如何存储数据**

1. Mysqlcluster 数据节点组内主从同步采用的是同步复制，来保证组内节点数据的一致性。一般通过两
阶段提交协议来实现，一般工作过程如下：

1 ）Master 执行提交语句时，事务被发送到 slave，slave 开始准备事务的提交。


2 ）每个 slave 都要准备事务，然后向 master 发送 OK (或 ABORT) 消息，表明事务已经准备好（或者无法
准备该事务）。

3 ）Master 等待所有 Slave 发送 OK 或 ABORT 消息

如果 Master 收到所有 Slave 的 OK 消息，它就会向所有 Slave 发送提交消息，告诉 Slave 提交该事务；

如果 Master 收到来自任何一个 Slave 的 ABORT 消息，它就向所有 Slave 发送 ABORT 消息，告诉 Slave 去中
止事务。

4 ）每个 Slave 等待来自 Master 的 OK 或 ABORT 消息。

如果 Slave 收到提交请求，它们就会提交事务，并向 Master 发送事务已提交的确认；

如果 Slave 收到取消请求, 它们就会撤销所有改变并释放所占有的资源，从而中止事务，然后向 Masterv
送事务已中止的确认。

5 ） 当 Master 收到来自所有 Slave 的确认后，就会报告该事务被提交（或中止），然后继续进行下一个
事务处理。

由于同步复制一共需要 4 次消息传递，故 mysql cluster 的数据更新速度比单机 mysql 要慢。所以 mysql
cluster 要求运行在千兆以上的局域网内，节点可以采用双网卡，节点组之间采用直连方式。

疑问： 对 cluster 进行扩容增加数据节点组时会不会导致数据更新速度降低？

答：不会，数据更新速度会变快。因为数据是分别处理，每个节点组所保存的数据是不一样的，
也能减少锁定。

2. Mysqlcluster 将所有的索引列都保存在主存中，其他非索引列可以存储在内存中或者通过建立表空间
存储到磁盘上。如果数据发生改变 (insert, update, delete 等)，mysql 集群将发生改变的记录写入重做日
志，然后通过检查点定期将数据定入磁盘。由于重做日志是异步提交的，所以故障期间可能有少量事务
丢失。为了减少事务丢失，mysql 集群实现延迟写入 (默认延迟两秒，可配置)，这样就可以在故障发生
时完成检查点写入，而不会丢失最后一个检查点。一般单个数据节点故障不会导致任何数据丢失，因为
集群内部采用同步数据复制。

**四、MySQL 集群的横向扩展**

1. 添加数据节点组来扩展写操作，提高 cluster 的存储能力。支持在线扩容，先将新的节点加入到
clsuter 里，启动后用
ALTER ONLINE TABLE table_name REORGANIZE PARTITION

命令进行数据迁移，把数据平均分配到数据节点上。

2. 添加 Slave 仅仅扩展读，而不能做到写操作的横向扩展。

整个系统的平均负载可以描述为：

AverageLoad=∑readload+ ∑writeload / ∑capacity

假设每个服务器每秒有 10000 的事务量，而 Master 每秒的写负载为 4000 个事务，每秒的读负载为
6000 ，结果就是:

AverageLoad=6000+4000/10000=100%

现在，添加 3 个 slave, 每秒的事务量增加到 40000 。因为写操作也会被复制，每个写操作执行 4 次，

这样每个 slave 的写负载就是每秒 4000 个事务。那么现在的平均负载为：


**五、MySQL 集群的优缺点**

优点：

1 ）99.999%的高可用性

2 ）) 快速的自动失效切换

3 ）灵活的分布式体系结构，没有单点故障

4 ）高吞吐量和低延迟

5 ）可扩展性强，支持在线扩容

缺点：

1 ）存在很多限制，比如：不支持外键

2 ）部署、管理、配置很复杂

3 ）占用磁盘空间大，内存大

4 ）备份和恢复不方便

5 ）重启的时候，数据节点将数据 load 到内存需要很长时间

###### 13 、关于操作系统：说一下进程和线程

进程和线程都是操作系统中的基本执行单元，但是它们之间有一些重要的区别。

进程 (Process) 是操作系统中正在运行的程序实例，每个进程都有自己的独立内存空间、系统资源和打开
的文件等。进程之间相互隔离，一个进程的崩溃不会影响其他进程的运行。进程之间可以通过系统调用
进行通信和协作。

线程 (Thread) 是进程中的一个执行单元，它与同一进程中的其他线程共享进程的内存空间和系统资源。
多个线程可以同时执行，它们之间相互协作，共享数据和资源。由于线程共享进程的内存空间，因此线
程之间的通信和同步比进程之间更加容易。

区别：

```
1. 内存空间：进程拥有独立的内存空间，而线程共享同一个进程的内存空间。
2. 资源占用：进程需要独立的系统资源来运行，如文件句柄、网络连接等，而线程可以共享这些资
源。
3. 通信方式：进程之间通信需要通过系统调用进行，而线程之间可以通过共享变量或者消息传递等方
式进行通信。
4. 创建和销毁开销：创建和销毁进程的开销比创建和销毁线程要大得多。
```
应用：

进程适用于需要独立运行、相互隔离的应用程序，如编译器、数据库管理系统等。在多核处理器上，使
用多个进程可以充分利用多核处理器的性能。

线程适用于需要频繁切换、共享资源的应用程序，如图形界面应用程序、网络应用程序等。在单核处理
器上，使用多个线程可以提高应用程序的并发性和响应速度。

```
AverageLoad= 6000 + 4 *4000/ 4 *10000= 55 %
```

###### 14 、说说进程通信方式

进程通信是操作系统提供的一种机制，使得多个进程之间可以交换信息和数据。以下是几种常见的进程
通信方式：

```
1. 共享内存：共享内存是最常见的进程通信方式之一。它允许两个或多个进程共享同一块内存，这样
它们就可以访问同一个数据。共享内存通常用于进程间通信，例如在同一个进程中的两个线程之间
共享数据。
2. 消息传递：消息传递是另一种进程通信方式，它允许进程之间交换消息。消息可以是任何类型的数
据，包括数字、字符串、结构体等。消息传递通常用于进程间通信，例如在操作系统中的进程调度
和同步中使用。
3. 共享文件：共享文件是一种特殊类型的共享内存，它允许两个或多个进程共享同一个文件。共享文
件通常用于文件传输和同步等操作。
4. 管道：管道是一种特殊类型的共享内存，它允许一个进程将数据写入管道，而另一个进程可以从管
道中读取数据。管道通常用于进程间通信，例如在命令行界面中使用管道来将命令和输出传递给其
他进程。
5. 信号量：信号量是一种特殊类型的变量，它允许一个进程在另一个进程中等待或响应。信号量通常
用于进程间通信，例如在操作系统中使用信号量来实现进程同步和调度。
```
这些是常见的进程通信方式，每种方式都有其优点和缺点，适用于不同的应用场景。

###### 15 、关于计算机网络：说一下 HTTP HTTPS

HTTP（超文本传输协议）和 HTTPS（安全超文本传输协议）都是使用 TCP/IP 协议进行通信的网络协
议。HTTP 是一种超文本标准协议，HTTPS 是安全的超文本标准协议。

特点：

```
HTTP 是一种明文协议，所有的数据包都会明文传输而可能会被黑客窃取。
HTTPS 是一种加密协议，使用公钥密码学技术来保证数据传输安全，即使数据被截获，也无法解
密。
HTTPS 还具有身份验证、数据加密、重定向等安全机制，确保用户的隐私和数据安全。
因此，HTTPS 被广泛用于需要传输敏感数据的网站。
```
应用：

```
HTTP 用于公共场所、非敏感信息的传输，允许数据直接传送，速度快，适用于小数据的传递。
HTTPS 用于需要传输敏感数据的网站，比如在线购物、银行支付等，它可以确保用户的隐私和数
据安全。
```
###### 16 、说说 HTTP 完整的请求过程

完整的 HTTP 请求过程包括以下几个步骤：


```
1. 客户端向服务器发送 HTTP 请求报文。
2. 服务器接收到请求报文后，对报文进行解析，根据报文中的方法（GET，POST 等）和请求的资源
（文件，数据等）来确定如何处理该请求。
3. 服务器向客户端发送响应报文，报文中包含服务器返回的数据和状态信息。
4. 客户端接收到响应报文后，解析响应报文中的数据和状态信息，根据响应确定是否成功获取了所需
的资源或者是否出现了错误。
```
需要注意的是，HTTP 请求和响应是通过 TCP 协议进行传输的，因此，在传输过程中需要进行三次握手建
立连接，同时需要进行数据的分片和确认，以确保数据的可靠传输。

HTTP (Hypertext Transfer Protocol) 是一种用于在 Web 浏览器和 Web 服务器之间传输数据的协议。
HTTP 请求过程可以分为以下几个步骤：

```
1. 建立 TCP 连接：客户端向服务器发送一个请求，服务器收到请求后会建立与客户端的 TCP 连接。
2. 发送请求头：客户端在建立 TCP 连接后会发送一个请求头 (Request Header), 其中包含了请求方
法、请求 URL、协议版本等信息。
3. 发送请求体：如果请求需要携带数据，则客户端会在请求头后面发送一个请求体 (Request
Body)。
4. 服务器响应头：服务器收到请求后会返回一个响应头 (Response Header), 其中包含了响应状态
码、协议版本等信息。
5. 发送响应体：服务器在返回响应头后会发送一个响应体 (Response Body), 其中包含了服务器返回的
数据。
6. 关闭连接：当客户端接收到服务器的响应后，会关闭 TCP 连接。
```
下面是一个简单的 HTTP 请求过程的示例：

假设有一个 Web 服务器在 IP 地址为 192.168.1.100 上运行，端口号为 80, 并且当前请求的 URL 为http://ww
w.example. com/index. html。

客户端使用浏览器向服务器发送一个 HTTP GET 请求，请求头部包含以下信息：

服务器收到请求后会根据请求头部中的信息进行相应的处理，然后返回一个 HTTP 响应给客户端。在这
个例子中，服务器可能会返回以下内容：

```
GET /index. html HTTP/1.1
Host: http://www.example.com
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win 64; x 64) AppleWebKit/537.36 (KHTML,
like Gecko) Chrome/58.0.3029.110 Safari/537.36
Accept:
text/html, application/xhtml+xml, application/xml; q=0.9, image/webp,*/*; q=0.8
Accept-Encoding: gzip, deflate, br
Accept-Language: en-US, en; q=0.8
Connection: keep-alive
Cookie: userid=12345; sessionid=67890
```
```
HTTP/1.1 200 OK
Date: Wed, 22 Oct 2021 10:30:00 GMT
Server: Apache/2.4.41 (Unix) OpenSSL/1.1.1 f CDH 11 x 86_64 GNU/Linux
Last-Modified: Tue, 21 Oct 2021 14:25:37 GMT
ETag: "e 6 d 7 cbe-f 7 b 8-4 a 9 f-b 7 c 8-e 7 a 9 fef 5 f 5 e 5"
Accept-Ranges: bytes
Content-Length: 32768
Connection: keep-alive
Content-Type: text/html; charset=UTF-8
Cache-Control: no-cache, no-store, must-revalidate
```

###### 17 、说说 http 报文请求行、请求头、请求正文

HTTP (Hypertext Transfer Protocol) 是一种用于在 Web 浏览器和 Web 服务器之间传输数据的协议。
HTTP 请求由三部分组成：请求行、请求头和请求正文。

**一、请求行：**

包含以下信息：

```
HTTP 方法 (Get、Post 等)
目标 URL
HTTP 版本号
```
例如，一个 GET 请求的请求行可能如下所示：

**二、请求头：**

请求头包含了一些元数据，用于描述客户端发送的请求。它包含以下字段：

```
Host: 目标服务器的主机名或 IP 地址。
User-Agent: 客户端的标识信息，通常包括浏览器类型和版本号。
Accept: 客户端可接受的内容类型列表。
Accept-Encoding: 客户端可以压缩的内容类型列表。
Accept-Language: 客户端可接受的语言类型列表。
Connection: 客户端与服务器之间的连接类型。常见的连接类型有 keep-alive 和 close。
```
```
Pragma: no-cache
Expires: -1
Set-Cookie: userid=12345; sessionid=67890; path=/; domain=www.example.com;
expires=Wed, 23 Oct 2021 10:30:00 GMT; secure; HttpOnly
X-Frame-Options: SAMEORIGIN
X-XSS-Protection: 1; mode=block
X-Powered-By: PHP/7.4.15 (Apache) with Suhosin-Patch for PHP 7.4. x and PHP API
v 2 on Apache+PHP 7.4.15 组合
```
```
<!DOCTYPE html> <html> <head> <title>Hello World</title> </head> <body>
<h1>Hello World!</h1> </body> </html>
```
```
GET /index. html HTTP/1.1
Host: http://www.example.com
User-Agent: Mozilla/5.0 (Windows NT 10.0; Win 64; x 64) AppleWebKit/537.36 (KHTML,
like Gecko) Chrome/58.0.3029.110 Safari/537.36
Accept:
text/html, application/xhtml+xml, application/xml; q=0.9, image/webp,*/*; q=0.8
Accept-Encoding: gzip, deflate, br
Accept-Language: en-US, en; q=0.8
Connection: keep-alive
Cookie: userid=12345; sessionid=67890
```

```
Cookie: 客户端发送给服务器的 Cookie 信息。
Referer: 客户端访问当前页面的前一个页面的 URL。
If-Modified-Since: 如果缓存未过期，则表示客户端希望从缓存中获取资源。
If-None-Match: 如果缓存未过期且资源没有被修改，则表示客户端希望使用缓存中的资源。
Content-Type: 客户端发送的数据的类型。常见的数据类型有 application/json、application/x-
www-form-urlencoded等。
Content-Length: 客户端发送的数据的长度。
```
例如，一个 POST 请求的请求头可能如下所示：

其中，Content-Type 指定了发送的数据类型为 JSON 格式，Content-Length 指定了发送的数据长度为 25
个字节。

**三、请求正文：**

请求正文是客户端发送的实际数据内容。对于 GET 请求来说，请求正文通常是一个 URL 参数；对于 POST
请求来说，请求正文是客户端发送的数据内容。

请求正文是 HTTP 报文的主体部分，用于描述请求的内容和请求的目标资源。请求正文通常包括以下内
容：

```
URI：包含请求资源的地址
Method：请求方法，例如 GET、POST、PUT 等
Header：请求头中包含的其他信息
Body：请求正文中包含的实际数据或请求参数
```
在 HTTP 报文中，请求行和请求正文是分开的，通过回车符或换行符分隔。HTTP 报文的格式如下：

其中，HTTP 版本和状态码表示请求是否成功，Date 表示请求发送的时间，Content-Type 和 Content-
Length 表示请求正文的类型和长度，Connection 表示连接方式。在请求正文中，JSON 格式的数据表示
请求参数。

###### 18 、说说 post 和 put 区别

HTTP 的 POST 和 PUT 方法都用于向服务器发送数据，但是它们的作用和使用方式有所不同。 POST
方法用于向服务器发送数据，并且数据会被附加到服务器端的请求正文中。当服务器端收到 POST 请求
时，它会将请求正文中的数据作为响应的主体部分返回给客户端。 PUT 方法用于向服务器发送数据，
并且数据会替换服务器端的现有资源。当服务器端收到 PUT 请求时，它会将请求中的数据作为请求正
文的一部分附加到服务器端的资源上。然后，服务器端会将资源的内容重新写入客户端请求的地址。下
面是一个简单的示例来说明 POST 和 PUT 方法的区别：

```
Content-Type: application/json
Content-Length: 25
{"name": "John", "age": 30 }
```
```
Copy codeHTTP/1.1 200 OK
Date: Wed, 25 Feb 2023 10:00:00 GMT
Content-Type: application/json
Content-Length: 123
Connection: keep-alive
```
```
Copy code// POST 方法
public void postData (String url, String data) {
```

在以上示例中，postData 方法使用 POST 方法向服务器发送数据，并且将数据附加到请求正文中。
putData 方法使用 PUT 方法向服务器发送数据，并且将数据替换服务器端的现有资源。

###### 19 、说一下 DNS 服务器解析原理

DNS (Domain Name System) 服务器是一种用于将域名解析为 IP 地址的计算机系统。当用户在浏览器中
输入一个网址时，浏览器会向本地 DNS 服务器发送一个查询请求，询问该网址对应的 IP 地址是什么。如
果本地 DNS 服务器没有缓存该网址对应的 IP 地址，它会向根 DNS 服务器发送一个查询请求，根 DNS 服务
器会继续向下查询，直到找到对应的权威 DNS 服务器或者直接返回查询结果。

下面是 DNS 服务器解析原理的具体步骤：

```
1. 用户在浏览器中输入一个网址，如www.example.com。
2. 浏览器向本地 DNS 服务器发送一个查询请求，请求包含以下信息：目标域名
(www.example.com)、查询类型 (A 记录或 MX 记录等)、查询方式 (默认为正向查询)。
3. 如果本地 DNS 服务器没有缓存目标域名对应的 IP 地址，它会向根 DNS 服务器发送一个查询请求，请
求包含目标域名、查询类型和查询方式等信息。
```
```
try {
URL obj = new URL (url);
HttpURLConnection con = (HttpURLConnection) obj.openConnection ();
con.setRequestMethod ("POST");
con.setRequestProperty ("Content-Type", "application/json");
con.setDoOutput (true);
```
```
OutputStream os = con.getOutputStream ();
os.write (data.getBytes ());
os.flush ();
os.close ();
con.getResponseCode (); // 执行 POST 请求
} catch (Exception e) {
e.printStackTrace ();
}
}
```
```
// PUT 方法
public void putData (String url, String data) {
try {
URL obj = new URL (url);
HttpURLConnection con = (HttpURLConnection) obj.openConnection ();
con.setRequestMethod ("PUT");
con.setRequestProperty ("Content-Type", "application/json");
con.setDoOutput (true);
```
```
OutputStream os = con.getOutputStream ();
os.write (data.getBytes ());
os.flush ();
os.close ();
con.getResponseCode (); // 执行 PUT 请求
} catch (Exception e) {
e.printStackTrace ();
}
}
```

```
4. 根 DNS 服务器收到查询请求后，会查找其缓存中是否已经存在目标域名对应的 IP 地址。如果存在，
则直接返回该 IP 地址给本地 DNS 服务器；如果不存在，则继续向下查询。
5. 根 DNS 服务器会继续向下查询，直到找到对应的权威 DNS 服务器或者直接返回查询结果。在向下
查询的过程中，可能会遇到多个权威 DNS 服务器，每个权威 DNS 服务器都会根据自己的缓存信息
来判断是否需要继续向下查询。
6. 当权威 DNS 服务器收到查询请求后，会查找其缓存中是否已经存在目标域名对应的 IP 地址。如果存
在，则直接返回该 IP 地址给本地 DNS 服务器；如果不存在，则继续向上查询。
7. 当权威 DNS 服务器找到目标域名对应的 IP 地址后，它会将该 IP 地址返回给本地 DNS 服务器。本地
DNS 服务器收到 IP 地址后，会将其缓存起来，并将该 IP 地址返回给浏览器。
8. 最后，浏览器收到本地 DNS 服务器返回的 IP 地址后，就会使用该 IP 地址来建立与目标网站的连接。
```
###### 20 、知道 ARP 欺骗吗？

ARP (Address Resolution Protocol) 协议是用于将一个 IP 地址映射到一个 MAC 地址的协议。ARP 欺骗是
一种网络攻击技术，攻击者通过发送伪造的 ARP 响应包来欺骗网络中的其他设备，使其认为攻击者的
MAC 地址和 IP 地址是合法的。

具体来说，ARP 欺骗可以分为以下两种类型：

```
1. 静态 ARP 欺骗：攻击者在网络中预先设置一个虚假的 ARP 响应包，使得网络中的其他设备误认为该
响应包是真实的。这样，当其他设备需要与攻击者通信时，它们会将自己的 MAC 地址和 IP 地址信
息发送给攻击者，从而被攻击者利用进行进一步的攻击。
2. 动态 ARP 欺骗：攻击者在网络中不断地发送伪造的 ARP 响应包，使得网络中的其他设备不断地更新
自己的 ARP 缓存表。这样，当其他设备需要与攻击者通信时，它们会再次发送 ARP 请求，而攻击者
则会发送伪造的 ARP 响应包，从而实现欺骗。
```
ARP 欺骗可以被用于多种攻击方式，例如中间人攻击、网络隔离等。为了防止 ARP 欺骗攻击，网络管理
员可以采取一些措施，例如定期更新 ARP 缓存表、限制 ARP 广播等。同时，用户也应该注意保护自己的
网络安全，避免点击来自陌生人或可疑网站的链接，以及使用安全的网络连接方式。

###### 21 、HTTP 一次请求响应时间过长，怎么分析和解决？

HTTP 一次请求响应时间过长可能是由多种原因引起的，下面是一些可能的分析和解决方法：

```
1. 网络延迟：可以通过 ping 命令或 traceroute 命令来检查网络延迟。如果网络延迟较高，可以考虑
更换网络服务提供商或使用 CDN 等技术来加速网络。
2. 服务器负载过高：可以通过监控服务器的 CPU、内存、磁盘等指标来判断服务器是否负载过高。
如果负载过高，可以考虑优化代码、增加服务器数量或使用负载均衡等技术来分散负载。
3. 数据库查询慢：可以通过检查数据库的慢查询日志来分析查询慢的原因。如果查询慢，可以考虑优
化数据库索引、优化查询语句或增加缓存等技术来提高查询效率。
4. 静态资源加载慢：可以通过使用浏览器的开发者工具来分析静态资源的加载时间。如果加载慢，可
以考虑使用 CDN 或优化静态资源的压缩、合并等技术来提高加载速度。
```

```
5. 程序逻辑复杂：如果程序逻辑过于复杂，可能会导致响应时间过长。可以通过简化程序逻辑、减少
数据库查询等方式来优化程序。
```
总之，要想解决 HTTP 一次请求响应时间过长的问题，需要全面分析问题，找出问题的根本原因，并采
取相应的解决方法。

###### 22 、编译原理还记得吗？说一下

编译原理是计算机科学中的一个重要分支，主要研究将高级语言翻译成机器语言的过程。编译器是实现
这一过程的工具，它将高级语言的源代码转换成目标代码，使计算机能够理解和执行。

编译器的主要工作包括词法分析、语法分析、语义分析、代码优化和代码生成等。词法分析器将源代码
转换成一个个的词法单元，语法分析器将这些词法单元组合成语法树，语义分析器则对语法树进行分
析，检查代码是否符合语义规则。代码优化器对代码进行优化，以提高程序的效率和性能。最后，代码
生成器将优化后的代码转换成目标代码，使计算机能够执行。

编译原理的研究对于理解计算机的工作原理、提高程序效率和开发高质量的编译器和解释器都具有重要
意义。

编译原理包括以下几个主要步骤：

```
1. 词法分析 (Lexical Analysis): 将源代码分解成一个个有意义的符号，例如关键字、标识符、运算符
等。
2. 语法分析 (Parsing): 将符号序列转化为语法树，即一棵表示源代码结构的树形结构。
3. 语义分析 (Semantic Analysis): 对语法树进行静态检查，确定程序是否符合语法规则和语义要求。
4. 中间代码生成 (Intermediate Code Generation): 将语法树转换为中间代码，中间代码是一种低级
形式的程序语言，接近于汇编语言。
5. 代码优化 (Optimization): 对中间代码进行优化，以提高生成的目标代码的性能。
6. 目标代码生成 (Target Code Generation): 将中间代码转换为目标代码，即计算机可以执行的机器语
言。
```
在实际编译过程中，通常会使用多种技术来实现这些步骤，例如正则表达式、递归下降解析器、语法分
析器、语义分析器、中间代码生成器、优化器等。同时，不同的编程语言也有其独特的编译原理和实现
方式。

###### 23 、说说语义语法分析

语义语法分析（Semantic Syntax Analysis，简称 SSA）是一种将代码分解为抽象语法树（Abstract
Syntax Tree，AST）的方法。它通过将代码分解为更小的、更基本的单元，使得代码更容易理解和优
化。

语义语法分析器通过以下步骤分析代码：


```
1. 词法分析：将源代码转换为一个个称为“标记”（token）的小部分，每个标记代表源代码中的一个
元素。
2. 语法分析：将标记转换为抽象语法树。抽象语法树表示源代码的结构，每个节点代表一个语法单
元，例如一个函数、表达式或声明。
3. 语义分析：对抽象语法树进行语义分析，将其转换为一个个抽象语义表达式（Abstract Syntax
Tree，AST）。AST 包含一个节点和一个“值”，节点表示节点的类型，而“值”则包含节点的值。
4. 优化：通过 AST 分析，可以对代码进行优化，例如去除冗余的节点或重构代码结构。
```
语义语法分析器在编译器和解释器中都很有用。在编译器中，语义语法分析器将源代码转换为 AST，然
后编译器可以根据 AST 来生成优化的代码。在解释器中，语义语法分析器可以将 AST 转换为代码，并将
代码解释为机器语言。

###### 24 、说说 JVM 内存模型

Java 虚拟机（Java Virtual Machine，简称 JVM）有三种内存模型：

```
1. 栈内存模型：此模型中，变量的值存储在栈中，函数调用时，参数和返回值会被压入或弹出栈。如
果有多个线程同时访问同一个变量，这些线程都会访问到同一个栈中的变量值。
2. 堆内存模型：此模型中，变量的值存储在堆中。当一个线程调用一个函数时，会在堆中分配一块内
存空间，该空间被用来存储函数中的变量值。函数调用结束后，这块内存空间可以被释放或重新分
配给其他对象。
3. 垃圾回收内存模型：此模型中，JVM 使用垃圾回收器来管理内存。当程序使用了一个对象之后，如
果不再需要它，就会被回收。JVM 会跟踪哪些对象正在被使用，哪些对象可以被回收。当对象不再
被使用时，JVM 会将其回收，以便为其他对象腾出空间。
```
JVM 的内存模型是由垃圾回收机制实现的。JVM 使用垃圾回收机制来解决内存分配和垃圾回收的问题，
从而支持多线程程序的并发执行。JVM 的垃圾回收机制可以分为标记清除、复制算法和标记整理等不同
的算法，不同的算法适用于不同的场景。

###### 25 、说说 JVM 垃圾回收算法

JVM（Java 虚拟机）垃圾回收算法主要分为以下几种：

```
1. 标记-清除算法（Mark-Sweep GC）：标记出所有需要回收的对象，然后清除所有被标记的对象所
占用的内存。标记-清除算法是最基本的垃圾回收算法，但是它会产生大量的内存碎片，碎片化的
内存会导致以后的内存分配效率降低。
2. 复制算法（Copy-on-Write GC）：将内存划分为两部分，每次只使用其中一部分。当一个对象需
要进行垃圾回收时，将对象复制到另一部分内存中，然后清除原来的内存。这样可以减少内存碎片
的产生，但是复制算法需要额外的开销来复制对象。
3. 标记-整理算法（Mark-Compact GC）：标记出所有需要回收的对象，然后将所有存活对象移动到
一端，清除另一端的内存。标记-整理算法既能减少内存碎片，又能减少复制对象的开销，但是它
需要一个较长的时间来进行垃圾回收。
4. G 1 算法（G 1 Garbage Collector）：G 1 算法是一种采用增量式垃圾回收的算法，与其他垃圾回
收算法不同的是，G 1 算法可以预测对象的生命周期，并且可以在对象被使用时进行垃圾回收，而
不是等到对象不再被使用时再进行回收。G 1 算法具有较好的性能和效率，是目前比较流行的垃圾
回收算法之一。
```

```
5. 其他垃圾回收算法：还有其他一些垃圾回收算法，如 EHCache、Tombstone 算法等，但是它们的
应用范围比较有限。
```
###### 26 、关于 redis，说一下 sorted set 底层原理

Redis 的 sorted set 是一种有序集合，它的底层实现是使用了跳跃表（Skip List）和哈希表（Hash
Table）这两种数据结构。跳跃表是一种类似于链表的数据结构，但是它在每个节点上增加了多个指
针，可以快速地跳过一些节点，从而提高了查找效率。而哈希表则是一种以键值对形式存储数据的数据
结构，可以快速地进行数据的插入、查找和删除操作。

在 Redis 的 sorted set 中，每个元素都有一个分数（score），根据分数的大小来进行排序。使用跳跃
表可以快速地进行分数的比较和排序，而使用哈希表可以快速地进行元素的查找和删除操作。同时，
Redis 还使用了压缩列表（Ziplist）来优化存储空间，对于一些小的 sorted set，它们的元素可以被存
储在一个压缩列表中，从而减少了内存的使用。

sorted set 底层的原理如下：

```
1. 哈希表：每个 sorted set 对象都由一个哈希表和一个分数 (score) 组成。哈希表用于存储成员的分
值和成员的散列值 (member), 分数用于对成员进行排序。
2. 分数计算：sorted set 中的每个成员都有一个分数，该分数是根据其散列值和一个权重因子计算出
来的。权重因子是一个介于 0 到 100 之间的整数，用于调整不同成员的分值大小。
3. 成员添加和删除：当向 sorted set 中添加或删除成员时，Redis 首先会根据其散列值计算出新的分
数，然后将新分数与旧分数进行比较，如果新分数大于旧分数，则更新哈希表中的对应项。
4. 范围查询：sorted set 支持范围查询，即可以根据分数范围查找成员。当执行范围查询时，Redis
首先会计算出最小分值和最大分值之间的所有成员的分数范围，然后遍历哈希表，找到所有分数在
该范围内的成员。
5. 迭代器：sorted set 支持迭代器，可以通过迭代器遍历 sorted set 中的所有成员。迭代器返回每
个成员的散列值和分值，但不返回成员本身。
```
总之，sorted set 底层的原理是基于哈希表和分数计算实现的，它支持添加、删除、范围查询和迭代等
操作。由于 sorted set 可以快速地进行范围查询和排序操作，因此在实际应用中被广泛使用。

###### 27 、说说 redis 持久化

Redis 持久化是指将 Redis 中的数据保存到磁盘上，以便在服务器重启或宕机时能够恢复数据。Redis
支持两种持久化方式：RDB (Redis Database) 快照和 AOF (Append-Only File) 日志。

```
1. RDB 持久化：RDB 持久化是将 Redis 内存中的数据集快照写入磁盘中，可以设置不同的快照间隔
时间和压缩选项。RDB 持久化的优点是可以将快照保存到磁盘中，占用较少的磁盘空间，并且可
以快速恢复数据。缺点是如果在备份过程中发生宕机，可能会丢失一部分数据。
2. AOF 持久化：AOF 持久化是将 Redis 执行的所有写操作记录到一个日志文件中，可以在服务器重
启时重新执行日志文件中的操作来恢复数据。AOF 持久化的优点是可以保证数据的完整性和可靠
性，因为每个写操作都会被记录下来。缺点是相对于 RDB 持久化，AOF 持久化需要更多的磁盘空
间，并且在恢复数据时可能会比 RDB 持久化慢一些。
```

除了以上两种持久化方式外，Redis 还支持主从复制功能，可以将多个 Redis 实例复制到不同的节点
上，以实现数据的备份和负载均衡。

总之，Redis 持久化是将 Redis 中的数据保存到磁盘上，以便在服务器重启或宕机时能够恢复数据。
Redis 支持 RDB 和 AOF 两种持久化方式，可以根据实际需求选择合适的方式进行配置。

###### 28 、TB 级别的日志文件中存储词汇，找出出现频率最高的十个

对于 TB 级别的日志文件，如果想要找出出现频率最高的十个词汇，可以考虑使用 MapReduce 框架来实
现。

具体实现可以分为以下几个步骤：

```
1. 将日志文件分割成小文件，每个小文件大小不超过 HDFS 的块大小。
2. 使用 MapReduce 框架，将每个小文件中的词汇进行统计，并将统计结果输出为键值对（key-
value）形式，其中键为词汇，值为该词汇出现的次数。
3. 将所有小文件的统计结果进行合并，即将相同键的值进行累加，得到所有词汇的出现次数。
4. 对所有词汇的出现次数进行排序，取出出现频率最高的前十个词汇即可。
```
以下是使用 Java 实现的示例代码：

```
import java. io. IOException;
import java. util. StringTokenizer;
import java. util. TreeMap;
import org. apache. hadoop. conf. Configuration;
import org. apache. hadoop. fs. Path;
import org. apache. hadoop. io. IntWritable;
import org. apache. hadoop. io. LongWritable;
import org. apache. hadoop. io. Text;
import org. apache. hadoop. mapreduce. Job;
import org. apache. hadoop. mapreduce. Mapper;
import org. apache. hadoop. mapreduce. Reducer;
import org. apache. hadoop. mapreduce. lib. input. FileInputFormat;
import org. apache. hadoop. mapreduce. lib. output. FileOutputFormat;
```
```
public class TopTenWords {
public static class WordCountMapper extends Mapper<LongWritable, Text, Text,
IntWritable> {
private final static IntWritable one = new IntWritable ( 1 );
private Text word = new Text ();
```
```
public void map (LongWritable key, Text value, Context context) throws
IOException, InterruptedException {
StringTokenizer itr = new StringTokenizer (value.toString ());
while (itr.hasMoreTokens ()) {
word.set (itr.nextToken ());
context.write (word, one);
}
}
```

在这个示例代码中，我们定义了一个 WordCountMapper 类和一个 WordCountReducer 类，用于实现
Map 和 Reduce 操作。其中，WordCountMapper 类将输入的文本文件按照空格进行分割，对每个词汇进
行计数，并输出为键值对形式。WordCountReducer 类将相同键的值进行累加，并将结果存储在一个
TreeMap 中，最后输出出现频率最高的前十个词汇。

在 main 函数中，我们定义了一个 Job 对象，设置输入和输出路径，并启动 MapReduce 任务。

注意，在实际应用中，还需要根据具体情况进行一些优化，例如设置 Combiner、使用压缩等。

###### 29 、说说一致性哈希算法

```
}
```
```
public static class WordCountReducer extends Reducer<Text, IntWritable,
Text, IntWritable> {
private TreeMap<Integer, String> topTenWords = new TreeMap<Integer,
String>();
```
```
public void reduce (Text key, Iterable<IntWritable> values, Context
context) throws IOException, InterruptedException {
int sum = 0 ;
for (IntWritable val : values) {
sum += val.get ();
}
topTenWords.put (sum, key.toString ());
if (topTenWords.size () > 10 ) {
topTenWords.remove (topTenWords.firstKey ());
}
}
```
```
protected void cleanup (Context context) throws IOException,
InterruptedException {
for (Integer count : topTenWords.descendingKeySet ()) {
context.write (new Text (topTenWords.get (count)), new
IntWritable (count));
}
}
}
```
```
public static void main (String[] args) throws Exception {
Configuration conf = new Configuration ();
Job job = Job.getInstance (conf, "top ten words");
job.setJarByClass (TopTenWords. class);
job.setMapperClass (WordCountMapper. class);
job.setReducerClass (WordCountReducer. class);
job.setOutputKeyClass (Text. class);
job.setOutputValueClass (IntWritable. class);
FileInputFormat.addInputPath (job, new Path (args[ 0 ]));
FileOutputFormat.setOutputPath (job, new Path (args[ 1 ]));
System.exit (job.waitForCompletion (true)? 0 : 1 );
}
}
```

在分布式应用中，应该来说使用到 hash 最多的地方就是 rpc 负载均衡和分库分表，通常对于正式意义上
的分布式应用来说，扩容和收缩是一个半自动化的过程，在此期间，应用基本上是可用的，所以不能发
生大规模动荡的意外，为了最小化潜在的影响，一致性 hash 算法就扮演了极为重要的角色。

consistent hashing 早在 1997 年就在论文 **Consistent hashing and random trees** 中被提出，目前
在 cache 系统中应用越来越广泛；

**一、基本场景**

比如你有 N 个 cache 服务器（后面简称 cache ），那么如何将一个对象 object 映射到 N 个 cache 上
呢，你很可能会采用类似下面的通用方法计算 object 的 hash 值，然后均匀的映射到到 N 个 cache ；

hash (object)%N

一切都运行正常，再考虑如下的两种情况；

1 一个 cache 服务器 m down 掉了（在实际应用中必须要考虑这种情况），这样所有映射到 cache m
的对象都会失效，怎么办，需要把 cache m 从 cache 中移除，这时候 cache 是 N-1 台，映射公式变成
了 hash (object)%(N-1) ；

2 由于访问加重，需要添加 cache ，这时候 cache 是 N+1 台，映射公式变成了 hash (object)%(N+1) ；

1 和 2 意味着什么？这意味着突然之间几乎所有的 cache 都失效了。对于服务器而言，这是一场灾难，
洪水般的访问都会直接冲向后台服务器；

再来考虑第三个问题，由于硬件能力越来越强，你可能想让后面添加的节点多做点活，显然上面的
hash 算法也做不到。

有什么方法可以改变这个状况呢，这就是 consistent hashing...

**二、hash 算法和单调性**

Hash 算法的一个衡量指标是单调性（ Monotonicity ），定义如下：

单调性是指如果已经有一些内容通过哈希分派到了相应的缓冲中，又有新的缓冲加入到系统中。哈希的
结果应能够保证原有已分配的内容可以被映射到新的缓冲中去，而不会被映射到旧的缓冲集合中的其他
缓冲区。

容易看到，上面的简单 hash 算法 hash (object)%N 难以满足单调性要求。

**三、consistent hashing 算法的原理**

consistent hashing 是一种 hash 算法，简单的说，在移除 / 添加一个 cache 时，它能够尽可能小的改
变已存在 key 映射关系，尽可能的满足单调性的要求。

下面就来按照 5 个步骤简单讲讲 consistent hashing 算法的基本原理。

**3.1 环形 hash 空间**

考虑通常的 hash 算法都是将 value 映射到一个 32 为的 key 值，也即是 0~2^32-1 次方的数值空间；
我们可以将这个空间想象成一个首（ 0 ）尾（ 2^32-1 ）相接的圆环，如下面图 1 所示的那样。


图 1 环形 hash 空间

**3.2 把对象映射到 hash 空间**

接下来考虑 4 个对象 object 1~object 4 ，通过 hash 函数计算出的 hash 值 key 在环上的分布如图 2 所
示。

hash (object 1) = key 1;

... ...

hash (object 4) = key 4;

图 2 4 个对象的 key 值分布

**3.3 把 cache 映射到 hash 空间**

Consistent hashing 的基本思想就是将对象和 cache 都映射到同一个 hash 数值空间中，并且使用相同
的 hash 算法。

假设当前有 A, B 和 C 共 3 台 cache ，那么其映射结果将如图 3 所示，他们在 hash 空间中，以对应的
hash 值排列。

hash (cache A) = key A;

... ...

hash (cache C) = key C;

图 3 cache 和对象的 key 值分布


说到这里，顺便提一下 cache 的 hash 计算，一般的方法可以使用 cache 机器的 IP 地址或者机器名作
为 hash 输入。

**3.4 把对象映射到 cache**

现在 cache 和对象都已经通过同一个 hash 算法映射到 hash 数值空间中了，接下来要考虑的就是如何
将对象映射到 cache 上面了。

在这个环形空间中，如果沿着顺时针方向从对象的 key 值出发，直到遇见一个 cache ，那么就将该对象
存储在这个 cache 上，因为对象和 cache 的 hash 值是固定的，因此这个 cache 必然是唯一和确定
的。这样不就找到了对象和 cache 的映射方法了吗？！

依然继续上面的例子（参见图 3 ），那么根据上面的方法，对象 object 1 将被存储到 cache A 上；
object 2 和 object 3 对应到 cache C ； object 4 对应到 cache B ；

**3.5 考察 cache 的变动**

前面讲过，通过 hash 然后求余的方法带来的最大问题就在于不能满足单调性，当 cache 有所变动时，
cache 会失效，进而对后台服务器造成巨大的冲击，现在就来分析分析 consistent hashing 算法。

**3.5.1 移除 cache**

考虑假设 cache B 挂掉了，根据上面讲到的映射方法，这时受影响的将仅是那些沿 cache B 逆时针遍历
直到下一个 cache （ cache C ）之间的对象，也即是本来映射到 cache B 上的那些对象。

因此这里仅需要变动对象 object 4 ，将其重新映射到 cache C 上即可；参见图 4 。

图 4 Cache B 被移除后的 cache 映射

**3.5.2 添加 cache**

再考虑添加一台新的 cache D 的情况，假设在这个环形 hash 空间中， cache D 被映射在对象 object 2
和 object 3 之间。这时受影响的将仅是那些沿 cache D 逆时针遍历直到下一个 cache （ cache B ）之间
的对象（它们是也本来映射到 cache C 上对象的一部分），将这些对象重新映射到 cache D 上即可。

因此这里仅需要变动对象 object 2 ，将其重新映射到 cache D 上；参见图 5 。


图 5 添加 cache D 后的映射关系

**四、虚拟节点**

考量 Hash 算法的另一个指标是平衡性 (Balance) ，定义如下：

平衡性是指哈希的结果能够尽可能分布到所有的缓冲中去，这样可以使得所有的缓冲空间都得到利用。

hash 算法并不是保证绝对的平衡，如果 cache 较少的话，对象并不能被均匀的映射到 cache 上，比如
在上面的例子中，仅部署 cache A 和 cache C 的情况下，在 4 个对象中， cache A 仅存储了 object 1
，而 cache C 则存储了 object 2 、 object 3 和 object 4 ；分布是很不均衡的。

为了解决这种情况， consistent hashing 引入了“虚拟节点”的概念，它可以如下定义：

“虚拟节点”（ virtual node ）是实际节点在 hash 空间的复制品（ replica ），一实际个节点对应了若干
个“虚拟节点”，这个对应个数也成为“复制个数”，“虚拟节点”在 hash 空间中以 hash 值排列。

仍以仅部署 cache A 和 cache C 的情况为例，在图 4 中我们已经看到， cache 分布并不均匀。现在我
们引入虚拟节点，并设置“复制个数”为 2 ，这就意味着一共会存在 4 个“虚拟节点”， cache A 1, cache
A 2 代表了 cache A ； cache C 1, cache C 2 代表了 cache C ；假设一种比较理想的情况，参见图 6 。

图 6 引入“虚拟节点”后的映射关系

此时，对象到“虚拟节点”的映射关系为：


objec 1->cache A 2 ； objec 2->cache A 1 ； objec 3->cache C 1 ； objec 4->cache C 2 ；

因此对象 object 1 和 object 2 都被映射到了 cache A 上，而 object 3 和 object 4 映射到了 cache C 上；
平衡性有了很大提高。

引入“虚拟节点”后，映射关系就从 { 对象 -> 节点 } 转换到了 { 对象 -> 虚拟节点 } 。查询物体所在 cache
时的映射关系如图 7 所示。

图 7 查询对象所在 cache

“虚拟节点”的 hash 计算可以采用对应节点的 IP 地址加数字后缀的方式。

例如假设 cache A 的 IP 地址为 202.168.14.241 。

引入“虚拟节点”前，计算 cache A 的 hash 值：

引入“虚拟节点”后，计算“虚拟节”点 cache A 1 和 cache A 2 的 hash 值：

###### 30 、说说多模匹配算法

多模匹配算法 (Multi-Mode Matching Algorithm) 是一种用于在多个模式中查找匹配项的算法。它的基
本思想是将每个模式看作一个独立的搜索空间，然后在这些搜索空间中进行匹配。

多模匹配算法通常包括以下几个步骤：

```
1. 初始化：将所有模式中的字符按照其出现的位置进行标记，并将其对应的位置存储在一个二维数组
中。
2. 第一阶段匹配：在第一个模式中，从左到右依次扫描每个字符，并在第二个模式中查找与之匹配的
字符。如果找到了匹配项，则将其位置记录下来。
```
```
Hash (“202.168.14.241”);
```
```
Hash (“202.168.14. 241 #1 ”); // cache A 1
```
```
Hash (“202.168.14. 241 #2 ”); // cache A 2
```

```
3. 第二阶段匹配：在第一个模式中，从上到下依次扫描每个字符，并在第二个模式中查找与之匹配的
字符。如果找到了匹配项，则将其位置记录下来。
4. 第三阶段匹配：在第一个模式中，从右到左依次扫描每个字符，并在第二个模式中查找与之匹配的
字符。如果找到了匹配项，则将其位置记录下来。
5. 第四阶段匹配：在第一个模式中，从下到上依次扫描每个字符，并在第二个模式中查找与之匹配的
字符。如果找到了匹配项，则将其位置记录下来。
6. 最终匹配：根据记录下来的匹配项位置，在两个模式中找到所有的匹配项，并将它们输出。
```
多模匹配算法的优点是可以处理多个模式之间的匹配问题，并且可以在不同模式之间进行灵活的选择和
组合。缺点是它的时间复杂度较高，因为需要对每个模式进行多次扫描和匹配。此外，由于它需要记录
每个模式中字符的位置信息，因此需要较大的内存空间来存储这些信息。

###### 31 、了解 web 容器吗？JBOSS、tomcat

Web 容器是一种用于部署和运行 Web 应用程序的软件。它负责将应用程序的代码和资源打包成一个可执
行的、可扩展的和安全的单元。 JBOSS 是一个流行的 Web 容器，基于 Java EE，它可以运行在不同的操
作系统上，如 Linux、Windows 和 Solaris。它提供了许多功能，包括：

```
部署和管理应用程序
负载均衡
认证和授权
缓存和反向代理
安全性
日志和监控
```
JBOSS 通常用于部署 Java EE 应用程序，如 Web 应用程序和 EJB 应用程序。 Tomcat 是另一个流行的 Web
容器，也基于 Java EE。它可以运行在不同的操作系统上，如 Linux、Windows 和 Solaris。它提供了许多
功能，包括：

```
部署和管理应用程序
负载均衡
认证和授权
缓存和反向代理
安全性
日志和监控
```
Tomcat 通常用于部署 Java EE 应用程序，如 Web 应用程序和 EJB 应用程序。它是一个开源软件，可以免费
使用和自由修改。

#### 二面总结

问题不多，也就 30 道题目，都是硬核题目

小伙伴的很多也没有回答那么完美，大概就是一小时

侥幸的是，二面竟然也通过啦


#### 三面（52 min）

###### 1 、说一下 spring 3 优点、缺点

Spring 是一个开源的 Java 企业应用开发框架，它提供了丰富的功能和组件，可以帮助开发人员快速构建
高质量的企业级应用程序。Spring 3 是 Spring 框架的最新版本之一，它继承了 Spring 2 的优点，并增加了
一些新的特性和改进。

Spring 3 的优点包括：

```
1. 更加灵活的配置方式：Spring 3 引入了基于注解的配置方式，使得配置文件更加简洁、易于维护。
同时，Spring 3 还支持基于 XML 的配置方式，可以满足不同开发需求。
2. 更加模块化的设计：Spring 3 将框架划分为多个模块，每个模块都有自己的职责和功能。这种模块
化的设计使得 Spring 3 更加灵活和可扩展，可以根据不同的需求选择相应的模块进行集成。
3. 更加完善的 AOP 支持：Spring 3 对 AOP 的支持更加完善，提供了更加灵活的 AOP 实现方式，并且支
持自定义切面和通知。
4. 更加强大的数据访问能力：Spring 3 提供了更加强大和灵活的数据访问技术，包括 JDBC、ORM 框
架、NoSQL 等，可以帮助开发人员更加高效地访问数据。
5. 更加安全的认证机制：Spring 3 引入了基于角色的访问控制 (Role-Based Access Control) 和基于表
单的认证 (Form-Based Authentication) 等新的认证机制，可以帮助开发人员更好地保护应用程序
的安全。
```
Spring 3 的缺点包括：

```
1. 学习曲线较陡峭：由于 Spring 3 引入了许多新的特性和概念，因此需要较长时间的学习成本来掌握
其使用方法和原理。
2. 需要更多的内存和 CPU 资源：由于 Spring 3 的功能和复杂性，它需要更多的内存和 CPU 资源来运
行，这可能会导致应用程序的性能问题。
```
###### 2 、说说 struts 2 和 springMVC 原理，区别

Struts 2 和 Spring MVC 都是常见的 Java Web 框架，它们都提供了丰富的功能和组件，可以帮助开发人员
快速构建高质量的 Web 应用程序。

Struts 2 的原理：

Struts 2 是一个基于 MVC (Model-View-Controller) 设计模式的 Web 框架，它将请求分为三个部分：模
型、视图和控制器。其中，模型表示客户端发送的数据，视图表示用户界面，控制器负责处理请求并将
数据传递给相应的视图进行渲染。Struts 2 还提供了拦截器机制，可以在请求到达控制器之前对其进行
拦截和处理，从而实现更加灵活的功能扩展。

Spring MVC 的原理：


Spring MVC 是一个基于 MVC 设计模式的 Web 框架，它将请求分为五个部分：控制器、模型、视图、处
理器和视图解析器。其中，控制器负责处理请求并将数据传递给相应的模型进行处理，模型表示业务数
据，视图表示用户界面，处理器负责对模型和视图进行处理，视图解析器负责将处理器返回的结果转换
为最终的视图。Spring MVC 还提供了拦截器机制，可以在请求到达控制器之前对其进行拦截和处理，
从而实现更加灵活的功能扩展。

区别：

```
1. 设计理念不同：Struts 2 是基于 MVC 设计模式的 Web 框架，而 Spring MVC 则是基于 MVC、AOP 和
IOC (Inversion of Control) 设计模式的 Web 框架。
2. 工作流程不同：在 Struts 2 中，请求会先经过拦截器进行处理，然后再由 Action 处理请求；而在
Spring MVC 中，请求会先由 DispatcherServlet 接收，然后再由 HandlerMapping 找到对应的
Controller 处理请求。
3. 配置方式不同：在 Struts 2 中，配置文件通常以. xml 或. properties 格式存在；而在 Spring MVC
中，配置文件通常以. xml 或. java 格式存在。
4. 功能扩展方式不同：在 Struts 2 中，可以通过编写 Interceptor 来扩展功能；而在 Spring MVC 中，可
以通过编写 HandlerInterceptor 或者 ControllerAdvice 来扩展功能。
```
###### 3 、说一下 memcache、redis 和 mongoDB

Memcached、Redis 和 MongoDB 都是常用的 NoSQL 数据库，但它们的特点、区别和应用场景有所
不同。

```
1. Memcached
```
Memcached 是一种高性能的分布式内存对象缓存系统，主要用于减轻数据库的负载。它的特点包括：

```
简单：Memcached 只支持键值存储，没有复杂的数据结构。
高性能：Memcached 的读写性能非常高，可以轻松处理高并发请求。
分布式：Memcached 支持分布式部署，可以通过添加节点来扩展性能。
不支持持久化：Memcached 不支持数据持久化，数据只存在于内存中。
```
应用场景：Memcached 适用于需要高速缓存的场景，如 Web 应用程序中的会话管理、页面缓存等。

```
2. Redis
```
Redis 是一种高性能的键值存储系统，支持多种数据结构，包括字符串、哈希、列表、集合、有序集合
等。它的特点包括：

```
多种数据结构：Redis 支持多种数据结构，可以满足不同的应用需求。
数据持久化：Redis 支持数据持久化，可以将内存中的数据异步地写入磁盘，以保证数据的可靠
性。
支持事务：Redis 支持事务，可以将多个命令封装成一个事务进行执行，保证数据的一致性。
支持分布式：Redis 支持分布式部署，可以通过添加节点来扩展性能。
```
应用场景：Redis 适用于需要高速缓存和数据存储的场景，如 Web 应用程序中的会话管理、页面缓
存、消息队列等。

```
3. MongoDB
```
MongoDB 是一种面向文档的 NoSQL 数据库，它采用了类似于 JSON 的文档格式来存储数据。它的特
点包括：

```
面向文档：MongoDB 是一种面向文档的数据库，每个文档可以包含不同的字段，非常灵活。
```

```
支持复杂查询：MongoDB 支持复杂的查询和聚合操作，可以方便地进行数据分析。
支持分布式：MongoDB 支持分布式部署，可以通过添加节点来扩展性能。
不支持事务：MongoDB 不支持事务，不能保证数据的一致性。
```
应用场景：MongoDB 适用于需要存储大量非结构化数据的场景，如 Web 应用程序中的日志、用户行
为数据等。

###### 4 、对比一下 memcache、redis

Memcache 和 Redis 都是流行的高性能、高可用性的内存缓存系统，它们都提供了多种数据结构和操作
模式，可以满足不同场景下的需求。下面是它们的一些对比：

```
1. 数据类型：Memcache 支持键值对 (key-value) 存储，而 Redis 支持更多的数据类型，包括字符串、
哈希表、列表、集合等。
2. 性能：Memcache 的性能比 Redis 略高，因为它使用单线程模型和简单的内存结构。但是，Redis
通过使用多线程模型和更复杂的数据结构来提高性能。
3. 可靠性：Memcache 具有较高的可靠性，因为它是基于内存的，并且支持持久化存储。Redis 也具
有较高的可靠性，但是需要进行数据备份和恢复操作。
4. 扩展性：Redis 具有更好的扩展性，因为它可以通过集群部署方式来扩展节点数量，从而提高性能
和容错能力。Memcache 不支持集群部署，只能通过增加服务器数量来扩展。
5. 功能：Redis 提供了更多的功能，例如发布订阅、Lua 脚本支持等，而 Memcache 则相对较简单。
```
总之，Memcache 适合于简单的缓存场景，而 Redis 则适合于更复杂的应用场景，例如实时消息传递、
排行榜等。选择哪种缓存系统取决于具体的需求和场景。

###### 5 、说说 memcached 默认过期时间

Memcached 是一种内存缓存系统，它可以缓存各种类型的数据，如字符串、对象、图像等。在
Memcached 中，每个缓存条目都有一个过期时间，一旦过期时间到了，该条目就会自动从缓存中删
除。

Memcached 的默认过期时间是 0 ，即永不过期。这意味着，如果你没有显式地设置过期时间，那么缓存
的条目将会一直存在，直到你手动删除它们或者 Memcached 的内存空间被占满。

当然，你也可以通过设置过期时间来控制缓存的生命周期。在 Memcached 中，可以通过向 set () 方法传
递第三个参数来设置过期时间，例如：

在上面的例子中，缓存的过期时间为 3600 秒，即 1 小时。当 1 小时过去后，该条目就会自动从缓存中删
除。

需要注意的是，Memcached 的过期时间只是一个估计值，它并不是绝对准确的。如果你的缓存系统非
常繁忙，那么可能会出现过期时间延迟的情况。因此，在设计缓存系统时，需要合理设置过期时间，避
免出现过期时间延迟导致的缓存不一致问题。

```
set ('key', 'value', 3600) # 将 key-value 对缓存 1 小时
```

###### 6 、说说 redis 数据结构

Redis 支持多种数据结构，包括：

```
1. 字符串 (String)：Redis 的最基本的数据结构，可以存储字符串、整数或者浮点数。
2. 列表 (List)：Redis 的列表是一个双向链表，可以在头部或尾部添加或删除元素，支持各种操作，如
范围查询、插入、删除等。
3. 集合 (Set)：Redis 的集合是无序的字符串集合，可以进行交集、并集、差集等操作。
4. 有序集合 (ZSet)：Redis 的有序集合是在集合的基础上增加了一个权重值，可以根据权重值进行排
序，支持各种操作，如范围查询、插入、删除等。
5. 哈希 (Hash)：Redis 的哈希是一个键值对集合，可以储存多个键值对，支持各种操作，如添加、删
除、查找等。
```
除了这些基本的数据结构，Redis 还支持一些高级数据结构，如：

```
1. 布隆过滤器 (Bloom Filter)：一种概率型数据结构，可以快速判断一个元素是否存在于一个集合
中，可以用于快速判断一个 URL 是否已经被爬取过，或者一个邮箱地址是否已经被注册过。
2. HyperLogLog：一种基数算法，可以用于快速统计一个集合中元素的数量，如统计一个网站的独
立访客数量。
3. 地理位置 (Geo)：可以储存地理位置信息，支持各种操作，如查询两个位置之间的距离、查询某个
位置周围的其他位置等。
```
总之，Redis 提供了丰富的数据结构，可以满足各种不同的应用场景。

###### 7 、说说全量复制和增量复制

全量复制和增量复制是数据备份和恢复中的两个重要概念。

全量复制指的是将所有数据从一个数据库实例复制到另一个数据库实例中，包括所有的数据、结构和配
置信息等。这种方式适用于需要完全一致的数据备份和恢复的情况，比如在进行数据库迁移或者数据库
重建时。但是，全量复制的缺点是数据量大、复制时间长，而且对于源数据库和目标数据库之间的差异
处理比较困难。

增量复制指的是只复制源数据库中发生变化的数据到目标数据库中。这种方式适用于只需要部分数据备
份和恢复的情况，比如在进行数据库更新或者数据同步时。增量复制的优点是速度快、效率高、成本
低，而且对于源数据库和目标数据库之间的差异处理比较容易。

总之，全量复制和增量复制都有各自的优缺点，具体使用哪种方式取决于具体的应用场景和需求。

###### 8 、说一下 mongoDB


MongoDB 是一种 NoSQL 数据库，它采用文档存储方式，支持动态查询和索引。下面是 MongoDB 的特
性、优缺点和应用。

特性：

```
1. 支持动态查询和索引：MongoDB 使用 BSON（Binary JSON）格式存储数据，支持动态查询和索
引，可以快速查询和分析数据。
2. 支持复制和故障转移：MongoDB 支持复制和故障转移，可以保证数据的高可用性和可靠性。
3. 支持分片：MongoDB 支持自动分片，可以扩展到大规模数据集。
4. 支持 MapReduce：MongoDB 支持 MapReduce，可以进行复杂的数据分析和聚合。
5. 支持全文搜索：MongoDB 支持全文搜索，可以对文本进行高效的搜索和分析。
```
优点：

```
1. 高性能：MongoDB 采用内存映射和预分配空间等技术，可以实现高性能的读写操作。
2. 易于扩展：MongoDB 支持自动分片和复制，可以方便地进行扩展。
3. 灵活性：MongoDB 采用文档存储方式，可以方便地存储结构不固定的数据。
4. 易于使用：MongoDB 使用简单，支持多种编程语言和平台。
```
缺点：

```
1. 不支持事务：MongoDB 不支持多文档事务，只支持单文档事务。
2. 存储空间占用较大：MongoDB 采用 BSON 格式存储数据，存储空间占用较大。
3. 不支持复杂查询：MongoDB 不支持复杂查询，如多表连接等。
```
应用：

```
1. Web 应用：MongoDB 可以用于 Web 应用的数据存储和查询。
2. 大数据分析：MongoDB 支持 MapReduce，可以用于大数据分析。
3. 日志处理：MongoDB 可以用于日志处理和分析。
4. 移动应用：MongoDB 可以用于移动应用的数据存储和查询。
```
总的来说，MongoDB 是一种高性能、易扩展、灵活性强的 NoSQL 数据库，适用于多种应用场景。

###### 9 、说一下 mongoDB 和 redis、memcached 区别，和 mysql 区

###### 别

MongoDB、Redis 和 Memcached 都是非关系型数据库，而 MySQL 是一种关系型数据库。它们有以下区
别：

```
1. 数据模型：MongoDB 采用文档模型，支持嵌套文档和数组类型；Redis 采用键值对模型，支持多
种数据结构；Memcached 采用键值对模型，支持缓存存储。MySQL 采用表模型，支持表格的关联
操作。
2. 数据分布方式：MongoDB 采用分布式架构，可以将数据分布在多个服务器上；Redis 和
Memcached 也可以进行分布式部署，但通常只使用一台服务器。MySQL 通常在单台服务器上运
行。
3. 查询语言：MongoDB 使用自己的查询语言 (类似于 JSON), 支持复杂的查询操作；Redis 使用基于命
令的查询语言 (类似于 Lua), 支持快速的数据访问；Memcached 使用简单的键值查询语言 (类似于 C
语言), 适合处理大量简单数据。
4. 扩展性：MongoDB 和 Redis 都具有很好的扩展性，可以轻松地增加节点以提高性能和容错能力；
Memcached 也可以进行扩展，但不如 MongoDB 和 Redis 那么容易。MySQL 可以通过主从复制和
```

```
分库分表等方式进行扩展。
5. 事务支持：MongoDB 不支持原生的事务处理，需要通过第三方库或框架来实现；Redis 和
Memcached 都不支持事务处理。MySQL 支持原生的事务处理。
```
总之，MongoDB、Redis 和 Memcached 都是非常流行的非关系型数据库，适用于不同的应用场景。如
果您需要存储半结构化或非结构化数据，并且需要高可扩展性和高性能，那么 MongoDB 是一个不错的
选择。如果您需要快速访问缓存数据，并且需要支持多种数据结构，那么 Redis 是一个不错的选择。如
果您需要将数据缓存到内存中，并且需要支持多种数据结构，那么 Memcached 是一个不错的选择。如
果您需要处理关系型数据，并且需要高可用性和高性能，那么 MySQL 是一个不错的选择。

###### 10 、说一下 myisam 和 innodb

MyISAM 和 InnoDB 是两种常见的数据库存储引擎，它们都是基于表的存储结构。

```
1. MyISAM
```
MyISAM 是一种简单的存储引擎，它以表为单位进行数据存储和管理。在 MyISAM 中，每个表都有一
个独立的文件，其中包含了表中的数据和索引信息。MyISAM 支持全文搜索、压缩和分区等功能，适用
于读操作较多的应用场景。但是，由于 MyISAM 不支持事务处理和外键约束等高级功能，因此在高并
发、高可靠性的应用场景下可能不太适合。

```
2. InnoDB
```
InnoDB 是 MySQL 的默认存储引擎，它是一个支持事务处理、外键约束、行级锁等高级功能的存储引
擎。在 InnoDB 中，每个表的数据和索引信息都存储在一个单独的 .ibd 文件中，并且支持行级锁定和多
版本并发控制 (MVCC) 等特性。InnoDB 还支持热备份、热恢复和崩溃恢复等功能，适用于高并发、高可
靠性的应用场景。但是，由于 InnoDB 不支持全文搜索和压缩等功能，因此在某些应用场景下可能需要
结合其他存储引擎使用。

###### 11 、说说事务基本特性

事务是指在计算机系统中执行的一系列操作，这些操作要么全部成功，要么全部失败。

**一、事务的四大特性**

事务具有 4 个基本特征，分别是：原子性（Atomicity）、一致性（Consistency）、隔离性
（Isolation）、持久性（Duration），简称 ACID

**① 原子性**
事务的原子性是指事务必须是一个原子的操作序列单元。事务中包含的各项操作在一次执行过程中，只
允许出现两种状态之一，要么都成功，要么都失败


任何一项操作都会导致整个事务的失败，同时其它已经被执行的操作都将被撤销并回滚，只有所有的操
作全部成功，整个事务才算是成功完成

**② 一致性（Consistency）**
事务的一致性是指事务的执行不能破坏数据库数据的完整性和一致性，一个事务在执行之前和执行之
后，数据库都必须处以一致性状态。

比如：如果从 A 账户转账到 B 账户，不可能因为 A 账户扣了钱，而 B 账户没有加钱

**③ 隔离性**
事务的隔离性是指在并发环境中，并发的事务是互相隔离的，一个事务的执行不能被其它事务干扰。也
就是说，不同的事务并发操作相同的数据时，每个事务都有各自完整的数据空间。

一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务是不能互相干扰的

**④ 持久性（Duration）**
事务的持久性是指事务一旦提交后，数据库中的数据必须被永久的保存下来。即使服务器系统崩溃或服
务器宕机等故障。只要数据库重新启动，那么一定能够将其恢复到事务成功结束后的状态

**在事物进行过程中，未结束之前，DML 语句是不会更改底层数据，只是将历史操作记录一下，在内存中
完成记录。只有在事物结束的时候，而且是成功的结束的时候，才会修改底层硬盘文件中的数据**

**二、事务的隔离级别详解**

事务的隔离性是指在并发环境中，并发的事务是互相隔离的，一个事务的执行不能被其它事务干扰。也
就是说，不同的事务并发操作相同的数据时，每个事务都有各自完整的数据空间。

一个事务内部的操作及使用的数据对其它并发事务是隔离的，并发执行的各个事务是不能互相干扰的。
不同的隔离级别可以解决不同的问题，SQL 的标准事务隔离级别包括：

**读未提交（read uncommitted）：** 一个事务还没有提交时，它做的变更就能被别的事务看到。

**读提交（read committed）：** 一个事物提交之后，它做的变更才会被其他事务看到。

**可重复读（repeatable read）：** 一个事物执行过程中看到的数据，总是跟这个事务在启动时看到的数
据是一致的。未提交变更对其他事务也是不可见的。

**串行化（serializable）：** 对于同一行记录，写会加“写锁”，读会加“读锁”，当出现锁冲突时，后访问
的事务需要等前一个事务执行完成，才能继续执行。

**可能导致的问题有**

**1. 脏读：** 一个事务读到另一个事务未提交的更新数据。

**2. 不可重复读：** 一个事务两次读同一行数据，可是这两次读到的数据不一样。

**3. 幻读：** 一个事务执行两次查询，但第二次查询比第一次查询多出了一些数据行。

**2.1 读未提交**

这个相对好理解，读操作不申请锁, 与允许读取未提交的修改, 也就是允许读脏数据, 读操作不会影响写操
作请求排他锁

```
create table T (c int) engine = InnoDB;
insert into T (c) values ( 1 );
```

假设数据表中 T 中只有一列，其中一行的值为 1

对上面的操作如果是读未提交，那么记住 A 事务是可以读取到 B 事务修改了但是还没有提交的事务的

v 1 的值是 2 ，这时候事务 B 虽然还没有提交，但是结果已经被事务 A 看到了，因此 v 2、v 3 也都是 2

这也就是所谓的脏读问题：一个事务读到另一个事务未提交的更新数据

**2.2 读提交**

读提交就是说一个事物提交之后，它做的变更才会被其他事务看到，也就是对于事务 A，虽然在事务 B 更
改了数据后进行了一次查询，但是这个时候 B 还没提交事务，那么查询到的还是原来的数据

即 v 1 是 1 ，v 2 的值是 2 ，事务 B 的更新在提交后才被事务 A 看到。所以 v 2 的值是 2

这个解决了所谓的脏读问题，但是出现了新问题，那就是不可重复读，也就是说在 A 事务中不能对 V 进行
重复的读取，不然你就发现出现了问题，在事务 B 提交前和事务 A 读取的三次 V 的值可能不一样

**2.3 可重复读**

一个事物执行过程中看到的数据，总是跟这个事务在启动时看到的数据是一致的。未提交变更对其他事
务也是不可见的

那么对于上面的例子，事务 A 读取到的值 1 ，值 V 1 值 V 2 不会受到事务 B 的影响，只有在离开事务后 V 3 才
的会被影响

即 v 1、v 2 是 1 ，v 3 是 2 ，之所以 v 2 还是 1 ，遵循的就是这个要求：事务在执行期间看到的数据前后必须
是一致的

这也就解决了所谓的不可重复读问题，但是出现了幻读


```
时
间事务 A 事务 B
```
```
T 1 开始事务 -
```
```
T 2 查询主键值为 1 的数据是否存在 (假设结果是不存在) 开始事务
```
```
T 3
```
```
插入主键值为 1 的
数据
```
```
T 4
```
```
查询主键值为 1 的数据是否存在 (由于 B 位提交的数据对 A 不可见，所
以还是不存在)^
```
```
T 5 插入主键值为 1 的数据结束事务
```
```
T 6 结束事务
```
所谓幻读的解释是这样的：一个事务执行两次查询，但第二次查询比第一次查询多出了一些数据行

我理解来说，上面的意思是幻读实际上是针对多条数据来说的，我们再举一个例子来说

由上面我们可以看到因为事务的隔离界别，事务 A 并不知道事务 B 插入了主键值为 1 的数据，所以自己也
去插入，这个时候其实已经有了，仿佛凭空产生出现了幻觉，从而发生了错误

**2.4 顺序读**

顺序读是最严格的事务隔离级别。它要求所有的事务排队顺序执行，即事务只能一个接一个地处理，不
能并发

自然也就解决了上面的所以问题

###### 12 、说说 mongoDB 索引

MongoDB 索引是 MongoDB 数据库中用于加速查询的一种数据结构。它可以对集合中的数据进行排序、
分组和过滤等操作，从而提高查询效率。

MongoDB 支持多种类型的索引，包括单键、复合索引、文本索引等。

单键索引：它是一种最基本的索引类型，可以对集合中的某个字段进行排序和唯一性约束。例如，可以
使用单键索引对一个名为“name”的字段进行排序和查询。

复合索引：它是一种组合了多个字段的索引类型，可以同时对多个字段进行排序和唯一性约束。例如，
可以使用复合索引对一个包含“name”、“age”和“gender”三个字段的集合进行排序和查询。

文本索引：它是一种用于搜索和匹配文本数据的索引类型，可以用于查询包含特定词语的文档。例如，
可以使用文本索引对一个名为“content”的字段进行搜索和查询。

MongoDB 的索引机制非常灵活，可以根据不同的查询需求选择合适的索引类型。但是，过多的索引可
能会降低写入性能，因为每个索引都需要占用一定的存储空间和内存资源。因此，在创建索引时需要权
衡查询性能和写入性能之间的平衡。

优点：


```
1. 索引可以大大提高查询速度，特别是在大型集合中。
2. MongoDB 支持多种类型的索引，包括单键、复合索引、文本索引等，可以根据不同的查询需求选
择合适的索引类型。
3. MongoDB 的索引机制非常灵活，可以随时添加、删除和修改索引，方便维护和优化。
4. MongoDB 的索引占用存储空间较小，不会过多占用内存资源。
```
缺点：

```
1. 创建索引需要消耗一定的时间和资源，对于大量数据的集合可能会影响性能。
2. 如果索引设计不当，会导致写入性能下降，因为写入操作需要更新多个字段。
3. MongoDB 的索引不支持跨文档查询，如果需要进行跨文档查询，需要使用聚合管道等方式实现。
```
应用：

```
1. 搜索和排序：MongoDB 的索引可以用于搜索和排序操作，提高查询效率。
2. 聚合和分析：MongoDB 的索引可以用于聚合和分析操作，例如统计每个用户的订单数量、计算平
均值等。
3. 地理空间查询：MongoDB 的索引可以用于地理空间查询，例如查询某个区域内的商品信息。
4. 全文搜索：MongoDB 的文本索引可以用于全文搜索操作，例如搜索包含特定关键词的文档。
```
###### 13 、说说 mongoDB 有事务吗

MongoDB 支持多文档事务，也称为“MongoDB 复制集事务”。它允许多个写操作在一个事务中进行，这
些操作可以是插入、更新或删除文档。

特点：

```
1. 原子性：MongoDB 的多文档事务确保所有操作都要么全部成功，要么全部失败回滚。
2. 一致性：MongoDB 的多文档事务确保在提交事务之前所有操作都已应用到数据库中。
3. 隔离性：MongoDB 的多文档事务确保每个操作都在一个独立的执行环境中进行，不会被其他并发
操作干扰。
```
应用：

```
1. 高可用性：MongoDB 的多文档事务可用于实现复制集的高可用性，确保在主节点故障时从节点能
够继续提供服务。
2. 数据一致性：MongoDB 的多文档事务可用于确保在多个写操作之间保持数据的一致性。
3. 并发控制：MongoDB 的多文档事务可用于控制多个写操作之间的并发访问，防止数据冲突和损
坏。
```
###### 14 、说说 mongoDB 持久化


MongoDB 的持久化是指将数据库中的数据写入磁盘，以防止在服务器宕机或重启时丢失数据。
MongoDB 支持两种持久化方式：

```
1. 事务日志 (WiredTiger)
```
WiredTiger 是 MongoDB 默认的存储引擎，它使用事务日志来实现持久化。事务日志是一种基于文件的
持久化方式，它将所有修改操作记录到一个单独的日志文件中，并在每次写入磁盘之前将日志文件刷新
到磁盘上。如果服务器崩溃或重启，MongoDB 会重新启动并从事务日志中读取数据，以恢复数据库状
态。

```
2. 复制集 (Replica Set)
```
复制集是一种通过将数据复制到多个节点来实现高可用性和容错性的机制。在 MongoDB 中，每个副本
集成员都有自己的数据目录和日志文件，它们之间通过网络通信来进行数据的同步和备份。如果主节点
宕机或出现故障，其中一个副本集成员会自动升格为新的主节点，并继续处理客户端请求。

优点：

```
1. WiredTiger 持久化可以提供更高的写入性能和更低的延迟，因为它使用了更快的数据压缩和写入
技术。
2. 复制集可以提供更高的可用性和容错性，因为它可以在多个节点之间进行数据复制和备份。
3. MongoDB 的持久化机制非常灵活，可以根据不同的应用需求选择合适的持久化方式。
```
缺点：

```
1. WiredTiger 持久化需要更多的磁盘空间和内存资源，因为它需要维护多个日志文件和数据目录。
2. 复制集需要更多的网络带宽和 CPU 资源，因为它需要在多个节点之间进行数据复制和同步。
```
###### 15 、说说分布式事务

分布式事务是指在分布式系统中，多个不同的节点 (或进程) 之间进行的一系列操作，这些操作要么全部
成功，要么全部失败，保证数据的一致性和可靠性。

在传统的单体架构中，事务只需要在单个节点上执行即可，但是在分布式系统中，由于节点之间的网络
延迟、故障等问题，单一节点无法保证所有操作的原子性、一致性、隔离性和持久性。因此，需要使用
分布式事务来解决这些问题。

分布式事务的实现方式有多种，包括两阶段提交协议 (2 PC)、消息队列等。其中，2 PC 是最常用的协议之
一，它将事务分为两个阶段：预提交和正式提交。在预提交阶段，各个节点会询问对方是否可以提交事
务；在正式提交阶段，如果所有节点都确认可以提交，则会正式提交事务。

分布式事务的实现比较复杂，需要考虑各种异常情况和性能问题。因此，在实际应用中需要谨慎选择合
适的分布式事务方案。

分布式事务的内容太多，完整的内容，请参考尼恩的尼恩 Java 面试宝典专题：


**《专题 17 ：分布式事务面试题（卷王专供 + 史上最全 + 2023 面试必备）》**

###### 16 、说说操作系统内存管理

**一、内存管理的概念**

内存管理 (Memory Management) 是操作系统设计中最重要和最复杂的内容之一。虽然计算机硬件一直
在飞速发展，内存容量也在不断增长，但是仍然不可能将所有用户进程和系统所需要的全部程序和数据
放入主存中，所以操作系统必须将内存空间进行合理地划分和有效地动态分配。操作系统对内存的划分
和动态分配，就是内存管理的概念。
有效的内存管理在多道程序设计中非常重要，不仅方便用户使用存储器、提高内存利用率，还可以通过
虚拟技术从逻辑上扩充存储器。
内存管理的功能有：

```
内存空间的分配与回收：由操作系统完成主存储器空间的分配和管理，使程序员摆脱存储分配的麻
烦，提高编程效率。
地址转换：在多道程序环境下，程序中的逻辑地址与内存中的物理地址不可能一致，因此存储管理
必须提供地址变换功能，把逻辑地址转换成相应的物理地址。
内存空间的扩充：利用虚拟存储技术或自动覆盖技术，从逻辑上扩充内存。
存储保护：保证各道作业在各自的存储空间内运行，. 互不干扰。
```
在进行具体的内存管理之前，需要了解进程运行的基本原理和要求。

**程序装入和链接**

创建进程首先要将程序和数据装入内存。将用户源程序变为可在内存中执行的程序，通常需要以下几个
步骤：

```
编译：由编译程序将用户源代码编译成若干个目标模块。
链接：由链接程序将编译后形成的一组目标模块，以及所需库函数链接在一起，形成一个完整的装
入模块。
装入：由装入程序将装入模块装入内存运行。
```
这三步过程如图 3-1 所示。

图 1 对用户程序的处理步骤

程序的链接有以下三种方式：


```
静态链接：在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，
以后不再拆开。
装入时动态链接：将用户源程序编译后所得到的一组目标模块，在装入内存时，釆用边装入边链接
的链接方式。
运行时动态链接：对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行的链
接。其优点是便于修改和更新，便于实现对目标模块的共享。
```
内存的装入模块在装入内存时，同样有以下三种方式：

1 ）绝对装入。在编译时，如果知道程序将驻留在内存的某个位置，编译程序将产生绝对地址的目标代
码。绝对装入程序按照装入模块中的地址，将程序和数据装入内存。由于程序中的逻辑地址与实际内存
地址完全相同，故不需对程序和数据的地址进行修改。

绝对装入方式只适用于单道程序环境。另外，程序中所使用的绝对地址, 可在编译或汇编时给出，也可由
程序员直接赋予。而通常情况下在程序中釆用的是符号地址，编译或汇编时再转换为绝对地址。

2 ）可重定位装入。在多道程序环境下，多个目标模块的起始地址通常都是从 0 开始，程序中的其他地址
都是相对于起始地址的, 此时应釆用可重定位装入方式。根据内存的当前情况，将装入模块装入到内存的
适当位置。装入时对目标程序中指令和数据的修改过程称为重定位，地址变换通常是在装入时一次完成
的，所以又称为静态重定位，如图 3-2 (a) 所示。

图 2 重定向类型

静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，
就不能装入该作业。此外，作业一旦进入内存后，在整个运行期间不能在内存中移动，也不能再申请内
存空间。

3 ）动态运行时装入，也称为动态重定位，程序在内存中如果发生移动，就需要釆用动态的装入方式。
装入程序在把装入模块装入内存后，并不立即把装入模块中的相对地址转换为绝对地址，而是把这种地
址转换推迟到程序真正要执行时才进行。因此，装入内存后的所有地址均为相对地址。这种方式需要一
个重定位寄存器的支持，如图 3-2 (b) 所示。

动态重定位的特点是可以将程序分配到不连续的存储区中；在程序运行之前可以只装入它的部分代码即
可投入运行，然后在程序运行期间，根据需要动态申请分配内存；便于程序段的共享，可以向用户提供
一个比存储空间大得多的地址空间。


**逻辑地址空间与物理地址空间**

编译后，每个目标模块都是从 0 号单元开始编址，称为该目标模块的相对地址（或逻辑地址)。

当链接程序将各个模块链接成一个完整的可执行目标程序时，链接程序顺序依次按各个模块的相对地址
构成统一的从 0 号单元开始编址的逻辑地址空间。用户程序和程序员只需知道逻辑地址，而内存管理的
具体机制则是完全透明的，它们只有系统编程人员才会涉及。不同进程可以有相同的逻辑地址，因为这
些相同的逻辑地址可以映射到主存的不同位置。

物理地址空间是指内存中物理单元的集合，它是地址转换的最终地址，进程在运行时执行指令和访问数
据最后都要通过物理地址从主存中存取。当装入程序将可执行代码装入内存时，必须通过地址转换将逻
辑地址转换成物理地址，这个过程称为地址重定位。

**内存保护**

内存分配前，需要保护操作系统不受用户进程的影响，同时保护用户进程不受其他用户进程的影响。通
过釆用重定位寄存器和界地址寄存器来实现这种保护。重定位寄存器含最小的物理地址值，界地址寄存
器含逻辑地址值。每个逻辑地址值必须小于界地址寄存器；内存管理机构动态地将逻辑地址与界地址寄
存器进行比较，如果未发生地址越界，则加上重定位寄存器的值后映射成物理地址，再送交内存单元，
如图 3-3 所示。

当 CPU 调度程序选择进程执行时，派遣程序会初始化重定位寄存器和界地址寄存器。每一个逻辑地址都
需要与这两个寄存器进行核对，以保证操作系统和其他用户程序及数据不被该进程的运行所影响。

图 3 重定位和界地址寄存器的硬件支持

**二、内存覆盖与内存交换**

覆盖与交换技术是在多道程序环境下用来扩充内存的两种方法。

**内存覆盖**

早期的计算机系统中，主存容量很小，虽然主存中仅存放一道用户程序，但是存储空间放不下用户进程
的现象也经常发生，这一矛盾可以用覆盖技术来解决。

覆盖的基本思想是：由于程序运行时并非任何时候都要访问程序及数据的各个部分（尤其是大程序），
因此可以把用户空间分成一个固定区和若干个覆盖区。将经常活跃的部分放在固定区，其余部分按调用
关系分段。首先将那些即将要访问的段放入覆盖区，其他段放在外存中，在需要调用前，系统再将其调
入覆盖区，替换覆盖区中原有的段。

覆盖技术的特点是打破了必须将一个进程的全部信息装入主存后才能运行的限制，但当同时运行程序的
代码量大于主存时仍不能运行。


**内存交换**

交换（对换）的基本思想是，把处于等待状态（或在 CPU 调度原则下被剥夺运行权利）的程序从内存移
到辅存，把内存空间腾出来，这一过程又叫换出；把准备好竞争 CPU 运行的程序从辅存移到内存，这一
过程又称为换入。中级调度就是釆用交换技术。

例如，有一个 CPU 釆用时间片轮转调度算法的多道程序环境。时间片到，内存管理器将刚刚执行过的进
程换出，将另一进程换入到刚刚释放的内存空间中。同时，CPU 调度器可以将时间片分配给其他已在内
存中的进程。每个进程用完时间片都与另一进程交换。理想情况下，内存管理器的交换过程速度足够
快，总有进程在内存中可以执行。

有关交换需要注意以下几个问题：

```
交换需要备份存储，通常是快速磁盘。它必须足够大，并且提供对这些内存映像的直接访问。
为了有效使用 CPU，需要每个进程的执行时间比交换时间长，而影响交换时间的主要是转移时间。
转移时间与所交换的内存空间成正比。
如果换出进程，必须确保该进程是完全处于空闲状态。
交换空间通常作为磁盘的一整块，且独立于文件系统，因此使用就可能很快。
交换通常在有许多进程运行且内存空间吃紧时开始启动，而系统负荷降低就暂停。
普通的交换使用不多，但交换策略的某些变种在许多系统中（如 UNIX 系统）仍发挥作用。
```
交换技术主要是在不同进程（或作业）之间进行，而覆盖则用于同一个程序或进程中。由于覆盖技术要
求给出程序段之间的覆盖结构，使得其对用户和程序员不透明，所以对于主存无法存放用户程序的矛
盾，现代操作系统是通过虚拟内存技术来解决的，覆盖技术则已成为历史；而交换技术在现代操作系统
中仍具有较强的生命力。

**三、内存连续分配管理方式**

连续分配方式，是指为一个用户程序分配一个连续的内存空间。它主要包括单一连续分配、固定分区分
配和动态分区分配。

**单一连续分配**

内存在此方式下分为系统区和用户区，系统区仅提供给操作系统使用，通常在低地址部分；用户区是为
用户提供的、除系统区之外的内存空间。这种方式无需进行内存保护。

这种方式的优点是简单、无外部碎片，可以釆用覆盖技术，不需要额外的技术支持。缺点是只能用于单
用户、单任务的操作系统中，有内部碎片，存储器的利用率极低。

**固定分区分配**

固定分区分配是最简单的一种多道程序存储管理方式，它将用户内存空间划分为若干个固定大小的区
域，每个分区只装入一道作业。当有空闲分区时，便可以再从外存的后备作业队列中, 选择适当大小的作
业装入该分区，如此循环。


图 4 固定分区分配的两种方法

固定分区分配在划分分区时，有两种不同的方法，如图 3-4 所示。

```
分区大小相等：用于利用一台计算机去控制多个相同对象的场合，缺乏灵活性。
分区大小不等：划分为含有多个较小的分区、适量的中等分区及少量的大分区。
```
为便于内存分配，通常将分区按大小排队，并为之建立一张分区说明表，其中各表项包括每个分区的起
始地址、大小及状态（是否已分配），如图 3-5 (a) 所示。当有用户程序要装入时，便检索该表，以找到
合适的分区给予分配并将其状态置为”已分配”；未找到合适分区则拒绝为该用户程序分配内存。存储空
间的分配情况如图 3-5 (b) 所示。

这种分区方式存在两个问题：一是程序可能太大而放不进任何一个分区中，这时用户不得不使用覆盖技
术来使用内存空间；二是主存利用率低，当程序小于固定分区大小时，也占用了一个完整的内存分区空
间，这样分区内部有空间浪费，这种现象称为内部碎片。

固定分区是可用于多道程序设计最简单的存储分配，无外部碎片，但不能实现多进程共享一个主存区，
所以存储空间利用率低。固定分区分配很少用于现在通用的操作系统中，但在某些用于控制多个相同对
象的控制系统中仍发挥着一定的作用。

图 5 固定分区说明表和内存分配情况

**动态分区分配**

动态分区分配又称为可变分区分配，是一种动态划分内存的分区方法。这种分区方法不预先将内存划
分，而是在进程装入内存时，根据进程的大小动态地建立分区，并使分区的大小正好适合进程的需要。
因此系统中分区的大小和数目是可变的。


图 6 动态分区

如图 3-6 所示，系统有 64 MB 内存空间，其中低 8 MB 固定分配给操作系统，其余为用户可用内存。开始时
装入前三个进程，在它们分别分配到所需空间后，内存只剩下 4 MB，进程 4 无法装入。在某个时刻，内
存中没有一个就绪进程，CPU 出现空闲，操作系统就换出进程 2 ，换入进程 4 。由于进程 4 比进程 2 小，这
样在主存中就产生了一个 6 MB 的内存块。之后 CPU 又出现空闲，而主存无法容纳进程 2, 操作系统就换出
进程 1 ，换入进程 2 。

动态分区在开始分配时是很好的，但是之后会导致内存中出现许多小的内存块。随着时间的推移，内存
中会产生越来越多的碎片（图 3-6 中最后的 4 MB 和中间的 6 MB，且随着进程的换入/换出，很可能会出现
更多更小的内存块)，内存的利用率随之下降。

这些小的内存块称为外部碎片，指在所有分区外的存储空间会变成越来越多的碎片，这与固定分区中的
内部碎片正好相对。克服外部碎片可以通过紧凑（Compaction) 技术来解决，就是操作系统不时地对进
程进行移动和整理。但是这需要动态重定位寄存器的支持，且相对费时。紧凑的过程实际上类似于
Windows 系统中的磁盘整理程序，只不过后者是对外存空间的紧凑。

在进程装入或换入主存时，如果内存中有多个足够大的空闲块，操作系统必须确定分配哪个内存块给进
程使用，这就是动态分区的分配策略，考虑以下几种算法：

```
首次适应 (First Fit) 算法：空闲分区以地址递增的次序链接。分配内存时顺序查找，找到大小能满足
要求的第一个空闲分区。
最佳适应 (Best Fit) 算法：空闲分区按容量递增形成分区链，找到第一个能满足要求的空闲分区。
最坏适应 (Worst Fit) 算法：又称最大适应 (Largest Fit) 算法，空闲分区以容量递减的次序链接。找
到第一个能满足要求的空闲分区，也就是挑选出最大的分区。
邻近适应 (Next Fit) 算法：又称循环首次适应算法，由首次适应算法演变而成。不同之处是分配内
存时从上次查找结束的位置开始继续查找。
```
在这几种方法中，首次适应算法不仅是最简单的，而且通常也是最好和最快的。在 UNIX 系统的最初版
本中，就是使用首次适应算法为进程分配内存空间，其中使用数组的数据结构 (而非链表）来实现。不
过，首次适应算法会使得内存的低地址部分出现很多小的空闲分区，而每次分配查找时，都要经过这些
分区，因此也增加了查找的开销。


```
作业道
数
```
```
内
部
碎
片
```
```
外
部
碎
片
```
```
硬件支持
```
```
可用空间管理
解决碎片方法
解决空间不足
提高作业道数
```
```
单道
连续
分配
```
```
1 有无界地址寄存器、越界^ 检查机
构
```
- – 覆
    盖

```
交
换
```
```
多道
固定
连续
分配
```
```
<=N
(用户空
间划为
N 块)
```
```
有无
```
```
上下界寄存器、越界检查机构
基地址寄存器、长度寄存器、
动态地址转换机构
```
- –

```
多道
可变
连续
分配
```
```
— 无有数组链表紧
凑
```
邻近适应算法试图解决这个问题，但实际上，它常常会导致在内存的末尾分配空间（因为在一遍扫描
中，内存前面部分使用后再释放时，不会参与分配)，分裂成小碎片。它通常比首次适应算法的结果要
差。

最佳适应算法虽然称为“最佳”，但是性能通常很差，因为每次最佳的分配会留下很小的难以利用的内存
块，它会产生最多的外部碎片。

最坏适应算法与最佳适应算法相反，选择最大的可用块，这看起来最不容易产生碎片，但是却把最大的
连续内存划分开，会很快导致没有可用的大的内存块，因此性能也非常差。

Kunth 和 Shore 分别就前三种方法对内存空间的利用情况做了模拟实验，结果表明：

首次适应算法可能比最佳适应法效果好，而它们两者一定比最大适应法效果好。另外注意, 在算法实现
时, 分配操作中最佳适应法和最大适应法需要对可用块进行排序或遍历查找，而首次适应法和邻近适应法
只需要简单查找；回收操作中，当回收的块与原来的空闲块相邻时（有三种相邻的情况，比较复杂)，需
要将这些块合并。在算法实现时，使用数组或链表进行管理。除了内存的利用率，这里的算法开销也是
操作系统设计需要考虑的一个因素。

以上三种内存分区管理方法有一共同特点，即用户进程（或作业）在主存中都是连续存放的。这里对它
们进行比较和总结，见表 3-1。

**四、内存非连续分配管理方式**

非连续分配允许一个程序分散地装入到不相邻的内存分区中，根据分区的大小是否固定分为分页存储管
理方式和分段存储管理方式。

分页存储管理方式中，又根据运行作业时是否要把作业的所有页面都装入内存才能运行分为基本分页存
储管理方式和请求分页存储管理方式。下面介绍基本分页存储管理方式。

**基本分页存储管理方式**


固定分区会产生内部碎片，动态分区会产生外部碎片，这两种技术对内存的利用率都比较低。我们希望
内存的使用能尽量避免碎片的产生，这就引入了分页的思想：把主存空间划分为大小相等且固定的块，
块相对较小，作为主存的基本单位。每个进程也以块为单位进行划分，进程在执行时，以块为单位逐个
申请主存中的块空间。

分页的方法从形式上看，像分区相等的固定分区技术，分页管理不会产生外部碎片。但它又有本质的不
同点：块的大小相对分区要小很多，而且进程也按照块进行划分，进程运行时按块申请主存可用空间并
执行。这样，进程只会在为最后一个不完整的块申请一个主存块空间时，才产生主存碎片，所以尽管会
产生内部碎片，但是这种碎片相对于进程来说也是很小的，每个进程平均只产生半个块大小的内部碎片
（也称页内碎片）。

**1 ）分页存储的几个基本概念**

①页面和页面大小。进程中的块称为页 (Page)，内存中的块称为页框（Page Frame，或页帧）。外存
也以同样的单位进行划分，直接称为块 (Block)。进程在执行时需要申请主存空间，就是要为每个页面分
配主存中的可用页框，这就产生了页和页框的一一对应。

为方便地址转换，页面大小应是 2 的整数幂。同时页面大小应该适中，如果页面太小，会使进程的页面
数过多，这样页表就过长，占用大量内存，而且也会增加硬件地址转换的开销，降低页面换入/换出的
效率；页面过大又会使页内碎片增大，降低内存的利用率。所以页面的大小应该适中，考虑到耷间效率
和时间效率的权衡。

②地址结构。分页存储管理的逻辑地址结构如图 3-7 所示。

图 7 分页存储管理的地址结构

地址结构包含两部分：前一部分为页号 P，后一部分为页内偏移量 W。地址长度为 32 位，其中 011 位为
页内地址，即每页大小为 4 KB； 1231 位为页号，地址空间最多允许有 2^20 页。

③页表。为了便于在内存中找到进程的每个页面所对应的物理块，系统为每个进程建立一张页表，记录
页面在内存中对应的物理块号，页表一般存放在内存中。

在配置了页表后，进程执行时，通过查找该表，即可找到每页在内存中的物理块号。可见，页表的作用
是实现从页号到物理块号的地址映射，如图 3-8 所示。

图 8 页表的作用


**2 ）基本地址变换机构**

地址变换机构的任务是将逻辑地址转换为内存中物理地址，地址变换是借助于页表实现的。图 3-9 给出
了分页存储管理系统中的地址变换机构。

图 3-9 分页存储管理的地址变换机构

在系统中通常设置一个页表寄存器 (PTR)，存放页表在内存的始址 F 和页表长度 M。进程未执行时，页表
的始址和长度存放在进程控制块中，当进程执行时，才将页表始址和长度存入页表寄存器。设页面大小
为 L，逻辑地址 A 到物理地址 E 的变换过程如下：

```
1. 计算页号 P (P=A/L) 和页内偏移量 W (W=A%L)。
2. 比较页号 P 和页表长度 M，若 P >= M，则产生越界中断，否则继续执行。
3. 页表中页号 P 对应的页表项地址 = 页表起始地址 F + 页号 P * 页表项长度，取出该页表项内容 b，即
为物理块号。
4. 计算 E=b*L+W，用得到的物理地址 E 去访问内存。
```
以上整个地址变换过程均是由硬件自动完成的。

例如，若页面大小 L 为 1 K 字节，页号 2 对应的物理块为 b=8，计算逻辑地址 A=2500 的物理地址 E 的过程
如下：P=2500/1 K=2，W=2500%1 K=452，查找得到页号 2 对应的物理块的块号为 8 ，
E=8*1024+452=8644。

下面讨论分页管理方式存在的两个主要问题：

```
每次访存操作都需要进行逻辑地址到物理地址的转换，地址转换过程必须足够快，否则访存速度会
降低；
每个进程引入了页表，用于存储映射机制，页表不能太大，否则内存利用率会降低。
```
**3 ）具有快表的地址变换机构**

由上面介绍的地址变换过程可知，若页表全部放在内存中，则存取一个数据或一条指令至少要访问两次
内存：一次是访问页表，确定所存取的数据或指令的物理地址，第二次才根据该地址存取数据或指令。
显然，这种方法比通常执行指令的速度慢了一半。

为此，在地址变换机构中增设了一个具有并行查找能力的高速缓冲存储器——快表，又称联想寄存器
(TLB)，用来存放当前访问的若干页表项，以加速地址变换的过程。与此对应，主存中的页表也常称为
慢表，配有快表的地址变换机构如图 3-10 所示。


图 10 具有快表的地址变换机构

在具有快表的分页机制中，地址的变换过程：

```
CPU 给出逻辑地址后，由硬件进行地址转换并将页号送入高速缓存寄存器，并将此页号与快表中的
所有页号进行比较。
如果找到匹配的页号，说明所要访问的页表项在快表中，则直接从中取出该页对应的页框号，与页
内偏移量拼接形成物理地址。这样，存取数据仅一次访存便可实现。
如果没有找到，则需要访问主存中的页表，在读出页表项后，应同时将其存入快表，以便后面可能
的再次访问。但若快表已满，则必须按照一定的算法对旧的页表项进行替换。
```
注意：有些处理机设计为快表和慢表同时查找，如果在快表中查找成功则终止慢表的查找。

一般快表的命中率可以达到 90%以上，这样，分页带来的速度损失就降低到 10%以下。快表的有效性是
基于著名的局部性原理，这在后面的虚拟内存中将会具体讨论。

**4 ）两级页表**

第二个问题：由于引入了分页管理，进程在执行时不需要将所有页调入内存页框中，而只要将保存有映
射关系的页表调入内存中即可。但是我们仍然需要考虑页表的大小。

以 32 位逻辑地址空间、页面大小 4 KB、页表项大小 4 B 为例，若要实现进程对全部逻辑地址空间的映
射，则每个进程需要 2^20，约 100 万个页表项。也就是说，每个进程仅页表这一项就需要 4 MB 主存空
间，这显然是不切实际的。而即便不考虑对全部逻辑地址空间进行映射的情况，一个逻辑地址空间稍大
的进程，其页表大小也可能是过大的。

以一个 40 MB 的进程为例，页表项共 40 KB, 如果将所有页表项内容保存在内存中，那么需要 10 个内存页
框来保存整个页表。整个进程大小约为 1 万个页面，而实际执行时只需要几十个页面进入内存页框就可
以运行，但如果要求 10 个页面大小的页表必须全部进入内存，这相对实际执行时的几十个进程页面的大
小来说，肯定是降低了内存利用率的；从另一方面来说，这 10 页的页表项也并不需要同时保存在内存
中，因为大多数情况下，映射所需要的页表项都在页表的同一个页面中。

将页表映射的思想进一步延伸，就可以得到二级分页：将页表的 10 页空间也进行地址映射，建立上一级
页表，用于存储页表的映射关系。这里对页表的 10 个页面进行映射只需要 10 个页表项，所以上一级页表
只需要 1 页就足够（可以存储 2^10=1024 个页表项）。在进程执行时，只需要将这 1 页的上一级页表调入
内存即可，进程的页表和进程本身的页面，可以在后面的执行中再 i 周入内存。


如图 3-11 所示，这是 Intel 处理器 80 x 86 系列的硬件分页的地址转换过程。在 32 位系统中，全部 32 位逻辑
地址空间可以分为 220 (4 GB/4 KB) 个页面。这些页面可以再进一步建立顶级页表，需要 210 个顶级页表项
进行索引，这正好是一页的大小，所以建立二级页表即可。

图 11 硬件分页地址转换

举例， 32 位系统中进程分页的工作过程：假定内核已经给一个正在运行的进程分配的逻辑地址空间是
0 x 20000000 到 0 x 2003 FFFF，这个空间由 64 个页面组成。在进程运行时，我们不需要知道全部这些页的
页框的物理地址，很可能其中很多页还不在主存中。这里我们只注意在进程运行到某一页时，硬件是如
何计算得到这一页的页框的物理地址即可。现在进程需要读逻辑地址 0 x 20021406 中的字节内容，这个
逻辑地址按如下进行处理：
逻辑地址： 0 x 20021406 (0010 0000 0000 0010 0001 0100 0000 0110 B)
顶级页表字段：0 x 80 (00 1000 0000 B)
二级页表字段：0 x 21 (00 0010 0001 B)
页内偏移量字段：0 x 406 (0100 0000 0110 B)

顶级页表字段的 0 x 80 用于选择顶级页表的第 0 x 80 表项，此表项指向和该进程的页相关的二级页表；二
级页表字段 0 x 21 用于选择二级页表的第 0 x 21 表项，此表项指向包含所需页的页框；最后的页内偏移量
字段 0 x 406 用于在目标页框中读取偏移量为 0 x 406 中的字节。

这是 32 位系统下比较实际的一个例子。看似较为复杂的例子，有助于比较深入地理解，希望读者能自己
动手计算一遍转换过程。

建立多级页表的目的在于建立索引，这样不用浪费主存空间去存储无用的页表项，也不用盲目地顺序式
查找页表项，而建立索引的要求是最高一级页表项不超过一页的大小。在 64 位操作系统中，页表的划
分则需要重新考虑，这是很多教材和辅导书中的常见题目，但是很多都给出了错误的分析，需要注意。

我们假设仍然釆用 4 KB 页面大小。偏移量字段 12 位，假设页表项大小为 8 B。这样，其上一级分页时，每
个页框只能存储 29 (4 KB/8 B) 个页表项，而不再是 210 个，所以上一级页表字段为 9 位。后面同理继续分
页。64=12+9+9+9+9+9+7，所以需 6 级分页才能实现索引。很多书中仍然按 4 B 页表项分析，虽然同样
得出 6 级分页的结果，但显然是错误的。这里给出两个实际的 64 位操作系统的分页级别（注意：里面没


```
平台页面大小寻址位数分页级数具体分级
```
```
Alpha 8 KB 43 3 13+10+10+10
```
```
X 86_64 4 KB 48 4 12+9+9+9+9
```
有使用全部 64 位寻址，不过由于地址字节对齐的设计考虑，仍然使用 8 B 大小的页表项），理解了表 3-2
中的分级方式，相信对多级分页就非常清楚了。

**五、基本分段存储管理方式**

分页管理方式是从计算机的角度考虑设计的，以提高内存的利用率，提升计算机的性能, 且分页通过硬
件机制实现，对用户完全透明；而分段管理方式的提出则是考虑了用户和程序员，以满足方便编程、信
息保护和共享、动态增长及动态链接等多方面的需要。

**1 ）分段**

段式管理方式按照用户进程中的自然段划分逻辑空间。例如，用户进程由主程序、两个子程序、栈和一
段数据组成，于是可以把这个用户进程划分为 5 个段，每段从 0 开始编址，并分配一段连续的地址空间
（段内要求连续，段间不要求连续，因此整个作业的地址空间是二维的）。其逻辑地址由段号 S 与段内
偏移量 W 两部分组成。

在图 3-12 中，段号为 16 位，段内偏移量为 16 位，则一个作业最多可有 2^16=65536 个段，最大段长为
64 KB。

```
图 12 分段系统中的逻辑地址结构
```
图 12 分段系统中的逻辑地址结构

在页式系统中，逻辑地址的页号和页内偏移量对用户是透明的，但在段式系统中，段号和段内偏移量必
须由用户显示提供，在髙级程序设计语言中，这个工作由编译程序完成。

**2 ）段表**

每个进程都有一张逻辑空间与内存空间映射的段表，其中每一个段表项对应进程的一个段，段表项记录
该段在内存中的起始地址和段的长度。段表的内容如图 3-13 所示。

图 13 段表项

在配置了段表后，执行中的进程可通过查找段表，找到每个段所对应的内存区。可见，段表用于实现从
逻辑段到物理内存区的映射，如图 3-14 所示。


图 14 利用段表实现地址映射

**3 ）地址变换机构**

分段系统的地址变换过程如图 3-15 所示。为了实现进程从逻辑地址到物理地址的变换功能，在系统中设
置了段表寄存器，用于存放段表始址 F 和段表长度 M。其从逻辑地址 A 到物理地址 E 之间的地址变换过程
如下：

```
从逻辑地址 A 中取出前几位为段号 S，后几位为段内偏移量 W。
比较段号 S 和段表长度 M，若 S 多 M，则产生越界中断，否则继续执行。
段表中段号 S 对应的段表项地址 = 段表起始地址 F + 段号 S * 段表项长度，取出该段表项的前几位得
到段长 C。若段内偏移量>=C，则产生越界中断，否则继续执行。
取出段表项中该段的起始地址 b，计算 E = b + W，用得到的物理地址 E 去访问内存。
```

图 15 分段系统的地址变换过程

**4 ）段的共享与保护**

在分段系统中，段的共享是通过两个作业的段表中相应表项指向被共享的段的同一个物理副本来实现
的。当一个作业正从共享段中读取数据时，必须防止另一个作业修改此共享段中的数据。不能修改的代
码称为纯代码或可重入代码（它不属于临界资源)，这样的代码和不能修改的数据是可以共享的，而可修
改的代码和数据则不能共享。

与分页管理类似，分段管理的保护方法主要有两种：一种是存取控制保护，另一种是地址越界保护。地
址越界保护是利用段表寄存器中的段表长度与逻辑地址中的段号比较，若段号大于段表长度则产生越界
中断；再利用段表项中的段长和逻辑地址中的段内位移进行比较，若段内位移大于段长，也会产生越界
中断。

**段页式管理方式**

页式存储管理能有效地提高内存利用率，而分段存储管理能反映程序的逻辑结构并有利于段的共享。如
果将这两种存储管理方法结合起来，就形成了段页式存储管理方式。


在段页式系统中，作业的地址空间首先被分成若干个逻辑段，每段都有自己的段号，然后再将每一段分
成若干个大小固定的页。对内存空间的管理仍然和分页存储管理一样，将其分成若干个和页面大小相同
的存储块，对内存的分配以存储块为单位，如图 3-16 所示。

图 16 段页式管理方式

在段页式系统中，作业的逻辑地址分为三部分：段号、页号和页内偏移量，如图 3-17 所示。


图 17 段页式系统的逻辑地址结构

为了实现地址变换，系统为每个进程建立一张段表，而每个分段有一张页表。段表表项中至少包括段
号、页表长度和页表起始地址，页表表项中至少包括页号和块号。此外，系统中还应有一个段表寄存
器，指出作业的段表起始地址和段表长度。

注意：在一个进程中，段表只有一个，而页表可能有多个。

在进行地址变换时，首先通过段表查到页表起始地址，然后通过页表找到页帧号，最后形成物理地址。
如图 3-18 所示，进行一次访问实际需要三次访问主存，这里同样可以使用快表以加快查找速度，其关键
字由段号、页号组成，值是对应的页帧号和保护码。

图 17 段页式系统的逻辑地址结构

为了实现地址变换，系统为每个进程建立一张段表，而每个分段有一张页表。段表表项中至少包括段
号、页表长度和页表起始地址，页表表项中至少包括页号和块号。此外，系统中还应有一个段表寄存
器，指出作业的段表起始地址和段表长度。

注意：在一个进程中，段表只有一个，而页表可能有多个。

在进行地址变换时，首先通过段表查到页表起始地址，然后通过页表找到页帧号，最后形成物理地址。
如图 3-18 所示，进行一次访问实际需要三次访问主存，这里同样可以使用快表以加快查找速度，其关键
字由段号、页号组成，值是对应的页帧号和保护码。


## 问麻了....... 阿里一面索命 27 问, 撑住 = 年薪

## 60 W+

#### 前言

在 40 岁老架构师尼恩的（50+） **读者社群** 中，经常有小伙伴，需要面试阿里、百度、头条、美团、京东
等大厂。

下面是一个小伙伴成功拿到通过了阿里三次技术面试，小伙伴通过三个多小时技术拷问，最终拿到
offer。

**从这些题目来看：阿里的面试，偏重底层知识和原理，大家来看看吧。**

现在把面试真题和参考答案收入咱们的宝典，大家看看， **收个阿里 Offer 需要学点啥？**

当然对于中高级开发来说，这些面试题，也有参考意义。

这里把题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》 V 78，供后面的小伙伴参考，提升大家的
3 高架构、设计、开发水平。

```
注：本文以 PDF 持续更新，相关尼恩架构笔记、面试题的 PDF 文件，请从这里获取：码云
```
#### 阿里一面索命 27 问

###### 1 、说说 redis，了解 redis 源码吗

Redis 是一种开源的、基于内存的数据库系统，它可以用作数据库、缓存和消息中间件。

Redis 是一种高性能的开源 key-value 内存数据库，它支持各种复杂数据结构，例如字符串、哈希、列
表、集合等。Redis 的特点是速度快，可以处理非常大的数据集，而且具有很强的可扩展性和数据持久
化功能。

Redis 的源码是用 C 语言编写的，它采用单线程模型，通过异步 IO 和事件驱动机制实现高并发。其架构包
括网络层、客户端请求处理、命令执行引擎、键空间与过期管理、持久化、复制、Sentinel（哨兵）以
及集群等模块。

**Redis 具有以下特点：**

```
1. 内存数据库 ：Redis 将数据存储在内存中，速度非常快，可以快速读写数据。
2. 数据持久化 ：Redis 支持将数据持久化到磁盘，以便在重启时恢复数据。
3. 支持数据复制 ：Redis 支持将数据复制到多个从节点，从而实现数据备份和故障恢复。
4. 支持多种数据结构 ：Redis 支持各种数据结构，包括字符串、列表、哈希表、集合和有序集合等。
5. 支持事务 ：Redis 支持事务，可以对多个操作进行原子性的集成，避免出现数据不一致的问题。
```
**Redis 应用场景包括：**

```
1. 缓存 ：Redis 可以作为缓存系统，用于存储热点数据，提高应用程序的响应速度。
2. 数据库 ：Redis 可以用作数据库，用于存储数据，支持多种数据结构和事务。
3. 消息队列 ：Redis 可以作为消息队列，用于异步消息的传递和处理。
```

```
4. 分布式系统 ：Redis 支持分布式架构，可以用于实现分布式数据存储和分布式计算。
5. 监控和日志 ：Redis 可以用于存储监控数据和日志，支持数据的快速查询和分析。
```
**Redis 的重功能及作用:**

```
网络层：负责接收来自客户端的 socket 连接请求，并将请求转发给执行引擎。
客户端请求处理: 将请求解析为命令，并在命令执行引擎中进行处理。
命令执行引擎: 负责解析和执行各种 redis 命令，例如 set、get、hgetall 等。
键空间与过期管理：管理 redis 数据库中的键值对，并按照过期时间删除过期的键值对。
持久化：提供 RDB 和 AOF 两种持久化方式，用于将 redis 数据库中的数据保存到磁盘上。
复制：实现主从复制功能，用于实现数据的备份和读写分离。
哨兵：用于监控 redis 主从服务器状态，并在主服务器宕机时自动将从服务器切换成主服务器。
集群：实现 redis 集群功能，支持水平扩展。
```
Redis 支持多种数据结构，如字符串、散列表、列表、集合和有序集合等。Redis 支持多种操作，如读
取、写入、删除、事务处理、消息传输等。Redis 还支持多种复杂的数据操作，如映射、排序、过滤
等。

**Redis 的源码，宏观层面主要分成两大部分：**

```
一个 redis 服务器，redis 服务器是 C 语言编写的底层实现，包括协议栈、内存管理、数据结构、事
务处理等模块；
另一个 redis 客户端，可以是不同的语言实现，比如 Java 编写的 API 层，redis 客户端包括命令、过
程、脚本、消息传输等模块。
```
redis 客户端与 redis 服务器之间的通信是通过 TCP 协议进行的。

**Redis 服务器源码包括以下几个部分：**

```
1. 协议栈 ：负责客户端与 redis 服务器之间的通信，包括协议解析、数据传输等。
2. 内存管理 ：负责管理 redis 内存，包括内存池、内存分配和释放等。
3. 数据结构 ：负责 redis 的数据存储和访问，包括字符串、散列表、列表、集合和有序集合等。
4. 事务处理 ：负责支持多种事务，包括原子性、一致性和持久性等。
5. 消息传输 ：负责支持多种消息传输协议，如 PING、PONG、EVICT 等。
6. 过程和脚本 ：负责支持各种复杂的数据操作，包括映射、排序、过滤等。
```
Redis 服务器源码非常庞大和复杂，如果要完整地研究和理解 Redis 的源码，需要有较强的编程能力和
C/C++语言基础。

###### 2 、了解 redis 集群吗？ 说说 redis 集群的功能和实现方式？

Redis 集群是由多个 Redis 实例构成的分布式系统，它能够扩展到非常大的数据集，并提供高可用性和负
载均衡功能。

**Redis 集群的功能作用：**

```
支持大规模数据存储 ：Redis 集群可以支持非常大的数据集，可以方便地对数据进行扩容。
分布式计算 ：Redis 集群可以将计算任务分配到不同的节点上进行计算，从而提高计算性能。
高可用性 ：当某个或某些节点发生故障时，Redis 集群可以自动将工作节点转移到其他节点上，从
而保证系统的高可用性。
```

```
负载均衡 ：Redis 集群可以根据哈希槽位映射功能，将数据分布到不同的节点上，从而实现负载均
衡。
```
**Redis 集群适合以下使用场景：**

```
对于需要存储大量数据并且需要进行读写操作的应用程序
高并发的 Web 应用程序，如电子商务、社交网络等。
大规模计算任务，如图像处理、视频处理等。
分散式数据存储。
```
**Redis 集群的两种主要的实现方式：**

**1. Redis Sentinel 实现**

Redis Sentinel 是一个特殊的 Redis 实例，它可以监控其他 Redis 实例的健康状态，并在发生故障时自动
进行故障转移。Redis Sentinel 通过主从复制实现故障转移，当主服务器出现故障时，Sentinel 会将一个
从服务器升级为新的主服务器，从而保证系统的高可用性。

Redis Sentinel 实现的优点是实现简单，只需要开启 Sentinel 服务即可；缺点是不支持数据的水平扩展，
通常适用于小规模集群环境。

**2. Redis Cluster 实现**

Redis Cluster 是 Redis 官方提供的集群实现方式，它采用分区（sharding）方式来保证系统的可扩展性
和高可用性，每个数据片段被存储在不同的节点上，从而实现水平扩展。

Redis Cluster 采用哈希槽位映射算法来对数据进行分片，每个节点负责一部分哈希槽位，当需要访问某
个键值对时，客户端会先计算该键的哈希值，然后根据哈希槽位映射算法找到负责该哈希槽位的节点，
从而实现负载均衡。

Redis Cluster 实现的优点是支持数据的水平扩展和自动故障转移等功能；缺点是实现相对复杂，需要在
多个节点上运行 Redis 实例，并进行相关配置。但是，在大规模集群环境下，Redis Cluster 是更为合适
的选择。

综上所述，Redis Sentinel 实现适合小规模集群环境，而 Redis Cluster 实现适合大规模集群环境。

###### 3 、说说，如何保证 MySQL 数据不丢？

保证 MySQL 数据不丢有多种方法，主要包括以下几点：

**1. 数据库备份：**

定期备份数据库，以防止数据丢失。可以使用 MySQL 自带的备份工具或者第三方备份工具来进行备
份。

**2. 数据库复制：**

使用 MySQL 的主从复制或者多主复制来进行数据备份和灾备。在主从复制中，主库写入数据后，从库
会自动同步数据。在多主复制中，多个主库之间相互同步数据。

**3. 数据库事务**

使用数据库事务来保证数据的一致性和完整性。在事务中，如果某个操作失败，整个事务会回滚到之前
的状态，从而保证数据不丢失。


**4. 数据库高可用：**

使用数据库集群或者主备架构来保证数据库的高可用性。
在集群或主备架构中，当一个节点出现故障时，可以自动切换到备用节点，从而保证服务的连续性和数
据的不丢失。

**5. 数据库监控：**

使用数据库监控工具来监控数据库的运行状态，及时发现并解决潜在的问题，从而保证数据的安全和可
靠性。

###### 4 、在读写分离的场景下，怎么保证从数据库读到最新的数据？

数据库读写分离，主要解决高并发时，提高系统的吞吐量。

读写分离数据库模型如下

```
写请求是直接写主库，然后同步数据到从库
读请求一般直接读从库，除非强制读主库
```
**怎么保证从数据库读到最新的数据**

**方案一：强制走主库**

● 写请求是直接写主库，然后同步数据到从库
● 读请求一般直接读从库，除非强制读主库


在高并发场景或者网络不佳的场景，如果存在较大的主从同步数据延迟，这时候读请求去读从库，就会
读到旧数据。这时候最简单暴力的方法，就是强制读主库。

**方案二：缓存标记法**

在高并发场景或者网络不佳的场景，如果存在较大的主从同步数据延迟，这时候读请求去读从库，就会
读到旧数据。这时候最简单暴力的方法，就是强制读主库。但是这样就违背了读写分离的初衷。

优化方案就是使用 **缓存标记法** ：

更新主库数据，并在缓存中设置一个标记，表示数据已更新。发起读请求，先判断数据已更新的标识，
在缓存中有更新标记。则走主库；如果没有，请求走从库。

**缓存标记法的执行流程如下：**

```
A 发起写请求，更新主库数据，并在缓存中设置一个标记，表示数据已更新，标记格式为：
userId+业务 Id。
设置此标记，设置过期时间（估值为主库和从库同步延迟的时间）
B 发起读请求，先判断此请求，在缓存中有没有更新标记。
如果存在标记，走主库；如果没有，请求走从库。
```
这个方案解决了数据不一致问题，但是每次请求都要先跟缓存打交道，会影响系统吞吐。

如何防止大流量请求把缓存击垮，可以引入多级缓存的架构。

关于多级缓存架构，请参见 40 岁老架构师尼恩的 100 W 三级缓存组件架构的原理和实操，那个非常重
要。


###### 5 、高并发下如何设计秒杀系统？

秒杀系统首先是一个分布式后台系统，首先来看看，如何设计一个分布式后台系统？

**一个分布式后台系统的设计要点**

何设计一个分布式后台系统主要从需要考虑以下几个方面：

**1. 架构设计** ：

秒杀系统需要采用分布式架构，将请求分散到多个服务器上，以提高系统的并发能力和稳定性。可以使
用负载均衡器来分发请求，使用缓存技术来减轻数据库的压力。

**2. 数据库设计** ：

秒杀系统需要采用高性能数据库，例如 Redis 等，来存储商品信息和用户订单信息。可以使用缓存技术
来减轻数据库的压力，同时使用数据库事务来保证数据的一致性和完整性。

**3. 接口设计** ：

秒杀系统需要设计高性能的接口，以应对高并发的请求。可以采用异步处理的方式，将请求放入消息队
列中，异步地处理请求，从而提高系统的并发能力。

**4. 安全设计** ：

秒杀系统需要采用安全措施，防止恶意攻击和刷单等行为。
可以采用验证码、IP 限制、用户限制等方式来保证系统的安全性和公平性。

**5. 系统测试** ：

秒杀系统需要进行充分的系统测试，包括压力测试、性能测试、安全测试等，以保证系统的可靠性和稳
定性。

**6. 业务设计** ：

秒杀系统需要设计合理的业务规则，例如限制每个用户的购买数量、限制每个商品的秒杀数量等，以保
证系统的公平性和可持续性。

综上所述，设计一个分布式后台系统，需要考虑多个方面，需要综合考虑系统的性能、安全、可靠性和
公平性等因素。

**一个高并发后台系统的设计要点**

秒杀系统首先是一个高并发后台系统，再来看看，在高并发的情况下，设计秒杀系统需要考虑那些问
题。

```
秒杀具有持续时间短和并发量大的特点，秒杀持续时间只有几分钟，而一般公司都为了制造轰动
效应，会以极低的价格来吸引用户，因此参与抢购的用户会非常的多，短时间内会有大量请求涌
进来。
```
一般在秒杀时间点（比如：双十一 12 点）前几分钟，用户并发量才真正突增，达到秒杀时间点时，并发
量会达到顶峰。活动是大量用户抢少量商品的场景，其实绝大部分用户秒杀会失败，只有极少部分用户
能够成功。

峰值持续的时间其实是非常短的，很容易出现瞬时高并发的情况，下面用一张图直观的感受一下流量的
变化：


像这种瞬时高并发的场景，传统的系统很难应对

所以，高并发秒杀，需要额外的从高并发、超高并发的维度，进行架构设计和架构优化：

**1. 限流：**

为了防止流量过大，造成系统崩溃或者无法正常使用，需要对流量进行限制。

使用限流措施来控制请求流量，可以保证系统的稳定性和可用性。

例如，使用令牌桶算法 (Token Bucket Algorithm) 或漏桶算法 (Leaky Bucket Algorithm) 来限制请求速
率。

为啥要限流呢？

很多刷子用户，并不会像我们一样老老实实，通过秒杀页面点击秒杀按钮，抢购商品。他们可能在自己
的服务器上，模拟正常用户登录系统，跳过秒杀页面，直接调用秒杀接口。

如果是我们手动操作，一般情况下，一秒钟只能点击一次秒杀按钮。

但是如果是服务器，一秒钟可以请求成上千接口。这种差距实在太明显了，如果不做任何限制，绝大部
分商品可能是被机器抢到，而非正常的用户，有点不太公平。


所以，我们有必要识别这些非法请求做一些限制。

目前有两种常用的限流方式：

```
基于 nginx 限流
基于 redis 限流
```
秒杀最终的本质是数据库的更新，但是有很多大量无效的请求，我们最终要做的就是如何把这些无效的
请求过滤掉，防止渗透到数据库。

**2. 降级：**

为了避免高并发导致系统崩溃，可以采用降级策略，即当系统压力过大时，降低系统的并发量，保证系
统的稳定性。

**3. 数据库分库分表：**

为了提高系统的性能，可以采用数据库分库分表的方式，将数据拆分成多个表，以提高查询效率。

**4. 缓存：**

为了减轻数据库的负载，可以采用缓存的方式，将一些热门数据缓存在内存中，加快查询速度。

使用缓存技术来减轻数据库的负担，可以提高系统的性能和可用性。例如，使用 Redis 或 Memcached 等
内存缓存来缓存热点数据，减少数据库的访问次数。

**5. 异步：**

为了避免阻塞主线程，可以采用异步的方式，将一些耗时的操作放到子线程中，避免阻塞主线程。

使用异步处理来处理大量请求，可以提高系统的吞吐量和响应速度。例如，使用 mq 异步处理来处理请
求。

我们都知道在真实的秒杀场景中，有三个核心流程：

而这三个核心流程中，真正并发量大的是秒杀功能，下单和支付功能实际并发量很小。

所以，我们在设计秒杀系统时，有必要把下单和支付功能从秒杀的主流程中拆分出来，特别是下单功能
要做成 mq 异步处理的。而支付功能，比如支付宝支付，是业务场景本身保证的异步。

于是，秒杀后下单的流程变成如下：


为了提升下单的效率，并且防止下单服务的失败。

需要将下单这一操作进行异步处理。最常采用的办法是使用消息队列，消息队列最显著的三个优点：异
步、削峰、解耦。这里可以采用 RocketMQ，在后台经过了限流、库存校验之后，流入到这一步骤的就
是有效请求。

然后发送到队列里，队列接受消息，异步下单。

下完单，入库没有问题可以用短信通知用户秒杀成功。假如失败的话，可以采用补偿机制，重试。

**6. CDN 加速的页面静态化**

秒杀详情页面是用户流量的第一入口，所以是并发量最大的地方。

如果这些流量都能直接访问服务端，恐怕服务端会因为承受不住这么大的压力，而直接挂掉。

秒杀详情页面绝大多数内容是固定的，比如：商品名称、商品描述、图片等。为了减少不必要的服务端
请求，通常情况下，会对秒杀详情页面做静态化处理。

用户浏览商品等常规操作，并不会请求到秒杀服务端。只有到了秒杀时间点，并且用户主动点了秒杀按
钮才允许访问秒杀服务端。这样能过滤大部分无效页面请求。

但只做页面静态化还不够，因为用户分布在全国各地，有些人在北京，有些人在成都，有些人在深圳，
地域相差很远，网速各不相同。

为了性能考虑，一般会将 css、js 和图片等静态资源文件提前缓存到 CDN 上，它的全称是 Content
Delivery Network，即内容分发网络。


CDN 让用户能够就近访问秒杀页面, 降低网络拥塞，提高用户访问响应速度和命中率。

**7. 安全措施：**

采取安全措施来保护系统的安全性，包括防止 SQL 注入、XSS 攻击等。例如，对用户输入的数据进行过
滤和验证，使用 SSL/TLS 加密通信等。

**8. 监控和报警：**

为了及时发现系统的异常情况，可以采用监控和报警的方式，及时发现和解决问题。

**秒杀业务的架构难题**

从业务视角，再来看看，秒杀系统有哪些特殊的业务架构难题：

```
库存超卖问题
秒杀 url 的接口防刷
库存高并发扣减问题
```
**1. 库存超卖问题**

分析秒杀的业务场景, 最重要的有一点就是超卖问题，

在多个用户同时发起对同一个商品的下单请求时，先查询商品库存，再修改商品库存，会出现资源竞争
问题，导致库存的最终结果出现异常。问题：
当商品 A 一共有库存 15 件，用户甲先下单 10 件，用户乙下单 8 件，这时候库存只能满足一个人下单成
功，如果两个人同时提交，就出现了超卖的问题。

常见的解决的三种方案

```
悲观锁
```
通过悲观锁解决超卖

```
乐观锁
```
通过乐观锁解决超卖

```
异步分段锁方案
```
通过分段执行的排队方案解决超卖

悲观锁和乐观锁的性能都比较低。尼恩在这里，重点介绍高性能版本的异步分段锁方案。

**分阶段排队下单方案**

将提交操作变成两段式：

```
第一阶段申请，申请预减减库，申请成功之后，进入消息队列；
第二阶段确认，从消息队列消费申请令牌，然后完成下单操作。查库存 -> 创建订单 -> 扣减库
存。通过分段锁锁保障解决多个 provider 实例并发下单产生的超卖问题。
```
**申请阶段：**

将存库从 MySQL 前移到 Redis 中，所有的预减库存的操作放到内存中，由于 Redis 中不存在锁故不会出现
互相等待，并且由于 Redis 的写性能和读性能都远高于 MySQL，这就解决了高并发下的性能问题。

**确认阶段：**


然后通过队列等异步手段，将变化的数据异步写入到 DB 中。

引入队列，然后数据通过队列排序，按照次序更新到 DB 中，完全串行处理。当达到库存阀值的时候就
不在消费队列，并关闭购买功能。这就解决了超卖问题。

**异步分段锁架构图**

**基于异步分段锁的性能提升**

一个高性能秒杀的场景：

```
假设一个商品 1 分钟 6000 订单，每秒的 600 个下单操作。
```
```
在排队阶段，每秒的 600 个预减库存的操作，对于 Redis 来说，没有任何压力。甚至每秒的 6000
个预减库存的操作，对于 Redis 来说，也是压力不大。
但是在下单阶段，就不一样了。假设加锁之后，释放锁之前，查库存 -> 创建订单 -> 扣减库存，
经过优化，每个 IO 操作 100 ms，大概 200 毫秒，一秒钟 5 个订单。 600 个订单需要 120 s， 2 分钟才
能彻底消化。
```
如何提升下单阶段的性能呢？

**可以使用 Redis 分段锁。**

为了达到每秒 600 个订单，可以将锁分成 600 /5 =120 个段，每个段负责 5 个订单， 600 个订单，在第二
个阶段 1 秒钟下单完成。


有关 Redis 分段锁的详细知识，请阅读下面的博文：

Redis 分布式锁 （图解-秒懂-史上最全）

**基于异步分段锁优点：**

解决超卖问题，库存读写都在内存中，故同时解决性能问题。

**基于异步分段锁缺点：**

```
数据不一致的问题：
```
由于异步写入 DB，可能存在数据不一致，存在某一时刻 DB 和 Redis 中数据不一致的风险。

```
可能存在少买
```
可能存在少买，也就是如果拿到号的人不真正下订单，可能库存减为 0 ，但是订单数并没有达到库存阀
值。

**2. 秒杀 url 的接口防刷问题**

对于普通用户来讲，看到的只是一个比较简单的秒杀页面，在未达到规定时间，秒杀按钮是灰色的，一
旦到达规定时间，灰色按钮变成可点击状态。这部分是针对小白用户的，如果是稍微有点电脑功底的用
户，会通过 F 12 看浏览器的 network 看到秒杀的 url，通过特定软件去请求也可以实现秒杀。或者提前知
道秒杀 url 的人，一请求就直接实现秒杀了。

这个问题我们需要考虑解决。

现在的秒杀大多都会出来针对秒杀对应的软件，这类软件会模拟不断向后台服务器发起请求，一秒几百
次都是很常见的，如何防止这类软件不断发起的的重复无效请求进行限流，是我们需要认真考虑的。

接口防刷的话，需要入手的方面很多：

**（ 1 ）前端限流**

首先第一步就是通过前端限流，用户在秒杀按钮点击以后发起请求，那么在接下来的 5 秒是无法点击
（通过设置按钮为 disable）。这一小举措开发起来成本很小，但是很有效。

**（ 2 ）同一个用户 xx 秒内重复请求直接拒绝**

具体多少秒需要根据实际业务和秒杀的人数而定，一般限定为 10 秒。


具体的做法就是通过 Redis 的键过期策略，首先对每个请求都从 String value = redis.get (userId);

如果获取到这个 value 为空或者为 null，表示它是有效的请求，然后放行这个请求。如果不为空表示它是
重复性请求，直接丢掉这个请求。

如果有效，采用 redis.setexpire (userId, value, 10). value 可以是任意值，一般放业务属性比较好，这个是
设置以 userId 为 key， 10 秒的过期时间（ 10 秒后，key 对应的值自动为 null）。

**（ 3 ）对同一 ip 限流**

有时候只对某个用户限流是不够的，有些高手可以模拟多个用户请求，这时需要用 Nginx 加同一 ip 限流
功能。

**（ 4 ） 加验证码**

通常情况下，用户在请求之前，需要先输入验证码。用户发起请求之后，服务端会去校验该验证码是否
正确。只有正确才允许进行下一步操作，否则直接返回，并且提示验证码错误。

此外，验证码一般是一次性的，同一个验证码只允许使用一次，不允许重复使用。

**（ 5 ）业务层检查**

业务服务层进行订单的数量检查，一个用户超过设置的订单数量，下单失败。

**3. 库存高并发扣减问题**

很多请求进来，都需要后台查询库存, 这是一个频繁读的场景。

可以使用 Redis 来预减库存，在秒杀开始前可以在 Redis 设值，比如 redis.set (goodsId, 100)，这里预放的
库存为 100 可以设值为常量，每次下单成功之后，Integer stock = (Integer) redis.get (goosId);

然后判断 sock 的值，如果小于常量值就减去 1 ；

不过注意当取消的时候，需要增加库存，增加库存的时候也得注意不能大于之间设定的总库存数（查询
库存和扣减库存需要原子操作，此时可以借助 lua 脚本）下次下单再获取库存的时候，直接从 Redis 里面
查就可以了。

###### 6 、说说，object 类你所知道的方法？

Object 类是所有 Java 类的基类，它里面定义了一些通用的方法，如下：

```
1. equals () 方法 ：判断两个对象是否相等。该方法默认使用"=="运算符进行比较，但可以通过重写该
方法实现自定义的对象比较。
2. hashCode () 方法 ：返回一个对象的哈希码值。哈希码值是根据对象的内部状态计算出来的一个整
数，具有唯一性和稳定性。
3. toString () 方法 ：返回一个字符串表示对象的信息。默认情况下，该方法返回对象所在的类名和内
存地址，但可以通过重写该方法实现自定义的对象信息输出
4. getClass () 方法 ：返回一个对象所属的类。该方法可以用于获取对象的运行时类型信息。
5. wait ()、notify ()、notifyAll () 方法 ：这三个方法用于线程间的协作，其中 wait () 方法使当前线程
进入阻塞状态，直到其他线程调用该对象的 notify () 或 notifyAll () 方法唤醒它。
```

```
6. finalize () 方法 ：该方法由垃圾回收器调用，用于清理不再使用的对象。一般情况下，该方法不需
要手动调用。
7. clone () ：创建并返回一个与原始对象相同类型和状态的新对象。
```
除此之外，Object 类还提供了许多其他的静态方法和构造方法，例如：

```
1. getDeclaredFields () ：返回指定类的所有字段，但不包括父类的字段。
2. getDeclaredMethods () ：返回指定类的所有方法，但不包括父类的方法。
3. getConstructors () ：返回指定类的所有构造方法。
4. newInstance () ：使用给定的参数创建一个新的实例。
```
###### 7 、用过分布式事务嘛？什么场景用分布式事务，有其他方案嘛？

在分布式环境下开发时，经常会遇到分布式事务问题。

分布式事务是一种解决分布式系统中的事务一致性问题的方案。在分布式系统中，由于各个节点之间的
数据存储和处理是分离的，因此容易出现数据不一致的问题。

而分布式事务可以确保在分布式系统中的多个节点之间进行的多个操作的原子性、一致性和持久性，从
而保证分布式系统的可靠性和可用性。

简单点来说，分布式事务是指涉及到多个数据库或应用服务器的事务，需要保证所有操作都要么全部成
功，要么全部失败。

通常情况下，业务项目上，基本上的分布式事务可以使用以下两种方式实现：

**1. 两阶段提交（2 PC）**

2 PC 是一种经典的分布式事务协议，它将分布式事务划分为两个阶段：准备阶段和提交阶段。在准备阶
段，各参与节点进行数据校验，并向一个协调器发送是否同意提交事务的消息；在提交阶段，协调器向
各个参与节点发送提交请求，参与节点执行事务并向协调器发送完成消息。

2 PC 方案的优点是简单易懂，适用于较小规模的分布式事务场景，但它存在单点故障风险和性能瓶颈等
问题。

**2. TCC 事务**

TCC 事务是一种比较新颖的分布式事务方案，它将事务分为 Try、Confirm、Cancel 三个阶段，分别对应
资源预留、执行确认、异常撤销等操作。TCC 事务通过代码层面的控制，实现了无锁化和高性能的分布
式事务处理。

TCC 方案的优点是性能较好，且没有 2 PC 的单点故障问题，但需要开发人员自己实现事务控制逻辑，实
现较为复杂。

总之，在分布式环境下需要使用分布式事务方案来保证多个节点间数据的一致性。2 PC 和 TCC 都是比较
常用的方案，需要根据具体业务场景选择合适方案。

**什么场景用分布式事务，有其他方案嘛？**

一般在保证数据的一致性和可靠性的高并发、分布式场景，使用分布式事务，比如秒杀系统中，通常会
使用分布式事务来保证数据的一致性和可靠性。


使用分布式事务的主要原因是，在高并发场景下，如果每个请求都直接访问数据库，可能会出现数据不
一致的情况。例如，当一个用户同时下单和支付时，如果这两个操作分别被不同的请求处理，就可能出
现订单信息不完整或者支付失败的情况。而使用分布式事务可以将多个操作打包成一个事务，确保这些
操作要么全部提交成功，要么全部回滚失败。

除了分布式事务，还有一些其他的方案可以用于实现高并发场景下的秒杀系统。

其中一些方案包括：

```
1. 分布式锁 ：使用分布式锁来控制对某些资源的操作顺序，以避免多个请求同时访问同一资源。例
如，使用 Redis 等内存数据库来实现分布式锁。
2. 异步处理+ 定时任务补偿 ：使用异步处理来处理大量请求，可以提高系统的吞吐量和响应速度。例
如，使用消息队列 (如 Kafka) 或异步处理框架 (如 Redis Cluster) 来处理请求。然后使用定时任务来进
行数据一致性的扫描，一旦发现数据不一致，就行补偿，甚至预警。
```
总之，如何使用分布式事务，是否使用分布式事务，决于具体的业务需求和系统架构设计。

在实际应用中，通常需要综合考虑多个因素来选择最合适的方案。

###### 8 、分布式事务有几种解决方案？

分布式事务是指涉及到多个数据库或应用服务器的事务，需要保证所有操作要么全部成功，要么全部失
败。为了解决这种问题，目前主要有以下几种分布式事务解决方案：

**1. 两阶段提交（2 PC）**

2 PC 是最经典的分布式事务协议之一，它将分布式事务划分为两个阶段: 准备阶段和提交阶段。在准备
阶段，各参与节点进行数据校验，并向协调器发送是否同意提交事务的消息；在提交阶段，协调器向各
个参与节点发送提交请求，参与节点执行事务并向协调器发送完成消息。

2 PC 方案的优点是较为简单易懂，适用于较小规模的分布式事务场景。但是，它存在单点故障风险和性
能瓶颈等问题。

**2. TCC 事务**

TCC 事务是一种相对新颖的分布式事务方案，它将事务分为 Try、Confirm、Cancel 三个阶段，分别对应
资源预留、执行确认、异常撤销等操作。TCC 事务通过代码层面的控制，实现了无锁化和高性能的分布
式事务处理。

TCC 方案的优点是性能较好，且没有 2 PC 的单点故障问题，但需要开发人员自己实现事务控制逻辑，实
现较为复杂。

**3. Saga 事务**

Saga 事务是一种将分布式事务拆解为多个本地事务的方案，它通过在各个本地事务之间传递消息，最终
完成整个分布式事务。Saga 事务与 2 PC 和 TCC 不同，它可以实现更加灵活的事务处理，但需要开发人员
自行设计和实现事务处理逻辑。

**4. 消息队列**

消息队列是一种异步通信方式，可以通过消息队列来保证数据的最终一致性。在分布式事务中，可以使
用消息队列将事务处理过程异步化，从而提高系统的并发能力和可靠性。

综上所述，分布式事务有 2 PC、TCC、Saga 事务和消息队列等多种解决方案。需要根据具体业务场景选
择合适的方案。


###### 12 、JDK 6、 7 、 8 分别提供了哪些新特性

JDK 6、 7 、 8 提供了许多不同的新特性，以下是其中一些的详细说明：

JDK 6 新特性：

```
1. JSR 223 ：将脚本语言集成到 Java 应用程序中。
2. JAX-WS 2.0 ：更好的 Web 服务支持。
3. JAXB 2.0 ：更好的 XML 数据绑定和解析支持。
4. 并发 API 增强 ：包括 java. util. concurrent 包的新增类和接口，如 ConcurrentHashMap，并发集合
等。
5. 插入式注解处理 API（APT） ：可用于在构建过程中生成源代码。
```
JDK 7 新特性：

```
1. 新的二进制字面量 ：可以使用 0 b 或 0 B 前缀表示二进制数字，并且可以使用下划线分隔数字，例如
0 b 1011_0010。
2. switch 语句支持字符串 ：可以使用字符串作为 switch 语句的参数。
3. try-with-resources 语句 ：可以自动关闭实现 java. lang. AutoCloseable 接口的资源。
4. 数值字面量下划线 ：可以使用下划线分隔数字，例如 1_000_000。
5. 简化泛型类型声明 ：可以通过“<>”来省略泛型类型声明。
6. 动态语言支持 ：支持动态语言，如 Groovy、Ruby 等。
```
JDK 8 新特性：

```
1. Lambda 表达式 ：可以使用 Lambda 表达式实现函数式编程风格。
2. 方法引用 ：可以使用方法引用来引用现有的方法。
3. 接口默认方法 ：可以在接口中定义默认方法。
4. Stream API ：可以使用 Stream API 实现数据流式处理。
5. 新的日期/时间 API ：引入了新的日期和时间 API，比原有的 Date 和 Calendar 类更加易于使用。
6. 对 Nashorn JavaScript 引擎的支持 ：可以使用 Nashorn 引擎来运行 JavaScript 代码。
```
总之，JDK 6、 7 、 8 提供了许多不同的新特性，包括并发 API 增强、Lambda 表达式、Stream API、新的
日期/时间 API 等。这些新特性可以帮助 Java 开发人员更加高效和方便地开发应用程序。

###### 13 、说一下 https 原理，它的工作流程呢？

HTTPS（Hyper Text Transfer Protocol Secure）是一种通过加密和认证来保护网络通信安全的协议。
它是 HTTP 的安全版，可以有效地防止黑客窃听、中间人攻击等网络安全问题，广泛应用于电子商务、
在线支付、社交媒体等领域。

HTTPS 的原理可以简单概括为：使用公开密钥加密算法对数据进行加密，确保数据在传输过程中不被窃
取或篡改；使用数字证书验证服务端身份，确保用户连接的是正规的服务器。

HTTPS 的工作流程如下：

```
1. 建立连接 ：客户端向服务器发送一个请求，请求中包含了要访问的资源的 URL。
2. SSL 握手 ：当服务器接收到请求后，会返回一个数字证书，证书中包含了服务器公钥。客户端收到
证书后，会对证书进行验证，如果验证通过，就会生成一个随机数并用服务器公钥加密，将加密后
的随机数和自己的私钥一起发送给服务器。服务器收到后，使用自己的私钥解密该随机数，得到客
户端发送的随机数。之后，双方会交换证书和密钥，用于后续的数据加密和解密。
```

```
3. 发送 HTTPS 请求 ：在 SSL 握手完成后，客户端会发送一个 HTTPS 请求到服务器。此时，HTTP 和
HTTPS 是分开的两个协议，需要进行切换。切换的过程是通过 TLS 协议实现的。TLS 协议会在客户
端和服务器之间建立一条安全通道，用于加密数据传输。
4. 发送 HTTP 请求 ：在 TLS 连接建立成功后，客户端会再次发送一个 HTTP 请求到服务器。此时，客户
端和服务器之间的通讯都是加密的。
5. 接收 HTTP 响应 ：服务器接收到请求后，处理完业务逻辑后会返回一个 HTTP 响应给客户端。此
时，客户端和服务器之间的通讯也是加密的。
6. 接收 HTTPS 响应 ：客户端接收到 HTTPS 响应后，会对响应进行解密，得到实际的响应内容。
```
总之，HTTPS 通过 SSL/TLS 协议对数据传输进行了加密和解密，保证了通信的安全性。

```
关于 Https 协议的底层原理和抓包分析，请参见尼恩《Java 高并发核心编程卷 1 加强版》 PDF。
最新消息，尼恩三部曲+面试题，帮助小伙伴涨薪一倍多。
```
###### 14 、Redis 的持久化？有哪些方式，原理是什么？

Redis 的持久化是指将 Redis 中的数据写入磁盘，以便在 Redis 重启后能够恢复数据。Redis 提供了两种持
久化方式：RDB 和 AOF。

**1. RDB 持久化**

RDB 持久化是将 Redis 在内存中的数据定期 dump 到磁盘中，生成一个 RDB 文件。RDB 文件是一个二进制
文件，包含了 Redis 在某个时间点上的数据快照。RDB 文件的生成可以手动触发，也可以通过配置文件
设置定期自动触发。

RDB 持久化的原理是 Redis 会 fork 出一个子进程，将数据写入到一个临时文件中，然后将临时文件替换
为旧的 RDB 文件。在这个过程中，Redis 会将所有新的写操作缓存在内存中，直到持久化完成后再将缓
存的写操作应用到新的 RDB 文件中。

**2. AOF 持久化**

AOF 持久化是将 Redis 的写操作以追加的方式写入到一个日志文件中，即 AOF 文件。AOF 文件是一个文本
文件，包含了 Redis 的所有写操作，以及执行这些操作所需的参数。AOF 文件的生成可以手动触发，也
可以通过配置文件设置定期自动触发。

AOF 持久化的原理是 Redis 会将所有新的写操作追加到 AOF 文件中，当 AOF 文件过大时，Redis 会自动执
行一次重写操作，将 AOF 文件中的冗余操作删除，从而减小 AOF 文件的大小。

总的来说，RDB 持久化和 AOF 持久化各有优劣。RDB 持久化的优点是生成的文件较小，恢复数据的速度
较快；而 AOF 持久化的优点是数据的完整性更好，可以做到每秒钟一次的持久化，从而减少数据的丢
失。在实际使用中，可以根据实际情况选择适合自己的持久化方式。

###### 15 、谈谈你对 volatile 关键字作用？

volatile 是 Java 中的一种关键字，用于确保多线程环境下变量的可见性和有序性。

在多线程编程中，使用 volatile 可以解决一些内存可见性和指令重排序问题，从而避免了一些难以调试
和排查的问题。

**作用** ：


```
1. 可见性：当一个变量被定义为 volatile 时，它会保证所有线程都能够看到该变量的最新值。
2. 禁止指令重排序：当一个变量被定义为 volatile 时，JVM 会禁止对它进行指令重排序操作，从而保
证程序的正确性。
```
**原理** ：

在 Java 内存模型中，每个线程都有自己的工作内存和主内存。当一个线程要读取共享变量的值时，它会
先将该变量的值从主内存中复制到自己的工作内存中，然后再执行操作；当一个线程要写入共享变量的
值时，它会先将该变量的值写入自己的工作内存中，然后再将其刷新到主内存中。

volatile 关键字通过以下两种方式保证多线程环境下的可见性和有序性：

```
1. 写入 volatile 变量时，JVM 会立即将其更新到主内存中，这样就保证了其他线程可以及时看到最新
的值。
2. 读取 volatile 变量时，JVM 会从主内存中读取最新的值，而不是使用工作内存的值。这样就保证了
线程之间共享变量时的可见性和有序性。
```
需要注意的是，volatile 只能保证单个变量的原子性操作，对于复合操作或者涉及多个变量的操作，还
需要使用 synchronized 等同步机制来保证线程安全。

总之，volatile 关键字可以保证多线程环境下变量的可见性和有序性，通过将变量的值立即更新到主内
存中来实现。在多线程编程中，使用 volatile 可以提高程序的并发性和可靠性。

```
关于 java jmm volatile 的实现原理，请参见尼恩《Java 高并发核心编程卷 2 加强版》 PDF。最
新消息，尼恩三部曲+面试题，帮助小伙伴涨薪一倍多。
```
###### 16 、讲讲 java jmm volatile 的实现原理？

Java 中的 JMM（Java 内存模型）是一种规范，用于定义多线程程序中的内存访问行为。它确保了多线程
程序的正确性和可见性，从而避免了常见的线程安全问题。

在 JMM 中，volatile 是一种关键字，用于确保变量的可见性和顺序性。当一个变量被声明为 volatile 时，
它的值将始终从主存中读取，而不是从线程的本地缓存中读取。当一个线程修改了一个 volatile 变量的
值时，这个值将立即被写回主存中，而不是在一段时间后才被写回。

volatile 的实现原理是通过内存屏障（memory barrier）来实现的。

内存屏障是一种硬件或软件机制，用于确保内存操作的顺序性和可见性。

在 Java 中，volatile 变量的读写操作会被编译器和 CPU 优化，为了确保操作的顺序性和可见性，Java 会在
编译时和运行时插入内存屏障。

具体来说，当一个线程访问一个 volatile 变量时，它会执行一个 load 指令，这个指令会强制从主存中读
取变量的值，并将其存储在线程的本地缓存中。当一个线程修改一个 volatile 变量的值时，它会执行一
个 store 指令，这个指令会强制将变量的值写回主存中。在这些指令周围，Java 会插入内存屏障，确保指
令的顺序性和可见性。

总之，volatile 通过内存屏障来实现变量的可见性和顺序性，从而确保了多线程程序的正确性和可靠
性。


```
关于 java jmm volatile 的实现原理，请参见尼恩《Java 高并发核心编程卷 2 加强版》 PDF。最
新消息，尼恩三部曲+面试题，帮助小伙伴涨薪一倍多。
```
###### 17 、在秒杀场景中，常用的限流算法有哪些？

秒杀场景是指在短时间内出现高并发请求的情况，为了保护系统的稳定性，需要对请求进行限流。常用
的限流算法有以下几种：

**1. 令牌桶算法**

令牌桶算法是一种固定窗口限流算法，它通过令牌桶来控制请求的频率。令牌桶中会不断产生令牌，并
将其放入桶中，每当一个请求到达时，就从桶中获取一个令牌，如果桶中没有令牌，则请求被拒绝。

**2. 漏桶算法**

漏桶算法也是一种固定窗口限流算法，它通过一个带有固定速率的漏桶，来控制请求的频率。当请求到
达时，先进入漏桶中，然后以固定速率流出，如果漏桶已满，则请求被拒绝。

**3. 计数器算法**

计数器算法是一种简单的限流算法，它通过记录请求次数和时间戳，来控制请求的频率。当请求到达
时，判断当前时间与最近一次请求的时间差是否小于设定阈值，如果小于，则请求被拒绝。

总之，在秒杀场景中，需要对请求进行限流来保护系统的稳定性。常用的限流算法有令牌桶算法、漏桶
算法、计数器算法等，需要根据实际情况选择合适的算法。

###### 18 、讲一讲 7 层网络模型，tcp 为什么要三次握手

七层网络模型是一种分层的网络模型，它将网络分为七个层次，每一层都有自己的功能和特点。其中，
最底层的是物理层，它主要负责将比特流转换为电信号，并进行物理传输。

TCP/IP 协议是一种常用于网络通信的协议，它由四个层次组成，分别是应用层、传输层、网络层和数据
链路层。其中，传输层是一个非常重要的层次，它负责在不同的网络之间传递数据，并保证数据的可靠
传输。

在传输层中，TCP 协议使用三次握手来确保数据的可靠传输。这三次握手分别是：

```
1. 第一次握手 ：客户端向服务器发送一个 SYN 数据包，表示客户端想要建立一个 TCP 连接。服务器
收到 SYN 数据包后，会向客户端发送一个 SYN+ACK 数据包，确认客户端的请求，同时也表示服
务器愿意建立这个连接。
2. 第二次握手 ：客户端收到服务器的 SYN+ACK 数据包后，会向服务器发送一个 ACK 数据包，确认
服务器的请求。
3. 第三次握手 ：服务器收到客户端的 ACK 数据包后，会向客户端发送一个 FIN 数据包，表示服务器
已经接受到客户端发送的数据，并且会等待客户端发送最后一个 ACK 数据包。
```
这三次握手的过程中，客户端和服务器会交换很多数据包，但是每一次握手都是独立的，即每一次握手
只传输一个数据包。只有当三次握手都成功完成后，客户端和服务器才会建立起一个 TCP 连接，并开始
传输数据。


通过三次握手，TCP 协议可以确保数据的可靠传输，即使在数据传输过程中出现了一些问题，TCP 协议
也可以通过重新发送数据包来恢复数据的传输。这也是 TCP 协议被广泛使用的重要原因之一。

###### 20 、说说线程池它的工作原理

线程池是一种常见的线程管理机制，它可以提高线程的利用率和性能，并且可以避免线程创建和销毁的
开销。线程池中包含一组可重用的线程，这些线程可以被多个任务共享，从而减少了线程创建和销毁的
开销。当有新的任务到来时，线程池会从池中取出一个空闲的线程来执行任务，当任务执行完成后，线
程会返回到池中，等待下一个任务的到来。

线程池的工作原理如下：

```
1. 当线程池被创建时，会初始化一定数量的线程，并将它们放入线程池中。
2. 当有新的任务到来时，线程池会从池中取出一个空闲的线程来执行任务。
3. 如果池中没有空闲线程，线程池会根据预设的策略来创建新的线程，或者等待有线程空闲为止。
4. 当任务执行完成后，线程会返回到池中，等待下一个任务的到来。
```
线程池的优点主要有以下几点：

```
1. 提高程序性能 ：线程池可以减少线程创建和销毁的开销，从而提高程序的性能。
2. 提高线程利用率 ：线程池可以避免线程因等待任务而处于空闲状态，从而提高线程的利用率。
3. 提高程序可靠性 ：线程池可以避免因线程创建和销毁的错误而导致程序出错。
4. v 提高程序可扩展性**：线程池可以根据需要动态调整线程的数量，从而提高程序的可扩展性。
```
总之，线程池是一种非常有用的线程管理机制，它可以提高程序的性能、可靠性和可扩展性，是多线程
编程中不可缺少的一部分。

```
关于线程池它的工作原理，请参见尼恩《Java 高并发核心编程卷 2 加强版》 PDF。最新消息，
尼恩三部曲+面试题，帮助小伙伴涨薪一倍多。
```
###### 21 、说说：JVM 内存模型

首先，说一下概念误区，jvm 内存模型很容易被误解为 JvM 内存结构。

JVM 内存结构是指 Java 程序在运行时所使用的内存结构和组织方式。Java 虚拟机在执行 Java 程序的过程
中会把它所管理的内存区域划分为若干个不同的数据区域。这些区域都有各自的用途，以及创建和销毁
的时间，有些区域随着虚拟机进程的启动而存在，有些区域则是依赖线程的启动和结束而建立和销毁。

Java 虚拟机所管理的内存被划分为如下几个区域：

```
1. 程序计数器 (Program Counter Register): 用于记录当前线程执行到哪一条指令，是线程私有的内存
区域。
2. Java 虚拟机栈 (Java Virtual Machine Stacks): 每个线程都有一个 Java 虚拟机栈，用于存储方法调用
的局部变量表、操作数栈、动态链接、方法返回值等信息。Java 虚拟机栈也是线程私有的内存区
域。
3. 堆 (Heap): 用于存储对象实例和数组等数据结构，是所有线程共享的内存区域。堆可以分为新生代
和老年代两个部分，根据对象的生命周期进行垃圾回收。
4. 方法区 (Method Area): 用于存储已被加载的类的信息、常量、静态变量等数据，也是所有线程共享
的内存区域。方法区也称为永久代 (Permanent Generation), 已经被标记为过时，现在被元空间
```

```
(Metaspace) 取代。
5. 本地方法栈 (Native Method Stack): 用于存储本地方法的调用信息，与 Java 虚拟机栈类似，但是它
是为虚拟机内部使用而设计的。
```
和 jvm 内存结构不同，JVM（Java Virtual Machine）内存模型定义了 Java 程序中各种变量的访问规则，
包括变量的读取、写入和同步等操作，以确保多线程程序的正确性和可靠性。

JVM 内存模型主要分为两个部分：线程工作内存和主内存。

线程工作内存是每个线程独有的内存区域，它包含了线程执行时所需要的所有变量和对象，以及线程执
行的指令集。每个线程都有自己的工作内存，线程之间的变量不共享，因此线程之间的通信需要通过主
内存来进行。

主内存是所有线程共享的内存区域，它包含了所有的变量和对象。当一个线程需要访问某个变量时，它
首先需要将变量从主内存中读取到自己的工作内存中，然后对变量进行操作。操作完成后，线程需要将
变量的值写回主内存，以便其他线程可以看到这个变量的最新值。

JVM 内存模型通过锁和内存屏障等机制来确保多线程程序的正确性和可靠性。锁用于同步多个线程对共
享变量的访问，内存屏障用于保证变量的可见性和顺序性。在 Java 中，volatile 关键字可以用来保证变量
的可见性和顺序性，synchronized 关键字可以用来保证线程的互斥和同步，而 Lock 接口和 Atomic 类可
以用来实现更灵活的同步机制。

```
关于 jvm 内存模型原理，请参见尼恩《Java 高并发核心编程卷 2 加强版》 PDF。最新消息，尼恩
三部曲+面试题，帮助小伙伴涨薪一倍多。
```
###### 22 、说说 JVM 垃圾回收机制（GC 机制；老年代和年轻代的含义）


垃圾回收机制是 Java 程序中非常重要的一部分，它可以自动地处理程序中不再使用的对象，从而避免内
存泄漏的问题。

Java 中有两种垃圾回收机制：

```
1. 标记-清除垃圾回收机制（Mark-Sweep GC）：这是 Java 早期的垃圾回收机制，使用标记-清除的方
式来回收内存。标记过程中，Java 虚拟机会给所有可达对象分配一个标记，标记的对象会被回收。
清除过程中，Java 虚拟机会扫描整个内存区域，找出所有未被标记的对象，然后将它们清除。
2. 复制垃圾回收机制（Copy-on-Write GC）：这是 Java 最新的垃圾回收机制，使用复制-分发的方式
来回收内存。在这种机制中，Java 虚拟机会将内存划分为两个部分，一部分是新生代（Young
Generation），一部分是老年代（Old Generation）。新生代中的对象会被复制到老年代中，当
老年代满了之后，Java 虚拟机会将老年代中的对象复制到新生代中。这样就可以保证新生代中始终
有一部分空间可以使用，而老年代中的对象可以被回收。
```
Java 中的内存分代模型：

**1. 内存分代模型**

分代模型并不是一种垃圾回收算法，而是一种内存管理模型。

将 java 中的内存分为不同区域，在 GC 时不同区域采用不同的算法，提高回收效率。

内存分代模型将 java 堆内存中的区域分成两部分新生代（new）和老年代（old），两块区域的默认比例
为1:2。

新生代：新生代中的对象被使用过，并且被引用过。

老年代：一旦新对象生成，就会被放入老年代中。老年代中的对象没有被使用过，也没有被引用过。

新生代又分为一个伊甸园区（eden）和两个存活区（survivor），s 0 和 s 1，默认比例为8:1:1

新生代的 GC 被称为 YGC/MinorGC，老年代的 GC 被称为 Full GC/MajorGC。

**2. 分代垃圾回收算法**

```
新对象出生在 eden 中，对象过大在 eden 装不下则直接进入老年代
第一次 YGC：新生代对象大多数会被回收（80%-90%），剩余活着的对象会被复制到 s 0 区，清空
eden
第二次 YGC：把活着的对象（eden+s 0 区）到复制到 s 1 区，清空 eden 和 s 0
再次 YGC：把活着的对象（eden+s 1 区）到复制到 s 0 区，清空 eden 和 s 1
每经过一次 GC，没有被回收的对象年龄+1，当存活对象到达一定年龄后，新生代对象进入老年代
（一般是 15 ，CMS 回收器默认是 6 ，其他垃圾回收器是 15 ）
YGC 复制时，如果对象过大，s 区装不下也会直接将对象拷贝到老年代。
```
垃圾回收的过程一般是由 Java 虚拟机自动进行的，开发人员不需要手动干预。

但是，开发人员可以通过设置垃圾回收的参数来控制垃圾回收的频率和方式。垃圾回收机制对于 Java 程
序的性能和稳定性都非常重要，需要开发人员认真对待。

###### 23 、类加载机制和双亲委派模型


类加载机制是指 Java 虚拟机 (JVM) 如何加载和链接 Java 程序中的类。在 Java 中，类的加载和链接是由 JVM
负责完成的，JVM 会在运行时动态地将类加载到内存中，并进行链接、初始化等操作。

**类加载机制指的是：虚拟机将描述类的数据从 class 文件加载到内存中，对加载的数据进行验证，解
析，初始化，最后得到虚拟机认可后转化为直接可以使用的 java 类型的过程**

类加载机制一共有七个阶段：加载，验证，准备，解析，初始化，使用，卸载。其中的验证，准备，解
析合称为连接阶段。

加载，验证，准备，初始化，卸载的顺序是确定是，另两个由动态绑定等情况可能会在初始化后面。
画个草图：

**双亲委派模型**

双亲委派模型是 Java 类加载机制的核心概念之一。它是一种基于层次结构的类加载模型，用于描述 Java
类加载器之间的父子关系。简单来说，双亲委派模型就是“委托”父类加载器去加载子类的类，而不是自
己直接去加载。

类加载器有是三个：启动类加载器、扩展类加载器、应用程序加载器（系统加载器）


具体来说，双亲委派模型包含以下几个阶段：

```
1. 父类加载器加载本地模块或扩展包中的类。
2. 如果父类加载器无法找到该类，则会委托给其父类加载器继续加载。
3. 如果父类加载器也无法找到该类，则会委托给顶层的启动类加载器 (Bootstrap ClassLoader) 去加
载。
4. 如果启动类加载器也无法找到该类，则会抛出 NoClassDefFoundError 异常。
```
总之，双亲委派模型通过将类加载委托给父类加载器来实现对类的管理和控制，从而保证了 Java 类的安
全性、可靠性和稳定性。

**工作过程是：如果一个类加载器收到了一个类加载的请求，它首先不会去加载类，而是去把这个请求委
派给父加载器去加载，直到顶层启动类加载器，如果父类加载不了（不在父类加载的搜索范围内），才
会自己去加载。**

```
1. 启动类加载器 ：加载的是 lib 目录中的类加载出来，包名是 java. xxx（如：java. lang. Object）
2. 扩展类加载器 ：加载的是 lib/ext 目录下的类，包名是 javax. xxx（如：javax. swing. xxx）
3. 应用程序扩展器 ：这个加载器就是 ClassLoader 的 getSystemClassLoader 的返回值，这个也是默
认的类加载器。
```
**双亲委派模型的意义在于不同的类之间分别负责所搜索范围内的类的加载工作，这样能保证同一个类在
使用中才不会出现不相等的类，举例：如果出现了两个不同的 Object，明明是该相等的业务逻辑就会不
相等，应用程序也会变得混乱。**

###### 24 、进程间通信的方式有哪些


进程间通信 (IPC, InterProcess Communication) 的方式通常有管道 (包括无名管道和命名管道)、消息队
列、信号量、共享存储、Socket、Streams 等。下面简述一下这六种方式：

```
1. 管道 (Pipe)：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系的进程
间使用。
2. 命名管道 (FIFO)：命名管道也是半双工的通信方式，但它允许无亲缘关系进程间的通信。
3. 消息队列 (Message Queue)：消息队列是由消息的链表，存放在内核中并由消息队列标识符标
识。消息队列克服了信号传递信息少、管道只能承载无格式字节流以及缓冲区大小受限等缺点。
4. 共享内存 (Shared Memory)：共享内存就是映射一段能被其他进程所访问的内存，这段共享内存
由一个进程创建，但多个进程都可以访问。
5. 信号 (Signal)：信号是一种比较复杂的通信方式，用于通知接收进程某个事件已经发生。
6. 信号量 (Semaphore)：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。
```
综上所述，不同的进程间通信方式各有优缺点，应根据具体的应用场景选择合适的方式。通常情况下，
管道适用于亲缘关系进程之间的通信；消息队列适用于无连接的进程间通信；共享内存适用于需要高效
数据共享的场景；套接字适用于需要跨平台、跨语言的网络通信。

###### 25 、string、stringbuffer、stringbuilder 的区别，各自的使用场

###### 景

String、StringBuffer 和 StringBuilder 都是 Java 中用于处理字符串的类，它们的区别如下：

```
1. String 是一个不可变对象，一旦被创建就无法被改变。对 String 进行修改操作时，会创建一个新
的 String 对象。因此在频繁修改字符串时，创建大量的 String 对象会导致内存浪费。
2. StringBuffer 是可变对象，可以进行字符串修改操作而不是创建新的对象。因此，使用
StringBuffer 可以提高程序的性能。但是，StringBuffer 需要手动控制方法的调用和字符串的长
度，使用不当可能导致程序出现异常。
3. StringBuilder 是 StringBuffer 的子类，提供了一种更加简单易用的方式来处理字符串。
StringBuilder 对一些常用的字符串操作 (如 append、insert、delete) 进行了重载，可以直接使用
这些方法来进行字符串修改操作，而无需手动控制方法的调用和字符串的长度。此外，
StringBuilder 还提供了一些其他的方法，如 reverse ()、toString () 等。
```
在使用上，一般而言：

```
如果只需要对字符串进行简单的操作 (如拼接), 可以使用 String 或 StringBuffer;
如果需要频繁地对字符串进行修改操作，可以使用 StringBuffer;
如果需要方便地进行字符串修改操作，可以使用 StringBuilder。
```
**使用策略**

```
（ 1 ）基本原则：如果要操作少量的数据，用 String ；单线程操作大量数据，用 StringBuilder ；多
线程操作大量数据，用 StringBuffer。
（ 2 ）不要使用 String 类的"+"来进行频繁的拼接，因为那样的性能极差的，应该使用 StringBuffer
或 StringBuilder 类，这在 Java 的优化上是一条比较重要的原则。
（ 3 ）为了获得更好的性能，在构造 StringBuffer 或 StringBuilder 时应尽可能指定它们的容量。
当然，如果你操作的字符串长度（length）不超过 16 个字符就不用了，当不指定容量
（capacity）时默认构造一个容量为 16 的对象。不指定容量会显著降低性能。
（ 4 ）StringBuilder 一般使用在方法内部来完成类似 + 功能，因为是线程不安全的，所以用完以后
可以丢弃。StringBuffer 主要用在全局变量中。
```

```
（ 5 ） 相同情况下使用 StringBuilder 相比使用 StringBuffer 仅能获得 10%~15% 左右的性能提
升，但却要冒多线程不安全的风险。而在现实的模块化编程中，负责某一模块的程序员不一定能清
晰地判断该模块是否会放入多线程的环境中运行，因此： 除非确定系统的瓶颈是在 StringBuffer
上，并且确定你的模块不会运行在多线程模式下，才可以采用 StringBuilder；否则还是用
StringBuffer。
```
**总结：优先考虑 StringBuffer！**

###### 26 、用过哪些第三方库?

第三方库是指由其他开发者创建和维护的，可以用于解决特定问题或实现特定功能的开源代码库。

Java 作为一门广泛应用于企业级开发的语言，拥有许多优秀的第三方库，以下是其中一些常用的库及其
作用和应用场景：

```
1. Spring Framework ：一个轻量级的、开源的应用程序框架，主要用于企业级 Java 应用程序的开
发。它提供了一个全面的编程和配置模型，用于构建现代化的基于 Java 的企业应用程序。
2. Apache Struts ：一个基于 MVC 的 Web 应用程序框架，它可以帮助开发人员构建可扩展的 Web 应
用程序。
3. Hibernate ：一个开源的对象关系映射框架，它可以将 Java 对象映射到关系型数据库中，从而简化
了数据访问层的开发。
4. Apache Log 4 j ：一个灵活的日志框架，它可以帮助开发人员记录应用程序的日志，并支持多种日
志级别和输出格式。
5. Apache Tomcat ：一个开源的 Web 应用程序服务器，它支持 Java Servlet 和 JavaServer
Pages（JSP）技术，并提供了一个可扩展的架构，可以用于构建高性能的 Web 应用程序。
6. Apache POI ：一个开源的 Java 库，用于操作 Microsoft Office 格式的文档，包括 Excel、Word 和
PowerPoint 等。
7. Gson ：一个开源的 Java 库，用于将 Java 对象转换为 JSON 格式的字符串，或者将 JSON 格式的字符串
转换为 Java 对象。
8. Jackson ：一个开源的 Java 库，用于将 Java 对象转换为 JSON 格式的字符串，或者将 JSON 格式的字
符串转换为 Java 对象。它支持多种 JSON 格式，包括 JSON、XML 和 YAML 等。
9. JUnit：一个开源的 Java 测试框架，它可以帮助开发人员编写单元测试，并提供了丰富的断言和测
试工具。
10. Apache Commons ：一个开源的 Java 库，它包含了许多常用的工具类和函数，可以帮助开发人员
简化 Java 编程。
```
以上是一些常用的 Java 第三方库，它们可以帮助开发人员简化 Java 编程，提高开发效率和代码质量。

###### 27 、工厂模式的三种实现方法

**工厂模式:** 是 Java 中最常用的设计模式之一, 它提供了一种创建对象的最佳方式.

在工厂模式中, 我们在使用工厂类创建对象时不会对客户端暴露创建逻辑, 并且是通过使用一个共同的
接口来指向新创建的对象

三种实现方法


```
简单工厂模式
工厂方法模式
抽象工厂模式
```
**一、简单工厂模式**

**简单工厂模式:** 定义一个创建对象的工厂类, 由工厂类决定创建出哪一种对象的实例, 工厂类内部已封装
创建出哪一种对象的实例的逻辑代码

Phone 手机接口

IPhone 苹果手机实现类

HuaweiPhone 华为手机实现类

PhoneFactory 定义一个创建 Phone 对象实例的手机工厂类, 内部已封装创建出哪一种品牌手机实例的逻
辑代码

测试

```
interface Phone {
// 运行手机的抽象方法
void run ();
}
```
```
class IPhone implements Phone{
@Override
public void run () {
System.out.println ("运行苹果手机");
}
}
```
```
class HuaweiPhone implements Phone {
@Override
public void run () {
System.out.println ("运行华为手机");
}
}
```
```
class PhoneFactory {
```
```
public Phone createPhone (String phoneType) {
Phone phone = null;
if ("IPhone".equals (phoneType)) {
phone = new IPhone ();
} else if ("HuaweiPhone".equals (phoneType)) {
phone = new HuaweiPhone ();
}
return phone;
}
}
```
```
public class SimpleFactory {
public static void main (String[] args) {
// 创建手机工厂类
```

简单工厂模式: 是使用工厂类来创建不同实例的对象, 可以将创建对象的方法静态化, 代码更简洁明了

简单工厂模式存在问题

```
工厂类集中了所有实例 (品牌手机) 的创建逻辑，一旦这个工厂类不能正常工作，整个系统都会受到
影响
违背了开闭原则 (对扩展是开放的, 对修改时关闭的), 一旦添加新对象实例 (新品牌手机) 就不得不修
改工厂类的逻辑
```
**二、工厂方法模式**

**工厂方法模式:** 先定义一个工厂父类 (负责定义创建对象的抽象接口). 再定义一个工厂子类 (负责生成具
体的对象), **工厂方法模式将对象的实例化推迟到工厂子类**

```
PhoneFactory phoneFactory = new PhoneFactory ();
```
```
// 通过手机工厂类创建 IPhone 手机实例对象
Phone IPhone = phoneFactory.createPhone ("IPhone");
IPhone.run (); // 运行苹果手机
```
```
// 通过手机工厂类创建 HuaweiPhone 手机实例对象
Phone HuaweiPhone = phoneFactory.createPhone ("HuaweiPhone");
HuaweiPhone.run (); // 运行华为手机
}
}
```
```
public class PhoneFactory {
```
```
public static Phone createPhone (String phoneType) {
Phone phone = null;
if ("IPhone".equals (phoneType)) {
phone = new IPhone ();
} else if ("HuaweiPhone".equals (phoneType)) {
phone = new HuaweiPhone ();
}
return phone;
}
}
```
```
// 可以直接通过 PhoneFactory.createPhone ("phoneType") 创建手机对象
```

Phone 手机抽象类、IPhone 苹果手机实现类和 HuaweiPhone 华为手机实现类

先定义一个工厂抽象父类: 提供创建手机对象的抽象方法

```
/**
* Phone 手机抽象类: 提供运行手机的抽象方法
*/
abstract class Phone {
abstract void run ();
}
```
```
/**
* IPhone 运行苹果手机
*/
class IPhone extends Phone{
@Override
public void run () {
System.out.println ("运行苹果手机");
}
}
```
```
/**
* HuaweiPhone 运行华为手机
*/
class HuaweiPhone extends Phone {
@Override
public void run () {
System.out.println ("运行华为手机");
}
}
```

再定义一个苹果工厂子类: 负责创建具体的对象 (苹果手机对象)
再定义一个华为工厂子类: 负责创建具体的对象 (华为手机对象)

测试:

**工厂方法模式存在问题: 对象父类与对象工厂父类一一对应, 对象子类与对象工厂子类一一对应. 即:
一个具体工厂子类只能创建一类产品**

**三、抽象工厂模式**

**抽象工厂模式:** Abstarct Factory Pattern, 是围绕一个超级工厂创建其他工厂, 该超级工厂又称为其他工
厂的工厂.

在抽象工厂模式中, 超级工厂中提供 **多个接口** , **每个接口负责创建一个相关对象的其他工厂** , 工厂创建的
对象不需要显式指定它们的类, **指向抽象类**

在抽象工厂模式中, 超级工厂子类负责创建具体的对象: **一个具体超级工厂子类创建多类产品**

```
abstract class PhoneFactory {
abstract Phone createPhone ();
}
```
```
class IPhoneFactory extends PhoneFactory {
```
```
@Override
public IPhone createPhone () {
return new IPhone ();
}
}
```
```
class HuaweiPhoneFactory extends PhoneFactory {
```
```
@Override
public HuaweiPhone createPhone () {
return new HuaweiPhone ();
}
}
```
```
public class FactoryMethod {
public static void main (String[] args) {
// 苹果子类工厂创建苹果手机对象
IPhoneFactory iPhoneFactory = new IPhoneFactory ();
IPhone iPhone = iPhoneFactory.createPhone ();
iPhone.run (); // 运行苹果手机
```
```
// 华为子类工厂创建华为手机对象
HuaweiPhoneFactory huaweiPhoneFactory = new HuaweiPhoneFactory ();
HuaweiPhone huaweiPhone = huaweiPhoneFactory.createPhone ();
huaweiPhone.run (); // 运行华为手机
}
}
```

在抽象工厂模式中, 超级工厂子类负责创建具体的对象: **一个具体超级工厂子类创建多类产品**

```
/**
* 电子产品超级工厂: 超级工厂创建其他工厂
* 创建手机工厂的抽象方法
* 创建电脑工厂的抽象方法
*/
abstract class ElectronicProductsFactory {
```
```
/**
* 手机工厂创建 Phone 手机抽象对象
* @return
*/
abstract Phone createPhoneFactory ();
```
```
/**
* 电脑工厂创建 Computer 电脑抽象对象
* @return
*/
abstract Computer createComputerFactory ();
}
```
```
/**
* 苹果超级工厂子类: 创建苹果手机和苹果电脑对象
*/
class AppleFactory extends ElectronicProductsFactory {
```
```
@Override
IPhone createPhoneFactory () {
return new IPhone ();
}
```
```
@Override
AppleComputer createComputerFactory () {
return new AppleComputer ();
}
}
```
```
/**
* 华为超级工厂子类: 创建华为手机和华为电脑对象
*/
class HuaweiFactory extends ElectronicProductsFactory {
```
```
@Override
HuaweiPhone createPhoneFactory () {
return new HuaweiPhone ();
}
```

定义产品抽象类和产品实体类

```
@Override
HuaweiComputer createComputerFactory () {
return new HuaweiComputer ();
}
}
```
```
/**
* 电子产品抽象族类
*/
abstract class ElectronicProducts {
```
```
abstract void run ();
}
```
```
/**
* 手机电子产品抽象类
*/
abstract class Phone extends ElectronicProducts {
```
```
@Override
abstract void run ();
}
```
```
/**
* 电脑电子产品抽象类
*/
abstract class Computer extends ElectronicProducts {
```
```
@Override
abstract void run ();
}
```
```
/**
* IPhone 苹果手机实体类
*/
class IPhone extends Phone{
```
```
@Override
public void run () {
System.out.println ("运行苹果手机");
}
}
```
```
/**
* HuaweiPhone 华为手机实体类
*/
class HuaweiPhone extends Phone {
```
```
@Override
public void run () {
System.out.println ("运行华为手机");
}
}
```
```
/**
```

抽象工厂模式的优缺点:

```
将具体产品对象的实例化推迟到超级工厂子类实现
超级工厂子类可以创建多个具体产品对象
新增具体产品类时, 只需要增加具体产品类和具体超级工厂子类. 对于新的具体产品类符合开-闭
原则
抽象工厂模式对于新增抽象产品类, 是需要修改源代码. 因此抽象工厂模式对于新的抽象产品类
不符合开-闭原则
```
**工厂模式的意义:**

将实例化对象的代码提取处理, 放到一个类中统一管理和维护, 达到和主项目的依赖关系的解耦, 从而提
提高项目的扩展和维护性.

工厂模式的依赖抽象原则:

```
创建对象实例时, 不要直接 new 对象, 而是把这个 new 类的动作放在一个工厂的方法中, 并返回. 甚至
是, 变量不要直接持有具体类的引用
不要让类继承具体的类, 而是继承抽象类或者是接口
不要覆盖类中已经实现的方法
```
## 炸裂了... 京东一面索命 40 问，过了就 50 W+

```
* AppleComputer 苹果电脑实体类
*/
class AppleComputer extends Computer {
```
```
@Override
public void run () {
System.out.println ("运行苹果电脑");
}
}
```
```
/**
* HuaweiComputer 华为电脑实体类
*/
class HuaweiComputer extends Computer {
```
```
@Override
public void run () {
System.out.println ("运行华为电脑");
}
}
```

#### 说在前面

在 40 岁老架构师尼恩的（50+） **读者社群** 中，经常有小伙伴，需要面试京东、阿里、百度、头条、美团
等大厂。

下面是一个小伙伴成功拿到通过了京东一次技术面试，最终，小伙伴通过后几面技术拷问、灵魂拷问，
最终拿到 offer。

**从这些题目来看：京东的面试，偏重底层知识和原理，大家来看看吧。**

现在把面试真题和参考答案收入咱们的宝典，大家看看， **收个京东 Offer 需要学点啥？**

当然对于中高级开发来说，这些面试题，也有参考意义。

这里把题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》 V 83 版本，供后面的小伙伴参考，提升大
家的 3 高架构、设计、开发水平。

```
《尼恩架构笔记》《尼恩高并发三部曲》《尼恩 Java 面试宝典》的 PDF，请到公众号【技术自由
圈】获取
```
#### 京东一面索命 40 问

###### 1 、聊聊五种 IO 模型

**一、什么是 IO**

IO 全程 Input/Output，即数据的读取（接收）或写入（发送）操作，针对不同的数据存储媒介，大致
可以分为网络 IO 和磁盘 IO 两种。

而在 Linux 系统中，为了保证系统安全，操作系统将虚拟内存划分为 **内核空间** 和 **用户空间** 两部分。因此
用户进程无法直接操作 IO 设备资源，需要通过系统调用完成对应的 IO 操作。

即此时一个完整的 IO 操作将经历一下两个阶段：用户空间 <-> 内核空间 <-> 设备空间。


**二、五种 IO 模型**

**1. 同步阻塞 IO**

**同步阻塞 IO（Blocking IO）** 指的是用户进程（或线程）主动发起，需要等待内核 IO 操作彻底完成后
才返回到用户空间的 IO 操作。在 IO 操作过程中，发起 IO 请求的用户进程处于阻塞状态。

**2. 同步非阻塞 IO**

**同步非阻塞 IO（Non-Blocking IO，NIO）** 指的是用户进程主动发起，不需要等待内核 IO 操作彻底完
成就能立即返回用户空间的 IO 操作。在 IO 操作过程中，发起 IO 请求的用户进程处于非阻塞状态。


1 ）当数据 Ready 之后，用户线程仍然会进入阻塞状态，直到数据复制完成，并不是绝对的非阻塞。

2 ）NIO 实时性好，内核态数据没有 Ready 会立即返回，但频繁的轮询内核，会占用大量的 CPU 资
源，降低效率。

**3. IO 多路复用**

**IO 多路复用（IO Multiplexing）** 实际上就解决了 NIO 中的频繁轮询 CPU 的问题，并且引入一种新的
select 系统调用。

复用 IO 的基本思路就是通过 slect 调用来监控多 fd（文件描述符），来达到不必为每个 fd 创建一个对
应的监控线程的目的，从而减少线程资源创建的开销。一旦某个描述符就绪（一般是内核缓冲区可读/
可写），内核就能够将文件描述符的就绪状态返回给用户进程（或者线程），用户空间可以根据文件描
述符的就绪状态进行相应的 IO 系统调用。

IO 多路复用（IO Multiplexing）属于一种经典的 Reactor 模式实现，有时也称为 **异步阻塞 IO** 。


**4. 异步 IO**

**异步 IO（Asynchronous IO，AIO）** 指的是用户空间的线程变成被动接收者，而内核空间成为主动调
用者。在异步 IO 模型中，当用户线程收到通知时，数据已经被内核读取完毕并放在用户缓冲区内，内
核在 IO 完成后通知用户线程直接使用即可。而此处说的 AIO 通常是一种 **异步非阻塞 IO** 。

**5. 信号驱动 IO**

当进程发起一个 IO 操作，会向内核注册一个信号处理函数，然后进程返回不阻塞；当内核数据就绪时
会发送一个信号给进程，进程便在信号处理函数中调用 IO 读取数据。


信号驱动 IO 不同于 AIO 的是依旧存在阻塞状态，即用户进程获取到数据就绪信号后阻塞进行 IO 操
作。

###### 2 、说说什么是一致性

**一、不同的一致性**

我们在不同的地方见到过一致性的概念，总结大概分为以下几类：

```
ACID 里的一致性
多副本的一致性
CAP 理论的一致性
一致性哈希
```
**二、ACID 里的一致性**

1. 最常见的定义是：事务的一致性是指系统从一个正确的状态, 迁移到另一个正确的状态。
指的是事务前后的正确性是一致的。
Consistency ensures that a transaction can only bring the database from one valid state to
another, maintaining database invariants: any data written to the database must be valid
according to all defined rules, including constraints, cascades, triggers, and any combination
thereof. This prevents database corruption by an illegal transaction, but does not guarantee that
a transaction is correct.

2.“ensuring the consistency is the responsibility of user, not DBMS.”, "DBMS assumes that
consistency holds for each transaction。
指的是对业务中和数据库中约束的检查，业务上的合理性，只靠 AID 手段不容易检查出逻辑性的问题
来。比如转账操作中，账户金额不能为负数，这是业务逻辑上的要求，用一致性来保证。

3.This (Consistency）does not guarantee correctness of the transaction in all ways the application
programmer might have wanted (that is the responsibility of application-level code) but merely
that any programming errors cannot result in the violation of any defined database constraints.
[1]

**三、多副本一致性**

某些数据保存了多个副本，所有副本内容相同。

**四、CAP 理论中的一致性**

整个分布式系统在对外的反馈上，与一台单机完全一样，不会因为分布式导致对外行为的前后冲突。

**五、一致性哈希**

一种哈希算法，指将存储节点和数据都映射到一个首尾相连的哈希环上，如果增加或者移除一个节点，
仅影响该节点在哈希环上顺时针相邻的后继节点，其它数据也不会受到影响。
在移除或者添加一个服务器时，能够尽可能小地改变已存在的服务请求与处理请求服务器之间的映射关
系。一致性哈希解决了简单哈希算法在分布式哈希表 ( Distributed Hash Table，DHT) 中存在的动态伸
缩等问题。
对比非一致性哈希（普通的哈希），映射时如果节点发生变化，需要重新计算所有数据的映射值。

**六、线性一致性、外部一致性、最终一致性的区别**


这三个都是分布式系统的一致性级别
线性一致性：强一致性，侧重于单个 key 的场景
外部一致性：事务在数据库内的执行序列不能违背外部观察到的顺序，更侧重于对比传统数据库系统的
内部一致性。
最终一致性：弱一致性。

```
40 岁老架构师尼恩提示 ：分布式事务是既是面试的绝对重点，也是面试的绝对难点，建议大家有
一个深入和详细的掌握，具体的内容请参见《尼恩 Java 面试宝典-专题 17 ：分布式事务面试题》
PDF，该专题对分布式事务有一个系统化、体系化、全面化的介绍。
```
```
如果要把分布式事务写入简历，可以找尼恩指导
```
###### 3 、说说什么是隔离性

**一、事务的四大特性：**

**1. 原子性（Atomicity）**

原子性是指事务包含的所有操作要么全部成功，要么全部失败回滚，这和前面两篇博客介绍事务的功能
是一样的概念，因此事务的操作如果成功就必须要完全应用到数据库，如果操作失败则不能对数据库有
任何影响。

**2. 一致性（Consistency）**

一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前
和执行之后都必须处于一致性状态。

拿转账来说，假设用户 A 和用户 B 两者的钱加起来一共是 5000 ，那么不管 A 和 B 之间如何转账，转几次
账，事务结束后两个用户的钱相加起来应该还得是 5000 ，这就是事务的一致性。

**3. 隔离性（Isolation）**

隔离性是当多个用户并发访问数据库时，比如操作同一张表时，数据库为每一个用户开启的事务，不能
被其他事务的操作所干扰，多个并发事务之间要相互隔离。

即要达到这么一种效果：对于任意两个并发的事务 T 1 和 T 2，在事务 T 1 看来，T 2 要么在 T 1 开始之前就已
经结束，要么在 T 1 结束之后才开始，这样每个事务都感觉不到有其他事务在并发地执行。

关于事务的隔离性数据库提供了多种隔离级别，稍后会介绍到。

**4. 持久性（Durability）**

持久性是指一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统
遇到故障的情况下也不会丢失提交事务的操作。

**二、隔离性：**

多个线程都开启事务操作数据库中的数据时，数据库系统要能进行隔离操作，以保证各个线程获取数据
的准确性，在介绍数据库提供的各种隔离级别之前，我们先看看如果不考虑事务的隔离性，会发生的几
种问题：

**1. 脏读**

脏读是指在一个事务处理过程里读取了另一个未提交的事务中的数据。


当一个事务正在多次修改某个数据，而在这个事务中这多次的修改都还未提交，这时一个并发的事务来
访问该数据，就会造成两个事务得到的数据不一致。例如：用户 A 向用户 B 转账 100 元，对应 SQL 命令如
下

当只执行第一条 SQL 时，A 通知 B 查看账户，B 发现确实钱已到账（此时即发生了脏读），而之后无论第
二条 SQL 是否执行，只要该事务不提交，则所有操作都将回滚，那么当 B 以后再次查看账户时就会发现
钱其实并没有转。

**2. 不可重复读**

不可重复读是指在对于数据库中的某个数据，一个事务范围内多次查询却返回了不同的数据值，这是由
于在查询间隔，被另一个事务修改并提交了。

例如事务 T 1 在读取某一数据，而事务 T 2 立马修改了这个数据并且提交事务给数据库，事务 T 1 再次读取
该数据就得到了不同的结果，发送了不可重复读。

不可重复读和脏读的区别是，脏读是某一事务读取了另一个事务未提交的脏数据，而不可重复读则是读
取了前一事务提交的数据。

在某些情况下，不可重复读并不是问题，比如我们多次查询某个数据当然以最后查询得到的结果为主。
但在另一些情况下就有可能发生问题，例如对于同一个数据 A 和 B 依次查询就可能不同，A 和 B 就可能打
起来了......

**3.虚读 (幻读)**

幻读是事务非独立执行时发生的一种现象。例如事务 T 1 对一个表中所有的行的某个数据项做了从“1”修
改为“2”的操作，这时事务 T 2 又对这个表中插入了一行数据项，而这个数据项的数值还是为“1”并且提交
给数据库。而操作事务 T 1 的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从
事务 T 2 中添加的，就好像产生幻觉一样，这就是发生了幻读。

幻读和不可重复读都是读取了另一条已经提交的事务（这点就脏读不同），所不同的是不可重复读查询
的都是同一个数据项，而幻读针对的是一批数据整体（比如数据的个数）。

现在来看看 MySQL 数据库为我们提供的四种隔离级别：

① Serializable (串行化)：可避免脏读、不可重复读、幻读的发生。

② Repeatable read (可重复读)：可避免脏读、不可重复读的发生。

③ Read committed (读已提交)：可避免脏读的发生。

④ Read uncommitted (读未提交)：最低级别，任何情况都无法保证。

以上四种隔离级别最高的是 Serializable 级别，最低的是 Read uncommitted 级别，当然级别越高，执行
效率就越低。像 Serializable 这样的级别，就是以锁表的方式 (类似于 Java 多线程中的锁) 使得其他的线程
只能在锁外等待，所以平时选用何种隔离级别应该根据实际情况。在 MySQL 数据库中默认的隔离级别为
Repeatable read (可重复读)。

在 MySQL 数据库中，支持上面四种隔离级别，默认的为 Repeatable read (可重复读)；而在 Oracle 数据
库中，只支持 Serializable (串行化) 级别和 Read committed (读已提交) 这两种级别，其中默认的为 Read
committed 级别。

```
40 岁老架构师尼恩提示 ：分布式事务是既是面试的绝对重点，也是面试的绝对难点，建议大家有
一个深入和详细的掌握，具体的内容请参见《尼恩 Java 面试宝典-专题 17 ：分布式事务面试题》
PDF，该专题对分布式事务有一个系统化、体系化、全面化的介绍。
```
```
update account set money=money+ 100 where name=’B’; (此时 A 通知 B)
update account set money=money - 100 where name=’A’;
```

```
如果要把分布式事务写入简历，可以找尼恩指导。
```
###### 4 、说说 MySQL 的隔离级别

在 SQL 标准中定义了四种隔离级别，包括了一些具体规则，用来限定事务内外的哪些改变是可见的，哪
些是不可见的。低级别的隔离级一般支持更高的并发处理，并拥有更低的系统开销。

1 ）Read Uncommitted（读取未提交内容）

在该隔离级别，所有事务都可以看到其他未提交事务的执行结果。本隔离级别很少用于实际应用，因为
它的性能也不比其他级别好多少。读取未提交的数据，也被称之为脏读（Dirty Read）。

2 ）Read Committed（读取提交内容）

这是大多数数据库系统的默认隔离级别（但不是 mysql 默认的）。它满足了隔离的简单定义：一个事务
只能看见已经提交事务所做的改变。这种隔离级别也支持所谓的不可重复读（Nonrepeatable
Read），因为同一事务的其他实例在该实例处理其间可能会有新的 commit，所以同一条 select 语句可
能返回不同结果。

3 ）Repeatable Read（可重读）

这是 mysql 的默认事务隔离级别，它确保同一事务的多个实例在并发读取数据时，会看到同样的数据
行。不过理论上，这会导致另一个棘手的问题：幻读 （Phantom Read）。简单的说，幻读指当用户读
取某一范围的数据行时，另一个事务又在该范围内插入了新行，当用户再读取该范围的数据行时，会发
现有新的“幻影” 行。InnoDB 和 Falcon 存储引擎通过多版本并发控制（MVCC，Multiversion
Concurrency Control）机制解决了该问题。

4 ）Serializable（可串行化）

这是最高的隔离级别，它通过强制事务排序，使之不可能相互冲突，从而解决幻读问题。简言之，它是
在每个读的数据行上加上共享锁。在这个级别，可能导致大量的超时现象和锁竞争，因此使用该隔离级
别会造成数据库性能的显著下降。

###### 5 、说说每个隔离级别是如何解决

在数据库中，事务隔离级别确定了事务中读取和写入操作的执行顺序。下面是每个隔离级别是如何解决
数据冲突的。

```
1. READ UNCOMMITTED：读取未提交。当事务读取其他事务未提交的数据时，可能会发生数据冲
突。解决方法是在读取未提交的数据时需要等待，直到所有事务都已提交。
2. READ COMMITTED：读取已提交。当事务读取其他事务已提交的数据时，不会发生数据冲突。
解决方法是在读取已提交的数据时，可以保证读取到的数据是一致的。
3. REPEATABLE READ：可重复读。当事务读取其他事务已提交的数据时，可能会发生数据冲突。解
决方法是在读取已提交的数据时，需要等待，直到所有事务都已提交，或者在事务提交后再读取数
据，可以保证数据的一致性。
4. SERIALIZABLE：串行化。当事务需要访问同一条数据时，需要按照事务提交的顺序进行访问，否
则会发生数据冲突。解决方法是在事务提交时，必须保证所有操作都已完成，否则会回滚事务。
```
总之，隔离级别越高，数据的一致性越高，但是性能越差。在实际应用中，需要根据不同的业务需求选
择合适的隔离级别。

###### 6 、MySQL 要加上 nextkey 锁，语句该怎么写


在 MySQL 中，要使用 next-key 锁，可以使用以下语句示例：

在上述示例中，你需要将 table_name 替换为你要查询的表名，column_name 替换为你要查询的列
名，value 替换为你要匹配的值。

使用 FOR UPDATE 语句可以确保在查询期间对所选行应用 next-key 锁，以防止其他事务对这些行进行修
改。

请注意，next-key 锁是在 InnoDB 存储引擎中实现的，默认情况下它是开启的。确保你的表使用了
InnoDB 引擎，以便使用 next-key 锁。

###### 7 、说说 Java 的内存模型，垃圾回收

**一、内存模型**

**JDK 8 的内存模型**

在 Java 中所有的垃圾收集问题几乎都是针对堆内存空间完成的，但是要想充分理解垃圾的收集流程，必
须首先掌握 Java 堆内存的最初内存模型组成。如图 1 所示：

**内存模型的变化**

JDK 1.8 以前提共用永久代，而从 JDK 1.8 后永久代被替换为元空间（MetaSpace)。在 JDK 1.8 之前，
HotSpot 都在努力改变永久代的存储位置，例如，在 JDK 1.6 时提供有永久代，到了 JDK 1.7 时又将永久代
的部分操作移交给了堆内存，而在 JDK 1.8 时使用元空间代替了永久代。

JDK 1.8 之前的内存模型如图 2 所示。

```
SELECT * FROM table_name WHERE column_name = 'value' FOR UPDATE
```

可以发现，在 JDK 1.8 之前都会提供有永久代，此部分内存是不受 GC 控制的。在最初的设计中，都将方
法区保存在了永久代，所以一旦方法执行中出现了内存不足的情况，将会抛出：
“OutOfMemoryError: PermGen space”错误。同时 Oracle 也在考虑将 HotSpot 与 JRockit (此虚拟机不存
在永久代）两个虚拟机合二为一，所以此内存空间被元空间所替代。

**二、垃圾收集流程**

在整个 Java 內存模型中，主要有 3 块内存区：年轻代（Young)、老年代（Tenured)、元空间
（MetaSpace)，同时还会有几块动态调整的内存伸缩区（当几个内存区空间不足时动态扩充）。而 JVM
的内存回收就是对这几块空间的回收处理操作，对于内存分配与 GC 的执行流程如图 3 所示。

上图中的垃圾回收主要是针对年轻代（Eden+Survivor）与老年代（Tenured）完成的。

具体流程如下：

```
1. 当使用关键字 new 创建一个新对象时，JVM 会将新对象保存在 Eden 区，此时需要判断 Eden 区是否
有空余空间。
如果没有，则会执行“MinorGC (年轻代 GC)”。
如果有，则直接将新对象保存在 Edeti 区之内；
2. 执行完“MinorGC”后会清除不活跃的对象，从而释放 Eden 区的内存空间，随后对 Eden 空间再次判
断。
如果此时 Eden 区的空间依然不足，则会将部分活跃对象保存在 Survivor 区。
如果此时剩余空间可以直接容纳新对象，则会直接为新对象申请内存空间；
3. 由于 Survivor 区也有对象会存储在内，所以在保存 Eden 区发送来的对象前首先需要判断其空间是
否充足。
如果 Suivivor 有足够的空余空间，则直接保存 Eden 区晋升的对象。此时 Eden 区空间得到释
放，随后可以在 Eden 区为新的对象申请内存空间。
如果 Survivor 区空间不足，则需要将 Survivor 区的部分活跃对象保存到 Tenured 区。
4. Tenured 区如果有足够的内存空间，则会将 Survivor 区发送来的对象进行保存。
如果此时 Tenured 区的内存空间也已经满了，则将执行“FullGC”（完全 GC 或称为 MajorGC，
其包括年轻代和老年代，相当于使用“Runtime.getRuntime (). gc ()”处理）以释放年轻代和老
年代中保存的不活跃对象。
如果在释放后有足够的内存空间，Survivor 将保存 Eden 发送来的对象，这样就可以在 Eden 区
内有足够的内存保存新的对象。
5. 此时，如果老年代的内存区也己经被占满，则会抛出“OutOfMemoryError (OOM 错误）”，程序将
中断运行。
```
可见，Java 在每次创建对象时如果发现内存不足都会自动向其他区域延伸。为了提高性能，在实际应用
中可能会开辟尽量大的内存空间，以实现更加合理的 GC 控制。


###### 8 、实现分布式锁，Zookeeper 和 Redis 哪种更好？

**一、zookeeper 实现分布式锁方案**

a.争抢锁，只有一个人能获得锁

b.获得锁，客户端出现问题，临时节点（session）

c.锁被释放，删除，如何通知其他客户端

c-1: 主动轮询，心跳：弊端：延迟，压力

c-2: watch: 解决延迟问题。弊端：压力

c-3: sequence+watch: watch 前一个，最小的获得锁，一旦最小的释放了锁，成本：zk 只需要给第二个
发时间回调

**二、Redis 实现分布式锁方案**

a.使用 setnx () 方法，获取锁信息

b.设置过期时间，防止客户端 down 机，造成死锁

c.多线程（守护线程），监控锁，业务还未处理完，锁过期，自动延期

**三、对比 zookeeper 与 redis 分布式锁的实现方案**

3.1 从获得锁的速度上，redis 的速度优于 zookeeper

3.2 从方案实现的角度，zookeeper 实现相对 redis 简单，zookeeper 只管获取锁和回调，redis 还要增加
线程对锁进行监控。

**四、Zookeeper 分布式锁的具体实现**

```
public class ZKUtils {
private static ZooKeeper zk;
```
```
private static String address =
"192.168.7.230:2181,192.168.7.240:2180,192.168.7.71:2181/testDistributeLock";
```
```
private static DefaultWatch watch = new DefaultWatch ();
```
```
private static CountDownLatch init = new CountDownLatch ( 1 );
public static ZooKeeper getZK (){
```
```
try {
zk = new ZooKeeper (address, 1000 ,watch);
watch.setCc (init);
init.await ();
```
```
} catch (Exception e) {
e.printStackTrace ();
}
return zk;
}
}
```

public class WatchCallBack implements Watcher, AsyncCallback. StringCallback
,AsyncCallback. Children 2 Callback ,AsyncCallback. StatCallback {
ZooKeeper zk ;
String threadName;
CountDownLatch cc = new CountDownLatch ( 1 );
String pathName;

public String getPathName () {
return pathName;
}

public void setPathName (String pathName) {
this. pathName = pathName;
}

public String getThreadName () {
return threadName;
}

public void setThreadName (String threadName) {
this. threadName = threadName;
}

public ZooKeeper getZk () {
return zk;
}

public void setZk (ZooKeeper zk) {
this. zk = zk;
}

public void tryLock (){
try {

System.out.println (threadName + " create....");
// if (zk.getData ("/"))
zk.create ("/lock",threadName.getBytes (),
ZooDefs. Ids. OPEN_ACL_UNSAFE, CreateMode. EPHEMERAL_SEQUENTIAL, this,"abc");
cc.await ();
} catch (InterruptedException e) {
e.printStackTrace ();
}
}

public void unLock (){
try {
zk.delete (pathName,- 1 );
System.out.println (threadName + " over work....");
} catch (InterruptedException e) {
e.printStackTrace ();
} catch (KeeperException e) {
e.printStackTrace ();
}
}

@Override
public void process (WatchedEvent event) {
//如果第一个哥们，那个锁释放了，其实只有第二个收到了回调事件！！


//如果，不是第一个哥们，某一个，挂了，也能造成他后边的收到这个通知，从而让他后边那个跟去
watch 挂掉这个哥们前边的。。。
switch (event.getType ()) {
case None:
break;
case NodeCreated:
break;
case NodeDeleted:
zk.getChildren ("/", false, this ,"sdf");
break;
case NodeDataChanged:
break;
case NodeChildrenChanged:
break;
}

}

@Override
public void processResult (int rc, String path, Object ctx, String name) {
if (name != null ){
System.out.println (threadName +" create node : " + name );
pathName = name ;
zk.getChildren ("/", false, this ,"sdf");
}

}

//getChildren call back
@Override
public void processResult (int rc, String path, Object ctx, List<String>
children, Stat stat) {

//一定能看到自己前边的。。
// System.out.println (threadName+"look locks.....");
// for (String child : children) {
// System.out.println (child);
// }
Collections.sort (children);
int i = children.indexOf (pathName.substring ( 1 ));
//是不是第一个
if (i == 0 ){
//yes
System.out.println (threadName +" i am first....");
try {
zk.setData ("/",threadName.getBytes (),- 1 );
cc.countDown ();

} catch (KeeperException e) {
e.printStackTrace ();
} catch (InterruptedException e) {
e.printStackTrace ();
}
}else{
//no
zk.exists ("/"+children.get (i- 1 ), this, this,"sdf");
}


}

@Override
public void processResult (int rc, String path, Object ctx, Stat stat) {
//偷懒
}
}

public class TestDistributeLock {
ZooKeeper zk ;

@Before
public void conn (){
zk = ZKUtils.getZK ();
}

@After
public void close (){
try {
zk.close ();
} catch (InterruptedException e) {
e.printStackTrace ();
}
}

@Test
public void lock (){

for (int i = 0 ; i < 10 ; i++) {
new Thread (){
@Override
public void run () {
WatchCallBack watchCallBack = new WatchCallBack ();
watchCallBack.setZk (zk);
String threadName = Thread.currentThread (). getName ();
watchCallBack.setThreadName (threadName);
//每一个线程：
//抢锁
watchCallBack.tryLock ();
//干活
System.out.println (threadName+" working...");
// try {
// Thread.sleep (1000);
// } catch (InterruptedException e) {
// e.printStackTrace ();
// }
//释放锁
watchCallBack.unLock ();
}
}. start ();
}
while (true){

}
}
}


```
40 岁老架构师尼恩提示 ：分布式锁是既是面试的绝对重点，也是面试的绝对难点，建议大家有一
个深入和详细的掌握，具体的内容请参见《尼恩 Java 面试宝典-专题 15 ：分布式锁面试题》PDF，
该专题对分布式锁有一个系统化、体系化、全面化的介绍。
```
```
如果要把分布式锁写入简历，可以找尼恩指导。
```
###### 9 、说一下分布式锁实现

**一、什么是分布式锁**

在一个进程中，多线程去竞争资源时，可以通过 synchronized 或者 Lock 锁进行同步执行，保证多线程情
况下，资源的调用是安全的，那么多进程中或者多节点机器中如何去保证对相同资源的调用是安全的，
此时就引出了分布式锁解决方案。分布式锁就是用来保证在分布式系统中对共享资源调用时保证其一致
性。

**二、分布式锁实现**

在实现分布式锁过程中需要考虑如下几点：

```
1. 加锁和释放锁的原理
2. 怎么保证一次只有一个节点拿到锁
3. 锁的可重入性
4. 怎么预防死锁问题
5. 没有获得锁的节点应该怎么处理
```
需要实现分布式锁，就得借助于第三方软件，比如数据库、Redis、ZooKeeper 等，本文就分别从这三
种软件着手，来看看是怎样的实现过程。

**1 、基于 Mysql 的分布式锁**

数据库中我们可以通过主键唯一性特点来进行加锁和解锁过程，主键唯一性就表示当前节点中只能有一
个节点创建成功，其余的都是得到创建异常，那么创建成功的节点就表示获得了锁，其余节点只能等待
获得锁。此时保证了第一步和第二步，那么怎么实现锁的可重入性呢？此时我们可以增加一列来存储当
前节点的当前线程信息（可以用节点的应用名称+ip+线程名），重入次数加上一个计数器，因为数据库
没有一个过期时间的设置，所以需要开启一个定时任务去判断当前锁是不是已经过期。所以我们还需要
一个更新时间。
表如下：

代码实现如下，

```
DROP TABLE IF EXISTS `locks`;
CREATE TABLE `locks` (
`id` int ( 11 ) NOT NULL AUTO_INCREMENT,
`lock_key` varchar ( 255 ) NOT NULL COMMENT '需要锁定的资源',
`repeat_key` varchar ( 255 ) NOT NULL COMMENT '可重入标识',
`repeat_time` int ( 11 ) DEFAULT NULL COMMENT '重入次数',
`update_time` datetime DEFAULT NULL COMMENT '更新时间',
PRIMARY KEY (`id`),
UNIQUE KEY `lock_key` (`lock_key`)
) ENGINE=InnoDB DEFAULT CHARSET=utf 8;
```
```
import javax. sql. DataSource;
import java. io. Closeable;
```

import java. io. IOException;
import java. net. InetAddress;
import java. net. UnknownHostException;
import java. sql. Connection;
import java. sql. PreparedStatement;
import java. sql. ResultSet;
import java. sql. SQLException;
import java. util. concurrent. TimeUnit;

/**
* Created by Administrator on 2022/1/13.
*/
public class MyLockFromMysql implements MyLock{

private DataSource dataSource;

public MyLockFromMysql (DataSource dataSource) {
this. dataSource = dataSource;
}

@Override
public void lock (String key) {
if (! tryLock (key)){
throw new RuntimeException ();
}
}

@Override
public void unlock (String key) {
String repeatKey= getRepeatKey ();
if (hasRepeatLock (key, repeatKey)){
updateLock (key, repeatKey,- 1 );
}else if (! deleteLock (key, repeatKey)){
throw new RuntimeException ();
}
}

@Override
public boolean tryLock (String key) {
String repeatKey= getRepeatKey ();
if (hasLock (key, repeatKey)){
return updateLock (key, repeatKey, 1 );
}
for (;;){
if (addLock (key, repeatKey)){
break;
}
try {
Thread.sleep ( 100 );
} catch (InterruptedException e) {
}
}
return true;
}

private String getRepeatKey () {


String host= "";
try {
host = InetAddress.getLocalHost (). getHostAddress ();
} catch (UnknownHostException e) {
e.printStackTrace ();
}
return host+Thread.currentThread (). getName ();//采用节点 ip+线程名来做重入判断
}

/**
* 根据 key 和 repeatKey 判断当前是否已经获得锁
* @param key 锁定的资源
* @param repeatKey 可重入标识
* @return
*/
private boolean hasLock (String key, String repeatKey){
Connection connection=null;
PreparedStatement statement=null;
ResultSet rs=null;
try {
connection=dataSource.getConnection ();
statement=connection.prepareStatement ("SELECT repeat_time FROM locks
WHERE lock_key=? AND repeat_key=?");
statement.setString ( 1 ,key);
statement.setString ( 2 ,repeatKey);

rs=statement.executeQuery ();
return rs.next ();

} catch (Exception e) {
return false;
}finally {
close (rs);
close (statement);
close (connection);
}
}

/**
* 判断当前是否有重入锁
* @param key
* @param repeatKey
* @return
*/
private boolean hasRepeatLock (String key, String repeatKey){
Connection connection=null;
PreparedStatement statement=null;
ResultSet rs=null;
try {
connection=dataSource.getConnection ();
statement=connection.prepareStatement ("SELECT repeat_time FROM locks WHERE
lock_key=? AND repeat_key=? AND repeat_time>1 ");
statement.setString ( 1 ,key);
statement.setString ( 2 ,repeatKey);

rs=statement.executeQuery ();
return rs.next ();


} catch (Exception e) {
return false;
}finally {
close (rs);
close (statement);
close (connection);
}
}
/**
* 如果当前线程没有获得锁直接添加一条数据去竞争锁
* @param key 锁定的资源
* @param repeatKey 可重入标识
* @return
*/
private boolean addLock (String key, String repeatKey){
Connection connection=null;
PreparedStatement statement=null;
try {
connection=dataSource.getConnection ();
statement=connection.prepareStatement ("INSERT INTO locks
(lock_key, repeat_key, repeat_time, update_time) VALUES (?,?,1,now ())");
statement.setString ( 1 ,key);
statement.setString ( 2 ,repeatKey);
return statement.executeUpdate ()> 0 ;
} catch (Exception e) {
return false;
}finally {
close (statement);
close (connection);
}
}
private boolean updateLock (String key, String repeatKey, int upDown){
Connection connection=null;
PreparedStatement statement=null;
try {
connection=dataSource.getConnection ();
statement=connection.prepareStatement ("UPDATE locks set
repeat_time=repeat_time+?, update_time=now () WHERE lock_key=? AND repeat_key=?");
statement.setInt ( 1 ,upDown);
statement.setString ( 2 ,key);
statement.setString ( 3 ,repeatKey);
return statement.executeUpdate ()> 0 ;
} catch (Exception e) {
return false;
}finally {
close (statement);
close (connection);
}
}
private boolean deleteLock (String key, String repeatKey){
Connection connection=null;
PreparedStatement statement=null;
try {
connection=dataSource.getConnection ();
statement=connection.prepareStatement ("DELETE FROM locks WHERE
lock_key=?");
statement.setString ( 1 ,key);


以上代码只是简单的去实现了用 mysql 来做分布式锁的过程（性能不是太友好，也会存在很多问题），
逻辑就是通过设定需要锁定的资源为主键，加锁的时候往数据库中添加数据，此时只会有添加成功的节
点会获得锁，当调用完成之后删掉数据，也就是表明释放锁。针对重入锁，采用了一个重入 key 和重入
次数两个字段来实现重入，如果当前节点已经获得锁，需要再次获得锁的时候，直接对次数+1 操作，释
放锁的时候做-1 操作。当为 1 的时候再释放就需要删除节点。

其中的缺点也可想而知：

```
1. 获得锁节点，不能正确的释放锁，那么锁记录就会一直存在数据库中，其它节点就不能获得锁，此
时就需要人工干预
2. 高并发时，会给系统和数据库系统带来压力
3. 没有唤醒操作，其它线程只能是循环去获得锁
```
**2 、基于 Redis 实现分布式锁**

Redis 中有一个 setnx 命令，这个命令 key 不存在添加成功放回 1 ，存在返回 0 ，所以采用 redis 实现分布式
锁就是基于这个命令来实现，也就是只有在创建成功放回 1 的节点就是获得锁的节点，释放锁的时候，
删除该节点即可，redis 中可以采用过期时间策略来保证，客户端释放锁失败后，也能在规定时间内释放
锁，锁的可重入性在于 value 的设计过程，value 我们可以保存当前节点的唯一标识和可重入次数。
简单代码如下所示：

```
return statement.executeUpdate ()> 0 ;
} catch (Exception e) {
e.printStackTrace ();
return false;
}finally {
close (statement);
close (connection);
}
}
private void close (AutoCloseable close){
if (close!=null){
try {
close.close ();
} catch (Exception e) {
}
}
}
}
```
```
import com. alibaba. fastjson. JSONObject;
import redis. clients. jedis. Jedis;
```
```
import java. net. InetAddress;
import java. net. UnknownHostException;
```
```
/**
* Created by Administrator on 2022/1/14.
*/
public class MyLockForRedis implements MyLock {
```
```
private final long TIME_WAIT=50 L;
@Override
public void lock (String key) {
tryLock (key);
```

}

@Override
public void unlock (String key) {
Jedis redis=new Jedis ("127.0.0.1", 6379 );
String json=redis.get (key);
LockValue lockValue= JSONObject.parseObject (json, LockValue. class);
if (getRepeatKeyV (). equals (lockValue.getRepeatKey ())){
if (lockValue.getTime ()> 1 ){
lockValue.setTime (lockValue.getTime ()- 1 );
redis.set (key,JSONObject.toJSONString (lockValue));
}else {
redis.del (key);
}
}
redis.close ();
}

@Override
public boolean tryLock (String key) {
Jedis redis=new Jedis ("127.0.0.1", 6379 );
try {
for (;;){

if ("OK".equals (redis.set (key,JSONObject.toJSONString (new
LockValue ()),"NX","EX", 200000 ))){
return true;
}else {
String json=redis.get (key);
LockValue lockValue= JSONObject.parseObject (json, LockValue. class);
if (lockValue!=null&&getRepeatKeyV (). equals (lockValue.getRepeatKey ()))
{
lockValue.setTime (lockValue.getTime ()+ 1 );
redis.set (key,JSONObject.toJSONString (lockValue));
return true;
}
}
try {
Thread.sleep (TIME_WAIT);
} catch (InterruptedException e) {

}
}
}finally {
redis.close ();
}

}
private static class LockValue{
private int time= 1 ;
private String repeatKey=getRepeatKeyV ();

public int getTime () {
return time;
}
public void setTime (int time) {
this. time = time;


以上只是简单的去实现了基于 Redis 的分布式锁功能（肯定存在很多问题），其中 value 保存的是 json 格
式的数据来实现锁的可重入性，这里就会存在一个性能的开销（不断的解析 json 格式），这里存在一个
问题是过期时间的设置，如果我们设置的是 10 ，如果某节点获得锁之后，执行的很慢超过了十秒，此时
别的节点就可以获得锁，一种解决方案就是在获得锁的节点中开启一个线程去更新锁的过期时间，当节
点执行完成之后关掉这个线程，如果获取锁的节点宕机之后，也可以通过过期时间来解决。

**3 、基于 Zookeeper 实现分布式锁**

ZooKeeper 中实现分布式锁方式有两种方案：

```
1. 创建临时节点，多个客户端同时去创建相同节点，只能一个创建成功，其余的都会创建失败，那么
创建成功的节点就获得锁，失败的就继续等待释放锁
2. 创建临时有序节点，每个客户端都去创建一个临时有序节点，然后获取到所有节点，判断自己是不
是最小的节点，如果是则获得锁，否则监听自己前一个节点锁的释放。
```
基于这种方式实现的分布式锁，可以查看 Curator 客户端连接中的 InterProcessMutex 实现，它的实现逻
辑就是通过创建临时顺序子节点，具体实现过程如下：

```
1. 首先在 InterProcessMutex 中维护一个 ConcurrentMap 集合，集合的键值是当前线程，值是
LockData（他是由当前线程，锁路径、以及重入次数组成）
2. 获取锁时，先从集合中取出当前的 LockData，如果存在说明当前线程已经获取锁，只需要重入次
数加 1 操作，否则就尝试获得锁
3. 尝试获得锁时，先创建属于自己的临时顺序节点，然后先获取到当前锁中所有的顺序子节点（排序
后的），然后判断当前节点是否是最小节点，如果是则获取锁，返回，否则找到前一个节点，然后
在前一个节点上注册一个 wathcer，然后调用 wait 方法进行阻塞（如果设置的等待时间为负数，表
示当前节点没有获得锁时，立即退出，然后会删除当前节点）
4. 当前节点释放锁时，当前节点就会收到 watcher 通知，然后调用 notifyAll () 方法进行唤醒，此时当
前节点再次去竞争锁
5. 当前获得锁之后，会把当前节点和 LockData 保存在集合中，用来处理重入性
6. 锁释放，根据当前节点线程找到需要释放的路径（不存在抛出异常），然后先判断当前的重入性，
如果大于 0 ，表示当前是重入锁，否则如果等于 0 ，则进行锁的释放，小于 0 ，抛出异常
7. 锁的释放过程就是，删除当前节点，从集合中移除当前线程，然后移除 watcher
```
```
}
public String getRepeatKey () {
return repeatKey;
}
public void setRepeatKey (String repeatKey) {
this. repeatKey = repeatKey;
}
@Override
public String toString () {
return "{time=" + time +", repeatKey=\"" + repeatKey+ "\"}";
}
}
```
```
private static String getRepeatKeyV () {
String host= "";
try {
host = InetAddress.getLocalHost (). getHostAddress ();
} catch (UnknownHostException e) {
e.printStackTrace ();
}
return host+Thread.currentThread (). getName ();//采用节点 ip+线程名来做重入判断
}
}
```

```
40 岁老架构师尼恩提示 ：分布式锁是既是面试的绝对重点，也是面试的绝对难点，建议大家有一
个深入和详细的掌握，具体的内容请参见《尼恩 Java 面试宝典-专题 15 ：分布式锁面试题》PDF，
该专题对分布式锁有一个系统化、体系化、全面化的介绍。
```
```
如果要把分布式锁写入简历，可以找尼恩指导。
```
###### 10 、了解 hystrix 么？说一下它的工作原理？

**一、流程图**

下面的图片显示了一个请求在 hystrix 中的流程图。

**1. 构造一个 HystrixCommand 或者 HystrixObservableCommand 对象**

第一步是创建一个 HystrixCommand 或者 HystrixObservableCommand 对象来执行依赖请求。创建时
需要传递相应的参数。

如果请求只返回一个单一值，使用 HystrixCommand。

如果希望返回一个 Observable 来监听多个值，使用 HystrixObservableCommand。

**2. 执行命令**

有四种方法来执行命令（前面两种只对 HystrixCommand 有用，HystrixObservableCommand 没有相
应的方法）。

```
execute－阻塞，阻塞直到收到调用的返回值（或者抛出异常）
queue 返回一个 future，可以通过 future 来获取调用的返回值。
observe 监听一个调用返回的 Observable 对象。
toObservable 返回一个 Observable，当监听该 Observable 后 hystrix 命令将会执行并返回结果。
```
```
HystrixCommand command = new HystrixCommand (arg 1, arg 2);
```
```
HystrixObservableCommand command = new HystrixObservableCommand (arg 1, arg 2);
```

同步调用 execute 本质是调用了 queue (). get (). queue () ,而 queue 本质上调用了
toObservable (). toBlocking (). toFuture (). 本质上都是通过 rxjava 的 Observable 实现。

**3. 是否使用缓存**

如果开启缓存，请求首先会返回缓存中的结果。

**4. 是否开启熔断**

当运行 hystrix 命令时，会判断是否熔断，如果已经熔断，hystrix 将不会执行命令，而是直接执行
fallback。等熔断关闭了，在执行命令。

**5. 线程／队列／信号量是否已满**

如果线程或队列（非线程池模式下是信号量）已满，将不会执行命令，而是直接执行 fallback。

**6.HystrixObservableCommand.construct () or HystrixCommand.run ()**

hystrix 通过一下两种方式来调用依赖：

HystrixObservableCommand.construct () ：返回一个 Observable，发射多个值。

HystrixCommand.run ()：返回一个单一值，或抛异常。

如果 HystrixCommand.run () 或 HystrixObservableCommand.construct () 发送超时，则执行的相应线
程将会抛出 TimeoutException 的异常。然后执行 fallback 流程。并且丢弃 run 或 construst 的返回值。

注意，hystrix 没有办法强制停止线程执行，hysrix 能做的最好方式是抛出 InterruptedException。如果
hystrix 执行的方法没有相应 InterruptedException，那么它会继续执行，但是用户的已经收到
TimeoutException 异常。大多是的 http client 不回响应 InterruptedException，确保正确配置了链接的
timeout 时间。

如果执行方法成功，hystrix 会记录日志、上报 metrics，然后返回执行结果。

**7. 熔断器计算**

hystrix 在成功、失败、拒绝、timeout 时会上报到熔断器模块，熔断器会计算当前的熔断状态。熔断器
使用一个状态来表示当前是否被熔断，一旦熔断所有的请求将不回执行命令直到熔断恢复。

**8. 执行 fallback**

当命令执行失败时，hystrix 会执行 fallback：当 run 或 construct 方法抛出异常；当熔断器被熔断；当线
程池／队列／信号量使用完；当 timeout。

通过 fallback 可以优雅降级，通过静态逻辑返回一个结果。如果你想要在 fallback 中执行依赖调用，那么
必须把这个依赖封装成一个 HystrixCommand 或者 HystrixObservableCommand。HystrixCommand
中通过 fallback 方法来返回一个单一值，HystrixObservableCommand 通过 resumeWithFallback 来返
回一个 Observable 来返回一个或多个值。hystrix 将会把返回值返回给调用方。

如果不实现 fallback 方法，或者执行 fallback 方法抛出异常，hystrix 仍然会返回一个 Observable，但该
Observable 不会发射数据，而是直接执行 error。通过 onerror 通知，告诉调用方失败结果。fallback 不
存在或者 fallback 执行失败，不同的方法将会有不同的表现：

execute，抛出一个异常。

queue，返回一个 future，但是调用 get 方法时，将会抛出异常。

```
K value = command.execute ();
Future<K> fValue = command.queue ();
Observable<K> ohValue = command.observe (); //hot observable
Observable<K> ocValue = command.toObservable ();  //cold observab
```

observe，返回一个 Observable，一旦被监听会立即调用监听者的 onError 方法。

toObservable，返回一个 Observable，一旦被监听会立即调用监听者的 onError 方法。

**9. 返回成功结果**

如果 hystrix 命令执行成功，它将会返回一个 Observable，根据调用的方法，Observable 将会被转换成
响应结果：

```
execute－通过 queue 获取一个 future，然后通过 future 对象的 get 方法获取一个值。
queue－通过 toObservable 获取一个 Observable 对象，然后通过 toBlocking 方法获得一个 Future.
observe-返回 Observable 对象, 当监听该 Observable 会把所有消息重新发送一边。
toObservable-返回 Observable 对象，当监听该 Observable，开始执行命令。
```
**二、熔断器**

下面的图表展示了 HystrixCommand 和 HystrixObservableCommand 与 HystrixCircuitBreaker 交互的
流程，以及 HystrixCircuitBreaker 的原理。


熔断器开关条件：

```
1. 如果请求量到达了指定值
（HystrixCommandProperties. circuitBreakerRequestVolumeThreshold）
2. 如果异常比率超过了指定值
（HystrixCommandProperties. circuitBreakerErrorThresholdPercentage）
3. 则，熔断器将状态设置为 OPEN.
4. 之后所有请求都会被直接熔断。
5. 在经过指定窗口期（HystrixCommandProperties. circuitBreakerSleepWindowInMilliseconds）
后，状态将会被设置为 HALF-OPEN，如果该请求失败了，状态重新被设置为 OPEN 并且等待下一
个窗口期，如果请求成功了，状态设置为 CLOSE。
```
**三、隔离**

hystrix 使用了舱壁隔离模式来隔离和限制各个请求。

**线程和线程池**

第三方依赖在独立的线程池中执行，这样可以隔离调用线程（tomcat 线程池）实现异步调用。

hystrix 为每个依赖服务调用使用独立池。


在依赖调用能够快速失败或者可以一直运行良好的情况下，也可以不使用线程池来执行调用。

hystrix 选择使用线程池有一下原因：

```
很多应用执行大量的第三方调用，这些第三方服务由不同的团队维护。
每一个服务有它自己的依赖包
这些依赖包时刻都可能变化。
依赖包对调用方来说是黑盒的。
```
**四、请求缓存**

HystrixCommand 和 HystrixObservableCommand 实现了缓存机制，通过指定一个 cache key，它们能
够在一个请求范围内对运行结果进行缓存以便下次使用。下面是在一个请求中两个线程执行同一个请求
的流程：


**使用缓存的好处**

```
线程池会隔离每一个依赖，避免他们相互影响，从而保护了整个系统
某几个依赖服务失败后，只要整个系统正常运行，那么恢复起来也很快。
通过线程池可以实现异步操作。
```
总之，通过线程池来隔离依赖服务可以很优雅的隔离那些经常发生变化的依赖服务从而保护整个系统的
运行。

**线程池的缺点**

线程池的主要缺点就是增加了额外的计算资源，每一个命令的执行都需要系统进行调度。netflix 基于线
程池不会耗费大量计算资源而决定使用这样的设计。

**线程池花费**

hystrix 计算了通过线程池执行 construct 和 run 的延时。Netflix API 每天使用线程池方式处理上百亿的请
求，每一个 API 都有 40 多个线程池，每个线程池中有 5 ～ 20 个线程。线图显示了一个 QPS 为 60 的
HystrixCommand 在线程池模式下的执行性能


平均请求，线程池几乎没有什么花费。

90 th％，线程池花费 3 ms

99 th％，线程池花费达到了 9 ms。但是线程池的增长远远小于整个请求的延时增长。超过 90 th%的花费
对于大多数的 Netflix 使用场景来说是可接受的。

**信号量**

也可以使用信号量来限制每个依赖的并发数量。他可以对依赖服务降级，但不能监听 timeout，如果我
们对依赖服务的调用确认不会出现 timeout 情况，我们也可以使用这中方式。

HystrixCommand 和 HystrixObservableCommand 在下面两个地方支持使用信号量。

```
降级方法 fallback ：当 Hystrix 执行 fallback 方法时，总是会通过信号量检查并发量。
执行方法 ：如果设置了 execution. isolation. strategy 为 SEMAPHORE，Hystrix 将会使用信号量来控
制并发数。
```
可以通过动态的配置来设置并发数。尽可能设置合适的并发数，不可设置过大的并发数，这样将导致无
法起保护作用。

**五、请求合并**

通过使用 HystrixCollapser 可以实现合并多个请求批量执行。下面的图标显示了使用请求合并和不是请
求合并，他们的线程迟和连接情况：

使用请求合并可以减少线程数和并发连接数，并且不需要使用这额外的工作。请求合并有两种作用域，
全局作用域会合并全局内的同一个 HystrixCommand 请求，请求作用域只会合并同一个请求内的同一个
HystrixCommand 请求。但是请求合并会增加请求的延时。


**六、缓存**

一个请求对同一个 Hystrix Command 调用可以避免重复执行。

对于一些延时比较低的，不需要检测 timeout 的依赖，我们也可以使用信号量控制方式来做隔离，减少
额外的花费。

这个功能对于多人协作开发的大型的项目非常有用。据一个例子，在一个请求中，多个地方需要使用用
户的 Account 对象。

Hystrix 将会执行 run 方法一次，两个线程都会接收到各自内容相同的 Account 对象。当执行第一次 run 方
法后，结果将会被缓存起来，当在同一个请求执行同一个命令时，会直接使用缓存值。

减少线程重复执行。

因为缓存是在执行 run 或者 construct 方法前进行判断的，所以可以减少 run 和 construct 的调用。如果
Hystrix 没有实现缓存功能，那么每个调用都需要执行 construct 或者 run 方法。

###### 11 、说说 Nio 和 IO 有什么区别

**一、概述**

NIO 即 New IO，这个库是在 JDK 1.4 中才引入的。NIO 和 IO 有相同的作用和目的，但实现方式不同，NIO
主要用到的是块，所以 NIO 的效率要比 IO 高很多。在 Java API 中提供了两套 NIO，一套是针对标准输入
输出 NIO，另一套就是网络编程 NIO。

NIO 和 IO 的主要区别，下表总结了 Java IO 和 NIO 之间的主要区别：

```
Account account = new UserGetAccount (accountId). execute ();
```
```
//or
Observable<Account> accountObservable = new UserGetAccount (accountId). observe ();
```

```
类型 IO NIO
```
```
流类型面向流面向缓冲
```
```
是否阻塞阻塞 IO 非阻塞 IO
```
```
有无选择器无选择器
```
真正的了解 NIO 一定要看 Netty，Netty 是 NIO 里用的最好的框架。

**二、IO 与 NIO 区别详解**

**1. 面向流与面向缓冲**

Java IO 和 NIO 之间第一个最大的区别是，IO 是面向流的，NIO 是面向缓冲区的。 Java IO 面向流意味着
每次从流中读一个或多个字节，直至读取所有字节，因为它们没有被缓存在任何地方，所以，它不能前
后移动流中的数据。如果需要前后移动从流中读取的数据，需要先将它缓存到一个缓冲区。

Java NIO 的缓冲导向方法略有不同。数据读取到一个它稍后处理的缓冲区，需要时可在缓冲区中前后移
动。这就增加了处理过程中的灵活性。但是，还需要检查是否该缓冲区中包含所有您需要处理的数据。
而且，需确保当更多的数据读入缓冲区时，不要覆盖缓冲区里尚未处理的数据。

**2. 阻塞与非阻塞 IO**

Java IO 的各种流是阻塞的。这意味着，当一个线程调用 read () 或 write () 时，该线程被阻塞，直到有一
些数据被读取，或数据完全写入。该线程在此期间不能再干任何事情了。Java NIO 的非阻塞模式，使一
个线程从某通道发送请求读取数据，但是它仅能得到目前可用的数据，如果目前没有数据可用时，就什
么都不会获取，而不是保持线程阻塞，所以直至数据变的可以读取之前，该线程可以继续做其他的事
情。非阻塞写也是如此。一个线程请求写入一些数据到某通道，但不需要等待它完全写入，这个线程同
时可以去做别的事情。线程通常将非阻塞 IO 的空闲时间用于在其它通道上执行 IO 操作，所以一个单独的
线程现在可以管理多个输入和输出通道 channel。

**3. 选择器（Selectors）**

Java NIO 的选择器允许一个单独的线程来监视多个输入通道，你可以注册多个通道使用一个选择器，然
后使用一个单独的线程来“选择”通道：这些通道里已经有可以处理的输入，或者选择已准备写入的通
道。这种选择机制，使得一个单独的线程很容易来管理多个通道。

**4. NIO 和 IO 适用场景**

NIO 是为弥补传统 IO 的不足而诞生的，但是尺有所短寸有所长，NIO 也有缺点，因为 NIO 是面向缓冲区
的操作，每一次的数据处理都是对缓冲区进行的，那么就会有一个问题，在数据处理之前必须要判断缓
冲区的数据是否完整或者已经读取完毕，如果没有，假设数据只读取了一部分，那么对不完整的数据处
理没有任何意义。所以每次数据处理之前都要检测缓冲区数据。

**那么 NIO 和 IO 各适用的场景是什么呢？**

如果需要管理同时打开的成千上万个连接，这些连接每次只是发送少量的数据，例如聊天服务器，这时
候用 NIO 处理数据可能是个很好的选择。

而如果只有少量的连接，而这些连接每次要发送大量的数据，这时候传统的 IO 更合适。使用哪种处理数
据，需要在数据的响应等待时间和检查缓冲区数据的时间上作比较来权衡选择。

**三、Java NIO 总览**

Java NIO 的三个核心基础组件：Channels、Buffers、Selectors。其余的诸如 Pipe，FileLcok 都是在使
用以上三个核心组件时帮助更好使用的工具类。


###### 12 、说说 NIO 和 AIO 的区别

NIO（New IO）和 AIO（Asynchronous I/O）都是基于内存缓存的通道与传输机制，可以直接读写本地
文件和网络通道，不需要经过文件系统和网络协议栈。两者的主要区别如下：

**1. 数据通信方式不同**

NIO 基于通道和传输机制，IO 基于文件和网络协议栈。在 NIO 中，通道可以是 TCP 通道、UDP 通道等，
而 IO 只能是 TCP 通道。

**2. 对内存的使用不同**

NIO 对内存进行了缓存和重用，使得 NIO 程序可以高效地读写内存中的数据。IO 没有使用内存缓存机
制，每次读写都需要使用文件和网络协议栈。

**3. 事件驱动模型不同**

NIO 采用了事件驱动模型，程序可以根据 IO 事件进行读写操作。IO 则采用了同步阻塞模型，需要等待操
作完成才能返回结果。

**4. 应用场景不同**

NIO 适用于需要高并发、高吞吐量的场景，例如 Web 服务器、IM 应用等。IO 适用于需要低延迟、高可靠
性的场景，例如数据库、文件系统等。

因此，虽然 NIO 和 AIO 都是基于内存缓存的通道与传输机制，但是两者的数据通信方式、对内存的使
用、事件驱动模型和应用场景有很大的不同。对于需要高并发和高吞吐量的应用，使用 NIO 是一个不错
的选择；而对于需要低延迟和高可靠性的应用，则可以使用 AIO。

###### 13 、Spring 的 aop 怎么实现？Spring 的 aop 有哪些实现方式

AOP（Aspect Oriented Programming）面向切面编程，通过预编译方式和运行期动态代理实现程序功
能的横向多模块统一控制的一种技术。通俗点，就是在不改变系统原本业务功能的前提下，对系统的功
能进行横向扩展。

**一、AOP 的相关概念**

```
1. 横切关注点 ：对哪些方法进行拦截，拦截后怎么处理，这些关注点称之为横切关注点
2. Aspect（切面） ：通常是一个类，里面可以定义切入点和通知
3. JointPoint（连接点） ：程序执行过程中明确的点，一般是方法的调用。被拦截到的点，因为
Spring 只支持方法类型的连接点，所以在 Spring 中连接点指的就是被拦截到的方法，实际上连接点
还可以是字段或者构造器
4. Advice（通知） ：AOP 在特定的切入点上执行的增强处理，有 before (前置)、after (后置)、
afterReturning (最终)、afterThrowing (异常)、around (环绕)
5. Pointcut（切入点） ：就是带有通知的连接点，在程序中主要体现为书写切入点表达式
6. weave（织入） ：将切面应用到目标对象并导致代理对象创建的过程
7. introduction（引入） ：在不修改代码的前提下，引入可以在运行期为类动态地添加一些方法或
字段
8. AOP 代理（AOP Proxy） ：AOP 框架创建的对象，代理就是目标对象的加强。Spring 中的 AOP 代
理可以使 JDK 动态代理，也可以是 CGLIB 代理，前者基于接口，后者基于子类
9. 目标对象（Target Object） : 包含连接点的对象。也被称作被通知或被代理对象。
```
**二、使用 AOP 的三大方式**

```
1. 方式一：使用原生 Spring API 接口
```

```
2. 方式二：自定义切面类
3. 方式三：注解方式
```
**方式一：使用原生 Spring API 接口**

创建 UserService 接口，包含 4 个方法，并创建 UserServiceImpl 类实现该接口。

创建 Log 类，实现 MethodBeforeAdvice 接口，在这里可以进行一些自定义操作，比如向控制台输出一
句话，还可以利用反射机制获得该方法的一些信息，必须方法名等，这是另外两大方法所不具备的优
点，该切面方法会放在切入点方法调用之前调用。

创建 AfterLog 类，实现 AfterReturningAdvice 接口，在这里可以进行一些自定义操作，比如向控制台输
出一句话，还可以利用反射机制获得该方法的一些信息，必须方法名等，这是另外两大方法所不具备的
优点，该切面方法会放在切入点方法调用之前调用。

```
public interface UserService {
public void add ();
public void delete ();
public void update ();
public void select ();
}
123456
public class UserServiceImpl implements UserService {
public void add () {
System.out.println ("增加了一个用户");
}
```
```
public void delete () {
System.out.println ("删除了一个用户");
}
```
```
public void select () {
System.out.println ("查询了一个用户");
}
```
```
public void update () {
System.out.println ("修改了一个用户");
}
}
```
```
import org. springframework. aop. MethodBeforeAdvice;
```
```
import java. lang. reflect. Method;
```
```
public class Log implements MethodBeforeAdvice {
//method: 要执行的目标对象的方法
//args: 参数
//target: 目标对象
public void before (Method method, Object[] args, Object target) throws
Throwable {
System.out.println (target.getClass (). getName ()+"的"+method.getName ()+"被
执行了");
}
}
```

在 xml 配置文件中的标签中应加上对应的 aop 地址，创建相应 bean，对 aop 进行配置，并导入 aop 的约
束。

_com. kuang. service. UserServiceImpl._ (...) 指切入点为 UserServiceImpl 类中的所有方法。

**运行结果：**

```
com. kuang. service. UserServiceImpl 的 add 被执行了
增加了一个用户
执行了 add 方法，返回结果为：null
```
**方式二：自定义切面类**

创建自定义切面类 DiyPointCut，里面包含一些自定义的切面方法。

```
import org. springframework. aop. AfterReturningAdvice;
```
```
import java. lang. reflect. Method;
```
```
public class AfterLog implements AfterReturningAdvice {
//returnValue: 返回值
public void afterReturning (Object returnValue, Method method, Object[] args,
Object target) throws Throwable {
System.out.println ("执行了"+method.getName ()+"方法，返回结果
为："+returnValue);
}
}
```
```
<?xml version="1.0" encoding="UTF-8"?>
<beans xmlns="http://www.springframework.org/schema/beans"
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
xmlns:aop="http://www.springframework.org/schema/aop"
xsi:schemaLocation="http://www.springframework.org/schema/beans
https://www.springframework.org/schema/beans/spring-
beans. xsd
http://www.springframework.org/schema/aop
https://www.springframework.org/schema/aop/spring-
aop. xsd">
```
```
<!--注册bean -->
<bean id="userService" class="com.kuang.service.UserServiceImpl"/>
<bean id="log" class="com.kuang.log.Log"/>
<bean id="afterLog" class="com.kuang.log.AfterLog"/>
```
```
<!-- 方式一：使用原生Spring API接口-->
<!-- 配置aop:需要导入aop的约束-->
<aop:config>
<!-- 切入点:execution:表达式，execution（要执行的位置）-->
<aop: pointcut id="poinicut" expression="execution (*
com. kuang. service. UserServiceImpl.*(..))"/>
<!--执行环绕增加 -->
<aop:advisor advice-ref="log" pointcut-ref="poinicut"/>
<aop:advisor advice-ref="afterLog" pointcut-ref="poinicut"/>
</aop:config>
```

在 applicationContext. xml 文件中的 aop 配置为：

**运行结果**

```
=========== 方法执行前 ==========
增加了一个用户
=========== 方法执行后==========
```
**方式三：注解方式**

建立一个切面方法类 (AnnotationPointCut)，里面包含一些切面方法，比如 before、after、aroud 等。

```
public class DiyPointCut {
public void before (){
System.out.println ("===========方法执行前==========");
}
public void after (){
System.out.println ("===========方法执行后==========");
}
}
```
```
<!-- 方式二：自定义类-->
<bean id="diy" class="com.kuang.diy.DiyPointCut"/>
<aop:config>
<!-- 自定义切面，ref要引用的类-->
<aop:aspect ref="diy">
<!--切入点 -->
<aop: pointcut id="point" expression="execution (*
com. kuang. service. UserServiceImpl.*(..))"/>
<!--通知 -->
<aop:before method="before" pointcut-ref="point"/>
<aop:after method="after" pointcut-ref="point"/>
</aop:aspect>
</aop:config>
```
```
import org. aspectj. lang. ProceedingJoinPoint;
import org. aspectj. lang. annotation. After;
import org. aspectj. lang. annotation. Around;
import org. aspectj. lang. annotation. Aspect;
import org. aspectj. lang. annotation. Before;
```
```
//方式三：使用注解方式实现 AOP
@Aspect//标注这个类是一个切面
public class AnnotationPointCut {
@Before ("execution (* com. kuang. service. UserServiceImpl.*(..))")
public void before (){
System.out.println ("==========方法执行前==========");
}
@After ("execution (* com. kuang. service. UserServiceImpl.*(..))")
public void after (){
System.out.println ("==========方法执行后==========");
}
@Around ("execution (* com. kuang. service. UserServiceImpl.*(..))")
public void around (ProceedingJoinPoint jp) throws Throwable{
System.out.println ("环绕前");
Object proceed=jp.proceed ();
```

在 applicationContext. xml 配置文件中对 aop 进行配置

**运行结果**

```
环绕前
========== 方法执行前==========
增加了一个用户
环绕后
========== 方法执行后==========
```
这里注意 aroud 与 before、after 方法的执行顺序：

```
环绕前—>方法执行前—>增加了一个用户—>环绕后—>方法执行后
```
**总结**

```
1. 使用原生的 spring AIP 接口，代码较为复杂，但可以在切面方法中利用反射机制获得切入点方法的
相关信息，比如获得切入点方法的方法名。
2. 使用自定义切面类的方法，简单易懂。
3. 使用注解的方式，方便便捷，大大简化了 xml 配置文件中 aop 代码，只需要开启注解即可
4. 最重要的是：AOP 思想可以与动态代理相结合，在本例中有所体现，UserServiceImpl 类实现了
UserService 接口，我们可以在 UserServiceImpl 类中对 UserService 接口中的方法进行扩展，再结
合 AOP 思想，可以极大的方便我们的日常开发。
```
###### 14 、说说动态代理的实现方式和区别

动态代理是一种在运行时创建代理对象的方式，它可以在不修改原始类的情况下，为其添加额外的功
能。在 Java 中，有两种常见的动态代理实现方式：基于接口的动态代理和基于类的动态代理。

```
1. 基于接口的动态代理：
实现方式 ：基于接口的动态代理是通过 Java 的 java. lang. reflect. Proxy 类实现的。该类
提供了一个 newProxyInstance () 方法，通过传入目标类的接口、一个
InvocationHandler 对象和类加载器来创建代理对象。
实现原理 ：在运行时，当调用代理对象的方法时，实际上会被转发到 InvocationHandler 对
象的 invoke () 方法中。在 invoke () 方法中，可以执行一些前置或后置操作，并最终调用目
标对象的方法。
适用场景 ：基于接口的动态代理适用于目标对象实现了接口的情况。
2. 基于类的动态代理：
实现方式 ：基于类的动态代理是通过使用第三方库（如 CGLIB）来实现的。该库通过生成目
标类的子类来创建代理对象。
实现原理 ：在运行时，当调用代理对象的方法时，实际上会被转发到子类中重写的方法中。
在重写的方法中，可以执行一些前置或后置操作，并最终调用目标对象的方法。
适用场景 ：基于类的动态代理适用于目标对象没有实现接口的情况。
```
```
System.out.println ("环绕后");
}
}
```
```
<!-- 方式三：注解方式-->
<bean id="annotationPointCut" class="com.kuang.diy.AnnotationPointCut"/>
<!--开启注解支持 -->
<aop:aspectj-autoproxy/>
```

区别：

```
基于接口的动态代理要求目标对象实现接口，而基于类的动态代理可以代理任何类，无论是否实现
接口。
基于接口的动态代理是通过 Java 标准库实现的，而基于类的动态代理需要使用第三方库。
基于接口的动态代理创建的代理对象是一个实现了目标接口的实例，而基于类的动态代理创建的代
理对象是目标类的子类。
基于接口的动态代理执行效率相对较高，而基于类的动态代理执行效率较低。
```
总体而言，基于接口的动态代理更加灵活，并且是 Java 官方支持的方式；而基于类的动态代理在某些场
景下更加方便，尤其是对于没有实现接口的类。

###### 15 、聊聊索引在哪些场景下会失效？

索引在以下场景下可能会失效：

```
1. 使用函数或表达式进行查询 ：如果在查询条件中使用了函数或表达式，例如 WHERE
UPPER (column_name) = 'VALUE'，索引可能无法起作用，因为函数或表达式的结果无法直接匹
配索引中的值。
2. 对索引列进行类型转换 ：如果在查询条件中对索引列进行了类型转换，例如 WHERE
CAST (column_name AS VARCHAR) = 'value'，索引可能无法起作用，因为类型转换后的值无法
直接匹配索引中的数据类型。
3. 使用模糊查询 ：当使用模糊查询操作符（如 LIKE）进行搜索时，如果搜索模式以通配符开头（例
如 LIKE '%value'），则索引可能无法起作用，因为通配符开头的模式无法利用索引的有序性。
4. 列的基数太低 ：如果索引列的基数（不同值的数量）非常低，即使使用了索引，数据库优化器可能
会认为全表扫描更快，从而选择不使用索引。
5. 数据量过小 ：当表中的数据量非常小（例如只有几行）时，使用索引进行查询可能会比全表扫描更
慢，因为额外的索引查找开销可能会抵消使用索引的好处。
6. 范围查询 ：对于一些范围查询（例如 BETWEEN、>、<等），索引可能会失效，因为范围查询需要
扫描多个索引节点，而不是单个等值匹配。
7. 隐式类型转换 ：如果在查询条件中进行了隐式类型转换，例如将字符串与数字进行比较，索引可能
无法起作用，因为隐式转换可能导致索引列的值与查询条件不匹配。
8. 复合索引中未使用第一个列 ：对于复合索引，如果查询条件没有使用到索引的第一个列，那么索引
可能会失效。
```
要确保索引的有效使用，需要根据具体的查询场景和数据特点来设计和优化索引。

###### 16 、怎么查看系统负载

**一、uptime**

一种简单的方法是通过命令 "uptime" 来查看系统负载。这个命令会输出系统启动以来的总时间和系统
当前的负载状态。

例如，如果系统负载较高，你可以看到类似下面的输出：

这个输出表示在过去 1 分钟、 5 分钟和 15 分钟内，系统的负载状态分别为 1.24、1.24 和 1.24。

**二、top**

```
load average: 1 .24 1 .24 1 .24
```

另外，一些图形化界面的系统管理工具也可以提供系统负载的图表，让你更直观地了解系统的负载状
态。例如，在 Linux 系统中，你可以使用 "top" 命令来查看系统负载，如下所示：

这个命令会以字符界面的形式显示系统当前的进程和系统资源的使用情况，包括 CPU、内存、磁盘等。
你可以根据需要使用 "Ctrl+C" 退出命令。

###### 17 、分布式 id 生成方案有哪些？什么是雪花算法？

分布式 ID 生成方案是在分布式系统中生成唯一 ID 的一种解决方案，常见的分布式 ID 生成方案包括：

```
1. UUID（Universally Unique Identifier）：UUID 是一种由 128 位数字组成的标识符，通常以 32 个
十六进制数字表示。它可以在不同系统和多个节点之间生成唯一 ID，但由于其长度较长，不适合
作为数据库索引或 URL 参数。
2. 数据库自增 ID：通过数据库的自增主键生成 ID，保证了递增和唯一性。但在分布式系统中，需要
使用分布式锁或其他机制来保证生成的 ID 的唯一性。
3. 基于 Redis 或 ZooKeeper 的分布式 ID 生成器：使用 Redis 或 ZooKeeper 等分布式存储系统作为中心
化的 ID 生成器，利用其原子性操作和分布式特性来保证生成的 ID 的唯一性。
4. Twitter 的 Snowflake 算法：Snowflake 算法是一种基于时间戳、机器 ID 和序列号的分布式 ID 生成算
法。它使用了一个 64 位的整数，其中包含了时间戳、机器 ID 和序列号，并且保证了生成的 ID 在分
布式系统中的唯一性和有序性。
```
雪花算法是 Twitter 开源的一种分布式 ID 生成算法，它是基于 Snowflake 算法实现的。雪花算法使用了一
个 64 位的整数，其中包含了时间戳、机器 ID、数据中心 ID 和序列号。具体来说：

```
符号位 ： 1 位，固定为 0 。
时间戳 ： 41 位，精确到毫秒级，可以支持约 69 年的时间戳。
数据中心 ID 和机器 ID ： 10 位，分别用于标识数据中心和机器，可以支持 1024 个数据中心和每个数
据中心 1024 台机器。
序列号 ： 12 位，用于解决在同一毫秒内生成 ID 时的并发冲突问题，支持每个节点每毫秒最多生成
4096 个 ID。
```
通过雪花算法生成的 ID 既能保证在分布式系统中的唯一性，又能保证 ID 的有序性（按照时间戳递增）。
雪花算法非常适合高并发环境下的分布式 ID 生成需求。

```
40 岁老架构师尼恩提示 ：分布式 id 是既是面试的绝对重点，也是面试的绝对难点，建议大家有一
个深入和详细的掌握，具体的内容请参见尼恩的《10 Wqps 推送中台实操》，该专题对分布式 id 有
一个系统化、体系化、全面化的介绍。
```
```
如果要把推送中台写入简历，可以找尼恩指导。
```
###### 18 、Linux 中，查找磁盘上最大的文件的命令

在 Linux 中，可以使用 du 命令来查找磁盘上最大的文件。具体命令如下：

这个命令的含义是：

```
top
```
```
du -sh * | sort -rh | head -n 1
```

```
du 命令用于显示指定目录或文件的磁盘使用情况；
```
- s 选项表示只显示指定目录或文件的总大小；
- h 选项表示以人类可读的方式显示大小 (例如，将字节转换为 KB、MB、GB 等);
* 表示查找当前目录下的所有文件和目录；
| 符号用于将前面的命令输出作为后面命令的输入；
sort 命令用于对输入进行排序；
- r 选项表示按照降序排序；
- h 选项表示按照人类可读的方式排序；
head 命令用于显示前几行结果，这里设置为只显示一行结果；
- n n 选项表示显示前 n 行结果。

###### 19 、Linux 中，如何查看系统日志文件

在 Linux 中，可以使用 cat、less、tail、grep 等命令来查看系统日志文件。

以下是一些常用的命令：

```
cat /var/log/messages：显示系统消息日志文件的内容；
less /var/log/messages：分页显示系统消息日志文件的内容；
tail -f /var/log/messages：实时显示系统消息日志文件的最后几行内容；
grep "error" /var/log/messages：查找包含 "error" 字符串的系统消息日志文件的内容；
sudo journalctl -u sshd. service：查看 SSHD 服务的日志文件。
```
```
40 岁老架构师尼恩提示 ：Linux 是既是面试的绝对重点，也是面试的绝对难点，建议大家有一个深
入和详细的掌握，具体的内容请参见《尼恩 Java 面试宝典-专题 22 ：Linux 面试题》PDF，该专题
对 Linux 有一个系统化、体系化、全面化的介绍。
```
```
如果要把 Linux 相关实战写入简历，可以找尼恩指导
```
###### 20 、聊聊事务隔离级别，以及可重复读实现原理

事务隔离级别是数据库管理系统中用来控制并发访问数据的一种机制。常见的事务隔离级别包括读未提
交（Read Uncommitted）、读已提交（Read Committed）、可重复读（Repeatable Read）和串行
化（Serializable）。

在可重复读隔离级别下，事务在执行期间看到的数据是一致的，即使其他事务对数据进行了修改。这是
通过多版本并发控制（MVCC）实现的。下面是可重复读实现原理的简要说明：

```
1. 事务开始时，会为每个读取的数据行创建一个快照（Snapshot），该快照会记录当前数据行的状
态。
2. 在事务执行期间，其他事务对数据行进行修改不会影响当前事务的快照数据。
3. 当前事务读取数据时，会使用快照数据而不是实时数据。
4. 当前事务对数据进行修改时，会在修改的数据行上创建一个新的版本，并更新快照数据。
5. 如果其他事务在当前事务执行期间对数据行进行修改，并且修改的数据行版本晚于当前事务的快照
版本，则当前事务会回滚并重新执行。
```
通过使用快照和版本控制，可重复读隔离级别可以保证事务在执行期间看到一致的数据。


需要注意的是，不同的数据库管理系统可能会有不同的实现方式，但基本原理是相似的。同时，可重复
读隔离级别也可能导致幻读问题，即在同一事务中多次执行相同的查询，但结果集不一致。为了解决幻
读问题，可以使用更高级别的隔离级别，如串行化。

###### 21 、os 进程间怎么通信？

在操作系统中，进程间通信 (Inter-Process Communication, IPC) 是指不同进程之间进行数据交换和共享
资源的过程。常见的进程间通信方式包括以下几种：

```
1. 管道 (Pipe) ：管道是一种半双工的通信方式，数据只能单向流动，且只能在具有亲缘关系的进程间
使用。管道分为匿名管道和命名管道两种。
2. 消息队列 (Message Queue) ：消息队列是一种消息的链表，存放在内核中并由消息队列标识符标
识。发送进程将消息放入消息队列中，接收进程从消息队列中取出消息进行处理。
3. 共享内存 (Shared Memory) ：共享内存是最快的 IPC 方式，它允许多个进程访问同一块内存空
间，因此可以实现数据的共享。但是，由于多个进程同时读写同一块内存空间可能会导致数据不一
致的问题，所以需要加锁来保证数据的同步性。
4. 信号量 (Semaphore) ：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。当一个
进程需要访问共享资源时，它会请求信号量，如果信号量的值大于 0, 则该进程可以获得访问权；否
则，该进程需要等待其他进程释放信号量。
5. 套接字 (Socket) ：套接字是一种网络编程中的通信方式，可以在不同的主机之间进行通信。套接字
提供了一种可靠的、高效的、全双工的通信机制，可以用于实现不同进程之间的通信。
```
###### 22 、os 有使用哪些数据结构？

操作系统中常用的数据结构包括：

```
1. 数组 (Array) ：是一种线性数据结构，用于存储相同类型的元素。数组在内存中是连续的一段空
间，可以通过下标来访问其中的元素。
2. 链表 (Linked List) ：是一种非线性数据结构，由一系列节点组成，每个节点包含一个数据元素和
指向下一个节点的指针。链表可以动态地添加或删除节点，但访问某个节点的时间复杂度为 O (n)。
3. 栈 (Stack) ：是一种后进先出 (LIFO) 的数据结构，用于存储函数调用时的局部变量、表达式的计算
结果等信息。栈中的元素只能从栈顶进行插入和删除操作。
4. 队列 (Queue) ：是一种先进先出 (FIFO) 的数据结构，用于实现生产者-消费者模型。队列中的元素按
照先进先出的顺序排列，可以进行入队和出队操作。
5. 树 (Tree) ：是一种非线性数据结构，由若干个节点组成，每个节点包含一个数据元素和若干个子节
点。树可以分为二叉树、平衡树、B+树等多种类型。
```
除了以上常见的数据结构，操作系统中还使用了其他一些特殊的数据结构，如散列表、红黑树、图等。
这些数据结构在操作系统的实现中发挥着重要的作用。

###### 23 、说说对 Linux 的了解

Linux 是一种操作系统内核，它是由一些志愿者开发的，具有开放源代码的特点。Linux 系统在全球范围
内被广泛应用于各种不同的领域，例如服务器、工作站、嵌入式系统等。

Linux 系统的优势包括：

```
1. 开放源代码 ：Linux 系统的源代码是开放的，这意味着用户可以根据需要自由地修改和扩展 Linux
系统。
2. 稳定性高 ：Linux 系统的稳定性非常高，它的稳定性和安全性已经得到了广泛的验证和认可。
```

```
3. 安全性高 ：Linux 系统的安全性也非常高，它具有多种安全保护措施，例如访问控制、权限管理、
病毒防范等。
4. 可定制性强 ：Linux 系统的可定制性非常强，用户可以根据需要自由地定制 Linux 系统的功能和外
观。
5. 性能优良 ：Linux 系统具有非常优良的性能，它可以快速地处理大量的数据和任务。
```
应用场景：

```
1. 服务器 ：Linux 系统是最常用的服务器操作系统之一，例如 Apache、MySQL、PHP 等都是基于
Linux 系统的。
2. 嵌入式系统 ：Linux 系统可以应用于各种嵌入式设备中，例如移动设备、物联网设备等。
3. 工作站 ：Linux 系统也是一种非常流行的工作站操作系统，例如 Ubuntu、Fedora 等。
```
注意事项：

```
1. 尽量避免在标准输入、标准输出和标准错误输出中使用"/"字符。
2. 在配置网络设备时，需要注意设备的型号、驱动程序等问题。
3. 在安装和配置 Linux 系统时，需要注意权限和用户管理等问题。
```
###### 24 、TCP 和 UDP 的区别？

**一、TCP 和 UDP 是什么？**

TCP：

传输控制协议（TCP，Transmission Control Protocol）是一种面向连接的、可靠的、基于字节流的传
输层通信协议，由 IETF 的 RFC 793 定义。

UDP：

Internet 协议集支持一个无连接的传输协议，该协议称为用户数据报协议（UDP，User Datagram
Protocol）。UDP 为应用程序提供了一种无需建立连接就可以发送封装的 IP 数据包的方法。RFC 768
描述了 UDP。

**二、TCP 和 UDP 有什么区别?**

**1. TCP 和 UDP 区别总结**

TCP 与 UDP 区别总结：

```
1. TCP 面向连接，通过三次握手建立连接，四次挥手接除连接; UDP 是无连接的，即发送数据之前不
需要建立连接，这种方式为 UDP 带来了高效的传输效率，但也导致无法确保数据的发送成功。
2. TCP 是可靠的通信方式。通过 TCP 连接传送的数据，TCP 通过超时重传、数据校验等方式来确保数
据无差错，不丢失，不重复，且按序到达；而 UDP 由于无需连接的原因，将会以最大速度进行传
输，但不保证可靠交付，也就是会出现丢失、重复等等问题。
3. TCP 面向字节流，实际上是 TCP 把数据看成一连串无结构的字节流，由于连接的问题，当网络出现
波动时，连接可能出现响应问题；UDP 是面向报文的，UDP 没有拥塞控制，因此网络出现拥塞不
会使源主机的发送速率降低。
4. 每一条 TCP 连接只能是点到点的；而 UDP 不建立连接，所以可以支持一对一，一对多，多对一和多
对多的交互通信，也就是可以同时接受多个人的包。
5. TCP 需要建立连接，首部开销 20 字节相比 8 个字节的 UDP 显得比较大。
6. TCP 的逻辑通信信道是全双工的可靠信道，UDP 则是不可靠信道。
```
**2. TCP 三次握手和四次挥手**

**1 ）TCP 三次握手**


三次握手是 TCP 用来确保连接可靠建立的方式：

```
第一次握手 ： A 给 B 发短信说：“B，你现在有空吗？”
第二次握手 ： B 此时收到了 A 的信息，然后对 A 说： “ 我有空，你呢？有空吗？ ”
第三次握手 ： A 此时收到了 B 的确认信息，然后说：“我也有空，那我跟你说个事。”
```
```
在三次握手之后，A 和 B 都能确定这么一件事： 双方的通信可以流畅的进行。这样，双方就可以
开始进行正常的对话了。
```
**2 ）TCP 四次挥手**

四次挥手是 TCP 用来确保连接可靠关闭的方式：

```
第一次挥手 ： A 给 B 发短信说：“B，我要准备吃饭了？”
第二次挥手 ： B 此时收到了 A 的信息，然后先对 A 说： “ 我知道了。”
第三次挥手 ： B 对 A 说到： “ 我也要准备吃饭了。”然后放下了手机，
第四次挥手 ： A 此时收到了 B 的确认信息，然后想 B 发一个包说：“好的，我知道了。”这时才放下手
机去吃饭，
```
```
在四次挥手之后，A 和 B 都能确定这么一件事： 双方的通信可以正常关闭。这样，双方就可以确
定对方已经完全知晓自己确认要关闭连接。
```
**3. TCP 维护可靠的通信方式**

```
1. 数据分片 ：在发送端对用户数据进行分片，在接收端进行重组，由 TCP 确定分片的大小并控制分片
和重组；
2. 到达确认 ：接收端接收到分片数据时，根据分片数据序号向发送端发送一个确认包；
3. 超时重发 ：发送方在发送分片后计时，若超时却没有收到相应的确认包，将会重发对应的分片；
4. 滑动窗口 ：TCP 连接双方的接收缓冲空间大小都固定，接收端只能接受缓冲区能接纳的数据。
5. 失序处理 ：TCP 的接收端需要重新排序接收到的数据。
6. 重复处理 ：如果传输的 TCP 分片出现重复，TCP 的接收端需要丢弃重复的数据。
7. 数据校验 ：TCP 通过保持它首部和数据的检验和来检测数据在传输过程中的任何变化。
```
**4. TCP 和 UDP 使用场景**

**1 ）UDP 使用场景:**

因此 UDP 不提供复杂的控制机制，利用 IP 提供面向无连接的通信服务，随时都可以发送数据，处理简单
且高效。
所以主要使用在以下场景：

```
包总量较小的通信（DNS、SNMP）
视频、音频等多媒体通信（即时通信）
QQ 就是使用的 UDP 协议。
广播通信
```
```
主要是一切追求速度的场景上
```
**2 ）TCP 使用场景:**

TCP 使用场景：相对于 UDP，TCP 实现了数据传输过程中的各种控制，可以进行丢包时的重发控制，
还可以对次序乱掉的分包进行顺序控制。在对可靠性要求较高的情况下，可以使用 TCP，即不考虑
UDP 的时候，都可以选择 TCP。

```
特别是需要可靠连接，比如付费、加密数据等等方向都需要依靠 TCP
```

**总结**

面向连接的 TCP 与无连接的 UDP 将是网络协议中不可或缺的重要知识点，TCP 和 UDP 是 TCP/IP 中有两
个具有代表性的传输层协议，也是常年常考题型。

```
40 岁老架构师尼恩提示 ：TCP/IP 协议是既是面试的绝对重点，也是面试的绝对难点，建议大家有
一个深入和详细的掌握，具体的内容请参见《尼恩 Java 面试宝典-专题 10 ：TCPIP 协议》PDF，该
专题对 TCP/IP 协议有一个系统化、体系化、全面化的介绍。
```
```
如果要把 TCP/IP 实战写入简历，可以找尼恩指导
```
###### 25 、HTTP 和 HTTPS 的区别？

**一、什么是 HTTP？**

超文本传输协议（HTTP，HyperText Transfer Protocol) 是互联网上应用最为广泛的一种网络协议。所
有的 WWW 文件都必须遵守这个标准。HTTP 是客户端浏览器或其他程序与 Web 服务器之间的应用层通
信协议。

**二、什么是 HTTPS？**

HTTPS（全称：Hyper Text Transfer Protocol over Secure Socket Layer 或 Hypertext Transfer
Protocol Secure，超文本传输安全协议），是以安全为目标的 HTTP 通道，简单讲是 HTTP 的安全版。即
HTTP 下加入 SSL 层，HTTPS 的安全基础是 SSL，因此加密的详细内容就需要 SSL。它是一个 URI
scheme（抽象标识符体系），句法类同 http 体系。用于安全的 HTTP 数据传输。

**三、HTTP 与 HTTPS 有什么区别？**

HTTP 协议传输的数据都是未加密的，也就是明文的，因此使用 HTTP 协议传输隐私信息非常不安全，为
了保证这些隐私数据能加密传输，于是网景公司设计了 SSL（Secure Sockets Layer）协议用于对 HTTP
协议传输的数据进行加密，从而就诞生了 HTTPS。简单来说，HTTPS 协议是由 SSL+HTTP 协议构建的可
进行加密传输、身份认证的网络协议，要比 http 协议安全。

HTTPS 和 HTTP 的区别主要如下：

```
1. https 需要到证书机构申请证书。
2. http 是超文本传输协议，信息是明文传输，https 则是通过 ssl 加密传输协议。
3. http 和 https 使用的是完全不同的连接方式，前者默认端口是 80 ，后者默认是 443 。
```
**四、HTTPS 有什么用？**

在描述 HTTPS 有什么用之前，先来了解什么是 HTTPS 证书（即 SSL 证书）。

简单来说，SSL 证书 = HTTPS +证书 +域名。HTTPS 证书（即 SSL 证书）。HTTPS 证书是颁发给标识互联
网域名的数字证书，证书作用为建立 SSL 加密通道。结合 HTTPS 证书，来描述 HTTPS，更容易理解
HTTPS 的作用。将 SSL 证书安装在网站服务器上，可实现网站身份验证和数据加密传输双重功能。

A：安全上的作用

1 ）实现加密传输

用户通过 http 协议访问网站时，浏览器和服务器之间是明文传输，安装 SSL 证书后，使用 Https 协议加密
访问网站，可激活客户端浏览器到网站服务器之间的"SSL 加密通道"（SSL 协议），实现高强度双向加密
传输，防止传输数据被泄露或篡改。

2 ）认证服务器真实身份（防钓鱼）


钓鱼欺诈网站泛滥，用户如何识别网站是钓鱼网站还是安全网站？网站部署全球信任的 SSL 证书后，浏
览器内置安全机制，实时查验证书状态，通过浏览器向用户展示网站认证信息，让用户轻松识别网站真
实身份，防止钓鱼网站仿冒。

B：提升企业形象

谷歌在 2014 年宣布，他们将考虑将 https 作为一个轻量级的因素，以鼓励网络安全。即使在 Google 的建
议之外，那些切换到 SSL 的站点也经常发现客户认为他们的站点更真实。该网站还受到更多保护，免受
第三方可能造成的损害。最近，谷歌警告 Chrome 用户，网络浏览器将开始重新标记仍在 http 上的网
站：“从 2017 年 10 月开始，Chrome 将在另外两种情况下显示‘不安全’警告。”

C：提升 SEO 搜索权重

重要的是要注意，从切换到 HTTPS，谷歌，百度搜索引擎已经提示了其权重。百度已明确表示 https 配
置作为排名因素，而且是出于网站安全的角度，那么我们也应该引起足够的重视，这可能并不需要花费
太多的精力去解决这个事情但是能为 SEO 优化带来很好的效果！

###### 26 、HTTPS 的 TLS 握手过程？

我们知道，https 就是 http+ssl/tls，而 http 又是建立在 tcp/ip 之上的，所以浏览器和服务器使用 https 协
议传输时，先用 tcp/ip 协议三次握手建立连接，再用 ssl/tls 协议握手确定算法密钥等，然后才是加密传
输应用数据，最后 tcp/ip 四次挥手断开连接。

TLS 协议分为 TLS 记录协议以及 TLS 握手协议。TLS 记录协议负责对消息的压缩、加密以及数据认证。TSL
握手协议则是生成共享密钥以及交换证书，其中共享密钥是为了支持 TLS 记录协议的加密传输，而交换
证书是通信双方进行认证。

TLS 握手协议的握手过程如下图所示：


具体步骤：

```
1. ClientHello ：客户端向服务器发送"ClientHello"消息，这些消息主要包含：可用版本号、当前时
间、客户端随机数、会话 ID、可用密码套件清单 (对称和非对称加密的组合清单)、可用的压缩方式
清单。客户端提供可用版本号、密码套件清单、压缩方式清单让服务器选择。是因为不同型号版本
浏览器不同，所能支持的算法也不同，需要和服务器进行协商。当前时间在 TLS 中基本没用到，随
机数可以被后续步骤用到。
```

```
2. ServerHello ：服务器端会响应客户端，发送"ServerHello"消息，具体内容有：使用的版本号、当
前时间、服务器随机数、会话 ID、使用的密码套件、使用的压缩方式。即，服务器发送本次传输
使用的版本号、密码套件、压缩方式给客户端。生成的随机数后续会用到，该随机数生成与浏览器
的随机数无关。
3. Cretificate ：服务器发送证书给客户端，首先发送服务器证书，接收按顺序发送服务器证书签名
的认证机构证书。匿名通信则会省略此步骤。
4. ServerKeyExchange ：服务器发送密钥参数给客户端，比如 RSA 公钥的参数 N 和 E 以及散列值等
5. CeritificateRequest ：服务器发送服务器能理解的证书类型清单和认证机构清单给客户端。服务
器请求对客户端进行认证，当不使用客户端认证，服务器不会发送此消息。
6. ServerHelloDone ：服务器发送问候结束消息给客户端，代表服务器从 ServerHello 之后的一系列
消息的结束。
7. Cretificate ：客户端向服务器发送证书，此步骤需要服务器发送了证书认证请求 (第五步骤
CeritificateRequest)，否则客户端不会发送证书给服务器。
8. ClientKeyExchange ：客户端发送非对称加密算法的预备主密码给服务器，服务器和客户端可以
根据预备主密码计算出相同的主密码，根据主密码生成对称加密的密钥、消息认真码的密钥、对
称密码 CBC 模式中的初始化向量 IV。
9. CretificateVerify ：客户端将主密码、握手协议消息的散列值以及自己的数字签名发送给服务
器，向服务器证明自己持有客户端证书的私钥。此步骤仅当服务器发送了证书认证请求 (第五步骤
CeritificateRequest) 才会进行，否则客户端不会向服务器发送自己的证明信息。
10. ChangeCipherSpec ：客户端会向服务器发送切换密码消息，声明之后，服务器和客户端会同时
切换密码。这个消息仅限于变更密码才会发出，实际上，这个消息不是握手协议消息，是密码变更
协议的消息。
11. Finished ：客户端发送握手协议结束消息给服务器，通过这个消息，可以确认客户端握手协议和
密码套件切换是否正确结束。
12. ChangeCipherSpec ：服务端发送切换密码消息给客服端。
13. Finished ：服务器发送握手协议结束消息给客户端，这一消息会通过确定好的密码套件来加密传
输。
14. 切换到应用数据协议 ：以上步骤完成后，客户端和服务器会使用应用数据协议和 TLS 记录协议进行
密码通信。
```
可以看到，握手协议完成了以下操作：

```
1. 客户端获得了服务器的公钥，完成了服务器认证。
2. 服务器获得了客户端的公钥，完成了客户端认证 (当需要认证客户端时)。
3. 客户端和服务器生成了密码通信中使用的共享密钥。
4. 客户端和服务器生成了消息认证码中使用的共享密钥。
```
以上握手协议是 TLS 握手协议的一部分，TLS 握手协议还包括：密码变更协议、警告协议、应用数据协
议。

密码变更协议：客户端和服务器修改密码前分别发出 ChangeCipherSpec 消息表明要切换密码，并发
送 Finished 消息确认切换密码结束。

警告协议：发生错误时通知通信对象，握手协议过程中异常、消息认证码错误等，都会使用该协议。

应用数据协议：用于通信对象之间传输应用数据，当 TLS 加密 http 时，请求和响应就会通过 TLS 的应用数
据协议和 TLS 记录协议来进行传送。

###### 27 、GC 了解吗？


**一、定义**

GC (Garbage Collection) 是 Java 虚拟机 (JVM) 垃圾回收器提供的一种用于在空闲时间不定时回收无任何对
象引用的对象占据的内存空间的一种机制。

**二、作用**

垃圾回收机制的引入可以有效的防止内存泄露、保证内存的有效使用，也减轻了 Java 程序员的对内存
管理的工作量。

**三、回收什么？**

在 JVM 内存模型中，有三个是不需要进行垃圾回收的：程序计数器、JVM 栈、本地方法栈。因为它们的
生命周期是和线程同步的，随着线程的销毁，它们占用的内存会自动释放，所以只有 **方法区和堆** 需要进
行 GC

垃圾收集器在对垃圾进行回收前，确定有哪些对象是“死亡”状态，在对他们进行回收

**四、判断方法**

**引用计数算法** （Reference Counting）：堆中每个对象实例都有一个引用计数。当一个对象被创建时，
就将该对象实例分配给一个变量，该变量计数设置为 1 。当任何其它变量被赋值为这个对象的引用时，
计数加 1 （a = b, 则 b 引用的对象实例的计数器+1），但当一个对象实例的某个引用超过了生命周期或者
被设置为一个新值时，对象实例的引用计数器减 1 。任何引用计数器为 0 的对象实例可以被当作垃圾收
集。当一个对象实例被垃圾收集时，它引用的任何对象实例的引用计数器减 1 。

**可达性算法** （根搜索算法 GC Roots Tracing）：从一个节点 GC ROOT 开始，寻找对应的引用节点，找到
这个节点以后，继续寻找这个节点的引用节点，当所有的引用节点寻找完毕之后，剩余的节点则被认为
是没有被引用到的节点，即无用的节点，无用的节点将会被判定为是可回收的对象。

GC ROOT 对象：a) 虚拟机栈中引用的对象（栈帧中的本地变量表）；b) 方法区中类静态属性引用的对
象；c) 方法区中常量引用的对象；d) 本地方法栈中 JNI（Native 方法）引用的对象。


**对象死亡（被回收）前的最后一次挣扎** ：通过可达性分析，那些不可达的对象并不是立即被销毁，他们
还有被拯救的机会。如果要回收一个不可达的对象，要经历两次标记过程。首先是第一次标记，并判断
对象是否覆写了 finalize 方法，如果没有覆写，则直接进行第二次标记并被回收。如果对象在 finalize ()
方法中重新与引用链建立了关联关系，那么将会 **逃离本次回收** ，继续存活。

**五、什么时候进行回收？**

```
1. 会在 cpu 空闲的时候自动进行回收
2. 在堆内存存储满了之后
3. 主动调用 System.gc () 后尝试进行回收
```
**六、怎么回收？**

垃圾收集算法、垃圾收集器

在介绍收集算法之前先给出一个术语：Stop-the-world (STW). 意味着 **JVM 由于要执行 GC 而停止了应用
程序的执行，并且这种情形会在任何一种 GC 算法中发生。** 当 Stop-the-world 发生时，除了 GC 所需的线
程以外，所有线程都处于等待状态直到 GC 任务完成。

**七、垃圾收集算法**

```
1. 标记-清除（Mark-Sweep） ：从根集合（GC Roots）进行扫描，对存活的对象进行标记，标记完
毕后，再扫描整个空间中未被标记的对象，进行回收，此算法一般没有虚拟机采用。（效率低，产
生不连续内存碎片）
2. 复制（Copying） ：将内存分成两块容量大小相等的区域，每次只使用其中一块，当这一块内存用
完了，就将所有存活对象复制到另一块内存空间，然后清除前一块内存空间。(复制代价高，适合
新生代，浪费空间)
3. 标记-整理（Mark-Compact） ：在完成标记之后，它不是直接清理可回收对象，而是将存活对象
都向一端移动，然后清理掉端边界以外的内存。不会产生内存碎片，但是依旧移动对象的成本。
（适合老年代）
4. 分代收集算法 ：分代收集算法是目前大部分 JVM 的垃圾收集器采用的算法。它的核心思想是根据对
象存活的生命周期将内存划分为若干个不同的区域。一般情况下将堆区划分为老年代 （Tenured
Generation）和新生代 （Young Generation），在堆区之外还有一个代就是永久代 （Permanet
Generation）。
```
在文章开头，已经说了垃圾回收机制主要负责回收方法区和堆的垃圾。方法区也叫做永久代。Java 堆就
包括新生代和老年代两部分

```
注意：在 JDK 1.8 中已经移除了永久代，改为元空间
```

**工作流程如下：**

```
1. 所有新生成的对象都放在 Eden，当 Eden 区快要满了，触发 Minor GC，把存活对象复制到
Survivor 0 区，清空 Eden 区；
2. Eden 区被清空后，继续对外提供堆内存；当 Eden 区再次被填满，又触发 Minor GC，对 Eden 区
和 S 0 区同时进行垃圾回收，把存活对象放入 S 1 区，同时清空 Eden 区和 S 0 区；
3. 不断重复上面的步骤，每进行一次垃圾回收存活的对象年龄就会加 1 ，默认临界值为 15 ；
4. 当到达临界年龄，对象就会被复制到老年代；
5. 当老年代的被占满，无法再进入对象时，就会进行一次 Full GC，也就是新生代、老年代都进行回
收，这个垃圾回收的时间比较长。
```
**八、垃圾收集器**

新生代收集器：Serial，ParNew，Parallel Scavenge

老年代收集器：CMS，Serial Old，Parallel Old

**Serial 收集器** ：新生代 **单线程** 收集器，标记和清理都是单线程，优点是简单高效。是 client 级别默认的
GC 方式，可以通过-XX:+UseSerialGC 来强制指定。

**Serial Old 收集器** ：老年代 **单线程** 收集器，Serial 收集器的老年代版本。

**ParNew 收集器** ：新生代收集器，可以认为是 Serial 收集器的 **多线程** 版本, 在多核 CPU 环境下有着比 Serial
更好的表现。

**Parallel Scavenge 收集器** ： **并行** 收集器，追求高吞吐量，高效利用 CPU。吞吐量一般为 99%，吞吐量
= 用户线程时间/(用户线程时间+GC 线程时间)。适合后台应用等对交互相应要求不高的场景。是 server
级别默认采用的 GC 方式，可用-XX:+UseParallelGC 来强制指定，用-XX:ParallelGCThreads=4 来指
定线程数。

**Parallel Old 收集器** ：Parallel Scavenge 收集器的老年代版本， **并行** 收集器，吞吐量优先。

**CMS (Concurrent Mark Sweep) 收集器** ：高 **并发** 、低停顿，追求最短 GC 回收停顿时间，cpu 占用比较
高，响应时间快，停顿时间短，多核 cpu 追求高响应时间的选择。

###### 28 、说说 Java 有哪些锁？


**一、悲观锁和乐观锁**

悲观锁：当前线程去操作数据的时候，总是认为别的线程会去修改数据，所以每次操作数据的时候都会
上锁，别的线程去操作数据的时候就会阻塞，比如 synchronized；

乐观锁：当前线程每次去操作数据的时候都认为别人不会修改，更新的时候会判断别人是否会去更新数
据，通过版本来判断，如果数据被修改了就拒绝更新，例如 cas 是乐观锁，但是严格来说并不是锁，通
过原子性来保证数据的同步，例如数据库的乐观锁，通过版本控制来实现，cas 不会保证线程同步，乐
观的认为在数据更新期间没有其他线程影响

总结：悲观锁适合写操作多的场景，乐观锁适合读操作多的场景，乐观锁的吞吐量会比悲观锁高

**二、公平锁和非公平锁**

公平锁：有多个线程按照申请锁的顺序来获取锁，就是说，如果一个线程组里面，能够保证每个线程都
能拿到锁，例如：ReentrantLock（使用的同步队列 FIFO）

非公平锁：获取锁的方式是随机的，保证不了每个线程都能拿到锁，会存在有的线程饿死，一直拿不到
锁，例如：synchronized，ReentrantLock

总结：非公平锁性能高于公平锁，更能重复利用 CPU 的时间

**三、可重入锁和不可重入锁**

可重入锁：也叫递归锁，在外层使用锁之后，在内层仍然可以使用，并且不会产生死锁

不可重入锁：在当前线程执行某个方法已经获取了该锁，那么在方法中尝试再次获取锁时，就会获取不
到被阻塞

总结：可重入锁能一定程度的避免死锁，例如：synchronized，ReentrantLock

**四、自旋锁**

自旋锁：一个线程在获取锁的时候，如果锁已经被其它线程获取，那么该线程将循环等待，然后不断的
判断锁是否能够被成功获取，直到获取到锁才会退出循环，任何时刻最多只能有一个执行单元获得锁

总结：不会发生线程状态的切换，一直处于用户态，减少了线程上下文切换的消耗，缺点是循环会消耗
CPU

**五、共享锁和独享锁**

共享锁：也叫读锁，可以查看数据，但是不能修改和删除的一种数据锁，加锁后其他的用户可以并发读
取，但不能修改、增加、删除数据，该锁可被多个线程持有，用于资源数据共享

独享锁：也叫排它锁、写锁、独占锁、独享锁，该锁每一次只能被一个线程所持有，加锁后任何线程试
图再次加锁都会被阻塞，直到当前线程解锁。例如：线程 A 对 data 加上排它锁后，则其他线程不能再对
data 加任何类型的锁，获得互斥锁的线程既能读数据又能修改数据

###### 29 、Lock 和 synchronized 有啥区别？

**一、作用**

lock 和 synchronized 都是 Java 中去用来解决线程安全问题的一个工具，是 Java 中两种用来实现
线程同步的方式。

**二、来源**


sychronized 是 Java 中的一个关键字，它可以修饰方法和代码块。当一个线程访问一个对象的同步
方法或同步代码块时，其他线程不能访问这个对象的其他同步方法或同步代码块。

lock 是 java. util. concurrent. locks 包里的一个接口，这个接口有很多实现类，其中就包括我们
最常用的 ReentrantLock (可重入锁)。它提供了更多的灵活性，比如可以尝试获取锁而不会阻塞线
程、可以重试获取锁的次数以及可以提供公平锁和非公平锁。

**三、锁的力度**

```
sychronized 可以通过两种方式去控制锁的力度：
```
```
1. 把 sychronized 关键字修饰在方法层面。
2. 修饰在代码块上。
```
**锁对象的不同：**

锁对象为静态对象或者是 class 对象，那这个锁属于全局锁。
锁对象为普通实例对象，那这个锁的范围取决于这个实例的生命周期。
lock 锁的力度是通过 lock () 与 unlock () 两个方法决定的。在两个方法之间的代码能保证其线程安
全。lock 的作用域取决于 lock 实例的生命周期。

**四、灵活性**

```
lock 锁比 sychronized 的灵活性更高。
```
lock 可以自主的去决定什么时候加锁与释放锁。只需要调用 lock 的 lock () 和 unlock () 这两个方法
就可以。

sychronized 由于是一个关键字，所以他无法实现非阻塞竞争锁的方法，一个线程获取锁之后，其他
锁只能等待那个线程释放之后才能有获取锁的机会。

**五、公平锁与非公平锁**

**（ 1 ）公平锁** ：

**多个线程按照申请锁的顺序去获得锁，线程会直接进入队列去排队，永远都是队列的第一位才能得到
锁。**

```
优点：所有的线程都能得到资源，不会饿死。
缺点：吞吐量低，队列里面除了第一个线程，其他的线程都会阻塞，cpu 唤醒阻塞线程的开销大。
```
**（ 2 ）非公平锁** ：

**多个线程去获取锁的时候，会直接去尝试获取，获取不到，再去进入等待队列，如果能获取到，就直接
获取到锁。**

```
优点：可以减少 CPU 唤醒线程的开销，整体的吞吐效率会高点，CPU 也不必取唤醒所有线程，会减
少唤起线程的数量。
缺点：可能导致队列中间的线程一直获取不到锁或者长时间获取不到锁，最终饿死。 lock 提供了
公平锁和非公平锁两种机制（默认非公平锁）。
```
**PS** ：sychronized 是非公平锁。

**六、异常是否释放锁**

synchronized 锁的释放是被动的，当 sychronized 同步代码块执行结束或者出现异常的时候才会被
释放。

lock 锁发生异常的时候，不会主动释放占有的锁，必须手动 unlock () 来释放，所以我们一般都是将
同步代码块放进 try-catch 里面，finally 中写入 unlock () 方法，避免死锁发生。


**七、判断是否能获取锁**

```
synchronized 不能。
```
lock 提供了非阻塞竞争锁的方法 trylock ()，返回值是 Boolean 类型。它表示的是用来尝试获取锁：
成功获取则返回 true；获取失败则返回 false，这个方法无论如何都会立即返回。

**八、调度方式**

```
synchronized 使用的是 object 对象本身的 wait、notify、notifyAll 方法，而 lock 使用的是
Condition 进行线程之间的调度。
```
**九、是否能中断**

```
synchronized 只能等待锁的释放，不能响应中断。
```
```
lock 等待锁过程中可以用 interrupt () 来中断。
```
**十、性能**

如果竞争不激烈，性能差不多；竞争激烈时，lock 的性能会更好。

```
lock 锁还能使用 readwritelock 实现读写分离，提高多线程的读操作效率。
```
**十一、sychronized 锁升级**

synchronized 代码块是由一对 monitorenter/monitorexit 指令实现的。Monitor 的实现完全是
依靠操作系统内部的互斥锁，因为需要进行用户态到内核态的切换，所以同步操作是一个无差别的重量
级操作。

所以现在 JVM 提供了三种不同的锁： **偏向锁** 、 **轻量级锁** 、 **重量级锁** 。

**（ 1 ）偏向锁** ：

当没有竞争出现时，默认使用偏向锁。线程会利用 CAS 操作在对象头上设置线程 ID ，以表示对象偏向
当前线程。

**目的** ：在很多应用场景中，大部分对象生命周期最多会被一个线程锁定，使用偏向锁可以降低无竞争时
的开销。

**（ 2 ）轻量级锁** ：

JVM 比较当前线程的 threadID 和 Java 对象头中的 threadID 是否一致，如果不一致（比如线程 2 要
竞争锁对象），那么需要查看 Java 对象头中记录的线程 1 是否存活（偏向锁不会主动释放因此还是存
储的线程 1 的 threadID）：

```
1. 如果没有存活，那么锁对象还是为偏向锁（对象头中的 threadID 为线程 2 的）；
2. 如果存活，那么撤销偏向锁，升级为轻量级锁。
```
当有其他线程想访问加了轻量级锁的资源时，会使用自旋锁优化，来进行资源访问。

**目的** ：竞争锁对象的线程不多，而且线程持有锁的时间也不长的情景。因为阻塞线程需要 CPU 从用户态
转到内核态，开销大，如果刚刚阻塞不久这个锁就被释放了，就得不偿失了，因此这个时候就干脆不阻
塞这个线程，让它自旋这等待锁释放。

**（ 3 ）重量级锁** ：

如果自旋失败，很大概率再进行一次自旋，如果也是失败，因此直接升级成重量级锁，进行线程阻
塞，减少 cpu 消耗。

当锁升级为重量级锁后，未抢到锁的线程都会被阻塞，进入阻塞队列。


###### 30 、synchronized 一定会阻塞吗？

synchronized 关键字并不一定会阻塞线程。synchronized 关键字用于实现 Java 中的同步机制，它可
以应用于方法或代码块。当一个线程获得了某个对象的锁时（通过 synchronized 关键字），其他线程
如果想要获取该对象的锁，就会被阻塞，直到持有锁的线程释放锁。

但是，如果一个线程尝试获取一个对象的锁时，如果锁没有被其他线程持有，那么该线程会立即获得
锁，而不会被阻塞。因此，synchronized 关键字只会在获取锁时可能导致线程阻塞，而不是一定会阻
塞线程。

另外需要注意的是，synchronized 关键字还可以用于静态方法和类级别的锁定，这时锁定的是整个类
而不是对象。在这种情况下，如果一个线程获取了类级别的锁，其他线程也会被阻塞，直到持有锁的线
程释放锁。

总结起来，synchronized 关键字的阻塞行为取决于锁的可用性，如果锁可用，线程会立即获取锁而不
被阻塞；如果锁不可用，线程会被阻塞直到锁可用。

###### 31 、说说偏向锁、轻量锁级、重量级锁是什么锁？

在 Java 中，锁是用于实现线程同步的机制。为了提高多线程程序的性能，Java 引入了偏向锁、轻量级锁
和重量级锁等不同级别的锁。

```
1. 偏向锁（Biased Locking）：
偏向锁是为了在无竞争的情况下减少锁的开销而引入的机制。当一个线程访问一个同步块并获取锁
时，锁会被标记为偏向锁，并且记录下持有锁的线程 ID。当该线程再次进入同步块时，无需进行
任何同步操作，直接获取锁。只有当其他线程尝试获取该锁时，偏向锁才会升级为轻量级锁。
2. 轻量级锁（Lightweight Locking）：
轻量级锁是为了在竞争不激烈的情况下减少锁的开销而引入的机制。当一个线程尝试获取一个已经
被偏向锁持有的锁时，会尝试将锁升级为轻量级锁。升级的过程中，会使用 CAS（Compare and
Swap）操作来尝试获取锁。如果获取成功，线程就可以进入临界区，执行同步操作。如果获取失
败，表示有其他线程竞争锁，锁会膨胀为重量级锁。
3. 重量级锁（Heavyweight Locking）：
重量级锁是最传统的锁实现方式，它使用操作系统的互斥量来实现线程的同步。当一个线程尝试获
取一个已经被轻量级锁持有的锁时，如果获取失败，锁就会膨胀为重量级锁。膨胀为重量级锁的过
程中，其他线程会被阻塞，进入等待状态，直到持有锁的线程释放锁。
```
总的来说，偏向锁和轻量级锁都是为了在竞争不激烈的情况下减少锁的开销，提高程序性能。只有在竞
争激烈的情况下，锁才会膨胀为重量级锁，使用操作系统的互斥量来实现线程同步。

**一、内存布局对应对应的锁状态**


**锁状态的变化结论**

**二、偏向锁**

```
偏向锁是一种针对加锁操作的优化手段。
在大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，因此为了消除数据在
无竞争情况下锁重入（CAS 操作）的开销而引入偏向锁。
对于没有锁竞争的场合，偏向锁有很好的优化效果。
JVM 启用了偏向锁模式：jdk 6 之后默认开启
新创建对象的 Mark Word 中的 Thread Id 为 0 ，说明此时处于可偏向但未偏向任何线程，也叫做匿
名偏向状态 (anonymously biased)。
```
**偏向锁延迟偏向**

```
HotSpot 虚拟机在启动后开启偏向锁模式默认在 4 s 后。
为了减少初始化时间，JVM 默认延时加载偏向锁。
```
```
//关闭延迟开启偏向锁
```
- XX:BiasedLockingStartupDelay= 0
//禁止偏向锁
- XX:-UseBiasedLocking


```
上图的代码可以验证：从无锁变为偏向锁（ 4 秒）
```
**偏向锁在无竞争的时候一直是偏向锁**

```
执行结果
```
```
public static void main (String[] args) throws InterruptedException {
log.debug (Thread.currentThread (). getName () + "最开始的状态。。。\n"
+ ClassLayout.parseInstance (new Object ()). toPrintable ());
// HotSpot 虚拟机在启动后有个 4 s 的延迟才会对每个新建的对象开启偏向锁模式
Thread.sleep ( 4000 );
Object obj = new Object ();
```
```
new Thread (new Runnable () {
@Override
public void run () {
log.debug (
Thread.currentThread (). getName () + "开始执行准备获取锁。。。\n" +
ClassLayout.parseInstance (obj). toPrintable ());
synchronized (obj) {
log.debug (Thread.currentThread (). getName () + "获取锁执行中。。。\n"
+ ClassLayout.parseInstance (obj). toPrintable ());
}
log.debug (Thread.currentThread (). getName () + "释放锁。。。\n" +
ClassLayout.parseInstance (obj). toPrintable ());
}
}, "thread 1"). start ();
```
```
Thread.sleep ( 5000 );
log.debug (Thread.currentThread (). getName () + "结束状态。。。\n" +
ClassLayout.parseInstance (obj). toPrintable ());
}
```

```
从结果可以看出：无锁状态经过 4 秒变为偏向锁，之后的的状态一直是偏向锁！
在进入同步代码块后，锁的偏向线程由 0 变为具体的线程。
```
**在同步代码块外调用 hashCode () 方法**


```
进入同步代码块后锁升级为轻量级锁
当对象可偏向（线程 ID 为 0 ）时，MarkWord 将变成未锁定状态，并只能升级成轻量锁。
```
**在同步代码块内调用 hashCode () 方法**

```
直接升级为重量级锁
当对象正处于偏向锁时，调用 HashCode 将使偏向锁强制升级成重量锁。
```
**偏向锁撤销：自己验证 wait 和 notify**

```
调用锁对象的 obj.hashCode () 或 System.identityHashCode (obj) 方法会导致该对象的偏向锁被撤
销。
因为对于一个对象，其 HashCode 只会生成一次并保存，偏向锁是没有地方保存 hashcode 的。
轻量级锁会在锁记录中记录 hashCode。
重量级锁会在 Monitor 中记录 hashCode。
当对象可偏向（线程 ID 为 0 ）时，MarkWord 将变成未锁定状态，并只能升级成轻量锁。
当对象正处于偏向锁时，调用 HashCode 将使偏向锁强制升级成重量锁。
偏向锁状态执行 obj.notify () 会升级为轻量级锁。
调用 obj.wait (timeout) 会升级为重量级锁。
```
**三、轻量级锁**

```
倘若偏向锁失败，虚拟机并不会立即升级为重量级锁，它还会尝试使用一种称为轻量级锁的优化手
段，此时 Mark Word 的结构也变为轻量级锁的结构。
轻量级锁所适应的场景是线程交替执行同步块的场合，如果存在同一时间多个线程访问同一把锁的
场合，就会导致轻量级锁膨胀为重量级锁。
轻量级锁在降级的时候直接变为无锁状态！（查看之前在同步代码块外调用 hashCode () 方法）
```
**模拟竞争不激烈的场景**

```
@Slf 4 j
public class TestMemory {
```

**竞争不激烈的场景的运行结果**

```
public static void main (String[] args) throws InterruptedException {
log.debug (Thread.currentThread (). getName () + "最开始的状态。。。\n"
+ ClassLayout.parseInstance (new Object ()). toPrintable ());
// HotSpot 虚拟机在启动后有个 4 s 的延迟才会对每个新建的对象开启偏向锁模式
Thread.sleep ( 4000 );
Object obj = new Object ();
```
```
Thread thread 1 = new Thread (new Runnable () {
@Override
public void run () {
log.debug (Thread.currentThread (). getName () + "开始执行
thread 1。。。\n"
+ ClassLayout.parseInstance (obj). toPrintable ());
synchronized (obj) {
log.debug (Thread.currentThread (). getName () + "获取锁执行中
thread 1。。。\n"
+ ClassLayout.parseInstance (obj). toPrintable ());
}
log.debug (Thread.currentThread (). getName () + "释放锁 thread 1。。。
\n"
+ ClassLayout.parseInstance (obj). toPrintable ());
}
}, "thread 1");
thread 1.start ();
```
```
// 控制线程竞争时机
Thread.sleep ( 1 );
```
```
Thread thread 2 = new Thread (new Runnable () {
@Override
public void run () {
log.debug (Thread.currentThread (). getName () + "开始执行
thread 2。。。\n"
+ ClassLayout.parseInstance (obj). toPrintable ());
synchronized (obj) {
log.debug (Thread.currentThread (). getName () + "获取锁执行中
thread 2。。。\n"
+ ClassLayout.parseInstance (obj). toPrintable ());
}
log.debug (Thread.currentThread (). getName () + "释放锁 thread 2。。。
\n"
+ ClassLayout.parseInstance (obj). toPrintable ());
}
}, "thread 2");
thread 2.start ();
```
```
Thread.sleep ( 5000 );
log.debug (Thread.currentThread (). getName () + "结束状态。。。\n" +
ClassLayout.parseInstance (obj). toPrintable ());
}
}
```

**四、重量级锁**

```
轻量级锁经过一次自选如果没有获取到锁，直接膨胀为重量级锁。
重量级锁是基于 Monitor 机制，并且在 Monitor 中记录 hashCode
```
**模拟竞争激烈的场景**

```
去掉不激烈的场景中的以下代码就是竞争激烈的场景
```
**竞争激烈的场景的运行结果**

###### 32 、线程池有哪些参数？

```
// 控制线程竞争时机
Thread.sleep ( 1 );
```

线程池的 7 大参数包括：corePoolSize、maximumPoolSize、keepAliveTime、TimeUnit、
workQueue、threadFactory 和 handler。

```
corePoolSize ：线程池核心线程大小，即线程池中会维护一个最小的线程数量，即使这些线程处
理空闲状态，他们也不会被销毁，除非设置了 allowCoreThreadTimeOut。这里的最小线程数量即
是 corePoolSize。任务提交到线程池后，首先会检查当前线程数是否达到了 corePoolSize, 如果没
有达到的话，则会创建一个新线程来处理这个任务。
maximumPoolSize ：线程池最大线程数量。当任务队列满了之后，新来的任务就会在这里等待
执行。如果超过了 maximunPoolSize 个任务在队列中等待，那么就会抛出
RejectedExecutionException 异常。
keepAliveTime ：线程空闲时间，也就是当一个线程处于空闲状态时，它会在这段时间内不会被
回收。默认情况下是 60 秒。
TimeUnit ：keepAliveTime 的时间单位，可以是毫秒 (ms)、秒 (s) 等等。
workQueue ：工作队列类型。Java 提供了几种不同的队列类型供选择，包括
ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue 等等。
threadFactory ：自定义线程工厂类。如果不指定这个参数，则使用默认的 ThreadFactory 实现。
handler ：拒绝策略。当任务无法被分配给正在运行的线程时，就会抛出
RejectedExecutionException 异常。Java 提供了几种不同的拒绝策略可供选择，包括
AbortPolicy、CallerRunsPolicy、DiscardOldestPolicy 等等。
```
在使用 ThreadPoolExecutor 创建线程池时所设置的 7 个参数，如以下源码所示：

**参数 1 ：corePoolSize**

**核心线程数：是指线程池中长期存活的线程数。**

```
这就好比古代大户人家，会长期雇佣一些“长工”来给他们干活，这些人一般比较稳定，无论这一
年的活多活少，这些人都不会被辞退，都是长期生活在大户人家的。
```
**参数 2 ：maximumPoolSize**

**最大线程数：线程池允许创建的最大线程数量，当线程池的任务队列满了之后，可以创建的最大线程
数。**

```
这是古代大户人家最多可以雇佣的人数，比如某个节日或大户人家有人过寿时，因为活太多，仅
靠“长工”是完不成任务，这时就会再招聘一些“短工”一起来干活，这个最大线程数就是“长工”+“短
工”的总人数，也就是招聘的人数不能超过 maximumPoolSize。
```
**注意事项**

最大线程数 maximumPoolSize 的值不能小于核心线程数 corePoolSize，否则在程序运行时会报
IllegalArgumentException 非法参数异常，如下图所示：

```
public ThreadPoolExecutor (int corePoolSize,
int maximumPoolSize,
long keepAliveTime,
TimeUnit unit,
BlockingQueue<Runnable> workQueue,
ThreadFactory threadFactory,
RejectedExecutionHandler handler) {
//...
}
```

**参数 3 ：keepAliveTime**

**空闲线程存活时间，当线程池中没有任务时，会销毁一些线程，销毁的线程数
=maximumPoolSize（最大线程数）-corePoolSize（核心线程数）。**

```
还是以大户人家为例，当大户人家比较忙的时候就会雇佣一些“短工”来干活，但等干完活之后，
不忙了，就会将这些“短工”辞退掉，而 keepAliveTime 就是用来描述没活之后，短工可以在大户
人家待的（最长）时间。
```
**参数 4 ：TimeUnit**

**时间单位：空闲线程存活时间的描述单位** ，此参数是配合参数 3 使用的。
参数 3 是一个 long 类型的值，比如参数 3 传递的是 1 ，那么这个 1 表示的是 1 天？还是 1 小时？还是
1 秒钟？是由参数 4 说了算的。
TimeUnit 有以下 7 个值：

```
1. TimeUnit. DAYS：天
2. TimeUnit. HOURS：小时
3. TimeUnit. MINUTES：分
4. TimeUnit. SECONDS：秒
5. TimeUnit. MILLISECONDS：毫秒
6. TimeUnit. MICROSECONDS：微妙
7. TimeUnit. NANOSECONDS：纳秒
```
**参数 5 ：BlockingQueue**

**阻塞队列：线程池存放任务的队列，用来存储线程池的所有待执行任务。**
它可以设置以下几个值：

```
8. ArrayBlockingQueue：一个由数组结构组成的有界阻塞队列。
9. LinkedBlockingQueue：一个由链表结构组成的有界阻塞队列。
10. SynchronousQueue：一个不存储元素的阻塞队列，即直接提交给线程不保持它们。
11. PriorityBlockingQueue：一个支持优先级排序的无界阻塞队列。
12. DelayQueue：一个使用优先级队列实现的无界阻塞队列，只有在延迟期满时才能从中提取元素。
13. LinkedTransferQueue：一个由链表结构组成的无界阻塞队列。与 SynchronousQueue 类似，还
含有非阻塞方法。
14. LinkedBlockingDeque：一个由链表结构组成的双向阻塞队列。
```
比较常用的是 LinkedBlockingQueue，线程池的排队策略和 BlockingQueue 息息相关。

**参数 6 ：ThreadFactory**


**线程工厂：线程池创建线程时调用的工厂方法，通过此方法可以设置线程的优先级、线程命名规则以及
线程类型（用户线程还是守护线程）等。**
线程工厂的使用示例如下：

以上程序的执行结果如下：

从上述执行结果可以看出，自定义线程工厂起作用了，线程的名称和线程的优先级都是通过线程工厂设
置的。

**参数 7 ：RejectedExecutionHandler**

**拒绝策略：当线程池的任务超出线程池队列可以存储的最大值之后，执行的策略。**
默认的拒绝策略有以下 4 种：

```
AbortPolicy：拒绝并抛出异常。
CallerRunsPolicy：使用当前调用的线程来执行此任务。
```
```
public static void main (String[] args) {
// 创建线程工厂
ThreadFactory threadFactory = new ThreadFactory () {
@Override
public Thread newThread (Runnable r) {
// 创建线程池中的线程
Thread thread = new Thread (r);
// 设置线程名称
thread.setName ("Thread-" + r.hashCode ());
// 设置线程优先级（最大值： 10 ）
thread.setPriority (Thread. MAX_PRIORITY);
//......
return thread;
}
};
// 创建线程池
ThreadPoolExecutor threadPoolExecutor = new ThreadPoolExecutor ( 10 , 10 , 0 ,
```
```
TimeUnit. SECONDS, new LinkedBlockingQueue<>(),
```
```
threadFactory); // 使用自定义的线程工厂
threadPoolExecutor.submit (new Runnable () {
@Override
public void run () {
Thread thread = Thread.currentThread ();
System.out.println (String.format ("线程：%s，线程优先级：%d",
thread.getName (),
thread.getPriority ()));
}
});
}
```

```
DiscardOldestPolicy：抛弃队列头部（最旧）的一个任务，并执行当前任务。
DiscardPolicy：忽略并抛弃当前任务。
```
线程池的默认策略是 AbortPolicy 拒绝并抛出异常。

###### 33 、说说 RocketMQ 的消息生产消费过程？

RocketMQ 消息生产消费过程如下：

```
1. 生产者向 RocketMQ 发送消息，消息会被封装到一个 Message 对象中，并放入到 topic 的
queue 中。
2. Producer 通过 producerGroup 向 Broker 发送消息，Broker 会将消息发送到所属的 topic 的
queue 中。
3. 消费者从 Broker 中拉取消息，消息会被封装到一个 Message 对象中，并从 topic 的 queue 中
取出。
4. 消费者通过 consumerGroup 从 Broker 中拉取消息，并在消费者自己的 messageListener 中处
理消息。
```
下面是用 Java 实现的 RocketMQ 消息生产消费过程的示例代码：

```
public class RocketMQProducer {
```
```
public static void main (String[] args) throws Exception {
// 创建生产者
Producer producer = new DefaultMQProducer ("my-project-namespace");
```
```
// 创建消息
Message message = new Message ("TopicTest", "TagA", "Hello
World".getBytes ());
```
```
// 发送消息到消息队列
producer.send (message);
```
```
// 关闭生产者
producer.close ();
}
}
```
```
public class RocketMQConsumer {
```
```
public static void main (String[] args) throws Exception {
// 创建消费者
Consumer consumer = new DefaultMQPushConsumer ("my-project-namespace");
```
```
// 设置消费者组名称
consumer.setConsumerGroup ("ConsumerGroup");
```
```
// 创建消息监听器
MessageListenerOrderly messageListener = new MessageListenerOrderly ();
consumer.subscribe ("TopicTest", "*");
consumer.setMessageListener (messageListener);
```
```
// 启动消费者
consumer.start ();
```

在以上示例代码中，我们使用 DefaultMQProducer 和 DefaultMQPushConsumer 来创建生产者和消
费者。我们使用 send () 方法将消息发送到消息队列中，使用 subscribe () 方法订阅消息主题，使用
setMessageListener () 方法设置消费者监听器，在监听器中实现 consumeMessage () 方法来处理消
息。在 consumeMessage () 方法中，我们可以对消息进行业务处理，并将处理结果返回给消费者。

在以上示例代码中，我们还使用了 MessageExt 类来封装消息，它包含了消息的主题、消息内容、消
息类型等信息。在使用 consumeMessage () 方法处理消息时，我们需要实现 MessageListener 接
口，并实现 consumeMessage () 方法来处理消息。

在实际应用中，我们还需要考虑消息的发送顺序、消息的重试等问题，可以使用 RocketMQ 提供的一
些高级特性来实现，例如：发送消息时设置 Priority，使用 TransactionManager 进行事务管理，
使用 BrokerSelector 选择合适的 Broker 等。

```
40 岁老架构师尼恩提示 ：RocketMQ 是既是面试的绝对重点，也是面试的绝对难点，建议大家有
一个深入和详细的掌握，具体的内容请参见《尼恩 RocketMQ 四部曲》，该专题对 RocketMQ 有一
个系统化、体系化、全面化的介绍。
如果要把 RocketMQ 实战写入简历，可以找尼恩指导
```
###### 34 、说说生产者的负载均衡？

生产者的负载均衡是指在多个 Broker 之间分配消息，以确保每个 Broker 处理的消息量大致相等。
RocketMQ 提供了多种负载均衡策略，包括以下几种：

```
1. 轮询 (RoundRobin) ：将消息依次发送到不同的 Broker 上，每个 Broker 处理的消息量大致相等。
2. 随机 (Random) ：将消息随机发送到不同的 Broker 上，每个 Broker 处理的消息量可能不相等。
3. 最少连接 (LeastConnections) ：将消息发送到当前连接数最少的 Broker 上，以确保每个 Broker 处
理的消息量大致相等。
4. 一致性哈希 (ConsistentHash) ：根据消息的 key 值计算哈希值，将消息发送到对应的 Broker 上，
以确保每个 Broker 处理的消息量大致相等。
```
在 RocketMQ 中，可以通过设置 ProducerConfig 对象的 loadBalancePolicy 属性来选择负载均衡策略。
例如，使用轮询策略可以这样设置：

```
// 关闭消费者
consumer.shutdown ();
}
```
```
static class MessageListenerOrderly implements MessageListener {
```
```
public ConsumeOrderlyStatus consumeMessage (List<MessageExt> msgs,
ConsumeOrderlyContext context) {
// 处理消息
System.out.println ("Received Message: " + new
String (msgs.get ( 0 ). getBody ()));
```
```
// 返回消费者消费状态
return ConsumeOrderlyStatus. SUCCESS;
}
}
}
```

###### 35 、说说消息的 reput 过程？

在 RocketMQ 中，消息的 reput 过程是指对消息的可靠性和一致性进行保障的过程。RocketMQ 是一个分
布式消息队列系统，用于实现高可靠性、高吞吐量的消息传递。

消息的 reput 过程在 RocketMQ 中包括以下几个步骤：

```
1. 消息发送 ：消息的发送者将消息发送到 RocketMQ 的生产者。
2. 消息持久化 ：生产者将消息持久化到本地磁盘，以保证消息的可靠性。消息会被写入消息日志文件
（Commit Log）和索引文件（Index File）。
3. 主从同步 ：消息在主节点持久化后，会通过主从同步机制将消息复制到从节点。这样可以保证即使
主节点宕机，消息仍然可以在从节点上访问。
4. 消息复制 ：消息在主从同步后，会在从节点上进行消息复制。从节点会将消息写入本地的消息日志
文件和索引文件。
5. 消息消费 ：消费者从 RocketMQ 的消费者端订阅消息，并从 Broker 拉取消息进行消费。消费者可以
设置消息的消费模式，包括集群模式和广播模式。
6. 消息确认 ：消费者消费消息后，会向 Broker 发送消息确认（ACK）。Broker 收到消息确认后会更
新消息的消费进度，并标记消息为已消费。
7. 消息重试 ：如果消费者在消费过程中出现异常或者超时，RocketMQ 会进行消息重试。消息重试机
制会根据配置的重试次数和重试间隔进行消息的重新消费。
8. 消息顺序 ：RocketMQ 还支持消息的顺序消费。在顺序消费模式下，消息会按照发送顺序进行消
费，保证消息的顺序性。
```
需要注意的是，RocketMQ 的消息 reput 过程是基于分布式架构的，通过主从同步和消息复制机制保证
消息的可靠性和一致性。同时，RocketMQ 还提供了丰富的配置选项和监控工具，以便对消息的 reput
过程进行监控和调优。

###### 36 、说说 RocketMQ 的 ConsumeQueue 消息的格式？

在 RocketMQ 中，ConsumeQueue 是用于存储消息消费进度的数据结构。它是基于文件的存储方式，
每个主题（Topic）都有一个对应的 ConsumeQueue 文件。

ConsumeQueue 文件由多个逻辑队列（Logical Queue）组成，每个逻辑队列对应一个消息队列
（Message Queue）。逻辑队列中存储了消息的索引信息，包括消息在 CommitLog 文件中的偏移量
（offset）和消息的大小。

ConsumeQueue 文件由两部分组成：索引文件（Index File）和位图文件（BitMap File）。

**1. 索引文件（Index File）：**

索引文件用于记录每个消息队列的消息索引信息。它包含了每个消息的偏移量和消息的存储时间戳。索
引文件按照消息的存储时间戳进行排序，方便快速查找特定时间范围内的消息。

**2. 位图文件（BitMap File）：**

位图文件用于记录消息队列中每个消息的消费状态。每个消息占用一个位， 0 表示未消费， 1 表示已消
费。通过位图文件，可以快速判断消息是否已经被消费。

```
DefaultMQProducer producer = new DefaultMQProducer ("producer_group");
producer.setNamesrvAddr ("localhost: 9876");
producer.setLoadBalancePolicy ("roundrobin"); // 设置负载均衡策略为轮询
producer.start ();
```

ConsumeQueue 中的消息格式如下：

```
Offset：消息在 CommitLog 文件中的偏移量。
CommitLogOffset：消息在 CommitLog 文件中的物理偏移量。
Size：消息的大小。
TagsCode：消息的标签编码。
StoreTimestamp：消息的存储时间戳。
ConsumeTimestamp：消息的消费时间戳。
```
通过解析 ConsumeQueue 文件，RocketMQ 可以快速定位消息的位置，提高消息的消费效率。

###### 37 、3 PC、2 PC、CAP 是啥？

```
1. 3 PC 原理 ：3 PC（Three-Processor Code）是一种多处理器并行编程模型，在这个模型中，有三个
基本的程序执行单位：线程、进程和中断处理程序。线程是执行单个任务的最小单位，进程是一个
执行单元，它可以拥有自己的地址空间，中断处理程序是处理硬件中断请求的一种机制。通过使用
线程来实现并行计算，可以有效地利用多个处理器的能力。
2. 2 PC 原理 ：2 PC（Two-Processor Code）是一种基于时间片轮转的多处理器并行编程模型。在这
个模型中，有两个基本的程序执行单位：线程和进程。线程轮流使用 CPU，进程则按照一定的时
间片轮流执行。线程和进程的切换由操作系统控制，并且时间片的长度是一定的。通过使用时间片
轮转的方式，可以有效地利用多个处理器的能力。
3. CAP 原理 ：CAP 原理是指在分布式系统中，对于一个分区容忍性的系统，必须同时满足
C（Consistency）、A（Availability）和 P（Partition Tolerance）三个属性。这三个属性中，C
属性表示数据的一致性，即在整个系统中，所有节点看到的数据都是一致的；A 属性表示系统的可
用性，即在出现故障时，整个系统必须能够继续运行；P 属性表示分区容忍性，即在系统中出现节
点故障或者通信异常时，整个系统仍然能够继续运行。
4. 区别 ： 3 PC 和 2 PC 都是多处理器并行编程模型，但是在实现方式上有所不同。3 PC 是基于线程的并
行，而 2 PC 是基于时间片轮转的并行。在使用场景上，3 PC 适用于计算密集型任务，2 PC 适用于时
间敏感型任务。
```
CAP 原理主要是针对分布式系统中的一致性、可用性和分区容忍性进行的讨论。在分布式系统中，这三
个属性是相互制约的，必须根据实际情况进行权衡。

###### 38 、RocketMQ 是 AP 还是 CP？

RocketMQ 是一个开源的分布式消息中间件，它的设计目标是提供高吞吐量、低延迟、高可用性和可伸
缩性的消息传递解决方案。

```
+---------------------+---------------------+
| Offset | CommitLogOffset |
| (8 字节) | (8 字节) |
+---------------------+---------------------+
| Size | TagsCode |
| (4 字节) | (8 字节) |
+---------------------+---------------------+
| StoreTimestamp | ConsumeTimestamp |
| (8 字节) | (8 字节) |
+---------------------+---------------------+
```

在分布式系统中，一般会使用 CAP 原则来描述系统的特性。CAP 原则指的是一致性（Consistency）、可
用性（Availability）和分区容错性（Partition tolerance），它表明在分布式系统中，无法同时满足一
致性、可用性和分区容错性这三个特性，只能在其中选择两个。

根据 CAP 原则，RocketMQ 被归类为 AP（可用性和分区容错性）系统。这意味着在 RocketMQ 中，当网
络分区发生时，它会保证可用性和分区容错性，即消息仍然可以进行传递和消费，但在某些情况下可能
会出现数据不一致的情况。

RocketMQ 通过主从复制和消息冗余机制来保证高可用性和可靠性。它使用了主题（Topic）和队列
（Queue）的概念来组织消息，消息被写入到主题中，然后根据配置的队列数量进行分布式存储。当一
个消息被发送到 RocketMQ 集群时，它会被复制到多个 Broker 节点上的队列中，以确保消息的可靠性和
高可用性。

总结起来，RocketMQ 是一个 AP 系统，它在可用性和分区容错性方面提供了强大的支持，但在某些情况
下可能会出现数据不一致的情况。

###### 39 、RocketMQ 的 Broker 宕机会怎样？

当 RocketMQ 的 Broker 宕机时，会对消息传递的可用性和可靠性产生一定的影响。下面是宕机时的一些
可能情况和处理方式：

```
1. 主节点宕机 ：RocketMQ 的 Broker 节点通常以主从复制的方式运行，当主节点宕机时，集群中的其
他节点会自动选举一个新的主节点来接管工作。这个过程通常是自动完成的，不需要人工干预。在
选举完成之前，消息的写入和消费可能会受到一定的影响，但一旦选举完成，系统将恢复正常。
2. 所有节点宕机 ：如果 RocketMQ 的所有 Broker 节点都宕机，消息的写入和消费将无法进行。在这种
情况下，需要将 Broker 节点恢复或重新启动，以使系统恢复正常运行。
3. 部分节点宕机 ：如果 RocketMQ 集群中的部分 Broker 节点宕机，其他正常运行的节点仍然可以接收
消息并提供服务。但是，由于部分节点宕机，整个集群的可用性和吞吐量可能会受到影响。一旦宕
机的节点恢复正常，系统将重新平衡负载并恢复正常运行。
```
为了减少 Broker 宕机对消息传递的影响，可以采取以下措施：

```
1. 配置高可用性 ：通过使用主从复制模式，将消息复制到多个 Broker 节点上，以确保即使其中一个
节点宕机，仍然可以从其他节点获取消息。
2. 监控和自动恢复 ：使用监控系统来实时监测 Broker 节点的状态，一旦宕机，可以自动触发恢复机
制，例如自动选举新的主节点。
3. 数据备份和恢复 ：定期备份 Broker 节点上的数据，以便在宕机后能够快速恢复数据并重新启动节
点。
```
总的来说，RocketMQ 对 Broker 宕机情况有一定的容错和恢复机制，可以保证消息传递的可用性和可靠
性。然而，对于关键业务场景，建议采取适当的高可用性和容灾措施，以确保系统的稳定性和可靠性。

###### 40 、有看过选主过程的源码吗？简述一下

RocketMQ 是一个开源项目，您可以在 Apache RocketMQ 的官方 GitHub 仓库（https://github.com/ap
ache/RocketMQ）中找到完整的源代码。

以下是选主过程的源码简要描述：

```
1. 首先，当一个 Broker 节点启动时，它会执行 org. apache. RocketMQ. broker. BrokerController
类中的 initialize () 方法，该方法用于初始化 Broker 节点的各个组件。
```

```
2. 在 initialize () 方法中，会执行 org. apache. RocketMQ. broker. BrokerController 类中的
registerBrokerAll () 方法，该方法用于向 NameServer 注册 Broker 节点的相关信息。
3. 在 registerBrokerAll () 方法中，会执行
org. apache. RocketMQ. namesrv. processor. RegisterBrokerProcessor 类中的
processRequest () 方法，该方法用于处理 Broker 节点注册的请求。
4. 在 processRequest () 方法中，会执行
org. apache. RocketMQ. namesrv. routeinfo. RouteInfoManager 类中的 registerBroker () 方
法，该方法用于将 Broker 节点的信息存储在内存中，并定期将这些信息持久化到磁盘上的文件
中。
5. 当一个 Master 节点宕机或失去连接时，NameServer 会检测到这个变化，并将 Master 节点对应的
Topic 和队列信息标记为不可用。
6. Slave 节点会通过与 NameServer 的交互，获取到 Master 节点宕机的信息。具体的代码逻辑可以在
org. apache. RocketMQ. client. impl. factory. MQClientInstance 类中的
updateTopicRouteInfoFromNameServer () 方法中找到。
7. Slave 节点会尝试与其他可用的 Master 节点建立连接，并请求成为宕机 Master 节点的 Slave 节点。
8. 如果其他 Master 节点同意将该 Slave 节点作为自己的 Slave 节点，那么该 Slave 节点将成为新的
Master 节点的 Slave 节点。具体的代码逻辑可以在
org. apache. RocketMQ. broker. BrokerController 类中的 slaveSynchronize () 方法中找
到。
9. 新的 Master 节点会将自己的写入操作同步给所有的 Slave 节点，以保证数据的一致性。具体的代码
逻辑可以在 org. apache. RocketMQ. store. DefaultMessageStore 类中的 doDispatch () 方法中
找到。
10. 一旦宕机的 Master 节点恢复正常，它会尝试重新成为 Master 节点，而原来的 Slave 节点则会转变为
它的 Slave 节点。具体的代码逻辑可以在 org. apache. RocketMQ. broker. BrokerController 类
中的 rebalanceService () 方法中找到。
```
## 问懵了.... 美团一面索命 44 问，过了就 60 W+

#### 说在前面

在 40 岁老架构师尼恩的（50+） **读者社群** 中，经常有小伙伴，需要面试美团、京东、阿里、百度、头条
等大厂。

下面是一个小伙伴成功拿到通过了美团一次技术面试，最终，小伙伴通过后几面技术拷问、灵魂拷问，
最终拿到 offer。

**从这些题目来看：美团的面试，偏重底层知识和原理，大家来看看吧。**

现在把面试真题和参考答案收入咱们的宝典，大家看看， **收个美团 Offer 需要学点啥？**

当然对于中高级开发来说，这些面试题，也有参考意义。

这里把题目以及参考答案，收入咱们的《尼恩 Java 面试宝典》 V 84 版本，供后面的小伙伴参考，提升大
家的 3 高架构、设计、开发水平。


```
注：本文以 PDF 持续更新，相关尼恩架构笔记、面试题的 PDF 文件，请从这里获取：码云
```
#### 美团一面索命 44 问

###### 1 、说一说 Java 内存区域和内存模型

Java 内存区域和内存模型是不一样的东西。

**内存区域** ：JVM 运行时将数据分区域存储，强调对内存空间的划分。

**内存模型（Java Memory Model，简称 JMM ）** ：定义了线程和主内存之间的抽象关系，即 JMM 定义
了 JVM 在计算机内存 (RAM) 中的工作方式。

**一、内存区域**

下图是 JDK 1.8 之前的 JVM 运行时数据区域分布图：

下图是 JDK 1.8 之后的 JVM 运行时数据区域分布图：


通过 JDK 1.8 之前与 JDK 1.8 之后的 JVM 运行时数据区域分布图对比，我们可以发现区别就是 1.8 有一
个 **元空间** 替代 **方法区** 。下文元空间章节介绍了 **为何替换方法区** 。

下面我们针对 JDK 1.8 之后的 JVM 内存分布图介绍每个区域的它们是干什么的。

**本地方法栈**

**Native Method Stacks** ：是为虚拟机使用到的 Native 方法服务，可以认为是通过 JNI (Java Native
Interface) 直接调用本地 C/C++ 库，不受 JVM 控制。

```
我们常用获取当前时间毫秒就是 Native 本地方法，方法被 native 关键字修饰。
```
其实就是为了解决一些 Java 本身做不到，但是 C/C++ 可以，通过 JNI 扩展 Java 的使用，融合不同的编
程语言。

**程序计数器**

**Program Counter Register** ：一块较小的内存空间，它的作用可以看做是当前线程所执行的字节码的
行号指示器。由于 JVM 可以并发执行线程，所以会为每个线程分配一个程序计数器，与线程的生命周期
相同。因此会存在线程之间的切换，而这个时候就程序计数器会记录下当前程序执行到的位置，以便在
其他线程执行完毕后，恢复现场继续执行。

如果线程正在执行的是 Java 方法，这个计数器记录的是正在执行虚拟机字节码指令的地址；如果正在
执行的是 Native 方法，计数器的值则为空（undefined）

此内存区域是唯一一个在 Java 虚拟机规范中没有规定任何 OutOfMemoryError 情况的区域。

```
package java. lang;
```
```
public final class System {
public static native long currentTimeMillis ();
}
```

**Java 虚拟机栈**

**Java Virtual Machine Stacks** ：与程序计数器一样，Java 虚拟机栈也是线程私有的，它的生命周期与
线程相同。

虚拟机栈描述的是 Java 方法执行的内存模型：每个方法被执行的时候都会同时创建一个栈帧（Stack
Frame）用于存储局部变量表、操作栈、动态链接、方法出口等信息。每一个方法被调用直至执行完成
的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。

```
栈是一个先入后出 (FILO-First In Last Out) 的有序列表。在活动线程中，只有位于栈顶的栈帧才是
有效的，称为当前栈帧。正在执行的方法称为当前方法，栈帧是方法运行的基本结构。在执行引
擎运行时，所有指令都只能针对当前栈帧进行操作。
```
**局部变量表**

局部变量表是存放 **方法参数** 和 **局部变量** 的区域。局部变量没有准备阶段，必须显式初始化。全局变量是
放在堆的，有两次赋值的阶段，一次在类加载的准备阶段，赋予系统初始值；另外一次在类加载的初始
化阶段，赋予代码定义的初始值。

**操作栈**

操作栈是个初始状态为空的桶式结构栈 (先入后出)。当一个方法刚刚开始执行的时候，这个方法的操作
数栈是空的，在方法的执行过程中，会有各种字节码指令往操作数栈中写入和提取内容，也就是出栈/
入栈操作。

**动态链接**

每个栈帧都包含一个指向运行时常量池中对当前方法的引用，目的是支持方法调用过程的动态连接。当
前方法中如果需要调用其他方法的时候，能够从运行时常量池中找到对应的符号引用，然后将符号引用
转换为直接引用，然后就能直接调用对应方法。


不是所有方法调用都需要动态链接的，有一部分符号引用会在类加载解析阶段将符号引用转换为直接引
用，这部分操作称之为: 静态解析，就是编译期间就能确定调用的版本，包括: 调用静态方法, 调用实例
的私有构造器, 私有方法，父类方法。

**方法返回地址**

方法执行时有两种退出情况：

```
1. 正常退出，即正常执行到任何方法的返回字节码指令，如 RETURN、IRETURN、ARETURN 等；
2. 异常退出。
```
无论何种退出情况，都将返回至方法当前被调用的位置。方法退出的过程相当于弹出当前栈帧。

**堆**

```
我们经常说的 GC 调优/JVM 调优，99%指的都是调堆！Java 栈、本地方法栈、程序计数器这些一
般不会产生垃圾。
```
**Heap** ：Java 虚拟机所管理的内存中最大的一块。Java 堆是被所有线程共享的一块内存区域，在虚拟机
启动时创建。此内存区域的唯一目的就是存放对象实例，几乎所有的对象实例都在这里分配内存。

堆是垃圾收集器管理的主要区域，因此很多时候也被称做“GC 堆”（Garbage Collected Heap）。

**元空间**

JDK 1.8 就把方法区改用元空间了。类的元信息被存储在元空间中，元空间没有使用堆内存，而是与堆不
相连的 **本地内存区域** 。所以，理论上系统可以使用的内存有多大，元空间就有多大。

**方法区**

**Method Area** ：与 Java 堆一样，是各个 **线程共享的内存区域** ，它用于存储已被虚拟机加载的类信息、
常量、静态变量、即时编译器编译后的代码等数据。

虽然 Java 虚拟机规范把方法区描述为堆的一个逻辑部分，但是它却有一个别名叫做 Non-Heap（非
堆），目的应该是与 Java 堆区分开来。

**方法区与元空间的变迁**

下图是 JDK 1.6、JDK 1.7 到 JDK 1.8 方法区的大致变迁过程：

JDK 1.8 中 HotSpot JVM 移出永久代（PermGen），开始时使用元空间（Metaspace）。使用元空间
取代永久代的实现的主要原因如下：

```
1. 避免 OOM 异常，字符串存在永久代中，容易出现性能问题和内存溢出；
2. 永久代设置空间大小是很难确定，太小容易出现永久代溢出，太大则容易导致老年代溢出；
```

```
3. 永久代进行调优非常困难；
4. 将 HotSpot 与 JRockit 合二为一；
```
**二、内存模型**

**内存模型** 是为了保证共享内存的正确性（可见性、有序性、原子性），内存模型定义了共享内存系统中
多线程程序读写操作行为的规范。

内存模型解决并发问题主要采用两种方式： **限制处理器优化** 和 **使用内存屏障** 。

Java 内存模型（JMM）控制 Java 线程之间的通信，决定一个线程对共享变量的写入何时对另一个线程
可见。

**计算机高速缓存和缓存一致性**

计算机在高速的 CPU 和相对低速的存储设备之间使用高速缓存，作为内存和处理器之间的缓冲。当程
序在运行过程中，会将运算需要的数据从主存 (计算机的物理内存) 复制一份到 CPU 的高速缓存当中，那
么 CPU 进行计算时就可以直接从它的高速缓存读取数据和向其中写入数据，当运算结束之后，再将高
速缓存中的数据刷新到主存当中。

在多处理器的系统中 (或者单处理器多核的系统)，每个处理器内核都有自己的高速缓存，它们有共享同
一主内存 (Main Memory)。当 CPU 要读取一个数据时，首先从一级缓存中查找，如果没有找到，再从二
级缓存中查找，如果还是没有就从三级缓存（不是所有 CPU 都有三级缓存）或内存中查找。

在多核 CPU 中，每个核在自己的缓存中，关于同一个数据的缓存内容可能不一致。为此，需要各个处
理器访问缓存时都遵循一些协议，在读写时要根据协议进行操作，来维护缓存的一致性。

**JVM 主内存与工作内存**

Java 内存模型中规定了所有的变量都存储在主内存中，每条线程还有自己的工作内存，线程对变量的
所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。

这里的工作内存是 JMM 的一个抽象概念，其存储了该线程以读 / 写共享变量的副本。


**重排序**

在执行程序时为了提高性能，编译器和处理器常常会对指令做重排序。重排序分三种类型：

```
1. 编译器优化的重排序 ：编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。
2. 指令级并行的重排序 ：现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）
来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。
3. 内存系统的重排序 ：由于处理器使用缓存和读 / 写缓冲区，这使得加载和存储操作看上去可能是在
乱序执行。
```
```
从 java 源代码到最终实际执行的指令序列，会分别经历下面三种重排序：
```
JMM 属于语言级的内存模型，它确保在不同的编译器和不同的处理器平台之上，通过禁止特定类型的
编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。

Java 编译器禁止处理器重排序是通过在生成指令序列的适当位置会插入内存屏障（重排序时不能把后面的
指令重排序到内存屏障之前的位置）指令来实现的。

**happens-before**


Java 内存模型提出了 happens-before 的概念，通过这个概念来阐述操作之间的内存可见性。这里的
“可见性”是指当一条线程修改了这个变量的值，新值对于其他线程来说是可以立即得知的。

如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在 happens-before 关
系。这里提到的两个操作既可以是在一个线程之内，也可以是在不同线程之间。

**Java 内存模型的实现**

在 Java 中提供了一系列和并发处理相关的关键字，比如 volatile、synchronized、final、JUC
包等。其实这些就是 Java 内存模型封装了底层的实现后提供给程序员使用的一些关键字。

**原子性**

为了保证原子性，提供了两个高级的字节码指令 monitorenter 和 monitorexit，这两个字节码，在
Java 中对应的关键字就是 synchronized。

```
我们对 synchronized 关键字都很熟悉，你们可以把下面的代码编译成 class 文件，用 javap -
v SyncViewByteCode. class 查看字节码，就可以找到 monitorenter 和 monitorexit 字节
码指令。
```
字节码，部分结果如下：

```
public class SyncViewByteCode {
public synchronized void buy () {
System.out.println ("buy porsche");
}
}
```
```
public com.dolphin.thread.locks.SyncViewByteCode ();
descriptor: () V
flags: ACC_PUBLIC
Code:
stack= 1 , locals= 1 , args_size= 1
0 : aload_0
1 : invokespecial #1 // Method java/lang/Object."
<init>": () V
4 : return
LineNumberTable:
line 3 : 0
LocalVariableTable:
Start Length Slot Name Signature
 0 5 0 this Lcom/dolphin/thread/locks/SyncViewByteCode;
```
```
public void test 2 ();
descriptor: () V
flags: ACC_PUBLIC
Code:
stack= 2 , locals= 3 , args_size= 1
0 : aload_0
1 : dup
2 : astore_1
3 : monitorenter
4 : aload_1
5 : monitorexit
6 : goto  14
9 : astore_2
 10 : aload_1
```

**可见性**

Java 内存模型是通过在变量修改后将新值同步回主内存，在变量读取前从主内存刷新变量值的这种依赖
主内存作为传递媒介的方式来实现的。

Java 中的 volatile 关键字提供了一个功能，那就是被其修饰的变量在被修改后可以立即同步到主内
存，被其修饰的变量在每次是用之前都从主内存刷新。因此，可以使用 volatile 来保证多线程操作
时变量的可见性。

除了 volatile，Java 中的 synchronized 和 final 两个关键字也可以实现可见性。只不过实现方式
不同。

**有序性**

在 Java 中，可以使用 synchronized 和 volatile 来保证多线程之间操作的有序性。实现方式有所区
别：

```
volatile：关键字会禁止指令重排。
synchronized：关键字保证同一时刻只允许一条线程操作。
```
###### 2 、什么是分布式系统？

分布式系统是由多台计算机组成的网络系统，这些计算机通过消息传递或共享存储等方式协同工作，以
实现共同的目标。分布式系统的设计目标是将计算和数据分布在多个节点上，以提供更高的性能、可扩
展性和可靠性。

在分布式系统中，各个节点可以独立地执行任务，并通过通信协议进行相互通信和协调。这些节点可以
是物理上分布在不同地理位置的计算机，也可以是虚拟机、容器或云服务实例。

分布式系统的特点包括：

```
1. 并行处理 ：分布式系统可以同时处理多个任务，通过将工作分配给不同的节点并行执行，提高系统
的处理能力。
2. 可扩展性 ：分布式系统可以根据需求增加或减少节点，以适应不同规模和负载的变化。通过添加更
多的节点，系统可以处理更多的请求并提供更高的性能。
3. 容错性 ：分布式系统可以通过冗余和备份机制来提高系统的可靠性和容错性。当某个节点发生故障
时，系统可以继续运行，并且可以通过其他节点接管故障节点的工作。
4. 数据共享和协调 ：分布式系统通过共享存储或消息传递等方式实现节点之间的数据共享和协调。这
使得不同节点之间可以共享数据、状态和资源，并协同完成复杂的任务。
```
分布式系统的设计和管理需要考虑到网络通信、一致性、并发控制、故障处理等方面的挑战。同时，分
布式系统也提供了更高的灵活性和可靠性，被广泛应用于各种领域，如云计算、大数据处理、物联网
等。

###### 3 、分布式系统你会考虑哪些方面？

```
 11 : monitorexit
 12 : aload_2
 13 : athrow
 14 : return
Exception table:
```

在设计和管理分布式系统时，需要考虑以下方面：

```
1. 可靠性和容错性 ：分布式系统应具备容错能力，能够在节点故障或网络中断等情况下继续正常运
行。这可以通过冗余备份、故障检测和自动恢复机制来实现。
2. 可扩展性 ：分布式系统应具备良好的可扩展性，能够根据需求增加或减少节点，以适应不同规模和
负载的变化。这可以通过水平扩展和垂直扩展等方式来实现。
3. 数据一致性 ：在分布式系统中，由于数据分布在多个节点上，需要确保数据的一致性。这可以通过
一致性协议（如 Paxos、Raft）和副本同步机制来实现。
4. 通信和协议 ：分布式系统中的节点需要进行通信和协调工作，因此需要选择适合的通信协议和消息
传递机制。常见的通信协议包括 TCP/IP、HTTP、RPC 等。
5. 负载均衡 ：为了提高系统的性能和可用性，需要在节点之间均衡地分配负载。负载均衡可以通过请
求调度算法和动态负载均衡策略来实现。
6. 安全性 ：分布式系统需要保护数据的机密性、完整性和可用性，因此需要考虑安全性措施，如身份
验证、数据加密、访问控制等。
7. 监控和诊断 ：分布式系统应具备监控和诊断功能，能够实时监测系统的运行状态和性能指标，并及
时发现和解决问题。
8. 部署和管理 ：分布式系统的部署和管理需要考虑节点的配置、软件的安装和更新、版本控制等方面
的问题。自动化部署和管理工具可以提高效率和可靠性。
9. 数据备份和恢复 ：为了应对节点故障或数据丢失的情况，需要进行数据备份和恢复。常见的备份策
略包括冷备份、热备份和增量备份等。
10. 性能优化 ：分布式系统的性能优化涉及到各个方面，包括算法优化、数据结构设计、并发控制、缓
存策略等。
```
综上所述，设计和管理分布式系统需要综合考虑可靠性、可扩展性、数据一致性、通信和协议、负载均
衡、安全性、监控和诊断、部署和管理、数据备份和恢复以及性能优化等方面的问题。

###### 4 、为什么说 TCP/IP 协议是不可靠的？

TCP/IP 协议被认为是可靠的协议，因为它提供了许多机制来确保数据的可靠传输。

然而，有时人们会说 TCP/IP 协议是不可靠的，这是因为在特定情况下，它可能无法满足用户的要求或出
现一些问题。

以下是一些可能导致 TCP/IP 协议被称为不可靠的情况：

```
1. 丢包 ：在网络传输过程中，由于网络拥塞、设备故障或其他原因，数据包可能会丢失。尽管 TCP 协
议具有重传机制，但在某些情况下，丢失的数据包可能无法被及时重传，从而导致数据传输的不可
靠性。
2. 延迟 ：TCP/IP 协议使用拥塞控制机制来确保网络的稳定性和公平性。这意味着在网络拥塞时，数
据传输可能会出现延迟。对于某些对实时性要求较高的应用，如在线游戏或视频通话，这种延迟可
能被认为是不可靠的。
3. 顺序问题 ：TCP 协议保证数据包的按序传输，但在某些情况下，数据包的顺序可能会被打乱。例
如，当数据包在网络中的不同路径上传输时，它们可能以不同的顺序到达目的地。这可能导致数据
包的重组和排序问题，从而影响数据的可靠性。
```
需要注意的是，尽管 TCP/IP 协议在某些情况下可能会出现问题，但它仍然是互联网上最常用的协议之
一，被广泛应用于各种应用和服务中。此外，TCP/IP 协议还可以通过配置和优化来提高其可靠性和性
能。


###### 5 、OSI 有哪七层模型？TCP/IP 是哪四层模型？

**一、什么是 OSI？**

OSI 模型 (Open System Interconnection model) 是一个由国际标准化组织提出的概念模型, 试图提供一
个使各种不同的计算机和网络在世界范围内实现互联的标准框架。
它将计算机网络体系结构划分为七层, 每层都可以?? 供抽象良好的接口。

从上到下可分为七层： **每一层都完成特定的功能，并为上一层提供服务，并使用下层所提供的服务。**

```
物理层：
物理层负责最后将信息编码成电流脉冲或其它信号用于网上传输；
eg：RJ 45 等将数据转化成 0 和 1 ；
数据链路层:
数据链路层通过物理网络链路提供数据传输。不同的数据链路层定义了不同的网络和协议特征, 其
中包括物理编址、网络拓扑结构、错误校验、数据帧序列以及流控;
可以简单的理解为：规定了 0 和 1 的分包形式，确定了网络数据包的形式；
网络层
网络层负责在源和终点之间建立连接;
可以理解为，此处需要确定计算机的位置，怎么确定？IPv 4，IPv 6！
传输层
传输层向高层提供可靠的端到端的网络数据流服务。
可以理解为：每一个应用程序都会在网卡注册一个端口号，该层就是端口与端口的通信！常用的
（TCP／IP）协议；
会话层
会话层建立、管理和终止表示层与实体之间的通信会话；
```

```
OSI 七层网络模型 TCP/IP 四层概念模型对应网络协议
```
```
应用层
（Application） 应用层
```
```
HTTP、TFTP, FTP, NFS, WAIS、
SMTP
```
```
表示层
（Presentation） Telnet, Rlogin, SNMP, Gopher^
```
```
会话层（Session） SMTP, DNS
```
```
传输层
（Transport）
```
```
传输层 TCP, UDP
```
```
网络层（Network） 网络层 IP, ICMP, ARP, RARP, AKP, UUCP
```
```
数据链路层（Data
Link） 数据链路层
```
```
FDDI, Ethernet, Arpanet, PDN,
SLIP, PPP
```
```
物理层（Physical） IEEE 802.1 A, IEEE 802.2 到 IEEE
802.11
```
```
建立一个连接（自动的手机信息、自动的网络寻址）;
表示层
表示层提供多种功能用于应用层数据编码和转化, 以确保以一个系统应用层发送的信息可以被另一
个系统应用层识别;
可以理解为：解决不同系统之间的通信，eg：Linux 下的 QQ 和 Windows 下的 QQ 可以通信；
应用层
OSI 的应用层协议包括文件的传输、访问及管理协议 (FTAM) ,以及文件虚拟终端协议 (VIP) 和公用管
理系统信息 (CMIP) 等;
规定数据的传输协议；
```
**二、什么是 TCP/IP 四层模型？**

**应用层** （Application）：为用户提供所需要的各种服务

**传输层** （Transport）：为应用层实体提供端到端的通信功能，保证了数据包的顺序传送及数据的完整
性

**网际层** （Internet）：主要解决主机到主机的通信问题

**网络接口层** （Network Access）：负责监视数据在主机和网络之间的交换

**三、OSI 七层网络模型和 TCP/IP 四层网络模型的关系：**

OSI 引入了服务、接口、协议、分层的概念，TCP/IP 借鉴了 OSI 的这些概念建立 TCP/IP 模型。

OSI 先有模型，后有协议，先有标准，后进行实践；而 TCP/IP 则相反，先有协议和应用再提出了模型，
且是参照的 OSI 模型。

OSI 是一种理论下的模型，而 TCP/IP 已被广泛使用，成为网络互联事实上的标准。

**四、OSI 七层和 TCP/IP 的区别**


```
TCP/IP 他是一个协议簇；而 OSI（开放系统互联）则是一个模型，且 TCP/IP 的开发时间在 OSI 之
前。
TCP/IP 是由一些交互性的模块做成的分层次的协议，其中每个模块提供特定的功能；OSI 则指定了
哪个功能是属于哪一层的。
TCP/IP 是四层结构，而 OSI 是七层结构。OSI 的最高三层在 TCP 中用应用层表示。
```
**40 岁老架构师尼恩提示** ：


```
TCP/IP 既是面试的绝对重点，也是面试的绝对难点，建议大家有一个深入和详细的掌握，具体的
内容请参见《尼恩 Java 面试宝典-专题 10 ：TCP/IP 协议》PDF，该专题对 TCP/IP 有一个系统化、体
系化、全面化的介绍。
```
###### 6 、讲一讲 TCP 协议的三次握手和四次挥手流程

TCP 的三次握手和四次挥手实质就是 TCP 通信的连接和断开。

三次握手：为了对每次发送的数据量进行跟踪与协商，确保数据段的发送和接收同步，根据所接收到的
数据量而确认数据发送、接收完毕后何时撤消联系，并建立虚连接。

四次挥手：即终止 TCP 连接，就是指断开一个 TCP 连接时，需要客户端和服务端总共发送 4 个包以确认连
接的断开。

TCP 三次握手、四次挥手时序图

**一、三次握手**

TCP 协议位于传输层，作用是提供可靠的字节流服务，为了准确无误地将数据送达目的地，TCP 协议采
纳三次握手策略。


**三次握手原理：**

**第 1 次握手** ：客户端发送一个带有 SYN（synchronize）标志的数据包给服务端；

**第 2 次握手** ：服务端接收成功后，回传一个带有 SYN/ACK 标志的数据包传递确认信息，表示我收到了；

**第 3 次握手** ：客户端再回传一个带有 ACK 标志的数据包，表示我知道了，握手结束。

其中：SYN 标志位数置 1 ，表示建立 TCP 连接；ACK 标志表示验证字段。

可通过以下趣味图解理解三次握手：

**三次握手过程详细说明：**

```
1. 客户端发送建立 TCP 连接的请求报文，其中报文中包含 seq 序列号，是由发送端随机生成的，并且
将报文中的 SYN 字段置为 1 ，表示需要建立 TCP 连接。（SYN=1，seq=x，x 为随机生成数值）；
2. 服务端回复客户端发送的 TCP 连接请求报文，其中包含 seq 序列号，是由回复端随机生成的，并且
将 SYN 置为 1 ，而且会产生 ACK 字段，ACK 字段数值是在客户端发送过来的序列号 seq 的基础上加 1
进行回复，以便客户端收到信息时，知晓自己的 TCP 建立请求已得到验证。（SYN=1，ACK=x+1，
seq=y，y 为随机生成数值）这里的 ack 加 1 可以理解为是确认和谁建立连接；
3. 客户端收到服务端发送的 TCP 建立验证请求后，会使自己的序列号加 1 表示，并且再次回复 ACK 验
证请求，在服务端发过来的 seq 上加 1 进行回复。（SYN=1，ACK=y+1，seq=x+1）。
```
**二、四次挥手**

由于 TCP 连接是全双工的，因此每个方向都必须单独进行关闭。这原则是当一方完成它的数据发送任务
后就能发送一个 FIN 来终止这个方向的连接。收到一个 FIN 只意味着这一方向上没有数据流动，一个 TCP
连接在收到一个 FIN 后仍能发送数据。首先进行关闭的一方将执行主动关闭，而另一方执行被动关闭。

**四次挥手原理：**


**第 1 次挥手** ：客户端发送一个 FIN，用来关闭客户端到服务端的数据传送，客户端进入 FIN_WAIT_1 状
态；

**第 2 次挥手** ：服务端收到 FIN 后，发送一个 ACK 给客户端，确认序号为收到序号+1（与 SYN 相同，一个
FIN 占用一个序号），服务端进入 CLOSE_WAIT 状态；

**第 3 次挥手** ：服务端发送一个 FIN，用来关闭服务端到客户端的数据传送，服务端进入 LAST_ACK 状态；

**第 4 次挥手** ：客户端收到 FIN 后，客户端 t 进入 TIME_WAIT 状态，接着发送一个 ACK 给 Server，确认序号
为收到序号+1，服务端进入 CLOSED 状态，完成四次挥手。

其中：FIN 标志位数置 1 ，表示断开 TCP 连接。

可通过以下趣味图解理解四次挥手：

**四次挥手过程详细说明：**

```
1. 客户端发送断开 TCP 连接请求的报文，其中报文中包含 seq 序列号，是由发送端随机生成的，并且
还将报文中的 FIN 字段置为 1 ，表示需要断开 TCP 连接。（FIN=1，seq=x，x 由客户端随机生成）；
2. 服务端会回复客户端发送的 TCP 断开请求报文，其包含 seq 序列号，是由回复端随机生成的，而且
会产生 ACK 字段，ACK 字段数值是在客户端发过来的 seq 序列号基础上加 1 进行回复，以便客户端收
到信息时，知晓自己的 TCP 断开请求已经得到验证。（FIN=1，ACK=x+1，seq=y，y 由服务端随机
生成）；
3. 服务端在回复完客户端的 TCP 断开请求后，不会马上进行 TCP 连接的断开，服务端会先确保断开
前，所有传输到 A 的数据是否已经传输完毕，一旦确认传输数据完毕，就会将回复报文的 FIN 字段
置 1 ，并且产生随机 seq 序列号。（FIN=1，ACK=x+1，seq=z，z 由服务端随机生成）；
```

```
4. 客户端收到服务端的 TCP 断开请求后，会回复服务端的断开请求，包含随机生成的 seq 字段和 ACK
字段，ACK 字段会在服务端的 TCP 断开请求的 seq 基础上加 1 ，从而完成服务端请求的验证回复。
（FIN=1，ACK=z+1，seq=h，h 为客户端随机生成）
至此 TCP 断开的 4 次挥手过程完毕。
```
**三、种状态名词解析**

###### 7 、为什么 TCP 建立连接协议是三次握手，而关闭连接却是四次握手

###### 呢？为什么不能用两次握手进行连接？

TCP 使用三次握手来建立连接，而使用四次握手来关闭连接，主要是为了确保通信双方的状态同步和可
靠性。下面是详细解释：

**一、为什么建立连接需要三次握手？**

```
第一次握手 ：客户端发送一个带有 SYN（同步）标志的数据包到服务器，请求建立连接，并进入
SYN_SENT 状态。
第二次握手 ：服务器接收到客户端的请求后，回复一个带有 SYN/ACK（同步/确认）标志的数据
包，表示同意建立连接，并进入 SYN_RCVD 状态。
第三次握手 ：客户端收到服务器的回复后，再发送一个带有 ACK（确认）标志的数据包，表示连接
建立成功，双方可以开始通信，客户端和服务器都进入 ESTABLISHED 状态。
```
三次握手的目的是确保双方都能够收到对方的确认消息，以建立可靠的连接。如果只有两次握手，那么
可能会出现以下情况：

```
客户端发送了连接请求，但由于网络延迟等原因，该请求在传输过程中被丢失，服务器无法知道客
户端的请求。
服务器接收到客户端的连接请求后，发送了确认，但由于网络延迟等原因，该确认在传输过程中被
丢失，客户端无法知道服务器的确认。
```
```
LISTEN：等待从任何远端 TCP 和端口的连接请求。
```
```
SYN_SENT：发送完一个连接请求后等待一个匹配的连接请求。
```
```
SYN_RECEIVED：发送连接请求并且接收到匹配的连接请求以后等待连接请求确认。
```
```
ESTABLISHED：表示一个打开的连接，接收到的数据可以被投递给用户。连接的数据传输阶段的正常状态。
```
```
FIN_WAIT_1：等待远端 TCP 的连接终止请求，或者等待之前发送的连接终止请求的确认。
```
```
FIN_WAIT_2：等待远端 TCP 的连接终止请求。
```
```
CLOSE_WAIT：等待本地用户的连接终止请求。
```
```
CLOSING：等待远端 TCP 的连接终止请求确认。
```
```
LAST_ACK：等待先前发送给远端 TCP 的连接终止请求的确认（包括它字节的连接终止请求的确认）
```
```
TIME_WAIT：等待足够的时间过去以确保远端 TCP 接收到它的连接终止请求的确认。
TIME_WAIT 两个存在的理由：
1. 可靠的实现 tcp 全双工连接的终止；
2. 允许老的重复分节在网络中消逝。
```
```
CLOSED：不在连接状态（这是为方便描述假想的状态，实际不存在）
```

如果只有两次握手，上述情况下客户端和服务器都无法确认对方是否接收到了自己的请求或确认，从而
无法建立可靠的连接。因此，通过三次握手可以确保双方都能够确认连接的建立。

**二、为什么关闭连接需要四次握手？**

```
第一次握手 ：当一方决定关闭连接时，发送一个带有 FIN（结束）标志的数据包，表示不再发送数
据，但仍然可以接收数据，进入 FIN_WAIT_1 状态。
第二次握手 ：另一方收到 FIN 后，发送一个带有 ACK 标志的数据包作为确认，表示收到了关闭请
求，进入 CLOSE_WAIT 状态。
第三次握手 ：另一方发送一个带有 FIN 标志的数据包，表示同意关闭连接，进入 LAST_ACK 状态。
第四次握手 ：请求关闭连接的一方收到确认后，发送一个带有 ACK 标志的数据包，表示连接关闭，
进入 TIME_WAIT 状态。
```
四次握手的目的是确保双方都能够完成数据的传输和确认，以避免数据丢失或混乱。关闭连接时，双方
需要交换确认信息，以确保对方知道连接已关闭，并且不会再发送数据。

如果只有三次握手，可能会出现以下情况：

```
一方发送了关闭请求，但对方没有收到，导致连接一直处于半关闭状态。
一方发送了关闭请求后，对方直接关闭连接，而不等待数据传输完成，导致数据丢失。
```
通过四次握手，可以确保双方都能够完成数据传输和确认，从而安全地关闭连接。

需要注意的是，四次握手中的最后一次握手（第四次）是为了确保连接的可靠关闭，并且在关闭后一段
时间内等待可能延迟的数据包到达，以防止出现连接复用时的问题。

```
40 岁老架构师尼恩提示 ：TCP/IP 既是面试的绝对重点，也是面试的绝对难点，
```
```
建议大家有一个深入和详细的掌握，具体的内容请参见《尼恩 Java 面试宝典-专题 10 ：TCP/IP 协
议》PDF，该专题对 TCP/IP 有一个系统化、体系化、全面化的介绍。
```
###### 8 、http 请求头里，expire 和 cache-control 字段含义，说说

###### HTTP 状态码

在 HTTP 请求头中，Expires 和 Cache-Control 字段用于控制缓存的行为。

Expires 字段指定了一个绝对的过期时间，表示在该时间之后，缓存的副本将被认为是过期的。服务器
在返回响应时，会在响应头中包含 Expires 字段，告知客户端缓存的有效期。客户端在接收到响应后，
会将该响应缓存起来，并在过期时间之前使用缓存的副本。然而，Expires 字段存在一些问题，比如服
务器和客户端的时钟不同步可能导致缓存失效。

为了解决 Expires 字段的问题，引入了 Cache-Control 字段。Cache-Control 字段提供了更加灵活和
可靠的缓存控制机制。它可以包含多个指令，用逗号分隔，每个指令都有特定的含义和参数。常见的指
令包括：

```
max-age=<seconds>：指定缓存的最大有效期，以秒为单位。
no-cache：表示缓存副本需要重新验证，不能直接使用。
no-store：表示不缓存任何副本，每次请求都需要重新获取资源。
public：表示响应可以被任意缓存存储。
private：表示响应只能被单个用户缓存，通常用于私有数据。
```

HTTP 状态码用于表示服务器对请求的响应状态。常见的 HTTP 状态码包括：

```
1 xx：信息性状态码，表示请求已被接收，继续处理。
2 xx：成功状态码，表示请求已成功被接收、理解、并处理。
3 xx：重定向状态码，表示需要进一步操作以完成请求。
4 xx：客户端错误状态码，表示请求包含错误或无法完成请求。
5 xx：服务器错误状态码，表示服务器在处理请求时发生了错误。
```
一些常见的状态码包括：

```
200 OK：请求成功，服务器成功处理了请求。
301 Moved Permanently：永久重定向，请求的资源已永久移动到新位置。
400 Bad Request：客户端请求有语法错误，服务器无法理解。
404 Not Found：请求的资源不存在。
500 Internal Server Error：服务器内部错误，无法完成请求。
```
状态码提供了一种标准化的方式，使得客户端和服务器能够准确地了解请求的处理结果，并采取相应的
操作。

###### 9 、说说 Redis 为什么快

Redis 之所以快速，主要有以下几个原因：

```
1. 内存存储 ：Redis 将数据存储在内存中，而不是磁盘上，这使得它能够快速读取和写入数据。相比
于传统的磁盘存储数据库，如 MySQL，Redis 能够提供更低的访问延迟。
2. 单线程模型 ：Redis 使用单线程模型处理客户端请求。虽然这听起来可能会导致性能瓶颈，但实际
上，这种设计使得 Redis 能够避免了多线程之间的锁竞争和上下文切换的开销。此外，单线程模型
还简化了 Redis 的实现和维护。
3. 高效的数据结构 ：Redis 支持多种数据结构，如字符串、哈希表、列表、集合和有序集合等。这些
数据结构在存储和操作数据时都经过了高度优化，使得 Redis 能够高效地执行各种操作，如读取、
写入、更新和删除等。
4. 异步操作 ：Redis 支持异步操作，即客户端可以将一些耗时的操作交给 Redis 后台线程处理，而不
需要等待操作完成。这使得 Redis 能够更好地处理并发请求和高负载情况。
5. 网络模型 ：Redis 使用基于事件驱动的网络模型，通过非阻塞 I/O 和事件通知机制来处理网络请求。
这种模型使得 Redis 能够高效地处理大量的并发连接和请求。
```
总的来说，Redis 通过内存存储、单线程模型、高效的数据结构、异步操作和优化的网络模型等多种技
术手段，实现了高性能和低延迟的特性。这使得 Redis 成为了一个快速、可靠的键值存储系统和缓存数
据库。

```
40 岁老架构师尼恩提示 ：Redis 既是面试的绝对重点，也是面试的绝对难点，
```
```
建议大家有一个深入和详细的掌握，具体的内容请参见《尼恩 Java 面试宝典-专题 14 ：Redis 面试
题》PDF，该专题对 Redis 有一个系统化、体系化、全面化的介绍。
```
```
如果要把 Redis 高并发实战写入简历，可以找尼恩指导。
```
###### 10 、Redis 有几种持久化方式

Redis 提供了两种主要的持久化方式：RDB（Redis Database）和 AOF（Append-Only File）。


**一、RDB 持久化：**

RDB 持久化是将 Redis 的数据以二进制文件的形式保存到磁盘上。它是通过定期执行快照操作来实现
的，可以手动触发或者根据配置的规则自动触发。RDB 持久化的过程中，Redis 会将当前内存中的数据
快照保存到一个 RDB 文件中，然后将该文件写入磁盘。在 Redis 重启时，可以通过加载 RDB 文件来恢复
数据。

RDB 持久化的优点是快速和紧凑，因为它是通过直接将内存数据写入磁盘来完成的，不需要执行额外的
I/O 操作。它适用于数据备份和灾难恢复。

**二、AOF 持久化：**

AOF 持久化是通过将 Redis 的写命令追加到一个日志文件中来实现的。Redis 会将每个写命令追加到 AOF
文件的末尾，以此来记录数据的变化。在 Redis 重启时，会重新执行 AOF 文件中的命令来恢复数据。

AOF 持久化的优点是数据的持久性更好，因为它记录了每个写操作，可以保证数据的完整性。此外，
AOF 文件是以文本格式保存的，易于阅读和理解。

AOF 持久化有两种模式：默认模式和重写模式。默认模式下，Redis 会将写命令追加到 AOF 文件的末
尾；而重写模式下，Redis 会根据当前内存中的数据生成一个新的 AOF 文件，用于替换旧的 AOF 文件。
重写模式可以减小 AOF 文件的大小，提高读取效率。

综合来说，RDB 持久化适用于快速备份和恢复数据，而 AOF 持久化适用于数据的持久性和完整性要求较
高的场景。可以根据实际需求选择合适的持久化方式，或者同时使用两种方式来提供更好的数据保护和
恢复能力。

###### 11 、Redis 挂了怎么办？

当 Redis 挂了时，你可以采取以下措施来解决问题：

```
1. 检查 Redis 进程 ：首先，确保 Redis 进程确实已经挂掉。你可以使用命令行或者管理工具来检查
Redis 进程的状态。
2. 查看日志文件 ：如果 Redis 挂掉，你可以查看 Redis 的日志文件，通常是 redis-server. log 文件，来
获取更多的错误信息和异常情况。日志文件可以帮助你了解 Redis 挂掉的原因。
3. 重启 Redis ：如果 Redis 挂掉了，你可以尝试重新启动 Redis。使用命令行或者管理工具来启动
Redis 服务器进程。
4. 恢复数据 ：如果 Redis 挂掉导致数据丢失，你可以尝试从备份中恢复数据。如果你使用了 Redis 的
持久化机制（如 RDB 或 AOF），你可以将备份文件恢复到 Redis 服务器上。
5. 检查服务器资源 ：如果 Redis 挂掉频繁，你需要检查服务器的资源使用情况，包括内存、CPU、磁
盘等。确保服务器有足够的资源来支持 Redis 的正常运行。
6. 优化配置 ：根据你的需求和服务器资源情况，可以考虑优化 Redis 的配置文件。例如，增加最大内
存限制、调整持久化机制、调整网络参数等。
7. 监控和预警 ：为了避免 Redis 挂掉，你可以使用监控工具来实时监测 Redis 的运行状态，并设置预
警机制，及时发现并解决潜在的问题。
8. 寻求专业支持 ：如果你无法解决 Redis 挂掉的问题，你可以寻求专业的技术支持或咨询，他们可以
帮助你分析和解决问题。
```
请注意，以上步骤仅提供了一般性的解决方案，具体的操作步骤可能因你的环境和情况而有所不同。在
处理 Redis 挂掉的问题时，建议参考 Redis 官方文档和相关技术资源，以获得更准确和详细的指导。

###### 12 、多线程情况下，如何保证线程安全？


**一、线程安全等级**

之前的博客中已有所提及“线程安全”问题，一般我们常说某某类是线程安全的，某某是非线程安全的。
其实线程安全并不是一个“非黑即白”单项选择题。按照“线程安全”的安全程度由强到弱来排序，我们可
以将 java 语言中各种操作共享的数据分为以下 5 类：不可变、绝对线程安全、相对线程安全、线程兼容
和线程对立。

**1. 不可变**

在 java 语言中，不可变的对象一定是线程安全的，无论是对象的方法实现还是方法的调用者，都不需要
再采取任何的线程安全保障措施。如 final 关键字修饰的数据不可修改，可靠性最高。

**2. 绝对线程安全**

绝对的线程安全完全满足 Brian GoetZ 给出的线程安全的定义，这个定义其实是很严格的，一个类要达
到“不管运行时环境如何，调用者都不需要任何额外的同步措施”通常需要付出很大的代价。

**3. 相对线程安全**

相对线程安全就是我们通常意义上所讲的一个类是“线程安全”的。
它需要保证对这个对象单独的操作是线程安全的，我们在调用的时候不需要做额外的保障措施，但是对
于一些特定顺序的连续调用，就可能需要在调用端使用额外的同步手段来保证调用的正确性。
在 java 语言中，大部分的线程安全类都属于相对线程安全的，例如 Vector、HashTable、Collections 的
synchronizedCollection () 方法保证的集合。

**4. 线程兼容**

线程兼容就是我们通常意义上所讲的一个类不是线程安全的。
线程兼容是指对象本身并不是线程安全的，但是可以通过在调用端正确地使用同步手段来保证对象在并
发环境下可以安全地使用。Java API 中大部分的类都是属于线程兼容的。如与前面的 Vector 和
HashTable 相对应的集合类 ArrayList 和 HashMap 等。

**5. 线程对立**


线程对立是指无论调用端是否采取了同步错误，都无法在多线程环境中并发使用的代码。由于 java 语言
天生就具有多线程特性，线程对立这种排斥多线程的代码是很少出现的。
一个线程对立的例子是 Thread 类的 supend () 和 resume () 方法。如果有两个线程同时持有一个线程对
象，一个尝试去中断线程，另一个尝试去恢复线程，如果并发进行的话，无论调用时是否进行了同步，
目标线程都有死锁风险。正因此如此，这两个方法已经被废弃啦。

**二、线程安全的实现方法**

保证线程安全以是否需要同步手段分类，分为同步方案和无需同步方案。

**1. 互斥同步**

互斥同步是最常见的一种并发正确性保障手段。同步是指在多线程并发访问共享数据时，保证共享数据
在同一时刻只被一个线程使用（同一时刻，只有一个线程在操作共享数据）。而互斥是实现同步的一种
手段，临界区、互斥量和信号量都是主要的互斥实现方式。因此，在这 4 个字里面，互斥是因，同步是
果；互斥是方法，同步是目的。
在 java 中，最基本的互斥同步手段就是 synchronized 关键字，synchronized 关键字编译之后，会在同步
块的前后分别形成 monitorenter 和 monitorexit 这两个字节码质量，这两个字节码指令都需要一个
reference 类型的参数来指明要锁定和解锁的对象。
此外，ReentrantLock 也是通过互斥来实现同步。在基本用法上，ReentrantLock 与 synchronized 很相
似，他们都具备一样的线程重入特性。
互斥同步最主要的问题就是进行线程阻塞和唤醒所带来的性能问题，因此这种同步也成为阻塞同步。从
处理问题的方式上说，互斥同步属于一种悲观的并发策略，总是认为只要不去做正确地同步措施（例如
加锁），那就肯定会出现问题，无论共享数据是否真的会出现竞争，它都要进行加锁。

**2. 非阻塞同步**

随着硬件指令集的发展，出现了基于冲突检测的乐观并发策略，通俗地说，就是先进行操作，如果没有
其他线程争用共享数据，那操作就成功了；如果共享数据有争用，产生了冲突，那就再采用其他的补偿
措施。（最常见的补偿错误就是不断地重试，直到成功为止），这种乐观的并发策略的许多实现都不需
要把线程挂起，因此这种同步操作称为非阻塞同步。

非阻塞的实现 CAS（compareandswap）：CAS 指令需要有 3 个操作数，分别是内存地址（在 java 中理
解为变量的内存地址，用 V 表示）、旧的预期值（用 A 表示）和新值（用 B 表示）。CAS 指令执行时，
CAS 指令指令时，当且仅当 V 处的值符合旧预期值 A 时，处理器用 B 更新 V 处的值，否则它就不执行更新，
但是无论是否更新了 V 处的值，都会返回 V 的旧值，上述的处理过程是一个原子操作。

**CAS 缺点：**


```
1. ABA 问题：因为 CAS 需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但
是一个值原来是 A，变成了 B，又变成了 A，那么使用 CAS 进行检查时会发现它的值没有发生变化，
但是实际上却变化了。
2. ABA 问题的解决思路就是使用版本号。在变量前面追加版本号，每次变量更新的时候把版本号加
一，那么 A-B-A 就变成了 1 A-2 B-3 C。JDK 的 atomic 包里提供了一个类 AtomicStampedReference 来
解决 ABA 问题。这个类的 compareAndSet 方法作用是首先检查当前引用是否等于预期引用，并且
当前标志是否等于预期标志，如果全部相等，则以原子方式将该引用和该标志的值设置为给定的更
新值。
```
**3. 无需同步方案**

要保证线程安全，并不是一定就要进行同步，两者没有因果关系。同步只是保证共享数据争用时的正确
性的手段，如果一个方法本来就不涉及共享数据，那它自然就无需任何同步操作去保证正确性，因此会
有一些代码天生就是线程安全的。

**1 ）可重入代码**

可重入代码（ReentrantCode）也称为纯代码（Pure Code），可以在代码执行的任何时刻中断它，转
而去执行另外一段代码，而在控制权返回后，原来的程序不会出现任何错误。所有的可重入代码都是线
程安全的，但是并非所有的线程安全的代码都是可重入的。
可重入代码的特点是不依赖存储在堆上的数据和公用的系统资源、用到的状态量都是由参数中传入、不
调用非可重入的方法等。
（类比：synchronized 拥有锁重入的功能，也就是在使用 synchronized 时，当一个线程得到一个对象
锁后，再次请求此对象锁时时可以再次得到该对象的锁）

**2 ）线程本地存储**

如果一段代码中所需的数据必须与其他代码共享，那就看看这些共享数据的代码是否能保证在同一个线
程中执行？如果能保证，我们就可以把共享数据的可见范围限制在同一个线程之内。这样无需同步也能
保证线程之间不出现数据的争用问题。
符合这种特点的应用并不少见，大部分使用消费队列的架构模式（如“生产者-消费者”模式）都会将产品
的消费过程尽量在一个线程中消费完。其中最重要的一个应用实例就是经典的 Web 交互模型中的“一个
请求对应一个服务器线程（Thread-per-Request）”的处理方式，这种处理方式的广泛应用使得很多
Web 服务器应用都可以使用线程本地存储来解决线程安全问题。

###### 13 、用过 volatile 吗？它是如何保证可见性的，原理是什么呢？

在 Java 中，volatile 关键字用于修饰变量，以确保对该变量的读写操作具有可见性和有序性。

volatile 关键字的原理是通过禁止线程对被修饰变量的缓存操作，直接从主内存中读取和写入变量的
值。当一个线程修改了 volatile 变量的值时，它会立即将新值刷新到主内存中，而不是仅仅更新自己
的本地缓存。其他线程在读取该变量时，会从主内存中获取最新的值，而不是使用自己的缓存。

这种机制确保了 volatile 变量的可见性，即一个线程对该变量的修改对其他线程是可见的。当一个线
程修改了 volatile 变量的值后，其他线程在读取该变量时，会看到最新的值。

此外，volatile 关键字还可以保证操作的有序性。具体来说，volatile 变量的写操作之前的所有操
作都会在写操作之前完成，而写操作之后的所有操作都会在写操作之后开始。这就确保了对 volatile
变量的操作是按照预期的顺序执行的。

需要注意的是，volatile 关键字只能保证单个变量的可见性和有序性，不能保证多个变量之间的原子
性操作。如果需要保证多个变量的原子性操作，可以考虑使用 synchronized 关键字或者
java. util. concurrent 包中的原子类。


###### 14 、谈谈你对 volatile 关键字作用和原理的理解

**voliate 关键字的两个作用** ：

**1 、保证变量的可见性** ：当一个被 volatile 关键字修饰的变量被一个线程修改的时候，其他线程可以立刻
得到修改之后的结果。当一个线程向被 volatile 关键字修饰的变量写入数据的时候，虚拟机会强制它被
值刷新到主内存中。当一个线程用到被 volatile 关键字修饰的值的时候，虚拟机会强制要求它从主内存
中读取。

**2 、屏蔽指令重排序** ：指令重排序是编译器和处理器为了高效对程序进行优化的手段，它只能保证程序
执行的结果时正确的，但是无法保证程序的操作顺序与代码顺序一致。这在单线程中不会构成问题，但
是在多线程中就会出现问题。非常经典的例子是在单例方法中同时对字段加入 voliate，就是为了防止指
令重排序。

**一、可见性**

**简单来说** ：当一个共享变量被 volatile 修饰时，它会保证修改的值会立即被更新到主存，当有其他线程
需要读取时，它会去内存中读取新值。

**MESI 协议** ：在早期的 CPU 中，是通过在 **总线加 LOCK #锁的方式实现的 ** ，但是这种方式开销太大，所以
Intel 开发了缓存一致性协议，也就是 MESI 协议。

**缓存一致性思路** ：当 CPU 写数据时，如果发现操作的变量时共享变量，即其他线程的工作内存也存在该
变量，于是会发信号通知其他 CPU 该变量的内存地址无效。当其他线程需要使用这个变量时，如内存地
址失效，那么它们会在主存中重新读取该值。

**详细过程** ：

流程图：


**总线嗅探机制** ：

嗅探机制其实就是一个监听器，回到我们刚才的流程，如果是加入 MESI 缓存一致性协议和总线嗅探机制
之后：

（ 1 ）CPU 1 读取数据 a=1，CPU 1 的缓存中都有数据 a 的副本，该缓存行置为（E）状态

（ 2 ）CPU 2 也执行读取操作，同样 CPU 2 也有数据 a=1 的副本，此时总线嗅探到 CPU 1 也有该数据，则
CPU 1、CPU 2 两个缓存行都置为（S）状态

（ 3 ）CPU 1 修改数据 a=2，CPU 1 的缓存以及主内存 a=2，同时 CPU 1 的缓存行置为（S）状态，总线发出
通知，CPU 2 的缓存行置为（I）状态

（ 4 ）CPU 2 再次读取 a，虽然 CPU 2 在缓存中命中数据 a=1，但是发现状态为（I），因此直接丢弃该数
据，去主内存获取最新数据

**二、禁止重排序**

volatile 禁止重排序是利用 **内存屏障** ，保证有序性。
内存屏障是一组 CPU 指令，用于实现对内存操作的顺序限制。
Java 编译器，会在生成指令系列时，在适当的位置会插入内存屏障来禁止处理器对指令的重新排序。

（ 1 ）volatile 会在变量 **写操作的前后** 加入两个内存屏障，来保证前面的写指令和后面的读指令是有序
的。


（ 2 ）volatile 在变量的 **读操作后面** 插入两个指令，禁止后面的读指令和写指令重排序。

**总结**

volatile 其实可以看作是轻量级的 synchronized，虽然说 volatile **不能保证原子性** ，但是如果在多线程下
的操作本身就是原子性操作（例如赋值操作），那么使用 volatile 会由于 synchronized。

volatile 可以适用于某个 **标识 flag** ，一旦被修改了就需要被其他线程立即可见的情况。也可以修饰作为 **触
发器的变量** ，一旦变量被任何一个线程修改了，就去触发执行某个操作。

**volatile 最适合用的场景是一个线程修改被 volatile 修饰的变量，其他多个线程获取这个变量的值。
当多个线程并发修改某个变量值时，必须使用 synchronized 来进行互斥同步。**

**volatile 的性能** ：
若一个变量用 volatile 修饰，那么对该变量的每次读写，CPU 都需要从主内存读取，性能肯定受到一定影
响。
也就是说：volatile 变量远离了 CPU Cache，所以没那么高效。

###### 15 、聊聊分库分表，分表为什么要停服这种操作，如果不停服可以怎

###### 么做？

**一、分库分表**

分库分表是一种数据库水平拆分的策略，用于解决单一数据库在数据量增大或访问压力增大时的性能瓶
颈问题。它将一个数据库拆分为多个子数据库（分库），并将每个子数据库中的表进一步拆分为多个子
表（分表），从而实现数据的分散存储和查询负载的分摊。

**二、分表为什么要停服**

在进行分表操作时，通常需要停服，主要原因有两点：

```
1. 数据迁移 ：分表操作涉及到将原有的表数据迁移到新的分表中，这个过程需要将数据从原表复制到
新表，可能需要进行数据转换和重新分配。在这个过程中，为了保证数据的一致性和完整性，需要
停止对数据库的写入操作，以免出现数据丢失或不一致的情况。
2. 数据库结构变更 ：分表操作通常需要对数据库的结构进行修改，包括创建新的分表、调整索引、更
新外键关系等。这些操作可能会导致数据库的元数据发生变化，而且在变更过程中，数据库可能无
法正常处理查询请求，因此需要停服。
```
**三、如果不停服可以怎么做**


如果不想停服进行分表操作，可以考虑以下几种方式：

```
1. 逐步迁移 ：可以先创建新的分表，并将新数据写入新表中，同时保持对旧表的读取操作。随着时间
的推移，新表中的数据会逐渐增多，而旧表中的数据会逐渐减少。当新表中的数据足够多时，可以
将旧表中的数据迁移到新表中，最终停止对旧表的读取操作。
2. 数据复制 ：可以在不停服的情况下，将原有表的数据复制到新表中，并通过数据同步的方式保持两
个表的数据一致性。在复制过程中，需要注意处理并发写入的情况，以避免数据冲突。
3. 分流处理 ：可以通过引入中间件或代理层来实现请求的分流处理。在分表过程中，可以将部分请求
路由到新表中，而将其他请求仍然路由到旧表中，以实现逐步的分表过渡。
```
需要注意的是，不停服进行分表操作可能会增加系统的复杂性和风险，需要谨慎评估和测试。在进行分
表操作前，应该备份数据、制定详细的计划，并确保有充分的测试和回滚策略。

###### 16 、Java 虚拟机中，数据类型可以分为哪几类？

在 Java 虚拟机中，数据类型可以分为以下几类：

```
1. 基本数据类型（Primitive Types） ：Java 提供了 8 种基本数据类型，分别是 boolean、byte、
short、int、long、float、double 和 char。这些类型直接存储数据的值，而不是对象的
引用。
2. 引用数据类型（Reference Types） ：引用数据类型是指除了基本数据类型以外的所有类型，包
括类（Class）、接口（Interface）、数组（Array）以及枚举（Enum）等。引用数据类型存储的
是对象的引用，而不是对象本身的值。
3. 数组类型（Array Types） ：数组是一种特殊的引用数据类型，可以存储多个相同类型的元素。数
组可以是一维的、二维的，甚至是多维的。
4. 类类型（Class Types） ：类类型是指通过 class 关键字定义的类。类是对象的模板，描述了对象
的属性和行为。
5. 接口类型（Interface Types） ：接口类型是指通过 interface 关键字定义的接口。接口定义了
一组方法的规范，实现了接口的类必须实现这些方法。
6. 枚举类型（Enum Types） ：枚举类型是指通过 enum 关键字定义的枚举类。枚举类表示一组具名
的常量，可以有自己的方法和属性。
7. 注解类型（Annotation Types） ：注解类型是指通过@interface 关键字定义的注解。注解用于
为程序的元素（类、方法、变量等）添加额外的元数据。
```
这些数据类型在 Java 虚拟机中都有相应的内存表示和操作方式，开发者可以根据需求选择合适的数据类
型来存储和操作数据。

###### 17 、怎么理解栈、堆？堆中存什么？栈中存什么？

在计算机科学中，栈（Stack）和堆（Heap）是两个重要的内存区域，用于存储程序运行时的数据。它
们具有不同的特点和用途。

**一、栈（Stack）：**


```
栈是一种线性数据结构，采用后进先出（LIFO）的原则，即最后进入的数据最先被访问。
栈中存储的是局部变量、方法参数、方法调用和返回状态等。
栈的大小是在程序编译阶段就确定的，由编译器自动分配和释放。栈的操作速度快，分配和回收内
存非常高效。
栈中的数据大小和生命周期都是确定的，当一个方法执行结束后，其在栈中的数据就会被立即释
放。
```
**二、堆（Heap）：**

```
堆是一种动态分配内存的方式，用于存储对象和数据结构。
堆中存储的是通过 new 关键字创建的对象、数组以及其他动态分配的数据。
堆的大小可以动态调整，由垃圾回收器负责管理内存的分配和释放。
堆中的数据大小和生命周期是不确定的，对象的生命周期由程序的逻辑决定，当没有引用指向一个
对象时，该对象就会被垃圾回收器回收。
```
**总结：**

```
栈用于存储方法的调用和返回信息，以及局部变量等数据，大小和生命周期确定。
堆用于存储动态分配的对象和数据，大小和生命周期不确定。
```
需要注意的是，Java 中的基本数据类型的值可以直接存储在栈上，而引用数据类型的对象则存储在堆
上，栈中存储的是对象的引用。

###### 18 、为什么要把堆和栈区分出来呢？栈中不是也可以存储数据吗？

将堆和栈区分出来是为了更好地管理内存和支持程序的执行。

首先，栈用于存储方法调用和返回信息，以及局部变量等数据。栈的特点是具有快速的分配和释放速
度，以及按照"先进后出"的原则进行操作。当一个方法被调用时，栈会为该方法分配一块内存空间，称
为栈帧。栈帧中包含了方法的参数、局部变量和返回地址等信息。当方法执行完毕后，其对应的栈帧会
被释放，以便其他方法使用。由于栈的管理方式简单高效，因此适合存储较小的数据和临时变量。

而堆用于存储动态分配的对象和数据。堆的特点是具有灵活的分配和释放方式，并且可以动态地调整内
存空间的大小。在堆中分配的对象可以在程序的不同部分进行共享和访问。由于堆的管理方式相对复
杂，需要考虑对象的生命周期、垃圾回收等问题，因此适合存储较大的数据和长期存在的对象。

总结来说，栈和堆的区分主要是为了满足不同类型数据的存储需求和内存管理的需要。栈适合存储方法
调用和局部变量等临时数据，而堆适合存储动态分配的对象和长期存在的数据。

###### 19 、为什么不把基本类型放堆中呢？

将基本类型放在堆中会导致额外的内存开销和性能损失。以下是几个原因：

```
1. 内存开销 ：将基本类型放在堆中会导致每个变量都需要额外的内存空间来存储对象头和其他管理信
息。相比之下，将基本类型存储在栈中只需要分配固定大小的内存空间，没有额外的开销。
```

```
2. 访问速度 ：栈的访问速度比堆更快。因为栈中的数据是按照"先进后出"的原则进行操作，所以可以
通过简单的指针操作来访问和释放栈中的数据。而堆中的数据需要通过引用来访问，需要额外的寻
址和解引用操作，因此访问速度相对较慢。
3. 管理复杂性 ：将基本类型放在堆中会增加内存管理的复杂性。堆中的对象需要进行垃圾回收和内存
释放等操作，而基本类型存储在栈中不需要进行这些操作，使内存管理更加简单和高效。
4. 值传递 ：基本类型在栈中存储时采用值传递的方式，而引用类型在堆中存储时采用引用传递的方
式。值传递可以避免对象的共享和副作用，而引用传递可以实现对象的共享和传递。
```
综上所述，将基本类型放在栈中可以减少内存开销、提高访问速度和简化内存管理，因此通常将基本类
型存储在栈中。而将引用类型存储在堆中可以实现对象的动态分配和共享。

###### 20 、Java 中的参数传递时传值呢？还是传引用？

在 Java 中，参数传递是通过值传递（pass by value）进行的。这意味着在方法调用时，实际上是将参数
的值复制一份传递给方法，而不是传递参数本身。

当传递基本类型（如 int、float、boolean 等）时，实际上是将该值的副本传递给方法。在方法内部对参
数进行修改不会影响原始的值，因为只是对副本进行的操作。

当传递引用类型（如对象、数组等）时，实际上是将引用的副本传递给方法。引用本身是一个地址值，
指向实际对象在堆中的存储位置。在方法内部对引用进行修改不会影响原始的引用，但是可以通过引用
访问和修改对象的属性和状态。

需要注意的是，虽然传递引用类型时传递的是引用的副本，但是这个副本仍然指向同一个对象。因此，
在方法内部对对象进行修改，会影响原始对象的状态。

另外，Java 中的字符串是不可变的对象，当传递字符串时，实际上是将字符串的副本传递给方法。在方
法内部对字符串进行修改时，会创建一个新的字符串对象，而不会修改原始的字符串对象。

综上所述，Java 中的参数传递是通过值传递进行的，无论是基本类型还是引用类型。对于基本类型，传
递的是值的副本；对于引用类型，传递的是引用的副本，但仍然指向同一个对象。

###### 21 、Java 中有没有指针的概念？

在 Java 中，存在指针的概念，但是 Java 中的指针被隐藏在底层，并且不允许直接访问和操作指针。相
反，Java 使用引用来实现对对象的操作。

在 Java 中，引用是指向对象的变量，它存储了对象在内存中的地址。通过引用，我们可以间接地访问和
操作对象。与指针不同，Java 的引用不允许进行指针运算，不能直接访问对象的内存地址。

Java 的引用具有自动内存管理的特性，即垃圾回收机制。在 Java 中，当一个对象不再被引用时，垃圾回
收机制会自动回收该对象所占用的内存空间，这样就避免了内存泄漏和悬空指针的问题。

因此，尽管 Java 中没有直接操作指针的概念，但通过引用的方式，Java 实现了对对象的间接操作，并提
供了自动内存管理的机制，使得开发人员更加方便和安全地进行编程。


###### 22 、Java 中，栈的大小通过什么参数来设置？

在 Java 中，栈的大小可以通过虚拟机参数来设置。具体而言，可以使用以下参数来调整栈的大小：

- Xss：该参数用于设置线程栈的大小。

例如，-Xss 1 m 表示将线程栈的大小设置为 1 MB。

请注意，栈的大小是每个线程独立设置的，因此通过调整线程栈的大小，可以控制每个线程所占用的栈
空间。

需要注意的是，栈的大小设置过小可能导致栈溢出的问题，而设置过大可能会占用过多的内存资源。因
此，在调整栈的大小时需要谨慎，并根据具体的应用场景和需求进行合理的设置。

另外，栈的大小还受到操作系统和硬件的限制，超过一定限制将无法设置更大的栈空间。因此，在设置
栈的大小时，需要考虑到系统的限制，并进行适当的调整。

###### 23 、一个空 Object 对象的占多大空间？

在 Java 中，一个空的 Object 对象占用的空间大小主要由对象头和对齐填充所占用的空间决定。

对象头包含了一些元数据信息，如对象的哈希码、锁状态、GC 标记等。在 64 位的 JVM 上，对象头的大小
通常为 12 字节。

此外，由于 JVM 对内存的分配和对齐要求，对象的大小必须是字节对齐的。在大多数情况下，Java 对象
的大小都会被自动调整为 8 字节的倍数。

因此，一个空的 Object 对象在 64 位的 JVM 上的占用空间大小通常为 16 字节。这包括对象头的 12 字节和
对齐填充的 4 字节。

需要注意的是，不同的 JVM 实现可能会有所不同，因此实际空对象的大小可能会有所差异。另外，如果
在 Object 对象中添加了实例变量，那么空对象的大小将会增加，具体大小取决于添加的实例变量的数
量和类型。

###### 24 、对象引用类型分为哪几类？

在 Java 中，对象引用类型可以分为以下几类：

```
1. 强引用（Strong Reference） ：强引用是最常见的引用类型。当一个对象被强引用关联时，即使
内存不足时也不会被垃圾回收器回收。只有当该对象没有任何强引用时，才会被判定为可回收对
象。
2. 软引用（Soft Reference） ：软引用用于描述一些还有用但非必需的对象。当内存不足时，垃圾
回收器可能会回收软引用对象。在 Java 中，可以使用 SoftReference 类来创建软引用。
```

```
3. 弱引用（Weak Reference） ：弱引用比软引用更弱，用于描述非必需的对象。当垃圾回收器运
行时，无论内存是否充足，都会回收弱引用对象。在 Java 中，可以使用 WeakReference 类来创建
弱引用。
4. 虚引用（Phantom Reference） ：虚引用是最弱的引用类型，几乎没有直接的访问价值。虚引用
的主要作用是跟踪对象被垃圾回收器回收的状态。在 Java 中，可以使用 PhantomReference 类来
创建虚引用。
```
这些引用类型的主要区别在于垃圾回收器对它们的处理方式不同。强引用在内存不足时也不会被回收，
而软引用、弱引用和虚引用在内存不足时可能会被回收。

###### 25 、讲一讲垃圾回收算法

垃圾回收算法是自动内存管理的核心部分，它负责在运行时自动回收不再使用的对象，释放它们所占用
的内存空间。垃圾回收算法主要包括以下几种：

```
1. 引用计数算法（Reference Counting） ：该算法通过为每个对象维护一个引用计数器，记录对象
被引用的次数。当引用计数器为 0 时，说明该对象不再被引用，可以被回收。然而，引用计数算法
无法解决循环引用的问题，即两个或多个对象相互引用，但没有被其他对象引用。因此，在 Java 中
并未采用引用计数算法作为主要的垃圾回收算法。
2. 标记-清除算法（Mark and Sweep） ：标记-清除算法是 Java 中最常用的垃圾回收算法之一。它分
为两个阶段：标记阶段和清除阶段。在标记阶段，垃圾回收器从根对象开始遍历所有可达对象，并
对它们进行标记。在清除阶段，垃圾回收器清除未被标记的对象，并回收它们占用的内存空间。标
记-清除算法可以有效地处理循环引用的情况，但会产生内存碎片。
3. 复制算法（Copying） ：复制算法将可用内存空间划分为两个区域，通常称为"From"空间
和"To"空间。在垃圾回收过程中，首先将所有存活的对象从"From"空间复制到"To"空间，然后清
除"From"空间中的所有对象。复制算法简单高效，不会产生内存碎片，但会浪费一部分内存空
间。
4. 标记-压缩算法（Mark and Compact） ：标记-压缩算法是一种综合了标记-清除算法和复制算法
的垃圾回收算法。它首先通过标记阶段标记所有存活的对象，然后将它们向一端移动，紧凑排列，
最后清除边界外的内存空间。标记-压缩算法既能够处理循环引用，又能够减少内存碎片。
```
垃圾回收器通常会根据不同的情况选择合适的垃圾回收算法。例如，新生代使用复制算法，老年代使用
标记-清除或标记-压缩算法。此外，Java 还提供了不同的垃圾回收器实现，如 Serial、Parallel、CMS、
G 1 等，每个垃圾回收器都有不同的特点和适用场景。

###### 26 、如何解决内存碎片的问题？

内存碎片是指在使用动态内存分配时，内存空间被分割成多个小块，而这些小块之间存在一些未被使用
的空隙。内存碎片的存在可能导致内存利用率降低，甚至造成内存分配失败。

为了解决内存碎片问题，可以采取以下几种方法：


```
1. 内存池 ：使用内存池技术可以避免频繁的内存分配和释放操作，从而减少内存碎片的产生。内存池
会在程序启动时预先分配一块连续的内存空间，并将其划分为多个固定大小的内存块。当需要内存
时，直接从内存池中获取一个可用的内存块，而不是每次都进行动态内存分配。这样可以减少碎片
的产生，提高内存利用率。
2. 内存整理 ：内存整理是指将散乱的内存块进行整理，使得空闲的内存块连续排列。可以通过内存拷
贝的方式将已分配的内存块移动到一起，从而消除碎片。这个过程需要暂停程序的执行，因此一般
在空闲时间进行。
3. 分配算法优化 ：内存分配算法也可以对内存碎片进行优化。常见的算法有首次适应、最佳适应和最
坏适应算法。首次适应算法选择第一个满足要求的空闲块进行分配，最佳适应算法选择最小的满足
要求的空闲块进行分配，最坏适应算法选择最大的满足要求的空闲块进行分配。不同的算法对内存
碎片的影响不同，可以根据实际情况选择合适的算法。
4. 压缩算法 ：压缩算法是一种将已分配的内存块进行压缩，使得空闲内存块连续排列的方法。通过将
内存块向一端移动，可以将空闲块合并在一起，从而减少碎片。这个过程需要暂停程序的执行，因
此一般在空闲时间进行。
```
以上是一些常见的解决内存碎片问题的方法，具体的选择可以根据实际情况和需求来确定。

###### 27 、说说 JVM 底层原理和排查命令

JVM（Java Virtual Machine）是 Java 虚拟机的缩写，是 Java 程序运行的基础平台。它是一个在物理机器
上模拟运行 Java 字节码的虚拟计算机，负责解释和执行 Java 程序。

JVM 底层原理：

```
1. 类加载 ：JVM 将 Java 源代码编译成字节码文件，然后通过类加载器将字节码文件加载到内存中。类
加载器负责查找、加载和验证类文件。
2. 内存管理 ：JVM 使用内存管理器来管理内存，包括堆、栈和方法区。堆用于存储对象实例，栈用于
存储局部变量和方法调用，方法区用于存储类信息和常量池。
3. 垃圾回收 ：JVM 通过垃圾回收机制自动管理内存。它会周期性地检查不再被引用的对象，并回收它
们所占用的内存空间。
4. 即时编译 ：JVM 使用即时编译器将字节码转换成本地机器码，以提高程序的执行效率。
5. 异常处理 ：JVM 提供了异常处理机制，可以捕获和处理程序中的异常。
```
JVM 排查命令：

```
1. jps：用于列出当前运行的 Java 进程，显示进程 ID 和类名。
2. jstat：用于监控 JVM 内存、垃圾回收和类加载等信息。
3. jmap：用于生成堆转储快照，查看堆内存使用情况。
4. jstack：用于生成线程转储快照，查看线程状态和调用栈信息。
5. jinfo：用于查看和修改 JVM 的配置参数。
6. jconsole：图形化工具，用于监视和管理 JVM。
7. jcmd：用于向正在运行的 Java 进程发送诊断命令。
```
这些命令可以帮助开发人员监控和调试 Java 应用程序，定位问题和优化性能。使用这些命令需要在命令
行中输入相应的命令和参数，具体使用方法可以参考各个命令的文档或使用帮助命令（例如：jps -
help）。

```
40 岁老架构师尼恩提示 ：JVM 既是面试的绝对重点，也是面试的绝对难点，
```

```
建议大家有一个深入和详细的掌握，具体的内容请参见《尼恩 Java 面试宝典-专题 01 ：JVM 面试
题》PDF，该专题对 JVM 有一个系统化、体系化、全面化的介绍。
```
```
如果要把 JVM 调优实战写入简历，可以找尼恩指导。
```
###### 28 、说说 ZK 一致性原理

ZooKeeper 是一个分布式协调服务，它提供了高可用性、一致性和可靠性的数据存储和访问机制。
ZooKeeper 的一致性原理主要基于 ZAB（ZooKeeper Atomic Broadcast）协议来实现。下面是
ZooKeeper 一致性原理的详细叙述：

```
1. 原子广播（Atomic Broadcast） ：ZooKeeper 使用原子广播协议来保证数据的一致性。该协议确
保了消息在 ZooKeeper 服务器集群中的顺序传递和一次性提交。ZAB 协议分为两个阶段：广播和提
交。
2. 领导者选举（Leader Election） ：ZooKeeper 集群中的服务器通过选举机制来选择一个领导者
（Leader）。领导者负责处理客户端的读写请求，并将结果广播给其他服务器。选举过程中，服
务器通过互相发送消息进行通信，最终选出一个具有最高编号的服务器作为领导者。
3. 写操作的一致性 ：当客户端发送写请求给领导者时，领导者将请求转发给其他服务器，并等待大多
数服务器的确认。一旦大多数服务器确认接收到写请求并成功写入数据，领导者会将写操作结果返
回给客户端。这样可以保证写操作的一致性。
4. 读操作的一致性 ：当客户端发送读请求给领导者时，领导者将请求转发给其他服务器，并等待大多
数服务器的响应。一旦大多数服务器返回相同的结果，领导者将结果返回给客户端。这样可以保证
读操作的一致性。
5. 数据同步 ：ZooKeeper 使用了多数派（Majority）的原则来保证数据的一致性。当一个服务器接收
到写请求后，它会将数据变更写入本地存储，并将变更广播给其他服务器。其他服务器接收到变更
后，会将其应用到本地存储。只有当大多数服务器都完成了数据的变更，才会认为写操作成功。
```
总之，ZooKeeper 通过领导者选举、原子广播协议和多数派原则来保证数据的一致性。这种机制确保了
在 ZooKeeper 集群中的所有服务器上的数据是一致的，并且可以提供高可用性和可靠性的分布式协调服
务。

```
40 岁老架构师尼恩提示 ：ZooKeeper 既是面试的绝对重点，也是面试的绝对难点，
```
```
建议大家有一个深入和详细的掌握，具体的内容请参见《Java 高并发核心编程卷 1 加强版：NIO、
Netty、Redis、ZooKeeper》PDF，该专题对 ZooKeeper 有一个系统化、体系化、全面化的介
绍。
```
###### 29 、说说 Redis 数据结构、持久化、哨兵、cluster 数据分片规则

Redis 是一种内存数据库，它支持多种数据结构和持久化方式，并提供了哨兵和集群功能。下面是对
Redis 数据结构、持久化、哨兵和集群的详细叙述：

**一、数据结构：**

```
字符串（String） ：最基本的数据结构，可以存储字符串、整数和浮点数。
列表（List） ：有序的字符串列表，可以在头部或尾部添加、删除元素。
集合（Set） ：无序的唯一字符串集合，支持集合运算如交集、并集、差集。
哈希（Hash） ：键值对的无序散列表，适合存储对象。
```

```
有序集合（Sorted Set） ：有序的字符串集合，每个元素关联一个分数，可以按照分数排序。
```
**二、持久化：**

```
RDB（Redis Database）持久化 ：将内存中的数据以二进制格式保存到磁盘上，可以通过配置定
期保存快照或手动执行 SAVE 和 BGSAVE 命令。
AOF（Append-Only File）持久化 ：以追加的方式将写操作日志保存到磁盘上，可以通过配置定
期刷写或手动执行 BGREWRITEAOF 命令。
```
**三、哨兵（Sentinel）：**

```
哨兵是一个独立的进程，用于监控 Redis 主从节点的状态。
当主节点出现故障时，哨兵可以自动将一个从节点升级为主节点，保证高可用性。
哨兵还负责监控主从节点的健康状态，并在需要时进行故障转移和故障恢复。
```
**四、集群（Cluster）：**

```
Redis 集群是一个分布式的解决方案，可以将数据分散存储在多个节点上，提供高可用性和扩展
性。
集群使用哈希槽（Hash Slot）来分片数据，每个节点负责处理一部分哈希槽的数据。
集群中的节点通过 Gossip 协议进行通信，实现节点之间的故障检测和信息传递。
客户端可以通过集群代理（Cluster Proxy）或者 Redis 客户端库来访问集群，集群代理会将请求转
发给正确的节点。
```
总之，Redis 提供了多种数据结构和持久化方式，可以根据不同的需求选择适合的存储方式。哨兵和集
群功能可以提供高可用性和扩展性，使 Redis 在分布式环境中更加稳定和可靠。

```
40 岁老架构师尼恩提示 ：Redis 既是面试的绝对重点，也是面试的绝对难点，
```
```
建议大家有一个深入和详细的掌握，具体的内容请参见《尼恩 Java 面试宝典-专题 14 ：Redis 面试
题》PDF，该专题对 Redis 有一个系统化、体系化、全面化的介绍。
如果要把 Redis 高并发实战写入简历，可以找尼恩指导。
```
###### 30 、Kafka 一致性原理，消费时的消息丢失和重复如何解决？

Kafka 是一种分布式流处理平台，其设计目标之一是提供高度可靠的消息传递。Kafka 的一致性原理主要
基于分布式复制和日志提交机制。

Kafka 通过将消息分为多个分区并在多个 Broker 上进行分布式复制来实现高可靠性。每个分区都有一个
主 Broker 和若干个副本 Broker，主 Broker 负责接收和写入消息，而副本 Broker 则负责复制主 Broker 上
的消息。当主 Broker 发生故障时，副本 Broker 可以接替成为新的主 Broker，确保消息的持久性和可用
性。

在 Kafka 中，消费者可以通过消费者组的方式进行消息的消费。每个消费者组内的消费者可以并行地消
费不同的分区，这样可以提高消费的吞吐量。Kafka 使用偏移量（offset）来跟踪消费者在每个分区上消
费的位置。消费者可以定期提交偏移量，以确保消费进度的可靠性。

关于消息丢失和重复的解决方案，Kafka 提供了以下机制：

```
1. 持久化存储 ：Kafka 使用持久化的日志存储消息，确保消息的可靠性。即使发生故障，Kafka 也可
以从日志中恢复消息。
```

```
2. 冗余副本 ：Kafka 将每个分区的消息复制到多个 Broker 上的副本中，确保即使某个 Broker 发生故
障，仍然可以从其他副本中获取消息。
3. 偏移量提交 ：消费者定期提交偏移量，以确保消费进度的可靠性。如果消费者发生故障，它可以从
上一次提交的偏移量处继续消费，避免消息的重复消费。
4. Exactly Once 语义 ：Kafka 提供了 Exactly Once 语义的支持，确保消息在生产者和消费者之间的精
确一次交付。这是通过事务机制和幂等性保证实现的。
```
通过这些机制，Kafka 能够提供高度可靠的消息传递，并有效地解决消息丢失和重复的问题。

###### 31 、说说微服务优缺点

微服务架构是一种将应用程序拆分为一组小型、独立部署的服务的软件开发方法。它具有以下优点和缺
点：

**优点：**

```
1. 松耦合 ：微服务架构将应用程序拆分为多个小型服务，每个服务都是独立的，可以独立开发、部署
和扩展。这种松耦合的设计使得团队可以更加独立地开发和部署不同的服务，提高了开发效率和灵
活性。
2. 可扩展性 ：由于微服务架构的服务是独立的，可以根据需求独立地扩展每个服务。这种可扩展性使
得应对高并发和大规模流量变得更加容易。
3. 技术多样性 ：微服务架构允许每个服务使用不同的技术栈和编程语言，因为每个服务都是独立的。
这使得团队可以选择最适合每个服务需求的技术，提高了开发灵活性和创新性。
4. 高可用性 ：微服务架构中的每个服务都可以进行独立部署和水平扩展，使得系统具有更高的可用
性。即使一个服务发生故障，其他服务仍然可以正常工作。
```
**缺点：**

```
1. 系统复杂性 ：微服务架构将应用程序拆分为多个服务，导致系统的复杂性增加。需要管理和协调多
个服务之间的通信、数据一致性和服务发现等问题。
2. 分布式系统的挑战 ：微服务架构中的每个服务都是独立的，它们之间通过网络进行通信。这带来了
网络延迟、分布式事务和数据一致性等分布式系统的挑战。
3. 运维复杂性 ：由于微服务架构中的服务数量增加，运维变得更加复杂。需要管理多个服务的部署、
监控、日志和故障排查等任务。
4. 团队协作成本 ：微服务架构要求团队具备分布式系统和服务治理的知识。团队需要协调和合作，确
保每个服务的开发和部署都能够顺利进行。
```
综上所述，微服务架构具有灵活性、可扩展性和高可用性等优点，但也需要应对复杂性、分布式系统挑
战和运维复杂性等缺点。在选择微服务架构时，需要权衡这些优缺点，并根据具体情况进行决策。

###### 32 、说说 synchronizedlock 的底层实现

synchronized 和 Lock 都是 Java 中用于实现线程同步的机制，它们的底层实现有所不同。

**一、synchronized 的底层实现：**

```
Java 中的每个对象都有一个监视器锁（也称为内置锁或对象锁），可以通过 synchronized 关键字
来获取和释放这个锁。
当一个线程执行到 synchronized 代码块时，它会尝试获取对象的监视器锁。
```

```
如果该锁没有被其他线程占用，那么该线程会获取到锁，并继续执行 synchronized 代码块中的内
容。
如果该锁已经被其他线程占用，那么该线程会被阻塞，直到获取到锁为止。
当线程执行完 synchronized 代码块或者发生异常时，会释放该锁。
```
**二、Lock 的底层实现：**

```
Lock 是 Java. util. concurrent 包中提供的一个接口，它定义了锁的基本操作。
Lock 接口的常用实现类是 ReentrantLock，它使用了一种称为
AQS（AbstractQueuedSynchronizer）的同步器来实现锁的功能。
AQS 是一个用于构建锁和同步器的框架，它提供了一个队列来管理等待锁的线程，并且使用
CAS（Compare and Swap）操作来实现线程的安全切换。
当一个线程调用 Lock 的 lock () 方法时，它会尝试获取锁。如果锁已经被其他线程占用，那么该线程
会被阻塞，直到获取到锁为止。
与 synchronized 不同，Lock 提供了更灵活的锁获取和释放方式，例如可以设置获取锁的超时时
间，可以在不同的代码块中分别获取和释放锁等。
```
总的来说，synchronized 和 Lock 都是用于实现线程同步的机制，它们的底层实现都依赖于底层的锁机
制。synchronized 使用的是对象的监视器锁，而 Lock 使用的是 AQS 同步器。Lock 相比 synchronized 提
供了更多的灵活性和功能，但使用起来也更加复杂。在实际开发中，选择使用哪种机制取决于具体的需
求和场景。

###### 33 、说说 hashmap 的底层实现

HashMap 是 Java 中常用的数据结构，它是基于哈希表（Hash Table）实现的。下面是 HashMap 的底层
实现的详细描述：

**一、数据结构：**

```
HashMap 是由数组和链表（或红黑树）组成的。
数组是 HashMap 的主体，用于存储元素。
链表（或红黑树）解决哈希冲突的问题，当多个元素映射到同一个数组位置时，它们会以链表（或
红黑树）的形式存储在这个位置。
```
**二、哈希算法：**

```
当向 HashMap 中插入一个元素时，会根据元素的哈希码（通过 hashCode () 方法计算得到）来确定
元素在数组中的位置。
HashMap 使用哈希算法将元素的哈希码映射到数组的索引位置。
哈希算法的目标是使得元素在数组中分布均匀，减少哈希冲突的概率。
```
**三、解决哈希冲突：**

```
当多个元素映射到同一个数组位置时，会以链表（或红黑树）的形式存储在这个位置。
在 JDK 8 及之前，使用的是链表解决哈希冲突的问题。
在 JDK 8 之后，当链表长度超过一定阈值（默认为 8 ）时，链表会自动转换为红黑树，以提高查找
效率。
```
**四、扩容：**

```
当 HashMap 中元素的数量超过数组容量的 75%时，会触发扩容操作。
扩容操作会创建一个新的数组，并将原数组中的元素重新分配到新数组中。
扩容操作会导致原数组中的元素重新计算哈希码和位置，以保证元素在新数组中的分布均匀。
```

总的来说，HashMap 的底层实现是通过数组和链表（或红黑树）的组合来实现的。它使用哈希算法将
元素的哈希码映射到数组的索引位置，并使用链表（或红黑树）解决哈希冲突的问题。在插入、查找和
删除元素时，HashMap 会根据元素的哈希码计算出数组位置，并在该位置上进行操作。当元素数量超
过一定阈值时，HashMap 会自动扩容，以保证元素在数组中的分布均匀。这样可以提高 HashMap 的插
入、查找和删除操作的效率。

###### 34 、说说 Java 的序列化底层实现

Java 的序列化是一种将对象转换为字节流的过程，使得对象可以在网络上传输或者持久化到磁盘中。
Java 提供了两种序列化方式：默认序列化和自定义序列化。

默认序列化是指当一个类实现了 java. io. Serializable 接口时，Java 会自动进行序列化和反序列化操
作。在默认序列化过程中，Java 会将对象的状态以字节流的形式写入到输出流中，而反序列化则是将字
节流重新转换为对象的过程。

Java 的默认序列化底层实现主要涉及以下几个类和接口：

```
1. java. io. ObjectOutputStream：该类是对象输出流，用于将对象序列化为字节流。它通过调用
对象的 writeObject () 方法将对象的状态写入输出流中。
2. java. io. ObjectInputStream：该类是对象输入流，用于将字节流反序列化为对象。它通过调
用对象的 readObject () 方法将字节流转换为对象的状态。
3. java. io. Serializable 接口：该接口是一个标记接口，用于标识一个类可以进行序列化。实现
了该接口的类必须提供一个无参的构造方法，并且所有非瞬态（transient）的字段都会被序列
化。
```
在序列化过程中，Java 会对对象的每个字段进行递归处理。对于基本类型和字符串类型的字段，Java 会
直接将其写入字节流中。对于引用类型的字段，Java 会将其引用的对象进行递归序列化。

自定义序列化是指通过实现 java. io. Externalizable 接口来自定义对象的序列化和反序列化过程。
与默认序列化不同，自定义序列化需要手动实现 writeExternal () 和 readExternal () 方法来控制对
象的序列化和反序列化过程。

总的来说，Java 的序列化底层实现主要依赖于对象输出流和对象输入流，通过将对象的状态转换为字节
流进行序列化，以及将字节流转换为对象的状态进行反序列化。

###### 35 、说说 MySQL 的底层实现

MySQL 是一种关系型数据库管理系统，其底层实现涉及多个组件和技术。

```
1. 存储引擎 ：MySQL 支持多个存储引擎，如 InnoDB、MyISAM、Memory 等。存储引擎负责数据的
存储和检索。其中，InnoDB 是 MySQL 的默认存储引擎，它支持事务、行级锁和崩溃恢复等特性，
适用于高并发和高可靠性的场景。
2. 文件系统 ：MySQL 使用文件系统来管理数据文件。每个数据库对应一个文件夹，每个表对应一个
或多个文件。数据文件包括表结构、索引、数据和日志等。
3. 查询优化器 ：MySQL 的查询优化器负责解析 SQL 语句，并生成最优的查询计划。它会根据表的统
计信息和索引选择最佳的执行路径，以提高查询性能。
4. 查询执行引擎 ：MySQL 的查询执行引擎负责执行查询计划，并返回结果。不同的存储引擎有不同
的查询执行引擎。例如，InnoDB 使用 B+树索引进行数据检索，MyISAM 使用哈希索引和全文索
引。
5. 锁和并发控制 ：MySQL 使用锁和并发控制机制来保证数据的一致性和并发访问的正确性。InnoDB
使用行级锁来实现高并发的读写操作，并提供了多版本并发控制（MVCC）来解决读写冲突。
```

```
6. 日志系统 ：MySQL 的日志系统包括事务日志（redo log）和二进制日志（binlog）。事务日志用于
崩溃恢复和事务的持久化，二进制日志用于主从复制和数据恢复。
7. 缓存管理 ：MySQL 使用缓存来提高查询性能。其中，查询缓存用于缓存查询结果，提高相同查询
的响应速度。但在高并发环境下，查询缓存可能导致性能下降，因此在最新的 MySQL 版本中已经
被废弃。
```
总的来说，MySQL 的底层实现包括存储引擎、文件系统、查询优化器、查询执行引擎、锁和并发控制、
日志系统以及缓存管理等组件和技术。这些组件和技术相互配合，使得 MySQL 能够提供高性能、可靠性
和可扩展性的数据库服务。

尼恩提示，如果要彻底掌握 mysql 底层实现，可以跟着尼恩架构团队的视频《从 0 开始，一步一步手写
mysql》，手写一个自己的 mysql，做到对 mysql 的深入了解。

###### 36 、说说 Spring IOC, AOP, MVC 的底层实现大致逻辑

Spring 框架是一个开源的 Java 企业级应用程序开发框架，它提供了一种轻量级的、非侵入式的解决方
案，用于构建企业级应用程序。Spring 框架的核心是 Spring IOC（Inversion of Control，控制反转）容
器、Spring AOP（Aspect-Oriented Programming，面向切面编程）和 Spring MVC（Model-View-
Controller，模型-视图-控制器）。

**一、Spring IOC 的底层实现逻辑：**

```
Spring IOC 容器负责管理和组织应用程序中的对象（也称为 bean）的创建和生命周期。它通过控
制反转的方式，将对象的创建和依赖关系的管理交给了容器来完成。
Spring IOC 的底层实现逻辑包括：定义 bean 的配置元数据（通常使用 XML 或注解方式）、解析配
置元数据、创建 bean 实例、处理 bean 之间的依赖关系、管理 bean 的生命周期等。
在应用程序启动时，Spring IOC 容器会读取配置文件或注解中定义的 bean 信息，并根据配置信息
创建相应的 bean 实例，并将其存储在容器中。当其他组件需要使用这些 bean 时，容器会通过依赖
注入的方式将相关的 bean 注入到需要的地方。
```
**二、Spring AOP 的底层实现逻辑：**

```
Spring AOP 是一种基于面向切面编程的技术，它通过将横切关注点（如日志、事务、安全性等）
从业务逻辑中分离出来，实现了代码的模块化和复用。
Spring AOP 的底层实现逻辑包括：定义切点（指定在哪些方法上应用切面逻辑）、定义切面（包
含切面逻辑的代码）、将切面织入到目标对象中等。
在运行时，Spring AOP 通过动态代理技术，将切面逻辑织入到目标对象的方法调用中。当调用目
标对象的方法时，切面逻辑会在方法的前后执行，实现横切关注点的功能。
```
**三、Spring MVC 的底层实现逻辑：**

```
Spring MVC 是基于 MVC 设计模式的 Web 应用程序框架，它通过将应用程序的不同层（模型、视
图、控制器）进行分离，实现了业务逻辑和界面展示的解耦。
Spring MVC 的底层实现逻辑包括：定义请求映射规则、处理请求和响应、调用业务逻辑处理器、
渲染视图等。
在应用程序启动时，Spring MVC 容器会初始化并加载配置信息，包括请求映射规则、视图解析器
等。当接收到客户端的请求时，容器会根据请求映射规则找到对应的处理器，并调用相应的方法进
行请求处理。处理器将处理结果返回给容器，容器再根据视图解析器将结果渲染成最终的视图，最
后返回给客户端。
```
总结来说，Spring 框架的底层实现逻辑包括配置元数据的解析、对象的创建和管理、依赖注入、动态代
理等技术的应用。通过这些技术，Spring 实现了控制反转、面向切面编程和基于 MVC 的 Web 应用程序开
发。这些底层实现逻辑使得开发人员可以更加专注于业务逻辑的实现，提高了代码的可维护性和可扩展
性。


###### 37 、大致说下你熟悉的框架中用到的设计模式

在 Java 开发中，常用的框架中使用了许多设计模式。下面是一些常见的 Java 框架和它们所使用的设计模
式的示例：

**一、Spring 框架：**

```
依赖注入（Dependency Injection） ：Spring 框架使用了依赖注入设计模式，通过注入对象的方
式来实现解耦和灵活性。
单例模式（Singleton） ：Spring 框架中的 Bean 默认是单例的，通过单例模式确保在整个应用中
只有一个实例。
```
**二、Apache Kafka：**

```
发布-订阅模式（Publish-Subscribe） ：Kafka 使用发布-订阅模式来实现消息的传递和处理，生
产者将消息发布到主题（Topic）上，消费者订阅主题并接收消息。
适配器模式（Adapter） ：Kafka 提供了各种适配器，用于与不同的数据源进行交互，如 Kafka
Connect 用于与外部系统进行数据交换。
```
**三、MyBatis 框架：**

```
数据访问对象模式（Data Access Object，DAO） ：MyBatis 框架使用了 DAO 设计模式，通过封
装数据库操作，提供了简化的数据访问接口。
```
**四、Spring Boot 框架：**

```
建造者模式（Builder） ：Spring Boot 使用建造者模式来构建应用程序的配置和环境，通过链式
调用的方式创建和配置对象。
外观模式（Facade） ：Spring Boot 框架提供了简化的配置和自动化的功能，隐藏了底层复杂性，
使开发人员可以更方便地使用和管理应用程序。
```
这只是一些常见的示例，实际上，Java 框架中使用的设计模式还有很多，不同的框架可能会使用不同的
设计模式来解决特定的问题。设计模式的使用可以提高代码的可维护性、灵活性和可扩展性，使开发过
程更加高效和规范化。

###### 38 、说说项目中用到的设计模式

在常见的 Java 项目中，我们经常会使用以下设计模式：

```
1. 单例模式（Singleton Pattern） ：用于确保一个类只有一个实例，并提供全局访问点。常见的应
用场景包括数据库连接池、线程池等。
2. 工厂模式（Factory Pattern） ：用于创建对象的接口，但将具体的实例化逻辑延迟到子类中。常
见的应用场景包括日志库、数据库驱动等。
3. 观察者模式（Observer Pattern） ：定义了对象之间的一对多依赖关系，使得当一个对象状态改
变时，所有依赖它的对象都会收到通知并自动更新。常见的应用场景包括事件监听器、消息队列
等。
4. 适配器模式（Adapter Pattern） ：将一个类的接口转换成客户端所期望的另一个接口，使得原
本由于接口不兼容而不能一起工作的类可以一起工作。常见的应用场景包括将不同版本的 API 适配
到统一的接口上。
5. 策略模式（Strategy Pattern） ：定义了一系列的算法，并将每个算法封装起来，使它们可以相
互替换。常见的应用场景包括排序算法、支付方式等。
```

```
6. 模板方法模式（Template Method Pattern） ：定义了一个算法的骨架，将一些步骤的实现延迟
到子类中。常见的应用场景包括框架中的生命周期方法、算法流程等。
7. 装饰器模式（Decorator Pattern） ：动态地给一个对象添加额外的职责，同时又不改变其接
口。常见的应用场景包括 IO 流的包装类、日志记录等。
8. 建造者模式（Builder Pattern） ：将一个复杂对象的构建过程与其表示分离，使得同样的构建过
程可以创建不同的表示。常见的应用场景包括构建复杂的数据对象、配置对象等。
9. 迭代器模式（Iterator Pattern） ：提供一种方法顺序访问一个聚合对象中的各个元素，而又不暴
露其内部的表示。常见的应用场景包括集合类的遍历、搜索等。
10. 代理模式（Proxy Pattern） ：为其他对象提供一种代理以控制对这个对象的访问。常见的应用场
景包括远程代理、虚拟代理等。
```
这些设计模式都是为了解决特定的问题而提出的，并在实际项目中得到广泛应用。不同的设计模式可以
根据具体的需求选择使用，以提高代码的可读性、可维护性和可扩展性。

###### 39 、说说 Netty 的主要组件

Netty 是一个高性能的网络编程框架，它提供了一组强大的、易于使用的组件和工具，用于构建可扩展
的、高性能的网络应用程序。Netty 的主要组件包括：

```
1. Channel（通道） ：Channel 是 Netty 的核心抽象，它代表了一个网络连接，可以用于读取和写入
数据。Channel 提供了异步的、事件驱动的 I/O 操作。
2. EventLoop（事件循环） ：EventLoop 是 Netty 的事件处理机制，它负责处理所有的 I/O 事件和执
行任务。每个 Channel 都绑定了一个 EventLoop，用于处理该 Channel 上的所有事件。
3. ChannelHandler（通道处理器） ：ChannelHandler 是 Netty 的事件处理器，它负责处理
Channel 上的各种事件，例如连接建立、数据读写等。开发人员可以通过实现自定义的
ChannelHandler 来处理特定的业务逻辑。
4. ChannelPipeline（通道管道） ：ChannelPipeline 是 ChannelHandler 的容器，它负责管理和调
度 ChannelHandler 的执行顺序。当一个事件被触发时，它会从 ChannelPipeline 的头部开始，依
次调用每个 ChannelHandler 的事件处理方法。
5. Codec（编解码器） ：Codec 是 Netty 的编解码器，它负责将数据在网络和应用程序之间进行转
换。Netty 提供了一系列的编解码器，包括基于长度的解码器、字符串编解码器、对象序列化编解
码器等。
6. Bootstrap（引导类） ：Bootstrap 是 Netty 的引导类，用于配置和启动 Netty 应用程序。它提供了
一组方法来设置各种参数，例如事件循环组、Channel 类型、ChannelHandler 等。
7. ChannelFuture（通道 Future） ：ChannelFuture 是 Netty 的异步操作的结果，它代表了一个尚
未完成的操作。通过 ChannelFuture，可以获取操作的结果、添加监听器等。
```
这些组件共同构成了 Netty 的核心架构，通过它们的协同工作，可以轻松地构建高性能、可扩展的网络
应用程序。

```
40 岁老架构师尼恩提示 ：Netty 既是面试的绝对重点，也是面试的绝对难点，
```
```
建议大家有一个深入和详细的掌握，具体的内容请参见《尼恩 Java 面试宝典-专题 25 ：Netty 面试
题》PDF，该专题对 Netty 有一个系统化、体系化、全面化的介绍。
```
```
如果要把 Netty 实战写入简历，可以找尼恩指导。
```
###### 40 、使用 dubbo 进行远程调用时消费端需要几个线程


使用 Dubbo 进行远程调用时，消费端需要使用多个线程来处理不同的任务。具体来说，消费端需要使用
以下几个线程：

```
1. 主线程 ：主线程负责接收消费端的请求，并将请求发送给提供端。主线程还负责接收提供端的响
应，并将响应返回给消费端的调用方。
2. IO 线程 ：IO 线程负责处理网络 IO 操作，包括发送请求和接收响应。这些线程通常使用 NIO（非阻
塞 IO）技术，可以高效地处理大量的并发请求。
3. 线程池 ：消费端还可以配置一个线程池，用于处理消费端的业务逻辑。当消费端收到提供端的响应
后，可以将响应交给线程池中的线程进行处理。这样可以避免阻塞主线程，提高整体的并发处理能
力。
```
需要注意的是，线程的数量可以根据具体的需求进行配置。通常情况下，可以根据消费端的负载和性能
要求来确定线程池的大小。较大的线程池可以处理更多的并发请求，但也会消耗更多的系统资源。因
此，需要根据实际情况进行权衡和调整。

总结起来，使用 Dubbo 进行远程调用时，消费端需要主线程、IO 线程和一个线程池来处理请求和响应，
并发处理能力可以根据实际需求进行配置

###### 41 、说说内存分配以及优化

内存分配是计算机系统中的重要环节，它涉及到如何为程序分配和管理内存资源。下面是关于内存分配
和优化的详细叙述：

**一、内存分配方式：**

```
栈（Stack） ：栈是用于存储局部变量和函数调用信息的内存区域。它的分配和释放是由编译器自
动完成的，具有较快的分配和释放速度，但容量较小。
堆（Heap） ：堆是用于存储动态分配的内存对象的区域。它的分配和释放由开发人员手动控制，
具有较大的容量，但分配和释放速度较慢。
静态存储区（Static Storage） ：静态存储区用于存储全局变量和静态变量，它在程序启动时分
配，直到程序结束才释放。
```
**二、内存分配优化：**

```
使用合适的数据结构 ：选择适合问题的数据结构可以减少内存的使用量。例如，使用数组代替链表
可以减少指针的开销。
避免内存碎片 ：内存碎片是指内存中存在一些零散的未被使用的空间。通过使用内存池或者内存分
配算法（如分配器）可以减少内存碎片的产生。
及时释放不再使用的内存 ：当不再需要某个对象时，及时释放其占用的内存，以便其他对象可以使
用这些内存。
使用对象池 ：对象池是一种将多个对象预先创建并存储在内存中的技术。通过重复使用这些对象，
可以减少内存分配和释放的开销。
压缩内存 ：一些压缩算法可以将内存中的数据进行压缩，从而减少内存的使用量。例如，使用哈夫
曼编码或字典压缩算法。
```
**三、内存分配的注意事项：**

```
避免内存泄漏 ：内存泄漏指的是程序在使用完内存后未正确释放，导致内存无法再被其他对象使
用。需要注意及时释放不再使用的内存，防止内存泄漏问题。
```

```
避免内存溢出 ：内存溢出指的是程序申请的内存超过了系统所能提供的内存资源。需要合理估计程
序的内存使用量，并做好内存管理和优化工作，以避免内存溢出问题。
```
总结起来，内存分配和优化是一个综合考虑性能和资源利用的过程。通过选择合适的数据结构、及时释
放内存、使用对象池等技术手段，可以提高程序的内存使用效率和性能。同时，需要注意避免内存泄漏
和内存溢出等问题，保证程序的稳定性和可靠性。

###### 42 、你怎么防止优惠券有人重复刷？

要防止优惠券被重复刷，可以考虑以下几种方法：

```
1. 限制使用次数 ：在优惠券的设计中，可以设置一个使用次数的限制。每次使用优惠券时，系统会检
查该优惠券的使用次数是否已达到限制，如果已达到则拒绝使用。
2. 绑定用户信息 ：将优惠券与用户进行绑定，确保每个用户只能使用一次。在用户使用优惠券时，系
统会验证该用户是否已经使用过该优惠券，如果已使用则拒绝再次使用。
3. 设计有效期 ：为优惠券设置一个有效期，确保只能在有效期内使用。在用户使用优惠券时，系统会
验证当前时间是否在优惠券的有效期范围内，如果不在则拒绝使用。
4. 使用唯一标识 ：为每个优惠券生成一个唯一的标识符，将其存储在数据库或缓存中。在用户使用优
惠券时，系统会检查该标识符是否已被使用过，如果已使用则拒绝再次使用。
5. 防止恶意刷券 ：监控系统日志，检测异常行为。例如，检测同一用户在短时间内频繁使用优惠券的
情况，或者检测同一 IP 地址下多个用户同时使用优惠券的情况。如果发现异常行为，可以采取相应
的措施，如暂时禁止该用户使用优惠券。
```
需要根据具体业务场景和系统架构来选择合适的防重复刷优惠券的方法，并进行合理的组合使用。

具体请参见尼恩的专题文章： 美团太狠：接口被恶刷 10 Wqps，怎么防？

###### 43 、有一个整型数组，数组元素不重复，数组元素先升序后

要实现一个整型数组，其中数组元素不重复且按升序排列，可以使用以下方法和原理：

```
1. 创建一个空的整型数组，用于存储最终结果。
2. 遍历给定的整型数组。
3. 对于每个元素，检查它是否已经存在于结果数组中。
4. 如果不存在，则将该元素插入到结果数组中的正确位置，以保持升序排列。
5. 返回结果数组作为最终结果。
```
以下是使用 Java 实现的示例代码：

```
import java. util. Arrays;
```
```
public class SortedArray {
public static int[] createSortedArray (int[] arr) {
int[] result = new int[arr. length];
int index = 0 ;
```
```
for (int i = 0 ; i < arr. length; i++) {
if (index == 0 || arr[i] > result[index - 1 ]) {
result[index++] = arr[i];
}
```

在上述代码中，我们使用 createSortedArray 方法来创建一个按升序排列的整型数组。我们使用
result 数组来存储最终结果，并使用 index 变量来跟踪结果数组的当前索引位置。我们遍历给定的数
组，如果当前元素大于结果数组中的最后一个元素，我们将其插入到结果数组中的正确位置，并递增
index。最后，我们使用 Arrays. copyOf 方法将结果数组截断为实际大小，并将其返回作为最终结
果。

在示例代码中，给定的数组为{1, 3, 2, 5, 4}，最终结果为{1, 2, 3, 4, 5}。

###### 44 、降序，找出最大值

要实现降序并找出最大值，可以使用以下步骤和方法：

```
1. 创建一个整数数组。
2. 使用循环将一组整数存储在数组中。
3. 使用排序算法（如冒泡排序、选择排序或快速排序）对数组进行降序排序。
4. 输出排序后的数组的第一个元素，即最大值。
```
以下是使用 Java 实现的示例代码：

```
}
```
```
return Arrays.copyOf (result, index);
}
```
```
public static void main (String[] args) {
int[] arr = { 1 , 3 , 2 , 5 , 4 };
int[] sortedArr = createSortedArray (arr);
System.out.println (Arrays.toString (sortedArr));
}
}
```
```
import java. util. Arrays;
```
```
public class DescendingOrder {
public static void main (String[] args) {
int[] numbers = { 5 , 2 , 9 , 1 , 7 }; // 示例整数数组
```
```
// 使用 Arrays.sort () 方法对数组进行降序排序
Arrays.sort (numbers);
for (int i = 0 ; i < numbers. length / 2 ; i++) {
int temp = numbers[i];
numbers[i] = numbers[numbers. length - 1 - i];
numbers[numbers. length - 1 - i] = temp;
}
```
```
// 输出排序后的数组
System.out.println ("降序排序后的数组：");
for (int number : numbers) {
System.out.print (number + " ");
}
```
```
// 输出最大值
System.out.println ("\n 最大值：" + numbers[ 0 ]);
```

该示例代码使用了 Arrays 类的 sort () 方法对数组进行降序排序。然后，通过遍历数组找到排序后的第一
个元素，即最大值。最后，输出排序后的数组和最大值。

请注意，这只是一种实现方法，还有其他排序算法和技术可以实现降序排序和找出最大值。

## 太猛了，靠“吹牛”过顺丰一面，月薪 30 k

#### 说在前面

在 40 岁老架构师尼恩的（50+） **读者社群** 中，经常有小伙伴，需要面试美团、京东、阿里、百度、头条
等大厂。

下面是一个 5 年小伙伴成功拿到通过了顺丰面试，拿到 offer，月薪 30 K。

现在把面试真题和参考答案收入咱们的宝典，大家看看， **收个优质 Offer 需要学点啥？**

当然对于中高级开发来说，这些面试题，也有参考意义。

小伙伴说， **光代码写得漂亮不够，面试，还得靠吹。**

这里把题目以及 **小伙伴的吹牛逼的方式方法** ，经过整理和梳理之后，收入咱们的《尼恩 Java 面试宝典》
V 93 版本，供后面的小伙伴参考，提升大家的 3 高架构、设计、开发、吹牛水平。

```
《尼恩架构笔记》《尼恩高并发三部曲》《尼恩 Java 面试宝典》的 PDF，请到公众号【技术自由
圈】获取
```
```
}
}
```

#### 1 、说说你觉得最有挑战的项目，有哪些难点，你是怎么解

#### 决的

小伙伴按照尼恩指导的，从尼恩 3 高架构+海量数据的维度，总计 4 个维度去 "吹牛"，说面试官被吹到
"口水直流，不能自己":

```
高并发访问难点
高可用性和容错性难题
应用内部的高性能难题
大规模数据的处理和存储难题：
```
小伙伴的回答：

我参与了一个具有挑战性的项目，该项目涉及高并发、高并发访问，以及应用内部的高性能难题，还有
一些大规模数据处理。

以下是该项目的难点以及我解决这些难点：

###### 1.1、高并发访问难点

项目需要支持大量用户的并发访问，并保证系统的稳定性和性能。为了解决这个问题，我采用了微服务
架构，将系统拆分为多个独立的服务，每个服务负责处理特定的功能。这样可以提高系统的可伸缩性和
并发处理能力。

同时，我使用 Redis 作为缓存和消息队列，通过缓存和异步消息处理来减轻数据库的负载和提高系统的
响应速度。

为了应对高并发和大量请求，我们需要设计一个可伸缩性高、可扩展性好的系统架构。通过采用分布式
架构、负载均衡和容器化技术，我们成功地解决了这个问题。

为了保证系统的稳定运行，我们需要实时监控系统的各项指标。我们采用了 Prometheus + Grafana 进
行系统监控和运维，及时发现并解决系统问题。我们使用了 ELK (Elasticsearch、Logstash、Kibana) 堆
栈来进行日志收集、分析和可视化。

###### 1.2、高可用性和容错性难题

项目需要具备高可用性和容错性，以应对系统故障和节点失效的情况。

为了解决这个问题，我使用了 Redis 的主从复制和哨兵机制。通过将 Redis 配置为主从模式，实现了数据
的备份和故障转移。哨兵机制可以监控 Redis 节点的状态，并在主节点故障时自动进行故障转移，确保
系统的可用性和稳定性。

###### 1.3、应用内部的高性能难题

在处理大量请求时，我们需要将一些耗时的任务进行异步处理，以避免阻塞主线程，提升应用的性能。

并且充分应用池化架构，包括线程池、对象池、内存池，实现应用内部的高性能。

为了实现高效的异步处理，我们采用了 Redis 的定时任务功能，结合 Spring 框架的定时任务调度器，
实现了任务的精确调度。

###### 1.4、大规模数据的处理和存储难题

项目需要处理大量的数据，并对其进行实时计算和存储。难点在于如何高效地处理和存储这些数据。为
了解决这个问题，我采用了 flink 框架进行数据处理和分析，利用其分布式计算和内存管理功能，实现了
高效的数据处理。


同时，我使用 Redis 作为缓存层，将计算结果缓存起来，减少对后端存储系统的访问压力。

引入了 redis 后，由于高并发访问，数据一致性和并发控制成为了一个挑战。

为了解决这个问题，我使用了 Redis 的事务和分布式锁来保证数据的一致性和并发控制。在关键操作
中，我使用 Redis 的事务功能将多个操作打包成一个原子操作，确保它们要么全部执行成功，要么全部
回滚。

同时，我使用 Redis 的分布式锁来实现对共享资源的并发控制，避免了数据竞争和冲突。

#### 2 、刚才你提到使用缓存，为什么要采用 Redis，当初是怎

#### 么样技术选型的

小伙伴说，他是参考《尼恩 Java 面试宝典》中 Redis 专题中的技术选型方案去吹的

#### 3 、如何保证缓存和数据库一致性

小伙伴说，他是参考《尼恩 Java 面试宝典》中 Redis 专题中的如何保证缓存和数据库一致性去吹的，面
试官非常满意

#### 4 、项目中为什么要使用到 ES，ES 有什么优势，什么是倒排

#### 索引

ES 的优势有很多，其中最重要的是它可以快速地对大量数据进行搜索和分析。ES 使用倒排索引技术来优
化搜索速度，虽然空间消耗比较大，但是搜索性能提高十分显著。

在项目中，我选择使用 Elasticsearch（简称 ES）作为搜索引擎，主要原因如下：

```
1. 高性能的全文搜索：Elasticsearch 是一个高性能的全文搜索引擎，可以快速地处理大量的文本数
据。在电商平台这样的高并发场景下，使用 Elasticsearch 可以显著提高搜索性能。
2. 数据可视化和分析：Elasticsearch 提供了丰富的数据可视化和分析工具，可以方便地进行数据分析
和可视化。这对于我们平台这样的数据驱动型业务非常重要。
3. 支持多种数据格式：Elasticsearch 支持多种数据格式，包括文本、JSON、XML 等。这使得我们可
以将各种数据类型存储在 Elasticsearch 中，方便进行数据分析和搜索。
4. 分布式部署：Elasticsearch 支持分布式部署，可以将数据和应用分布在多台服务器上，以提高系统
的可用性和容错性。这对于我们的平台这样的大规模系统非常重要。
```
Elasticsearch 的优势在于其高性能的全文搜索和数据可视化能力，以及其支持多种数据格式和分布式部
署的能力。

这些优势使得 Elasticsearch 成为项目中一个非常重要的组成部分。

```
1. 倒排索引：倒排索引是一种用于搜索引擎的技术，它将所有文档中包含的关键词和它们在文档中出
现的位置进行索引。在搜索时，搜索引擎会根据用户输入的关键词查找所有包含这些关键词的文
档，并将这些文档返回给用户。倒排索引的优势在于它可以快速地搜索包含关键词的文档，从而提
高搜索效率。
2. 索引：索引是一种用于存储和检索数据的结构。在搜索引擎中，索引用于存储所有文档中包含的关
键词和它们在文档中出现的位置。在搜索时，搜索引擎会根据用户输入的关键词查找所有包含这些
关键词的文档，并将这些文档返回给用户。索引的优势在于它可以快速地检索包含关键词的文档，
从而提高搜索效率。
```

总之，在项目中，我通过使用 Elasticsearch 作为搜索引擎，实现了高性能的全文搜索和数据可视化能
力，以及其支持多种数据格式和分布式部署的能力。同时，我还使用了倒排索引和索引等技术手段，提
高了搜索引擎的效率和性能。

#### 5 、说说你对垃圾回收的认识

小伙伴说，他是参考《尼恩 Java 面试宝典》JVM 专题，各种垃圾回收器的原理吹的

#### 6 、Redis 如何实现分布式锁，使用 redis 分布式锁需要注意

#### 什么

小伙伴说，他是参考《尼恩 Java 面试宝典》分布式锁专题吹的，包括红锁，看门狗，都吹上了，面试官
非常满意

#### 7 、Redis 集群用的是什么方式，怎么做动态扩容，原理是

#### 什么

Redis 集群使用的方式是主从复制，其中一个主节点负责写入数据，从节点负责备份数据。

当需要对 Redis 集群进行扩容时，可以通过添加新的从节点来实现。Redis 集群的动态扩容是指在集群
正在运行的过程中，添加或删除从节点，而不需要停机。

Redis Cluster 的具体实现细节是采用了 Hash 槽的概念，集群会预先分配 16384 个槽，并将这些槽分配
给具体的服务节点，通过对 Key 进行 CRC 16 (key)%16384 运算得到对应的槽是哪一个，从而将读写操作
转发到该槽所对应的服务节点。

当有新的节点加入或者移除的时候，再来迁移这些槽以及其对应的数据。在这种设计之下，我们就可以
很方便的进行动态扩容或缩容。

Redis 集群的扩容原理是通过主节点将数据迁移到新的从节点上。

随着业务发展，数据量的不断上升。

当已有的缓存系统无法满足我们的需求时，需要对已有服务器集群进行扩容。

新增集群的主从节点，主节点 7006 ，从节点 7007 。


```
步骤描述
```
1. 在已有集群中添
加新节点

```
添加新的 Redis 节点到已有的集群中
```
2. 将新节点加入集
群

```
将新的 Redis 节点加入到集群中，并进行握手和插槽分配
```
3. 迁移槽位

```
自动将一部分槽位从已有的节点迁移到新的节点上，主要可以通过 redis-
cli --cluster reshard 命令完成
```
Redis 集群的架构图可知，在整个集群新增节点的过程中涉及到一下几个步骤：建立主节点、建立从节
点、槽范围移动、槽分区移动。

具体来说，当需要添加一个新的从节点时，先将该节点配置好，然后通过主节点将其数据迁移到该节点
上。

迁移过程中，主节点会将部分槽和数据复制到新的从节点上，直到新节点上的数据与主节点上的数据一
致。

此时，新节点就可以加入到 Redis 集群中，开始提供读写服务。

Redis 集群的动态扩容过程中，大概需要进行以下步骤：

Redis 集群的动态扩容原理是通过主节点将数据迁移到新的从节点上，然后将新节点加入到集群中，从
而实现集群的扩容。

这种方式可以保证集群在运行过程中不停机，并且能够快速响应节点故障和负载增加的情况。

#### 8 、你知道分布式事务吗？有哪些方案，你们公司是采用哪

#### 种方案

小伙伴说，他是参考《尼恩 Java 面试宝典》分布式事务专题吹的，面试官非常满意


#### 9 、怎么做 SQL 优化

小伙伴一直关注尼恩的博文，从以下 7 个维度去 "吹牛"，说面试官被吹到 "口水直流，不能自己"

如何做 mysql 调优？绝命 7 招，让慢 SQL 调优 100 倍

#### 10 、怎么做限流，可以在什么层面上做限流，限流算法有

#### 哪些

小伙伴从以下 7 个维度去 "吹牛"，说面试官被吹到 "口水直流，不能自己"

```
首先，说说为什么要限流
其次，计数器限流
再次：漏桶限流
再次： 令牌桶限流
再次：Guava 的 RateLimiter 提供了令牌桶限流
再次：Nginx 漏桶限流
最后：分布式限流组件
```
###### 为什么要限流

限流是指在高并发的系统中，为了保护系统资源不被过度消耗，采取一定的措施来限制请求的速率。限
流可以在不同的层面上进行，例如网络层、应用层等。

简单来说：

限流在很多场景中用来限制并发和请求量，比如说秒杀抢购，保护自身系统和下游系统不被巨型流量冲
垮等。

以微博为例，例如某某明星公布了恋情, 访问从平时的 50 万增加到了 500 万，系统的规划能力，最多可以
支撑 **200 万访问** ,那么就要执行限流规则, 保证是一个可用的状态, 不至于 **服务器崩溃** ，所有请求不可用。

**限流的思想**

在保证可用的情况下尽可能多增加进入的人数, 其余的人在排队等待, 或者返回友好提示, 保证里面的进行
系统的用户可以正常使用，防止系统雪崩。

**日常生活中, 有哪些需要限流的地方?**

像我旁边有一个国家景区, 平时可能根本没什么人前往, 但是一到五一或者春节就人满为患, 这时候景区管
理人员就会实行一系列的政策来限制进入人流量,
为什么要限流呢?

假如景区能容纳一万人, 现在进去了三万人, 势必摩肩接踵, 整不好还会有事故发生, 这样的结果就是所有人
的体验都不好，如果发生了事故景区可能还要关闭, 导致对外不可用，这样的后果就是所有人都觉得体验
糟糕透了。


###### 限流的算法

限流算法很多, 常见的有三类, 分别是计数器算法、漏桶算法、令牌桶算法。

限流的手段通常有计数器、漏桶、令牌桶。注意限流和限速（所有请求都会处理）的差别，视
业务场景而定。

（ 1 ）计数器：

在一段时间间隔内（时间窗/时间区间），处理请求的最大数量固定，超过部分不做处理。

（ 2 ）漏桶：

漏桶大小固定，处理速度固定，但请求进入速度不固定（在突发情况请求过多时，会丢弃过多的请
求）。

（ 3 ）令牌桶：

令牌桶的大小固定，令牌的产生速度固定，但是消耗令牌（即请求）速度不固定（可以应对一些某些时
间请求过多的情况）；每个请求都会从令牌桶中取出令牌，如果没有令牌则丢弃该次请求。

###### 计数器限流

**计数器限流定义**

在一段时间间隔内（时间窗/时间区间），处理请求的最大数量固定，超过部分不做处理。

简单粗暴, 比如指定线程池大小，指定数据库连接池大小、nginx 连接数等, 这都属于计数器算法。

计数器算法是限流算法里最简单也是最容易实现的一种算法。

举个例子, 比如我们规定对于 A 接口，我们 1 分钟的访问次数不能超过 100 个。

那么我们可以这么做：

```
在一开始的时候，我们可以设置一个计数器 counter，每当一个请求过来的时候，counter 就加
1 ，如果 counter 的值大于 100 并且该请求与第一个请求的间隔时间还在 1 分钟之内，那么说明请求
数过多, 拒绝访问；
如果该请求与第一个请求的间隔时间大于 1 分钟，且 counter 的值还在限流范围内，那么就重置
counter, 就是这么简单粗暴。
```
**计算器限流的实现**

参考：参见尼恩的《Java 高并发核心编程卷 3 加强版》


**计数器限流的严重问题**

这个算法虽然简单，但是有一个十分致命的问题，那就是临界问题，我们看下图：

从上图中我们可以看到，假设有一个恶意用户，他在0:59时，瞬间发送了 100 个请求，并且1:00又瞬间
发送了 100 个请求，那么其实这个用户在 1 秒里面，瞬间发送了 200 个请求。

我们刚才规定的是 1 分钟最多 100 个请求（规划的吞吐量），也就是每秒钟最多 1.7 个请求，用户通过在
时间窗口的重置节点处突发请求，可以瞬间超过我们的速率限制。

用户有可能通过算法的这个漏洞，瞬间压垮我们的应用。

###### 漏桶限流

漏桶算法限流的基本原理为：水（对应请求）从进水口进入到漏桶里，漏桶以一定的速度出水（请求放
行），当水流入速度过大，桶内的总水量大于桶容量会直接溢出，请求被拒绝，如图所示。
大致的漏桶限流规则如下：
（ 1 ）进水口（对应客户端请求）以任意速率流入进入漏桶。
（ 2 ）漏桶的容量是固定的，出水（放行）速率也是固定的。
（ 3 ）漏桶容量是不变的，如果处理速度太慢，桶内水量会超出了桶的容量，则后面流入的水滴会溢
出，表示请求拒绝。

**漏桶算法原理**

漏桶算法思路很简单：

水（请求）先进入到漏桶里，漏桶以一定的速度出水，当水流入速度过大会超过桶可接纳的容量时直接
溢出。

可以看出漏桶算法能强行限制数据的传输速率。

可以看出漏桶算法能强行限制数据的传输速率，起到了缓冲与 **削峰** 的作用，如图所示。


漏桶算法其实很简单，可以粗略的认为就是注水漏水过程，往桶中以任意速率流入水，以一定速率流出
水，当水超过 **桶容量（capacity）** 则丢弃，因为桶容量是不变的，保证了整体的速率。

以一定速率流出水，


**削峰** ：有大量流量进入时, 会发生溢出, 从而限流保护服务可用

**缓冲** ：不至于请求直接打到到后端服务器, 缓冲压力

因为后端计算性能固定，所以放行的速度，或者说消费速度固定

**漏桶算法实现**

参考：参见尼恩的《Java 高并发核心编程卷 3 加强版》

**漏桶的问题**

漏桶的出水速度固定，也就是请求放行速度是固定的。

网上抄来抄去的说法：

```
漏桶不能有效应对突发流量，但是能起到平滑突发流量（整流）的作用。
```
实际上的问题：

```
漏桶出口的速度固定，不能灵活的应对后端能力提升。比如，通过动态扩容，后端流量从
1000 QPS 提升到 1 WQPS，漏桶没有办法。
```
```
说明：本文会以 pdf 格式持续更新，更多最新尼恩 3 高 pdf 笔记，请关注本公众号【技术自由圈】
领取
```
###### 令牌桶限流

令牌桶算法以一个设定的速率产生令牌并放入令牌桶，每次用户请求都得申请令牌，如果令牌不足，则
拒绝请求。
令牌桶算法中新请求到来时会从桶里拿走一个令牌，如果桶内没有令牌可拿，就拒绝服务。当然，令牌
的数量也是有上限的。令牌的数量与时间和发放速率强相关，时间流逝的时间越长，会不断往桶里加入
越多的令牌，如果令牌发放的速度比申请速度快，令牌桶会放满令牌，直到令牌占满整个令牌桶，如图
所示。

令牌桶限流大致的规则如下：

（ 1 ）进水口按照某个速度，向桶中放入令牌。

（ 2 ）令牌的容量是固定的，但是放行的速度不是固定的，只要桶中还有剩余令牌，一旦请求过来就能
申请成功，然后放行。

（ 3 ）如果令牌的发放速度，慢于请求到来速度，桶内就无牌可领，请求就会被拒绝。

总之，令牌的发送速率可以设置，从而可以对突发的出口流量进行有效的应对。

**令牌桶算法**

令牌桶与漏桶相似, 不同的是令牌桶桶中放了一些令牌, 服务请求到达后, 要获取令牌之后才会得到服务, 举
个例子, 我们平时去食堂吃饭, 都是在食堂内窗口前排队的, 这就好比是漏桶算法, 大量的人员聚集在食堂内
窗口外, 以一定的速度享受服务, 如果涌进来的人太多, 食堂装不下了, 可能就有一部分人站到食堂外了, 这就
没有享受到食堂的服务, 称之为溢出, 溢出可以继续请求, 也就是继续排队, 那么这样有什么问题呢?


如果这时候有特殊情况, 比如有些赶时间的志愿者啦、或者高三要高考啦, 这种情况就是突发情况, 如果也
用漏桶算法那也得慢慢排队, 这也就没有解决我们的需求, 对于很多应用场景来说，除了要求能够限制数
据的平均传输速率外，还要求允许某种程度的突发传输。这时候漏桶算法可能就不合适了，令牌桶算法
更为适合。如图所示，令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要
被处理，则需要先从桶里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。

桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶里获
取一个令牌，当桶里没有令牌可取时，则拒绝服务。

令牌桶算法的原理是系统会以一个恒定的速度往桶里放入令牌，而如果请求需要被处理，则需要先从桶
里获取一个令牌，当桶里没有令牌可取时，则拒绝服务。


令牌桶限流大致的规则如下：

```
（ 1 ）进水口按照某个速度，向桶中放入令牌。
```
```
（ 2 ）令牌的容量是固定的，但是放行的速度不是固定的，只要桶中还有剩余令牌，一旦请求过来
就能申请成功，然后放行。
```
```
（ 3 ）如果令牌的发放速度，慢于请求到来速度，桶内就无牌可领，请求就会被拒绝。
```
总之，令牌的发送速率可以设置，从而可以对突发的出口流量进行有效的应对。

令牌桶与漏桶相似，不同的是令牌桶桶中放了一些令牌，服务请求到达后，要获取令牌之后才会得到服
务。令牌使用的灵活性赋予了令牌桶使用场景的灵活性，除了要求能够限制数据的平均传输速率外，还
要求允许某种程度的突发传输。

**令牌桶算法实现**


参考：参见尼恩的《Java 高并发核心编程卷 3 加强版》

**令牌桶的好处**

令牌桶的好处之一就是可以方便地应对突发出口流量（后端能力的提升）。

比如，可以改变令牌的发放速度，算法能按照新的发送速率调大令牌的发放数量，使得出口突发流量能
被处理。

###### Guava 的 RateLimiter 提供了令牌桶算法实现

1 、平滑突发限流 (SmoothBursty)
2 、平滑预热限流 (SmoothWarmingUp)

**一、Guava 平滑突发限流**

1 、使用 RateLimiter 的静态方法创建一个限流器，设置每秒放置的令牌数为 5 个。返回的 RateLimiter 对
象可以保证 1 秒内不会给超过 5 个令牌，并且以固定速率进行放置，达到平滑输出的效果。

```
原理：创建的时候，记录当前时间，当需要获取令牌的时候，拿当前请求时间，减去创建时记录
的时间，得到时间差除以速率，得到已经产生的令牌数，然后判断如果当前需要使用的令牌数和
产生的令牌数对比
```
```
1 、如果小于当前的令牌，OK 没有问题，直接执行。
2 、如果大于当前的令牌数，那就得到需要额外预先支付的令牌数量，通过速率得到超出的令牌所
需要的时间，加上记录的时间，得到下次获取令牌的时间
```
```
3 、当新的获取令牌的请求进来，活进行判断，如果记录的时间大于当前请求的时间，那就说明，
上一个请求拿了太多的令牌，此时你需要等待。
```
```
public abstract class RateLimiter {
//平滑突发限流
static RateLimiter create (double permitsPerSecond, SleepingStopwatch
stopwatch) {
RateLimiter rateLimiter = new SmoothBursty (stopwatch, 1.0 /*
maxBurstSeconds */);
rateLimiter.setRate (permitsPerSecond);
return rateLimiter;
}
//平滑预热限流
static RateLimiter create (double permitsPerSecond, long warmupPeriod,
TimeUnit unit, double coldFactor, SleepingStopwatch
stopwatch) {
RateLimiter rateLimiter = new SmoothWarmingUp (stopwatch, warmupPeriod,
unit, coldFactor);
rateLimiter.setRate (permitsPerSecond);
return rateLimiter;
}
}
```
```
public void testSmoothBursty () {
RateLimiter r = RateLimiter.create ( 5 );
while (true) {
System.out.println ("get 1 tokens: " + r.acquire () + "s");
```

2 、RateLimiter 使用令牌桶算法，会进行令牌的累积，如果获取令牌的频率比较低，则不会导致等待，
直接获取令牌。

3 、RateLimiter 由于会累积令牌，所以可以应对突发流量。在下面代码中，有一个请求会直接请求 5 个
令牌，但是由于此时令牌桶中有累积的令牌，足以快速响应。 RateLimiter 在没有足够令牌发放时，采
用滞后处理的方式，也就是前一个请求获取令牌所需等待的时间由下一次请求来承受，也就是代替前一
个请求进行等待。

```
}
/**
* output: 基本上都是 0.2 s 执行一次，符合一秒发放 5 个令牌的设定。
* get 1 tokens: 0.0 s
* get 1 tokens: 0.182014 s
* get 1 tokens: 0.188464 s
* get 1 tokens: 0.198072 s
* get 1 tokens: 0.196048 s
* get 1 tokens: 0.197538 s
* get 1 tokens: 0.196049 s
*/
}
```
```
public void testSmoothBursty 2 () {
RateLimiter r = RateLimiter.create ( 2 );
while (true)
{
System.out.println ("get 1 tokens: " + r.acquire ( 1 ) + "s");
try {
Thread.sleep ( 2000 );
} catch (Exception e) {}
System.out.println ("get 1 tokens: " + r.acquire ( 1 ) + "s");
System.out.println ("get 1 tokens: " + r.acquire ( 1 ) + "s");
System.out.println ("get 1 tokens: " + r.acquire ( 1 ) + "s");
System.out.println ("end");
/**
* output:
* get 1 tokens: 0.0 s
* get 1 tokens: 0.0 s
* get 1 tokens: 0.0 s
* get 1 tokens: 0.0 s
* end
* get 1 tokens: 0.499796 s
* get 1 tokens: 0.0 s
* get 1 tokens: 0.0 s
* get 1 tokens: 0.0 s
*/
}
}
```
```
public void testSmoothBursty 3 () {
RateLimiter r = RateLimiter.create ( 5 );
while (true)
{
System.out.println ("get 5 tokens: " + r.acquire ( 5 ) + "s");
System.out.println ("get 1 tokens: " + r.acquire ( 1 ) + "s");
```

**二、Guava 平滑预热限流**

RateLimiter 的 SmoothWarmingUp 是带有预热期的平滑限流，它启动后会有一段预热期，逐步将分发
频率提升到配置的速率。比如下面代码中的例子，创建一个平均分发令牌速率为 2 ，预热期为 3 分钟。
由于设置了预热时间是 3 秒，令牌桶一开始并不会 0.5 秒发一个令牌，而是形成一个平滑线性下降的坡
度，频率越来越高，在 3 秒钟之内达到原本设置的频率，以后就以固定的频率输出。这种功能适合系统
刚启动需要一点时间来“热身”的场景。

###### Nginx 漏桶限流

**Nginx 限流的简单演示**

```
System.out.println ("get 1 tokens: " + r.acquire ( 1 ) + "s");
System.out.println ("get 1 tokens: " + r.acquire ( 1 ) + "s");
System.out.println ("end");
/**
* output:
* get 5 tokens: 0.0 s
* get 1 tokens: 0.996766 s 滞后效应，需要替前一个请求进行等待
* get 1 tokens: 0.194007 s
* get 1 tokens: 0.196267 s
* end
* get 5 tokens: 0.195756 s
* get 1 tokens: 0.995625 s 滞后效应，需要替前一个请求进行等待
* get 1 tokens: 0.194603 s
* get 1 tokens: 0.196866 s
*/
}
}
```
```
public void testSmoothwarmingUp () {
RateLimiter r = RateLimiter.create ( 2 , 3 , TimeUnit. SECONDS);
while (true)
{
System.out.println ("get 1 tokens: " + r.acquire ( 1 ) + "s");
System.out.println ("get 1 tokens: " + r.acquire ( 1 ) + "s");
System.out.println ("get 1 tokens: " + r.acquire ( 1 ) + "s");
System.out.println ("get 1 tokens: " + r.acquire ( 1 ) + "s");
System.out.println ("end");
/**
* output:
* get 1 tokens: 0.0 s
* get 1 tokens: 1.329289 s
* get 1 tokens: 0.994375 s
* get 1 tokens: 0.662888 s 上边三次获取的时间相加正好为 3 秒
* end
* get 1 tokens: 0.49764 s 正常速率 0.5 秒一个令牌
* get 1 tokens: 0.497828 s
* get 1 tokens: 0.49449 s
* get 1 tokens: 0.497522 s
*/
}
}
```

**每六秒才处理一次请求, 如下**

**这是从请求参数里边，提前参数做限流**

这是从请求参数里边，提前参数，进行限流的次数统计 key。

在 http 块里边定义限流的内存区域 zone。

在 location 块中使用限流 zone，参考如下：

测试

```
limit_req_zone  $arg_sku_id zone=skuzone: 10 m  rate=6 r/m;
limit_req_zone  $http_user_id zone=userzone: 10 m  rate=6 r/m;
limit_req_zone  $binary_remote_addr zone=perip: 10 m  rate=6 r/m;
limit_req_zone  $server_name zone=perserver: 1 m rate=6 r/m;
```
```
limit_req_zone  $arg_sku_id zone=skuzone: 10 m  rate=6 r/m;
limit_req_zone  $http_user_id zone=userzone: 10 m  rate=6 r/m;
limit_req_zone  $binary_remote_addr zone=perip: 10 m  rate=6 r/m;
limit_req_zone  $server_name zone=perserver: 1 m rate=10 r/s;
```
```
# ratelimit by sku id
location  = /ratelimit/sku {
limit_req  zone=skuzone;
echo "正常的响应";
}
```
```
[ root@cdh1 ~]# /vagrant/LuaDemoProject/sh/linux/openresty-restart. sh
shell dir is: /vagrant/LuaDemoProject/sh/linux
Shutting down openrestry/nginx: pid is 13479 13485
Shutting down succeeded!
OPENRESTRY_PATH:/usr/local/openresty
PROJECT_PATH:/vagrant/LuaDemoProject/src
nginx: [alert] lua_code_cache is off; this will hurt performance in
/vagrant/LuaDemoProject/src/conf/nginx-seckill. conf:90
openrestry/nginx starting succeeded!
pid is 14197
```
```
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
正常的响应
root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
正常的响应
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
限流后的降级内容
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
限流后的降级内容
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
限流后的降级内容
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
限流后的降级内容
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
限流后的降级内容
```

**从 Header 头部提前参数**

1 、nginx 是支持读取非 nginx 标准的用户自定义 header 的，但是需要在 http 或者 server 下开启 header 的
下划线支持:

underscores_in_headers on;

2 、比如我们自定义 header 为 X-Real-IP, 通过第二个 nginx 获取该 header 时需要这样:

$http_x_real_ip; (一律采用小写，而且前面多了个 http_)

测试

```
[ root@cdh1 ~]# curl http://cdh1/ratelimit/sku?sku_id=1
正常的响应
```
```
underscores_in_headers on;
```
```
limit_req_zone  $http_user_id zone=userzone: 10 m  rate=6 r/m;
server {
listen 80 default;
server_name nginx. server *. nginx. server;
default_type 'text/html';
charset utf-8;
```
```
# ratelimit by user id
location  = /ratelimit/demo {
limit_req  zone=userzone;
echo "正常的响应";
}
```
```
location = /50 x. html{
echo "限流后的降级内容";
}
```
```
error_page 502 503 = 200 /50 x. html;
}
```
```
[ root@cdh1 ~]# curl - H "USER-ID: 1" http://cdh1/ratelimit/demo
正常的响应
[ root@cdh1 ~]# curl - H "USER-ID: 1" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]# curl - H "USER-ID: 1" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]# curl - H "USER-ID: 1" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]# curl - H "USER-ID: 1" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]# curl - H "USER-ID: 1" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]# curl - H "USER-ID: 1" http://cdh1/ratelimit/demo
```

###### Nginx 漏桶限流的三个细分类型，即 burst、nodelay 参数详解

**每六秒才处理一次请求, 如下**

**不带缓冲队列的漏桶限流**

limit_req zone=limti_req_zone;

```
严格依照在 limti_req_zone 中配置的 rate 来处理请求
超过 rate 处理能力范围的，直接 drop
表现为对收到的请求无延时
```
```
假设 1 秒内提交 10 个请求，可以看到一共 10 个请求， 9 个请求都失败了, 直接返回 503 ，
```
接着再查看 /var/log/nginx/access. log，印证了只有一个请求成功了，其它就是都直接返回了 503 ，即
服务器拒绝了请求。

**带缓冲队列的漏桶限流**

limit_req zone=limti_req_zone burst=5;

```
依照在 limti_req_zone 中配置的 rate 来处理请求
同时设置了一个大小为 5 的缓冲队列，在缓冲队列中的请求会等待慢慢处理
超过了 burst 缓冲队列长度和 rate 处理能力的请求被直接丢弃
表现为对收到的请求有延时
```
```
限流后的降级内容
[ root@cdh1 ~]# curl - H "USER_ID: 2" http://cdh1/ratelimit/demo
正常的响应
[ root@cdh1 ~]# curl - H "USER_ID: 2" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]#
[ root@cdh1 ~]# curl - H "USER_ID: 2" http://cdh1/ratelimit/demo
限流后的降级内容
[ root@cdh1 ~]# curl - H "USER-ID: 3" http://cdh1/ratelimit/demo
正常的响应
[ root@cdh1 ~]# curl - H "USER-ID: 3" http://cdh1/ratelimit/demo
限流后的降级内容
```
```
limit_req_zone  $arg_user_id zone=limti_req_zone: 10 m  rate=10 r/m;
```

```
假设 1 秒内提交 10 个请求，则可以发现在 1 s 内，在服务器接收到 10 个并发请求后，先处理 1 个请
求，同时将 5 个请求放入 burst 缓冲队列中，等待处理。而超过（burst+1）数量的请求就被直接
抛弃了，即直接抛弃了 4 个请求。 burst 缓存的 5 个请求每隔 6 s 处理一次。
```
接着查看 /var/log/nginx/access. log 日志

**带瞬时处理能力的漏桶限流**

limit_req zone=req_zone burst=5 nodelay;

**如果设置 nodelay，会在瞬时提供处理 (burst + rate) 个请求的能力** ，请求数量超过 **（burst + rate）**
的时候就会直接返回 503 ，峰值范围内的请求， **不存在请求需要等待的情况** 。

```
假设 1 秒内提交 10 个请求，则可以发现在 1 s 内，服务器端处理了 6 个请求（峰值速度：burst＋10 s
内一个请求）。对于剩下的 4 个请求，直接返回 503 ，在下一秒如果继续向服务端发送 10 个请求，
服务端会直接拒绝这 10 个请求并返回 503 。
```
接着查看 /var/log/nginx/access. log 日志

**可以发现在 1 s 内，服务器端处理了 6 个请求（峰值速度：burst＋原来的处理速度）。对于剩下的 4 个请
求，直接返回 503 。**

```
但是，总数额度和速度*时间保持一致，就是额度用完了，需要等到一个有额度的时间段，才开
始接收新的请求。如果一次处理了 5 个请求，相当于占了 30 s 的额度， 6 *5=30。因为设定了 6 s 处理
1 个请求，所以直到 30
s 之后，才可以再处理一个请求，即如果此时向服务端发送 10 个请求，会返回 9 个 503 ，一个 200
```
```
说明：本文会以 pdf 格式持续更新，更多最新尼恩 3 高 pdf 笔记，请关注本公众号【技术自由圈】
领取
```
###### 分布式限流组件

**why**

```
但是 Nginx 的限流指令只能在同一块内存区域有效，而在生产场景中秒杀的外部网关往往是多节点
部署，所以这就需要用到分布式限流组件。
```

高性能的分布式限流组件可以使用 Redis+Lua 来开发，京东的抢购就是使用 Redis+Lua 完成的限流。并
且无论是 Nginx 外部网关还是 Zuul 内部网关，都可以使用 Redis+Lua 限流组件。

理论上，接入层的限流有多个维度：

（ 1 ）用户维度限流：在某一时间段内只允许用户提交一次请求，比如可以采取客户端 IP 或者用户 ID 作
为限流的 key。

（ 2 ）商品维度的限流：对于同一个抢购商品，在某个时间段内只允许一定数量的请求进入，可以采取
秒杀商品 ID 作为限流的 key。

什么时候用 nginx 限流：

用户维度的限流，可以在 ngix 上进行，因为使用 nginx 限流内存来存储用户 id，比用 redis 的 key，来存
储用户 id，效率高。

什么时候用 redis+lua 分布式限流：

商品维度的限流，可以在 redis 上进行，不需要大量的计算访问次数的 key，另外，可以控制所有的接入
层节点的访问秒杀请求的总量。

###### redis+lua 分布式限流组件

```
--- 此脚本的环境： redis 内部，不是运行在 nginx 内部
```
```
---方法：申请令牌
--- -1 failed
--- 1 success
--- @param key key 限流关键字
--- @param apply 申请的令牌数量
local function acquire (key, apply)
local times = redis.call ('TIME');
-- times[1] 秒数 -- times[2] 微秒数
local curr_mill_second = times[1] * 1000000 + times[2];
curr_mill_second = curr_mill_second / 1000 ;
```
```
local cacheInfo = redis.pcall ("HMGET", key, "last_mill_second",
"curr_permits", "max_permits", "rate")
--- 局部变量：上次申请的时间
local last_mill_second = cacheInfo[1];
--- 局部变量：之前的令牌数
local curr_permits = tonumber (cacheInfo[2]);
--- 局部变量：桶的容量
local max_permits = tonumber (cacheInfo[3]);
--- 局部变量：令牌的发放速率
local rate = cacheInfo[4];
--- 局部变量：本次的令牌数
local local_curr_permits = 0 ;
```
```
if (type (last_mill_second) ~= 'boolean' and last_mill_second ~= nil) then
-- 计算时间段内的令牌数
```

local reverse_permits = math.floor (((curr_mill_second -
last_mill_second) / 1000 ) * rate);
-- 令牌总数
local expect_curr_permits = reverse_permits + curr_permits;
-- 可以申请的令牌总数
local_curr_permits = math.min (expect_curr_permits, max_permits);
else
-- 第一次获取令牌
redis.pcall ("HSET", key, "last_mill_second", curr_mill_second)
local_curr_permits = max_permits;
end

local result = -1;
-- 有足够的令牌可以申请
if (local_curr_permits - apply >= 0 ) then
-- 保存剩余的令牌
redis.pcall ("HSET", key, "curr_permits", local_curr_permits - apply);
-- 为下次的令牌获取，保存时间
redis.pcall ("HSET", key, "last_mill_second", curr_mill_second)
-- 返回令牌获取成功
result = 1 ;
else
-- 返回令牌获取失败
result = -1;
end
return result
end
--eg
-- /usr/local/redis/bin/redis-cli  -a 123456 --eval
/vagrant/LuaDemoProject/src/luaScript/redis/rate_limiter. lua key , acquire 1  1

-- 获取 sha 编码的命令
-- /usr/local/redis/bin/redis-cli  -a 123456 script load "$(cat
/vagrant/LuaDemoProject/src/luaScript/redis/rate_limiter. lua)"
-- /usr/local/redis/bin/redis-cli  -a 123456 script exists
"cf 43613 f 172388 c 34 a 1130 a 760 fc 699 a 5 ee 6 f 2 a 9"

-- /usr/local/redis/bin/redis-cli -a 123456 evalsha
"cf 43613 f 172388 c 34 a 1130 a 760 fc 699 a 5 ee 6 f 2 a 9" 1 "rate_limiter:seckill: 1" init 1  1
-- /usr/local/redis/bin/redis-cli -a 123456 evalsha
"cf 43613 f 172388 c 34 a 1130 a 760 fc 699 a 5 ee 6 f 2 a 9" 1 "rate_limiter:seckill: 1" acquire 1

--local rateLimiterSha = "e 4 e 49 e 4 c 7 b 23 f 0 bf 7 a 2 bfee 73 e 8 a 01629 e 33324 b";

---方法：初始化限流 Key
--- 1 success
--- @param key key
--- @param max_permits 桶的容量
--- @param rate 令牌的发放速率
local function init (key, max_permits, rate)
local rate_limit_info = redis.pcall ("HMGET", key, "last_mill_second",
"curr_permits", "max_permits", "rate")
local org_max_permits = tonumber (rate_limit_info[3])
local org_rate = rate_limit_info[4]

if (org_max_permits == nil) or (rate ~= org_rate or max_permits ~=
org_max_permits) then


在 redis 中，为了避免重复发送脚本数据浪费网络资源，可以使用 script load 命令进行脚本数据缓存，并
且返回一个哈希码作为脚本的调用句柄，

每次调用脚本只需要发送哈希码来调用即可。

###### 分布式令牌限流实战

**可以使用 redis+lua，实战一票下边的简单案例：**

令牌按照 1 个每秒的速率放入令牌桶，桶中最多存放 2 个令牌，那系统就只会允许持续的每秒处理 2 个请
求，

或者每隔 2 秒，等桶中 2 个令牌攒满后，一次处理 2 个请求的突发情况，保证系统稳定性。

###### 商品维度的限流

当秒杀商品维度的限流，当商品的流量，远远大于涉及的流量时，开始随机丢弃请求。

```
redis.pcall ("HMSET", key, "max_permits", max_permits, "rate", rate,
"curr_permits", max_permits)
end
return 1 ;
end
--eg
-- /usr/local/redis/bin/redis-cli -a 123456 --eval
/vagrant/LuaDemoProject/src/luaScript/redis/rate_limiter. lua key , init 1  1
-- /usr/local/redis/bin/redis-cli -a 123456 --eval
/vagrant/LuaDemoProject/src/luaScript/redis/rate_limiter. lua
"rate_limiter:seckill: 1" , init 1  1
```
```
---方法：删除限流 Key
local function delete (key)
redis.pcall ("DEL", key)
return 1 ;
end
--eg
-- /usr/local/redis/bin/redis-cli  --eval
/vagrant/LuaDemoProject/src/luaScript/redis/rate_limiter. lua key , delete
```
```
local key = KEYS[1]
local method = ARGV[1]
if method == 'acquire' then
return acquire (key, ARGV[2], ARGV[3])
elseif method == 'init' then
return init (key, ARGV[2], ARGV[3])
elseif method == 'delete' then
return delete (key)
else
--ignore
end
```

Nginx 的令牌桶限流脚本 getToken_access_limit. lua 执行在请求的 access 阶段，但是，该脚本并没有实
现限流的核心逻辑，仅仅调用缓存在 Redis 内部的 rate_limiter. lua 脚本进行限流。

getToken_access_limit. lua 脚本和 rate_limiter. lua 脚本的关系，具体如下图所示。

图 getToken_access_limit. lua 脚本和 rate_limiter. lua 脚本关系

什么时候在 Redis 中加载 rate_limiter. lua 脚本呢？

和秒杀脚本一样，该脚本是在 Java 程序启动商品秒杀时，完成其在 Redis 的加载和缓存的。

还有一点非常重要，Java 程序会将脚本加载完成之后的 sha 1 编码，去通过自定义的 key（具体
为"lua: sha 1: rate_limiter"）缓存在 Redis 中，以方便 Nginx 的 getToken_access_limit. lua 脚本去获取，
并且在调用 evalsha 方法时使用。

注意：使用 redis 集群，因此每个节点都需要各自缓存一份脚本数据

#### 11 、说说 dubbo 的 rpc 原理

```
/**
* 由于使用 redis 集群，因此每个节点都需要各自缓存一份脚本数据
* @param slotKey 用来定位对应的 slot 的 slotKey
*/
public void storeScript (String slotKey){
if (StringUtils.isEmpty (unlockSha 1) ||
!jedisCluster.scriptExists (unlockSha 1, slotKey)){
//redis 支持脚本缓存，返回哈希码，后续可以继续用来调用脚本
unlockSha 1 = jedisCluster.scriptLoad (DISTRIBUTE_LOCK_SCRIPT_UNLOCK_VAL,
slotKey);
}
}
```

小伙伴从以下 4 个维度去 "吹牛"，说面试官被吹到 "口水直流，不能自己"

```
首先，说说 Dubbo 的 RPC 的大致功能流程
其次，从 dubbo 的源码角度，说说 dubbo 的总体分层架构
再次：源码视角，说说 Dubbo 总体 RPC 调用过程图
最后： 嘚瑟一下，Dubbo 底层 netty 框架的高性能通信原理
```
Dubbo 是一个开源的 RPC 框架，它主要用于构建分布式服务治理框架，提供服务注册、调用和负载均
衡等功能。

###### 首先，说说 Dubbo 的 RPC 的大致功能流程

Dubbo 的 RPC 的大致功能流程：可以概括为以下几个步骤：

```
1. 服务提供者注册：服务提供者在启动时，会将自己的地址、端口、接口全限定类名等信息注册到注
册中心（通常是 ZooKeeper）。
2. 服务消费者订阅：服务消费者在启动时，会从注册中心订阅可用的服务提供者信息。
3. 调用服务：当服务消费者需要调用某个服务时，它会根据订阅到的服务提供者信息，选择一个可用
的服务提供者，并通过 RPC 调用该服务的接口。
4. 负载均衡：Dubbo 支持多种负载均衡算法，如随机、轮询、最少活跃调用等。其中，随机算法是
最简单的一种负载均衡算法。
5. 服务提供者处理请求：服务提供者接收到请求后，会根据请求中的参数和方法名称，调用对应的方
法实现，并返回结果。
6. 返回结果：服务提供者将结果返回给服务消费者，服务消费者再将结果返回给客户端。
7. 服务调用链路追踪：Dubbo 支持服务调用链路追踪功能，可以通过日志等方式查看服务调用过程
中的详细信息。
```
Dubbo 的 RPC 原理采用了客户端和服务端双向通信的方式，通过服务提供者注册和消费者订阅的方式
实现服务的发现和调用。在使用 Dubbo 时，用户可以通过配置注册中心、服务提供者和服务消费者的
地址和端口等信息，实现分布式服务的搭建和调用。

###### 其次，从 dubbo 的源码角度，说说 dubbo 的总体分层架构

从 API、SPI 角度来说，dubbo 分为 2 层

```
Service 和 Config 两层可以认为是 API 层，主要提供给 API 使用者，使用者只需要配置和完成业务代
码就可以了。
后面所有的层级是 SPI 层，主要提供给扩展者使用主要是用来做 Dubbo 的二次开发扩展功能。
```
从大的范围来说，Dubbo 分为三层：

```
Business 业务逻辑层：由我们自己来提供接口和实现，还有一些配置信息。
RPC 层：就是真正的 RPC 调用的核心层，封装整个 RPC 的调用过程、负载均衡、集群容错、代
理。
Remoting 则是对网络传输协议和数据转换的封装。
```
从大的范围来说，dubbo 分为三层


**business** 业务逻辑层由我们自己来提供，接口和实现还有一些配置信息

**RPC** 层就是真正的 RPC 调用的核心层，封装整个 RPC 的调用过程、负载均衡、集群容错、代理

**remoting** 则是对网络传输协议和数据转换的封装。

整个分层依赖由上至下，除 Business 业务逻辑之外，其他的几层都是 SPI 机制。

再划分到更细的层面，就是图中的 10 层模式。


更细的层面，分 10 层：

**第一层：service 层，接口层** ，给服务提供者和消费者来实现的（留给开发人员来实现）；

**第二层：config 层，配置层** ，主要是对 Dubbo 进行各种配置的，Dubbo 相关配置；

**第三层：proxy 层，服务代理层** ，透明生成客户端的 stub 和服务单的 skeleton，调用的是接口，实现
类没有，所以得生成代理，代理之间再进行网络通讯、负责均衡等；

**第四层：registry 层，服务注册层** ，负责服务的注册与发现；

**第五层：cluster 层，集群层** ，封装多个服务提供者的路由以及负载均衡，将多个实例组合成一个服
务；

**第六层：monitor 层，监控层** ，对 rpc 接口的调用次数和调用时间进行监控；第七层：protocol 层，
远程调用层，封装 rpc 调用；

**第八层：exchange 层，信息交换层** ，封装请求响应模式，同步转异步；

**第九层：transport 层，网络传输层** ，抽象 mina 和 netty 为统一接口；

**第十层：serialize 层，数据序列化层** 。

这是个很坑爹的面试题，但是很多面试官又喜欢问，你真的要背么？你能背那还是不错的，我建议不要
背，你就想想 Dubbo 服务调用过程中应该会涉及到哪些技术，把这些技术串起来就 OK 了。

###### 再次：源码视角，说说 Dubbo 总体 RPC 调用过程图：

```
1. Proxy 持有一个 Invoker 对象，使用 Invoker 调用
2. 之后通过 Cluster 进行负载容错，失败重试
3. 调用 Directory 获取远程服务的 Invoker 列表
4. 负载均衡用户配置了路由规则，则根据路由规则过滤获取到的 Invoker 列表用户没有配置路由规则
或配置路由后还有很多节点，则使用 LoadBalance 方法做负载均衡，选用一个可以调用的 Invoker
5. 经过一个一个过滤器链，通常是处理上下文、限流、计数等。
```

```
6. 会使用 Client 做数据传输
7. 私有化协议的构造 (Codec)
8. 进行序列化
9. 服务端收到这个 Request 请求，将其分配到 ThreadPool 中进行处理
10. Server 来处理这些 Request
11. 根据请求查找对应的 Exporter
12. 之后经过一个服务提供者端的过滤器链
13. 然后找到接口实现并真正的调用，将请求结果返回
```
###### 最后、底层 netty 框架的高性能通信原理

Netty 是一个异步事件驱动的网络应用程序框架，用于快速开发可维护的高性能协议服务器和客户端。
它极大地简化并简化了 TCP 和 UDP 套接字服务器等网络编程。

传统的通讯，使用 BIO：(Blocking IO)

而 Netty 是 NIO (Non-Blocking IO)


虽然最新的 tomcat 也是 nio，但是 Netty 棋高一着，是 reactor 反应器模式


```
有关高性能 IO 的系统化知识，请参见尼恩的《Java 高并发核心编程卷 1 加强版》
```
## 炸裂，靠“吹牛”过京东一面，月薪 40 k

#### 说在前面

在 40 岁老架构师尼恩的（50+） **读者社群** 中，经常有小伙伴，需要面试美团、京东、阿里、百度、头条
等大厂。

下面是一个 5 年小伙伴成功拿到通过了京东一面面试，并且最终拿到 offer，月薪 40 K。

现在把面试真题和参考答案收入咱们的宝典，大家看看， **收个优质 Offer 需要学点啥？**

当然对于中高级开发来说，这些面试题，也有参考意义。

小伙伴说， **光代码漂亮不够，面试，还得会吹。**

这里把题目以及 **小伙伴的吹牛逼的方式方法** ，经过整理和梳理之后，收入咱们的《尼恩 Java 面试宝典》
V 95 版本，供后面的小伙伴参考，提升大家的 3 高架构、设计、开发、吹牛水平。

```
《尼恩架构笔记》《尼恩高并发三部曲》《尼恩 Java 面试宝典》的 PDF，请到公众号【技术自由
圈】获取
```

#### 京东一面

###### 1 、说一说 JVM 内存模型

小伙伴从以下 2 个维度去 "吹牛"，吹到面试官 "口水直流，不能自已"

```
第一个维度：JVM 内存结构
第二个维度：Java 内存模型图
```
**JVM 内存结构**

程序计数器：当前线程所执行的字节码的行号指示器，用于记录正在执行的虚拟机字节指令地址，线程
私有。

Java 虚拟栈：存放基本数据类型、对象的引用、方法出口等，线程私有。

Native 方法栈：和虚拟栈相似，只不过它服务于 Native 方法，线程私有。

Java 堆：java 内存最大的一块，所有对象实例、数组都存放在 java 堆，GC 回收的地方，线程共享。

方法区：存放已被加载的类信息、常量、静态变量、即时编译器编译后的代码数据等。（即永久带），
回收目标主要是常量池的回收和类型的卸载，各线程共享

**Java 内存模型图**


Java 内存模型规定了所有的 **变量都存储在主内存** 中，每条 **线程还有自己的工作内存** ，线程的工作内存中
保存了该线程中是用到的变量的主内存副本拷贝， **线程对变量的所有操作都必须在工作内存中** 进行， **而
不能直接读写主内存** 。不同的线程之间也 **无法直接访问对方工作内存中的变量** ，线程间变量的传递均需
要自己的工作内存和主存之间进行数据同步进行。

```
尼恩说明：
由于篇幅限制，这里对 JVM 内存结构、Java 内存模式的介绍，没有做展开，
```
```
有关 JVM 内存结构、Java 内存模式的详细介绍，可以参考《尼恩 Java 面试宝典》中 JVM 面试专题的
内存模型部分
```
###### 2 、CMS 和 G 1 有什么区别? 什么时候发生垃圾回收？ 然后，说说大致

###### 的回收过程?

小伙伴从以下 6 个维度去 "吹牛"，吹到面试官 "口水直流，不能自已"


```
首先，说说垃圾回收的本质
其次，CMS 和 G 1 有什么区别
再次：完整的 GC 流程
再次： 什么时候发生垃圾回收
再次：对象存活判断方法
最后：垃圾回收算法
```
**垃圾回收的本质**

垃圾回收是 Java 程序执行自动内存管理的过程。当 Java 程序在 JVM 上运行时，将在堆上创建对象，这是
专用于该程序的内存的一部分。最终，将不再需要某些对象。垃圾收集器找到这些未使用的对象并将其
删除以释放内存。

**CMS 和 G 1 有什么区别**

CMS (Concurrent Mark Sweep) 收集器（标记-清除算法）： 老年代并行收集器，以获取最短回收停顿
时间为目标的收集器，具有高并发、低停顿的特点，追求最短 GC 回收停顿时间。

G 1 (Garbage First) 收集器（标记-整理算法）： Java 堆并行收集器，G 1 收集器是 JDK 1.7 提供的一个新收
集器，G 1 收集器基于“标记-整理”算法实现，也就是说不会产生内存碎片。此外，G 1 收集器不同于之前
的收集器的一个重要特点是：G 1 回收的范围是整个 Java 堆 (包括新生代，老年代)，而前六种收集器回收
的范围仅限于新生代或老年代。

区别：

```
CMS 收集器是老年代的收集器，可以配合新生代的 Serial 和 ParNew 收集器一起使用；
G 1 收集器收集范围是老年代和新生代，不需要结合其他收集器使用；
CMS 收集器以最小的停顿时间为目标的收集器；
G 1 收集器可预测垃圾回收的停顿时间
CMS 收集器是使用“标记-清除”算法进行的垃圾回收，容易产生内存碎片
G 1 收集器使用的是“标记-整理”算法，进行了空间整合，降低了内存空间碎片。
```
**完整的 GC 流程**

在 JVM 中一次完整的 GC 流程如下：

```
1. 标记垃圾对象；
2. 清除垃圾对象；
3. 将存活的对象复制到另一个区域；
```

```
4. 清空原区域。
```
JVM 中的垃圾回收分为三个阶段：Minor GC、Full GC 和 G 1 GC。

```
Minor GC ，是针对新生代的垃圾回收器，主要清理 Eden 区和 Survivor 区的垃圾；
Full GC ，是对整个堆空间进行垃圾回收，包括新生代和老年代；
G 1 GC ，是一种基于 Region 的垃圾回收器，它将堆空间划分为不同的 Region, 每个 Region 都有一个
根节点，当某个 Region 的大小达到一定阈值时，就会触发一次 GC。
```
**什么时候发生垃圾回收**

当对象对当前使用这个对象的应用程序变得不可触及的时候，这个对象就可以被回收了。

垃圾回收不会发生在永久代，如果永久代满了或者是超过了临界值，会触发完全垃圾回收 (Full GC)。

如果你仔细查看垃圾收集器的输出信息，就会发现永久代也是被回收的。这就是为什么正确的永久代大
小对避免 Full GC 是非常重要的原因。

**对象存活判断方法**

Java 中判断对象存活的方法有以下两种算法:

```
1. 引用计数算法 ：给对象添加一个引用计数器，每当有一个地方引用它时，计数器值就+1; 当引用失
效时，计数器值就-1; 任何时刻计数器为 0 的对象就是不可能再被使用的对象。这种算法虽然简单，
但是有个致命的缺点，就是不能适用于相互引用的情况。
2. 可达性分析算法 ：通过从根对象开始向下搜索，直到找到一个无法直接或间接访问到的对象为止。
这个过程称为“可达性分析”，如果一个对象不可达，则说明它已经不再使用，可以被回收。
```
**垃圾回收算法**

Java 中常见的三种垃圾收集算法是标记-清除算法 (Mark-Sweep)、复制算法 (Copying) 和分代收集算法
(Generational Collection)。

```
1. 标记-清除算法 ：这种算法首先会标记出所有活动对象，然后将它们从内存中移除。接下来，算法
会遍历整个堆空间，将未被标记的对象进行回收。这种算法的缺点是会产生内存碎片。
2. 复制算法 ：这种算法将堆空间分为两个区域：Eden 区和 Survivor 区。新创建的对象首先分配到
Eden 区中，然后经过多次复制和清除后才会被移动到 Survivor 区中。当 Survivor 区空间不足时，
就会触发一次 Full GC 来进行垃圾回收。这种算法的优点是可以避免内存碎片。
3. 分代收集算法 ：这种算法将堆空间分为三个区域：新生代、老年代和永久代。新生代又分为 Eden
区、Survivor 区和 From 区。这种算法的优点是可以更好地利用 CPU 缓存，提高程序运行效率。
```
###### 3 、对于数据的一致性是怎么保证的？

小伙伴说，他是参考《尼恩 Java 面试宝典》中 Redis 专题中的数据一致性问题及方案去吹的，面试官非
常满意

###### 4 、Redis 集群有没有了解过，主从和选举是怎样的？


小伙伴从以下 7 个维度去 "吹牛"，吹到面试官 "口水直流，不能自已"

```
首先，说说 Redis 高可用集群架构
两个小的维度一，主从哨兵模式
两个小的维度二，Cluster 集群模式
再次：说说两种主从数据同步方式
两个小的维度一，全量复制
两个小的维度二，增量复制
第三：说说说说两种选主机制
两个小的维度一，主从哨兵模式选主
两个小的维度二，Cluster 集群模式选主
最后，嘚瑟一下过期内存淘汰策略
```
**一、Redis 高可用集群架构**

Redis 高可用集群有两种，分别是主从哨兵模式和集群模式

**1. 主从哨兵模式**

其中一台服务器作为 master 服务器，提供读写服务，配置多台从服务器，从服务器只提供只读服务，同
时配置多台 sentinel，也即是哨兵，哨兵的作用是可以监控 master 节点，如果 master 宕机，可以从从服
务器中选举出一台作为 master 服务器。

哨兵模式，客户端连接哨兵集群，即可获得 master 服务器的信息。此时客户端并不会做读写分离，也就
是所有读写都由 master 服务器处理，这里相当于从服务器只作为主服务器的数据备份。如果 master 发
生故障，切换到其他从服务器，哨兵会把新的 master 服务器地址告知客户端。

jedis 和 RedisTemplate 都没有实现读写分离。如果需要可以分别建立 master 服务器连接池和 slave 服务
器连接池，并严格区分读写操作，路由到需要使用的连接池。需要注意的是，Redis 主从复制是异步
的，可能存在小概率数据不一致的问题。

**2. Cluster 集群模式**


在主从哨兵模式，所有的写操作都是由 master 处理，这在性能上可能会出现瓶颈。Redis 3.0 后推出了集
群模式，可以实现水平扩展，配置多台的 master 服务器处理读写请求。

集群模式下，看似于将一个大的主从架构拆分成多个主从架构的服务器群，具有复制，高可用和分片的
特性。不需要哨兵，也可以实现节点故障移除和 master 选举功能。性能和高可用性均优于哨兵模式，但
需要更多的服务器。可以从公司业务的并发量和成本等角度考量选择哪种模式。

Redis Cluster 集群模式默认将所有的数据划分为 16384 个 slot 槽，每个 master 节点均匀负责一部的槽
位。

通常，会对 key 值使用 crc 16 算法进行 hash 得到一个整数值，然后使用这个整数值对 16384 进行取模，来
得到具体的槽位。

Cluster 集群模式下，Redis 默认从服务是不分担读请求，只作为备注和故障转移。但有读请求到达从服
务器，会重定向到主服务器处理。

**二、主从数据同步**

Redis 主从数据同步大致分为两种， **全量复制和增量复制** 。

**全量复制**


**增量复制**

一般情况下，主从断开连接后会进行全量复制，但 Redis 2.8 后开始支持部分数据的复制。

master 和从服务器第一次连接时会进行全量复制，同时 master 和所有的 slave 都会维护一个复制数据的
偏移量 offset 和 master 的进程 id。


如果从服务器断开重连后，会比较偏移量是否太旧或者 master 进程 id 是否变更了，如果这样则会进行一
次全量复制，否则会进行部分复制，把 offset 之后的数据同步给从服务器。

**三、选主机制**

**1. 主从哨兵模式**

这种模式下，是有哨兵监控 master 服务器状态，并实现故障转移。一旦 master 服务器宕机，则哨兵会
从剩下的从服务器中选举一条作为新的 master 节点。这里有几个概念:

主观下线:

哨兵会定期向主服务器发送心跳包检测是否正常，如果超过配置文件中 sentinel down-after-
milliseconds mymaster 配置的时间没有收到主服务器的回复，则这个哨兵认为主服务下线。

客观下线:

一个哨兵把 master 记为主观下线，并不代表 master 就一定下线了，此时要向其他哨兵确认 master 是否
真的下线，如果超过 sentinel monitor mymaster 配置的数量（一般为哨兵数量/2 + 1）哨兵认为
master 下线，则记为客观下线。

哨兵选举 master 服务器过程：

```
1. 先从哨兵中选举出一个 leader，并由这个 leader 选举出新的 master
2. 过滤故障节点，从剩余的节点中按照下列规则选出 master
3. 优先选择 slave-priority 最大的从节点作为主节点
4. 其次选择数据偏移量最大的节点
5. 选择 runid 最小的从节点
```
**2. 集群模式**

```
1. slave 发现自己的 master 下线后，会广播故障转移信息到其他 master 节点
2. master 接收到 slave 故障转移请求后，首先会检测请求的合法性，然后发送响应 ack 给 slave, 每轮投
票，master 只会响应一次
3. 一旦一个 slave 接收超过半数 master 的 ack 后，则被选中成为新的 master，否则会进行下一轮的投
票
```
**四、过期内存淘汰策略**

```
1. 被动删除，客户端 get 请求某个 key 时，会判断是否过期，如果过期了，则会清楚
2. 主动删除，redis 定期扫描一批 key, 检查是否过期，如果过期，则清楚
3. 内存淘汰策略，当 redis 内存不足以容纳更多的 key 时，则会触发内存淘汰策略，可以在配置文件配
置。常用有 lru (最久没访问)，lfu (访问频率最低) random (随机)，同时可以配置针对所有的 key, 还是
设置了过期时间的 key 执行淘汰。
```
###### 5 、看你们公司使用的是 MySQL，你们使用的是哪种存储引擎，为什

###### 么？MyISAM 和 InnoDB 的区别

小伙伴说，他是参考《尼恩 Java 面试宝典》中 Mysql 面试专题中的 Mysql 原理、MyISAM 和 InnoDB 的对
比去吹的


###### 6 、mysql 索引的底层数据结构是什么，为什么选择这种数据结构

小伙伴从以下 6 个维度去 "吹牛"，吹到面试官 "口水直流，不能自已"

```
首先，索引的底层数据结构
其次，时间复杂度对比
再次：为什么索引采用 B+树，而不采用 Hash 这种结构
再次：为什么不用二叉树
再次：为什么不用红黑二叉树
最后：为什么没有采用 B 树，或则说 B-树？
```
**索引的底层数据结构有** ：

```
1. 树 Tree，准确的说是 B+树
2. Hash
```
**时间复杂度对比** ：

Hash 的时间 O (1)

Tree 的 O (logn)

**为什么索引采用 B+树，而不采用 Hash 这种结构？**

Hash 这种结构对与获取单条记录时的查询效率是要比 B+树效率要高的，但是对与数据的范围查找效率
就很低，特别是对于数据量大的时候（ 10 万甚至百万级别的数据）。

为什么低？它是根据字段值算出获取一个 hash 值，然后根据 hash 值找到在索引表中查找出 hash 值对应
的数据行，它的索引没有按顺序存储

B+树：是一种多路平衡树，一个横向存放多个节点，并且它的非叶子节点都只存放指向子节点的索引指
针，不存放数据。所有非叶子节点都存放一个节点在叶子节点上，并且这个叶子节点是一个有序的列表
结构。

当我们查一个范围数据时，通过 B+树搜索

多路：一课树每个节点最多可以拥有大于 2 个子节点的树

平衡树： 一颗树左子树和右子树保持相对平衡，不会出现一边层级特别多，一边层级特别少的情况

**为什么不用二叉树？**

二叉树为非平衡树，如果是有序递变的数据，很有可能就会变成左边树层级过高，或则右边树的层级过
高，甚至是退化成链表。

**层级过高为什么就不能用了呢？**

假设是 1,2,3,4,5,6 这样的数据，如果我们要找到底部 6 这个数据，就要进行 6 次 IO（加载磁盘数据进内
存，索引是在磁盘文件中以表的形式存在的）才能找到。如果按一次 IO 10 ms 计算，60 ms 也不算什么。
但是假设是 100 万呢？1001000010 ms，也就是 10000 s，换算成分钟也就是 167 ，所以这种结构肯定是
不行的。

**为什么不用红黑二叉树？**

红黑二叉树一种平衡树，虽然它不会出现有一树的层级过高的情况，但是它还是没有从根本上解决树的
层级问题，随着数据量增大，树的层级会越来越高。要遍历叶子节点的数据 IO 消耗还是过高。

**为什么没有采用 B 树，或则说 B-树？**

B 树虽然虽然通过多路平衡树解决了树的高度问题，但是它对与访问数据的查找效率还是低下的，对于
数据访问在非叶子节点和叶子节点都有的范围，它不仅非叶子节点的遍历还需要做叶子节点的遍历。


总体来说：选择 B+树是因为它具有以下优点：

```
1. 查询效率高 ：B+树的搜索性能非常接近二叉树，而且它的查询效率更高，因为它的每个节点都包
含很多关键字，可以支持范围查询。
2. 空间利用率高 ：B+树的每个节点都包含很多关键字，所以它的空间利用率更高，可以支持更多的
索引。
3. 适用于外部存储 ：B+树的节点之间的距离比较大，所以它更适用于外部存储，可以减少内存开
销。
```
因此，B+树是一种非常适合用于 MySQL 索引的底层数据结构，它可以提供高效、稳定、可靠的查询性
能。

###### 7 、说说什么情况下索引失效

小伙伴说，他是参考《尼恩 Java 面试宝典》中 Mysql 面试专题中的索引失效面试题去吹的，面试官非常
满意

###### 8 、手写代码：设计一个分布式自增 id 生成服务

设计一个分布式自增 id 生成服务的步骤如下：

```
1. 选择合适的分布式 ID 生成算法，例如 Snowflake、Apache Skywalking 等。
2. 设计分布式 ID 生成服务的架构，包括节点的部署、负载均衡、数据同步等。
3. 实现分布式 ID 生成服务的代码，包括生成 ID 的算法、节点的连接和数据同步等。
4. 部署分布式 ID 生成服务，并进行测试和性能优化。
```
下面是一个简单的 Java 实现：

```
public class DistributedIdGenerator {
private static final int PARTITION_ID = 1 ; // 分区 ID
private static final int NODE_ID = 1 ; // 节点 ID
private static final int SEQUENCE = 1 ; // 序列号
private static final long SEQUENCE_ROOT = 1 L << 32 ; // 序列号根节点
private static final long MAX_ID = SEQUENCE_ROOT + 1 - 1 L << 32 ; // 最大 ID
private static final long TIMESTAMP = System.currentTimeMillis () / 1000 ; //
时间戳
private static final long MACHINE_ID =
UUID.randomUUID (). getMostSignificantBits (); // 机器 ID
private static final int SCALE = 10 ; // 位数
private static final int SHIFT = 22 ; // 位移
private static final int PARTITION_SIZE = 1 << SCALE; // 分区大小
private static final DistributedIdGenerator instance = new
DistributedIdGenerator ();
private static int sequence = 0 ; // 当前节点的序列号
private static long lastId = SEQUENCE_ROOT; // 上一次生成的 ID
private static Map<Integer, Long> partitionMap = new HashMap<>(); // 分区 ID 和
最大 ID 的映射
```
```
private DistributedIdGenerator () {
// 初始化分区 ID 和节点 ID
```

这个实现使用了 Snowflake 算法，通过获取当前时间的毫秒数、机器 ID 和序列号来生成 ID。在生成 ID
时，首先获取当前节点的序列号，如果序列号溢出，则从上一次生成的 ID 开始。如果分区 ID 和节点 ID 都
溢出，则从最大 ID 开始。最后，计算出 ID 并更新上一次生成的 ID 和分区 ID 和节点 ID 的映射。

###### 9 、有没有了解过网络安全问题，常见的网络攻击有哪些，原理是什

###### 么，可以怎么解决

小伙伴从以下 4 个维度去 "吹牛"，吹到面试官 "口水直流，不能自已"

```
首先，XSS 跨站脚本攻击
其次，CSRF 跨站请求伪造
再次：DDoS 分布式拒绝服务攻击
再次：SQL 注入
```
```
partitionMap.put (PARTITION_ID, SEQUENCE_ROOT);
partitionMap.put (NODE_ID, SEQUENCE_ROOT);
}
```
```
public static synchronized long generateId () {
// 获取当前节点的序列号
sequence = (sequence + 1 ) & SEQUENCE_ROOT;
if (sequence == 0 ) {
// 如果序列号溢出，则从上一次生成的 ID 开始
sequence = partitionMap.get (PARTITION_ID);
if (sequence == SEQUENCE_ROOT) {
// 如果分区 ID 溢出，则从最大 ID 开始
sequence = partitionMap.get (NODE_ID);
if (sequence == SEQUENCE_ROOT) {
// 如果节点 ID 溢出，则从最大 ID 开始
sequence = SEQUENCE_ROOT;
}
}
}
// 获取当前时间的毫秒数
long now = System.currentTimeMillis () / 1000 ;
// 计算 ID
long id = ((now - TIMESTAMP) << SHIFT) | (MACHINE_ID << SCALE) |
(sequence << SEQUENCE_SHIFT) | lastId;
// 如果 ID 溢出，则从最大 ID 开始
if (id > MAX_ID) {
id = SEQUENCE_ROOT;
}
// 更新上一次生成的 ID
lastId = id;
// 更新分区 ID 和节点 ID 的映射
partitionMap.put (PARTITION_ID, partitionMap.get (PARTITION_ID) +
PARTITION_SIZE);
partitionMap.put (NODE_ID, partitionMap.get (NODE_ID) + PARTITION_SIZE);
// 返回 ID
return id;
}
}
```

**一、XSS 跨站脚本攻击**

XSS 攻击是指攻击者通过在受信任的网页上注入恶意脚本，使得脚本在用户浏览器中执行，从而窃取用
户敏感信息、劫持会话或执行其他恶意行为。XSS 攻击的原理是利用网页中的漏洞，将攻击者的恶意脚
本注入到网页中，然后当用户浏览该网页时，浏览器会执行该恶意脚本。

解决 XSS 攻击的方法包括：

```
输入验证：对用户输入的数据进行有效性验证，过滤掉无效或恶意的输入。
输出过滤：在输出用户输入数据到网页上之前，对数据进行过滤，去掉其中的恶意脚本代码。
安全编码：使用安全的编码方式，避免在网页中嵌入恶意脚本。
浏览器安全设置：设置浏览器的安全选项，禁用或限制脚本执行，阻止 XSS 攻击。
```
**二、CSRF 跨站请求伪造**

CSRF 攻击是指攻击者通过伪造用户的请求，向网站服务器发送恶意请求，从而操纵用户账户或执行其
他恶意行为。CSRF 攻击的原理是利用网站应用程序中的漏洞，绕过网站的安全验证机制，以用户的身
份执行恶意请求。

解决 CSRF 攻击的方法包括：

```
添加 token：在请求中添加一个随机生成的 token，服务器验证该 token 是否合法，以判断请求是
否来自合法用户。
采用 POST 方法：使用 POST 方法提交表单，因为 POST 方法不能被缓存，从而避免 CSRF 攻击。
限制 HTTP 方法：对网站应用程序进行安全配置，限制允许使用的 HTTP 方法，禁止使用 GET、
POST 等可被伪造的方法。
```
**三、DDoS 分布式拒绝服务攻击**

DDoS 攻击是指攻击者通过控制大量僵尸主机，向目标主机发送海量流量，从而瘫痪目标主机或使其服
务不可用。DDoS 攻击的原理是通过大量流量消耗目标主机的带宽和资源，使其无法正常提供服务。

解决 DDoS 攻击的方法包括：

```
流量清洗：使用流量清洗设备对入侵流量进行过滤和清洗，阻断攻击流量。
负载均衡：使用负载均衡设备，将攻击流量分发到多个服务器上，减轻目标服务器的压力。
扩大带宽：增加网络带宽，提高网络容量，使攻击流量无法占据主导地位。
关闭不必要服务：关闭不必要的服务，减少攻击目标，从而降低攻击效果。
```
**四、SQL 注入**

SQL 注入攻击是指攻击者通过在 Web 应用程序的输入框中注入恶意 SQL 语句，从而获取未授权的访问
权限或窃取敏感数据。SQL 注入攻击的原理是利用应用程序中的漏洞，将恶意 SQL 语句插入到 SQL 查
询语句中，从而操纵数据库。

```
1. 输入验证 ：对用户输入的数据进行有效性验证，过滤掉无效或恶意的输入。可以使用正则表达式、
字符串匹配等方法对输入数据进行过滤，确保输入数据的合法性和准确性。
2. 参数化查询 ：使用参数化查询，避免将用户输入的数据直接拼接到 SQL 查询语句中。参数化查询
可以将用户输入的数据与 SQL 语句分离，从而避免 SQL 注入漏洞。在 Java 中，可以使用
PreparedStatement 语句进行参数化查询。
3. 预编译语句 ：使用预编译语句进行预处理，可以将 SQL 语句和参数分离，从而避免 SQL 注入漏
洞。预编译语句可以在第一次执行时编译成机器码，后续执行时直接使用机器码执行，提高了执行
效率。在 Java 中，可以使用 PreparedStatement 语句进行预编译。
4. Mybatis 映射语句 ：在 Mybatis 映射语句中，使用#{xxx}而不是${}来表示参数。这样可以避免将
用户输入的数据直接拼接到 SQL 查询语句中，从而避免 SQL 注入漏洞。在 Mybatis 中，可以使用
#{param 1}, #{param 2}等语法来表示参数。
```

```
5. 访问控制 ：对数据库的访问进行严格的权限控制，禁止未经授权的用户访问敏感数据。可以使用数
据库的访问控制机制，如 ACL、RLS 等，对数据库的访问进行限制。此外，可以在应用程序中对用
户进行身份验证和授权，确保只有授权用户可以访问敏感数据。
6. 数据加密 ：对敏感数据进行加密，防止数据泄露，即使被攻击者窃取也无法获取明文数据。可以使
用加密算法，如 AES、SSL 等，对敏感数据进行加密。在 Java 中，可以使用 Java 加密算法或第三
方加密库进行加密。
```
###### 10 、平时在开发接口或者设计项目的时候如何保证安全性的

小伙伴从以下 8 个维度去 "吹牛"，吹到面试官 "口水直流，不能自已"

```
1. 签名和加密 ：确保数据在传输过程中不被篡改或窃取，可以使用签名和加密技术。签名可以确保数
据的完整性和真实性，而加密可以确保数据的保密性。常用的签名算法有 SHA-256、SHA-3 等，
加密算法有 AES、RSA 等。
2. IP 检测和限流 ：通过检测请求的 IP 地址，可以实现访问控制和限流。例如，可以限制某个 IP 地
址的请求次数或限制某个 IP 地址的访问权限。这可以帮助防止 DDoS 攻击和其他恶意行为。
3. 接口幂等性 ：确保接口在多次调用下不会产生副作用，可以实现接口的幂等性。例如，在处理支付
接口时，可以确保同一个订单多次支付不会产生重复扣款。
4. 特殊字符过滤 ：通过过滤特殊字符，可以防止 XSS 和 SQL 注入攻击。例如，可以过滤掉单引号、
双引号、斜杠等特殊字符，避免攻击者通过注入恶意代码来执行攻击。
5. 防止 CSRF 攻击 ：CSRF 攻击是一种利用用户浏览器发起恶意请求的攻击方式。为了防止 CSRF 攻
击，可以使用 token 技术，即在客户端生成一个随机的 token，在请求时将其发送给服务器，服
务器验证 token 的合法性，从而确保请求是合法的。
6. 防止 XSS 攻击 ：可以使用过滤器来过滤掉一些可能会导致 XSS 攻击的特殊字符或代码，例如反斜
杠、单引号等。
7. SQL 注入的攻击 ：可以使用预编译语句或者参数化查询来防止 SQL 注入的攻击，从而保护数据库的
数据安全。
8. 输入验证 ：在接收用户输入时，需要对输入进行验证，确保输入的格式和内容是合法的。例如，可
以验证输入的数字范围、字符长度等，避免因为输入不合法而导致的安全漏洞。
```
###### 11 、使用 Redis 集群时可能会存在什么问题

小伙伴从以下 7 个维度去 "吹牛"，吹到面试官 "口水直流，不能自已"

```
首先，数据一致性问题
其次，性能问题
再次：可用性问题
再次：负载均衡问题
再次：网络延迟问题
再次：节点故障问题
最后，安全问题
```
**一、数据一致性问题**


在 Redis 集群中，当多个节点同时进行写操作时，可能会导致数据不一致。例如，当节点 A 和节点 B
同时尝试向同一个 key 写入数据时，如果节点 A 先写入成功，而节点 B 的后写入操作失败，则导致该
key 的数据在节点 A 和节点 B 上不一致。为了解决这个问题，可以使用 Redis 集群的主节点来协调多个
节点之间的数据写入操作，确保数据的一致性。

**解决方法** ：

```
使用主节点进行写操作协调 ：所有写操作必须经过主节点协调，由主节点分配节点进行写操作，并
确保所有节点写操作的顺序和一致性。这样可以保证数据的一致性，但会增加主节点的负担，降低
性能。
使用分布式锁 ：在写操作之前，节点需要获取分布式锁，以确保在该节点完成写操作之前，其他节
点无法进行写操作。这样可以避免多个节点同时进行写操作导致的数据不一致问题。然而，分布式
锁可能会带来性能瓶颈，因为锁的竞争可能会导致节点之间的延迟。
```
**二、性能问题**

在使用 Redis 集群时，可能会出现性能瓶颈。例如，当集群中的某个节点出现网络延迟或负载过高时，
可能会导致整个集群的性能下降。此外，由于 Redis 集群需要进行数据同步和协调，因此可能会增加额
外的延迟和开销，从而影响集群的性能。

**解决方法** ：

```
增加节点数量 ：通过增加节点数量来提高集群的性能和吞吐量。更多的节点意味着更多的计算和存
储资源，可以更好地支持并发访问和数据处理。
优化网络拓扑结构 ：通过优化网络拓扑结构，例如使用高速网络、增加网络带宽、使用负载均衡器
等，来提高集群的性能和吞吐量。
优化 Redis 配置 ：通过调整 Redis 的配置参数，例如调整缓存大小、调整持久化策略、优化数据
库文件等，来提高集群的性能和吞吐量。
```
**三、可用性问题**

在使用 Redis 集群时，如果某个节点出现故障或宕机，可能会导致整个集群的不可用。

**解决方法** ：

需要使用 Redis 集群的高可用性机制来确保集群的可用性，例如使用多个节点进行数据冗余和备份，以
便在节点故障或宕机时能够自动切换到备用节点。

可以通过以下两种方式来实现：

```
数据冗余备份 ：在 Redis 集群中，可以将数据备份到多个节点上，以确保在节点故障或宕机时，
仍有其他节点可以提供数据服务。
故障转移 ：在 Redis 集群中，可以使用故障转移机制，将故障节点的服务切换到其他节点上，以
确保集群的可用性。故障转移可以通过主节点检测节点状态，或者通过心跳机制实现。
```
**四、负载均衡问题**

在 Redis 集群中，每个节点都需要承担一定的负载，如果负载不均衡，可能会导致某些节点的负载过
高，影响系统的性能。

**解决方法** ：

可以使用 Redis Cluster 来解决负载均衡问题。Redis Cluster 会根据节点的负载情况，自动地将负载较高
的节点上的数据转移到负载较低的节点上，从而实现负载均衡。

**五、网络延迟问题**


在 Redis 集群中，节点之间的通信需要通过网络进行，如果网络延迟过高，可能会导致数据的延迟，影
响系统的性能。

**解决方法** ：

可以使用 Redis Cluster 来解决网络延迟问题。Redis Cluster 会根据节点之间的网络延迟情况，自动地将
数据转移到网络延迟较低的节点上，从而降低数据的延迟。

**六、节点故障问题**

在 Redis 集群中，如果某个节点发生故障，可能会导致数据的不一致性或者系统的不可用性。

**解决方法** ：

可以使用 Redis Cluster 来解决节点故障问题。Redis Cluster 会自动地将故障节点上的数据转移到其他节
点上，保证数据的一致性和系统的可用性。

**七、安全问题**

在 Redis 集群中，数据的安全性也是一个问题，如果节点的安全性受到攻击，可能会导致数据的泄露或
者被篡改。因此，在使用 Redis 集群时，需要注意数据的安全性，并采取相应的安全措施。

**解决方法** ：

可以使用 Redis Cluster 来解决安全问题。Redis Cluster 会对节点的安全性进行监控，并采取相应的安全
措施，例如限制节点的访问权限、加密数据等，从而保证数据的安全性。

###### 12 、有没有了解过 cap 和 base 原则

小伙伴从以下 8 个维度去 "吹牛"，吹到面试官 "口水直流，不能自已"

```
首先，CAP 理论
其次，CAP 理论的一致性 (C：Consistency)
再次：CAP 理论的可用性 (A：Availability)
再次：CAP 理论的分区容错性（P：Partition tolerance）
再次：BASE 理论
再次：BASE 理论的 Basically Available
再次：BASE 理论的 Soft State
最后，BASE 理论的 Eventually Consistent
```
**一、CAP 理论**

CAP 理论作为分布式系统的基础理论，指的是在一个分布式系统中， Consistency（一致性）、
Availability（可用性）、Partition tolerance（分区容错性），这三个要素最多只能同时实现两点。

**一致性 (C：Consistency)：**

一致性是指数据在多个副本之间能否保持一致的特性。例如一个数据在某个分区节点更新之后，在其他
分区节点读出来的数据也是更新之后的数据。

**可用性 (A：Availability)：**


```
选择说明
```
```
CA 放弃分区容错性，加强一致性和可用性，其实就是传统的单机数据库的选择
```
```
AP 放弃一致性，分区容错性和可用性，这是很多分布式系统设计时的选择
```
```
CP 放弃可用性，追求一致性和分区容错性，网络问题会直接让整个系统不可用
```
可用性是指系统提供的服务必须一直处于可用的状态，对于用户的每一个操作请求总是能够在有限的时
间内返回结果。这里的重点是"有限时间内"和"返回结果"。

**分区容错性（P: Partition tolerance）:**

分布式系统在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务。

**二、BASE 理论**

BASE 理论，是对 CAP 中 AP 的一个扩展，对于我们的业务系统，我们考虑牺牲一致性来换取系统的可用
性和分区容错性。BASE 是 Basically Available (基本可用)，Soft state（软状态）, 和 Eventually
consistent（最终一致性）三个短语的缩写。

**Basically Available**

基本可用：通过支持局部故障而不是系统全局故障来实现的。如将用户分区在 5 个数据库服务器上，一
个用户数据库的故障只影响这台特定主机那 20% 的用户，其他用户不受影响。

**Soft State**

软状态，状态可以有一段时间不同步

**Eventually Consistent**

最终一致，最终数据是一致的就可以了，而不是时时保持强一致。

###### 13 、zk 是如何保证一致性的

小伙伴从以下 4 个维度去 "吹牛"，吹到面试官 "口水直流，不能自已"

```
首先，ZAB 协议（Zookeeper 原子消息广播协议）
其次，选主
再次：选主后的数据同步
再次：事务操作
```
**一：ZAB 协议（Zookeeper 原子消息广播协议）**

zookeeper 实现数据一致性的核心是 ZAB 协议（Zookeeper 原子消息广播协议）。该协议需要做到以下
几点：

（ 1 ）集群在半数以下节点宕机的情况下，能正常对外提供服务；


（ 2 ）客户端的写请求全部转交给 leader 来处理，leader 需确保写变更能实时同步给所有 follower 及
observer；

（ 3 ）leader 宕机或整个集群重启时，需要确保那些已经在 leader 服务器上提交的事务最终被所有服务
器都提交，确保丢弃那些只在 leader 服务器上被提出的事务，并保证集群能快速恢复到故障前的状态。

Zab 协议有两种模式，崩溃恢复（选主+数据同步）和消息广播（事务操作）。

任何时候都需要保证只有一个主进程负责进行事务操作，而如果主进程崩溃了，就需要迅速选举出一个
新的主进程。主进程的选举机制与事务操作机制是紧密相关的。

下面详细讲解这三个场景的协议规则，从细节去探索 ZAB 协议的数据一致性原理。

**二、选主**

leader 选举是 zk 中最重要的技术之一，也是保证分布式数据一致性的关键所在。当集群中的一台服务器
处于如下两种情况之一时，就会进入 leader 选举阶段——服务器初始化启动、服务器运行期间无法与
leader 保持连接。

选举阶段，集群间互传的消息称为投票，投票 Vote 主要包括二个维度的信息：ID、ZXID

```
ID 被推举的 leader 的服务器 ID，集群中的每个 zk 节点启动前就要配置好这个全局唯一的 ID。
ZXID 被推举的 leader 的事务 ID ，该值是从机器 DataTree 内存中取的，即事务已经在机器上被
commit 过了。
```
节点进入选举阶段后的大体执行逻辑如下：

（ 1 ）设置状态为 LOOKING，初始化内部投票 Vote (id, zxid) 数据至内存，并将其广播到集群其它节点。
节点首次投票都是选举自己作为 leader，将自身的服务 ID、处理的最近一个事务请求的 ZXID（ZXID 是从
内存数据库里取的，即该节点最近一个完成 commit 的事务 id）及当前状态广播出去。然后进入循环等
待及处理其它节点的投票信息的流程中。

（ 2 ）循环等待流程中，节点每收到一个外部的 Vote 信息，都需要将其与自己内存 Vote 数据进行 PK，规
则为取 ZXID 大的，若 ZXID 相等，则取 ID 大的那个投票。若外部投票胜选，节点需要将该选票覆盖之前
的内存 Vote 数据，并再次广播出去；同时还要统计是否有过半的赞同者与新的内存投票数据一致，无则
继续循环等待新的投票，有则需要判断 leader 是否在赞同者之中，在则退出循环，选举结束，根据选举
结果及各自角色切换状态，leader 切换成 LEADING、follower 切换到 FOLLOWING、observer 切换到
OBSERVING 状态。

算法细节可参照 FastLeaderElection.lookForLeader ()，主要有三个线程在工作：选举线程（主动调用
lookForLeader 方法的线程，通过阻塞队列 sendqueue 及 recvqueue 与其它两个线程协作）、
WorkerReceiver 线程（选票接收器，不断获取其它服务器发来的选举消息，筛选后会保存到 recvqueue
队列中。zk 服务器启动时，开始正常工作，不停止）以及 WorkerSender 线程（选票发送器，会不断地
从 sendqueue 队列中获取待发送的选票，并广播至集群）。WorkerReceiver 线程一直在工作，即使当
前节点处于 LEADING 或者 FOLLOWING 状态，它起到了一个过滤的作用，当前节点为 LOOKING 时，才
会将外部投票信息转交给选举线程处理；如果当前节点处于非 LOOKING 状态，收到了处于 LOOKING 状
态的节点投票数据（外部节点重启或网络抖动情况下），说明发起投票的节点数据跟集群不一致，这
时，当前节点需要向集群广播出最新的内存 Vote (id，zxid)，落后节点收到该 Vote 后，会及时注册到
leader 上，并完成数据同步，跟上集群节奏，提供正常服务。

**三、选主后的数据同步**

选主算法中的 zxid 是从内存数据库中取的最新事务 id，事务操作是分两阶段的（提出阶段和提交阶
段），leader 生成提议并广播给 followers，收到半数以上的 ACK 后，再广播 commit 消息，同时将事务
操作应用到内存中。


follower 收到提议后先将事务写到本地事务日志，然后反馈 ACK，等接到 leader 的 commit 消息时，才会
将事务操作应用到内存中。可见，选主只是选出了内存数据是最新的节点，仅仅靠这个是无法保证已经
在 leader 服务器上提交的事务最终被所有服务器都提交。比如 leader 发起提议 P 1, 并收到半数以上
follower 关于 P 1 的 ACK 后，在广播 commit 消息之前宕机了，选举产生的新 leader 之前是 follower，未收
到关于 P 1 的 commit 消息，内存中是没有 P 1 的数据。而 ZAB 协议的设计是需要保证选主后，P 1 是需要应
用到集群中的。这块的逻辑是通过选主后的数据同步来弥补。

选主后，节点需要切换状态，leader 切换成 LEADING 状态后的流程如下：

（ 1 ）重新加载本地磁盘上的数据快照至内存，并从日志文件中取出快照之后的所有事务操作，逐条应
用至内存，并添加到已提交事务缓存 commitedProposals。这样能保证日志文件中的事务操作，必定会
应用到 leader 的内存数据库中。

（ 2 ）获取 learner 发送的 FOLLOWERINFO/OBSERVERINFO 信息，并与自身 commitedProposals 比
对，确定采用哪种同步方式，不同的 learner 可能采用不同同步方式（DIFF 同步、TRUNC+DIFF 同步、
SNAP 同步）。这里是拿 learner 内存中的 zxid 与 leader 内存中的 commitedProposals（min、max）比
对，如果 zxid 介于 min 与 max 之间，但又不存在于 commitedProposals 中时，说明该 zxid 对应的事务需
要 TRUNC 回滚；如果 zxid 介于 min 与 max 之间且存在于 commitedProposals 中，则 leader 需要将
zxid+1~max 间所有事务同步给 learner，这些内存缺失数据，很可能是因为 leader 切换过程中造成
commit 消息丢失，learner 只完成了事务日志写入，未完成提交事务，未应用到内存。

（ 3 ）leader 主动向所有 learner 发送同步数据消息，每个 learner 有自己的发送队列，互不干扰。同步结
束时，leader 会向 learner 发送 NEWLEADER 指令，同时 learner 会反馈一个 ACK。当 leader 接收到来自
learner 的 ACK 消息后，就认为当前 learner 已经完成了数据同步，同时进入“过半策略”等待阶段。当
leader 统计到收到了一半已上的 ACK 时，会向所有已经完成数据同步的 learner 发送一个 UPTODATE 指
令，用来通知 learner 集群已经完成了数据同步，可以对外服务了。

细节可参照 Leader.lead () 、Follower.followLeader () 及 LearnerHandler 类。

**四、事务操作**

ZAB 协议对于事务操作的处理是一个类似于二阶段提交过程。

针对客户端的事务请求，leader 服务器会为其生成对应的事务 proposal，并将其发送给集群中所有
follower 机器，然后收集各自的选票，最后进行事务提交。

流程如下图。


ZAB 协议的二阶段提交过程中，移除了中断逻辑（事务回滚），所有 follower 服务器要么正常反馈
leader 提出的事务 proposal，要么就抛弃 leader 服务器。follower 收到 proposal 后的处理很简单，将该
proposal 写入到事务日志，然后立马反馈 ACK 给 leader，也就是说如果不是网络、内存或磁盘等问题，
follower 肯定会写入成功，并正常反馈 ACK。leader 收到过半 follower 的 ACK 后，会广播 commit 消息给
所有 follower，并将事务应用到内存；follower 收到 commit 消息后会将事务应用到内存。

ZAB 协议中多次用到“过半”设计策略，该策略是 zk 在 A（可用性）与 C（一致性）间做的取舍，也是 zk 具
有高容错特性的本质。相较分布式事务中的 2 PC（二阶段提交协议）的“全量通过”，ZAB 协议可用性更
高（牺牲了部分一致性），能在集群半数以下服务宕机时正常对外提供服务。

###### 14 、你如何设计一个能抗住大流量的系统，说说设计方案

小伙伴说，他是参考《尼恩 Java 面试宝典》中架构设计面试专题吹的，面试官非常满意

###### 15 、有没有了解过缓存策略有哪些

小伙伴从以下 3 个维度去 "吹牛"，吹到面试官 "口水直流，不能自已"

```
首先，Cache Aside（旁路缓存）策略
其次，Read/Write Through（读穿 / 写穿）策略
再次：Write Back（写回）策略
```
**一、Cache Aside（旁路缓存）策略**

我们可以在更新数据时不更新缓存，而是删除缓存中的数据，在读取数据时，发现缓存中没了数据之
后，再从数据库中读取数据，更新到缓存中。

缓存读写过程


这个策略就是我们使用缓存最常见的策略，Cache Aside 策略（也叫旁路缓存策略），这个策略数据以
数据库中的数据为准，缓存中的数据是按需加载的。它可以分为读策略和写策略，

**读策略的步骤是：**

从缓存中读取数据；

如果缓存命中，则直接返回数据；

如果缓存不命中，则从数据库中查询数据；

查询到数据后，将数据写入到缓存中，并且返回给用户。

**写策略的步骤是：**

更新数据库中的记录；

删除缓存记录。

**注意**

Cache Aside 存在的最大的问题是当写入比较频繁时，缓存中的数据会被频繁地清理，这样会对缓存的
命中率有一些影响。如果你的业务对缓存命中率有严格的要求，那么可以考虑两种解决方案：

```
1. 一种做法是在更新数据时也更新缓存，只是在更新缓存前先加一个分布式锁，因为这样在同一时间
只允许一个线程更新缓存，就不会产生并发问题了。当然这么做对于写入的性能会有一些影响；
2. 另一种做法同样也是在更新数据时更新缓存，只是给缓存加一个较短的过期时间，这样即使出现缓
存不一致的情况，缓存的数据也会很快过期，对业务的影响也是可以接受。
```
**二、Read/Write Through（读穿 / 写穿）策略**

这个策略的核心原则是用户只与缓存打交道，由缓存和数据库通信，写入或者读取数据。这就好比你在
汇报工作的时候只对你的直接上级汇报，再由你的直接上级汇报给他的上级，你是不能越级汇报的。

Write Through 的策略是这样的：先查询要写入的数据在缓存中是否已经存在，如果已经存在，则更新
缓存中的数据，并且由缓存组件同步更新到数据库中，如果缓存中数据不存在，我们把这种情况叫做
“Write Miss（写失效）”。

一般来说，我们可以选择两种“Write Miss”方式：一个是“Write Allocate（按写分配）”，做法是写入缓
存相应位置，再由缓存组件同步更新到数据库中；另一个是“No-write allocate（不按写分配）”，做法
是不写入缓存中，而是直接更新到数据库中。

在 Write Through 策略中，我们一般选择“No-write allocate”方式，原因是无论采用哪种“Write Miss”
方式，我们都需要同步将数据更新到数据库中，而“No-write allocate”方式相比“Write Allocate”还减少
了一次缓存的写入，能够提升写入的性能。

Read Through 策略就简单一些，它的步骤是这样的：先查询缓存中数据是否存在，如果存在则直接返
回，如果不存在，则由缓存组件负责从数据库中同步加载数据。

下面是 Read Through/Write Through 策略的示意图：


Read/Write Through 策略示意图

Read Through/Write Through 策略的特点是由缓存节点而非用户来和数据库打交道，在我们开发过程
中相比 Cache Aside 策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是 Memcached
还是 Redis 都不提供写入数据库，或者自动加载数据库中的数据的功能。而我们在使用本地缓存的时候
可以考虑使用这种策略，比如说在上一节中提到的本地缓存 Guava Cache 中的 Loading Cache 就有
Read Through 策略的影子。

我们看到 Write Through 策略中写数据库是同步的，这对于性能来说会有比较大的影响，因为相比于写
缓存，同步写数据库的延迟就要高很多了。那么我们可否异步地更新数据库？这就是我们接下来要提到
的“Write Back”策略。

**三、Write Back（写回）策略**

这个策略的核心思想是在写入数据时只写入缓存，并且把缓存块儿标记为“脏”的。而脏块儿只有被再次
使用时才会将其中的数据写入到后端存储中。

**需要注意的是** ，在“Write Miss”的情况下，我们采用的是“Write Allocate”的方式，也就是在写入后端存
储的同时要写入缓存，这样我们在之后的写请求中都只需要更新缓存即可，而无需更新后端存储了，我
将 Write back 策略的示意图放在了下面：


Write Back 写回策略示意图

如果使用 Write Back 策略的话，读的策略也有一些变化了。

我们在读取缓存时如果发现缓存命中则直接返回缓存数据。如果缓存不命中则寻找一个可用的缓存块
儿，如果这个缓存块儿是“脏”的，就把缓存块儿中之前的数据写入到后端存储中，并且从后端存储加载
数据到缓存块儿，如果不是脏的，则由缓存组件将后端存储中的数据加载到缓存中，最后我们将缓存设
置为不是脏的，返回数据就好了。


其实这种策略不能被应用到我们常用的数据库和缓存的场景中，它是计算机体系结构中的设计，比如我
们在向磁盘中写数据时采用的就是这种策略。无论是操作系统层面的 Page Cache，还是日志的异步刷
盘，亦或是消息队列中消息的异步写入磁盘，大多采用了这种策略。因为这个策略在性能上的优势毋庸
置疑，它避免了直接写磁盘造成的随机写问题，毕竟写内存和写磁盘的随机 I/O 的延迟相差了几个数量
级呢。

但因为缓存一般使用内存，而内存是非持久化的，所以一旦缓存机器掉电，就会造成原本缓存中的脏块
儿数据丢失。所以你会发现系统在掉电之后，之前写入的文件会有部分丢失，就是因为 Page Cache 还
没有来得及刷盘造成的。


**当然，你依然可以在一些场景下使用这个策略，在使用时，我想给你的落地建议是** ：你在向低速设备写
入数据的时候，可以在内存里先暂存一段时间的数据，甚至做一些统计汇总，然后定时地刷新到低速设
备上。比如说，你在统计你的接口响应时间的时候，需要将每次请求的响应时间打印到日志中，然后监
控系统收集日志后再做统计。但是如果每次请求都打印日志无疑会增加磁盘 I/O，那么不如把一段时间
的响应时间暂存起来，经过简单的统计平均耗时，每个耗时区间的请求数量等等，然后定时地，批量地
打印到日志中。

**总结**

```
1. Cache Aside 是我们在使用分布式缓存时最常用的策略，你可以在实际工作中直接拿来使用。推荐
使用
2. Read/Write Through 和 Write Back 策略需要缓存组件的支持，所以比较适合你在实现本地缓存
组件的时候使用；
3. Write Back 策略是计算机体系结构中的策略，不过写入策略中的只写缓存，异步写入后端存储的
策略倒是有很多的应用场景。
```
## 参考文献

尼恩的系统架构知识图谱（一张价值 10 w 的系统架构知识图谱）

https://www.processon.com/view/link/60fb9421637689719d246739

尼恩的秒杀系统的架构

https://www.processon.com/view/link/61148c2b1e08536191d8f92f

## 尼恩说在最后

在尼恩的（50+）读者社群中，很多、很多小伙伴需要进大厂、拿高薪。

尼恩团队，会持续结合一些大厂的面试真题，给大家梳理一下学习路径，看看大家需要学点啥？

前面用多篇文章，给大家介绍阿里、百度、字节、滴滴的真题：

《炸裂，靠“吹牛”过京东一面，月薪 40 k》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《问懵了.... 美团一面索命 44 问，过了就 60 W+》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》


《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》

这些真题，都会收入到史上最全、持续升级的 PDF 电子书《尼恩 Java 面试宝典》。

本文收录于《尼恩 Java 面试宝典》。

基本上，把尼恩的《尼恩 Java 面试宝典》吃透，大厂 offer 很容易拿到滴。另外，下一期的大厂面经大
家有啥需求，可以发消息给尼恩。

## 推荐阅读

《百亿级访问量，如何做缓存架构设计》

《多级缓存架构设计》

《消息推送架构设计》

《阿里 2 面：你们部署多少节点？1000 W 并发，当如何部署？》

《美团 2 面： 5 个 9 高可用 99.999%，如何实现？》

《网易一面：单节点 2000 Wtps，Kafka 怎么做的？》

《字节一面：事务补偿和事务重试，关系是什么？》

《网易一面：25 Wqps 高吞吐写 Mysql，100 W 数据 4 秒写完，如何实现？》

《亿级短视频，如何架构？》

《炸裂，靠“吹牛”过京东一面，月薪 40 K》

《太猛了，靠“吹牛”过顺丰一面，月薪 30 K》

《炸裂了... 京东一面索命 40 问，过了就 50 W+》

《问麻了... 阿里一面索命 27 问，过了就 60 W+》

《百度狂问 3 小时，大厂 offer 到手，小伙真狠！》

《饿了么太狠：面个高级 Java，抖这多硬活、狠活》

《字节狂问一小时，小伙 offer 到手，太狠了！》

《收个滴滴 Offer：从小伙三面经历，看看需要学点啥？》



```
技术自由圈
```
## 未来职业，如何突围：三栖架构师


```
技术自由圈
```
### 成功案例： 2 年翻 3 倍， 35 岁卷王成功转型为架构师

详情：http://topcoder.cloud/forum.php?mod=forumdisplay&fid=43&page=1


技术自由圈


技术自由圈


技术自由圈


```
技术自由圈
```
### 硬核推荐：尼恩 Java 硬核架构班

详情：https://www.cnblogs.com/crazymakercircle/p/9904544.html


技术自由圈


```
技术自由圈
```
##### 架构班（社群 VIP）的起源：

最初的视频，主要是给读者加餐。很多的读者，需要一些高质量的实操、理论视频，所以，我就围绕书，和底层，做了几个
实操、理论视频，然后效果还不错，后面就做成迭代模式了。

##### 架构班（社群 VIP）的功能：^

提供高质量实操项目整刀真枪的架构指导、快速提升大家的:
⚫ 开发水平
⚫ 设计水平
⚫ 架构水平
弥补业务中 CRUD 开发短板，帮助大家尽早脱离具备 3 高能力，掌握：
⚫ 高性能
⚫ 高并发
⚫ 高可用
作为一个高质量的架构师成长、人脉社群，把所有的卷王聚焦起来，一起卷：
⚫ 卷高并发实操
⚫ 卷底层原理
⚫ 卷架构理论、架构哲学
⚫ 最终成为顶级架构师，实现人生理想，走向人生巅峰

##### 架构班（社群 VIP）的目的：^

⚫ 高质量的实操，大大提升简历的含金量，吸引力，增强面试的召唤率
⚫ 为大家提供九阳真经、葵花宝典，快速提升水平
⚫ 进大厂、拿高薪
⚫ 一路陪伴，提供助学视频和指导，辅导大家成为架构师
⚫ 自学为主，和其他卷王一起，卷高并发实操，卷底层原理、卷大厂面试题，争取狠卷 3 月成高手，狠卷 3 年成为顶级架
构师


```
技术自由圈
```
##### N 个超高并发实操项目：简历压轴、个顶个精彩


```
技术自由圈
```
【样章】第 17 章：横扫全网 Rocketmq 视频第 2 部曲: 工业级 rocketmq 高可用（HA）底层原
理和实操

工业级 rocketmq 高可用底层原理，包含：消息消费、同步消息、异步消息、单向消息等不同消息的底层原理和源码实现；
消息队列非常底层的主从复制、高可用、同步刷盘、异步刷盘等底层原理。
工业级 rocketmq 高可用底层原理和搭建实操，包含：高可用集群的搭建。
解决以下难题：
1 、技术难题：RocketMQ 如何最大限度的保证消息不丢失的呢？RocketMQ 消息如何做到高可靠投递？
2 、技术难题：基于消息的分布式事务，核心原理不理解
3 、选型难题： kafka or rocketmq ，该娶谁？
下图链接：https://www.processon.com/view/6178e8ae0e3e7416bde9da19


```
技术自由圈
```
### 简历优化后的成功涨薪案例（ VIP 含免费简历优化）


技术自由圈


技术自由圈


技术自由圈


技术自由圈


技术自由圈


技术自由圈


技术自由圈


```
技术自由圈
```
### 修改简历找尼恩（资深简历优化专家）

⚫ 如果面试表达不好，尼恩会提供简历优化指导

⚫ 如果项目没有亮点，尼恩会提供项目亮点指导

⚫ 如果面试表达不好，尼恩会提供面试表达指导

作为 40 岁老架构师，尼恩长期承担技术面试官的角色：

⚫ 从业以来，“阅历”无数，对简历有着点石成金、改头换面、脱胎换骨的指导能力。

⚫ 尼恩指导过刚刚就业的小白，也指导过 P 8 级的老专家，都指导他们上岸。

如何联系尼恩。尼恩微信，请参考下面的地址：

语雀：https://www.yuque.com/crazymakercircle/gkkw8s/khigna
码云：https://gitee.com/crazymaker/SimpleCrayIM/blob/master/疯狂创客圈总目录.md


