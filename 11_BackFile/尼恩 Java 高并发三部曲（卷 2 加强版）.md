```
疯狂创客圈^
```
## 牛逼的职业发展之路

40 岁老架构尼恩用一张图揭秘: Java 工程师的高端职业发展路径，走向食物链顶端的之路

链接：https://www.processon.com/view/link/618a2b62e0b34d73f7eb3cd


```
疯狂创客圈
```
## 史上最全：价值 10 W 的架构师知识图谱

此图梳理于尼恩的多个 3 高生产项目：多个亿级人民币的大型 SAAS 平台和智慧城市项目

链接：https://www.processon.com/view/link/60fb9421637689719d


```
疯狂创客圈
```
## 牛逼的架构师哲学

40 岁老架构师尼恩对自己的 20 年的开发、架构经验总结

链接：https://www.processon.com/view/link/616f801963768961e9d9aec


```
疯狂创客圈
```
## 牛逼的 3 高架构知识宇宙

尼恩 3 高架构知识宇宙，帮助大家穿透 3 高架构，走向技术自由，远离中年危机

链接：https://www.processon.com/view/link/635097d2e0b34d40be778ab


```
疯狂创客圈
```
## 尼恩 Java 高并发三部曲（卷 1 加强版）

老版本：《Java 高并发核心编程卷 1 ：NIO、Netty、Redis、ZooKeeper》（已经过时，不建
议购买）

###### 新版本：《Java 高并发核心编程卷 1 加强版 ：NIO、Netty、Redis、ZooKeeper》

 由浅入深地剖析了高并发 IO 的底层原理。

 图文并茂的介绍了 TCP、HTTP、WebSocket 协议的核心原理。

 细致深入地揭秘了 Reactor 高性能模式。

 全面介绍了 Netty 框架，并完成单体 IM、分布式 IM 的实战设计。

 详尽地介绍了 ZooKeeper、Redis 的使用，以帮助提升高并发、可扩展能力

详情：https://www.cnblogs.com/crazymakercircle/p/16868827.html


```
疯狂创客圈
```
## 尼恩 Java 高并发三部曲（卷 2 加强版）

老版本：《Java 高并发核心编程卷 2 ：多线程、锁、JMM、JUC、高并发设计模式》
（已经过时，不建议购买）

###### 新版本：《Java 高并发核心编程卷 2 加强版 ：多线程、锁、JMM、JUC、高并发设计模式》

 由浅入深地剖析了 Java 多线程、线程池的底层原理。

 总结了 IO 密集型、CPU 密集型线程池的线程数预估算法。

 图文并茂的介绍了 Java 内置锁、JUC 显式锁的核心原理。

 细致深入地揭秘了 JMM 内存模型。

 全面介绍了 JUC 框架的设计模式与核心原理，并完成其高核心组件的实战介绍。

 详尽地介绍了高并发设计模式的使用，以帮助提升高并发、可扩展能力

详情参阅：https://www.cnblogs.com/crazymakercircle/p/16868827.html


```
疯狂创客圈
```
## 尼恩 Java 高并发三部曲（卷 3 加强版）

老版本：《SpringCloud Nginx 高并发核心编程》（已经过时，不建议购买）

###### 新版本：《Java 高并发核心编程卷 3 加强版 ：亿级用户 Web 应用架构与实战》

 在当今的面试场景中， 3 高知识是大家面试必备的核心知识，本书基于亿级用户 3 高 Web 应用

```
的架构分析理论，为大家对 3 高架构系统做一个系统化和清晰化的介绍。
```
 从 Java 静态代理、动态代理模式入手，抽丝剥茧地解读了 Spring Cloud 全家桶中 RPC 核心原

```
理和执行过程，这是高级Java工程师面试必备的基础知识。
```
 从 Reactor 反应器模式入手，抽丝剥茧地解读了 Nginx 核心思想和各配置项的底层知识和原理，

```
这是高级Java工程师、架构师面试必备的基础知识。
```
 从观察者模式入手，抽丝剥茧地解读了 RxJava、Hystrix 的核心思想和使用方法，这也是高级

```
Java工程师、架构师面试必备的基础知识。
```
详情：https://www.cnblogs.com/crazymakercircle/p/16868827.html


```
疯狂创客圈
```
## 尼恩 Java 面试宝典

35 个专题（卷王专供+ 史上最全 + 2023 面试必备）
详情：https://www.cnblogs.com/crazymakercircle/p/13917138.html


## 本书封面


II | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式


## 本书前言

5 G 时代、物联网时代的大幕已经开启，新时代提升了对 Java 应用的高性能、高并发的要求，也
抬高了 Java 工程师的技术台阶和面试门槛。
很多公司的面试题从某个侧面反映了生产场景的技术要求。之前只有 BAT 等大公司才有高并发
技术相关的面试题，现在与 Java 项目相关的整个行业基本都涉及此类面试题。多线程、线程池、内
置锁、JMM、CAS、JUC、高并发设计模式等 Java 并发编程方面的面试题，从以前的加分题变成现
在的基础题。本书着重介绍 Java 并发编程基础知识，揭秘 Java 高并发编程的核心难题和解决方案。

#### 本书内容

本书是三卷本《Java 高并发核心编程》的第 2 卷，旨在帮助大家掌握 Java 高并发基础知识：多
线程、线程池、内置锁、JMM、CAS、JUC、高并发设计模式、Java 异步回调、CompletableFuture
类等。

第 1 章介绍线程的核心原理、线程的基本操作、线程池的核心原理、JUC 的线程池架构、 4 种快
捷创建线程池的方法。除此之外，还从生产实际的角度出发，介绍在生产场景中如何合理预估 3 类
线程池（IO 密集型、CPU 密集性、混合型）的线程数。
第 2 章基于生产者－消费者模式的实战案例介绍线程安全问题和 Java 内置锁的核心原理。首先
揭秘 Java 对象的存储布局、对象头的具体结构，并介绍如何用 JOL 工具查看对象的结构。然后介绍
synchronized 内置锁的核心原理，以及内置锁从偏向锁到轻量级锁再到重量级锁的升级过程。
第 3 章介绍 CAS 原理与 JUC 原子类，并解密在争用激烈的高并发场景下，如何提升 CAS 操作的
性能。最后揭秘 CAS 操作的弊端和两类规避措施。
第 4 章介绍 Java 并发编程的三大问题——原子性问题、可见性问题和有序性问题，阐述 JMM 的
核心原理，揭秘 Java 内存可见性和 volatile 关键字的底层知识。
第 5 章介绍 JUC 显式锁的原理与实战。首先介绍使用显式锁的正确方法、显式锁的分类，然后
揭秘 CAS 可能导致的“总线风暴”和 CLH 自旋锁，最后从实例出发介绍 JUC 中的可中断锁和不可中
断锁、共享锁与独占锁、读写锁。
第 6 章介绍 JUC 高并发的基础设施——AQS 抽象同步器的核心原理。本章从模板模式入手，抽
丝剥茧，层层深入，揭秘 AQS 的内部结构。然后结合 SimpleMockLock 独占锁的释放流程、
ReentrantLock 的抢锁流程，图文并茂地剖析释放、抢占 AQS 锁的源码和原理。
第 7 章介绍 JUC 容器类，包括 CopyOnWriteArrayList、BlockingQueue、ConcurrentHashMap 等高
并发容器类的原理和使用。
第 8 章介绍高并发设计模式，主要包括 Java 开发必须掌握的安全单例模式、Master-Worker 模式、
ForkJoin 模式、生产者－消费者模式、Future 模式。
第 9 章着重介绍高并发编程中经常用到的高并发设计模式——异步回调模式。
第 10 章介绍 Java 8 所提供的一个具备异步回调能力的新工具类——CompletableFuture 类的原理
和使用。


```
IV | Java高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式
```
```
以上内容是开发Java高并发应用所必备的知识，也是广大Java工程师必须掌握的高并发基础知识。
```
#### 读者对象

```
1 ）对Java编程感兴趣的大专院校学生。
2 ）Java工程师。
3 ）Java架构师。
```
#### 本书源代码下载

本书的源代码可以扫码右侧的二维码进行下载，若下载有问题，请发送
电子邮件至 booksaga@ 126 .com，邮件主题为“Java 高并发核心编程卷 2 （加
强版）下载资源”。

#### 勘误和支持

```
由于笔者水平和能力有限，书中不妥之处在所难免，希望读者批评指正。
```
#### 致谢

首先感谢卞诚君老师，没有他的指导和帮助，就不会有《Netty、Redis、ZooKeeper 高并发实战》
一书的面世，更不会有后续的本书。
然后感谢《Netty、Redis、ZooKeeper 高并发实战》一书的读者，是他们对该书的高度评价，极
大地提升了笔者的写作自信，激励笔者推出了三卷《Java 高并发核心编程》，本书为第 2 卷。
最后感谢“疯狂创客圈”社群中的小伙伴们，他们中有很多非常有前途的技术狂人，他们对 Java
高并发技术的狂热喜爱让笔者惊叹不已。技术狂人们也获得了丰厚的回报，比如专科毕业的第 76
号、第 453 号技术狂人，已经顺利走向技术自由，成为 P 7 级以上的技术专家，尤其是第 76 号卷王，
两年之内薪资涨 3 倍，可喜可贺。
欢迎大家进入“疯狂创客圈”社群积极“砸”问题，虽然有的技术难题笔者不一定能给出最佳
的解决方案，但坦诚、纯粹的技术交流，能让大家相互启发，产生技术灵感，拓展技术视野，并最
终提升技术水平。
尼恩
2022 年 8 月 25 日


## 自序

身边常常有小伙伴问我怎样提高 Java 技术水平。下面给两个简单的例子：
小伙伴 A（ 6 年经验）说：尼恩，使用 Java 编程时，我在思路和速度上都赶不上小伙伴 B（ 5 年
经验），尤其是在解决复杂问题的时候，我该怎么办？
小伙伴 C（ 12 年经验）说：尼恩，我司刚刚引进了一位高薪的 Java 核心架构师，他的薪酬挺令
人心动的，如何才能提高我的 Java 技术水平，成为核心架构师呢？

遇到这类问题，我一概回答：“多读书、多画图、多实操。就目前看来，这是一条快捷、经济、
有效地提高 Java 水平的途径。”
为什么这么说呢？首先，以我本人为例，身为核心架构师，我在技术能力方面早已得到团队认
可，在团队内长期居于 Bug 排除榜前列，专门负责解决复杂、困难的技术问题。实际上，方法很简
单，就是多阅读专业图书，我家里的技术书都可以用汗牛充栋来形容了。其次，给大家简单地分析
一下具体原因。目前学习技术的途径大致有三种：（ 1 ）阅读博文；（ 2 ）观看视频；（ 3 ）阅读图
书。通过途径 1 （阅读博文）获得的知识往往过于碎片化，难成系统。这种途径更适用于了解技术
趋势、解决临时的技术问题。通过途径 2 （观看视频）获取知识需要耗费大量的时间，而且很多视
频是填鸭式的知识灌输。所以，途径 2 更适用于初学者，或者用于掌握某个完整的知识体系。对于
有经验、能动性高的 Java 工程师来说，途径 2 不足之处在于效率太低、时间成本高。通过途径 3 （阅
读图书）获取知识有一个显著的优势：图书能以很小的体积承载巨量知识，而且所承载的是系统化、
层次化的知识。
上述三种途径各有优劣，鉴于 Java 高并发所涉及的核心技术比较多，包括 SpringCloud、Netty、
Nginx、JUC、JMM、Kafka、ElasticSearch 等，我将结合博文、视频、图书三种形式，为大家提供
一个立体的、全方位的 Java 高并发核心编程知识仓库。在“疯狂创客圈”（我发起的 Java 高并发
交流社群）中，将规划的图书整合成一个高并发核心编程的图书系列，大致清单如下：

1 ）《Java 高并发核心编程卷 1 （加强版）：NIO、Netty、Redis、ZooKeeper》：从操作系统
底层 IO 模式和原理、Reactor 高并发 IO 模式入手，介绍 Java 分布式、高并发通信原理，并指导大家进
行高并发 IM 实战。
卷 1 详细介绍 Reactor 模式、Netty、ZooKeeper、Redis、TCP、HTTP、WebSocket、NIO 等 Java
高性能通信的核心原理和编程知识，并指导大家编写一个高并发的分布式 IM 实战程序——CrazyIM。
2 ）《Java 高并发核心编程卷 2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式》：
聚焦 Java 高并发基础知识，内容包括多线程、线程池、JMM 内存模型、JUC 并发包、AQS 同步器、
高并发容器类、高并发设计模式等。
卷 2 为大家建立高并发、高性能 Java 应用的底层知识体系，是本系列图书中最为基础、最为核
心的一卷书。
3 ）《Java 高并发核心编程卷 3 （加强版）：亿级用户 Web 应用架构与实战》：从亿级用户的


```
VI | Java高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式
```
Web 应用架构入手，介绍高架构所涉及的理论知识体系和核心实操知识，涵盖 SpringCloud、Nginx
的核心原理和编程知识，并指导大家编写一个高并发的秒杀实战程序。
卷 3 通过高并发架构的介绍和实操指导，引导大家建立架构师知识框架体系，并且指导大家做
一些架构师必备的实操。

本书是《Java 高并发核心编程卷 2 》的加强版。自《Java 高并发核心编程卷 2 》初版后的一年
半以来，在和广大读者小伙伴的答疑、交流过程中，以及在对 Java 顶级高并发组件的研究过程中，
尼恩对《Java 高并发核心编程卷 2 》的内容进行了大量的修订、完善、充实，要点内容如下：

1 ）增加、扩展了 ThreadLocal 的内容。增加了 Netty 的 FastThreadLocal 和 ThreadLocal 1. 7 / 1. 8 之间
本质区别的内容，并对 ThreadLocal 1. 7 / 1. 8 、FastThreadLocal 三大本地变量的内部结构做了对比介
绍，以帮助大家了解什么是高性能版本的 ThreadLocal。
2 ）更新了 JMM 中 volatile 语义上的四个内存屏障。更新之后，逻辑更加清晰，并且还提供了快
速记忆的技巧。例如，“JMM 中 volatile 如何保障可见性，涉及哪些内存屏障？”是 Java 高并发相关
职位面试时的核心问题（也是难题）之一。新的内容能够帮忙大家快速地掌握和记忆 volatile 语义，
相应的面试难题也就迎刃而解了。
3 ）新增了 JVM 的全局安全点原理和偏向锁撤销的性能问题方面的内容。这个也是面试的重点、
难点。读完此版本，大家对 JVM 的全局安全点、线程的安全点、偏向锁撤销的 STW 停顿的原理，
应该会有一个非常深入的了解。
4 ）更新了偏向锁、轻量级锁的部分内容。新增的内容对 MarkWord 在偏向锁、轻量级锁、重
量级锁三大场景下的备份机制做了细化和深入的对比与区分。这是超级难点，是很多小伙伴模糊不
清的地方。读完此版本，大家将对锁记录的用途，以及为啥偏向锁不需要锁记录等问题有更深刻的
记忆。
5 ）新增了如何对 volatile 变量的写入进行性能优化的内容。这个技巧是开发高性能组件的必备
技巧，Netty、JCTool 等组件中有大量的应用。此版本深入剖析了 volatile 变量写入时的低性能的根
本原理，并介绍了性能优化措施。

编写 Java 高并发核心编程系列图书的初衷是为大家奉上一系列有关 Java 高并发方面的“原理
级”“思想级”的图书，帮助大家轻松、切实、快捷地获取 Java 高并发核心知识，从而稳固自己
的知识底盘，提升自己的开发内功。
由于书的篇幅有限，高并发知识体系又非常庞大，所以，笔者还编写了大量博客文章作为本书
的配套知识和补充知识，具体的博客，请加“疯狂创客圈”社群获取。

```
尼 恩
2022 年 9 月 26 日
```

# 第 1 章多线程原理与实战

```
在学习多线程之前，先介绍笔者经历过的两个有意思的面试小故事。
```
#### 1. 1 两个技术面试故事

笔者作为核心架构师、技术主管经常组织技术面试，期间遇到过很多候选人，发生过很多有
意思的小故事。

1 .面试故事之一
候选人是一位至少有着 6 年以上开发经验、毕业于某二本院校计算机专业、看上去非常老练的
Java 高级工程师，简称 L 君。L 君所应聘的岗位是一个网络设备配置管理类项目的 MDE（模块设计
师、Java 主程）。该项目的特点是：有着 8 年历史代码积累，反复地修修补补，项目代码量庞大，
并且有着 18 %以上的重复代码率，模块之间的耦合度非常高。所以，该项目迫切需要进行架构解耦，
想找一位有开发基础扎实、擅长进行模块解耦的 MDE。
为了考察 L 君的编程水平，笔者先给 L 君上了一道正餐前的开胃菜，出了一个比较简单的题目：
程序开发时为什么要用多线程，单线程不是很好吗？多线程有什么意义？多线程会带来哪些
问题，如何解决？
以上问题对于一个合格的 Java 工程师来说是个非常简单的。出人意料的是，这位有着 6 年以上
开发经验的 L 君竟然没有答上来。L 君的理由这个问题太理论、太基础，已经忘记其答案了。呜呼
哀哉，这么简单的基础知识都忘记了。当然，L 君也不好意思，只能怏怏离去了。
为什么答不上来呢？可能的原因从 L 君的简历可以探知一二：L 君干了多年传统 Web 开发，在工作
过程中，估计 L 君完全是埋头干活，每天只顾着完成领导（开发经理）分配的小任务，完成 Web 模块的
CRUD（增删改查）工作，完全没有去系统地看书学习和理解 Java 的基础知识，连基础的东西都丢了。

2 .面试故事之二
候选人是从重庆一所“双一流大学”毕业了一年的初级 Java 工程师，简称 Y 君。在笔者面试前，
Y 君已经过了第一面，并且前面的同事甚至还反馈说 Y 君的技术不错。看上去 Y 君拿到 Offer 已经没
有什么悬念了。在面试时，笔者考察多线程知识似乎已经成为习惯，在 Y 君自我介绍完之后，笔者
一上来就出了一道古老的面试题：
什么是线程安全问题，“++”运算是不是线程安全的？


2 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

Y 君的答案比前面 L 君的更出人意料。Y 君直接说：“我从来没有用过多线程，不知道线程安
全问题的意义，也不清楚‘++’运算是不是线程安全的。”笔者心里有底了：Y 君和 L 君一样，又
是一个埋头于 Web 模块 CRUD 的机械活，没有去认真学习和理解 Java 基础和原理。
“没用过多线程？难道你不知道 JVM 一启动，默认就开启了多个线程吗？”笔者反问和提醒 Y
君，可 Y 君依旧两眼茫然。尽管 Y 君在面试的临场反应和语言沟通能力以及学历都令人满意，但是
笔者作为面试官只能非常无奈地撤回了差一点就给到 Y 君的 Offer。为什么呢？Java 多线程属于编程
的基本功，如果一点都不了解，很难编写出高健壮和高安全的程序。
临走的时候，笔者建议 Y 君回去做一个小实验：对一个共享的变量使用 10 个线程，每个线程自
增 100 万次。看看最终的结果是不是 1000 万。

3 .面试官总结
两个真真切切的面试故事已经讲完。实际上，笔者面试过的很多候选人都有一个共性问题：
Java 基础知识尤其是多线程、高并发知识非常欠缺。所以很遗憾，很多候选人无缘优质 Offer。
总体而言，多线程是 Java 程序运行的基础性机制，对于高性能、高并发 Java 程序来说用好多线
程尤为重要，所以多线程知识是每个 Java 工程师必知必会的基础性知识。
本章的目标是由浅入深，对 Java 多线程的核心原理和使用方法做一个非常详尽的介绍。

#### 1. 2 无处不在的进程和线程

线程从何而来呢？先从计算机的发展史讲起。从 1946 年 2 月 14 日世界上第一台计算机在美国宾
夕法尼亚大学诞生到今天，计算和处理的模式早已从单用户单任务的串行处理模式发展到了多用户
多任务的高并发处理模式。计算机处理任务的调度单位就是我们今天所讲的进程和线程。
进程和线程是操作系统中两个容易混淆的概念，实际上，它们的区分非常简单。在 Windows
操作系统中打开任务管理器，可以查看进程和线程的详细信息。本书为了方便演示，使用了一个专
业的进程查看小软件——ProcessExplorer 来查看系统中的进程和线程，具体如图 1 - 1 所示。

```
ProcessExplorer是一个轻量级的进程管理器，是由Sysinternals出品的免费工具，
大家可以从网上下载。
```
打开 ProcessExplorer 软件（或者 Windows 的任务管理器），首先看到的就是系统进程的列表，
列出了操作系统中当前运行的所有进程（运行中的程序）。列表的每一行对于每个进程的详细信息，
并且列出了所占用的系统资源，包括 CPU、内存、磁盘、线程数等。


```
第 1 章 多线程原理与实战 | 3
```
图^1 -^1 使用 ProcessExplorer 小工具查看系统中的进程和线程
在 Windows 操作系统中，进程被分为后台进程和应用进程两类。大部分后台进程在系统开始运
行时被操作系统启动，完成操作系统的基础服务功能。大部分应用进程主要由用户启动，完成用户
所需要的具体应用功能，比如听音乐、社交聊天、浏览网站等。
什么是进程呢？简单来说，进程是程序的一次启动执行。什么是程序呢？程序是存放在硬盘
中的可执行文件，主要包括代码指令和数据。一个进程是一个程序的一次启动和执行，是操作系统
将程序装入内存，给程序分配必要的系统资源，并且开始运行程序的指令。
进程与程序是什么关系呢？同一个程序可以多次启动，对应多个进程。比如，多次打开 Chrome
浏览器程序，在 ProcessExplorer 中可以看到多个 Chrome 浏览器进程。

###### 1. 2. 1 进程的基本原理

在计算机中，CPU 是核心的硬件资源，承担了所有的计算任务；内存资源承担了运行时数据
的保存任务；外存资源（硬盘等）承担了数据外部永久存储的任务。其中，计算任务的调度、资源
的分配由操作系统来统领。应用程序以进程的形式运行于操作系统之上，享受操作系统提供的服务。
进程的定义一直以来没有完美的标准。一般来说，一个进程由程序段、数据段和进程控制块
三部分组成。进程的大致结构如图 1 - 2 所示。
程序段一般也被称为代码段。代码段是进程的程序指令在内存中的位置，包含需要执行的指
令集合；数据段是进程的操作数据在内存中的位置，包含需要操作的数据集合；程序控制块（Program
ControlBlock，PCB）包含进程的描述信息和控制信息，是进程存在的唯一标志。
PCB 主要由 4 大部分组成：
1 ）进程的描述信息。主要包括：进程 ID 和进程名称，进程 ID 是唯一的，代表进程的身份；进
程的状态，比如运行、就绪、阻塞；进程优先级，是进程调度的重要依据。
2 ）进程的调度信息。主要包括：程序起始地址，程序的第一行指令的内存地址，从这里开始
程序的执行；通信信息，进程间通信时的消息队列。


4 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

图 1 - 2 进程的大致结构
3 ）进程的资源信息。主要包括：内存信息，内存占用情况和内存管理所用的数据结构；I/O
设备信息，所用的 I/O 设备编号及相应数据结构；文件句柄，所打开文件的信息。
4 ）进程上下文。主要包括执行时各种 CPU 寄存器的值、当前的程序计数器（PC）的值以及各
种栈的值等，即进程的环境。在操作系统切换进程时，当前进程被迫让出 CPU，当前进程的上下文
就保存在 PCB 结构中，供下次恢复运行时使用。

现代操作系统中，进程是并发执行的，任何进程都可以同其他进程一起进行。在进程内部，
代码段和数据段有自己的独立地址空间，不同进程的地址空间是相互隔离的。
作为 Java 工程师来说，这里有一个问题：什么是 Java 程序的进程呢？
Java 编写的程序都运行在 Java 虚拟机（JVM）中，每当使用 Java 命令启动一个 Java 应用程序时，
就会启动一个 JVM 进程。在这个 JVM 进程内部，所有 Java 程序代码都是以线程来运行的。JVM 找到
程序的入口点 main () 方法，然后运行 main () 方法，这样就产生了一个线程，这个线程称为主线程。
当 main () 方法结束后，主线程运行完成，JVM 进程也随即退出。

###### 1. 2. 2 线程的基本原理

早期的操作系统只有进程而没有线程。进程是程序执行和系统进行并发调度的最小单位。随
着计算机的发展，CPU 的性能越来越高，从早期的 20 MHz 发展到了现在 2 GHz 以上，从单核 CPU 发
展到了多核 CPU，性能提升了成千上万倍。为了充分发挥 CPU 的计算性能，提升 CPU 的硬件资源的
利用率，同时弥补进程调度过于笨重产生的问题，进程内部演进出了并发调度的诉求，于是就发明
了线程。
线程是指“进程代码段”的一次的顺序执行流程。线程是 CPU 调度的最小单位。一个进程可

```
进程
```
```
进程控制块
```
```
程序段
```
```
数据段
```
```
文件句柄
```
```
其他
```
```
进程ID 进程名称
```
```
进程状态 进程优先级
```
```
程序起始地址
```
```
进程上下文
```

```
第 1 章 多线程原理与实战 | 5
```
以有一个或多个线程，各个线程之间共享进程的内存空间、系统资源，进程仍然是操作系统资源分
配的最小单位。
Java 程序的进程执行过程就是标准的多线程的执行过程。每当使用 Java 命令执行一个 class 类时，
实际上就是启动了一个 JVM 进程。理论上，在该进程的内部至少会启动两个线程，一个 main 线程，
另一个是 GC（垃圾回收）线程。实际上，执行一个 Java 程序后，通过 ProcessExplorer 来观察，线程
数量远远不止两个，达到了 18 个之多。
一个标准的线程主要由三部分组成，即线程描述信息、程序计数器（ProgramCounter，PC）
和栈内存，如图 1 - 3 所示。

图 1 - 3 线程的大致结构
在线程的结构中，线程描述信息即线程的基本信息，主要包括：
1 ）线程 ID（ThreadID，线程标识符）。线程的唯一标识，同一个进程内不同线程的 ID 不会
重叠。
2 ）线程名称。主要是方便用户识别，用户可以指定线程的名字，如果没有指定，系统就会自
动分配一个名称。
3 ）线程优先级。表示线程调度的优先级，优先级越高，获得 CPU 的执行机会就越大。
4 ）线程状态。表示当前线程的执行状态，为新建、就绪、运行、阻塞、结束等状态中的一种。
5 ）其他。例如是否为守护线程等，后面会详细介绍。
在线程的结构中，程序计数器很重要，它记录着线程下一条指令的代码段内存地址。
在线程的结构中，栈内存是代码段中局部变量的存储空间，为线程所独立拥有，在线程之间
不共享。在 JDK 1. 8 中，每个线程在创建时默认被分配 1 MB 大小的栈内存。栈内存和堆内存不同，
栈内存不受垃圾回收器管理。
下面是一段简单的演示代码，演示一个 Java 程序的线程信息：
packagecom. crazymakercircle. mutithread. basic. create;
importcom. crazymakercircle. util. Print;
publicclassStackAreaDemo{

```
（PC）
```
```
其他
```

6 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

publicstaticvoidmain (Stringargs[]) throwsInterruptedException{
Print.cfo ("当前线程名称："+Thread.currentThread (). getName ());
Print.cfo ("当前线程 ID："+Thread.currentThread (). getId ());
Print.cfo ("当前线程状态："+Thread.currentThread (). getState ());
Print.cfo ("当前线程优先级："+Thread.currentThread (). getPriority ());
inta= 1 ,b= 1 ;
intc=a/b;
anotherFun ();
Thread.sleep ( 10000000 );
}
privatestaticvoidanotherFun (){
inta= 1 ,b= 1 ;
intc=a/b;
anotherFun 2 ();
}
privatestaticvoidanotherFun 2 (){
inta= 1 ,b= 1 ;
intc=a/b;
}
}
程序执行的结果如下：
[StackAreaDemo: main]: 当前线程名称：main
[StackAreaDemo: main]: 当前线程 ID： 1
[StackAreaDemo: main]: 当前线程状态：RUNNABLE
[StackAreaDemo: main]: 当前线程优先级： 5
这里使用了 java. lang 包中的 Thread.currentThread () 静态方法，用于获取正在执行的当前线程。
从结果可以看出，正在执行 main () 方法的当前线程的其描述信息如下：线程 ID 为 1 ，名称为 main，
状态为 RUNNABLE，线程的优先级为 5 。
在 Java 中，执行程序流程的重要单位是“方法”，而栈内存的分配的单位是“栈帧”（或者叫
“方法帧”）。方法的每一次执行都需要为其分配一个栈帧（方法帧），栈帧主要保存该方法中的
局部变量、方法的返回地址以及其他方法的相关信息。当线程的执行流程进入方法时，JVM 就会为
方法分配一个对应的栈帧压入栈内存；当线程的执行流程跳出方法时，JVM 就从栈内存弹出该方法
的栈帧，此时方法栈帧的内存空间就会被回收，栈帧中的变量就会被销毁。
以前面的 StackAreaDemo 示例代码为例，详细介绍一下 main 线程的栈内存。该示例中定义了三
种方法：main ()、anotherFun () 和 anotherFun 2 ()，这三种方法都有相同的三个局部变量 a、b、c。整体
的执行流程如下：

1 ）当执行到 main () 方法时，JVM 为 main () 方法分配一个栈帧，保存三个局部变量，然后将栈帧
压入 main 线程的栈内存。接着，main () 方法还没有执行完，执行流程进入 anotherFun () 方法。
2 ）执行流程进入 anotherFun () 之前 JVM 为其分配对应的栈帧，保存其三个局部变量，然后压入
main 线程的栈内存。
3 ）执行流程进入了 anotherFun 2 () 方法，老样子，JVM 为 anotherFun 2 () 分配对应的栈帧，保存
其三个局部变量，然后将帧压入 main 线程的栈内存。

进入到 anotherFun 2 () 后，main 线程含有三个帧，其栈结构如图 1 - 4 所示。
三种方法的栈帧弹出的过程与压入的过程刚好相反。anotherFun 2 () 方法执行完成后，其栈帧从
main 线程的栈内存首先弹出，执行流程回到 anotherFun () 方法。anotherFun () 方法执行完成后，其栈
帧从 main 线程的栈内存弹出之后，执行流程回到 main () 方法。main 方法执行完成后，其栈帧最后弹


```
第 1 章 多线程原理与实战 | 7
```
出，此时 main 线程的栈内存已经全部弹空，没有剩余的栈帧。至此，main 线程结束。
正是由于栈帧（方法帧）的操作是后进先出的模式，这也是标准的栈操作模式，所以存放方
法帧的内存也被叫作栈内存。

```
图 1 - 4 进入到anotherFun 2 ()后main线程的栈结构
```
###### 1. 2. 3 进程与线程的区别

下面总结一下进程与线程的区别，主要有以下几点：
1 ）线程是“进程代码段”的一次的顺序执行流程。一个进程由一个或多个线程组成；一个进
程至少有一个线程。
2 ）线程是 CPU 调度的最小单位，进程是操作系统分配资源的最小单位。线程的划分尺度小于
进程，使得多线程程序的并发性高。
3 ）线程是出于高并发的调度诉求从进程内部演进而来的。线程的出现既充分发挥 CPU 的计算
性能，又弥补了进程调度过于笨重的问题。
4 ）进程之间是相互独立的，但进程内部各个线程之间并不完全独立。各个线程之间共享进程
的方法区内存、堆内存、系统资源（文件句柄、系统信号等）。
5 ）切换速度不同，线程上下文切换比进程上下文切换要快得多。所以，有时线程也称为轻量
级进程。

#### 1. 3 创建线程的 4 种方法

Java 进程中每一个线程都对应着一个 Thread 实例。线程的描述信息在 Thread 的实例属性中得到
保存，供 JVM 进行线程管理和调度时使用。
Thread 类除定义了很多操作线程实例的成员方法之外，还有一系列的类的静态方法。比如 1. 2

```
的栈帧
```
```
的栈帧
```
```
的栈帧
```
```
的栈帧
```
```
压栈次序 弹栈次序
```

8 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

节用到的 Thread.currentThread () 静态方法就是其中之一，该方法的作用是取得当前 CPU 内核上正在
运行的线程实例。

```
虽然一个进程有很多个线程，但是在一个CPU内核上，同一时刻只能有一个线
程是正在执行的，该线程也被叫作当前线程。
```
Thread 类是 Java 多线程编程的基础。Java 中创建线程虽然有
三种方式，但是三种方式都会涉及 Thread 类。

###### 1. 3. 1 Thread 类详解

一个线程在 Java 中使用一个 Thread 实例来描述。Thread 类是
Java 语言一个重要的基础类，位于 java. lang 包中。Thread 类有不
少非常重要的属性和方法，用于存储和操作线程的描述信息，该
类的结构大致如图 1 - 5 所示。
接下来，为大家逐一介绍 Thread 类中比较重要的属性和方法。
1 .线程 ID
属性：privatelongtid，此属性用于保存线程的 ID。这是一
个 private 类型属性，外部只能使用 getId () 方法进行访问线程的 ID。
方法：publiclonggetId ()，获取线程 ID，线程 ID 由 JVM 进行
管理，在进程内唯一。比如， 1. 2 节的实例中，所输出的 main 线
程的 ID 为 1 。

2 .线程名称
属性：privateStringname，该属性保存一个 Thread 线程实例的名字。
方法一：publicfinalStringgetName ()，获取线程名称。
方法二：publicfinalvoidsetName (Stringname)，设置线程名称。
方法三：Thread (StringthreadName)，通过此构造方法给线程设置一个定制化的名字。
3 .线程优先级
属性：privateintpriority，保存一个 Thread 线程实例的优先级。
方法一：publicfinalintgetPriority ()，获取线程优先级。
方法二：publicfinalvoidsetPriority (intpriority)，设置线程优先级。
Java 线程优先级的最大值为 10 ，最小值为 1 ，默认值为 5 。这三个优先级值为三个常量值，也是
在 Thread 类中使用类常量定义，三个类常量如下：
publicstaticfinalintMIN_PRIORITY= 1 ;
publicstaticfinalintNORM_PRIORITY= 5 ;
publicstaticfinalintMAX_PRIORITY= 10 ;

```
图 1 - 5 Thread类的结构图
```

```
第 1 章 多线程原理与实战 | 9
```
4 .是否为守护线程
属性：privatebooleandaemon=false，该属性保存 Thread 线程实例的守护状态，默认为 false，
表示是普通的用户线程，而不是守护线程。
方法：publicfinalvoidsetDaemon (booleanon)，将线程实例标记为守护线程或用户线程，如果
参数值为 true，那么将线程实例标记为守护线程。

什么是守护线程呢？
守护线程是在进程运行时提供某种后台服务的线程，比如垃圾回收（GC）线程。有关守护
线程的知识将在后文详细介绍。
5 .线程的状态
属性：privateintthreadStatus，该属性以整数的形式保存线程的状态。
方法：publicThread.StategetState ()，返回表示当前线程的执行状态，为新建、就绪、运行、
阻塞、结束等状态中的一种。

Thread 的内部静态枚举类 State 用于定义 Java 线程的所有状态，具体如下：
publicstaticenumState{
NEW, //新建
RUNNABLE, //就绪、运行
BLOCKED, //阻塞
WAITING, //等待
TIMED_WAITING, //计时等待
TERMINATED; //结束
}
在 Java 线程的状态中，就绪状态和运行状态在内部都用同一种状态 RUNNABLE 表示。就绪状
态表示线程具备运行条件，正在等待获取 CPU 时间片；运行状态表示线程已经获取了 CPU 时间片，
CPU 正在执行线程代码逻辑。

6 .线程的启动和运行
方法一：publicvoidstart ()，用来启动一个线程，当调用 start () 方法后，JVM 才会开启一个新的
线程来执行用户定义的线程代码逻辑，在这个过程中会为相应的线程分配需要的资源。
方法二：publicvoidrun ()，作为线程代码逻辑的入口方法。run () 方法不是由用户程序来调用的，
当调用 start () 方法启动一个线程之后，只要线程获得了 CPU 执行时间，便进入 run () 方法去执行具体
的用户线程代码。

总之，这两个方法是非常重要的方法，start () 方法用于线程的启动，run () 方法作为用户代码逻
辑的执行入口。

7 .取得当前线程
方法：publicstaticThreadcurrentThread ()，该方法是一个非常重要的静态方法，用于获取当前
线程的 Thread 实例对象。什么是当前线程呢？就是当前在 CPU 上执行的线程。在没有其他的途径获
取当前线程的实例对象的时候，可以通过 Thread.currentThread () 静态方法获取。


10 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

8 .其他的属性和方法
Thread 类中还有很多的重要属性和方法，本章后面会对 Thread 类进行深入的介绍，具体参见后
面的内容。

###### 1. 3. 2 创建一个空线程

第一个创建线程的方法是通过继承 Thread 类创建一个线程实例。这里为大家奉上一个非常简单
的例子，让大家先体验一下如何通过 Thread 类的完成线程创建、启动和运行。
首先演示一下如何创建一个空线程。空线程在启动后不会执行任何用户代码逻辑。创建一个
空线程的参考代码如下：
packagecom. crazymakercircle. mutithread. basic. create;
importpersonal. nien. javabook. util. Print;
publicclassEmptyThreadDemo{
publicstaticvoidmain (Stringargs[]) throwsInterruptedException{
//使用 Thread 类创建和启动线程
Threadthread=newThread ();
Print.cfo ("线程名称："+thread.getName ());
Print.cfo ("线程 ID："+thread.getId ());
Print.cfo ("线程状态："+thread.getState ());
Print.cfo ("线程优先级："+thread.getPriority ());
Print.cfo (getCurThreadName ()+"运行结束.");
thread.start ();
}
}
代码非常简单，通过 newThread () 创建一个线程实例，然后调用 thread.start () 的实例方法启动线
程的执行，并且示例程序在 start 线程启动前输出了线程的一些描述信息：
[EmptyThreadDemo: main]: 线程名称：Thread- 0
[EmptyThreadDemo: main]: 线程 ID： 11
[EmptyThreadDemo: main]: 线程状态：NEW
[EmptyThreadDemo: main]: 线程优先级： 5
通过输出结果可以看到：新的线程的 ID 为 11 ，线程名称为 Thread- 0 。该线程名称是 JVM 默认设
置的名称，和执行 main () 方法线程的名称为 main 一样，都是 JVM 默认的。
在 thread 线程信息输出完成后，程序调用 thread.start () 的实例方法启动新线程 thread 的执行。从
上一小节大家知道，这时新线程的执行会调用 Thread 的 run () 实例方法，该方法作为用户业务代码逻
辑的入口。查看一下 Thread 类源码，其 run () 方法的具体代码如下：
publicvoidrun (){
if (this. target!=null){
this.target.run ();
}
}
这里的 target 属性是 Thread 类的一个实例属性，该属性是很重要的，在后面会用到和讲到。在
Thread 类中，target 的属性值默认为空。在这个例子中，thread 线程的 target 属性默认为 null。所以在
thread 线程执行时，其 run () 方法其实什么也没有做，线程就执行完了。
总之，以上的简单例子向大家展示了通过 Thread 类如何新建和启动线程。例子中 thread 线程的
run () 方法也确实执行了，只是由于 target 目标为空，什么也没有做而已。


```
第 1 章 多线程原理与实战 | 11
```
###### 1. 3. 3 线程创建方法一：继承 Thread 类创建线程类

通过前面的空线程例子可以看出，新线程如果要并发执行自己的代码，需要做以下两件事情：
1 ）需要继承 Thread 类，创建一个新的线程类。
2 ）同时重写 run () 方法，将需要并发执行的业务代码编写在 run () 方法中。
下面的示例演示如何通过继承 Thread 类创建一个线程类，新的线程子类重写了 Thread 的 run ()
方法，实现了用户业务代码的并发执行，具体如下：
packagecom. crazymakercircle. mutithread. basic. create;
importpersonal. nien. javabook. util. Print;
publicclassCreateDemo{
publicstaticfinalintMAX_TURN= 5 ;
publicstaticStringgetCurThreadName (){
returnThread.currentThread (). getName ();
}
//线程的编号
staticintthreadNo= 1 ;
staticclassDemoThreadextendsThread{ //①
publicDemoThread (){
super ("DemoThread-"+threadNo++);//②
}
publicvoidrun (){ //③
for (inti= 1 ;i<MAX_TURN; i++){
Print.cfo (getName ()+", 轮次："+i);
}
Print.cfo (getName ()+"运行结束.");
}
}
publicstaticvoidmain (Stringargs[]) throwsInterruptedException{
Threadthread=null;
//方法一：使用 Thread 子类创建和启动线程
for (inti= 0 ;i< 2 ;i++){
thread=newDemoThread ();
thread.start ();
}
Print.cfo (getCurThreadName ()+"运行结束.");
}
}
运行该实例，结果如下：
[CreateDemo: main]: main 运行结束.
[CreateDemo$DemoThread: run]: DemoThread- 1 ,轮次： 1
[CreateDemo$DemoThread: run]: DemoThread- 1 ,轮次： 2
[CreateDemo$DemoThread: run]: DemoThread- 1 ,轮次： 3
[CreateDemo$DemoThread: run]: DemoThread- 1 ,轮次： 4
[CreateDemo$DemoThread: run]: DemoThread- 1 运行结束.
[CreateDemo$DemoThread: run]: DemoThread- 2 ,轮次： 1
[CreateDemo$DemoThread: run]: DemoThread- 2 ,轮次： 2
[CreateDemo$DemoThread: run]: DemoThread- 2 ,轮次： 3
[CreateDemo$DemoThread: run]: DemoThread- 2 ,轮次： 4
[CreateDemo$DemoThread: run]: DemoThread- 2 运行结束.


12 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

例子中新建了一个静态内部类 DemoThread，该内部类继承了 Thread 线程类。在 DemoThread 的
构造函数中，通过 super () 调用了基类的 Thread (StringthreadName) 构造方法设置了线程的名称。
staticclassDemoThreadextendsThread{ //①
publicDemoThread (){
super ("DemoThread-"+threadNo++);//②
}
...
}
这里为什么要将 DemoThread 设计成静态内部类呢？主要是为了方便访问外部类的成员属性和
方法，和线程的使用没有任何关系。如果将 DemoThread 设计成外部类，最终的执行结果是一样的。
静态内部类 DemoThread 的关键点是重写了 Thread 类的 run () 方法，将需要并发执行的用户业务
代码编写在继承的 run () 方法中。这里 run () 方法的代码非常简单，具体如下：
publicvoidrun (){ //③
for (inti= 1 ;i<MAX_TURN; i++){
Print.cfo (getName ()+", 轮次："+i);
}
Print.cfo (getName ()+"运行结束.");
}
在 DemoThread 的 run () 方法的代码中，主要是包括一个循环执行 MAX_TURN 轮的循环，每一轮
输出一个循环轮次，且顺便通过调用基类的 getName () 方法取得线程对象的名称并输出。

###### 1. 3. 4 线程创建方法二：实现 Runnable 接口创建线程目标类

通过继承 Thread 类并重写其 run () 方法只是创建 Java 线程的一种方式。是否可以不继承 Thread 类
实现线程新建呢？答案是肯定的。
重温一下 Thread 类 run () 方法代码，里面其实有点玄机，代码如下：
packagejava. lang;
publicclassThreadimplementsRunnable{
...
privateRunnabletarget;//执行目标
publicvoidrun (){
if (this. target!=null){
this.target.run (); //调用执行目标的 run () 方法
}
}
publicThread (Runnabletarget){ //包含执行目标的构造器
init (null, target,"Thread-"+nextThreadNum (), 0 );
}
}
在 Thread 类的 run () 方法中，如果 target（执行目标）不为空，就执行 target 属性的 run () 方法。而
target 属性是 Thread 类的一个实例属性，并且 target 属性的类型为 Runnable。
Thread 类 target 属性什么情况下非空呢？Thread 类有一系列的构造器，其中有多个构造器可以
为 target 属性赋值，这些构造器包括如下两个：

```
1 ）publicThread(Runnabletarget)
2 ）publicThread(Runnabletarget，Stringname)
```

```
第 1 章 多线程原理与实战 | 13
```
使用这两个构造器传入 target 执行目标实例（Runnable 实例），就可以直接通过 Thread 类的 run ()
方法以默认方式实现，达到并发执行线程的目的。在这种场景下，可以不通过继承 Thread 类来实现
线程类的创建。
在为 Thread 的构造器传入 target 实例前，先来看看 Runnable 接口是何方神圣。
1 .Runnable 接口
Runnable 是一个极为简单的接口，位于 java. lang 包中。接口中只有一个方法 run ()，具体的源代
码如下：
packagejava. lang;
@FunctionalInterface
publicinterfaceRunnable{
voidrun ();
}
Runnable 有且仅有一个抽象方法——voidrun ()，代表被执行的用户业务逻辑的抽象，在使用
的时候，将用户业务逻辑编写在 Runnable 实现类的 run () 的实现版本中。当 Runnable 实例传入 Thread
实例的 target 属性后，Runnable 接口的 run () 的实现版本将被异步调用。

2 ．通过实现 Runnable 接口创建线程类
创建线程的第二种方法就是实现 Runnable 接口，将需要异步执行的业务逻辑代码放在 Runnable
实现类的 run () 方法中，将 Runnable 实例作为 target 执行目标传入 Thread 实例。该方法的具体步骤如下：

1 ）定义一个新类实现 Runnable 接口。
2 ）实现 Runnable 接口中的 run () 抽象方法，将线程代码逻辑存放在该 run () 实现版本中。
3 ）通过 Thread 类创建线程对象，将 Runnable 实现类实例作为实际参数传递给 Thread 类的构造
器，由 Thread 构造器将该 Runnable 实例赋值给自己的 target 执行目标属性。
4 ）调用 Thread 实例的 start () 方法启动线程。
5 ）线程启动之后，线程的 run () 将被 JVM 执行，该 run () 方法将调用到 target 属性的 run () 方法，从
而完成 Runnable 实现类中业务代码逻辑的并发执行。

```
按照上面的 5 步，即可实现一个简单的并发执行的多线程演示实例，代码如下：
packagecom.crazymakercircle.mutithread.basic.create;
//省略import
publicclassCreateDemo 2
{
publicstaticfinalintMAX_TURN= 5 ;
staticintthreadNo= 1 ;
staticclassRunTargetimplementsRunnable //①实现Runnable接口
{
publicvoidrun() //②在这里编写业务逻辑
{
for(intj= 1 ;j<MAX_TURN;j++)
{
Print.cfo(ThreadUtil.getCurThreadName()+",轮次："+j);
}
Print.cfo(getCurThreadName()+"运行结束.");
}
}
```

14 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

publicstaticvoidmain (Stringargs[]) throwsInterruptedException
{
Threadthread=null;
for (inti= 0 ;i< 2 ;i++)
{
Runnabletarget=newRunTarget ();
//通过 Thread 类创建线程对象，将 Runnable 实例作为实际参数传入
thread=newThread (target,"RunnableThread"+threadNo++);
thread.start ();
}
}
}
实例中静态内部类 RunTarget 执行目标类，不再是继承了 Thread 线程类，而是实现 Runnable 接
口，需要异步并发执行的代码逻辑被编写在其 run () 方法中。

```
值得注意的是，run()实现版本中在获取当前线程的名称时，所用的方法是在外
部类ThreadUtil中所定义的getCurThreadName()静态方法，而不是Thread类的getName()实例方
法。原因是：这个RunTarget内部类和Thread类不再是继承关系，无法直接去调用Thread类的
任何实例方法。
```
通过实现 Runnable 接口的方式创建的执行目标类，如果需要访问线程的任何属性和方法，必须
通过 Thread.currentThread () 获取当前的线程对象，通过当前线程对象去间接访问。
publicstaticStringgetCurThreadName (){
returnThread.currentThread (). getName (); //获取线程名称
}
通过继承 Thread 类的方式创建的线程类，可以在子类中直接调用 Thread 父类的方法访问当前线
程的名称、状态等信息。这也是使用 Runnable 实现异步执行与继承 Thread 方法实现异步执行的不同
的地方。
完成了 Runnable 的实现类后，需要调用 Thread 类的构造器创建线程，并将 Runnable 实现类的实
例作为实参传入。可以使用的构造函数包括如下三个：

1 ）publicThread (Runnabletarget)
2 ）publicThread (Runnabletarget，Stringname)
3 ）publicThread (ThreadGroupgroup, Runnabletarget)
若使用以上的第二个构造器构造线程时可以指定线程的名称，则实例如下：
thread=newThread (newRunTarget (),"name"+threadNo++);
线程对象创建完成后，调用 Thread 线程实例的 start () 方法启动新线程的并发执行。这时，
Runnable 实例的 run () 方法会在新线程 Thread 的实例方法 run () 方法中被调用。

###### 1. 3. 5 优雅创建 Runnable 线程目标类的两种方式

使用 Runnable 创建线程目标类除了直接实现 Runnable 接口之外，还有两种比较优雅的代码组织
方式：

```
1 ）通过匿名类优雅创建Runnable线程目标类。
```

```
第 1 章 多线程原理与实战 | 15
```
2 ）使用 Lambda 表达式优雅创建 Runnable 线程目标类。
1 .通过匿名类优雅创建 Runnable 线程目标类
在实现 Runnable 的编写 target 执行目标类时，如果 target 实现类是一次性类，可以使用匿名实例
的形式。上一小节的执行目标类是一个静态内部类，现在改写成匿名实例的形式，代码如下：
packagecom. crazymakercircle. mutithread. basic. create;
//省略 import
publicclassCreateDemo 2 {
publicstaticfinalintMAX_TURN= 5 ;
staticintthreadNo= 1 ;
publicstaticvoidmain (Stringargs[]) throwsInterruptedException{
Threadthread=null;
//使用 Runnable 的匿名类创建和启动线程
for (inti= 0 ;i< 2 ;i++){
thread=newThread (newRunnable (){//①匿名实例
@Override
publicvoidrun (){//②异步执行的业务逻辑
for (intj= 1 ;j<MAX_TURN; j++){
Print.cfo (getCurThreadName ()+", 轮次："+j);
}
Print.cfo (getCurThreadName ()+"运行结束.");
}
},"RunnableThread"+threadNo++);
thread.start ();
}
Print.cfo (getCurThreadName ()+"运行结束.");
}
}
使用 Runnable 的匿名实例方式和编写普通的执行目标类相比，代码的区别很小。主要的区别体
现在代码①处，其他的代码完成相同。在代码①处，通过编写了匿名类的实现代码直接创建了一个
Runnable 类型的匿名 target 执行目标对象。

2 .使用 Lambda 表达式优雅创建 Runnable 线程目标类
回顾一下 Runnable 接口，其源代码中还有一个小玄机，具体如下：
@FunctionalInterface
publicinterfaceRunnable{
voidrun ();
}
源码的小玄机为：在 Runnable 接口上声明了一个@FunctionalInterface 注解。该注解的作用是：
标记 Runnable 接口是一个“函数式接口”。在 Java 中，“函数式接口”是有且仅有一个抽象方法的
接口。反过来说，如果一个接口中包含两个或以上的抽象方法，就不能使用@FunctionalInterface
注解，否则编译会报错。

```
@FunctionalInterface注解不是必需的，只要一个接口符合“函数式接口”的定义，
使用时加不加@FunctionalInterface注解都没有影响，都可以当作“函数式接口”来使用。
```
```
Runnable接口是一个函数式接口，在接口实现时可以使用Lambda表达式提供匿名实现，编写
```

16 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

出比较优雅的代码。上一小节的执行目标类是一个静态内部类，现在改写成 Lambda 表达式的形式，
代码如下：
packagecom. crazymakercircle. mutithread. basic. create;
//省略 import
publicclassCreateDemo 2 {
publicstaticfinalintMAX_TURN= 5 ;
staticintthreadNo= 1 ;
publicstaticvoidmain (Stringargs[]) throwsInterruptedException{
Threadthread=null;
//使用 Lambda 表达式形式创建和启动线程
for (inti= 0 ;i< 2 ;i++){
thread=newThread ( **()->{** //①Lambda 表达式
for (intj= 1 ;j<MAX_TURN; j++){
Print.cfo (getCurThreadName ()+", 轮次："+j);
}
Print.cfo (getCurThreadName ()+"运行结束.");
**}** ,"RunnableThread"+threadNo++);
thread.start ();
}
Print.cfo (getCurThreadName ()+"运行结束.");
}
}
创建 Lambda 表达式版本的 target 执行目标实例的代码与创建 target 执行目标匿名实例的区别也
很小，区别主要是在代码①处，其他的部分完成相同。在代码①处，通过 Lambda 表达式直接编写
Runnable 接口 run () 方法的实现代码，接口的名称（Runnable）、方法的名称 run () 全部被省略，仅剩
下了 run () 方法的形参列表和方法体。
总体而言，经过对比可以发现：使用 Lambda 表达式创建 target 执行目标实例，代码已经做到极
致的简化。

###### 1. 3. 6 实现 Runnable 接口的方式创建线程目标类的优缺点

通过实现 Runnable 接口的方式创建线程目标类有以下缺点：
1 ）所创建的类并不是线程类，而是线程的 target 执行目标类，需要将其实例作为参数传入线程
类的构造器，才能创建真正的线程。
2 ）如果访问当前线程的属性（甚至控制当前线程），不能直接访问 Thread 的实例方法，必须
通过 Thread.currentThread () 获取当前线程实例，才能访问和控制当前线程。

通过实现 Runnable 接口的方式创建线程目标类有以下优点：
1 ）可以避免由于 Java 单继承带来的局限性。如果异步逻辑所在类已经继承了一个基类，就没
有办法再继承 Thread 类。比如，当一个 Dog 类继承了 Pet 类，再要继承 Thread 类时就不行了。所以在
已经存在继承关系的情况下，只能使用实现 Runnable 接口的方式。
2 ）逻辑和数据更好分离。通过实现 Runnable 接口的方法创建多线程更加适合同一个资源被多
段业务逻辑并行处理的场景。在同一个资源被多个线程逻辑去异步、并行处理的场景中，通过实现
Runnable 接口的方式设计多个 target 执行目标类可以更加方便、清晰地将执行逻辑和数据存储分离，
更好地体现了面向对象的设计思想。


```
第 1 章 多线程原理与实战 | 17
```
1 .“逻辑和数据更好地分离”演示实例
通过实现 Runnable 接口的方式创建线程目标类更加适合多个线程的代码逻辑去共享计算和处
理同一个资源的场景。这个优点不是太好理解，接下来通过具体例子说明一下。
packagecom. crazymakercircle. mutithread. basic. create;
//省略 import
publicclassSalesDemo
{
publicstaticfinalintMAX_AMOUNT= 5 ;//商品数量
//商店商品类（销售线程类），一个商品一个销售线程，每个线程异步销售 4 次
staticclassStoreGoodsextendsThread
{
StoreGoods (Stringname)
{
super (name);
}
privateintgoodsAmount=MAX_AMOUNT;
publicvoidrun ()
{
for (inti= 0 ;i<=MAX_AMOUNT; i++)
{
if (this. goodsAmount> 0 )
{
Print.cfo (getCurThreadName ()+"卖出一件，还剩："
+(--goodsAmount));
sleepMilliSeconds ( 10 );
}
}
Print.cfo (getCurThreadName ()+"运行结束.");
}
}
//商场商品类型（target 销售线程的目标类），一个商品最多销售 4 次，可以多人销售
staticclassMallGoodsimplementsRunnable
{
//多人销售可能导致数据出错，使用原子数据类型保障数据安全
privateAtomicIntegergoodsAmount=newAtomicInteger (MAX_AMOUNT);
publicvoidrun ()
{
for (inti= 0 ;i<=MAX_AMOUNT; i++)
{
if (this.goodsAmount.get ()> 0 )
{
Print.cfo (getCurThreadName ()+"卖出一件，还剩："
+(goodsAmount.decrementAndGet ()));
sleepMilliSeconds ( 10 );
}
}
Print.cfo (getCurThreadName ()+"运行结束.");
}
}
publicstaticvoidmain (Stringargs[]) throwsInterruptedException
{
Print.hint ("商店版本的销售");
for (inti= 1 ;i<= 2 ;i++)
{


18 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

Threadthread=null;
thread=newStoreGoods ("店员-"+i);
thread.start ();
}
Thread.sleep ( 1000 );
Print.hint ("商场版本的销售");
MallGoodsmallGoods=newMallGoods ();
for (inti= 1 ;i<= 2 ;i++)
{
Threadthread=null;
thread=newThread (mallGoods,"商场销售员-"+i);
thread.start ();
}
Print.cfo (getCurThreadName ()+"运行结束.");
}
}
运行代码，输出的结果如下：
[main|Print. hint]：/--商店版本的销售--/
[SalesDemo$StoreGoods. run]：店员- 2 卖出一件，还剩： 4
[SalesDemo$StoreGoods. run]：店员- 1 卖出一件，还剩： 4
[SalesDemo$StoreGoods. run]：店员- 2 卖出一件，还剩： 3
[SalesDemo$StoreGoods. run]：店员- 1 卖出一件，还剩： 3
[SalesDemo$StoreGoods. run]：店员- 2 卖出一件，还剩： 2
[SalesDemo$StoreGoods. run]：店员- 1 卖出一件，还剩： 2
[SalesDemo$StoreGoods. run]：店员- 1 卖出一件，还剩： 1
[SalesDemo$StoreGoods. run]：店员- 2 卖出一件，还剩： 1
[SalesDemo$StoreGoods. run]：店员- 2 卖出一件，还剩： 0
[SalesDemo$StoreGoods. run]：店员- 1 卖出一件，还剩： 0
[SalesDemo$StoreGoods. run]：店员- 1 运行结束.
[SalesDemo$StoreGoods. run]：店员- 2 运行结束.
[main|Print. hint]：/--商场版本的销售--/
[SalesDemo. main]：main 运行结束.
[SalesDemo$MallGoods. run]：商场销售员- 1 卖出一件，还剩： 3
[SalesDemo$MallGoods. run]：商场销售员- 2 卖出一件，还剩： 4
[SalesDemo$MallGoods. run]：商场销售员- 1 卖出一件，还剩： 2
[SalesDemo$MallGoods. run]：商场销售员- 2 卖出一件，还剩： 1
[SalesDemo$MallGoods. run]：商场销售员- 1 卖出一件，还剩： 0
[SalesDemo$MallGoods. run]：商场销售员- 2 运行结束.
[SalesDemo$MallGoods. run]：商场销售员- 1 运行结束.
2 .“逻辑和数据更好地分离”原理分析
在上面的例子中，静态内部类 StoreGoods 继承 Thread 类实现了一个异步销售类。在 main () 方法
中创建销售线程时创建了 2 个商店商品的销售线程实例。
Print.hint ("商店版本的销售");
for (inti= 1 ;i<= 2 ;i++)
{
Threadthread=null;
thread=newStoreGoods ("店员-"+i);//商店商品的销售线程
thread.start ();
}
上面的代码新建了 n 个（这里为 2 个）线程，相当于 n 个不同的商店店员，每个商店店员负责一
个数量，并且负责将自己的数量卖完。每个商店店员（线程）各卖各的，其剩余数量都是从 4 卖到 0 ，
没有关联。商店店员的售卖过程大致如图 1 - 6 所示。


```
第 1 章 多线程原理与实战 | 19
```
图 1 - 6 n 个商店店员的售卖过程
再来看另一个内部类 MallGoods，通过实现 Runnable 接口实现多线程目标类。在 main () 方法中
创建销售线程时创建了 1 个公用的 MallGoods 商品销售对象。
Print.hint ("商场版本的销售");
MallGoodsmallGoods=newMallGoods (); //创建了 1 个公共的 MallGoods 对象
for (inti= 1 ;i<= 2 ;i++)
{
Threadthread=null;
thread=newThread (mallGoods,"商场销售员-"+i); //销售员线程
thread.start ();
}
以上代码新建了 n 个（这里为 2 个）线程，相当于商场招聘了 n 个不同的商场销售员。每个商场
销售员一个线程，n 个线程共享了一个 Runnable 类型的 target 执行目标实例——mallGoods 实例。
这里的关键点是：n 个商场销售员线程通过线程的 target.run () 方法共同访问 mallGoods 实例的同
一个商品数量 goodsAmount，剩余数量从 4 卖到 0 ，大家一起售卖，卖一个少一个，卖完为止。其售
卖过程大致如图 1 - 7 所示。

图 1 - 7 n 个商场销售对同一商品的售卖过程
通过对比可以看出：
1 ）通过继承 Thread 类实现多线程能更好地做到多个线程并发地完成各自的任务，访问各自的
数据资源。

```
商店店员- 1 商店店员- 2 商店店员-n
```
```
商店销售员- 1 商店销售员- 2 商店销售员-n
```

20 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

2 ）通过实现 Runnable 接口实现多线程能更好地做到多个线程并发地完成同一个任务，访问同
一份数据资源。多个线程的代码逻辑可以方便地访问和处理同一个共享数据资源（如例子中的
MallGoods. goodsAmount），这样可以将线程逻辑和业务数据进行有效的分离，更好地体现了面向
对象的设计思想。
3 ）通过实现 Runnable 接口实现多线程时，如果数据资源存在多线程共享的情况，那么数据共
享资源需要使用原子类型（而不是普通数据类型），或者需要进行线程的同步控制，以保证对共享
数据操作时不会出现线程安全问题。

总之，在大多数情况下，偏向于用实现 Runnable 接口来实现线程执行目标类，这样能使得代码
更加简洁明了。后面介绍线程池的时候会讲到，异步执行任务在大多数情况下是通过线程池去提交
的，而很少通过创建一个新的线程去提交，所以更多的做法是，通过实现 Runnable 接口创建异步执
行任务，而不是继承 Thread 去创建异步执行任务。

###### 1. 3. 7 线程创建方法三：使用 Callable 和 FutureTask 创建线程

前面已经介绍了继承 Thread 类或者实现 Runnable 接口这两种方式来创建线程类，但是这两种方
式都有一个共同的缺陷：不能获取异步执行的结果。
这是一个比较大的问题，很多场景都需要获取异步执行的结果，通过 Runnable 无法实现，因为
其 run () 方法是不支持返回值。
为了解决异步执行的结果问题，Java 语言在 1. 5 版本之后提供了一种新的多线程创建方法：通
过 Callable 接口和 FutureTask 类相结合创建线程。

1 .Callable 接口
Callable 接口位于 java. util. concurrent 包中，查看它的 Java 源代码，如下：
packagejava. util. concurrent;
@FunctionalInterface
publicinterfaceCallable<V>{
Vcall () throwsException;
}
Callable 接口是一个泛型接口，也是一个“函数式接口”。其唯一的抽象方法 call () 有返回值，
返回值的类型为 Callable 接口的泛型形参类型。call () 抽象方法还有一个 Exception 的异常声明，容许
方法的实现版本的内部异常直接抛出，并且可以不予捕获。
Callable 接口类似于 Runnable。不同的是，Runnable 的唯一抽象方法 run () 没有返回值，也没有
受检异常的异常声明。比较而言，Callable 接口的 call () 有返回值，并且声明了受检异常，其功能更
强大一些。
问题：Callable 实例能否和 Runnable 实例一样，作为 Thread 线程实例的 target 来使用呢？答案是
不行。Thread 的 target 属性的类型为 Runnable，而 Callable 接口与 Runnable 接口之间没有任何继承关
系，并且二者唯一的方法在名字上也不同。显而易见，Callable 接口实例没有办法作为 Thread 线程
实例的 target 来使用。既然如此，那么该如何使用 Callable 接口去创建线程呢？一个在 Callable 接口与
Thread 线程之间起到搭桥作用的重要接口马上就登场了。


```
第 1 章多线程原理与实战 | 21
```
2 .RunnableFuture 接口
这个重要中间搭桥接口就是 RunnableFuture 接口，该接口与 Runnable 接口、Thread 类紧密相关。
与 Callable 接口一样，RunnableFuture 接口也位于 java. util. concurrent 包中，使用时需要用 import 导入。
RunnableFuture 是如何在 Callable 与 Thread 之间实现搭桥功能的呢？RunnableFuture 接口实现了
两个目标：一是可以作为 Thread 线程实例的 target 实例，二是可以获取异步执行的结果。它是如何
做到一箭双雕的呢？请看 RunnableFuture 的接口的代码：
packagejava. util. concurrent;
publicinterfaceRunnableFuture<V> extends Runnable, Future<V>{
voidrun ();
}
通过源代码可以看出，RunnableFuture 继承了 Runnable 接口，从而保证了其实例可以作为 Thread
线程实例的 target 目标；同时，RunnableFuture 通过继承 Future 接口，保证了通过它可以获取未来的
异步执行结果。
在这里，一个新的、从来没有介绍过的、非常重要的 Future 接口马上登场。
3 .Future 接口
Future 接口至少提供了三大功能：
1 ）能够取消异步执行中的任务。
2 ）判断异步任务是否执行完成。
3 ）获取异步任务完成后的执行结果。
Future 接口的源代码如下：
packagejava. util. concurrent;
publicinterfaceFuture<V>{
booleancancel (booleanmayInterruptRunning); //取消异步执行
booleanisCancelled ();
booleanisDone (); //判断异步任务是否执行完成
//获取异步任务完成后的执行结果
Vget () throwsInterruptedException, ExecutionException;
//设置时限，获取异步任务完成后的执行结果
Vget (longtimeout, TimeUnitunit) throwsInterruptedException, ExecutionException,
TimeoutException;
...
}
对 Future 接口的主要方法详细说明如下：
 Vget ()：获取异步任务执行的结果。注意，这个方法的调用是阻塞性的。如果异步任务没
有执行完成，异步结果获取线程（调用线程）会一直被阻塞，一直阻塞到异步任务执行完
成，其异步结果返回给调用线程。
 Vget (Longtimeout, TimeUnitunit)：设置时限，（调用线程）阻塞性地获取异步任务执行
的结果。该方法的调用也是阻塞性的，但是结果获取线程（调用线程）会有一个阻塞时长
限制，不会无限制地阻塞和等待，如果其阻塞时间超过设定的 timeout 时间，该方法将抛出
异常，调用线程可捕获此异常。


22 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

 booleanisDone ()：获取异步任务的执行状态。如果任务执行结束，就返回 true。
 booleanisCancelled ()：获取异步任务的取消状态。如果任务完成前被取消，就返回 true。
 booleancancel (booleanmayInterruptRunning)：取消异步任务的执行。
总体来说，Future 是一个对异步任务进行交互、操作的接口。但是 Future 仅仅是一个接口，通
过它没有办法直接完成对异步任务的操作，JDK 提供了一个默认的实现类——FutureTask。

4 .FutureTask 类
FutureTask 类是 Future 接口的实现类，提供了对异步任务的操作的具体实现。但是，FutureTask
类不仅仅实现了 Future 接口，还实现了 Runnable 接口，或者更加准确地说，FutureTask 类实现了
RunnableFuture 接口。
前面讲到 RunnableFuture 接口很关键，既可以作为 Thread 线程实例的 target 目标，也可以获取并
发任务执行的结果，是 Thread 与 Callable 之间一个非常重要的搭桥角色。但是，RunnableFuture 只是
一个接口，无法直接创建对象，如果需要创建对象，就需用到它的实现类——FutureTask。所以说，
FutureTask 类才是真正的在 Thread 与 Callable 之间搭桥的类。
FutureTask 类的 UML 关系图大致如图 1 - 8 所示。

图 1 - 8 FutureTask 类的 UML 关系图
从 FutureTask 类的 UML 关系图可以看到：FutureTask 实现了 RunnableFuture 接口，而
RunnableFuture 接口继承了 Runnable 接口和 Future 接口，所以 FutureTask 既能当作一个 Runnable 类型
的 target 执行目标直接被 Thread 执行，又能作为 Future 异步任务来获取 Callable 的计算结果。
FutureTask 如何完成多线程的并发执行、任务结果的异步获取呢？FutureTask 内部有一个
Callable 类型的成员——callable 实例属性，具体如下：
privateCallable<V>callable;


```
第 1 章多线程原理与实战 | 23
```
callable 实例属性用来保存并发执行的 Callable<V>类型的任务，并且 callable 实例属性需要在
FutureTask 实例构造时进行初始化。FutureTask 类实现了 Runnable 接口，在其 run () 方法的实现版本中
会执行 callable 成员的 call () 方法。
此外，FutureTask 内部还有另一个非常重要的 Object 类型的成员——outcome 实例属性：
privateObjectoutcome;
FutureTask 的 outcome 实例属性用于保存 callable 成员 call () 方法的异步执行结果。在 FutureTask
类 run () 方法完成 callable 成员的 call () 方法的执行之后，其结果将被保存在 outcome 实例属性中，供
FutureTask 类的 get () 方法获取。

5 .使用 Callable 和 FutureTask 创建线程的具体步骤
通过 FutureTask 类和 Callable 接口的联合使用可以创建能获取异步执行结果的线程。具体步骤
如下：

1 ）创建一个 Callable 接口的实现类，并实现其 call () 方法，编写好异步执行的具体逻辑，可以
有返回值。
2 ）使用 Callable 实现类的实例构造一个 FutureTask 实例。
3 ）使用 FutureTask 实例作为 Thread 构造器的 target 入参，构造新的 Thread 线程实例。
4 ）调用 Thread 实例的 start () 方法启动新线程，启动新线程的 run () 方法并发执行。其内部的执行
过程为：启动 Thread 实例的 run () 方法并发执行后，会执行 FutureTask 实例的 run () 方法，最终会并发
执 Callable 实现类的 call () 方法。
5 ）调用 FutureTask 对象的 get () 方法阻塞性地获得并发线程的执行结果。
按照以上步骤，通过 Callable 接口和 Future 接口相结合去创建多线程，实例如下：
packagecom. crazymakercircle. mutithread. basic. create;
//省略 import
publicclassCreateDemo 3 {
publicstaticfinalintMAX_TURN= 5 ;
publicstaticfinalintCOMPUTE_TIMES= 100000000 ;
//①创建一个 Callable 接口的实现类
staticclassReturnableTaskimplementsCallable<Long>{
//②编写好异步执行的具体逻辑，可以有返回值
publicLongcall () throwsException{
longstartTime=System.currentTimeMillis ();
Print.cfo (getCurThreadName ()+"线程运行开始.");
Thread.sleep ( 1000 );
for (inti= 0 ;i<COMPUTE_TIMES; i++){
intj=i* 10000 ;
}
longused=System.currentTimeMillis ()-startTime;
Print.cfo (getCurThreadName ()+"线程运行结束.");
returnused;
}
}
publicstaticvoidmain (Stringargs[]) throwsInterruptedException{
ReturnableTasktask=newReturnableTask ();//③
FutureTask<Long>futureTask=newFutureTask<Long>(task);//④


24 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

Threadthread=newThread (futureTask,"returnableThread");//⑤
thread.start ();//⑥
Thread.sleep ( 500 );
Print.cfo (getCurThreadName ()+"让子弹飞一会儿.");
Print.cfo (getCurThreadName ()+"做一点自己的事情.");
for (inti= 0 ;i<COMPUTE_TIMES/ 2 ;i++){
intj=i* 10000 ;
}
Print.cfo (getCurThreadName ()+"获取并发任务的执行结果.");
try{
Print.cfo (thread.getName ()+"线程占用时间："
+futureTask.get ());//⑦
}catch (InterruptedExceptione){
e.printStackTrace ();
}catch (ExecutionExceptione){
e.printStackTrace ();
}
Print.cfo (getCurThreadName ()+"运行结束.");
}
}
执行实例程序，结果如下：
[CreateDemo 3 $ReturnableTask: call]: returnableThread 线程运行开始.
[CreateDemo 3 : main]: main 让子弹飞一会儿.
[CreateDemo 3 : main]: main 做一点自己的事情.
[CreateDemo 3 : main]: main 获取并发任务的执行结果.
[CreateDemo 3 $ReturnableTask: call]: returnableThread 线程运行结束.
[CreateDemo 3 : main]: returnableThread 线程占用时间： 1008
[CreateDemo 3 : main]: main 运行结束.
在这个例子中有两个线程：一个是执行 main () 方法的主线程，叫作 main 线程；另一个是 main
线程通过 thread.start () 方法启动的业务线程，叫作 returnableThread 线程。该线程是一个包含了
FutureTask 任务作为 target 的 Thread 线程。
main 线程通过 thread.start () 启动 returnableThread 线程之后，会继续自己的事情，returnableThread
线程开始并发执行。
returnableThread 线程首先开始执行的是 thread.run () 方法，然后在其中会执行到其 target
（futureTask 任务）的 run () 方法；接着在这个 futureTask.run () 方法中会执行 futureTask 的 callable 成员
的 call () 方法，这里的 callable 成员（ReturnableTask 实例）是通过 FutureTask 构造器在初始化时传递
进来的、自定义的 Callable 实现类的实例。
main 线程和 returnableThread 线程的执行流程大致如图 1 - 9 所示。
FutureTask 的 Callable 成员的 call () 方法执行完成后，会将结果保存在 FutureTask 内部的 outcome
实例属性中。以上演示实例的 Callable 实现类中，这里 call () 方法中业务逻辑的返回结果是 call () 方法
从进入到出来的执行时长：
longstartTime=System.currentTimeMillis ();
...
longused=System.currentTimeMillis ()-startTime;
returnused;
执行时长被返回之后，将被作为结果保存在 futureTask 内部的 outcome 实例属性中。至此，异步
的 returnableThread 线程执行完毕。在 main 线程处理完自己的事情后（以上实例中是一个消磨时间的
循环），通过 futureTask 的 get 实例方法获取异步执行的结果。这里有两种情况：


```
第 1 章多线程原理与实战 | 25
```
图 1 - 9 main 线程和 returnableThread 线程
1 ）futureTask 的结果 outcome 不为空，callable.call () 执行完成。在这种情况下，futureTast. get 会
直接取回 outcome 结果，返回给 main 线程（结果获取线程）。
2 ）futureTask 的结果 outcome 为空，callable.call () 还没有执行完。在这种情况下，main 线程作为
结果获取线程会被阻塞住，一直被阻塞到 callable.call () 执行完成。当执行完后，最终结果保存到
outcome 中，futureTask 会唤醒 main 线程去提取 callable.call () 执行结果。

###### 1. 3. 8 线程创建方法四：通过线程池创建线程

前面的示例中，所创建的 Thread 实例在执行完成之后都销毁了，这些线程实例都是不可复用的。
实际上创建一个线程实例在时间成本、资源耗费上都很高的（稍后会介绍），在高并发的场景中，
断然不能频繁进行线程实例的创建与销毁，而是需要对已经创建好的线程实例进行复用，这就涉及
线程池的技术。Java 中提供了一个静态工厂来创建不同的线程池，该静态工厂为 Executors 工厂类。

1 .线程池的创建与执行目标提交
通过 Executors 工厂类创建一个线程池，一个简单的示例如下：
//创建一个包含三个线程的线程池
privatestaticExecutorServicepool=Executors.newFixedThreadPool ( 3 );
以上示例通过工厂类 Executors 的 newFixedThreadPool (intthreads) 方法创建了一个线程池，所创
建的线程池的类型为 ExecutorService。工厂类的 newFixedThreadPool (intthreads) 方法用于创建包含
一个固定数目的线程池，示例中的线程数量为 3 。
ExecutorService 是 Java 提供的一个线程池接口，每次我们在异步执行 target 目标任务的时候，可
以通过 ExecutorService 线程池实例去提交或者执行。ExecutorService 实例负责对池中的线程进行管
理和调度，并且可以有效控制最大并发线程数，提高系统资源的使用率，同时提供定时执行、定频
执行、单线程、并发数控制等功能。


26 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

向 ExecutorService 线程池提交异步执行 target 目标任务的常用方法有：
//方法一：执行一个 Runnable 类型的 target 执行目标实例，无返回
voidexecute (Runnablecommand);
//方法二：提交一个 Callable 类型的 target 执行目标实例，返回一个 Future 异步任务实例
<T>Future<T>submit (Callable<T>task);
//方法三：提交一个 Runnable 类型的 target 执行目标实例，返回一个 Future 异步任务实例
Future<?>submit (Runnabletask);
2 .线程池的使用实战
使用 Executors 创建线程池，然后使用 ExecutorService 线程池执行或者提交 target 执行目标实例
的示例代码，大致如下：
packagecom. crazymakercircle. mutithread. basic. create;
//省略 import
publicclassCreateDemo 4
{
publicstaticfinalintMAX_TURN= 5 ;
publicstaticfinalintCOMPUTE_TIMES= 100000000 ;
//创建一个包含三个线程的线程池
privatestaticExecutorServicepool=Executors.newFixedThreadPool ( 3 );
staticclassDemoThreadimplementsRunnable
{
@Override
publicvoidrun ()
{
for (intj= 1 ;j<MAX_TURN; j++)
{
Print.cfo (getCurThreadName ()+", 轮次："+j);
sleepMilliSeconds ( 10 );
}
}
}
staticclassReturnableTaskimplementsCallable<Long>
{
//返回并发执行的时间
publicLongcall () throwsException
{
longstartTime=System.currentTimeMillis ();
Print.cfo (getCurThreadName ()+"线程运行开始.");
for (intj= 1 ;j<MAX_TURN; j++)
{
Print.cfo (getCurThreadName ()+", 轮次："+j);
sleepMilliSeconds ( 10 );
}
longused=System.currentTimeMillis ()-startTime;
Print.cfo (getCurThreadName ()+"线程运行结束.");
returnused;
}
}
publicstaticvoidmain (String[]args){
pool.execute (newDemoThread ());//执行线程实例，无返回


```
第 1 章多线程原理与实战 | 27
```
pool.execute (newRunnable ()
{
@Override
publicvoidrun ()
{
for (intj= 1 ;j<MAX_TURN; j++)
{
Print.cfo (getCurThreadName ()+", 轮次："+j);
sleepMilliSeconds ( 10 );
}
}
});
//提交 Callable 执行目标实例，有返回
Futurefuture=pool.submit (newReturnableTask ());
Longresult=(Long) future.get ();
Print.cfo ("异步任务的执行结果为："+result);
sleepSeconds (Integer. MAX_VALUE);
}
}
运行程序，输出的结果如下：
[CreateDemo 4 $DemoThread. run]：pool- 1 - thread- 1 ,轮次： 1
[CreateDemo 4 $ 1 .run]：pool- 1 - thread- 2 ,轮次： 1
[CreateDemo 4 $ 1 .run]：pool- 1 - thread- 2 ,轮次： 2
[CreateDemo 4 $DemoThread. run]：pool- 1 - thread- 1 ,轮次： 2
[CreateDemo 4 $DemoThread. run]：pool- 1 - thread- 1 ,轮次： 3
[CreateDemo 4 $ 1 .run]：pool- 1 - thread- 2 ,轮次： 3
[CreateDemo 4 $DemoThread. run]：pool- 1 - thread- 1 ,轮次： 4
[CreateDemo 4 $ 1 .run]：pool- 1 - thread- 2 ,轮次： 4
[CreateDemo 4 $ReturnableTask. call]：pool- 1 - thread- 3 线程运行开始.
[CreateDemo 4 $ReturnableTask. call]：pool- 1 - thread- 3 ,轮次： 1
[CreateDemo 4 $ReturnableTask. call]：pool- 1 - thread- 3 ,轮次： 2
[CreateDemo 4 $ReturnableTask. call]：pool- 1 - thread- 3 ,轮次： 3
[CreateDemo 4 $ReturnableTask. call]：pool- 1 - thread- 3 ,轮次： 4
[CreateDemo 4 $ReturnableTask. call]：pool- 1 - thread- 3 线程运行结束.
[CreateDemo 4 .main]：异步任务的执行结果为： 45
大家可以对比和分析一下这些线程池中线程的名称和普通线程的线程名称有何不同。
ExecutorService 线程池的 execute (...) 与 submit (...) 方法的区别如下。
（ 1 ）接收的参数不一样
Submit () 可以接受两种入参：无返回值的 Runnable 类型的 target 执行目标实例和有返回值
Callable 类型的 target 执行目标实例。而 execute () 仅仅接收无返回值的 target 执行目标实例，或者无返
回值的 Thread 实例。

（ 2 ）submit () 有返回值，而 execute () 没有
submit () 方法在提交异步 target 执行目标之后会返回 Future 异步任务实例，以对 target 的异步执行
过程进行控制，比如取消执行、获取结果等。execute () 没有任何返回，target 执行目标实例在执行之
后没有办法对其异步执行过程进行控制，只能任其执行，直到其执行结束。

```
本小节的案例仅供学习使用，实际生产环境禁止使用 Executors 创建线程池，线
程池是一个很重要的 Java 知识点，后面会详细介绍。
```

28 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

#### 1. 4 线程的核心原理

现代操作系统（如 Windows、Linux、Solaris）提供了强大的线程管理能力，Java 不需要再进行
自己独立的线程管理和调度，而是将线程调度工作委托给操作系统的调度进程去完成。在某些系统
（比如 Solaris 操作系统）上，JVM 甚至将每个 Java 线程一对一地对应到操作系统的本地线程，彻底
将线程调度委托给操作系统。

###### 1. 4. 1 线程的调度与时间片

由于 CPU 的计算频率非常高，每秒计算数十亿次，因此可以将 CPU 的时间从毫秒的维度进行
分段，每一小段叫作一个 CPU 时间片。对于不同的操作系统、不同的 CPU，线程的 CPU 时间片长度
都不同。假定操作系统（比如 WindowsXP）线程的时间片长度为 20 毫秒，在一个 2 GHz 的 CPU 上，
一个时间片可以进行计算的次数是 20 亿/( 1000 / 20 )= 4000 万次，也就是说，一个时间片内的计算量是
非常巨大的。
目前操作系统中主流的线程调度方式是：基于 CPU 时间片方式进行线程调度。线程只有得到
CPU 时间片才能执行指令，处于执行状态，没有得到时间片的线程处于就绪状态，等待系统分配下
一个 CPU 时间片。由于时间片非常短，在各个线程之间快速地切换，因此表现出来的特征是很多个
线程在“同时执行”或者“并发执行”。
线程的调度模型目前主要分为两种：分时调度模型和抢占式调度模型。
1 ）分时调度模型：系统平均分配 CPU 的时间片，所有线程轮流占用 CPU。分时调度模型在时
间片调度的分配上，所有线程“人人平等”。
图 1 - 10 就是一个分时调度的简单例子：三个线程轮流得到 CPU 时间片，一个线程执行时，另外
两个线程处于就绪状态。

图^1 -^10 三个线程的分时调度模型示意图
2 ）抢占式调度模型：系统按照线程优先级分配 CPU 时间片。优先级高的线程，优先分配 CPU
时间片，如果所有就绪线程的优先级相同，那么会随机选择一个，优先级高的线程获取的 CPU 时间
片相对多一些。


```
第 1 章多线程原理与实战 | 29
```
由于目前大部分操作系统都是使用抢占式调度模型进行线程调度，Java 的线程管理和调度是委
托给操作系统完成的，与之相对应，Java 的线程调度也是使用抢占式调度模型，因此 Java 的线程都
有优先级。

###### 1. 4. 2 线程的优先级

在 Thread 类中有一个实例属性和两个实例方法，专门用于进行线程优先级相关的操作，与线程
优先级相关的成员属性为：
privateintpriority；//该属性保存一个 Thread 实例的优先级，即 1 ~ 10 之间的值
与 Thread 类线程优先级相关的实例方法为：
方法 1 ：publicfinalintgetPriority ()，获取线程优先级。
方法 2 ：publicfinalvoidsetPriority (intpriority)，设置线程优先级。
Thread 实例的 priority 属性默认是级别 5 ，对应的类常量是 NORM_PRIORITY。优先级最大值为
10 ，最小值为 1 ，Thread 类中定义的三个优先级常量如下：
publicstaticfinalintMIN_PRIORITY= 1 ;
publicstaticfinalintNORM_PRIORITY= 5 ;
publicstaticfinalintMAX_PRIORITY= 10 ;
Java 中使用抢占式调度模型进行线程调度。priority 实例属性的优先级越高，线程获得 CPU 时间
片的机会越多，但也不是绝对的。举一个例子，顺便演示以上两个线程优先级实例方法的使用，具
体如下：
packagecom. crazymakercircle. mutithread. basic. create 2 ;
importpersonal. nien. javabook. util. Print;
publicclassPriorityDemo{
publicstaticfinalintSLEEP_GAP= 1000 ;
staticclassPrioritySetThreadextendsThread{
staticintthreadNo= 1 ;
publicPrioritySetThread (){
super ("thread-"+threadNo);
threadNo++;
}
publiclongopportunities= 0 ;
publicvoidrun (){
for (inti= 0 ;; i++){
opportunities++;
}
}
}
publicstaticvoidmain (Stringargs[]) throwsInterruptedException{
PrioritySetThread[]threads=newPrioritySetThread[ 10 ];
for (inti= 0 ;i<threads. length; i++){
threads[i]=newPrioritySetThread ();
//优先级的设置， 1 ~ 10
threads[i]. setPriority (i+ 1 );
}
for (inti= 0 ;i<threads. length; i++){
threads[i]. start ();//启动线程


30 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

}
Thread.sleep (SLEEP_GAP); //等待线程运行 1 秒
for (inti= 0 ;i<threads. length; i++){
threads[i]. stop (); //停止线程
}
for (inti= 0 ;i<threads. length; i++){
Print.cfo (threads[i]. getName ()+
"-优先级为-"+threads[i]. getPriority ()+ //获取优先级
"-机会值为-"+threads[i]. opportunities
);
}
}
}
运行以上例子，结果如下：
[PriorityDemo: main]: thread- 1 ;优先级为- 1 ;机会值为- 0
[PriorityDemo: main]: thread- 2 ;优先级为- 2 ;机会值为- 580416
[PriorityDemo: main]: thread- 3 ;优先级为- 3 ;机会值为- 0
[PriorityDemo: main]: thread- 4 ;优先级为- 4 ;机会值为- 449545
[PriorityDemo: main]: thread- 5 ;优先级为- 5 ;机会值为- 151777
[PriorityDemo: main]: thread- 6 ;优先级为- 6 ;机会值为- 5206493
[PriorityDemo: main]: thread- 7 ;优先级为- 7 ;机会值为- 1091936570
[PriorityDemo: main]: thread- 8 ;优先级为- 8 ;机会值为- 1085458844
[PriorityDemo: main]: thread- 9 ;优先级为- 9 ;机会值为- 1196934380
[PriorityDemo: main]: thread- 10 ;优先级为- 10 ;机会值为- 1174667391
例子中创建了 10 个线程，放在一个线程数组中。 10 个线程的优先级各不相同，通过 for 循环进
行设置，将优先级设置成从 1 ~ 10 ：第 1 线程的优先级最低，其值为 1 ，第 10 个线程的优先级最高，
其值为 10 。
定制的 PrioritySetThread 线程的 run () 方法非常简单，其功能是对实例属性 opportunities 的值进行
自增。
publiclongopportunities= 0 ;
publicvoidrun (){
for (inti= 0 ;; i++){
opportunities++;
}
}
在线程的 run () 方法中，设置了一个没有条件判断表达式的 for 循环，这是一个死循环，线程启
动之后，永远也不会退出，直到线程被停止。那么，问题来了，如何停止这 10 个线程呢？这里使用
的 Thread 类的 stop () 实例方法，该方法的作用是终止线程的执行。
for (inti= 0 ;i<threads. length; i++){
threads[i]. stop ();
}
Thread 类的 stop () 实例方法是一个过时的方法，也是一个不安全的方法。这里的安全指的是系
统资源（文件、网络连接等）的安全——stop () 实例方法可能导致资源状态不一致，或者说资源出
现问题时很难定位。在实际开发过程中，不建议使用 stop () 实例方法。本例非常简单，这里是因为
演示需要，不会存在安全问题，所以使用 stop () 实例方法来终止线程的执行。
10 个线程的运行时间合计 1 秒， 1 秒之后，所有的线程停止：


```
第 1 章多线程原理与实战 | 31
```
for (inti= 0 ;i<threads. length; i++){
threads[i]. start (); //启动线程
}
Thread.sleep (SLEEP_GAP); //等待 1 秒， 10 个线程的运行时间合计 1 秒
for (inti= 0 ;i<threads. length; i++){
threads[i]. stop (); //停止线程
}
演示示例中 10 个线程停下来之后，某个线程的实例属性 opportunities 的值越大，就表明该线程
获得的 CPU 时间片越多。分析案例的执行结果，可以看出以下结论：

1 ）整体而言，高优先级的线程获得的执行机会更多。在实例中可以看到：优先级在 6 级以上
的线程和 4 级以下的线程执行机会明显偏多，整体对比非常明显。
2 ）执行机会的获取具有随机性，优先级高的不一定获得的机会多。比如，例子中的 thread- 10
比 thread- 9 优先级高，但是 thread- 10 所获得的机会反而偏少。

###### 1. 4. 3 线程的生命周期

Java 中的线程的生命周期分为 6 种状态。Thread 类有一个实例属性和一个实例方法专门用于保
存和获取线程的状态。其中，用于保存线程 Thread 实例状态的实例属性为：
privateintthreadStatus； //以整数的形式保存线程的状态。
Thread 类用于获取线程状态的实例方法为：
publicThread.StategetState (); //返回当前线程的执行状态，一个枚举类型值
Thread. State 是一个内部枚举类，定义了 6 个枚举常量，分别代表 Java 线程的 6 种状态，具体如下：
publicstaticenumState{
NEW, //新建
RUNNABLE, //可执行：包含操作系统的就绪、运行两种状态
BLOCKED, //阻塞
WAITING, //等待
TIMED_WAITING, //计时等待
TERMINATED; //终止
}
在 Thread. State 定义的 6 种状态中，有 4 种是比较常见的状态，它们是：NEW（新建）状态、
RUNNABLE（可执行）状态、TERMINATED（终止）状态、TIMED_WAITING（限时等待）状态。

1 .NEW 状态
Java 源码对 NEW 状态的注释说明是：创建成功但是没有调用 start () 方法启动的 Thread 线程实例
都处于 NEW 状态。
当然，并不是 Thread 线程实例的 start () 方法一经调用，其状态就从 NEW 状态到 RUNNABLE 状
态，此时并不意味着线程立即获取 CPU 时间片并且立即执行，中间需要一系列的操作系统内部操作。

2 .RUNNABLE 状态
前面讲到，当调用了 Thread 实例 start () 方法后，下一步如果线程获取 CPU 时间片开始执行，JVM
将异步调用线程的 run () 方法执行其业务代码，那么在 run () 方法被异步调用之前，JVM 做了哪些事
情呢？


32 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

JVM 的幕后工作和操作系统的线程调度有关。Java 中的线程管理是通过 JNI 本地调用的方式，
委托操作系统的线程管理 API 完成的。当 Java 线程的 Thread 实例的 start () 方法被调用后，操作系统中
的对应线程进入的并不是运行状态，而是就绪状态，而 Java 线程并没有这个就绪状态。操作系统中
线程的就绪状态是什么状态的呢？
JVM 的线程状态与其幕后的操作系统线程状态之间的转换关系简化后如图 1 - 11 所示。

图 1 - 11 JVM 的线程状态与其幕后的操作系统线程状态的转换关系（简化版）
一个操作系统线程如果处于就绪状态，表示“万事俱备，只欠东风”，即该线程已经满足了
执行条件，但是还不能执行。处于就绪状态的线程需要等待系统的调度，一旦就绪状态被系统选中，
获得 CPU 时间片，线程就开始占用 CPU，开始执行线程的代码，这时线程的操作系统状态发生了改
变，进入了运行状态。
在操作系统中，处于运行状态的线程在 CPU 时间片用完之后，又回到就绪状态，等待 CPU 的
下一次调度。就这样，操作系统线程在就绪状态和执行状态之间被系统反复地调度，这种情况会一
直持续，直到线程的代码逻辑执行完成或者异常终止。这时线程的操作系统状态又发生了改变，进
入了线程的最后状态——TERMINATED 状态。
就绪状态和运行状态都是操作系统中的线程状态。在 Java 语言中，并没有细分这两种状态，而
是将这两种状态合并成同一种状态——RUNNABLE 状态。因此，在 Thread. State 枚举类中，没有定
义线程的就绪状态和运行状态，只是定义了 RUNNABLE 状态。这就是 Java 线程状态和操作系统中
的线程状态有所不同的地方。
总之，NEW 状态的 Thread 实例调用了 start () 方法后，线程的状态将变成 RUNNABLE 状态。尽
管如此，线程的 run () 方法不一定会马上被并发执行，需要在线程获取了 CPU 时间片之后，才会真正
启动并发执行。

3 .TERMINATED 状态
处于 RUNNABLE 状态的线程在 run () 方法执行完成之后就变成终止状态 TERMINATED 了。当
然，如果在 run () 方法执行过程中发生了运行时异常而没有被捕获，run () 方法将被异常终止，线程也
会变成 TERMINATED 状态。

4 .TIMED_WAITING 限时等待状态
线程处于一种特殊的等待状态，准确地说，线程处于限时等待状态。能让线程处于限时等待
状态的操作大致有以下几种：

```
1 ）Thread.sleep (intn)：使得当前线程进入限时等待状态，等待时间为 n 毫秒。
```
```
start () run () 结束
```

```
第 1 章多线程原理与实战 | 33
```
```
2 ）Object.wait ()：带时限的抢占对象的 monitor 锁。
3 ）Thread.join ()：带时限的线程合并。
4 ）LockSupport.parkNanos ()：让线程等待，时间以纳秒为单位。
5 ）LockSupport.parkUntil ()：让线程等待，时间可以灵活设置。
```
###### 1. 4. 4 一个线程状态的简单演示案例

为了演示线程的 RUNNABLE 状态，在下面的案例中设计了两个线程轮番计数的一个公共的静
态变量 turn。两个线程中都有一个同样的 for 循环，当线程占用时间片的时候，都对静态变量 turn 进
行累加，直到 turn 的值达到上限值 MAX_TURN。
案例代码如下：
packagecom. crazymakercircle. mutithread. basic. create 3 ;
//省略 import
publicclassStatusDemo
{
//每个线程执行的轮次
publicstaticfinallongMAX_TURN= 5 ;
//线程编号
staticintthreadSeqNumber= 0 ;
//全局的静态线程列表
staticList<Thread>threadList=newArrayList<>();
//输出静态线程列表中，每个线程的状态
privatestaticvoidprintThreadStatus ()
{
for (Threadthread:threadList)
{
Print.tco (thread.getName ()+"状态为"+thread.getState ());
}
}
//向全局的静态线程列表加入线程
privatestaticvoidaddStatusThread (Threadthread)
{
threadList.add (thread);
}
staticclassStatusDemoThreadextendsThread
{
publicStatusDemoThread ()
{
super ("statusPrintThread"+(++threadSeqNumber));
//将自己加入到全局的静态线程列表
addStatusThread (this);
}
publicvoidrun ()
{
Print.cfo (getName ()+", 状态为"+getState ());
for (intturn= 0 ;turn<MAX_TURN; turn++)
{
//线程睡眠
sleepMilliSeconds ( 500 );
//输出所有线程的状态
printThreadStatus ();
}


34 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

Print.tco (getName ()+"-运行结束.");
}
}
publicstaticvoidmain (Stringargs[]) throwsInterruptedException
{
//将 main 线程加入全局列表
addStatusThread (Thread.currentThread ());
//新建三个线程，这些线程在构造器中会将自己加入全局列表
ThreadsThread 1 =newStatusDemoThread ();
Print.cfo (sThread 1 .getName ()+"-状态为"+sThread 1 .getState ());
ThreadsThread 2 =newStatusDemoThread ();
Print.cfo (sThread 2 .getName ()+"-状态为"+sThread 2 .getState ());
ThreadsThread 3 =newStatusDemoThread ();
Print.cfo (sThread 3 .getName ()+"-状态为"+sThread 3 .getState ());
sThread 1 .start (); //启动第一个线程
sleepMilliSeconds ( 500 ); //等待 500 毫秒启动第二个线程
sThread 2 .start ();
sleepMilliSeconds ( 500 ); //等待 1000 毫秒启动第三个线程
sThread 3 .start ();
sleepSeconds ( 100 ); //睡眠 100 秒
}
}
运行程序，输出的结果如下：
[StatusDemo. main]：statusPrintThread 1 - 状态为 NEW
[StatusDemo. main]：statusPrintThread 2 - 状态为 NEW
[StatusDemo. main]：statusPrintThread 3 - 状态为 NEW
...
[statusPrintThread 1 ]：main 状态为 TIMED_WAITING
[statusPrintThread 1 ]：statusPrintThread 1 状态为 RUNNABLE
[statusPrintThread 1 ]：statusPrintThread 2 状态为 TIMED_WAITING
[statusPrintThread 1 ]：statusPrintThread 3 状态为 TIMED_WAITING
[statusPrintThread 2 ]：main 状态为 TIMED_WAITING
[statusPrintThread 2 ]：statusPrintThread 1 状态为 TIMED_WAITING
[statusPrintThread 2 ]：statusPrintThread 2 状态为 RUNNABLE
[statusPrintThread 2 ]：statusPrintThread 3 状态为 RUNNABLE
[statusPrintThread 3 ]：main 状态为 TIMED_WAITING
[statusPrintThread 3 ]：statusPrintThread 1 状态为 TIMED_WAITING
[statusPrintThread 3 ]：statusPrintThread 2 状态为 RUNNABLE
[statusPrintThread 3 ]：statusPrintThread 3 状态为 RUNNABLE
[statusPrintThread 1 ]：main 状态为 TIMED_WAITING
[statusPrintThread 1 ]：statusPrintThread 1 状态为 RUNNABLE
[statusPrintThread 1 ]：statusPrintThread 2 状态为 TIMED_WAITING
[statusPrintThread 1 ]：statusPrintThread 3 状态为 TIMED_WAITING
...
[statusPrintThread 3 ]：statusPrintThread 1 状态为 TERMINATED
[statusPrintThread 3 ]：statusPrintThread 2 状态为 TERMINATED
[statusPrintThread 3 ]：statusPrintThread 3 状态为 RUNNABLE
[statusPrintThread 3 ]：statusPrintThread 3 - 运行结束.
通过以上结果可以看出：当线程新建之后，在没有启动之前其状态为 NEW；调用其 start () 方法
启动之后，其状态为 RUNNABLE；当使用 LockSupport.parkNanos (...) 方法使得当前线程等待之后，
线程的状态变成了 TIMED_WAITING；等待结束之后，其状态又变成了 RUNNABLE；线程执行完
成之后，它的状态变成 TERMINATED。


```
第 1 章多线程原理与实战 | 35
```
对于示例中用到的 sleepMilliSeconds () 方法，它的内部调用了 LockSupport.parkNanos (...) 方法使
得当前线程限时等待，这是为了编程快捷而自定义的方法，其代码如下：
packagecom. crazymakercircle. util;
//省略 import
publicclassThreadUtil
{
publicstaticvoidsleepMilliSeconds (intmillisecond)
{
LockSupport.parkNanos (millisecond* 1000 L* 1000 L);
}
//省略其他方法
}
以上代码中用到的 LockSupport 类是来自 JDK 中的锁辅助类，该类在后面的章节
会详细介绍。

###### 1. 4. 5 使用 Jstack 工具查看线程状态

有时，服务器 CPU 占用率会一直很高，甚至一直处于 100 %。如果 CPU 使用率居高不下，自然
是有某些线程一直占用着 CPU 资源，如何查看 CPU 占用率较高的线程呢？或者说，如何查看到线程
的状态呢？一种比较快捷的办法是使用 Jstack 工具。
Jstack 工具是 Java 虚拟机自带的一种堆栈跟踪工具。Jstack 用于生成或导出（DUMP）JVM 虚拟
机运行实例当前时刻的线程快照。线程快照是对当前 JVM 实例内每一个线程正在执行的方法堆栈的
集合，生成或导出线程快照的主要目的是用于定位线程出现长时间运行、停顿或者阻塞的原因，如
线程间死锁、死循环、请求外部资源导致的长时间等待等。线程出现停顿的时候通过 Jstack 来查看
各个线程的调用堆栈，就可以知道没有响应的线程到底在后台做什么事情，或者等待什么资源。
Jstack 命令的语法格式：
jstack<pid> //pid 表示 Java 进程 id，可以用 jps 命令查看
一般情况下，通过 Jstack 输出的线程信息主要包括：JVM 线程、用户线程等。其中 JVM 线程会
在 JVM 启动时就存在，主要用于执行譬如垃圾回收、低内存的检测等后台任务，这些线程往往在 JVM
初始化的时候就存在。而用户线程则是在程序创建了新的线程时才会生成。这里要注意的是：

1 ）在实际运行中，往往一次 DUMP 的信息不足以确认问题。建议产生三次 DUMP 信息，如果
每次 DUMP 都指向同一个问题，我们才确定问题的典型性。
2 ）不同的 Java 虚拟机的线程导出来的 DUMP 信息格式是不一样的，并且同一 JVM 的不同版本
DUMP 信息也有差别。

JVM 线程往往在 JVM 初始化的时候就存在。在 Java 程序刚启动时，通过 Jstack 命令可以立即
DUMP 出来一些 JVM 后台线程。下面是一些 JVM 线程的例子：
"VMThread"os_prio= 2 tid= 0 x 00000000150 c 8000 nid= 0 x 3 b 8 crunnable
"GCtaskthread# 0 (ParallelGC)"os_prio= 0 tid= 0 x 0000000002 a 48000 nid= 0 x 41 f 8 runnable
"GCtaskthread# 1 (ParallelGC)"os_prio= 0 tid= 0 x 0000000002 a 49800 nid= 0 x 3254 runnable
"GCtaskthread# 2 (ParallelGC)"os_prio= 0 tid= 0 x 0000000002 a 4 b 000 nid= 0 x 271 crunnable
"GCtaskthread# 3 (ParallelGC)"os_prio= 0 tid= 0 x 0000000002 a 4 c 800 nid= 0 x 1578 runnable


36 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

"VMPeriodicTaskThread"os_prio= 2 tid= 0 x 0000000016594000 nid= 0 x 1 d 10 waitingon
condition
其中，GCtaskthread 为垃圾回收线程，此类该线程会负责进行垃圾回收。通常 JVM 会启动多
个 GC 线程，在 GC 线程的名称中， #后面的数字会累加 ，如 GCtaskthread# 1 、GCtaskthread# 2 等。
其中，VMPeriodicTaskThread 线程是 JVM 周期性任务调度的线程，该线程在 JVM 内使用得比
较频繁，比如定期的内存监控、JVM 运行状况监控。
Jstack 指令所输出的信息中包含以下重要信息：
1 ）tid：线程实例在 JVM 进程中的 id。
2 ）nid：线程实例在操作系统中对应的底层线程的线程 id。
3 ）prio：线程实例在 JVM 进程中的优先级。
4 ）os_prio：线程实例在操作系统中对应的底层线程的优先级。
5 ）线程状态：如 runnable、waitingoncondition 等。
用户线程往往是执行业务逻辑的线程，是大家所关注的重点，也是最容易产生死锁的地方。
接下来的内容会用 Jstack 命令来分析用户线程的 WAITING、BLOCKED 两种状态。

#### 1. 5 线程的基本操作

```
Java 线程的常用操作基本上都定义在 Thread 类中，包括一些重要的静态方法和线程实例方法。
```
###### 1. 5. 1 线程名称的设置和获取

在 Thread 类中可以通过构造器 Thread (...) 初始化设置线程名称，也可以通过 setName (...) 实例方
法去设置线程名称，取得线程名称可以通过 getName () 方法完成。
关于线程名称有以下几个要点：
1 ）线程名称一般在启动线程前设置，但也允许为运行的线程设置名称。
2 ）允许两个 Thread 对象有相同的名称，但是应该避免。
3 ）如果程序没有为线程指定名称，系统会自动为线程设置名称。
一个简单的线程名称操作实例如下：
packagecom. crazymakercircle. mutithread. basic. use;
//省略 import
publicclassThreadNameDemo
{
privatestaticfinalintMAX_TURN= 3 ;
//异步执行目标类
staticclassRunTargetimplementsRunnable
{ //实现 Runnable 接口
publicvoidrun ()
{ //重新 run () 方法
for (intturn= 0 ;turn<MAX_TURN; turn++)
{
sleepMilliSeconds ( 500 ); //线程睡眠


```
第 1 章多线程原理与实战 | 37
```
Print.tco ("线程执行轮次: "+turn);
}
}
}
publicstaticvoidmain (Stringargs[])
{
RunTargettarget=newRunTarget (); //实例化 Runnable 异步执行目标类
newThread (target). start (); //系统自动设置线程名称
newThread (target). start (); //系统自动命令线程名称
newThread (target). start (); //系统自动命令线程名称
newThread (target,"手动命名线程-A"). start (); //手动设置线程名称
newThread (target,"手动命名线程-B"). start (); //手动设置线程名称
sleepSeconds (Integer. MAX_VALUE); //主线程不能结束
}
};
运行程序，部分输出如下：
[Thread- 0 ]：线程执行轮次: 0
[手动命名线程-B]：线程执行轮次: 0
[Thread- 1 ]：线程执行轮次: 0
[Thread- 2 ]：线程执行轮次: 0
[手动命名线程-A]：线程执行轮次: 0
[手动命名线程-A]：线程执行轮次: 1
...
从输出结果可以看到：如果线程名称没有手动设置，线程将使用“Thread-”加上自动编号的
形式进行自动命名，如 Thread- 0 、Thread- 1 等。
在以上代码中，并没有看到使用 getName () 去获取线程名称，获取线程名称并且输出到控制台
的操作是在 Print.tco () 方法中完成的。这是一个自定义的辅助方法，帮助用户在输出信息时自动输
出线程名称，省去了特意、单独地进行一次 getName () 实例方法的调用。Print.tco () 方法的代码如下：
packagecom. crazymakercircle. util;
publicclassPrint
{
/**
*在正式输出的内容前，输出线程的名称
*@params 待输出的字符串
*/
publicstaticvoidtco (Objects)
{
Stringcft="["+Thread.currentThread (). getName ()+"]"+"："+s;
//提交线程池进行异步输出，使得输出过程不影响当前线程的执行
//异步输出的好处：不会造成输出乱序，也不会造成当前线程阻塞
ThreadUtil.execute (()->
{
synchronized (System. out)
{
System.out.println (cft);
}
});
}
//省略不相关的代码
}
在以上代码中，调用了 Thread.currentThread () 静态方法获取当前正在执行的线程，简称为当前
线程。准确地说，当前线程就是正在执行当前代码逻辑的 Java 线程。


38 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
编程规范要求：创建线程或线程池时，需要指定有意义的线程名称，方便出错
时回溯。
```
###### 1. 5. 2 线程的 sleep 操作

sleep 的作用是让目前正在执行的线程休眠，让 CPU 去执行其他的任务。从线程状态来说，就
是从执行状态变成限时阻塞状态。sleep () 方法定义在 Thread 类中，是一组静态方法，有两个重载
版本：
//使目前正在执行的线程休眠 millis 毫秒
publicstaticvoidsleep (longmillis) throwsInterruptException；
//使目前正在执行的线程休眠 millis 毫秒，nanos 纳秒
publicstaticvoidsleep (longmillis，intnanos) throwsInterruptException；
sleep () 方法会有 InterruptException 受检异常抛出，如果调用了 sleep () 方法，就必须进行异常审
查，捕获 InterruptedException 异常，或者再次通过方法声明存在 InterruptedException 异常。
举一个示例演示一下 sleep () 静态方法的使用，具体如下：
packagecom. crazymakercircle. mutithread. basic. use;
//省略 import
publicclassSleepDemo
{
publicstaticfinalintSLEEP_GAP= 5000 ; //睡眠时长 5 秒
publicstaticfinalintMAX_TURN= 50 ; //睡眠次数，稍微多点方便使用 Jstack
staticclassSleepThreadextendsThread
{
staticintthreadSeqNumber= 1 ;
publicSleepThread ()
{
super ("sleepThread-"+threadSeqNumber);
threadSeqNumber++;
}
publicvoidrun ()
{
try
{
for (inti= 1 ;i<MAX_TURN; i++)
{
Print.tco (getName ()+", 睡眠轮次："+i);
//线程睡眠一会
Thread.sleep (SLEEP_GAP);
}
}catch (InterruptedExceptione)
{
Print.tco (getName ()+"发生异常被中断.");
}
Print.tco (getName ()+"运行结束.");
}
}
publicstaticvoidmain (Stringargs[]) throwsInterruptedException
{
for (inti= 0 ;i< 5 ;i++)
{


```
第 1 章多线程原理与实战 | 39
```
Threadthread=newSleepThread ();
thread.start ();
}
Print.tco (getCurThreadName ()+"运行结束.");
}
}
运行以上程序，然后通过 Jstack 命令可以去查看 4 个睡眠线程的状态，不过在此之前需要使用 jps
指令查找出以上程序对应的 JVM 进程 SleepDemo 的进程 ID，具体的命令使用过程以及其大致输出的
信息截取如下：
C:\Users\user>jps
8468 Jps
18024 SleepDemo
C:\Users\user>jstack 18024
//省略不相干的输出
"sleepThread- 4 "# 17 prio= 5 os_prio= 0 tid= 0 x 000000001 fd 21800 nid= 0 x 462 cwaitingon
condition[ 0 x 0000000020 cbf 000 ]
java. lang. Thread. State: TIMED_WAITING (sleeping)
atjava.lang.Thread.sleep (NativeMethod)
at... SleepDemo$SleepThread.run (SleepDemo. java: 35 )
"sleepThread- 3 "# 16 prio= 5 os_prio= 0 tid= 0 x 000000001 fd 1 e 800 nid= 0 x 28 a 4 waitingon
condition[ 0 x 0000000020 bbf 000 ]
java. lang. Thread. State: TIMED_WAITING (sleeping)
atjava.lang.Thread.sleep (NativeMethod)
at... SleepDemo$SleepThread.run (SleepDemo. java: 35 )
"sleepThread- 2 "# 15 prio= 5 os_prio= 0 tid= 0 x 000000001 fd 1 e 000 nid= 0 x 1264 waitingon
condition[ 0 x 0000000020 abf 000 ]
java. lang. Thread. State: TIMED_WAITING (sleeping)
atjava.lang.Thread.sleep (NativeMethod)
at... SleepDemo$SleepThread.run (SleepDemo. java: 35 )
"sleepThread- 1 "# 14 prio= 5 os_prio= 0 tid= 0 x 000000001 fd 29000 nid= 0 x 1914 waitingon
condition[ 0 x 00000000209 be 000 ]
java. lang. Thread. State: TIMED_WAITING (sleeping)
atjava.lang.Thread.sleep (NativeMethod)
at... SleepDemo$SleepThread.run (SleepDemo. java: 35 )
通过以上的 Jstack 指令输出，可以看到在进行线程 DUMP 的时间点，所创建的 4 个 sleepThread
线程都处于 TIMED_WAITING（sleeping）状态。
当线程睡眠时间满后，线程不一定会立即得到执行，因为此时 CPU 可能正在执行其他的任务，
线程首先是进入就绪状态，等待分配 CPU 时间片以便有机会执行。

###### 1. 5. 3 线程的 interrupt 操作

Java 语言提供了 stop () 方法终止正在运行的线程，但是 Java 将 Thread 的 stop () 方法设置为过时，
不建议大家使用。为什么呢？因为使用 stop () 方法是很危险的，就像突然关闭计算机电源，而不是
按正常程序关机。在程序中，我们是不能随便中断一个线程的，我们无法知道这个线程正运行在什
么状态，它可能持有某把锁，强行中断线程可能导致锁不能被释放的问题；或者线程可能在操作数
据库，强行中断线程可能导致数据不一致的问题。正是由于使用 stop () 方法来终止线程可能会产生
不可预料的结果，因此并不推荐调用 stop () 方法。
一个线程什么时候可以退出呢？当然只有线程自己才能知道。所以，这里介绍一下 Thread 的


40 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

interrupt () 方法，此方法本质不是用来中断一个线程，而是将线程设置为中断状态。
当我们调用线程的 interrupt () 方法时，它有两个作用：
1 ）如果此线程处于阻塞状态（如调用了 Object.wait () 方法），就会立马退出阻塞，并抛出
InterruptedException 异常，线程就可以通过捕获 InterruptedException 来做一定的处理，然后让线程退
出。更确切地说，如果线程被 Object.wait ()、Thread.join () 和 Thread.sleep () 三种方法之一阻塞，此时
调用该线程的 interrupt () 方法，该线程将抛出一个 InterruptedException 中断异常（该线程必须事先预
备好处理此异常），从而过早终结被阻塞状态。
2 ）如果此线程正处于运行中，线程就不受任何影响，继续运行，仅仅是线程的中断标记被设
置为 true。所以，程序可以在适当的位置通过调用 isInterrupted () 方法来查看自己是否被中断，并执
行退出操作。

```
如果线程的 interrupt () 方法先被调用，然后线程开始调用阻塞方法进入阻塞状态，
InterruptedException 异常依旧会抛出。如果线程捕获 InterruptedException 异常后，继续调用阻
塞方法，将不再触发 InterruptedException 异常。
```
```
下面是一个调用 interrupt () 方法的实例，代码如下：
packagecom. crazymakercircle. mutithread. basic. use;
//省略 import
publicclassInterruptDemo
{
publicstaticfinalintSLEEP_GAP= 5000 ; //睡眠时长
publicstaticfinalintMAX_TURN= 50 ; //睡眠次数
staticclassSleepThreadextendsThread
{
staticintthreadSeqNumber= 1 ;
publicSleepThread ()
{
super ("sleepThread-"+threadSeqNumber);
threadSeqNumber++;
}
publicvoidrun ()
{
try
{
Print.tco (getName ()+"进入睡眠.");
//线程睡眠一会儿
Thread.sleep (SLEEP_GAP);
}catch (InterruptedExceptione)
{
e.printStackTrace ();
Print.tco (getName ()+"发生被异常打断.");
return;
}
Print.tco (getName ()+"运行结束.");
}
}
publicstaticvoidmain (Stringargs[]) throwsInterruptedException
{
Threadthread 1 =newSleepThread ();
```

```
第 1 章多线程原理与实战 | 41
```
thread 1 .start ();
Threadthread 2 =newSleepThread ();
thread 2 .start ();
sleepSeconds ( 2 ); //主线程等待 2 秒
thread 1 .interrupt (); //打断线程 1
sleepSeconds ( 5 ); //主线程等待 5 秒
thread 2 .interrupt (); //打断线程 2 ，此时线程 2 已经终止
sleepSeconds ( 1 ); //主线程等待 1 秒
Print.tco ("程序运行结束.");
}
}
运行程序，结果大致如下：
[sleepThread- 2 ]：sleepThread- 2 进入睡眠.
[sleepThread- 1 ]：sleepThread- 1 进入睡眠.
java. lang. InterruptedException:sleepinterrupted
atjava.lang.Thread.sleep (NativeMethod)
at... InterruptDemo$SleepThread.run (InterruptDemo. java: 33 )
[sleepThread- 1 ]：sleepThread- 1 发生被异常打断.
[sleepThread- 2 ]：sleepThread- 2 运行结束.
[main]：程序运行结束.
从结果可以看到，sleepThread- 1 线程在大致睡眠了 2 秒后，被主线程打断（或者中断）。被打
断的 sleepThread- 1 线程停止睡眠，并捕获到 InterruptedException 受检异常。程序在异常处理时直接
返回了，其后面的执行逻辑被跳过。
从结果还可以看到，sleepThread- 2 线程在睡眠了 7 秒后，被主线程中断，但是在 sleepThread- 2
线程被中断的时候，其执行已经结束了，所以 thread 2 .interrupt () 中断操作没有发生实质性的效果。
Thread.interrupt () 方法并不像 Thread.stop () 方法那样中止一个正在运行的线程，其作用是设置线
程的中断状态位（为 true），至于线程是死亡、等待新的任务还是继续运行至下一步，就取决于这
个程序本身。线程可以不时地检测这个中断标示位，以判断线程是否应该被中断（中断标示值是否
为 true）。总之，Thread.interrupt () 方法只是改变中断状态，不会中断一个正在运行的线程，线程是否
停止执行，需要用户程序去监视线程的 isInterrupted () 状态，并进行相应的处理。
下面的示例程序演示如何使用 isInterrupted () 实例方法监视线程的中断状态，如果发现线程被中
断，就进行相应的处理，具体的代码如下：
packagecom. crazymakercircle. mutithread. basic. use;
//省略 import
publicclassInterruptDemo
{
//测试用例：获取异步调用的结果
@Test
publicvoidtestInterrupted 2 ()
{
Threadthread=newThread ()
{
publicvoidrun ()
{
Print.tco ("线程启动了");
//一直循环
while (true)
{


42 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
Print.tco (isInterrupted ());
sleepMilliSeconds ( 5000 );
//如果线程被中断，退出死循环
if ( isInterrupted ())
{
Print.tco ("线程结束了");
return;
}
}
}
};
thread.start ();
sleepSeconds ( 2 ); //等待 2 秒
thread.interrupt (); //中断线程
sleepSeconds ( 2 ); //等待 2 秒
thread.interrupt ();
}
}
运行程序，输出的结果如下：
[Thread- 0 ]：线程启动了
[Thread- 0 ]：false
[Thread- 0 ]：线程结束了
```
###### 1. 5. 4 线程的 join 操作

线程的合并是一个比较难以说清楚的概念，什么是线程的合并呢？举一个例子，假设有两个
线程 A 和 B，现在线程 A 在执行过程中对另一个线程 B 的执行有依赖，具体的依赖为：线程 A 需要线
程 B 的执行流程合并到自己的执行流程中（至少表面如此），这就是线程合并，被动方线程 B 可以
叫作被合并线程。这个例子中线程 A 合并线程 B 的伪代码大致为：
classThreadAextendsThread
{
voidrun ()
{
Threadthreadb=newThread ("thread-b");
threadb. **join** ();
}
}
1 .线程的 join 操作的三个版本
Join () 方法是 Thread 类的一个实例方法，有三个重载版本：
//重载版本 1 ：此方法会把当前线程变为 WAITING，直到被合并线程执行结束
publicfinalvoidjoin () throwsInterruptedException：
//重载版本 2 ：此方法会把当前线程变为 TIMED_WAITING，直到被合并线程结束，或者等待被合并线程执行 millis
的时间
publicfinalsynchronizedvoidjoin (longmillis) throwsInterruptedException：
//重载版本 3 ：此方法会把当前线程变为 TIMED_WAITING，直到被合并线程结束，或者等待被合并线程执行
millis+nanos 的时间
publicfinalsynchronizedvoidjoin (longmillis, intnanos) throwsInterruptedException：
调用 join () 方法的要点：
1 ）join () 方法是实例方法，需要使用被合并线程的句柄（或者指针、变量）去调用，如


```
第 1 章多线程原理与实战 | 43
```
threadb.join ()。执行 threadb.join () 这行代码的当前线程为合并线程（甲方），进入 TIMED_WAITING
等待状态，让出 CPU。
2 ）如果设置了被合并线程的执行时间 millis（或者 millis+nanos），并不能保证当前线程一定
会在 millis 时间后变为 RUNNABLE。
3 ）如果主动方合并线程在等待时被中断，就会抛出 InterruptedException 受检异常。

```
调用 join () 方法的语句可以理解为合并点，合并的本质是：线程 A 需要在合并点
等待，一直等到线程 B 执行完成，或者等待超时。
```
为了方便表达，本书将依赖的线程 A 叫作甲方线程，被依赖的线程 B 叫作乙方线程。简单理解
线程合并就是甲方线程调用乙方线程的 join () 方法，在执行流程上将乙方线程合并到甲方线程。甲
方线程等待乙方线程执行完成后，甲方线程再继续执行，如图 1 - 12 所示。

图 1 - 12 线程合并的示意图
如果乙方线程无限制长时间地执行，甲方线程可以进行限时等待：甲方线程等待乙方线程执
行一定的时间后，如果乙方还没有完成，甲方线程再继续执行。
使用 join () 方法的优势是比较简单的，劣势是 join () 方法没有办法直接取得乙方线程的执行结果。
2 .线程的 join 操作的演示实例
packagecom. crazymakercircle. mutithread. basic. use;
//省略 import
publicclassJoinDemo
{
publicstaticfinalintSLEEP_GAP= 5000 ; //睡眠时长
publicstaticfinalintMAX_TURN= 50 ; //睡眠次数
staticclassSleepThreadextendsThread
{
//省略 SleepThread 的代码，执行时睡眠 5 秒


44 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

//具体代码与上一个小节的 SleepThread 内部类相同，也可以参考随书源码
}
publicstaticvoidmain (Stringargs[])
{
Threadthread 1 =newSleepThread ();
Print.tco ("启动 thread 1 .");
thread 1 .start ();
try
{
thread 1 .join (); //合并线程 1 ，不限时
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}
Print.tco ("启动 thread 2 .");
//启动第二条线程，并且进行限时合并，等待时间为 1 秒
Threadthread 2 =newSleepThread ();
thread 2 .start ();
try
{
thread 2 .join ( 1000 ); //限时合并，限时 1 秒
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}
Print.tco ("线程运行结束.");
}
}
运行程序，执行的结果如下：
[main]：启动 thread 1.
[sleepThread- 1 ]：sleepThread- 1 进入睡眠.
[sleepThread- 1 ]：sleepThread- 1 运行结束.
[main]：启动 thread 2.
[sleepThread- 2 ]：sleepThread- 2 进入睡眠.
[sleepThread- 2 ]：sleepThread- 2 运行结束.
[main]：线程运行结束.
3 .join 线程的 WAITING 状态
线程的 WAITING（等待）状态表示线程在等待被唤醒。处于 WAITING 状态的线程不会被分配
CPU 时间片。执行以下两个操作，当前线程将处于 WAITING 状态：

1 ）执行没有时限（timeout）参数的 thread.join () 调用：在线程合并场景中，若线程 A 调用B.join ()
去合入 B 线程，则在 B 执行期间线程 A 处于 WAITING 状态，一直等线程 B 执行完成。
2 ）执行没有时限参数的 object.wait () 调用：指一个拥有 object 对象锁的线程，进入到相应的代
码临界区后，调用相应的 object 的 wait () 方法去等待其“对象锁”（ObjectMonitor）上的信号，若“对
象锁”上没有信号，则当前线程处于 WAITING 状态，如图 1 - 13 所示。

通过 Jstack 指令 DUMP 出来上面 JoinDemo 演示实例执行过程中的线程信息，当 main 线程合入
sleepThread- 1 线程的时候，sleepThread- 1 处于 TIMED_WAITING 状态（sleep 操作导致），main 线程
也处于 WAITING 状态。Jstack 指令的部分输出结果截取如下：


```
第 1 章多线程原理与实战 | 45
```
```
图 1 - 13 线程的 WAITING 状态
C:\Users\user>jps
13660 JoinDemo
C:\Users\user>Jstack 13660
//省略部分输出
"sleepThread- 1 "# 14 prio= 5 os_prio= 0 tid= 0 x 000000001 fa 69000 nid= 0 x 35 d 8 waitingon
condition[ 0 x 000000002068 f 000 ]
java. lang. Thread. State: TIMED_WAITING (sleeping)
atjava.lang.Thread.sleep (NativeMethod)
at... JoinDemo$SleepThread.run (JoinDemo. java: 33 )
"main"# 1 prio= 5 os_prio= 0 tid= 0 x 0000000003216000 nid= 0 x 2914 inObject.wait ()
[ 0 x 000000000305 f 000 ]
java.lang.Thread.State: WAITING (onobjectmonitor)
atjava.lang.Object.wait (NativeMethod)
```
- waitingon< 0 x 000000076 b 8 a 3128 >(a... JoinDemo$SleepThread)
atjava.lang.Thread.join (Thread. java: 1245 )
- locked< 0 x 000000076 b 8 a 3128 >(a... use. JoinDemo$SleepThread)
atjava.lang.Thread.join (Thread. java: 1319 )
at...JoinDemo.main (JoinDemo. java: 53 )
4 .join 线程的 TIMED_WAITING 状态
线程的 TIMED_WAITING 状态表示在等待唤醒。处于 TIMED_WAITING 状态的线程不会被分
配 CPU 时间片，它们要等待被唤醒，或者直到等待的时限到期。
在线程合入场景中，若线程 A 在调用B.join () 操作时加入了时限参数，则在 B 执行期间线程 A 处
于 TIMED_WAITING 状态。若 B 在等待时限内没有返回，则线程 A 结束等待 TIMED_WAITING 状态，
恢复成 RUNNABLE 状态。
通过 Jstack 指令 DUMP 出来 JoinDemo 演示实例执行过程中的线程信息，在 main 线程合入
sleepThread- 2 线程的时候，sleepThread- 2 处于 TIMED_WAITING 状态（sleep 操作导致），main 线程
也处于 TIMED_WAITING 状态。Jstack 指令的部分输出结果截取如下：
C:\Users\user>jps
11736 JoinDemo

```
start () run () 结束
```

46 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
C:\Users\user>Jstack 11736
//省略部分输出
"sleepThread- 2 "# 16 prio= 5 os_prio= 0 tid= 0 x 000000001 f 61 c 800 nid= 0 x 318 waitingon
condition[ 0 x 000000002036 f 000 ]
java. lang. Thread. State: TIMED_WAITING ( sleeping )
atjava.lang.Thread.sleep (NativeMethod)
at... JoinDemo$SleepThread.run (JoinDemo. java: 33 )
"main"# 1 prio= 5 os_prio= 0 tid= 0 x 0000000002 de 6000 nid= 0 x 2 ec 4 inObject.wait ()
[ 0 x 0000000002 cdf 000 ]
java. lang. Thread. State: TIMED_WAITING (onobjectmonitor)
atjava.lang.Object.wait (NativeMethod)
```
- waitingon< 0 x 000000076 bdfb 838 >(a... JoinDemo$SleepThread)
atjava.lang.Thread.join (Thread. java: 1253 )
- locked< 0 x 000000076 bdfb 838 >(a... JoinDemo$SleepThread)
at...JoinDemo.main (JoinDemo. java: 65 )

###### 1. 5. 5 线程的 yield 操作

线程的 yield（让步）操作的作用是让目前正在执行的线程放弃当前的执行，让出 CPU 的执行
权限，使得 CPU 去执行其他的线程。处于让步状态的 JVM 层面的线程状态仍然是 RUNNABLE 状态，
但是该线程所对应的操作系统层面的线程从状态上来说会从执行状态变成就绪状态。线程在 yield
时，线程放弃和重占 CPU 的时间是不确定的，可能是刚刚放弃 CPU，马上又获得 CPU 执行权限，重
新开始执行。
yield () 方法是 Thread 类提供的一个静态方法，它可以让当前正在执行的线程暂停，但它不会阻
塞该线程，只是让线程转入就绪状态。yield 只是让当前线程暂停一下，让系统的线程调度器重新调
度一次，yield () 方法只有一个版本：
packagecom. crazymakercircle. mutithread. basic. use;
//省略 import
publicclassYieldDemo
{
publicstaticfinalintMAX_TURN= 100 ; //执行次数
publicstaticAtomicIntegerindex=newAtomicInteger ( 0 ); //执行编号
//记录线程的执行次数
privatestaticMap<String,AtomicInteger>metric=newHashMap<>();
//输出线程的执行次数
privatestaticvoidprintMetric ()
{
Print.tco ("metric="+metric);
}
staticclassYieldThreadextendsThread
{
staticintthreadSeqNumber= 1 ;
publicYieldThread ()
{
super ("sleepThread-"+threadSeqNumber);
threadSeqNumber++;
//将线程加入到执行次数统计 map
metric.put (this.getName (), newAtomicInteger ( 0 ));
}
publicvoidrun ()
{
for (inti= 1 ;i<MAX_TURN&&index.get ()<MAX_TURN; i++)


```
第 1 章多线程原理与实战 | 47
```
{
Print.tco ("线程优先级："+getPriority ());
index.incrementAndGet ();
//统计一次
metric.get (this.getName ()). incrementAndGet ();
if (i% 2 == 0 )
{
//让步：出让执行的权限
Thread.yield ();
}
}
//输出所有线程的执行次数
printMetric ();
Print.tco (getName ()+"运行结束.");
}
}
@Test
publicvoidtest ()
{
Threadthread 1 =newYieldThread ();
//设置为最高的优先级
thread 1 .setPriority (Thread. MAX_PRIORITY);
Threadthread 2 =newYieldThread ();
//设置为最低的优先级
thread 2 .setPriority (Thread. MIN_PRIORITY);
Print.tco ("启动线程.");
thread 1 .start ();
thread 2 .start ();
sleepSeconds ( 100 );
}
}
执行以上代码，部分结果输出如下：
[main]：启动线程.
[YieldThread- 1 ]：线程优先级： 10
[YieldThread- 1 ]：线程优先级： 10
[YieldThread- 1 ]：线程优先级： 10
[YieldThread- 1 ]：线程优先级： 10
[YieldThread- 1 ]：线程优先级： 10
[YieldThread- 1 ]：线程优先级： 10
[YieldThread- 2 ]：线程优先级： 1
[YieldThread- 1 ]：线程优先级： 10
[YieldThread- 2 ]：线程优先级： 1
[YieldThread- 1 ]：线程优先级： 10
[YieldThread- 2 ]：线程优先级： 1
...
[YieldThread- 1 ]：metric={YieldThread- 2 = 36 ,YieldThread- 1 = 64 }
[YieldThread- 1 ]：YieldThread- 1 运行结束.
[YieldThread- 2 ]：线程优先级： 1
[YieldThread- 2 ]：metric={YieldThread- 2 = 37 ,YieldThread- 1 = 64 }
[YieldThread- 2 ]：YieldThread- 2 运行结束.
在以上演示案例中，一共启动了两个让步演示线程，两个线程每执行两次操作就让出 CPU。
但是两个线程的优先级有区别，YieldThread- 1 的优先级为 Thread. MAX_PRIORITY（值为 10 ），
YieldThread- 2 的优先级为 Thread. MIN_PRIORITY（值为 1 ），从输出的结果可以看出，优先级高的
YieldThread- 1 执行的次数比优先级低的 YieldThread- 2 在执行的次数多很多。得到的结论是：线程调
用 yield 之后，操作系统在重新进行线程调度时偏向于将执行机会让给优先级较高的线程。


48 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

总结起来，Thread.yield () 方法有以下特点：
1 ）yield 仅能使一个线程从运行状态转到就绪状态，而不是阻塞状态。
2 ）yield 不能保证使得当前正在运行的线程迅速转换到就绪状态。
3 ）即使完成了迅速切换，系统通过线程调度机制从所有就绪线程中挑选下一个执行线程时，
就绪的线程有可能被选中，也有可能不被选中，其调度的过程受到其他因素（如优先级）的影响。

###### 1. 5. 6 线程的 daemon 操作

Java 中的线程分为两类：守护线程与用户线程。守护线程也称为后台线程，专门指在程序进程
运行过程中，在后台提供某种通用服务的线程。比如，每启动一个 JVM 进程，都会在后台运行着一
系列的 GC（垃圾回收）线程，这些 GC 线程就是守护线程，提供幕后的垃圾回收服务。使用 Jstack 指
令 DUMP 某个 JVM 进程时，截取到的如下 GC 线程如下：
"GCtaskthread# 0 (ParallelGC)"os_prio= 0 tid= 0 x 000000000322 b 800 nid= 0 x 3 db 0 runnable
"GCtaskthread# 1 (ParallelGC)"os_prio= 0 tid= 0 x 000000000322 e 000 nid= 0 x 3 ca 8 runnable
"GCtaskthread# 2 (ParallelGC)"os_prio= 0 tid= 0 x 000000000322 f 800 nid= 0 x 1240 runnable
"GCtaskthread# 3 (ParallelGC)"os_prio= 0 tid= 0 x 0000000003231000 nid= 0 x 79 crunnable
"GCtaskthread# 4 (ParallelGC)"os_prio= 0 tid= 0 x 0000000003233800 nid= 0 x 1770 runnable
"GCtaskthread# 5 (ParallelGC)"os_prio= 0 tid= 0 x 0000000003234800 nid= 0 x 3 b 1 crunnable
"GCtaskthread# 6 (ParallelGC)"os_prio= 0 tid= 0 x 0000000003238000 nid= 0 x 2 cc 8 runnable
"GCtaskthread# 7 (ParallelGC)"os_prio= 0 tid= 0 x 0000000003239000 nid= 0 x 3008 runnable
//省略其他的输出
举一个比较通俗的例子，守护线程在 JVM 相当于保姆的角色：只要 JVM 实例中尚存在任何一
个用户线程没有结束，守护线程就能执行自己工作；只有当最后一个用户线程结束，守护线程随着
JVM 一同结束工作。

1 .守护线程的基本操作
在 Thread 类中，有一个实例属性和两个实例方法，专门用于进行守护线程相关的操作。
1 ）实例属性 daemon：保存一个 Thread 线程实例的守护状态，默认为 false，表示线程默认为用
户线程。
privatebooleandaemon=false；
2 ）实例方法 setDaemon (...)：此方法将线程标记为守护线程或者用户线程。setDaemon (true) 将
线程设置为守护线程，setDaemon (false) 将线程设置为用户线程。
publicfinalvoidsetDaemon (booleanon)；
3 ）实例方法 isDaemon ()：获取线程的守护状态，用于判断该线程是不是守护线程。
publicfinalbooleanisDaemon ();
2 .守护线程的基本操作演示实例
举一个例子，演示守护线程的两个实例方法的使用，具体如下：
packagecom. crazymakercircle. mutithread. basic. use;
//省略 import
publicclassDaemonDemo


```
第 1 章多线程原理与实战 | 49
```
{
publicstaticfinalintSLEEP_GAP= 500 ; //每一轮的睡眠时长
publicstaticfinalintMAX_TURN= 4 ; //用户线程执行轮次
//守护线程实现类
staticclassDaemonThreadextendsThread
{
publicDaemonThread ()
{
super ("daemonThread");
}
publicvoidrun ()
{
Print.synTco ("--daemon 线程开始.");
for (inti= 1 ;; i++) //死循环
{
Print.synTco ("--轮次："+i);
Print.synTco ("--守护状态为: "+isDaemon ());
//线程睡眠一会儿， 500 毫秒
sleepMilliSeconds (SLEEP_GAP);
}
}
}
publicstaticvoidmain (Stringargs[]) throwsInterruptedException
{
ThreaddaemonThread=newDaemonThread ();
daemonThread.setDaemon (true);
daemonThread.start ();
//创建一个用户线程，执行 4 轮
ThreaduserThread=newThread (()->
{
Print.synTco (">>用户线程开始.");
for (inti= 1 ;i<=MAX_TURN; i++)
{
Print.synTco (">>轮次："+i);
Print.synTco (">>守护状态为: "+getCurThread (). isDaemon ());
sleepMilliSeconds (SLEEP_GAP);
}
Print.synTco (">>用户线程结束.");
},"userThread");
//启动用户线程
userThread.start ();
Print.synTco ("守护状态为: "+getCurThread (). isDaemon ());
Print.synTco ("运行结束.");
}
}

运行程序，大致的结果如下：
[daemonThread]：--daemon 线程开始.
[daemonThread]：--轮次： 1 - -守护状态为:true
[main]：守护状态为:false
[main]：运行结束.
[userThread]：>>用户线程开始.
[userThread]：>>轮次： 1 - 守护状态为:false
[daemonThread]：--轮次： 2 - -守护状态为:true
[userThread]：>>轮次： 2 - 守护状态为:false
[daemonThread]：--轮次： 3 - -守护状态为:true


50 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

[userThread]：>>轮次： 3 - 守护状态为:false
[daemonThread]：--轮次： 4 - -守护状态为:true
[userThread]：>>轮次： 4 - 守护状态为:false
[daemonThread]：--轮次： 5 - -守护状态为:true
[userThread]：>>用户线程结束.
本例创建了两个线程：一个线程为守护线程，其名称为 daemonThread，使用继承 Thread 的方式
创建；另一个线程为用户线程，其名称为 userThread，使用 Lambda 表达式新建了一个 Runnable 实例
后，传入 Thread 构造器创建。
在守护线程 daemonThread 的 run () 方法中设置了一个 for 死循环（没有条件判断表达式的循环），
启动之后，理论上永远也不会停止。程序中使用 setDaemon (true) 语句将 daemonThread 线程设置成守
护线程。
在用户线程 userThread 的匿名 run () 方法中设置了一个能循环 4 轮的 for 循环。每一轮循环，输出
当前的轮次和当前线程的守护状态等信息。程序中，userThread 线程的 daemon 属性还是默认的 false
值，因此该线程为用户线程。
从例子的输出结果来看，main 线程也是一条用户线程。main 线程在创建和启动了 daemonThread
和 userThread 后，就提前结束了。虽然 main 线程结束了，但是两条线程还在继续执行，其中就有一
个用户线程，所以进程还不能结束。当剩下的一个用户线程 userThread 的 run () 方法执行完成后，
userThread 线程执行结束。这时，所有的用户线程执行已经完成，JVM 进程就随之退出了。
在 JVM 退出时，守护线程 daemonThread 远远没有结束，还在死循环的执行中。但是 JVM 不管
这些，强行终止了所有守护线程的执行。

3 .守护线程与用户线程的关系
从是否为守护线程的角度，对 Java 线程进行分类，分为用户线程和守护线程。守护线程和用户
线程的本质区别：二者与 JVM 虚拟机进程终止的方向不同。用户线程和 JVM 进程是主动关系，如果
用户线程全部终止，JVM 虚拟机进程也随之终止；守护线程和 JVM 进程是被动关系，如果 JVM 进程
终止，所有的守护线程也随之终止，如图 1 - 14 所示。

图 1 - 14 守护线程与用户线程的关系
换个角度来理解，守护线程提供服务，是守护者，用户线程享受服务，是被守护者。只有全
部的用户线程终止了，相当于没有了被守护者，守护线程也就没有工作可做了，也就可以全部终止
了。当然，用户线程全部终止，JVM 进程也就没有继续的必要了。反过来说，只要有一个用户线程
没有终止，JVM 进程也不会退出。
但是在终止维度上，守护线程和 JVM 进程没有主动关系。也就是说，哪怕是守护线程全部被
终止，JVM 虚拟机也不一定终止。

```
4 .守护线程的要点
使用守护线程时，有以下几点需要特别注意：
```

```
第 1 章多线程原理与实战 | 51
```
1 ）守护线程必须在启动前将其守护状态设置为 true，启动之后不能再将用户线程设置为守护
线程，否则 JVM 会抛出一个 InterruptedException 异常。
具体来说，如果线程为守护线程，就必须在线程实例的 start () 方法调用之前调用线程实例的
setDaemon（true），设置其 daemon 实例属性值为 true。
2 ）守护线程存在被 JVM 强行终止的风险，所以在守护线程中尽量不去访问系统资源，如文件
句柄、数据库连接等。守护线程被强行终止时，可能会引发系统资源操作不负责任的中断，从而导
致资源不可逆的损坏。
3 ）守护线程创建的线程也是守护线程。
在守护线程中创建的线程，新的线程都是守护线程。在创建之后，如果通过调用 setDaemon (false)
将新的线程显式地设置为用户线程，新的线程可以调整成用户线程。

```
5 .守护线程创建的线程也是守护线程
举一个非常简单的例子，演示一下在守护线程中创建的线程也是守护线程。代码如下：
packagecom. crazymakercircle. mutithread. basic. use;
//省略 import
publicclassDaemonDemo 2 {
publicstaticfinalintSLEEP_GAP= 500 ; //每一轮的睡眠时长
publicstaticfinalintMAX_TURN= 4 ; //线程执行轮次
staticclassNormalThreadextendsThread{
staticintthreadNo= 1 ;
publicNormalThread (){
super ("normalThread-"+threadNo);
threadNo++;
}
publicvoidrun (){
for (inti= 0 ; ;i++)
{
sleepMilliSeconds (SLEEP_GAP);
Print.synTco (getName ()+", 守护状态为: "+isDaemon ());
}
}
}
publicstaticvoidmain (Stringargs[]) throwsInterruptedException{
ThreaddaemonThread=newThread (()->{
for (inti= 0 ;i< 5 ;i++){
ThreadnormalThread=newNormalThread ();
//normalThread.setDaemon (false);
normalThread.start ();
}
},"daemonThread");
daemonThread.setDaemon (true);
daemonThread.start ();
//这里一定不能让 main 线程立即结束，否则看不到结果
sleepMilliSeconds (SLEEP_GAP);
Print.synTco (getCurThreadName ()+"运行结束.");
}
}
运行程序，输出的结果如下：
[normalThread- 3 ]：normalThread- 3 ,守护状态为:true
[normalThread- 4 ]：normalThread- 4 ,守护状态为:true
```

52 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

[main]：main 运行结束.
[normalThread- 5 ]：normalThread- 5 ,守护状态为:true
[normalThread- 2 ]：normalThread- 2 ,守护状态为:true
[normalThread- 1 ]：normalThread- 1 ,守护状态为:true
本例中使用 Lambda 表达式方式创建一个 daemonThread 线程，这是一个守护线程。在这个守护
线程的业务代码中又创建了 5 个普通线程。 5 个新线程启动前，虽然 daemon 状态没有被设置为 true（预
期是用户线程），但是从程序的结果中可以看出，实际上这 5 个线程 daemon 状态为 true，都是守护
线程。
在本例中，main 线程加上 Thread. sleep（SLEEP_GAP）语句让 main 线程等待一段时间再结束。
这是非常必要的，为什么呢？因为另外的 6 个线程都是守护线程。只有 main 线程是唯一的一个用户
线程，为了看到守护线程所输出的部分结果，一定不能让 main 线程提前结束。
如果要将守护线程所创建的线程调整为用户线程，可以通过 setDaemon (false) 显式地将这些线
程设置为用户线程。上面的代码可以进行如下调整，将创建的 5 个新线程调整为用户线程：
ThreaddaemonThread=newThread (()->{
for (inti= 0 ;i< 5 ;i++){
ThreadnormalThread=newNormalThread ();
//显式地将这些线程设置为用户线程
normalThread.setDaemon (false);
normalThread.start ();
}
},"daemonThread");
daemonThread.setDaemon (true);
daemonThread.start ();
调整之后，再一次运行以上示例，大家可以去分析一下执行的结果。

###### 1. 5. 7 线程状态总结

接下来，将线程的 6 种状态以及各种状态的进入条件做一个总结。
1 .NEW 状态
通过 newThread (...) 已经创建线程，但尚未调用 start () 启动线程，该线程处于 NEW（新建）状态。
虽然前面介绍了 4 种方式创建线程，但是其中的其他三种方式本质上都是通过 newThread () 创建的线
程，仅仅是创建了不同的 target 执行目标实例（如 Runnable 实例）。

2 .RUNNABLE 状态
Java 把 Ready（就绪）和 Running（执行）两种状态合并为一种状态：RUNNABLE（可执行）
状态（或者可运行状态）。调用了线程的 start () 实例方法后，线程就处于就绪状态。此线程获取到
CPU 时间片后，开始执行 run () 方法中的业务代码，线程处于执行状态。

（ 1 ）就绪状态
就绪状态仅仅表示线程具备运行资格，如果没有被操作系统的调度程序选中，线程就永远是
就绪状态；当前线程进入就绪状态的条件大致包括以下几种：

```
 调用线程的 start () 方法，此线程进入就绪状态。
 当前线程的执行时间片用完。
```

```
第 1 章多线程原理与实战 | 53
```
 线程睡眠（sleep）操作结束。
 对其他线程合入（join）操作结束。
 等待用户输入结束。
 线程争抢到对象锁（ObjectMonitor）。
 当前线程调用了 yield () 方法出让 CPU 执行权限。
（ 2 ）执行状态
线程调度程序从就绪状态的线程中选择一个线程，被选中的线程状态将变成执行状态。这也
是线程进入执行状态的唯一方式。

3 .BLOCKED 状态
处于 BLOCKED（阻塞）状态的线程并不会占用 CPU 资源，以下情况会让线程进入阻塞状态：
（ 1 ）线程等待获取锁
等待获取一个锁，而该锁被其他线程持有，则该线程进入阻塞状态。当其他线程释放了该锁，
并且线程调度器允许该线程持有该锁时，该线程退出阻塞状态。

（ 2 ）IO 阻塞
线程发起了一个阻塞式 IO 操作后，如果不具备 IO 操作的条件，线程就会进入阻塞状态。IO 包
括磁盘 IO、网络 IO 等。IO 阻塞的一个简单例子：线程等待用户输入内容后继续执行。

网络 IO 阻塞的原理以及 Java 高性能 IO 编程的核心知识可参阅另一本书《Java 高
并发核心编程卷 1 （加强版）：NIO、Netty、Redis、ZooKeeper》。
4 .WAITING 状态
处于 WAITING（无限期等待）状态的线程不会被分配 CPU 时间片，需要被其他线程显式地唤
醒，才会进入就绪状态。线程调用以下 3 种方法让自己进入无限等待状态：

 Object.wait () 方法，对应的唤醒方式为：Object.notify ()/Object.notifyAll ()。
 Thread.join () 方法，对应的唤醒方式为：被合入的线程执行完毕。
 LockSupport.park () 方法，对应的唤醒方式为：LockSupport.unpark (Thread)。
5 .TIMED_WAITING 状态
处于 TIMED_WAITING（限时等待）状态的线程不会被分配 CPU 时间片，如果指定时间之内
没有被唤醒，限时等待的线程会被系统自动唤醒，进入就绪状态。以下 3 种方法会让线程进入限时
等待状态：

```
 Thread.sleep (time) 方法，对应的唤醒方式为：sleep 睡眠时间结束。
 Object.wait (time) 方法，对应的唤醒方式为：调用 Object.notify ()/Object.notifyAll () 去主动唤
醒，或者限时结束。
 LockSupport.parkNanos (time)/parkUntil (time) 方法，对应的唤醒方式为：线程调用配套的
LockSupport.unpark (Thread) 方法结束，或者线程停止（park）时限结束。
进入 BLOCKED 状态、WAITING 状态、TIMED_WAITING 状态的线程都会让出 CPU 的使用权；
```

54 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

另外，等待或者阻塞状态的线程被唤醒后，进入 Ready 状态，需要重新获取时间片才能接着运行。

6 .TERMINATED 状态
线程结束任务之后，将会正常进入 TERMINATED（死亡）状态；或者说在线程执行过程中发
生了异常（而没有被处理），也会导致线程进入死亡状态。

#### 1. 6 线程池原理与实战

Java 线程的创建非常昂贵，需要 JVM 和 OS（操作系统）配合完成大量的工作：
1 ）必须为线程堆栈分配和初始化大量内存块，其中包含至少 1 MB 的栈内存。
2 ）需要进行系统调用，以便在 OS（操作系统）中创建和注册本地线程。
Java 高并发应用频繁创建和销毁线程的操作将是非常低效的，而且是不被编程规范所允许的。
如何降低 Java 线程的创建成本？必须使用到线程池。线程池主要解决了以下两个问题：

1 ）提升性能：线程池能独立负责线程的创建、维护和分配。在执行大量异步任务时，可以不
需要自己创建线程，而是将任务交给线程池去调度。线程池能尽可能使用空闲的线程去执行异步任
务，最大限度地对已经创建的线程进行复用，使得性能提升明显。
2 ）线程管理：每个 Java 线程池会保持一些基本的线程统计信息，例如完成的任务数量、空闲
时间等，以便对线程进行有效管理，使得能对所接收到的异步任务进行高效调度。

```
在主要大厂的编程规范中，不允许在应用中自行显式地创建线程，线程必须通
过线程池提供。由于创建和销毁线程上需要时间以及系统资源开销，使用线程池的好处是减
少这些开销，解决资源不足的问题。
```
###### 1. 6. 1 JUC 的线程池架构

在多线程编程中，任务都是一些抽象且离散的工作单元，而线程是使任务异步执行的基本机
制。随着应用的扩张，线程和任务管理也变得非常复杂，为了简化这些复杂的线程管理模式，我们
需要一个“管理者”来统一管理线程及任务分配，这就是线程池。
在 JUC 中有关线程池的类与接口的架构图大致如图 1 - 15 所示。

```
JUC 就是 java. util. concurrent 工具包的简称，该工具包是从 JDK 1. 5 开始加入 JDK
的，是用于完成高并发、处理多线程的一个工具包。
```

```
第 1 章多线程原理与实战 | 55
```
图 1 - 15 JUC 中线程池的类与接口的架构
1 .Executor
Executor 是 Java 异步目标任务的“执行者”接口，其目标是来执行目标任务。“执行者”Executor
提供了 execute () 接口来执行已提交的 Runnable 执行目标实例。Executor 作为执行者的角色，其目的
是“任务提交者”与“任务执行者”分离开来的机制。它只包含一个函数式方法：
voidexecute (Runnablecommand)
2 .ExecutorService
ExecutorService 继承于 Executor。它是 Java 异步目标任务的“执行者服务”接口，对外提供异
步任务的接收服务，ExecutorService 提供了“接收异步任务并转交给执行者”的方法，如 submit 系
列方法、invoke 系列方法等。具体如下：
//向线程池提交单个异步任务
<T>Future<T>submit (Callable<T>task);
//向线程池提交批量异步任务
<T>List<Future<T>>invokeAll (Collection<?extendsCallable<T>>tasks)
throwsInterruptedException;
3 .AbstractExecutorService
AbstractExecutorService 是一个抽象类，它实现了 ExecutorService 接口。AbstractExecutorService
存在的目的是为 ExecutorService 中的接口提供默认实现。

4 .ThreadPoolExecutor
ThreadPoolExecutor 就是大名鼎鼎的“线程池”实现类，它继承于 AbstractExecutorService 抽
象类。
ThreadPoolExecutor 是 JUC 线程池的核心实现类。线程的创建和终止需要很大的开销，线程池


56 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

中预先提供了指定数量的可重用线程，所以使用线程池会节省系统资源，并且每个线程池都维护了
一些基础的数据统计，方便线程的管理和监控。

5 .ScheduledExecutorService
ScheduledExecutorService 是一个接口，它继承于 ExecutorService。它是一个可以完成“延时”
和“周期性”任务的调度线程池接口，其功能和 Timer/TimerTask 类似。

6 .ScheduledThreadPoolExecutor
ScheduledThreadPoolExecutor 继承于 ThreadPoolExecutor，它提供了 ScheduledExecutorService 线
程池接口中“延时执行”和“周期执行”等抽象调度方法的具体实现。
ScheduledThreadPoolExecutor 类似于 Timer，但是在高并发程序中，ScheduledThreadPoolExecutor
的性能要优于 Timer。

7 .Executors
Executors 是个静态工厂类，它通过静态工厂方法返回 ExecutorService、
ScheduledExecutorService 等线程池实例对象，这些静态工厂方法可以理解为一些快捷的创建线程池
的方法。

###### 1. 6. 2 Executors 的 4 种快捷创建线程池的方法

Java 通过 Executors 工厂类提供 4 种快捷创建线程池的方法，具体如表 1 - 1 所示。
表 1 - 1 Executors 工厂类提供的四种快捷创建线程池方法
方法名功能简介
newSingleThreadExecutor () 创建只有一个线程的线程池
newFixedThreadPool (intnThreads) 创建固定大小的线程池
newCachedThreadPool () 创但是建空一闲个线不程限会制得线到程及数时量回的收线程池，任何提交的任务都将立即执行，
newScheduledThreadPool () 创建一个可定期或者延时执行任务的线程池
1 .newSingleThreadExecutor 创建“单线程化线程池”
该方法用于创建一个“单线程化线程池”，也就是只有一条线程的线程池，所创建的线程池
用唯一的工作线程来执行任务，使用此方法创建的线程池能保证所有任务按照指定顺序（如 FIFO）
执行。
调用 Executors.newSingleThreadExecutor () 快捷工厂方法去创建一个“单线程化线程池”的测试
用例，其代码如下：
packagecom. crazymakercircle. mutithread. basic. create 3 ;
//省略 import
publicclassCreateThreadPoolDemo
{
publicstaticfinalintSLEEP_GAP= 500 ;
//异步任务的执行目标类
staticclassTargetTaskimplementsRunnable
{


```
第 1 章多线程原理与实战 | 57
```
staticAtomicIntegertaskNo=newAtomicInteger ( 1 );
privateStringtaskName;
publicTargetTask ()
{
taskName="task-"+taskNo.get ();
taskNo.incrementAndGet ();
}
publicvoidrun ()
{
Print.tco ("任务："+taskName+"doing");
//线程睡眠一会儿
sleepMilliSeconds (SLEEP_GAP);
Print.tco (taskName+"运行结束.");
}
}
//测试用例：只有一个线程的线程池
@Test
publicvoidtestSingleThreadExecutor ()
{
ExecutorServicepool=Executors.newSingleThreadExecutor ();
for (inti= 0 ;i< 5 ;i++)
{
pool.execute (newTargetTask ());
pool.submit (newTargetTask ());
}
sleepSeconds ( 1000 );
//关闭线程池
pool.shutdown ();
}
}
运行以上代码，部分结果截取如下：
[pool- 1 - thread- 1 ]：任务：task- 1 doing
[pool- 1 - thread- 1 ]：task- 1 运行结束.
[pool- 1 - thread- 1 ]：任务：task- 2 doing
...
[pool- 1 - thread- 1 ]：任务：task- 10 doing
[pool- 1 - thread- 1 ]：task- 10 运行结束.
从以上输出中可以看出，该线程池有以下特点：
1 ）单线程化的线程池中的任务，是按照提交的次序顺序执行的。
2 ）池中的唯一线程的存活时间是无限的。
3 ）当池中的唯一线程正繁忙时，新提交的任务实例会进入内部的阻塞队列中，并且其阻塞队
列是无界的。

总体来说，单线程化的线程池所适用的场景是：任务按照提交次序，一个任务接一个任务执
行的场景。
以上用例在最后调用 shutdown () 方法用来关闭线程池。执行 shutdown () 方法后，线程池状态变
为 SHUTDOWN 状态，此时线程池将拒绝新任务，不能再往线程池中添加新任务，否则会抛出
RejectedExecutionException 异常。此时，线程池不会立刻退出，直到添加到线程池中的任务都已经
处理完成才会退出。还有一个与 shutdown () 类似的方法，叫作 shutdownNow ()，执行 shutdownNow ()
方法后，线程池状态会立刻变成 STOP，并试图停止所有正在执行的线程，不再处理还在阻塞队列
中等待的任务，会返回那些未执行的任务。


58 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

2 .newFixedThreadPool 创建“固定数量的线程池”
该方法用于创建一个“固定数量的线程池”，其唯一的参数用于设置池中线程的“固定数量”。
调用 Executors.newFixedThreadPool (intthreads) 快捷工厂方法创建“固定数量的线程池”的测试用例，
其代码如下：
packagecom. crazymakercircle. mutithread. basic. create 3 ;
//省略 import
publicclassCreateThreadPoolDemo
{
publicstaticfinalintSLEEP_GAP= 500 ;
//异步任务的执行目标类
staticclassTargetTaskimplementsRunnable
{
//为了节约篇幅，省略重复内容
}
//测试用例：只有 3 个线程固定大小的线程池
@Test
publicvoidtestNewFixedThreadPool ()
{
ExecutorServicepool=Executors.newFixedThreadPool ( 3 );
for (inti= 0 ;i< 5 ;i++)
{
pool.execute (newTargetTask ());
pool.submit (newTargetTask ());
}
sleepSeconds ( 1000 );
//关闭线程池
pool.shutdown ();
}
//省略其他
}
执行以上测试用例，部分结果截取如下：
[pool- 1 - thread- 3 ]：任务：task- 3 doing
[pool- 1 - thread- 2 ]：任务：task- 2 doing
[pool- 1 - thread- 1 ]：任务：task- 1 doing
[pool- 1 - thread- 1 ]：task- 1 运行结束.
[pool- 1 - thread- 1 ]：任务：task- 4 doing
[pool- 1 - thread- 2 ]：task- 2 运行结束.
...
[pool- 1 - thread- 3 ]：任务：task- 8 doing
[pool- 1 - thread- 2 ]：任务：task- 9 doing
[pool- 1 - thread- 1 ]：task- 7 运行结束.
[pool- 1 - thread- 1 ]：任务：task- 10 doing
[pool- 1 - thread- 3 ]：task- 8 运行结束.
[pool- 1 - thread- 2 ]：task- 9 运行结束.
[pool- 1 - thread- 1 ]：task- 10 运行结束.
在测试用例中，创建了一个线程数为 3 的“固定数量线程池”，然后向其中提交了 10 个任务。
从输出结果可以看到，该线程池同时只能执行 3 个任务，剩余的任务会排队等待。
“固定数量的线程池”的特点大致如下：
1 ）如果线程数没有达到“固定数量”，每次提交一个任务池内就创建一个新线程，直到线程
达到线程池固定的数量。
2 ）线程池的大小一旦达到“固定数量”就会保持不变，如果某个线程因为执行异常而结束，
那么线程池会补充一个新线程。


```
第 1 章多线程原理与实战 | 59
```
3 ）在接收异步任务的执行目标实例时，如果池中的所有线程均在繁忙状态，新任务会进入阻
塞队列中（无界的阻塞队列）。

“固定数量的线程池”的适用场景：需要任务长期执行的场景。“固定数量的线程池”的线
程数能够比较稳定保证一个数，避免频繁回收线程和创建线程，故适用于处理 CPU 密集型的任务，
在 CPU 被工作线程长时间使用的情况下，能确保尽可能少地分配线程。
“固定数量的线程池”的弊端：内部使用无界队列来存放排队任务，当大量任务超过线程池
最大容量需要处理时，队列无线增大，使服务器资源迅速耗尽。

3 .newCachedThreadPool 创建“可缓存线程池”
该方法用于创建一个“可缓存线程池”，如果线程池内的某些线程无事可干成为空闲线程，
“可缓存线程池”可灵活回收这些空闲线程。
使用 Executors.newCachedThreadPool () 快捷工厂方法去创建一个“可缓存线程池”的测试用例，
其代码如下：
packagecom. crazymakercircle. mutithread. basic. create 3 ;
//省略 import
publicclassCreateThreadPoolDemo
{
publicstaticfinalintSLEEP_GAP= 500 ;
//异步任务的执行目标类
staticclassTargetTaskimplementsRunnable
{
//为了节约篇幅，省略重复内容
}
//测试用例：“可缓存线程池”
@Test
publicvoidtestNewCacheThreadPool ()
{
ExecutorServicepool=Executors.newCachedThreadPool ();
for (inti= 0 ;i< 5 ;i++)
{
pool.execute (newTargetTask ());
pool.submit (newTargetTask ());
}
sleepSeconds ( 1000 );
//关闭线程池
pool.shutdown ();
}
//省略其他
}
运行以上测试用例，结果如下：
[pool- 1 - thread- 9 ]：任务：task- 9 doing
[pool- 1 - thread- 2 ]：任务：task- 2 doing
[pool- 1 - thread- 7 ]：任务：task- 7 doing
[pool- 1 - thread- 5 ]：任务：task- 5 doing
[pool- 1 - thread- 8 ]：任务：task- 8 doing
[pool- 1 - thread- 3 ]：任务：task- 3 doing
[pool- 1 - thread- 1 ]：任务：task- 1 doing
[pool- 1 - thread- 4 ]：任务：task- 4 doing
[pool- 1 - thread- 6 ]：任务：task- 6 doing
[pool- 1 - thread- 10 ]：任务：task- 10 doing
[pool- 1 - thread- 5 ]：task- 5 运行结束.


60 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

[pool- 1 - thread- 3 ]：task- 3 运行结束.
[pool- 1 - thread- 7 ]：task- 7 运行结束.
[pool- 1 - thread- 4 ]：task- 4 运行结束.
[pool- 1 - thread- 8 ]：task- 8 运行结束.
[pool- 1 - thread- 9 ]：task- 9 运行结束.
[pool- 1 - thread- 1 ]：task- 1 运行结束.
[pool- 1 - thread- 2 ]：task- 2 运行结束.
[pool- 1 - thread- 10 ]：task- 10 运行结束.
[pool- 1 - thread- 6 ]：task- 6 运行结束.
“可缓存线程池”的特点大致如下：
1 ）在接收新的异步任务 target 执行目标实例时，如果池内所有线程繁忙，此线程池就会添加新
线程来处理任务。
2 ）此线程池不会对线程池大小进行限制，线程池大小完全依赖于操作系统（或者说 JVM）能
够创建的最大线程大小。
3 ）如果部分线程空闲，也就是存量线程的数量超过了处理任务数量，就会回收空闲（ 60 秒不
执行任务）线程。

“可缓存线程池”的适用场景：需要快速处理突发性强、耗时较短的任务场景，如 Netty 的 NIO
处理场景、RESTAPI 接口的瞬时削峰场景。“可缓存线程池”的线程数量不固定，只要有空闲线
程就会被回收；接收到的新异步任务执行目标，查看是否有线程处于空闲状态，如果没有就直接创
建新的线程。
“可缓存线程池”的弊端：线程池没有最大线程数量限制，如果大量的异步任务执行目标实
例同时提交，可能会因线程过多而导致资源耗尽。

4 .newScheduledThreadPool 创建“可调度线程池”
该方法用于创建一个“可调度线程池”，即一个提供“延时”和“周期性”任务的调度功能
的 ScheduledExecutorService 类型的线程池。Executors 提供了多个创建“可调度线程池”工厂方法，
部分如下：
//方法一：创建一个可调度线程池，池内仅含有一个线程
publicstaticScheduledExecutorServicenewSingleThreadScheduledExecutor ();
//方法二：创建一个可调度线程池，池内含有 N 个线程，N 的值为输入参数 corePoolSize
publicstaticScheduledExecutorServicenewScheduledThreadPool (intcorePoolSize);
newSingleThreadScheduledExecutor 工厂方法所创建的仅含有一个线程的可调度线程池，适用于调
度串行化任务，也就是一个任务接一个任务地串行化调度执行。使用 Executors. newScheduledThreadPool
(intcorePoolSize) 快捷工厂方法创建一个“可调度线程池”的测试用例，其代码如下：
packagecom. crazymakercircle. mutithread. basic. create 3 ;
//省略 import
publicclassCreateThreadPoolDemo
{
publicstaticfinalintSLEEP_GAP= 500 ;
//异步任务的执行目标类
staticclassTargetTaskimplementsRunnable
{
//为了节约篇幅，省略重复内容
}


```
第 1 章多线程原理与实战 | 61
```
//测试用例：“可调度线程池”
@Test
publicvoidtestNewScheduledThreadPool ()
{
ScheduledExecutorServicescheduled=
Executors.newScheduledThreadPool ( 2 );
for (inti= 0 ;i< 2 ;i++)
{
scheduled.scheduleAtFixedRate (newTargetTask (),
0 , 500 ,TimeUnit. MILLISECONDS);
//以上的参数中： 0 表示首次执行任务的延迟时间， 500 表示每次执行任务的间隔时间
//TimeUnit. MILLISECONDS 执行的时间间隔数值，单位为毫秒
}
sleepSeconds ( 1000 );
//关闭线程池
scheduled.shutdown ();
}
//省略其他
}
运行程序，部分结果截取如下：
[pool- 1 - thread- 2 ]：任务：task- 2 doing
[pool- 1 - thread- 1 ]：任务：task- 1 doing
...
[pool- 1 - thread- 1 ]：任务：task- 1 doing
[pool- 1 - thread- 2 ]：任务：task- 2 doing
[pool- 1 - thread- 1 ]：task- 1 运行结束.
[pool- 1 - thread- 2 ]：task- 2 运行结束.
newScheduledThreadPool 工厂方法可以创建一个执行“延时”和“周期性”任务可调度线程池，
所创建的线程池为 ScheduleExecutorService 类型的实例。ScheduleExecutorService 接口中有多个重要
的接收被调目标任务方法，其中 scheduleAtFixedRate 和 scheduleWithFixedDelay 使用得比较多。
ScheduleExecutorService 接收被调目标任务方法之一 scheduleAtFixedRate 方法的定义如下：
publicScheduledFuture<?>scheduleAtFixedRate (
Runnablecommand, //异步任务 target 执行目标实例
longinitialDelay, //首次执行延时
longperiod, //两次开始执行最小间隔时间
TimeUnitunit //所设置的时间的计时单位，如 TimeUnit. SECONDS 常量
);
ScheduleExecutorService 接收被调目标任务方法之二 scheduleWithFixedDelay 方法的定义如下：
publicScheduledFuture<?>scheduleWithFixedDelay (
Runnablecommand, //异步任务 target 执行目标实例
longinitialDelay, //首次执行延时
longdelay, //前一次执行结束到下一次执行开始的间隔时间（间隔执行延迟时间）
TimeUnitunit //所设置的时间的计时单位，如 TimeUnit. SECONDS 常量
);
当被调任务的执行时间大于指定的间隔时间时，ScheduleExecutorService 并不会在创建一个新
的线程去并发执行这个任务，而是等待前一次调度执行完毕。
“可调度线程池”的适用场景：周期性执行任务的场景。SpringBoot 中的任务调度器，底层借
助了 JUC 的 ScheduleExecutorService“可调度线程池”实现，并且可以通过@Configuration 配置类型
的 Bean。对“可调度线程池”实例进行配置，下面是一个例子：
@Configuration
publicclassScheduledConfigimplementsSchedulingConfigurer


62 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

{
@Override
publicvoidconfigureTasks (ScheduledTaskRegistrarscheduledTaskRegistrar)
{
Method[]methods=BatchProperties.Job.class.getMethods ();
intdefaultPoolSize= 4 ;//默认的线程数为 4
intcorePoolSize= 0 ;
//扫描配置了@Scheduled 调度注解的方法
//根据需要调度的方法数，配置线程池中的线程数
if (methods!=null&&methods. length> 0 )
{
for (Methodmethod:methods)
{
Scheduledannotation=method.getAnnotation (Scheduled. class);
if (annotation!=null)
{
corePoolSize++;
}
}
if (defaultPoolSize>corePoolSize)
{
corePoolSize=defaultPoolSize;
}
}
scheduledTaskRegistrar.setScheduler (
Executors.newScheduledThreadPool (corePoolSize));
}
}
以上是通过 JUC 的 Executors 中 4 个主要的快捷创建线程池方法。为何 JUC 要提供工厂方法呢？
原因是使用 ThreadPoolExecutor、ScheduledThreadPoolExecutor 构造器去创建普通线程池、可调度线
程池比较复杂，这些构造器会涉及大量的复杂参数。尽管 Executors 的工厂方法使用方便，但是在生
产场景中被很多企业（尤其是大厂）的开发规范所禁用。

###### 1. 6. 3 线程池的标准创建方式

大部分企业的开发规范都会禁止使用快捷线程池（具体原因稍后介绍），要求通过标准构造
器 ThreadPoolExecutor 去构造工作线程池。Executors 工厂类中创建线程池的快捷工厂方法实际上是
调用 ThreadPoolExecutor（定时任务使用 ScheduledThreadPoolExecutor ）线程池的构造方法完成的。
ThreadPoolExecutor 构造方法有多个重载版本，其中一个比较重要的构造器如下：
//使用标准构造器构造一个普通的线程池
publicThreadPoolExecutor (
intcorePoolSize, //核心线程数，即使线程空闲（Idle），也不会回收
intmaximumPoolSize, //线程数的上限
longkeepAliveTime, TimeUnitunit, //线程最大空闲（Idle）时长
BlockingQueue<Runnable>workQueue, //任务的排队队列
ThreadFactorythreadFactory, //新线程的产生方式
RejectedExecutionHandlerhandler) //拒绝策略
很无奈，构造一个线程池竟然有 7 个参数，但是确实需要这么多参数。接下来对这些参数做一
下具体介绍。

```
1 .核心和最大线程数量
参数 corePoolSize 用于设置核心（Core）线程池数量，参数 maximumPoolSize 用于设置最大线程
```

```
第 1 章多线程原理与实战 | 63
```
数量。线程池执行器将会根据 corePoolSize 和 maximumPoolSize 自动地维护线程池中的工作线程，大
致的规则为：

1 ）当在线程池接收到的新任务，并且当前工作线程数少于 corePoolSize 时，即使其他工作线程
处于空闲状态，也会创建一个新线程来处理该请求，直到线程数达到 corePoolSize。
2 ）如果当前工作线程数多于 corePoolSize 数量，但小于 maximumPoolSize 数量，那么仅当任务
排队队列已满时才会创建新线程。通过设置 corePoolSize 和 maximumPoolSize 相同，可以创建一个固
定大小的线程池。
3 ）当 maximumPoolSize 被设置为无界值（如 Integer. MAX_VALUE）时，线程池可以接收任意
数量的并发任务。
4 ）corePoolSize 和 maximumPoolSize 不仅能在线程池构造时设置，也可以调用 setCorePoolSize ()
和 setMaximumPoolSize () 两个方法进行动态更改。

2 .BlockingQueue
BlockingQueue（阻塞队列）的实例用于暂时接收到的异步任务，如果线程池的核心线程都在
忙，那么所接收到的目标任务缓存在阻塞队列中。

3 .keepAliveTime
线程构造器的 keepAliveTime（空闲线程存活时间）参数用于设置池内线程最大 Idle（空闲）时
长或者说保活时长，如果超过这个时间，默认情况下 Idle、非 Core 线程会被回收。
如果池在使用过程中提交任务的频率变高，也可以调用方法 setKeepAliveTime（long，TimeUnit）
进行线程存活时间的动态调整，可以将时长延长。如果需要防止 Idle 线程被终止，可以将 Idle 时间
设置为无限大，具体如下：
setKeepAliveTime (Long. MAX_VALUE，TimeUnit. NANOSECONDS);
默认情况下，Idle 超时策略仅适用于存在超过 corePoolSize 线程的情况。但是如果调用了
allowCoreThreadTimeOut (boolean) 方法，并且传入了参数 true，则 keepAliveTime 参数所设置的 Idle
超时策略也将被应用于核心线程。

###### 1. 6. 4 向线程池提交任务的两种方式

```
向线程池提交任务的两种方式，大致如下：
方式一：调用 execute () 方法，例如：
//Executor 接口中的方法
voidexecute (Runnablecommand);
方式二：调用 submit () 方法，例如：
//ExecutorService 接口中的方法
<T>Future<T>submit (Callable<T>task);
<T>Future<T>submit (Runnabletask, Tresult);
Future<?>submit (Runnabletask);
以上的 submit 和 execute 两类方法区别在哪里呢？大致有三点：
```

64 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

（ 1 ）二者所接受的参数不一样
execute () 方法只能接收 Runnable 类型的参数，而 submit () 方法可以接收 Callable、Runnable 两种类型
的参数。Callable 类型的任务是可以返回执行结果的，而 Runnable 类型的任务不可以返回执行结果。
Callable 是 JDK 1. 5 加入的执行目标接口，作为 Runnable 的一种补充，允许有返回值，允许抛出
异常。Runnable 和 Callable 的主要区别为：Callable 允许有返回值，Runnable 不允许有返回值；Runnable
不允许抛出异常，Callable 允许抛出异常。

（ 2 ）submit () 提交任务后会有返回值，而 execute () 没有
execute () 方法主要用于启动任务的执行，而任务的执行结果和可能的异常调用者并不关心。而
submit () 方法也用于启动任务的执行，但是启动之后会返回 Future 对象，代表一个异步执行实例，可
以通过该异步执行实例去获取结果。

（ 3 ）submit () 方便 Exception 处理
execute () 方法在启动任务的执行后，任务执行过程中可能发生的异常调用者并不关心。而通过
submit () 方法返回 Future 对象（异步执行实例），可以进行异步执行过程中的异常捕获。

接下来通过简单的案例，演示一下如何通过 submit 获取异步结果和处理异步任务执行过程中的
异常。

1 .通过 submit () 返回的 Future 对象获取结果
submit () 方法自身并不会传递结果，而是返回一个 Future 异步执行实例，处理过程的结果被包
装到 Future 实例中，调用者可以通过 Future.get () 方法获取异步执行的结果。通过 submit 返回的 Future
对象获取异步执行结果，演示代码如下：
packagecom. crazymakercircle. mutithread. basic. create 3 ;
//省略 import
publicclassCreateThreadPoolDemo
{
//省略其他
//测试用例：获取异步调用的结果
@Test
publicvoidtestSubmit 2 ()
{
ScheduledExecutorServicepool=Executors.newScheduledThreadPool ( 2 );
Future<Integer>future=pool.submit (newCallable<Integer>()
{
@Override
publicIntegercall () throwsException
{
//返回 200 ~ 300 之间的随机数
returnRandomUtil.randInRange ( 200 , 300 );
}
});
try
{
Integerresult=future.get ();
Print.tco ("异步执行的结果是: "+result);
}catch (InterruptedExceptione)
{
Print.tco ("异步调用被中断");
e.printStackTrace ();
}catch (ExecutionExceptione)


```
第 1 章多线程原理与实战 | 65
```
{
Print.tco ("异步调用过程中，发生了异常");
e.printStackTrace ();
}
sleepSeconds ( 10 );
//关闭线程池
pool.shutdown ();
}
}
运行以上程序，执行的结果如下：
[main]：异步执行的结果是: 220
2 .通过 submit () 返回的 Future 对象捕获异常
submit () 方法自身并不会传递异常，处理过程中的异常都被包装到 Future 实例中，调用者在使
用 Future.get () 方法获取执行结果时，可以捕获异步执行过程中抛出的受检异常和运行时异常，并进
行对应的业务处理。演示代码如下：
packagecom. crazymakercircle. mutithread. basic. create 3 ;
//省略 import
publicclassCreateThreadPoolDemo
{
//异步任务的执行目标类
staticclassTargetTaskimplementsRunnable
{
//为了节约篇幅，省略重复内容
}
//异步的执行目标类：执行过程中将发生异常
staticclassTargetTaskWithErrorextendsTargetTask
{
publicvoidrun ()
{
super.run ();
thrownewRuntimeException ("Errorfrom"+taskName);
}
}
//测试用例：提交和执行
@Test
publicvoidtestSubmit ()
{
ScheduledExecutorServicepool=Executors.newScheduledThreadPool ( 2 );
pool.execute (newTargetTaskWithError ());
/**
*submit (Runnablex) 返回一个 future
*/
Futurefuture=pool.submit (newTargetTaskWithError ());
try
{
//如果异常抛出，会在调用 Future.get () 时传递给调用者
if (future.get ()==null)
{
//如果 Future 的返回为 null，那么任务完成
Print.tco ("任务完成");
}
}catch (Exceptione)
{
Print.tco (e.getCause (). getMessage ());


66 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

}
sleepSeconds ( 10 );
//关闭线程池
pool.shutdown ();
}
//省略其他
}
运行以上用例，执行结果如下：
[pool- 1 - thread- 2 ]：任务：task- 2 doing
[pool- 1 - thread- 1 ]：任务：task- 1 doing
[pool- 1 - thread- 2 ]：task- 2 运行结束.
[pool- 1 - thread- 1 ]：task- 1 运行结束.
[main]：Errorfromtask- 2
在 ThreadPoolExecutor 类的实现中，内部核心的任务提交方法是 execute () 方法，虽然用户程序
通过 submit () 也可以提交任务，但是实际上 submit () 方法中最终调用的还是 execute () 方法。

###### 1. 6. 5 线程池的任务调度流程

线程池的任务调度流程（包含接收新任务和执行下一个任务）大致如下：
1 ）如果当前工作线程数量小于核心线程池数量，执行器总是优先创建一个任务线程，而不是
从线程队列中获取一个空闲线程。
2 ）如果线程池中总的任务数量大于核心线程池数量，新接收的任务将被加入到阻塞队列中，
一直到阻塞队列已满。在核心线程池数量已经用完、阻塞队列没有满的场景下，线程池不会为新任
务创建一个新线程。
3 ）当完成一个任务的执行时，执行器总是优先从阻塞队列中获取下一个任务，并开始执行，
一直到阻塞队列为空，其中所有的缓存任务被取光。
4 ）在核心线程池数量已经用完、阻塞队列也已经满了的场景下，如果线程池接收到新的任务，
将会为新任务创建一个线程（非核心线程），并且立即开始执行新任务。
5 ）在核心线程都用完、阻塞队列已满的情况下，一直会创建新线程去执行新任务，直到池内
的线程总数超出 maximumPoolSize。如果线程池的线程总数超过 maximumPoolSize，线程池就会拒
绝接收任务，当新任务过来时，会为新任务执行拒绝策略。

```
总体的线程池的任务调度流程大致如图 1 - 16 所示。
```
```
图 1 - 16 总体的线程池的任务调度流程
```

```
第 1 章多线程原理与实战 | 67
```
在创建线程池时，如果线程池的参数（如核心线程数量、最大线程数量、BlockingQueue 等）
配置不合理，就会出现任务不能被正常调度的问题。
下面是一个错误的线程池配置示例：
packagecom. crazymakercircle. mutithread. basic. create 3 ;
//省略 import
publicclassCreateThreadPoolDemo
{
@org. junit. Test
publicvoidtestThreadPoolExecutor ()
{
ThreadPoolExecutorexecutor=newThreadPoolExecutor (
1 ,//corePoolSize
100 ,//maximumPoolSize
100 ,//keepAliveTime 空闲保活时长
TimeUnit. SECONDS,//空闲保活时长的单位
newLinkedBlockingDeque<>( 100 ));//workQueue
//提交 5 个任务
for (inti= 0 ;i< 5 ;i++)
{
finalinttaskIndex=i;
executor.execute (()->
{
Print.tco ("taskIndex="+taskIndex);
try
{ //极端测试：无限制睡眠
Thread.sleep (Long. MAX_VALUE);
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}
});
}
while (true)
{
//每隔 1 秒，输出线程池的工作任务数量、总计的任务数量
Print.tco ("-activeCount: "+executor.getActiveCount ()+
"-taskCount: "+executor.getTaskCount ());
sleepSeconds ( 1 );
}
}
//省略其他
}
运行程序，结果如下：
[main]：-activeCount: 1 - taskCount: 5
[pool- 1 - thread- 1 ]：taskIndex= 0
[main]：-activeCount: 1 - taskCount: 5
[main]：-activeCount: 1 - taskCount: 5
[main]：-activeCount: 1 - taskCount: 5
[main]：-activeCount: 1 - taskCount: 5
[main]：-activeCount: 1 - taskCount: 5
[main]：-activeCount: 1 - taskCount: 5
...
以上示例创建了最大线程数量 maximumPoolSize 为 100 的线程池，仅仅向其中提交了 5 个任务。
理论上，这 5 个任务都会被执行到，奇怪的是示例中只有 1 个任务在执行，其他的 4 个任务都在等待。


68 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

其他任务被加入到了阻塞队列中，需要等 pool- 1 - thread- 1 线程执行完成第一个任务后，才能依次从
阻塞队列取出执行。但是，实例中的第一个任务是一个永远也没有办法完成的任务，所以其他的 4
个任务只能永远在阻塞队列中等待着。由于参数配置得不合理，因此出现了以上的奇怪现象。
为什么会出现上面奇怪的现象呢？因为例子中的 corePoolSize 为 1 ，阻塞队列的大小为 100 ，按
照线程创建的规则，需要等阻塞队列已满，才会为去创建新的线程。例子中加入了 5 个任务，阻塞
队列大小为 4 （< 100 ），所以线程池的调度器不会去创建新的线程，后面的 4 个任务只能等待。
以上示例的目的是传递两个知识点：
1 ）核心和最大线程数量、BlockingQueue 队列等参数如果配置得不合理，可能会造成异步任务
得不到预期的并发执行，造成严重的排队等待现象。
2 ）线程池的调度器创建线程的一条重要的规则是：在 corePoolSize 已满之后，还需要等阻塞队
列已满，才会为去创建新的线程。

下面是一个有关线程池调度的面试真题，来自于疯狂创客圈社群：
一个线程池的核心线程数为 10 个，最大线程数为 20 个，阻塞队列的容量为 30 。现在提交 45 个
任务，每个任务的耗时为 500 毫秒。
请问：这批任务执行完成总计需要多少时间？注：忽略线程创建、调度的耗时。
有关面试题的解决方案和答案这里不揭晓，大家可以来社群交流方案和结论。

###### 1. 6. 6 ThreadFactory（线程工厂）

ThreadFactory 是 Java 线程工厂接口，这是一个非常简单的接口，具体如下：
packagejava. util. concurrent;
publicinterfaceThreadFactory{
//唯一的方法：创建一个新线程
ThreadnewThread (Runnabletarget);
}
在调用 ThreadFactory 的唯一方法 newThread () 创建新线程时，可以更改创建新线程的名称、线
程组、优先级、守护进程状态等。如果 newThread () 返回值为 null，表示线程工厂未能成功创建线程，
线程池可能无法执行任何任务。
使用 Executors 创建新的线程池时，也可以基于 ThreadFactory（线程工厂）创建，在创建新线程池
时可以指定将使用 ThreadFactory 实例。只不过，如果没有指定的话，就会使用
Executors. defaultThreadFactory 默认实例。使用默认的线程工厂实例所创建的线程全部位于同一个
ThreadGroup（线程组）中，具有相同的 NORM_PRIORITY（优先级为 5 ），而且都是非守护进程状态。

```
这里提到了两个工厂类，比较容易混淆，故作出说明。Executors 为线程池工厂
类，用于快捷创建线程池（ThreadPool）；ThreadFactory 为线程工厂类，用于创建线程（Thread）。
```
基于自定义的 ThreadFactory 实例创建线程池，首先需要实现一个 ThreadFactory 类，实现其唯一
的抽象方法 newThread (Runnable)。下面的例子首先实现一个简单的线程工厂，然后基于该线程工厂
快捷创建线程池，具体的代码如下：


```
第 1 章多线程原理与实战 | 69
```
packagecom. crazymakercircle. mutithread. basic. create 3 ;
//省略 import
publicclassCreateThreadPoolDemo
{
//一个简单的线程工厂
staticpublicclassSimpleThreadFactoryimplementsThreadFactory
{
staticAtomicIntegerthreadNo=newAtomicInteger ( 1 );
//实现其唯一的创建线程方法
@Override
publicThreadnewThread (Runnabletarget)
{
StringthreadName="simpleThread-"+threadNo.get ();
Print.tco ("创建一条线程，名称为："+threadName);
threadNo.incrementAndGet ();
//设置线程名称和异步执行目标
Threadthread=newThread (target, threadName);
//设置为守护线程
thread.setDaemon (true);
returnthread;
}
}
//线程工厂的测试用例
@org. junit. Test
publicvoidtestThreadFactory ()
{
//使用自定义线程工厂，快捷创建一个固定大小线程池
ExecutorServicepool=
Executors.newFixedThreadPool ( 2 ,new SimpleThreadFactory ());
for (inti= 0 ;i< 5 ;i++)
{
pool.submit (newTargetTask ());
}
//等待 10 秒
sleepSeconds ( 10 );
Print.tco ("关闭线程池");
pool.shutdown ();
}
//省略其他
}
运行以上代码，其输出如下：
[main]：创建一条线程，名称为：simpleThread- 1
[main]：创建一条线程，名称为：simpleThread- 2
[simpleThread- 1 ]：任务：task- 1 doing
[simpleThread- 2 ]：任务：task- 2 doing
[simpleThread- 1 ]：task- 1 运行结束.
[simpleThread- 1 ]：任务：task- 3 doing
[simpleThread- 2 ]：task- 2 运行结束.
[simpleThread- 2 ]：任务：task- 4 doing
[simpleThread- 2 ]：task- 4 运行结束.
[simpleThread- 1 ]：task- 3 运行结束.
[simpleThread- 2 ]：任务：task- 5 doing
[simpleThread- 2 ]：task- 5 运行结束.
[main]：关闭线程池
从结果输出看到，新建池中的线程名称都不是默认的 pool- 1 - thread- 1 形式，是线程工厂更改后
的形式。


70 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

###### 1. 6. 7 任务阻塞队列

Java 中的阻塞队列（BlockingQueue）与普通队列相比有一个重要的特点：在阻塞队列为空时，
会阻塞当前线程的元素获取操作。具体来说，在一个线程从一个空的阻塞队列中获取元素时线程会
被阻塞，直到阻塞队列中有了元素；当队列中有元素后，被阻塞的线程会自动被唤醒（唤醒过程不
需要用户程序干预）。
Java 线程池使用 BlockingQueue 存放接收到的异步任务，BlockingQueue 是 JUC 包的一个超级接
口，比较常用的实现类有：

1 ）ArrayBlockingQueue：是一个数组实现的有界阻塞队列（有界队列），队列中的元素按 FIFO
排序。ArrayBlockingQueue 在创建时必须设置大小，接收的任务超出 corePoolSize 数量时，任务被缓
存到该阻塞队列中，任务缓存的数量只能为创建时设置的大小，若该阻塞队列满，则会为新的任务
创建线程，直到线程池中的线程总数大于 maximumPoolSize。
2 ）LinkedBlockingQueue：是一个基于链表实现的阻塞队列，按 FIFO 排序任务，可以设置容量
（有界队列），不设置容量则默认使用 Integer. Max_VALUE 作为容量（无界队列）。该队列的吞吐
量高于 ArrayBlockingQueue。
如果不设置 LinkedBlockingQueue 的容量（无界队列），当接收的任务数量超出 corePoolSize 数
量时，则新任务可以被无限制地缓存到该阻塞队列中，直到资源耗尽。有两个快捷创建线程池的工
厂方法 Executors. newSingleThreadExecutor 和 Executors. newFixedThreadPool 使用了这个队列，并且都
没有设置容量（无界队列）。
3 ）PriorityBlockingQueue：是具有优先级的无界队列。
4 ）DelayQueue：这是一个无界阻塞延迟队列，底层基于 PriorityBlockingQueue 实现，队列中每
个元素都有过期时间，当从队列获取元素（元素出队）时，只有已经过期的元素才会出队，而队列
头部的元素是最先过期的元素。快捷工厂方法 Executors. newScheduledThreadPool 所创建的线程池使
用此队列。
5 ）SynchronousQueue（同步队列）：是一个不存储元素的阻塞队列，每个插入操作必须等到另一
个线程的调用移除操作，否则插入操作一直处于阻塞状态，其吞吐量通常高于 LinkedBlockingQueue。
快捷工厂方法 Executors. newCachedThreadPool 所创建的线程池使用此队列。与前面的队列相比，这
个队列比较特殊，它不会保存提交的任务，而是直接新建一个线程来执行新来的任务。

1. 6. (^8) 调度器的钩子方法
ThreadPoolExecutor 线程池调度器为每个任务执行前后都提供了钩子方法。ThreadPoolExecutor
类提供了三个钩子方法（空方法），这三个空方法一般用作被子类重写，具体如下：
//任务执行之前的钩子方法（前钩子）
protectedvoidbeforeExecute (Threadt, Runnabler) {}
//任务执行之后的钩子方法（后钩子）
protectedvoidafterExecute (Runnabler, Throwablet){}
//线程池终止时的钩子方法（停止钩子）
protectedvoidterminated (){}


```
第 1 章多线程原理与实战 | 71
```
（ 1 ）beforeExecute：异步任务执行之前的钩子方法
线程池工作线程在异步执行完成的目标实例（如 Runnable 实例）前调用此钩子方法。此方法仍
然由执行任务的工作线程调用。默认实现不执行任何操作，但可以在子类中对其进行自定义。
此方法由执行目标实例的工作线程调用，可用于重新初始化 ThreadLocal 线程本地变量实例、
更新日志记录、开始计时统计、更新上下文变量等。

（ 2 ）afterExecute：异步任务执行之后的钩子方法
线程池工作线程在异步执行目标实例后调用此钩子方法。此方法仍然由执行任务的工作线程
调用。此钩子方法的默认实现不执行任何操作，可以在调度器子类中对其进行自定义。
此方法由执行目标实例的工作线程调用，可用于清除 ThreadLocal 线程本地变量、更新日志记
录、收集统计信息、更新上下文变量等。

```
（ 3 ）terminated：线程池终止时的钩子方法
terminated 钩子方法在 Executor 终止时调用，默认实现不执行任何操作。
```
```
beforeExecute 和 afterExecute 两个方法在每个任务执行前后被调用，如果钩子（回
调方法）引发异常，内部工作线程可能失败并突然终止。
```
```
为线程池定制钩子方法的示例，具体代码如下：
packagecom. crazymakercircle. mutithread. basic. create 3 ;
//省略 import
publicclassCreateThreadPoolDemo
{
@org. junit. Test
publicvoidtestHooks ()
{
ExecutorServicepool=newThreadPoolExecutor ( 2 ,//coreSize
4 , //最大线程数
60 , //空闲保活时长
TimeUnit. SECONDS,
newLinkedBlockingQueue<>( 2 )) //等待队列
{
//继承：调度器终止钩子
@Override
protectedvoidterminated ()
{
Print.tco ("调度器已经终止!");
}
//继承：执行前钩子
@Override
protectedvoidbeforeExecute (Threadt, Runnabletarget)
{
Print.tco (target+"前钩被执行");
//记录开始执行时间
startTime .set (System.currentTimeMillis ());
super.beforeExecute (t, target);
}
//继承：执行后钩子
@Override
protectedvoidafterExecute (Runnabletarget, Throwablet)
{
super.afterExecute (target, t);
```

72 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

//计算执行时长
longtime=(System.currentTimeMillis ()-startTime.get ());
Print.tco (target+"后钩被执行, 任务执行时长（ms）："+time);
//清空本地变量
startTime.remove ();
}
};
for (inti= 1 ;i<= 5 ;i++)
{
pool.execute (newTargetTask ());
}
//等待 10 秒
sleepSeconds ( 10 );
Print.tco ("关闭线程池");
pool.shutdown ();
}
//省略其他
}
运行以上示例代码，输出的结果如下：
[pool- 1 - thread- 3 ]：TargetTask{task- 5 }前钩被执行
[pool- 1 - thread- 1 ]：TargetTask{task- 1 }前钩被执行
[pool- 1 - thread- 2 ]：TargetTask{task- 2 }前钩被执行
[pool- 1 - thread- 2 ]：任务：task- 2 doing
[pool- 1 - thread- 1 ]：任务：task- 1 doing
[pool- 1 - thread- 3 ]：任务：task- 5 doing
[pool- 1 - thread- 3 ]：task- 5 运行结束.
[pool- 1 - thread- 2 ]：task- 2 运行结束.
...
[pool- 1 - thread- 3 ]：TargetTask{task- 4 }后钩被执行, 任务执行时长（ms）： 515
[main]：关闭线程池
[pool- 1 - thread- 3 ]：调度器已经终止!
示例代码在 beforeExecute（前钩子）方法中通过 startTime 线程局部变量暂存了异步目标任务（如
Runnable 实例）的开始执行时间（起始时间）；在 afterExecute（后钩子）方法中通过 startTime 线程
局部变量获取了之前暂存的起始时间，然后计算与系统当前时间（结束时间）之间的时间差，从而
得出异步目标任务的执行时长。

###### 1. 6. 9 线程池的拒绝策略

在线程池的任务缓存队列为有界队列（有容量限制的队列）的时候，如果队列满了，提交任
务到线程池的时候就会被拒绝。总体来说，任务被拒绝有两种情况：

1 ）线程池已经被关闭。
2 ）工作队列已满且 maximumPoolSize 已满。
无论以上哪种情况任务被拒绝，线程池都会调用 RejectedExecutionHandler 实例的 rejectedExecution ()
方法。RejectedExecutionHandler 是拒绝策略的接口，JUC 为该接口提供了以下几种实现：

```
 AbortPolicy：拒绝策略。
 DiscardPolicy：抛弃策略。
 DiscardOldestPolicy：抛弃最老任务策略。
 CallerRunsPolicy：调用者执行策略。
```

```
第 1 章多线程原理与实战 | 73
```
```
 自定义策略。
JUC 线程池拒绝策略的接口与类之间的关系图如图 1 - 17 所示。
```
图 1 - 17 JUC 线程池拒绝策略类图
（ 1 ）AbortPolicy
使用该策略时，如果线程池队列满了，新任务就会被拒绝，并且抛出 RejectedExecutionException
异常。该策略是线程池的默认的拒绝策略。

（ 2 ）DiscardPolicy
该策略是 AbortPolicy 的 Silent（安静）版本，如果线程池队列满了，新任务就会直接被丢掉，
并且不会有任何异常抛出。

（ 3 ）DiscardOldestPolicy
抛弃最老任务策略，也就是说如果队列满了，就会将最早进入队列的任务抛弃，从队列中腾
出空间，再尝试加入队列。因为队列是队尾进队头出，队头元素是最老的，所以每次都是移除对头
元素后再尝试入队。

（ 4 ）CallerRunsPolicy
调用者执行策略。在新任务被添加到线程池时，如果添加失败，那么提交任务线程会自己去
执行该任务，不会使用线程池中的线程去执行新任务。
在以上 4 种内置策略中，线程池默认的拒绝策略为 AbortPolicy，如果提交的任务被拒绝，线程
池抛出 RejectedExecutionException 异常，该异常是非受检异常（运行时异常），很容易忘记捕获。
如果关心任务被拒绝的事件，需要在提交任务时捕获 RejectedExecutionException 异常。

（ 5 ）自定义策略
如果以上拒绝策略都不符合需求，那么可自定义一个拒绝策略，实现 RejectedExecutionHandler
接口的 rejectedExecution 方法即可。
下面给出一个自定义拒绝策略的例子，代码如下：
packagecom. crazymakercircle. mutithread. basic. create 3 ;
//省略 import
publicclassCreateThreadPoolDemo
{
//一个简单的线程工厂
staticpublicclass **SimpleThreadFactory** implements **ThreadFactory**
{
//为了节约篇幅，省略重复内容
}
//自定义拒绝策略
publicstaticclassCustomIgnorePolicyimplementsRejectedExecutionHandler
{


74 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
publicvoidrejectedExecution (Runnabler, ThreadPoolExecutore)
{
//可做日志记录等
Print.tco (r+"rejected;"+"-getTaskCount: "+e.getTaskCount ());
}
}
@org. junit. Test
publicvoidtestCustomIgnorePolicy ()
{
intcorePoolSize= 2 ; //核心线程数
intmaximumPoolSize= 4 ; //最大线程数
longkeepAliveTime= 10 ;
TimeUnitunit=TimeUnit. SECONDS;
//最大排队任务数
BlockingQueue<Runnable>workQueue=newArrayBlockingQueue<>( 2 );
//线程工厂
ThreadFactorythreadFactory=newSimpleThreadFactory ();
//拒绝和异常处理策略
RejectedExecutionHandlerpolicy=newCustomIgnorePolicy ();
ThreadPoolExecutorpool=newThreadPoolExecutor (
corePoolSize,
maximumPoolSize,
keepAliveTime, unit,
workQueue,
threadFactory,
policy);
//预启动所有核心线程
pool.prestartAllCoreThreads ();
for (inti= 1 ;i<= 10 ;i++)
{
pool.execute (newTargetTask ());
}
//等待 10 秒
sleepSeconds ( 10 );
Print.tco ("关闭线程池");
pool.shutdown ();
}
//省略其他
}
运行以上代码，大致结果如下：
[main]：创建一条线程，名称为：simpleThread- 1
[main]：创建一条线程，名称为：simpleThread- 2
[main]：创建一条线程，名称为：simpleThread- 3
[simpleThread- 1 ]：任务：task- 1 doing
[simpleThread- 2 ]：任务：task- 2 doing
[main]：创建一条线程，名称为：simpleThread- 4
[simpleThread- 3 ]：任务：task- 3 doing
[simpleThread- 4 ]：任务：task- 6 doing
[main]：TargetTask{task- 7 }rejected; -getTaskCount: 6
[main]：TargetTask{task- 8 }rejected; -getTaskCount: 6
[main]：TargetTask{task- 9 }rejected; -getTaskCount: 6
[main]：TargetTask{task- 10 }rejected; -getTaskCount: 6
[simpleThread- 1 ]：task- 1 运行结束.
[simpleThread- 2 ]：task- 2 运行结束.
[simpleThread- 1 ]：任务：task- 4 doing
[simpleThread- 2 ]：任务：task- 5 doing
[simpleThread- 2 ]：task- 5 运行结束.
[simpleThread- 4 ]：task- 6 运行结束.
```

```
第 1 章多线程原理与实战 | 75
```
```
[simpleThread- 3 ]：task- 3 运行结束.
[simpleThread- 1 ]：task- 4 运行结束.
[main]：关闭线程池
```
###### 1. 6. 10 线程池的优雅关闭

一般情况下，线程池启动后建议手动关闭。在介绍线程池的优雅关闭之前，我们先了解一下
线程池状态。线程池总共存在 5 种状态，定义在 ThreadPoolExecutor 类中，具体代码如下：
packagejava. util. concurrent;
//省略 import
publicclassThreadPoolExecutorextendsAbstractExecutorService{
//runStateisstoredinthehigh-orderbits
privatestaticfinalintRUNNING =- 1 <<COUNT_BITS;
privatestaticfinalintSHUTDOWN = 0 <<COUNT_BITS;
privatestaticfinalintSTOP = 1 <<COUNT_BITS;
privatestaticfinalintTIDYING = 2 <<COUNT_BITS;
privatestaticfinalintTERMINATED = 3 <<COUNT_BITS;
//省略其他
}
线程池的 5 种状态具体如下：
1 ）RUNNING：线程池创建之后的初始状态，这种状态下可以执行任务。
2 ）SHUTDOWN：该状态下线程池不再接受新任务，但是会将工作队列中的任务执行完毕。
3 ）STOP：该状态下线程池不再接受新任务，也不会处理工作队列中的剩余任务，并且将会
中断所有工作线程。
4 ）TIDYING：该状态下所有任务都已终止或者处理完成，将会执行 terminated () 钩子方法。
5 ）TERMINATED：执行完 terminated () 钩子方法之后的状态。
线程池的状态转换规则为：
1 ）线程池创建之后状态为 RUNNING。
2 ）执行线程池的 shutdown () 实例方法，会使线程池状态从 RUNNING 转变为 SHUTDOWN。
3 ）执行线程池的 shutdownNow () 实例方法，会使线程池状态从 RUNNING 转变为 STOP。
4 ）当线程池处于 SHUTDOWN 状态，执行其 shutdownNow () 方法会将其状态转变为 STOP。
5 ）等待线程池的所有工作线程停止，工作队列清空之后，线程池状态会从 STOP 转变为
TIDYING。
6 ）执行完 terminated () 钩子方法之后，线程池状态从 TIDYING 转变为 TERMINATED。
线程池的状态之间的转换规则如图 1 - 18 所示。
优雅地关闭线程池主要涉及的方法有 3 种：
1 ）shutdown：是 JUC 提供一个有序关闭线程池的方法，此方法会等待当前工作队列中的剩余
任务全部执行完成之后才会执行关闭，但是此方法被调用之后线程池的状态转变为 SHUTDOWN，
线程池不会再接收新的任务。
2 ）shutdownNow：是 JUC 提供一个立即关闭线程池的方法，此方法会打断正在执行的工作线
程，并且会清空当前工作队列中的剩余任务，返回的是尚未执行的任务。


76 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

图 1 - 18 线程池的状态转换规则
3 ）awaitTermination：等待线程池完成关闭。在调用线程池的 shutdown () 与 shutdownNow () 方法
时，当前线程会立即返回，不会一直等待直到线程池完成关闭。如果需要等到线程池关闭完成，可
以调用 awaitTermination () 方法。

1 .shutdown () 方法原理
shutdown () 方法的源码大致如下：
publicvoidshutdown ()
{
finalReentrantLockmainLock=this. mainLock;
mainLock.lock ();
try
{
//检查权限
checkShutdownAccess ();
//设置线程池状态
advanceRunState (SHUTDOWN);
//中断空闲线程
interruptIdleWorkers ();
//钩子函数，主要用于清理一些资源
onShutdown ();
}finally
{
mainLock.unlock ();
}
tryTerminate ();
}
shutdown () 方法首先加锁，其次检查调用者是否具有执行线程池关闭的 JavaSecurity 权限。接
着 shutdown () 方法会将线程池状态变为 SHUTDOWN，在这之后线程池不再接受提交的新任务。此
时如果还继续往线程池提交任务，将会使用线程池拒绝策略响应，默认的拒绝策略将会使用
ThreadPoolExecutor. AbortPolicy，接收新任务时会抛出 RejectedExecutionException 异常。

```
2 .shutdownNow () 方法的原理
shutdownNow () 方法的源码大致如下：
publicList<Runnable>shutdownNow ()
{
```

```
第 1 章多线程原理与实战 | 77
```
List<Runnable>tasks;
finalReentrantLockmainLock=this. mainLock;
mainLock.lock ();
try
{
//检查状态
checkShutdownAccess ();
//将线程池状态变为 STOP
advanceRunState (STOP);
//中断所有线程，包括工作线程以及空闲线程
interruptWorkers ();
//丢弃工作队列中剩余任务
tasks=drainQueue ();
}finally
{
mainLock.unlock ();
}
tryTerminate ();
returntasks;
}
shutdownNow () 方法将会把线程池状态设置为 STOP，然后中断所有线程（包括工作线程以及
空闲线程），最后清空工作队列，取出工作队列中所有未完成的任务返回给调用者。与有序的
shutdown () 方法相比，shutdownNow () 方法比较粗暴，直接中断工作线程。不过这里需要注意的是，
中断线程并不代表线程立刻结束，只是通过工作线程的 interrupt () 实例方法设置了中断状态，这里
需要用户程序主动配合线程进行中断操作。

3 .awaitTermination () 方法的使用
调用了线程池 shutdown () 与 shutdownNow () 方法之后，用户程序都不会主动等待线程池关闭完
成，如果需要等到线程池关闭完成，需要调用 awaitTermination () 进行主动等待。调用方法大致如下：
threadPool.shutdown ();
try{
//一直等待，直到线程池完成关闭
while (! threadPool.awaitTermination ( 60 ,TimeUnit. SECONDS)){
System.out.println ("线程池任务还未执行结束");
}
}catch (InterruptedExceptione){
e.printStackTrace ();
}
如果线程池完成关闭，awaitTermination () 方法将会返回 true，否则当等待时间超过指定时间后
将会返回 false。如果需要调用 awaitTermination ()，建议不是永久等待，而是设置一定重试次数。下
面的代码参考了阿里巴巴著名的分布式框架 Dubbo 中线程池关闭源码中的部分代码：
if (! threadPool.isTerminated ())
{
try
{
for (inti= 0 ;i< 1000 ;i++)//循环关闭 1000 次，每次等待 10 毫秒
{
if (threadPool.awaitTermination ( 10 ,TimeUnit. MILLISECONDS))
{
break;
}
threadPool.shutdownNow ();


78 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

}
}catch (InterruptedExceptione)
{
System.err.println (e.getMessage ());
}catch (Throwablee)
{
System.err.println (e.getMessage ());
}
}
4 .优雅地关闭线程池
大家可以结合 shutdown ()、shutdownNow () 和 awaitTermination () 三个方法去优雅关闭一个线程池，
大致分为以下几步：

1 ）执行 shutdown () 方法，拒绝新任务的提交，并等待所有任务有序地执行完毕。
2 ）执行 awaitTermination（longtimeout, TimeUnitunit）方法，指定超时时间，判断是否已经关
闭所有任务，线程池关闭完成。
3 ）如果 awaitTermination () 方法返回 false，或者被中断，就调用 shutDownNow () 方法立即关闭
线程池所有任务。
4 ）补充执行 awaitTermination（longtimeout, TimeUnitunit）方法，判断线程池是否关闭完成。
如果超时，就可以进入循环关闭，循环一定的次数（如 1000 次），不断关闭线程池，直到其关闭或
者循环结束。

```
优雅地关闭线程池的参考代码具体如下：
packagecom. crazymakercircle. util;
//省略 import
publicclassThreadUtil
{
publicstaticvoidshutdownThreadPoolGracefully (ExecutorServicethreadPool)
{
//若已经关闭则返回
if (! (threadPoolinstanceofExecutorService)||threadPool.isTerminated ())
{
return;
}
try
{
threadPool.shutdown (); //拒绝接受新任务
}catch (SecurityExceptione)
{
return;
}catch (NullPointerExceptione)
{
return;
}
try
{
//等待 60 秒，等待线程池中的任务完成执行
if (! threadPool.awaitTermination ( 60 ,TimeUnit. SECONDS))
{
//调用 shutdownNow () 方法取消正在执行的任务
threadPool.shutdownNow ();
//再次等待 60 秒，如果还未结束，可以再次尝试，或者直接放弃
if (! threadPool.awaitTermination ( 60 ,TimeUnit. SECONDS))
```

```
第 1 章多线程原理与实战 | 79
```
{
System.err.println ("线程池任务未正常执行结束");
}
}
}catch (InterruptedExceptionie)
{
//捕获异常，重新调用 shutdownNow () 方法
threadPool.shutdownNow ();
}
//仍然没有关闭，循环关闭 1000 次，每次等待 10 毫秒
if (! threadPool.isTerminated ())
{
try
{
for (inti= 0 ;i< 1000 ;i++)
{
if (threadPool.awaitTermination ( 10 ,TimeUnit. MILLISECONDS))
{
break;
}
threadPool.shutdownNow ();
}
}catch (InterruptedExceptione)
{
System.err.println (e.getMessage ());
}catch (Throwablee)
{
System.err.println (e.getMessage ());
}
}
}
//省略不相关代码
}
5 .注册 JVM 钩子函数自动关闭线程池
如果使用了线程池，可以在 JVM 注册一个钩子函数，在 JVM 进程关闭之前，由钩子函数自动
将线程池优雅关闭，以确保资源正常释放。
下面的例子使用 JVM 钩子函数关闭了一个定义在随书源码的 ThreadUtil 辅助类中用于执行定
时、顺序任务的线程池，具体代码如下：
packagecom. crazymakercircle. util;
//省略 import
publicclassThreadUtil
{
//懒汉式单例创建线程池：用于执行定时、顺序任务
staticclassSeqOrScheduledTargetThreadPoolLazyHolder
{
//线程池：用于定时任务、顺序排队执行任务
staticfinalScheduledThreadPoolExecutorEXECUTOR=
newScheduledThreadPoolExecutor ( 1 ,
newCustomThreadFactory ("seq"));
static
{
//注册 JVM 关闭时的钩子函数
Runtime.getRuntime (). addShutdownHook (
newShutdownHookThread ("定时和顺序任务线程池",
newCallable<Void>()


80 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
{
@Override
publicVoidcall () throwsException
{
//优雅地关闭线程池
shutdownThreadPoolGracefully (EXECUTOR);
returnnull;
}
}));
}
}
//省略不相关代码
}
```
###### 1. 6. 11 Executors 快捷创建线程池的潜在问题

在很多公司（如阿里、华为等）的编程规范中，非常明确地禁止使用 Executors 快捷创建线程
池，为什么呢？这里从源码讲起，介绍使用 Executors 工厂方法快捷创建线程池将会面临的潜在问题。

1 .使用 Executors 创建“固定数量的线程池”的潜在问题
使用 newFixedThreadPool 工厂方法“固定数量的线程池”的源码如下：
publicstaticExecutorServicenewFixedThreadPool (intnThreads)
{
returnnewThreadPoolExecutor (
nThreads, //核心线程数
nThreads, //最大线程数
0 L, //线程最大空闲（Idle）时长
TimeUnit. MILLISECONDS, //时间单位：毫秒
newLinkedBlockingQueue<Runnable>() //任务的排队队列，无界队列
);
}
newFixedThreadPool 工厂方法返回一个 ThreadPoolExecutor 实例，该线程池实例的 corePoolSize
数量为参数 nThread，其 maximumPoolSize 数量也为参数 nThread，其 workQueue 属性的值为
LinkedBlockingQueue<Runnable>() 无界阻塞队列。
使用 Executors 创建的“固定数量的线程池”的潜在问题主要存在于其 workQueue 上，其值为
LinkedBlockingQueue（无界阻塞队列）。如果任务提交速度持续大于任务处理速度，就会造成队
列中大量的任务等待。如果队列很大，很有可能导致 JVM 出现 OOM（OutOfMemory）异常，即内
存资源耗尽。

```
2 .使用 Executors 创建“单线程化线程池”的潜在问题
使用 newSingleThreadExecutor 工厂方法创建“单线程化线程池”的源码如下：
publicstaticExecutorServicenewSingleThreadExecutor ()
{
returnnewFinalizableDelegatedExecutorService
(newThreadPoolExecutor (
1 , //核心线程数
1 , //最大线程数
0 L, //线程最大空闲（Idle）时长
TimeUnit. MILLISECONDS, //时间单位：毫秒
new LinkedBlockingQueue <Runnable>() //无界队列
));
}
```

```
第 1 章多线程原理与实战 | 81
```
以上代码首先通过调用工厂方法 newFixedThreadPool ( 1 ) 创建一个数量为 1 的“固定大小线程池”，
然后使用 FinalizableDelegatedExecutorService 对该“固定大小线程池”进行包装，这一层包装的作
用是防止线程池的 corePoolSize 被动态地修改。
为了演示“单线程化线程池”的 corePoolSize 始终保持为 1 而不能被修改，接下来首先使用
newSingleThreadExecutor () 工厂方法创建一个“单线程化线程池”，然后试图修改其 corePoolSize 属
性，具体的代码如下：
@org. junit. Test
publicvoidtestNewFixedThreadPool 2 ()
{
//创建一个固定大小线程池
ExecutorServicefixedExecutorService=Executors.newFixedThreadPool ( 1 );
ThreadPoolExecutorthreadPoolExecutor=
(ThreadPoolExecutor) fixedExecutorService;
Print.tco (threadPoolExecutor.getMaximumPoolSize ());
//设置核心线程数
threadPoolExecutor.setCorePoolSize ( 8 );
//创建一个单线程化的线程池
ExecutorServicesingleExecutorService=Executors.newSingleThreadExecutor ();
//转换成普通线程池，会抛出运行时异常 java. lang. ClassCastException
((ThreadPoolExecutor) singleExecutorService). setCorePoolSize ( 8 );
}
以上代码在运行时会抛出异常。观察所抛出的异常，可以知道
FinalizableDelegatedExecutorService 实例无法被转型为 ThreadPoolExecutor 类型，所以也就无法修改
其 corePoolSize 属性，从而确保“单线程化线程池”在运行过程中 corePoolSize 不会被调整，其线程
数始终唯一，做到了真正的 Single。反过来说，如果没有被 FinalizableDelegatedExecutorService 包装，
原始的 ThreadPoolExecutor 实例是可以动态调整 corePoolSize 属性的。
使用 Executors 创建的“单线程化线程池”与“固定大小线程池”一样，其潜在问题仍然存在
与其 workQueue 属性上，该属性的值为 LinkedBlockingQueue（无界阻塞队列）。如果任务提交速度
持续大于任务处理速度，就会造成队列大量阻塞。如果队列很大，很有可能导致 JVM 的 OOM 异常，
甚至造成内存资源耗尽。

3 .使用 Executors 创建“可缓存线程池”的潜在问题
使用 newCachedThreadPool 工厂方法“可缓存线程池”的源码如下：
publicstaticExecutorServicenewCachedThreadPool ()
{
returnnewThreadPoolExecutor (
0 , //核心线程数
Integer. MAX_VALUE, //最大线程数
60 L, //线程最大空闲（Idle）时长
TimeUnit. MILLISECONDS, //时间单位：毫秒
newSynchronousQueue<Runnable>() //任务的排队队列，无界队列
);
}
以上代码通过调用 ThreadPoolExecutor 标准构造器创建一个核心线程数为 0 、最大线程数不设限
制的线程池。所以，理论上“可缓存线程池”可以拥有无数个工作线程，即线程数量几乎无限制。
“可缓存线程池”的 workQueue 为 SynchronousQueue 同步队列，这个队列类似于一个接力棒，入队


82 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

与出队必须同时传递，正因为“可缓存线程池”可以无限制创建线程，不会有任务等待，所以才使
用 SynchronousQueue。
当“可缓存线程池”有新任务到来时，新任务会被插入到 SynchronousQueue 实例中，由于
SynchronousQueue 是同步队列，因此会在池中寻找可用线程来执行，若有可用线程则执行，若没有
可用线程，则线程池会创建一个线程来执行该任务。
SynchronousQueue 是一个比较特殊的阻塞队列实现类，SynchronousQueue 没有容量，每一个插
入操作都要等待对应的删除操作，反之每个删除操作都要等待对应的插入操作。也就是说，如果使
用 SynchronousQueue，提交的任务不会被真实地保存，而是将新任务交给空闲线程执行，如果没有
空闲线程，就创建线程，如果线程数都已经大于最大线程数，就执行拒绝策略。使用这种队列需要
将 maximumPoolSize 设置得非常大，从而使得新任务不会被拒绝。
使用 Executors 创建的“可缓存线程池”的潜在问题存在于其最大线程数量不设上限。由于其
maximumPoolSize 的值为 Integer. MAX_VALUE（非常大），可以认为是无限创建线程的，如果任务
提交较多，就会造成大量的线程被启动，很有可能造成 OOM 异常，甚至导致 CPU 线程资源耗尽。

4 .使用 Executors 创建“可调度线程池”的潜在问题
使用 newScheduledThreadPool 工厂方法“可调度线程池”的源码如下：
publicstaticScheduledExecutorServicenewScheduledThreadPool (intcorePoolSize)
{
returnnewScheduledThreadPoolExecutor (corePoolSize);
}
Executors 的 newScheduledThreadPool 工厂方法调用了 ScheduledThreadPoolExecutor 实现类的构
造器，而 ScheduledThreadPoolExecutor 继承了 ThreadPoolExecutor 的普通线程池类，在其构造内部进
一步调用了该父类的构造器，具体的代码如下：
publicScheduledThreadPoolExecutor (intcorePoolSize)
{
super (corePoolSize, //核心线程数
Integer. MAX_VALUE, //最大线程数
0 , //线程最大空闲（Idle）时长
NANOSECONDS, //时间单位
newDelayedWorkQueue () //任务的排队队列
);
}
以上代码创建一个 ThreadPoolExecutor 实例，其 corePoolSize 为传递来的参数，maximumPoolSize 为
Integer. MAX_VALUE，表示线程数不设上限，其 workQueue 为一个 DelayedWorkQueue 实例，这是
一个按到期时间升序排序的阻塞队列。
使用 Executors 创建的“可调度线程池”的潜在问题存在于其最大线程数量不设上限。由于其
线程数量不设限制，如果到期任务太多，就会导致 CPU 的线程资源耗尽。实际上，通过源码分析可
以看出，“可调度线程池”的潜在问题首先还是无界工作队列（任务排队的队列）长度都为
Integer. MAX_VALUE，可能会堆积大量的任务，从而导致 OOM 甚至耗尽内存资源的问题。
以上内容分别梳理了 Executors 四个工厂方法所创建的线程池将面临的潜在问题。总结起来，
使用 Executors 去创建线程池主要的弊端如下：


```
第 1 章多线程原理与实战 | 83
```
（ 1 ）FixedThreadPool 和 SingleThreadPool
这两个工厂方法所创建的线程池，工作队列（任务排队的队列）长度都为 Integer. MAX_VALUE，
可能会堆积大量的任务，从而导致 OOM（即耗尽内存资源）。

（ 2 ）CachedThreadPool 和 ScheduledThreadPool
这两个工厂方法所创建的线程池允许创建的线程数量为 Integer. MAX_VALUE，可能会导致创
建大量的线程，从而导致 OOM 问题。

网上众人和阿里编程规范，没有深入研读源码，被 ScheduledThreadPool 的最大线程数没有限制
的参数所误导。通过源码分析发现，最大线程数参数 maximumPoolSize 对可调度线程池并未起作用，
实际上，ScheduledThreadPool 内部的线程数最多为核心线程数，关键的问题还是在于其工作队列上。
该线程池的工作队列（任务排队的队列）长度都为 Integer. MAX_VALUE，可能会堆积大量的任务，
从而导致 OOM 问题。
虽然 Executors 工厂类提供了构造线程池的便捷方法，但是对于服务器程序而言，大家应该杜
绝使用这些便捷方法，而是直接使用线程池 ThreadPoolExecutor 的构造器，从而有效避免由于使用
无界队列可能导致的内存资源耗尽，或者由于对线程个数不做限制而导致的 CPU 资源耗尽等问题。
所以，大厂的编程规范都不允许使用 Executors 创建线程池，而是要求使用标准构造器
ThreadPoolExecutor 创建线程池。

#### 1. 7 确定线程池的线程数

使用线程池的好处主要有以下三点：
1 ）降低资源消耗：线程是稀缺资源，如果无限制地创建，不仅会消耗系统资源，还会降低系
统的稳定性，通过重复利用已创建的线程可以降低线程创建和销毁造成的消耗。
2 ）提高响应速度：当任务到达时，可以不需要等待线程创建就能立即执行。
3 ）提高线程的可管理性：线程池提供了一种限制、管理资源的策略，维护一些基本的线程统
计信息，如已完成任务的数量等。通过线程池可以对线程资源进行统一的分配、监控和调优。

虽然使用线程池的好处很多，但是如果其线程数配置得不合理，不仅可能达不到预期效果，
反而可能降低应用的性能。

###### 1. 7. 1 按照任务类型对线程池进行分类

使用标准构造器 ThreadPoolExecutor 创建线程池时，会涉及线程数的配置，而线程数的配置与
异步任务类型是分不开的。这里将线程池的异步任务大致分为以下三类：

（ 1 ）IO 密集型任务
此类任务主要是执行 IO 操作。由于执行 IO 操作的时间较长，导致 CPU 的利用率不高，这类任
务 CPU 常处于空闲状态。Netty 的 IO 读写操作为此类任务的典型例子。


84 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

（ 2 ）CPU 密集型任务
此类任务主要是执行计算任务。由于响应时间很快，CPU 一直在运行，这种任务 CPU 的利用
率很高。

（ 3 ）混合型任务
此类任务既要执行逻辑计算，又要进行 IO 操作（如 RPC 调用、数据库访问）。相对来说，由
于执行 IO 操作的耗时较长（一次网络往返往往在数百毫秒级别），这类任务的 CPU 利用率也不是太
高。Web 服务器的 HTTP 请求处理操作为此类任务的典型例子。

一般情况下，针对以上不同类型的异步任务需要创建不同类型的线程池，并进行针对性的参
数配置。

###### 1. 7. 2 为 IO 密集型任务确定线程数

由于 IO 密集型任务的 CPU 使用率较低，导致线程空余时间很多，因此通常需要开 CPU 核心数
两倍的线程。当 IO 线程空闲时，可以启用其他线程继续使用 CPU，以提高 CPU 的使用率。
Netty 的 IO 处理任务就是典型的 IO 密集型任务。所以，Netty 的 Reactor（反应器）实现类（定制
版的线程池）的 IO 处理线程数默认正好为 CPU 核数的两倍，以下是其相关的代码：
//多线程版本 Reactor 反应器组
publicabstractclassMultithreadEventLoopGroupextends
MultithreadEventExecutorGroupimplementsEventLoopGroup{
//IO 事件处理线程数
privatestaticfinalintDEFAULT_EVENT_LOOP_THREADS;
//IO 事件处理线程数默认值为 CPU 核数的两倍
static{
DEFAULT_EVENT_LOOP_THREADS=Math.max ( 1 ,
SystemPropertyUtil.getInt ("io. netty. eventLoopThreads",
Runtime.getRuntime (). availableProcessors ()* 2 ));
}
/**
*构造器
*/
protectedMultithreadEventLoopGroup (intnThreads,
ThreadFactorythreadFactory, Object... args){
super (nThreads== 0?
DEFAULT_EVENT_LOOP_THREADS: nThreads, threadFactory, args);
}
//省略其他
}

```
Netty 是基于 Java 实现的高性能传输框架，基于 Reactor 模式实现，是目前非常火
热的高性能传输中间件，在大量的著名框架中被使用，也是 Java 工程师、架构师必知必会的
基础框架。有关 Netty 的知识，请参考本书的上卷《Java 高并发核心编程卷 1 （加强版）：
NIO、Netty、Redis、ZooKeeper》。
```
本书在随书源码的 ThreadUtil 类中为 IO 密集型任务创建了一个简单的参考线程池，具体代码
如下：


```
第 1 章多线程原理与实战 | 85
```
packagecom. crazymakercircle. util;
//省略 import
publicclassThreadUtil
{
//CPU 核数
privatestaticfinalintCPU_COUNT=Runtime.getRuntime (). availableProcessors ();
//IO 处理线程数
privatestaticfinalintIO_MAX=Math.max ( 2 ,CPU_COUNT* 2 );
/**
*空闲保活时限，单位为秒
*/
privatestaticfinalintKEEP_ALIVE_SECONDS= 30 ;
/**
*有界队列 size
*/
privatestaticfinalintQUEUE_SIZE= 128 ;
//懒汉式单例创建线程池：用于 IO 密集型任务
privatestaticclassIoIntenseTargetThreadPoolLazyHolder
{
//线程池：用于 IO 密集型任务
privatestaticfinalThreadPoolExecutorEXECUTOR=newThreadPoolExecutor (
IO_MAX, //CPU 核数* 2
IO_MAX, //CPU 核数* 2
KEEP_ALIVE_SECONDS,
TimeUnit. SECONDS,
newLinkedBlockingQueue (QUEUE_SIZE),
newCustomThreadFactory ("io"));
static
{
EXECUTOR.allowCoreThreadTimeOut (true);
//JVM 关闭时的钩子函数
Runtime.getRuntime (). addShutdownHook (
newShutdownHookThread ("IO 密集型任务线程池", newCallable<Void>()
{
@Override
publicVoidcall () throwsException
{
//优雅地关闭线程池
shutdownThreadPoolGracefully (EXECUTOR);
returnnull;
}
}));
}
}
//省略不相关代码
}
在以上的参考代码中，有以下几个要点需要进行特别说明：
1 ）为参考的 IO 线程池调用了 allowCoreThreadTimeOut (...) 方法，并且传入了参数 true，
keepAliveTime 参数所设置的 Idle 超时策略也将被应用于核心线程，当池中的线程长时间空闲时，可
以自行销毁。
2 ）使用有界队列缓冲任务而不是无界队列，如果 128 太小，可以根据具体需要进行增大，但
是不能使用无界队列。
3 ）corePoolSize 和 maximumPoolSize 不一致时，当 corePoolSize 满了而 maximumPoolSize 没满时
即使可以创建线程，但是此时线程池默认不会创建线程，而是将任务加入阻塞队列，等待核心线程


86 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

空闲，而如果核心线程不空闲，那么任务得不到执行（具体参见前面的例子）。如果 corePoolSize
和 maximumPoolSize 保持一致，使得在接收到新任务时，如果没有空闲工作线程，就优先创建新的
线程去执行新任务，而不是将任务优先加入阻塞队列且等待现有工作线程空闲后再执行。
4 ）使用懒汉式单例模式创建线程池，如果代码没有用到此线程池，就不会立即创建。
5 ）使用 JVM 关闭时的钩子函数优雅地自动关闭线程池。

###### 1. 7. 3 为 CPU 密集型任务确定线程数

CPU 密集型任务也叫计算密集型任务，其特点是要进行大量计算而需要消耗 CPU 资源，比如
计算圆周率、对视频进行高清解码等。CPU 密集型任务虽然也可以并行完成，但是并行的任务越多，
花在任务切换的时间就越多，CPU 执行任务的效率就越低，所以要最高效地利用 CPU，CPU 密集型
任务并行执行的数量应当等于 CPU 的核心数。
比如说 4 个核心的 CPU，通过 4 个线程并行执行 4 个 CPU 密集型任务，此时的效率是最高的。但
是如果线程数远远超出 CPU 核心数量，就需要频繁地切换线程，线程上下文切换时需要消耗时间，
反而会使得任务效率下降。因此，对于 CPU 密集型的任务来说，线程数等于 CPU 数就行。
本书在随书源码的 ThreadUtil 类中为 CPU 密集型任务创建了一个简单的参考线程池，具体代码
如下：
packagecom. crazymakercircle. util;
//省略 import
publicclassThreadUtil
{
//CPU 核数
privatestaticfinalintCPU_COUNT=Runtime.getRuntime (). availableProcessors ();
privatestaticfinalintMAXIMUM_POOL_SIZE=CPU_COUNT;
//懒汉式单例创建线程池：用于 CPU 密集型任务
privatestaticclassCpuIntenseTargetThreadPoolLazyHolder
{
//线程池：用于 CPU 密集型任务
privatestaticfinalThreadPoolExecutorEXECUTOR=newThreadPoolExecutor (
MAXIMUM_POOL_SIZE,
MAXIMUM_POOL_SIZE,
KEEP_ALIVE_SECONDS,
TimeUnit. SECONDS,
newLinkedBlockingQueue (QUEUE_SIZE),
newCustomThreadFactory ("cpu"));
static
{
EXECUTOR.allowCoreThreadTimeOut (true);
//JVM 关闭时的钩子函数
Runtime.getRuntime (). addShutdownHook (
newShutdownHookThread ("CPU 密集型任务线程池", newCallable<Void>()
{
@Override
publicVoidcall () throwsException
{
//优雅关闭线程池
shutdownThreadPoolGracefully (EXECUTOR);
returnnull;
}
}));


```
第 1 章多线程原理与实战 | 87
```
```
}
}
//省略不相关代码
}
```
###### 1. 7. 4 为混合型任务确定线程数

混合型任务既要执行逻辑计算，又要进行大量非 CPU 耗时操作（如 RPC 调用、数据库访问、网
络通信等），所以混合型任务 CPU 利用率不是太高，非 CPU 耗时往往是 CPU 耗时的数倍。比如在
Web 应用处理 HTTP 请求处理时，一次请求处理会包括 DB 操作、RPC 操作、缓存操作等多种耗时操
作。一般来说，一次 Web 请求的 CPU 计算耗时往往较少，大致在 100 ~ 500 毫秒，而其他耗时操作会
占用 500 ~ 1000 毫秒，甚至更多的时间。
在为混合型任务创建线程池时，如何确定线程数呢？业界有一个比较成熟的估算公式，具体
如下：
最佳线程数=（（线程等待时间+线程 CPU 时间）/线程 CPU 时间）*CPU 核数
经过简单的换算，以上公式可进一步转换为：
最佳线程数目=（线程等待时间与线程 CPU 时间之比+ 1 ）*CPU 核数
通过公式可以看出：等待时间所占比例越高，需要的线程就越多；CPU 耗时所占比例越高，
需要的线程就越少。下面举一个例子：比如在 Web 服务器处理 HTTP 请求时，假设平均线程 CPU 运
行时间为 100 毫秒，而线程等待时间（比如包括 DB 操作、RPC 操作、缓存操作等）为 900 毫秒，如
果 CPU 核数为 8 ，那么根据上面这个公式，估算如下：
（ 900 ms+ 100 ms）/ 100 ms* 8 = 10 * 8 = 80
经过计算，以上案例中需要的线程数为 80 。很多小伙伴认为，线程数越高越好。那么，使用
很多线程是否就一定比单线程高效呢？答案是否定的，比如大名鼎鼎的 Redis 就是单线程的，但它
却非常高效，基本操作都能达到十万量级/秒。

```
为什么 Redis 使用单线程也如此之快，原因在于：Redis 基本都是内存操作，在这
种情况下单线程可以高效地利用 CPU，多线程带来线程上下文切换的开销，单线程就没有这
种开销。有关 Redis 的知识，可参考笔者的另一本书《Java 高并发核心编程卷 1 （加强版）：
NIO、Netty、Redis、ZooKeeper》。
```
由于 Redis 基本都是内存操作，在这种情况下单线程可以高效地利用 CPU，多线程反而不是太
适用。多线程适用场景一般是：存在相当比例非 CPU 耗时操作，如 IO、网络操作，需要尽量提高并
行化比率以提升 CPU 的利用率。
以上公式的估算结果仅仅是理论最佳值，在生产环境中的使用也仅供参考。生产环境需要结合
系统网络环境和硬件情况（CPU、内存、硬盘读写速度）不断尝试，获取一个符合实际的线程数值。
本书在随书源码的 ThreadUtil 类中为混合型任务创建了一个简单的参考线程池，具体代码如下：
packagecom. crazymakercircle. util;
//省略 import
publicclassThreadUtil
{
privatestaticfinalintMIXED_MAX= 128 ; //最大线程数


88 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

privatestaticfinalStringMIXED_THREAD_AMOUNT="mixed. thread. amount";
//懒汉式单例创建线程池：用于混合型任务
privatestaticclassMixedTargetThreadPoolLazyHolder
{
//首先从环境变量 mixed. thread. amount 中获取预先配置的线程数
//如果没有对 mixed. thread. amount 进行配置，就使用常量 MIXED_MAX 作为线程数
privatestaticfinalintmax=
(null!=System.getProperty (MIXED_THREAD_AMOUNT))?
Integer.parseInt (System.getProperty (MIXED_THREAD_AMOUNT))
: MIXED_MAX;
//线程池：用于混合型任务
privatestaticfinalThreadPoolExecutorEXECUTOR=newThreadPoolExecutor (
max,
max,
KEEP_ALIVE_SECONDS,
TimeUnit. SECONDS,
newLinkedBlockingQueue (QUEUE_SIZE),
newCustomThreadFactory ("mixed"));
static
{
EXECUTOR.allowCoreThreadTimeOut (true);
//JVM 关闭时的钩子函数
Runtime.getRuntime (). addShutdownHook (
newShutdownHookThread ("混合型任务线程池", newCallable<Void>()
{
@Override
publicVoidcall () throwsException
{
//优雅地关闭线程池
shutdownThreadPoolGracefully (EXECUTOR);
returnnull;
}
}));
}
}
//省略不相关代码
}
在使用以上代码创建混合型线程池时，建议按照前面的最佳线程数估算公式提前预估好线程
数（如 80 ），然后设置在环境变量 mixed. thread. amount 中，测试用例如下：
packagecom. crazymakercircle. mutithread. basic. create 3 ;
//省略 import
publicclassCreateThreadPoolDemo
{
@org. junit. Test
publicvoidtestMixedThreadPool ()
{
System.getProperties (). put ("mixed. thread", 600 );
//获取自定义的混合线程池
ExecutorServicepool=ThreadUtil.getMixedTargetThreadPool ();
for (inti= 0 ;i< 1000 ;i++)
{
try
{
sleepMilliSeconds ( 10 );
pool.submit (newTargetTask ());
}catch (RejectedExecutionExceptione)
{


```
第 1 章多线程原理与实战 | 89
```
```
//异常处理
}
}
//等待 10 秒
sleepSeconds ( 10 );
Print.tco ("关闭线程池");
}
//省略其他
}
```
#### 1. 8 ThreadLocal 原理与实战

在 Java 的多线程并发执行过程中，为了保证多个线程对变量的安全访问，可以将变量放到
ThreadLocal 类型的对象中，使变量在每个线程中都有独立值，不会出现一个线程读取变量时而被另
一个线程修改的现象。ThreadLocal 类通常被翻译为“线程本地变量”类或者“线程局部变量”类。

###### 1. 8. 1 ThreadLocal 的基本使用

ThreadLocal 是位于 JDK 的 java. lang 核心包中。如果程序创建了一个 ThreadLocal 实例，那么在访
问这个变量的值时，每个线程都会拥有一个独立的、自己的本地值。“线程本地变量”可以看成专
属于线程的变量，不受其他线程干扰，保存着线程的专属数据。当线程结束后，每个线程所拥有的
那个本地值会被释放。在多线程并发操作“线程本地变量”的时候，线程各自操作的是自己的本地
值，从而规避了线程安全问题。
ThreadLocal 的英文字面翻译为“线程本地”，
实际上 ThreadLocal 代表的是线程本地变量，可能将
其命名为 ThreadLocalVariable 更加容易让人理解。
ThreadLocal 如何做到为每个线程存有一份独
立的本地值呢？一个 ThreadLocal 实例可以形象地
理解为一个 Map（早期版本的 ThreadLocal 是这样设
计的）。当工作线程 Thread 实例向本地变量保持某
个值时，会以“Key-Value 对”（即键-值对）的形
式保存在 ThreadLocal 内部的 Map 中，其中 Key 为线
程 Thread 实例，Value 为待保存的值。当工作线程
Thread 实例从 ThreadLocal 本地变量取值时，会以
Thread 实例为 Key，获取其绑定的 Value。一个
ThreadLocal 实例内部结构的形象展示大致如图 1 - 19
所示。
Java 程序可以使用 ThreadLocal 的成员方法进
行本地值操作，具体的成员方法如表 1 - 2 所示。

```
图 1 - 19 一个 ThreadLocal（早期版本）
实例内部结构的形象展示
```

90 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

表 1 - 2 ThreadLocal 的成员方法
方法说明
set (Tvalue) 设置当前线程在“线程本地变量”实例中绑定的本地值
Tget () 获得当前线程在“线程本地变量”实例中绑定的本地值
remove () 移除当前线程在“线程本地变量”实例中绑定的本地值
下面的例子通过 ThreadLocal 的成员方法进行“线程本地变量”中线程本地值的设置、获取、
移除，具体的代码如下：
packagecom. crazymakercircle. mutithread. basic. threadlocal;
//省略 import
publicclassThreadLocalTest
{
@Data
staticclassFoo
{
//实例总数
staticfinalAtomicIntegerAMOUNT=newAtomicInteger ( 0 );
//对象的编号
intindex= 0 ;
//对象的内容
intbar= 10 ;
//构造器
publicFoo ()
{
index=AMOUNT.incrementAndGet (); //总数增加，并且给对象的编号
}
@Override
publicStringtoString ()
{
returnindex+"@Foo{bar="+bar+'}';
}
}
//定义线程本地变量
privatestaticfinalThreadLocal<Foo>LOCAL_FOO= newThreadLocal<Foo>();
publicstaticvoidmain (String[]args) throwsInterruptedException
{
//获取自定义的混合型线程池
ThreadPoolExecutorthreadPool=ThreadUtil.getMixedTargetThreadPool ();
//提交 5 个任务，将会用到 5 个线程
for (inti= 0 ;i< 5 ;i++)
{
threadPool.execute (newRunnable ()
{
@Override
publicvoidrun ()
{
//获取“线程本地变量”中当前线程所绑定的值
if (LOCAL_FOO.get ()==null)
{
//设置“线程本地变量”中当前线程所绑定的值
LOCAL_FOO.set (newFoo ());
}
Print.tco ("初始的本地值："+LOCAL_FOO.get ());
//每个线程执行 10 次
for (inti= 0 ;i< 10 ;i++)


```
第 1 章多线程原理与实战 | 91
```
{
Foofoo=LOCAL_FOO.get ();
foo.setBar (foo.getBar ()+ 1 ); //值增 1
sleepMilliSeconds ( 10 );
}
Print.tco ("累加 10 次之后的本地值："+LOCAL_FOO.get ());
//删除“线程本地变量”中当前线程所绑定的值
LOCAL_FOO.remove (); //这点对于线程池中的线程尤其重要
}
});
}
}
}
运行以上示例，其结果如下：
[apppool- 1 - mixed- 3 ]：初始的本地值： 3 @Foo{bar= 10 }
[apppool- 1 - mixed- 4 ]：初始的本地值： 4 @Foo{bar= 10 }
[apppool- 1 - mixed- 5 ]：初始的本地值： 5 @Foo{bar= 10 }
[apppool- 1 - mixed- 2 ]：初始的本地值： 1 @Foo{bar= 10 }
[apppool- 1 - mixed- 1 ]：初始的本地值： 2 @Foo{bar= 10 }
[apppool- 1 - mixed- 1 ]：累加 10 次之后的本地值： 2 @Foo{bar= 20 }
[apppool- 1 - mixed- 3 ]：累加 10 次之后的本地值： 3 @Foo{bar= 20 }
[apppool- 1 - mixed- 5 ]：累加 10 次之后的本地值： 5 @Foo{bar= 20 }
[apppool- 1 - mixed- 2 ]：累加 10 次之后的本地值： 1 @Foo{bar= 20 }
[apppool- 1 - mixed- 4 ]：累加 10 次之后的本地值： 4 @Foo{bar= 20 }
通过输出的结果可以看出，在“线程本地变量”（LOCAL_FOO）中，每一个线程都绑定了一
个独立的值（Foo 对象），这些值对象是线程的私有财产，可以理解为线程的本地值，每一次操作
都是在自己的同一个本地值上进行的，从例子中线程本地值的 index 始终一致可以看出，每个线程
操作的是同一个 Foo 对象。
如果线程尚未在本地变量（如 LOCAL_FOO）中绑定一个值，直接通过 get () 方法去获取本地值
会获取到一个空值，此时可以通过调用 set () 方法设置一个值作为初始值，具体的代码如下：
//获取“线程本地变量”中当前线程所绑定的值
if (LOCAL_FOO.get ()==null)
{
//设置“线程本地变量”中当前线程所绑定的初始值
LOCAL_FOO.set (newFoo ());
}
在当前线程尚未绑定值时，如果希望能从线程本地变量获取到初始值，而且也不想采用以上
的“判空后设值”这种相对烦琐的方式，可以调用 ThreadLocal.withInitial (...) 静态工厂方法，在定义
ThreadLocal 对象时设置一个获取初始值的回调函数，具体的代码如下：
ThreadLocal<Foo>LOCAL_FOO=ThreadLocal.withInitial (()->newFoo ());
以上代码并没有使用 newThreadLocal<Foo>() 构造一个 ThreadLocal 对象，而是调用 withInitial (...) 工
厂方法创建一个 ThreadLocal 对象，并传递了一个获取初始值的 Lambda 回调函数。在线程尚未绑定
值而直接从“线程本地变量”获取值时，将会取得回调函数被调用之后所返回的值。

###### 1. 8. 2 ThreadLocal 使用场景

```
ThreadLocal 是解决线程安全问题一个较好方案，它通过为每个线程提供一个独立的本地值去
```

92 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

解决并发访问的冲突问题。在很多情况下，使用 ThreadLocal 比直接使用同步机制（如 synchronized）
解决线程安全问题更简单、更方便，且结果程序拥有更高的并发性。
ThreadLocal 使用场景大致可以分为以下两类：
（ 1 ）线程隔离
ThreadLocal 的主要价值在于线程隔离，ThreadLocal 中的数据只属于当前线程，其本地值对别
的线程是不可见的，在多线程环境下，可以防止自己的变量被其他线程篡改。另外，由于各个线程
之间的数据相互隔离，避免了同步加锁带来的性能损失，大大提升了并发性的性能。
ThreadLocal 在线程隔离的常用案例为：可以每个线程绑定一个用户会话信息、数据库连接、
HTTP 请求等，这样一个线程的所有调用到的处理函数都可以非常方便地访问这些资源。
常见的 ThreadLocal 使用场景为数据库连接独享、Session 数据管理等。
在“线程隔离”场景中，使用 ThreadLocal 的典型案例为：可以每个线程绑定一个数据库连接，
使得这个数据库连接为线程所独享，从而避免数据库连接被混用而导致操作异常问题。

（ 2 ）跨函数传递数据
通常用于同一个线程内，跨类、跨方法传递数据时，如果不用 ThreadLocal，那么相互之间的
数据传递势必要靠返回值和参数，这样无形之中增加了这些类或者方法之间的耦合度。
由于 ThreadLocal 的特性，同一线程在某些地方进行设置，在随后的任意地方都可以获取到。
线程执行过程中所执行到的函数都能读写 ThreadLocal 变量的线程本地值，从而可以方便地实现跨
函数的数据传递。使用 ThreadLocal 保存函数之间需要传递的数据，在需要的地方直接获取，也能
避免通过参数传递数据带来的高耦合。
在“跨函数传递数据”场景中使用 ThreadLocal 的典型案例为：可以为每个线程绑定一个 Session
（用户会话）信息，这样一个线程所有调用到的代码都可以非常方便地访问这个本地会话，而不需
要通过参数传递。
接下来举例分析一下在以上两类场景中大家应该如何使用 ThreadLocal。

###### 1. 8. 3 使用 ThreadLocal 进行线程隔离

ThreadLocal 在“线程隔离”应用场景的典型应用为“数据库连接独享”。下面的代码来自
Hibernate，代码中通过 ThreadLocal 进行数据库连接（Session）的“线程本地化”存储，主要的代
码如下：
privatestaticfinalThreadLocalthreadSession=newThreadLocal ();
publicstaticSessiongetSession () throwsInfrastructureException{
Sessions=(Session) threadSession.get ();
try{
if (s==null){
s=getSessionFactory (). openSession ();
threadSession.set (s);
}
}catch (HibernateExceptionex){
thrownewInfrastructureException (ex);
}
returns;
}


```
第 1 章多线程原理与实战 | 93
```
Hibernate 对数据库连接进行了封装，一个 Session 代表一个数据库连接。通过以上代码可以看
到，在 Hibernate 的 getSession () 方法中，首先判断当前线程中有没有放进去 session，如果还没有，那
么通过 sessionFactory (). openSession () 来创建一个 Session，再将 Session 设置到 ThreadLocal 变量中，这
个 Session 相当于线程的私有变量，而不是所有线程共用的，显然其他线程中是取不到这个 Session。
一般来说，完成数据库操作之后程序会将 Session 关闭，从而节省数据库连接资源。如果 Session
的使用方式为共享而不是独占，在这种情况下，Session 是多线程共享使用的，如果某个线程使用
完成之后直接将 Session 关闭，其他线程在操作 Session 时就会报错。所以 Hibernate 通过 ThreadLocal
非常简单实现了数据库连接的安全使用。

###### 1. 8. 4 使用 ThreadLocal 进行跨函数数据传递

ThreadLocal 在“跨函数数据传递”应用场景的典型有很多：
1 ）用来传递请求过程中的用户 ID。
2 ）用来传递请求过程中的用户会话（Session）。
3 ）用来传递 HTTP 的用户请求实例 HttpRequest。
4 ）其他需要在函数之间频繁传递的数据。
以下代码来自于疯狂创客圈社群的微服务脚手架 Crazy-SpringCloud 工程，通过 ThreadLocal 在
函数之间传递用户信息、会话信息等，并且封装成了一个独立的 SessionHolder 类，具体的代码如下：
packagecom. crazymaker. springcloud. common. context;
//省略 import
publicclassSessionHolder
{
//sessionid，线程本地变量
privatestaticfinalThreadLocal<String>sidLocal=newThreadLocal<>("sidLocal");
//用户信息，线程本地变量
privatestaticfinalThreadLocal< **UserDTO** >sessionUserLocal=
newThreadLocal<>("sessionUserLocal");
//session，线程本地变量
privatestaticfinalThreadLocal< **HttpSession** >sessionLocal=
newThreadLocal<>("sessionLocal");
//省略其他
/**
*保存 session 在线程本地变量中
*/
publicstaticvoidsetSession (HttpSessionsession)
{
sessionLocal.set (session);
}
/**
*取得绑定在线程本地变量中的 session
*/
publicstaticHttpSessiongetSession ()
{
HttpSessionsession=sessionLocal.get ();
Assert.notNull (session,"session 未设置");
returnsession;
}
//省略其他
}


94 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

###### 1. 8. 5 ThreadLocal 内部结构演进

在早期的 JDK 版本中，ThreadLocal 的内部结构是一个 Map，其中每一个线程实例作为 Key，线
程在“线程本地变量”中绑定的值为 Value（本地值）。早期版本中的 Map 结构，其拥有者为 ThreadLocal
实例，每一个 ThreadLocal 实例拥有一个 Map 实例。
在大部分的应用中，实际上线程比较多，往往会配置数百个线程。反过来说，一个应用的线
程局部变量又很少，可能就几个。
大家知道，HashMap 在扩容时存在高成本、低性能问题。为什么呢？在 HashMap 的内部是一个
槽位（slot）数组，这个数组也叫哈希表，存储的是 Key 的哈希值。当槽位数组中的元素个数超过
容量（默认为 16 ）×加载因子（默认为 0. 75 ）也是 12 的时候，槽位数组会进行扩容，扩容成 32 个槽
位。对于每一个槽位，可以理解为一个桶（bucket），如果一个桶内元素超过 8 个，链表会转换成
红黑树。无论是槽位数组扩容还是桶内链表转换成红黑树，这都是高成本、低性能的扩容工作。
ThreadLocal 实例内部的 Map 结构叫作 ThreadLocalMap，并没有直接采用 HashMap 对象，而是自
定义的和 HashMap 类似的结构。与 HashMap 不同的是，ThreadLocalMap 去掉了桶结构，如果发生哈
希碰撞，将 Key 相同的 Entry 放在槽位后面相邻的空闲位置上。为了区分这两种处理碰撞的方案，把
HashMap（数组加链表）的处理方式叫作链地址法，即发生碰撞就把 Entry 放在桶的链表中；把
ThreadLocalMap 的处理方式叫作开放地址法，即发生碰撞，就按照某种方法继续探测哈希表中的其
他存储单元，直到找到空位置为止。
ThreadLocalMap 与 HashMap 一样，槽位数组（哈希表）在扩容时存在高成本、低性能问题。其
槽位数组初始的容量为 16 ，当槽位数组中的元素个数超过容量（默认为 16 ）×加载因子（默认为 0. 75 ）
也是 12 的时候，槽位数组会进行扩容，扩容成 32 个槽位。这里需要创建一个新的数组，再进行 Entry
的哈希值的二次取模，在新数组找到新的位置后放入。
由于 ThreadLocalMap 扩容存在性能问题，因此在线程比较多、线程局部变量少的场景下是不
是可以转换思路，将 ThreadLocal 实例变成 Key，一个线程一个 Map 呢？这是可以的，而且免去了
ThreadLocalMap 高成本、低性能的扩容工作。
在 JDK 8 版本中，ThreadLocal 的内部结构发生了演进，虽然还是使用了 Map 结构，但是 Map 结
构的拥有者已经发生了变化，其拥有者为 Thread（线程）实例，每一个 Thread 实例拥有一个 Map 实
例。另外，Map 结构的 Key 值也发生了变化：新的 Key 为 ThreadLocal 实例。
在 JDK 8 版本中，每一个 Thread 线程内部都有一个 Map（ThreadLocalMap），如果我们给一个
Thread 创建多个 ThreadLocal 实例，然后放置本地数据，那么当前线程的 ThreadLocalMap 中就会有多
个“Key-Value 对”，其中 ThreadLocal 实例为 Key，本地数据为 Value。
在代码的层面来说，新版本的 ThreadLocalMap 还是由 ThreadLocal 类维护的，由 ThreadLocal 负
责 ThreadLocalMap 实例的获取和创建，并从中设置本地值、获取本地值。所以 ThreadLocalMap 还寄
存于 ThreadLocal 内部，并没有被迁移到 Thread 内部。
一个 ThreadLocalMap（新版本）实例内部结构形象展示如图 1 - 20 所示。
每一个线程在获取本地值时，都会将 ThreadLocal 实例作为 Key 从自己拥有的 ThreadLocalMap
中获取值，别的线程无法访问自己的 ThreadLocalMap 实例，自己也无法访问别人的 ThreadLocalMap
实例，达到相互隔离，互不干扰。


```
第 1 章多线程原理与实战 | 95
```
图 1 - 20 一个 ThreadLocalMap（新版本）实例内部结构的形象展示
与早期版本的 ThreadLocalMap 实现相比，新版本的主要变化为：
1 ）拥有者发生了变化：新版本的 ThreadLocalMap 拥有者为 Thread，早期版本的 ThreadLocalMap
拥有者为 ThreadLocal。
2 ）Key 发生了变化：新版本的 Key 为 ThreadLocal 实例，早期版本的 Key 为 Thread 实例。
与早期版本的 ThreadLocalMap 实现相比，新版本的主要优势为：
1 ）每个 ThreadLocalMap 存储的“Key-Value 对”数量变少。早期版本的“Key-Value 对”数量
与线程个数强关联，若线程数量多，则 ThreadLocalMap 存储“Key-Value 对”数量也多。新版本的
ThreadLocalMap 的 Key 为 ThreadLocal 实例，多线程情况下 ThreadLocal 实例比线程数少。
2 ）早期版本 ThreadLocalMap 的拥有者为 ThreadLocal，在 Thread（线程）实例被销毁后，
ThreadLocalMap 还是存在的；新版本的 ThreadLocalMap 的拥有者为 Thread，现在当 Thread 实例被销
毁后，ThreadLocalMap 也会随之被销毁，在一定程度上能减少内存的消耗。

如果追求极致，能不能对性能进一步优化呢？
通过上面的场景分析大家看到，一般来说一个应用有数百个线程，几个线程局部变量在这个
场景下是否可以使用数组来替代 HashMap 呢？
比如：可以把线程内部的 ThreadLocalMap 结构换成数组，然后对线程局部变量进行编号，通
过编号在数组中去访问局部变量的值。在这个场景下，无论是存放元素还是获取元素，直接使用数
组比使用 HashMap 能获得更低的内存成本、更高的访问性能。
实际上，追求性能极致 Netty 就是这么优化的，Netty 内部的存储 FastThreadLocal 的结构具体如
图 1 - 21 所示。
有关 FastThreadLocal 的介绍，这里不作展开。


96 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
图 1 - 21 Netty 内部的存储 FastThreadLocal 的结构
```
###### 1. 8. 6 ThreadLocal 源码分析

ThreadLocal 源码提供的方法不多，主要有：set (Tvalue) 方法、get () 方法、remove () 方法和
initialValue () 方法。

1 .set (Tvalue) 方法
set (Tvalue) 方法用于设置“线程本地变量”在当前线程的 ThreadLocalMap 中对应的值，相当于
设置线程本地值，其核心源码如下：
publicvoidset (Tvalue){
//获取当前线程对象
Threadt=Thread.currentThread ();
//获取当前线程的 ThreadLocalMap 成员
ThreadLocalMapmap=getMap (t);
//判断 map 是否存在
if (map!=null)
{
//value 被绑定到 threadLocal 实例
map.set (this, value);
}
else
{
//如果当前线程没有 ThreadLocalMap 成员实例
//创建一个 ThreadLocalMap 实例，然后作为成员关联到 t（thread 实例）
createMap (t, value);
}
}
//获取线程 t 的 ThreadLocalMap 成员
ThreadLocalMapgetMap (Threadt){
returnt. threadLocals;


```
第 1 章多线程原理与实战 | 97
```
}
//线程 t 创建一个 ThreadLocalMap 成员
//并为新的 Map 成员设置第一个“Key-Value 对”，Key 为当前的 ThreadLocal 实例
voidcreateMap (Threadt, TfirstValue){
t.threadLocals=newThreadLocalMap (this, firstValue);
}
通过以上的源码可以看出 set (Tvalue) 方法的执行流程，大致如下：
1 ）获得当前线程，然后获得当前线程的 ThreadLocalMap 成员，暂存于 map 变量。
2 ）如果 map 不为空，就将 Value 设置到 map 中，当前的 ThreadLocal 作为 key。
3 ）如果 map 为空，为该线程创建 map，然后设置第一个“Key-Value 对”，Key 为当前的 ThreadLocal
实例，Value 为 set 方法的参数 value 值。

2 .get () 方法
get () 方法用于获取“线程本地变量”在当前线程的 ThreadLocalMap 中对应的值，相当于获取线
程本地值，其核心源码如下：
publicTget (){
//获得当前线程对象
Threadt=Thread.currentThread ();
//获得线程对象的 ThreadLocalMap 内部成员
ThreadLocalMapmap=getMap (t);
//如果当前线程的内部 map 成员存在
if (map!=null){
//以当前 ThreadLocal 为 Key，尝试获得条目
ThreadLocalMap. Entrye=map.getEntry (this);
//条目存在
if (e!=null){
Tresult=(T)e.value;
returnresult;
}
}
//如果当前线程对应 map 不存在
//或者 map 存在，但是当前 ThreadLocal 实例没有对应的“Key-Value 对”，返回初始值
returnsetInitialValue ();
}
//设置 ThreadLocal 关联的初始值并返回
privateTsetInitialValue (){
//调用初始化钩子函数，获取初始值
Tvalue=initialValue ();
Threadt=Thread.currentThread ();
ThreadLocalMapmap=getMap (t);
if (map!=null)
map.set (this, value);
else
createMap (t, value);
returnvalue;
}
通过以上的源码可以看出 Tget () 方法的执行流程，大致如下：
1 ）先尝试获得当前线程，然后获得当前线程的 ThreadLocalMap 成员，暂存于 map 变量。
2 ）如果获得的 map 不为空，那么以当前 ThreadLocal 实例为 Key 尝试获得 map 中的 Entry（条目）。


98 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

3 ）如果 Entry 条目不为空，就返回 Entry 中的 Value。
4 ）如果 Entry 为空，就通过调用 initialValue 初始化钩子函数获取“ThreadLocal”初始值，并设
置在 map 中。如果 map 不存在，还会给当前线程创建新 ThreadLocalMap 成员，并绑定第一个
“Key-Value 对”。

3 .remove () 方法
remove () 方法用于在当前线程的 ThreadLocalMap 中移除“线程本地变量”所对应的值，其核心
源码如下：
publicvoidremove (){
ThreadLocalMapm=getMap (Thread.currentThread ());
if (m!=null)
m.remove (this);
}
4 .initialValue () 方法
当“线程本地变量”在当前线程的 ThreadLocalMap 中尚未绑定值时，initialValue () 方法用于获
取初始值。其源码如下：
protectedTinitialValue (){
returnnull;
}
如果没有调用 set () 而直接调用 get ()，就会调用此方法，但是该方法只会被调用一次。默认情况
下，initialValue () 方法返回 null，如果不想返回 null，可以继承 ThreadLocal 以覆盖此方法。
真的需要继承 ThreadLocal 去重写 initialValue () 方法吗？其实没有必要。JDK 已经为大家定义了
一个 ThreadLocal 的内部 SuppliedThreadLocal 静态子类，并且提供了 ThreadLocal.withInitial (...) 静态工
厂方法，方便大家在定义 ThreadLocal 实例时设置初始值回调函数。使用工厂方法构造 ThreadLocal
实例的代码如下：
ThreadLocal<Foo>LOCAL_FOO=ThreadLocal.withInitial (()->newFoo ());
JDK 定义的 ThreadLocal.withInitial (...) 静态工厂方法及其内部子类 SuppliedThreadLocal 的源码
如下：
//ThreadLocal 工厂方法可以设置本地变量初始值钩子函数
publicstatic<S>ThreadLocal<S>withInitial (Supplier<?extendsS>supplier){
returnnewSuppliedThreadLocal<>(supplier);
}
//内部静态子类
//继承了 ThreadLocal，重写了 initialValue () 方法，返回钩子函数的值作为初始值
staticfinalclassSuppliedThreadLocal<T>extendsThreadLocal<T>{
//保存钩子函数
privatefinalSupplier<?extendsT>supplier;
//传入钩子函数
SuppliedThreadLocal (Supplier<?extendsT>supplier){
this. supplier=Objects.requireNonNull (supplier);
}
@Override
protectedTinitialValue (){
returnsupplier.get (); //返回钩子函数的值作为初始值
}
}


```
第 1 章多线程原理与实战 | 99
```
###### 1. 8. 7 ThreadLocalMap 源码分析

ThreadLocal 的操作都是基于 ThreadLocalMap 展开的，而 ThreadLocalMap 是 ThreadLocal 的一个
静态内部类，其实现了一套简单的 Map 结构（比 HashMap 简单）。

1 .ThreadLocalMap 的主要成员变量
ThreadLocalMap 的成员变量与 HashMap 的成员变量非常类似，其内部的主要成员如下所示：
publicclassThreadLocal<T>{
//省略其他
staticclassThreadLocalMap{
//Map 的条目数组，作为哈希表使用
privateEntry[]table;
//Map 的条目初始容量 16
privatestaticfinalintINITIAL_CAPACITY= 16 ;
//Map 的条目数量
privateintsize= 0 ;
//扩容因子
privateintthreshold;
//Map 的条目类型，一个静态的内部类
//Entry 继承子 WeakReference, Key 为 ThreadLocal 实例
staticclassEntryextendsWeakReference<ThreadLocal<?>>{
Objectvalue;//条目的值
Entry (ThreadLocal<?>k, Objectv){
super (k);
value=v;
}
}
//省略其他
}
ThreadLocal 源码中 get ()、set ()、remove () 方法都涉及 ThreadLocalMap 的方法调用，主要调用了
ThreadLocalMap 的如下几个方法：

1 ）set (ThreadLocal<?>key, Objectvalue)：向 Map 实例设置“Key-Value 对”。
2 ）getEntry (ThreadLocal)：从 Map 实例获取 Key（ThreadLocal 实例）所属的 Entry。
3 ）remove (ThreadLocal)：根据 Key（ThreadLocal 实例）从 Map 实例移除所属的 Entry。
作为参考，这里只对 ThreadLocalMap 的 set (ThreadLocal<?>key, Objectvalue) 方法的代码以注
释的形式做一个简单的分析，具体如下：
privatevoidset (ThreadLocal<?>key, Objectvalue){
Entry[]tab=table;
intlen=tab. length;
//根据 key 的 HashCode，找到 key 在数组上的槽点 i
inti=key. threadLocalHashCode&(len- 1 );
//从槽点 i 开始向后循环搜索，找空余槽点（空余位置）或者找现有槽点
//如果没有现有槽点，则必定有空余槽点，因为没有空间时会扩容
for (Entrye=tab[i]; e!=null; e=tab[i=nextIndex (i, len)]){
ThreadLocal<?>k=e.get ();
//找到现有槽点：Key 值为 ThreadLocal 实例
if (k==key){
e.value=value;
return;


100 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

}
//找到异常槽点：槽点被 GC 掉，重设 Key 值和 Value 值
if (k==null){
replaceStaleEntry (key, value, i);
return;
}
}
//没有找到现有的槽点，增加新的 Entry
tab[i]=newEntry (key, value);
//设置 ThreadLocal 数量
intsz=++size;
//清理 Key 为 null 的无效 Entry
//没有可清理的 Entry，并且现有条目数量大于扩容因子值，进行扩容
if (! cleanSomeSlots (i, sz)&&sz>=threshold)
rehash ();
}
2 .Entry 的 Key 需要使用弱引用
Entry 用于保存 ThreadLocalMap 的“Key-Value”条目，但是 Entry 使用了对 Threadlocal 实例进行
包装之后的弱引用（WeakReference）作为 Key，其代码如下：
//Entry 继承了 WeakReference，并使用 WeakReference 对 Key 进行包装
staticclassEntryextendsWeakReference<ThreadLocal<?>>{
Objectvalue; //值
Entry (ThreadLocal<?>k, Objectv){
super (k); //使用 WeakReference 对 Key 值进行包装
value=v;
}
}
为什么 Entry 需要使用弱引用对 Key 进行包装，而不是直接使用 Threadlocal 实例作为 Key 呢？这
个问题有点儿复杂，要分析清楚还有点难度。这里从一个简单的例子入手，假设有一个方法 funcA ()
创建了一个“线程本地变量”，具体如下：
publicvoidfuncA ()
{
//创建一个线程本地变量
ThreadLocallocal=newThreadLocal<Integer>();
//设置值
local.set ( 100 );
//获取值
local.get ();
//函数末尾
}
当线程 tn 执行 funcA () 方法到其末尾时，线程 tn 相关的 JVM 栈内存以及内部 ThreadLocalMap 成员
的结构大致如图 1 - 22 所示。
线程 tn 调用 funcA () 方法新建了一个 ThreadLocal 实例，使用 local 局部变量指向这个实例，并且
此 local 是强引用；在调用 local.set ( 100 ) 之后，线程 tn 的 ThreadLocalMap 成员内部会新建一个 Entry 实
例，其 Key 以弱引用包装的方式指向 ThreadLocal 实例。
当线程 tn 执行完 funcA () 方法后，funcA () 的方法栈帧将被销毁，强引用 local 的值也就没有了，
但此时线程的 ThreadLocalMap 中对应的 Entry 的 Key 引用还指向了 ThreadLocal 实例。如果 Entry 的
Key 引用是强引用，就会导致 Key 引用指向的 ThreadLocal 实例及其 Value 值都不能被 GC 回收，这将
造成严重的内存泄漏，具体如图 1 - 23 所示。


```
第 1 章多线程原理与实战 | 101
```
```
图 1 - 22 当线程 tn 执行 funcA () 方法末尾时内存结构
```
图 1 - 23 Entry 的 Key 为强引用将导致 ThreadLocal 实例不能回收
什么是弱引用呢？仅有弱引用（WeakReference）指向的对象只能生存到下一次垃圾回收之前。
换句话说，当 GC 发生时，无论内存够不够，仅有弱引用所指向的对象都会被回收。而拥有强引用
指向的对象则不会被直接回收。

```
什么叫作内存泄漏？不再用到的内存没有及时释放（归还给系统），就叫作内
存泄漏。对于持续运行的服务进程必须及时释放内存，否则内存占用量越来越高，轻则影响
系统性能，重则导致进程崩溃。
```
由于 ThreadLocalMap 中 Entry 的 Key 使用了弱引用，在下次 GC 发生时，就可以使那些没有被其
他强引用指向、仅被 Entry 的 Key 所指向的 ThreadLocal 实例能被顺利回收。并且，在 Entry 的 Key 引用
被回收之后，其 Entry 的 Key 值变为 null。后续当 ThreadLocal 的 get ()、set () 或 remove () 被调用时，
ThreadLocalMap 的内部代码会清除这些 Key 为 null 的 Entry，从而完成相应的内存释放。
总结一下，使用 ThreadLocal 会发生内存泄漏的前提条件如下：
1 ）线程长时间运行而没有被销毁。线程池中的 Thread 实例很容易满足此条件。
2 ）ThreadLocal 引用被设置为 null，且后续在同一 Thread 实例的执行期间，没有发生对其他
ThreadLocal 实例的 get ()、set () 或 remove () 操作。只要存在一个针对任何 ThreadLocal 实例的 get ()、set ()

```
funcA () 的栈帧
```

102 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

或 remove () 操作，就会触发 Thread 实例拥有的 ThreadLocalMap 的 Key 为 null 的 Entry 清理工作，释放掉
ThreadLocal 弱引用为 null 的 Entry。

综合以上两点可以看出：使用 ThreadLocal 出现内存泄漏还是比较容易的。但是一般公司对如何
使用 ThreadLocal 都有编程规范要求，只要大家按照规范编写程序，也没有那么容易发生内存泄漏。
3 .编程规范推荐使用 staticfinal 修饰 ThreadLocal 对象
编程规范有云：ThreadLocal 实例作为 ThreadLocalMap 的 Key，针对一个线程内所有操作是共享
的，所以建议设置 static 修饰符，以便被所有的对象共享。由于静态变量会在类第一次被使用时装
载，只会分配一次存储空间，此类的所有实例都会共享这个存储空间，所以使用 static 修饰
ThreadLocal 就会节约内存空间。另外，为了确保 ThreadLocal 实例的唯一性，除了使用 static 修饰之
外，还会使用 final 进行加强修饰，以防止其在使用过程中发生动态变更。参考的实例如下：
//推荐使用 **staticfinal** 线程本地变量
**privatestaticfinal** ThreadLocal<Foo>LOCAL_FOO=newThreadLocal<Foo>();

```
以上代码中，为什么 ThreadLocal 实例除了添加 staticfinal 修饰之后，还经常加上
了 private 修饰呢？主要目的是缩小使用的范围，尽可能不让他人引用。
```
凡事都有两面性，使用 static、final 修饰 ThreadLocal 实例也会带来副作用，使得 Thread 实例内
部的 ThreadLocalMap 中 Entry 的 Key 在 Thread 实例的生命期内将始终保持为非 null，从而导致 Key 所在
的 Entry 不会被自动清空，这就会让 Entry 中的 Value 指向的对象一直存在强引用，于是 Value 指向的
对象在线程生命期内不会被释放，最终导致内存泄漏。所以，在使用完 static、final 修饰 ThreadLocal
实例，使用完后必须使用 remove () 进行手动释放。
如果使用线程池，可以定制线程池的 afterExecute () 方法（任务执行完成之后的钩子方法），在
任务执行完成之后，调用 ThreadLocal 实例的 remove () 方法对其手动释放，从而使得其线程内部的
Entry 得到释放，参考的代码如下：
//线程本地变量, 用于记录线程异步任务的开始执行时间
privatestaticfinalThreadLocal<Long>START_TIME=newThreadLocal<>();
ExecutorServicepool=newThreadPoolExecutor ( 2 ,
4 , 60 ,
TimeUnit. SECONDS, newLinkedBlockingQueue<>( 2 )){
//省略其他
//异步任务执行完成之后的钩子方法
@Override
protectedvoidafterExecute (Runnabletarget, Throwablet)
{
//省略其他
//清空 ThreadLocal 实例的本地值
START_TIME. **remove** ();
}
};

###### 1. 8. 8 ThreadLocal 综合使用案例

由于 ThreadLocal 使用不当会导致严重的内存泄漏问题，所以为了更好地避免内存泄漏问题的
发生，我们使用 ThreadLocal 时遵守以下两个原则：


```
第 1 章多线程原理与实战 | 103
```
1 ）尽量使用 privatestaticfinal 修饰 ThreadLocal 实例。使用 private 与 final 修饰符主要是尽可能
不让他人修改、变更 ThreadLocal 变量的引用，使用 static 修饰符主要为了确保 ThreadLocal 实例的全
局唯一。
2 ）ThreadLocal 使用完成之后务必调用 remove () 方法。这是简单、有效地避免 ThreadLocal 引发
内存泄漏的方法。

下面用一个综合案例演示一下 ThreadLocal 的使用。此案例的功能为：记录执行过程中所调用
的函数所需的执行时间（即执行耗时）。比如在实际 Web 开发过程中，一次客户端请求往往会涉及
DB、缓存、RPC 等多个调用，一旦出现性能问题，就需要记录一下各个点的耗时，从而判断性能
的瓶颈所在。
下面的代码定义了三个方法 serviceMethod ()、daoMethod () 和 rpcMethod ()，用于模拟实际的 DB、
RPC 等耗时调用，具体的代码如下：
packagecom. crazymakercircle. mutithread. basic. threadlocal;
//省略 import
publicclassThreadLocalTest 2
{
/**
*模拟业务方法
*/
publicvoidserviceMethod ()
{
//睡眠 500 毫秒，模拟执行所需的时间（耗时）
sleepMilliSeconds ( 500 );
//记录从开始调用到当前这个点（"point- 1 "）的耗时
SpeedLog.logPoint ("point- 1 service");
//调用 DAO 方法：模拟 dao 业务方法
daoMethod ();
//调用 RPC 方法：模拟 RPC 远程业务方法
rpcMethod ();
}
/**
*模拟 dao 业务方法
*/
publicvoiddaoMethod ()
{
//睡眠 400 毫秒，模拟执行所需的时间
sleepMilliSeconds ( 400 );
//记录上一个点（"point- 1 "）到这里（"point- 2 "）的耗时
SpeedLog.logPoint ("point- 2 dao");
}
/**
*模拟 RPC 远程业务方法
*/
publicvoidrpcMethod ()
{
//睡眠 400 毫秒，模拟执行所需的时间
sleepMilliSeconds ( 600 );
//记录上一个点（"point- 2 "）这里（"point- 3 "）的耗时
SpeedLog.logPoint ("point- 3 rpc");
}


104 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

//省略不相关代码
}
为了能灵活地记录各个执行埋点的耗时，这里定义了一个 SpeedLog 类。该类含有一个 ThreadLocal
类型的、初始值为一个 Map<String,Long>实例的“线程本地变量”，名为 TIME_RECORD_LOCAL。
如果要记录某个函数的调用耗时，就需要进行耗时埋点，具体的方法为 logPoint (Stringpoint)。
该方法会操作 TIME_RECORD_LOCAL 本地变量，在其中增加一次耗时记录：Key 为耗时埋点的名称，
Value（值）为当前时间和上一次记录时间的差值，也就是上一次埋点到本次埋点之间的调用耗时。
SpeedLog 类的代码大致如下：
packagecom. crazymakercircle. mutithread. basic. threadlocal;
//省略 import
publicclassSpeedLog
{
/**
*记录调用耗时的本地 Map 变量
*/
privatestaticfinalThreadLocal<Map<String,Long>>
TIME_RECORD_LOCAL=ThreadLocal.withInitial (SpeedLog::initialStartTime);
/**
*记录调用耗时的本地 Map 变量的初始化方法
*/
publicstaticMap<String,Long>initialStartTime ()
{
Map<String,Long>map=newHashMap<>();
map.put ("start",System.currentTimeMillis ());
map.put ("last",System.currentTimeMillis ());
returnmap;
}
/**
*开始耗时记录
*/
publicstaticfinalvoidbeginSpeedLog ()
{
Print.fo ("开始耗时记录");
TIME_RECORD_LOCAL.get ();
}
/**
*结束耗时记录
*/
publicstaticfinalvoidendSpeedLog ()
{
TIME_RECORD_LOCAL.remove ();
Print.fo ("结束耗时记录");
}
/**
*耗时埋点
*/
publicstaticfinalvoidlogPoint (Stringpoint)
{
//获取上一次的时间
Longlast=TIME_RECORD_LOCAL.get (). get ("last");
//计算上一次埋点到当前埋点的耗时
Longcost=System.currentTimeMillis ()-last;
//保存上一次埋点到当前埋点的耗时


```
第 1 章多线程原理与实战 | 105
```
TIME_RECORD_LOCAL.get (). put (point+"cost: ", cost);
//保存当前时间，供下一次埋点使用
TIME_RECORD_LOCAL.get (). put ("last",System.currentTimeMillis ());
}
//省略不相关代码
}
下面是一个测试用例，演示一下在 serviceMethod ()、daoMethod ()、rpcMethod () 三个模拟方法
的调用过程中，它们的耗时记录和输出，具体的代码如下：
packagecom. crazymakercircle. mutithread. basic. threadlocal;
//省略 import
publicclassThreadLocalTest 2
{
/**
*测试用例：线程方法调用的耗时
*/
@org. junit. Test
publicvoidtestSpeedLog () throwsInterruptedException
{
Runnablerunnable=()->
{
//开始耗时记录，保存当前时间
SpeedLog.beginSpeedLog ();
//调用模拟业务方法
serviceMethod ();
//打印耗时
SpeedLog.printCost ();
//结束耗时记录
SpeedLog.endSpeedLog ();
};
newThread (runnable). start ();
sleepSeconds ( 10 );//等待 10 秒看结果
}
//省略不相关代码
}
运行以上用例，三个模拟方法 serviceMethod ()、daoMethod ()、rpcMethod () 的耗时输出如下：
[SpeedLog. beginSpeedLog]：开始耗时记录
[SpeedLog. printCost]：start=> 1600347227334
[SpeedLog. printCost]：point- 1 servicecost:=> 500
[SpeedLog. printCost]：point- 2 daocost:=> 401
[SpeedLog. printCost]：point- 3 rpccost:=> 600
[SpeedLog. printCost]：last=> 1600347228835
[SpeedLog. endSpeedLog]：结束耗时记录
以上案例中，将 ThreadLocal 变量声明成为 privatestaticfinal 的形式，使得外部不能直接访问，
外部能访问的是将 ThreadLocal 变量封装之后的接口函数，如 beginSpeedLog ()、logPoint (Stringpoint)、
endSpeedLog () 等。
总之，使用 ThreadLocal 能实现每个线程都有一份变量的本地值，其原因是由于每个线程都有
自己独立的 ThreadLocalMap 空间，本质上属于以空间换时间的设计思路，该设计思路属于了另一种
意义的“无锁编程”。


# 第 2 章 Java 内置锁的核心原理

Java 内置锁是一个互斥锁，这就是意味着最多只有一个线程能够获得该锁，当线程 B 尝试去获
得线程 A 持有的内置锁时，线程 B 必须等待或者阻塞，直到线程 A 释放这个锁，如果线程 A 不释放这
个锁，那么线程 B 将永远等待下去。
Java 中每个对象都可以用作锁，这些锁被称为内置锁。线程进入同步代码块或方法时会自动获
得该锁，在退出同步代码块或方法时会释放该锁。获得内置锁的唯一途径就是进入被这个锁保护的
同步代码块或方法。
本章从线程安全问题开始讲起，为大家揭秘 Java 内置锁的核心原理。

#### 2. 1 线程安全问题

什么是线程安全呢？当多个线程并发访问某个 Java 对象（Object）时，无论系统如何调度这些
线程，也不论这些线程如何交替操作，这个对象都能表现出一致的、正确的行为，那么对这个对象
的操作是线程安全的。如果这个对象表现出不一致的、错误的行为，那么对这个对象的操作不是线
程安全的，发生了线程的安全问题。

###### 2. 1. 1 自增运算不是线程安全的

粗看上去，感觉这是一个不可思议的事情：对一个整数进行自增运算（++），怎么可能不是
线程安全的呢？这可只有一个完整的操作，看上去是那么的不可分割。
在第 1 章开头讲到第二个面试故事中，临行时笔者给候选人 Y 君建议，回去做一个线程安全的
自增小实验：使用 10 个线程，对一个共享的变量，每个线程自增 100 万次，看看最终的结果是不是
1000 万。完成这个小实验，就知道“++”运算是否是线程安全的了。

1 .线程安全小实验
为了讲清楚问题，这里先提供一下以上实验的代码： 10 个线程并行运行，对一个共享数据进
行自增运算，每个线程自增运算 1000 次。具体的代码如下：
packagecom. crazymakercircle. plus;
//省略 import
publicclassNotSafePlus
{
private Integeramount= 0 ;
//自增
publicvoidselfPlus ()


```
第 2 章 Java 内置锁的核心原理 | 107
```
{
amount++;
}
publicIntegergetAmount ()
{
returnamount;
}
}
以上的测试不安全的累加器 NotSafePlus 的测试用例，大致如下：
packagecom. crazymakercircle. plus;
//省略 import
importstaticcom. crazymakercircle. util. ThreadUtil. sleepMilliSeconds;
publicclassPlusTest
{
finalintMAX_TREAD= 10 ;
finalintMAX_TURN= 1000 ;
/**
*测试用例：测试不安全的累加器
*/
@org. junit. Test
publicvoidtestNotSafePlus () throwsInterruptedException
{
//倒数闩，需要倒数 MAX_TREAD 次
CountDownLatchlatch=newCountDownLatch (MAX_TREAD);
NotSafePluscounter=newNotSafePlus ();
Runnablerunnable=()->
{
for (inti= 0 ;i<MAX_TURN; i++)
{
counter.selfPlus ();
}
latch.countDown (); //倒数闩减少一次
};
for (inti= 0 ;i<MAX_TREAD; i++)
{
newThread (runnable). start ();
}
latch.await (); //等待倒数闩的次数减少到 0 ，所有的线程执行完成
Print.tcfo ("理论结果："+MAX_TURN*MAX_TREAD);
Print.tcfo ("实际结果："+counter.getAmount ());
Print.tcfo ("差距是："+
(MAX_TURN*MAX_TREAD-counter.getAmount ()));
}
}
运行程序，输出的结果是：
[main|PlusTest. testNotSafePlus]：理论结果： 10000
[main|PlusTest. testNotSafePlus]：实际结果： 7006
[main|PlusTest. testNotSafePlus]：差距是： 2994
通过结果可以看出：总计自增 10000 次，结果少了 2994 次，差距在 30 %左右。当然，这只是一
次结果，每一次运行，差距都是不同的，大家可以动手运行体验一下。总之，从结果可以看出，对
NotSafePlus 的 amount 成员的“++”运算在多线程并发执行场景下出现了不一致的、错误的行为，
自增运算符“++”不是线程安全的。
以上代码中，为了获得 10 个线程的结果，主线程通过 CountDownLatch（倒数闩）工具类进行
了并发线程的等待。


108 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
CountDownLatch（倒数闩）是一个非常实用的等待多线程并发的工具类。调用
线程可以在倒数闩上进行等待，一直等待倒数闩的次数减少到 0 ，才继续往下执行。每一个
被等线程执行完成之后进行一次倒数。所有的被等线程执行完成之后，倒数闩的次数减少到
0 ，调用线程可以往下执行，从而达到并发等待的效果。
```
在使用 CountDownLatch 时，先创建了一个 CountDownLatch 实例，设置其倒数的总数，例子中
值为 10 ，表示等待 10 个线程执行完成。主线程通过调用 latch.await () 在倒数闩实例上执行等待，等到
latch 实例的倒数到 0 时才能继续执行。

2 .原因分析：自增运算不是线程安全的
为什么自增运算不是线程安全的呢？实际上，一个自增运算符是一个复合操作，至少包括三
个 JVM 指令：“内存取值”“寄存器增加 1 ”“存值到内存”。这三个指令在 JVM 内部是独立进行
的，中间完全可能会出现多个线程并发进行。
比如在 amount= 100 时，假设有三个线程同一时间读取 amount 值，读到的都是 100 ，增加 1 后结
果为 101 ，三个线程都将结果存入到 amount 的内存，amount 的结果是 101 ，而不是 103 。
“内存取值”“寄存器增加 1 ”“存值到内存”这三个 JVM 指令是不可以再分的，它们都具备原子
性，是线程安全的，也叫原子操作。但是，两个或者两个以上的原子操作合在一起进行操作就不再具
备原子性。比如先读后写，就有可能在读之后，其实这个变量被修改了，就出现了数据不一致的情况。

###### 2. 1. 2 临界区资源与临界区代码段

Java 工程师在进行代码开发时，常常倾向于认为代码会以线性的、串行的方式执行，容易忽视
多个线程并行执行，从而导致意想不到的结果。
前面的线程安全小实验展示了在多个线程操作相同资源（如变量、数组或者对象）时就可能
出现线程安全问题。一般来说，只在多个线程对这个资源进行写操作的时候才会出现问题，如果是
简单的读操作，不改变资源的话，显然是不会出现问题的。
临界区资源表示一种可以被多个线程使用的公共资源或共享数据，但是每一次只能有一个线
程使用它。一旦临界区资源被占用，想使用该资源的其他线程则必须等待。
在并发情况下，临界区资源是受保护的对象。临界区代码段（CriticalSection）是每个线程中
访问临界资源的那段代码，多个线程必须互斥地对临界区资源进行访问。线程进入临界区代码段之
前，必须在进入区申请资源，申请成功之后进行临界区代码段，执行完成之后释放资源。临界区代
码段的进入和退出具体如图 2 - 1 所示。

```
图 2 - 1 临界区代码段的进入和退出
竞态条件（RaceConditions）可能是由于在访问临界区代码段时没有互斥地访问而导致的特殊
```

```
第 2 章 Java 内置锁的核心原理 | 109
```
情况。如果多个线程在临界区代码段的并发执行结果可能因为代码的执行顺序不同而出现不同的结
果，我们就说这时在临界区出现了竞态条件问题。
前面的线程安全小实验的代码中，amount 为临界区资源，selfPlus () 可以理解为临界区代码段，
具体如下：
publicclassNotSafePlus
{
private Integeramount= 0 ;//临界区资源
//临界区代码段
publicvoidselfPlus ()
{
amount++;
}
}
当多个线程访问临界区 selfPlus () 方法时，就会出现竞态条件的问题。更标准地说，当两个或多
个线程竞争同一个资源时，对资源的访问顺序就变得非常关键。
为了避免竞态条件的问题，我们必须保证临界区代码段操作必须具备排他性。这就意味着当
一个线程进入 CriticalSection 执行时，其他线程不能进入临界区代码段执行。
在 Java 中，我们可以使用 synchronized 关键字同步代码块，对临界区代码段进行排他性保护，
示意代码如下：
synchronized (syncObject){
//criticalsection
}
在 Java 中，使用 synchronized 关键字还可以使用 Lock 显式锁实例，或者使用原子变量（Atomic
Variables）对临界区代码段进行排他性保护。Lock 显式锁、原子变量将在后续文章中介绍，接下来
介绍 synchronized 关键字。

#### 2. 2 synchronized 关键字

在 Java 中，线程同步使用最多的方法是使用 synchronized 关键字。每个 Java 对象都隐含有一把
锁，这里称为 Java 内置锁（或者对象锁、隐式锁）。使用 synchronized（syncObject）调用相当于获
取 syncObject 的内置锁，所以可以使用内置锁对临界区代码段进行排他性保护。


110 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

###### 2. 2. 1 synchronized 同步方法

synchronized 关键字是 Java 的保留字，当使用 synchronized 关键字修饰一个方法的时候，该方法
被声明为同步方法，具体的例子如下：
//同步方法
publicsynchronized voidselfPlus ()
{
amount++;
}
关键字 synchronized 的位置处于同步方法的返回类型之前。回到前面的线程安全小实验，现在
使用 synchronized 关键字对临界区代码段进行保护，代码如下：
packagecom. crazymakercircle. plus;
//省略 import
publicclassSafePlus
{
privateIntegeramount= 0 ;
//临界区代码段，使用 synchronized 进行保护
publicsynchronizedvoidselfPlus ()
{
amount++;
}
}
再次运行测试用例程序，累加 10000 次之后，最终的结果不再有偏差，与预期的结果（ 10000 ）
是相同的。
在方法声明中设置 synchronized 同步关键字，保证了其方法的代码执行流程是排他性的。任何
时间只允许一条线程进入同步方法（临界区代码段），如果其他线程都需要执行同一个方法，那么
只能等待和排队。

###### 2. 2. 2 synchronized 同步块

对于小的临界区，我们直接在方法声明中设置 synchronized 同步关键字，可以避免竞态条件
（RaceConditions）的问题。但是对于较大的临界区代码段，为了执行效率，最好将同步方法分为
小的临界区代码段。通过下面这个例子来具体讲述：
publicclassTwoPlus{
privateintsum 1 = 0 ;
privateintsum 2 = 0 ;
//同步方法
publicsynchronizedvoidplus (intval 1 ,intval 2 ){
//临界区代码段
this. sum 1 +=val 1 ;
this. sum 2 +=val 2 ;
}
}
在以上代码中，临界区代码段包含了对两个临界区资源的操作，这两个临界区资源分别为 sum 1 、
sum 2 。使用 synchronized 对 plus (intval 1 ,intval 2 ) 进行同步保护之后，进入临界区代码段的线程拥有


```
第 2 章 Java 内置锁的核心原理 | 111
```
sum 1 、sum 2 的操作权，并且是全部占用。一旦线程进入，当线程在操作 sum 1 而没有操作 sum 2 时，
也将 sum 2 的操作权白白占用，其他的线程由于没有进入临界区，只能看着 sum 2 被闲置而不能去执
行操作。
所以，将 synchronized 加在方法上，如果其保护的临界区代码段包含的临界区资源（要求是相互
独立的）多于一个，会造成临界区资源的闲置等待，这就会影响临界区代码段的吞吐量。为了提升
吞吐量，可以将 synchronized 关键字放在函数体内，同步一个代码块。synchronized 同步块的写法是：
synchronized (syncObject)//同步块而不是方法
{
//临界区代码段的代码块
}
在 synchronized 同步块后边的括号中是一个 syncObject 对象，代表着进入临界区代码段需要获取
syncObject 对象的监视锁，或者说将 syncObject 对象监视锁作为临界区代码段的同步锁。由于每一个
Java 对象都有一把监视锁（Monitor），因此任何 Java 对象都能作为 synchronized 的同步锁。
单个线程在 synchronized 同步块后边同步锁后，方能进入临界区代码段；反过来说，当一条线
程获得 syncObject 对象的监视锁后，其他线程就只能等待。
使用 synchronized 同步块对上面的 TwoPlus 类进行吞吐量的提升改造，具体的代码如下：
publicclassTwoPlus{
privateintsum 1 = 0 ;
privateintsum 2 = 0 ;
privateIntegersum 1 Lock=newInteger ( 1 ); //同步锁一
privateIntegersum 2 Lock=newInteger ( 2 ); //同步锁二
publicvoidplus (intval 1 ,intval 2 ){
//同步块 1
synchronized (this. sum 1 Lock){
this. sum 1 +=val 1 ;
}
//同步块 2
synchronized (this. sum 2 Lock){
this. sum 2 +=val 2 ;
}
}
}
改造之后，对两个独立的临界区资源 sum 1 、sum 2 的加法操作可以并发执行了，在某一个时刻，
不同的线程可以对 sum 1 、sum 2 的同时进行加法操作，提升了 plus () 方法的吞吐量。
在 TwoPlus 代码中，由于同步块 1 和同步块 2 保护着两个独立的临界区代码段，需要两把不同的
syncObject 对象锁，因此 TwoPlus 代码新加了 sum 1 Lock 和 sum 2 Lock 两个新的成员属性。这两个属性
没有参与业务处理，TwoPlus 仅仅利用了 sum 1 Lock 和 sum 2 Lock 的内置锁功能。
synchronized 方法和 synchronized 同步块有什么区别呢？总体来说，synchronized 方法是一种粗
粒度的并发控制，某一时刻只能有一个线程执行该 synchronized 方法；而 synchronized 代码块是一种
细粒度的并发控制，处于 synchronized 块之外的其他代码是可以被多条线程并发访问的。在一个方
法中，并不一定所有代码都是临界区代码段，可能只有几行代码会涉及线程同步问题。所以
synchronized 代码块比 synchronized 方法更加细粒度地控制了多条线程的同步访问。
synchronized 方法和 synchronized 代码块有什么联系呢？在 Java 的内部实现上，synchronized 方法
实际上等同于用一个 synchronized 代码块，这个代码块包含了同步方法中的所有语句，然后在


112 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

synchronized 代码块的括号中传入 this 关键字，使用 this 对象锁作为进入临界区的同步锁。
例如，下面两种实现多线程同步的 plus 方法版本编译成 JVM 内部字节码后结果是一样的。
版本一，使用 synchronized 代码块进行方法内部全部代码的保护，具体代码如下：
publicvoidplus (){
synchronized (this){ //对方法内部的全部代码进行保护
amount++;
}
}
版本二，synchronized 方法进行方法内部全部代码的保护，具体代码如下：
public synchronized voidplus (){
amount++;
}
综上所述，synchronized 方法的同步锁实质上使用了 this 对象锁，这样就免去了手工设置同步锁
的工作。而使用 synchronized 代码块需要手工设置同步锁。

###### 2. 2. 3 静态的同步方法

在 Java 世界里一切皆对象。Java 有两种对象：Object 实例对象和 Class 对象。每个类运行时的类
型信息用 Class 对象表示，它包含与类名称、继承关系、字段、方法有关的信息。JVM 将一个类加
载入自己的方法区内存时，会为其创建一个 Class 对象，对于一个类来说其 Class 对象也是唯一的。
Class 类没有公共的构造方法，Class 对象是在类加载的时候由 Java 虚拟机调用类加载器中的
defineClass 方法自动构造的，因此不能显式地声明一个 Class 对象。
所有的类都是在第一次使用时被动态加载到 JVM 中（懒加载），其各个类都是在必需时才加
载的。这一点与许多传统语言（如 C++）都不同，JVM 为动态加载机制配套了一个判定动态加载使
能的行为，使得类加载器首先检查这个类的 Class 对象是否已经被加载。如果尚未加载，类加载器
会根据类的全限定名查找. class 文件，验证后加载到 JVM 的方法区内存，并构造其对应的 Class 对象。
普通的 synchronized 实例方法，其同步锁是当前对象 this 的监视锁。如果某个 synchronized 方法
是 static（静态）方法，而不是普通的对象实例方法，其同步锁又是什么呢？
下面展示一个使用 synchronized 关键字修饰 static 静态方法的例子，具体如下：
packagecom. crazymakercircle. plus;
//省略 import
publicclassSafeStaticMethodPlus
{ //静态的临界区资源
privatestaticIntegeramount= 0 ;
//使用 synchronized 关键字修饰 static 静态方法
public **staticsynchronized** voidselfPlus ()
{
amount++;
}
}
大家都知道，静态方法属于 Class 实例而不是单个 Object 实例，在静态方法内部是不可以访问
Object 实例的 this 引用（也叫指针、句柄）的。所以，修饰 static 静态方法 synchronized 关键字就没有
办法获得 Object 实例的 this 对象的监视锁。


```
第 2 章 Java 内置锁的核心原理 | 113
```
实际上，使用 synchronized 关键字修饰 static 静态方法时，synchronized 的同步锁并不是普通
Object 对象的监视锁，而是类所对应的 Class 对象的监视锁。
为了以示区分，这里将 Object 对象的监视锁叫作对象锁，将 Class 对象的监视锁叫作类锁。当
synchronized 关键字修饰 static 静态方法时，同步锁为类锁；synchronized 关键字修饰普通的成员方法
（非静态方法）时，同步锁为对象锁。由于类的对象实例可以有很多，但是每个类只有一个 Class
实例，所以使用类锁作为 synchronized 的同步锁时会造成同一个 JVM 内的所有线程只能互斥进入临
界区段。
//对 JVM 内的所有线程同步
publicstaticsynchronizedvoidselfPlus ()
{
//临界区代码
}
所以，使用 synchronized 关键字修饰 static 静态方法时，一个 JVM 内所有争用线程共用一把锁，
是非常粗粒度的同步机制。如果使用对象锁，并且 JVM 内的争用线程所争用的是不同的对象锁，将
争用线程可以同步进入临界区，锁的粒度就变细；当然，如果 JVM 内的争用线程所争用的还是同一
把对象锁，也只能互斥进入临界区段，同样是非常粗粒度的同步机制。
通过 synchronized 关键字所抢占的同步锁，什么时候释放呢？一种场景是 synchronized 块（代码
块或者方法）正确执行完毕，监视锁自动释放；另一种场景是程序出现异常，非正常退出 synchronized
块，监视锁也会自动释放。所以，使用 synchronized 块时不必担心监视锁的释放问题。

#### 2. 3 生产者－消费者问题

生产者－消费者问题（Producer-ConsumerProblem）也称有限缓冲问题（Bounded-Buffer
Problem），是一个多线程同步问题的经典案例。
生产者－消费者问题描述了两类访问共享缓冲区的线程（即所谓的“生产者”和“消费者”）
在实际运行时会发生的问题。生产者线程的主要功能是生成一定量的数据放到缓冲区中，然后重复
此过程。消费者线程的主要功能是从缓冲区提取（或消耗）数据。
生产者―消费者问题关键是：
1 ）保证生产者不会在缓冲区满时加入数据，消费者也不会在缓冲区中为空时消耗数据。
2 ）保证在生产者加入过程、消费者消耗过程中，不会产生错误的数据和行为。
生产者－消费者问题不仅仅是一个多线程同步问题的经典案例，而且业内已经将解决该问题
的方案，抽象成为了一种设计模式——“生产者－消费者”模式。“生产者－消费者”模式是一个
经典的多线程设计模式，它为多线程间的协作提供了良好的解决方案。

###### 2. 3. 1 生产者－消费者模式

在生产者－消费者模式中，通常由两类线程，即生产者线程（若干个）和消费者线程（若干
个）。生产者线程向数据缓冲区（DataBuffer）加入数据，消费者线程则从 DataBuffer 消耗数据。生
产者和消费者、内存缓冲区之间的关系结构图如图 2 - 2 所示。


114 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

图 2 - 2 生产者－消费者模式结构图
生产者－消费者模式中，至少有以下关键点：
1 ）生产者与生产者之间、消费者与消费者之间，对数据缓冲区的操作是并发进行的。
2 ）数据缓冲区是有容量上限的。数据缓冲区满后，生产者不能再加入数据；DataBuffer 空时，
消费者不能再取出数据。
3 ）数据缓冲区是线程安全的。在并发操作数据区的过程中，不能出现数据不一致情况；或者
在多个线程并发更改共享数据后，不会造成出现脏数据的情况。
4 ）生产者或者消费者线程在空闲时，需要尽可能阻塞而不是执行无效的空操作，尽量节约 CPU
资源。

###### 2. 3. 2 一个线程不安全的实现版本

根据上面对生产者―消费者问题的描述先来实现一个非线程安全版本：包含了数据缓冲区
（DataBuffer）类、生产者（Producer）类、消费者（Consumer）类。

```
1 .不是线程安全的数据缓冲区类
首先定义其数据缓冲区类，具体的代码如下：
packagecom. crazymakercircle. producerandcomsumer. store;
//省略 import
//数据缓冲区（DataBuffer），不安全版本的类定义
classNotSafeDataBuffer<T>
{
publicstaticfinalintMAX_AMOUNT= 10 ;
privateList<T>dataList=newLinkedList<>();
//保存数量
privateAtomicIntegeramount=newAtomicInteger ( 0 );
//向数据区增加一个元素
publicvoidadd (Telement) throwsException
{
if (amount.get ()>MAX_AMOUNT)
{
Print.tcfo ("队列已经满了！");
return;
}
dataList.add (element);
Print.tcfo (element+"");
amount.incrementAndGet ();
//如果数据不一致，抛出异常
```

```
第 2 章 Java 内置锁的核心原理 | 115
```
if (amount.get ()!=dataList.size ())
{
thrownewException (amount+"!="+dataList.size ());
}
}
//从数据区取出一个元素
publicTfetch () throwsException
{
if (amount.get ()<= 0 )
{
Print.tcfo ("队列已经空了！");
returnnull;
}
Telement=dataList.remove ( 0 );
Print.tcfo (element+"");
amount.decrementAndGet ();
//如果数据不一致，抛出异常
if (amount.get ()!=dataList.size ())
{
thrownewException (amount+"!="+dataList.size ());
}
returnelement;
}
}
DataBuffer 类型的实例属性 dataList 保存具体数据元素，实例属性 amount 保存元素的数量。
DataBuffer 类型有两个实例方法，实例方法 add () 用于向数据区增加元素，实例方法 fetch () 用于从数
据区消耗元素。
在 add () 实例方法中，加入元素之前首先会对 amount 是否达到上限进行判断，如果数据区满了，
则不能加入数据；在 fetch () 实例方法中，消耗元素前首先会对 amount 是否大于零进行判断，如果数
据区空了，就不能取出数据。

2 .生产者、消费者的逻辑与动作解耦
生产者－消费者模式在本书中有多个不同版本的实现，这些版本的区别在于数据缓冲区
（DataBuffer）类以及相应的生产、消费动作（Action）不同，而生产者类、消费者类的执行逻辑
是相同的。“分离变与不变”是软件设计的一个基本原则。现在将生产者类、消费者类与具体的生
产、消费 Action 解耦，从而使得生产者类、消费者类的代码在后续可以复用。
生产者、消费者逻辑与对应 Action 解耦后的类结构图如图 2 - 3 所示。

```
图 2 - 3 解耦后的生产者－消费者模式结构
```

116 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

“分离变与不变”原则的背后蕴藏着丰富的软件工程思想，例如信息的分装与隐藏、系统的
模块化、使用分层构架等。其中，“变”是指易变的代码或者模块，“不变”就是指系统中不易变
化的部分。在解耦后的生产者－消费者模式结构中，不变的部分为生产者（Producer）类、消费者
（Consumer）类，后续可以直接复用，不需要修改代码；变化的部分为数据缓冲区（DataBuffer）
类以及相应的生产和消费动作，后续不同的生产者－消费者实现版本，只要编写各自的 DataBuffer
和 Action 实现即可。

3 .通用的 Producer 类实现
通用 Producer 类组合了一个 Callable 类型的成员 action 实例，代表了生产数据所需要执行的实际
动作，需要在构造 Producer 实例时传入。
通用生产者类的代码具体如下：
packagecom. crazymakercircle. petstore. actor;
//省略 import
/**
*通用的生产者
*/
publicclassProducerimplementsRunnable
{
//生产的时间间隔，生产一次等待的时间，默认为 200 毫秒
publicstaticfinalintPRODUCE_GAP= 200 ;
//总次数
staticfinalAtomicIntegerTURN=newAtomicInteger ( 0 );
//生产者对象编号
staticfinalAtomicIntegerPRODUCER_NO=newAtomicInteger ( 1 );
//生产者名称
Stringname=null;
//生产的动作
Callableaction=null;
intgap=PRODUCE_GAP;
publicProducer (Callableaction, intgap)
{
this. action=action;
this. gap=gap;
name="生产者-"+PRODUCER_NO.incrementAndGet ();
}
@Override
publicvoidrun ()
{
while (true)
{
try
{
//执行生产动作
Object out=action.call ();
//输出生产的结果
if (null!=out)
{
Print.tcfo ("第"+TURN.get ()+"轮生产："+out);
}


```
第 2 章 Java 内置锁的核心原理 | 117
```
//每一轮生产之后，稍微等待一下
sleepMilliSeconds (gap);
//增加生产轮次
TURN.incrementAndGet ();
}catch (Exceptione)
{
e.printStackTrace ();
}
}
}
}
4 .通用的 Consumer 类实现
通用 Consumer 类也组合了一个 Callable 类型的成员 action 实例，代表了消费者所需要执行的实
际消耗动作，需要在构造 Consumer 实例时传入。
通用 Consumer 类的代码具体如下：
packagecom. crazymakercircle. petstore. actor;
//省略 import
/**
*通用的消费者的定义
*/
publicclassConsumerimplementsRunnable
{
//消费的时间间隔，默认等待 100 毫秒
publicstaticfinalintCONSUME_GAP= 100 ;
//消费总次数
staticfinalAtomicIntegerTURN=newAtomicInteger ( 0 );
//消费者对象编号
staticfinalAtomicIntegerCONSUMER_NO=newAtomicInteger ( 1 );
//消费者名称
Stringname;
//消费的动作
Callableaction=null;
//消费一次等待的时间，默认为 100 毫秒
intgap=CONSUME_GAP;
publicConsumer (Callableaction, intgap)
{
this. action=action;
this. gap=gap;
name="消费者-"+CONSUMER_NO.incrementAndGet ();
}
@Override
publicvoidrun ()
{
while (true)
{
//增加消费次数
TURN.incrementAndGet ();
try
{
//执行消费动作
Objectout=action.call ();
if (null!=out)


118 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

{
Print.tcfo ("第"+TURN.get ()+"轮消费："+out);
}
//每一轮消费之后，稍微等待一下
sleepMilliSeconds (gap);
}catch (Exceptione)
{
e.printStackTrace ();
}
}
}
}
5 .数据缓冲区实例、生产动作、消费动作的定义
在完成了数据缓冲区类的定义、生产者类定义、消费者类的定义之后，接下来定义一下数据
缓冲区实例、生产动作和消费动作，具体的代码如下：
packagecom. crazymakercircle. producerandcomsumer. store;
//省略 import
publicclassNotSafePetStore
{
//数据缓冲区静态实例
privatestaticNotSafeDataBuffer<IGoods>notSafeDataBuffer=newNotSafeDataBuffer ();
//生产者执行的动作
staticCallable<IGoods>produceAction=()->
{
//首先生成一个随机的商品
IGoodsgoods=Goods.produceOne ();
//将商品加上共享数据区
try
{
notSafeDataBuffer.add (goods);
}catch (Exceptione)
{
e.printStackTrace ();
}
returngoods;
};
//消费者执行的动作
staticCallable<IGoods>consumerAction=()->
{
//从 PetStore 获取商品
IGoodsgoods=null;
try
{
goods=notSafeDataBuffer.fetch ();
}catch (Exceptione)
{
e.printStackTrace ();
}
returngoods;
};
//省略其他
}
这里的缓冲区中的具体数据类型使用一个自定义的 IGoods（商品）类，从而让整个生产者和
消费者演示程序模拟出一个宠物商店的功能。


```
第 2 章 Java 内置锁的核心原理 | 119
```
上面的实现版本 NotSafePetStore. java 中定义了三个重要的静态成员：
1 ）数据缓冲区静态实例。以元素类型为 IGoods，定义了一个不安全的 NotSafeDataBuffer 数据
缓冲区实例。
2 ）生产者 Action 静态实例。这是一个 Callable<IGoods>类型的匿名对象，其具体的动作为：首
先调用 Goods.produceOne () 产生一个随机的商品，然后通过调用 notSafeDataBuffer.add () 方法，将这
个随机商品加入数据缓冲区实例中，完成生产者的动作。
3 ）消费者 Action 静态实例。这也是一个 Callable<IGoods>类型的匿名对象，其具体的动作为：
调用 notSafeDataBuffer.fetch () 方法从数据区取出一个商品，完成消费者的动作。

6 .组装出一个生产者－消费者模式的简单实现版本
利用以上 NotSafePetStore 类所定义的三个静态成员，可以快速组装出一个简单的生产者－消费
者模式的 Java 实现版本，具体的代码如下：
packagecom. crazymakercircle. producerandcomsumer. store;
//省略 import
publicclassNotSafePetStore
{
publicstaticvoidmain (String[]args) throwsInterruptedException
{
System.setErr (System. out);
//同时并发执行的线程数
finalintTHREAD_TOTAL= 20 ;
//线程池，用于多线程模拟测试
ExecutorServicethreadPool=
Executors.newFixedThreadPool (THREAD_TOTAL);
for (inti= 0 ;i< 5 ;i++)
{
//生产者实例每生产一个商品，间隔 500 毫秒
threadPool.submit (newProducer (produceAction, 500 ));
//消费者实例每消费一个商品，间隔 1500 毫秒
threadPool.submit (newConsumer (consumerAction, 1500 ));
}
}
//省略其他
}
在 NotSafePetStore 的 main () 方法中，利用 for 循环向线程池提交了 5 个生产者线程和 5 个消费者实
例。每个生产者实例生产一个商品间隔 500 毫秒；消费者实例每消费一个商品间隔 1500 毫秒；也就
是说，生产的速度大于消费的速度。
启动 main () 方法，程序开始并发执行，稍微等待一段时间，问题就出来了，部分结果截取如下：
java. lang. Exception: 4 != 5
at.......DataBuffer.add (DataBuffer. java: 36 )
at....... NotSafePetStore. lambda$main$ 0 (NotSafePetStore. java: 38 )
at.......actor.ProducerTask.run (ProducerTask. java: 54 )
at....... Executors$RunnableAdapter.call (Executors. java: 511 )
at....... FutureTask. run$$$capture (FutureTask. java: 266 )
at.......FutureTask.run (FutureTask. java)
at.......ThreadPoolExecutor.runWorker (ThreadPoolExecutor. java: 1142 )
at....... ThreadPoolExecutor$Worker.run (ThreadPoolExecutor. java: 617 )
atjava.lang.Thread.run (Thread. java: 745 )
[pool- 1 - thread- 3 |DataBuffer. add]：商品{ID= 5 ,名称=宠物粮食- 1 ,价格= 51. 0 }


120 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

java. lang. Exception: 1 != 5
[pool- 1 - thread- 3 |ProducerTask. run]：第 7 轮生产：商品{ID= 5 ,名称=宠物粮食- 1 ,价格= 51. 0 }
[pool- 1 - thread- 9 |ProducerTask. run]：第 8 轮生产：商品{ID= 4 ,名称=宠物衣服- 2 ,价格= 75. 0 }
[pool- 1 - thread- 5 |ProducerTask. run]：第 9 轮生产：商品{ID= 1 ,名称=宠物衣服- 1 ,价格= 58. 0 }
[pool- 1 - thread- 7 |DataBuffer. add]：商品{ID= 6 ,名称=宠物粮食- 2 ,价格= 83. 0 }
从以上异常可以看出，在向数据缓冲区进行元素的增加或者提取时，多个线程在并发执行对
amount、dataList 两个成员操作时次序已经混乱，导致了数据不一致和线程安全问题。

###### 2. 3. 3 一个线程安全的实现版本

上一个版本生产者―消费者问题的实现中，由于线程安全问题，导致数据区的 amount 属性和
dataList 的长度在数据值上差别巨大。
解决线程安全问题很简单，为临界区代码加上 synchronized 关键字即可，主要修改的是涉及操
作两个临界区资源 amount 和 dataList 的代码，具体为 DataBuffer 的 add () 和 fetch () 方法。
创建一个安全的数据缓存区类 SafeDataBuffer 类，在其 add () 和 fetch () 两个实例方法的 public 声明
后面加上 synchronized 关键字即可。其他的代码行不动，与 NotSafeDataBuffer 的代码雷同。
SafeDataBuffer 类的代码如下：
packagecom. crazymakercircle. producerandcomsumer. store;
//省略 import
//共享数据区，类定义
classSafeDataBuffer<T>
{
publicstaticfinalintMAX_AMOUNT= 10 ;
privateBlockingQueue<T>dataList=newLinkedBlockingQueue<>();
//保存数量
privateAtomicIntegeramount=newAtomicInteger ( 0 );
/**
*向数据区增加一个元素
*/
publicsynchronizedvoidadd (Telement) throwsException
{
//省略其他相同的代码
dataList.add (element);
Print.tcfo (element+"");
amount.incrementAndGet ();
}
/**
*从数据区取出一个元素
*/
publicsynchronizedTfetch () throwsException
{
Telement=dataList.remove ( 0 );
//省略其他相同的代码
returnelement;
}
}
运行这个线程安全的生产者－消费者模式的实现版本，等待一段时间，惊喜出现了：之前出
现的 amount 数量和 dataList 的长度不相等的受检异常没有再抛出；之前出现的数据不一致情况以及
线程安全问题也被完全解除。


```
第 2 章 Java 内置锁的核心原理 | 121
```
虽然线程安全问题顺利解决，但是以上的解决方式使用了 SafeDataBuffer 的实例的对象锁作为
同步锁，这样一来，所有的生产、消费动作在执行过程中都需要抢占同一个同步锁，最终的结果是
所有的生产、消费动作都被串行化了。
高效率的生产者―消费者模式，生产、消费动作是肯定不能串行执行，而是需要并行执行的，
而且并行化程度越高越好。如何既保障没有线程安全问题，又能提高生产、消费动作的并行化程度，
这就是本书后续的实现版本需要解决的问题。
如果需要开发出并行化程度更高的生产者－消费者模式实现版本，需要彻底地掌握和理解对
象锁、synchronized 等机制的内部原理，这就需要从 Java 对象的头部结构等基础知识讲起。

#### 2. 4 Java 对象结构与内置锁

Java 内置锁的很多重要信息都存放在对象结构中。作为铺垫，在介绍 Java 内置锁之前，先为大
家介绍一下 Java 对象结构。

###### 2. 4. 1 Java 对象结构

不同的 JVM 的对象结构的实现不一样，这里以 HotSpotJVM 为例。
HotSpotJVM 并没有将 Java 实例对象直接一对一的映射到本地（native）的 C++对象，而是设计
了一个 oop-klass 模型。什么是 OOP 呢？实际上，OOP（OrdinaryObjectPointer，普通对象指针）是
指“对象－类”二者中的对象，表示对象的实例信息，从名字看是一个指针，实际并不仅仅是一个
内存地址，而是对内存地址的一个描述或者对内存中数据结构的一个描述。所以，JVM 中的对象的
类被定义为 oopDesc，具体参见下面的代码。
为了区别于 Java 语言中的 Object 对象，JVM 对象实例的 C++类型为 instanceOopDesc，其基类为
oopDesc，代码如下：
classoopDesc{
friendclassVMStructs;
private:
volatilemarkOop _mark; //对象头
union_metadata{
wideKlassOop _klass; //普通指针
narrowOop _compressed_klass; //压缩类指针
}_metadata;
private:
//省略不相干的代码
}
classinstanceOopDesc: publicoopDesc{ //普通对象类型
//省略不相干的代码
}
classarrayOopDesc: publicoopDesc{ //数组对象类型
//省略不相干的代码
}
每当在 Java 代码中创建一个对象时，JVM 会创建一个 instanceOopDesc 实例来表示这个对象，此
对象实例存放在堆区。类似地，每当在 Java 代码中创建一个数组时，JVM 会创建一个 arrayOopDesc
实例来表示。所以，一个普通 Java 对象的底层为一个 instanceOopDesc 实例。


122 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

在 oop-klass 模型中什么是 Klass 呢？实际上，Klass 指的是“对象－类”二者中的类。为了区别
于 Java 语言的 Class 类，JVM 中用 Klass 来描述类型，Klass 包含元数据和方法信息，用来描述语言层
的类型。
//用来描述语言层的类型
classKlass: publicMetadata{
//省略不相干的代码
//指向 java. lang. Class 的 instance，mirroringthisclass 即是这个类的影子类
OopHandle_java_mirror;
}
//在虚拟机层面描述一个 Java 类
classInstanceKlass: publicKlass{
//省略不相干的代码
}
HotSpot 为每一个已加载的 Java 类创建一个 InstanceKlass 对象，用来在 JVM 层表示 Java 元数据对
象。但是这个 InstanceKlass 对象就是给 JVM 内部用的，并不直接暴露给 Java 层。实际上，给 Java 层
用的类元数据对象为 java. lang. Class 类型的对象，或者说 java. lang. Class 类型的实例。
那么，一份类的元数据就出现了两个对象：一个 Java 层的 java. lang. Class 类型的实例；一个 JVM
层的 InstanceKlass 类型的实例。
根据前面的 Java 对象的底层介绍，一个普通 Java 对象的底层为一个 instanceOopDesc 实例。我们
知道，Java 层的 java. lang. Class 类型的实例也是一个普通对象，所以 Class 对象也就对应到一个
instanceOopDesc 实例。这个 instanceOopDesc 实例，被称为 JVM 层 InstanceKlass 实例的“Java 镜像”，
二者的关系如图 2 - 4 所示。

图 2 - 4 JVM 堆区和方法区
InstanceKlass 实例可以导航到其“Java 镜像”，具体的成员为_java_mirror（参考上面的代码），
可以导航到 instanceOopDesc 实例，也就是 java. lang. Class 类型的实例。
大致了解 oop-klass 模型后，接下来就比较好介绍 Java 对象（Object 实例）结构了，其实际上是
C++中 instanceOopDesc 的结构。
总体而言，Java 对象（Object 实例）结构包括三部分：对象头、对象体和对齐字节。具体如
图 2 - 5 所示。

1 .Java 对象（Object 实例）的三个部分
（ 1 ）对象头
对象头包括三个字段，第一个字段叫作 MarkWord（标记字），用于存储自身运行时的数据例
如 GC 标志位、哈希码、锁状态等信息。


```
第 2 章 Java 内置锁的核心原理 | 123
```
图 2 - 5 Java 对象（Object 实例）结构
第二个字段叫作 ClassPointer（类对象指针），用于存放此对象的元数据（InstanceKlass）的地
址。虚拟机通过此指针可以确定这个对象是哪个类的实例。
第三个字段叫作 ArrayLength（数组长度）。如果对象是一个 Java 数组，那么此字段必须有，用
于记录数组长度的数据；如果对象不是一个 Java 数组，那么此字段不存在，所以这是一个可选字段。

（ 2 ）对象体
对象体包含了对象的实例变量（成员变量），用于成员属性值，包括父类的成员属性值。这
部分内存按 4 字节对齐。

（ 3 ）对齐字节
对齐字节也叫作填充对齐，其作用是用来保证 Java 对象在所占内存字节数为 8 的倍数（ 8 Nbytes）。
HotSpotVM 的内存管理要求对象起始地址必须是 8 字节的整数倍。对象头本身是 8 的倍数，当对象
的实例变量数据不是 8 的倍数，需要填充数据来保证 8 字节的对齐。

2 .对象结构中的核心字段作用
接下来，对 Object 实例结构中几个重要的字段的作用做一下简要说明：
1 ）MarkWord（标记字）字段主要用来表示对象的线程锁状态，另外还可以用来配合 GC、存
放该对象的 hashCode。
2 ）ClassPointer（类对象指针）字段是一个指向方法区中类元数据信息的指针，意味着该对象
可随时知道自己是哪个 Class 的实例。
3 ）ArrayLength（数组长度）字段也占用 32 位（在 32 位 JVM 中）的字节，这是可选的，只有
当本对象是一个数组对象时才会有这个部分。
4 ）对象体用于保存对象属性值，是对象的主体部分，占用的内存空间大小取决于对象的属性
数量和类型。
5 ）对齐字节并不是必然存在的，也没有特别的含义，它仅仅起着占位符的作用。当对象实例
数据部分没有对齐（ 8 字节的整数倍）时，就需要通过对齐填充来补全。


124 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

3 .对象结构中的字段长度
MarkWord、ClassPointer、ArrayLength 等字段的长度都与 JVM 的位数有关。MarkWord 的长
度为 JVM 的一个 Word（字）大小，也就是说 32 位 JVM 的 MarkWord 为 32 位， 64 位 JVM 为 64 位。Class
Pointer（类对象指针）字段的长度也为 JVM 的一个 Word 大小，即 32 位的 JVM 为 32 位， 64 位的 JVM
为 64 位。
所以，在 32 位 JVM 虚拟机中，MarkWord 和 ClassPointer 这两部分都是 32 位的；在 64 位 JVM 虚
拟机中，MarkWord 和 ClassPointer 这两部分都是 64 位的。
对于对象指针而言，如果 JVM 中对象数量过多，使用 64 位的指针将浪费大量内存，通过简单
统计， 64 位的 JVM 将会比 32 位的 JVM 多耗费 50 %的内存。为了节约内存可以使用选项
+UseCompressedOops 开启指针压缩。选项 UseCompressedOops 中的 Oop 部分为 Ordinaryobjectpointer
（普通对象指针）的缩写。
如果开启 UseCompressedOops 选项，以下类型的指针将从 64 位压缩至 32 位：
 Class 对象的属性指针（即静态变量）。
 Object 对象的属性指针（即成员变量）。
 普通对象数组的元素指针。
当然，也不是所有的指针都会压缩，一些特殊类型的指针不会压缩，比如指向 PermGen（永久
代）的 Class 对象指针（JDK 8 中指向元空间的 Class 对象指针）、本地变量、堆栈元素、入参、返回
值和 NULL 指针等。

```
在堆内存小于 32 GB 的情况下， 64 位虚拟机的 UseCompressedOops 选项是默认开
启的，该选项表示开启 Oop 对象的指针压缩，会将原来 64 位的 Oop 对象指针压缩为 32 位。
```
手动开启 Oop 对象指针压缩的 Java 指令为：
java-XX:+UseCompressedOopsmainclass
手动关闭 Oop 对象指针压缩的 Java 指令为：
java-XX:-UseCompressedOopsmainclass
如果对象是一个数组，那么对象头还需要有额外的空间用于存储数组的长度（ArrayLength 字
段）。ArrayLength 字段的长度也随着 JVM 架构的不同而不同：在 32 位的 JVM 上，长度为 32 位；在
64 位 JVM 上，长度为 64 位。 64 位 JVM 如果开启了 OOP 对象的指针压缩，ArrayLength 字段的长度也
将由 64 位压缩至 32 位。

###### 2. 4. 2 MarkWord 的结构信息

Java 内置锁的涉及很多重要信息，这些都存放在对象结构中，并且存放于对象头的 MarkWord
字段中。MarkWord 的位长度为 JVM 的一个 Word 大小，也就是说 32 位 JVM 的 MarkWord 为 32 位，
64 位 JVM 的 MarkWord 为 64 位。MarkWord 的位长度不会受到 OOP 对象指针压缩选项的影响。
Java 内置锁的状态总共有 4 种，级别由低到高依次为：无锁、偏向锁、轻量级锁和重量级锁。
其实在 JDK 1. 6 之前，Java 内置锁还是一个重量级锁，是一个效率比较低下的锁，在 JDK 1. 6 之后，


```
第 2 章 Java 内置锁的核心原理 | 125
```
JVM 为了提高锁的获取与释放效率，对 synchronized 的实现进行了优化，引入了偏向锁、轻量级锁
的实现，从此以后 Java 内置锁的状态就有了 4 种（无锁、偏向锁、轻量级锁和重量级锁），并且 4 种
状态会随着竞争的情况逐渐升级，而且是不可逆的过程，即不可降级，也就是说只能进行锁升级（从
低级别到高级别）。

1 .不同锁状态下的 MarkWord 字段结构
MarkWord 字段的结构与 Java 内置锁的状态强相关。为了让 MarkWord 字段存储更多的信息，
JVM 将 MarkWord 的最低两个位设置为 Java 内置锁状态位，不同锁状态下的 32 位 MarkWord 结构，
如表 2 - 1 所示。

```
表 2 - 1 不同锁状态下 32 位 MarkWord 的结构信息
```
```
内置锁状态
```
```
25 位
4 位
```
```
1 位 2 位
23 位 2 位偏向 bia 标 se 志 d 位 lock 锁状态
无锁对象的 hashCode（ 25 位） 分代年龄 0 01
偏向锁线程 ID（ 23 位） epoch（ 2 位） 分代年龄 1 01
轻量级锁 ptr_to_lock_record 指向方法栈帧中的锁记录指针（ 30 位） 00
重量级锁 ptr_to_heavyweight_monitor 指向重量级锁监视器的指针（ 30 位） 10
GC 标记空（ 30 位） 11
64 位的 MarkWord 与 32 位的 MarkWord 结构相似，具体如表 2 - 2 所示。
表 2 - 2 不同锁状态下 64 位 MarkWord 的结构信息
```
内置锁状态 57 位 4 位
1 位 2 位
biased lock
无锁 unused（ 25 位） 对（象 31 的位 h）ashCode unused（ 1 位） 分代年龄 0 01
偏向锁线程 ID（ 54 位） epoch（ 2 位） unused（ 1 位） 分代年龄 1 01
轻量级锁 ptr_to_lock_record 指向方法栈帧中的锁记录指针（ 62 位） 00
重量级锁 ptr_to_heavyweight_monitor 指向重量级锁监视器的指针（ 62 位） 10
GC 标记空（ 62 位） 11
2. 64 位 MarkWord 的构成
由于目前主流的 JVM 都是 64 位，使用 64 位的 MarkWord，接下来对 64 位的 MarkWord 中各部分
的内容做具体介绍。

1 ）lock：锁状态标记位，占两个二进制位，由于希望用尽可能少的二进制位表示尽可能多的
信息，所以设置了 lock 标记。该标记的值不同，整个 MarkWord 表示的含义不同。
2 ）biased_lock：对象是否启用偏向锁标记，只占 1 个二进制位。为 1 时表示对象启用偏向锁，
为 0 时表示对象没有偏向锁。

lock 和 biased_lock 两个标记位组合在一起，共同表示 Object 实例处于什么样的锁状态。二者组
合的含义具体如表 2 - 3 所示。


126 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

表 2 - 3 lock 和 biased_lock 组合起来表示锁状态
状态 biased_lock lock
无锁 0 01
偏向锁 1 01
轻量级锁 0 00
重量级锁 0 10
GC 标记 0 11
3 ）age： 4 位的 Java 对象分代年龄。在 GC 中，如果对象在 Survivor 区复制一次，年龄增加 1 。当
对象达到设定的阈值时，将会晋升到老年代。默认情况下，并行 GC 的年龄阈值为 15 ，并发 GC 的年
龄阈值为 6 。由于 age 只有 4 位，因此最大值为 15 ，这就是-XX: MaxTenuringThreshold 选项最大值为 15
的原因。
4 ）identity_hashcode： 31 位的对象标识 HashCode（哈希码）采用延迟加载技术，当调用
Object.hashCode () 方法或者 System.identityHashCode () 方法计算对象的 HashCode 后，其结果将被写到
该对象头中。当对象被锁定时，该值会移动到 Monitor（监视器）中。
5 ）thread： 54 位的线程 ID 值为持有偏向锁的线程 ID。
6 ）epoch：偏向时间戳。
7 ）ptr_to_lock_record：占 62 位，在轻量级锁的状态下指向栈帧中锁记录的指针。
8 ）ptr_to_heavyweight_monitor：占 62 位，在重量级锁的状态下，指向对象监视器的指针。
32 位的 MarkWord 与 64 位 MarkWord 结构相似，这里不再赘述。

###### 2. 4. 3 使用 JOL 工具查看对象的布局

如何通过 Java 程序查看 Object 对象头的结构呢？OpenJDK 提供的 JOL（JavaObjectLayout）包
是一个非常好的工具，可以帮我们在运行时计算某个对象的大小。
JOL 是分析 JVM 中对象的结构布局的工具，该工具大量使用了 Unsafe、JVMTI 来解码内部布局
情况，其分析结果相对比较精准的。要使用 JOL 工具，先引入 Maven 的依赖坐标：
<!--JavaObjectLayout-->
<dependency>
<groupId>org. openjdk. jol</groupId>
<artifactId>jol-core</artifactId>
<version> 0. 11 </version>
</dependency>
接下来，创建一个 ObjectLock 待分析类，然后使用 JOL 对其进行对象布局分析。
1 .准备进行对象布局分析的 ObjectLock 类
我们先创建一个等待进行对象布局分析的 ObjectLock，其代码如下：
packagecom. crazymakercircle. innerlock;
//省略 import
publicclassObjectLock
{
privateIntegeramount= 0 ;//整型字段占用 4 字节
publicvoidincrease ()


```
第 2 章 Java 内置锁的核心原理 | 127
```
{
synchronized (this)
{
amount++;
}
}
/**
*输出十六进制、小端模式的 hashCode
*/
publicStringhexHash ()
{
//对象的原始 hashCode，Java 默认为大端模式
inthashCode=this.hashCode ();
//转成小端模式的字节数组
byte[]hashCode_LE=ByteUtil. int 2 Bytes_LE (hashCode);
//转成十六进制形式的字符串
returnByteUtil.byteToHex (hashCode_LE);
}
/**
*输出二进制、小端模式的 hashCode
*/
publicStringbinaryHash ()
{
//对象的原始 hashCode，Java 默认为大端模式
inthashCode=this.hashCode ();
//转成小端模式的字节数组
byte[]hashCode_LE=ByteUtil. int 2 Bytes_LE (hashCode);
StringBufferbuffer=newStringBuffer ();
for (byteb:hashCode_LE)
{
//转成二进制形式的字符串
buffer.append (ByteUtil. byte 2 BinaryString (b));
buffer.append ("");
}
returnbuffer.toString ();
}
/**
*输出十六进制、小端模式的 ThreadId
*/
publicStringhexThreadId ()
{
//当前线程的 threadID，Java 默认为大端模式
longthreadID=Thread.currentThread (). getId ();
//转成小端模式的字节数组
byte[]threadID_LE=ByteUtil. long 2 bytes_LE (threadID);
//转成十六进制形式的字符串
returnByteUtil.byteToHex (threadID_LE);
}
/**
*输出二进制、小端模式的 ThreadId
*/
publicStringbinaryThreadId ()
{
//当前线程的 threadID，Java 默认为大端模式
longthreadID=Thread.currentThread (). getId ();


128 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

//转成小端模式的字节数组
byte[]threadID_LE=ByteUtil. long 2 bytes_LE (threadID);
StringBufferbuffer=newStringBuffer ();
for (byteb:threadID_LE)
{
//转成二进制形式的字符串
buffer.append (ByteUtil. byte 2 BinaryString (b));
buffer.append ("");
}
returnbuffer.toString ();
}
publicvoidprintSelf ()
{
//输出十六进制、小端模式的 hashCode
Print.fo ("lockhexHash="+hexHash ());
//输出二进制、小端模式的 hashCode
Print.fo ("lockbinaryHash="+binaryHash ());
//通过 JOL 工具获取 this 的对象布局
Stringprintable=ClassLayout.parseInstance (this). toPrintable ();
//输出对象布局
Print.fo ("lock="+printable);
}
//省略其他
}
由于在 JVM 中的数据使用大端模式存储和计算，而 JOL 工具使用小端模式进行输出，所以在以
上的代码中，通过 Java 程序手工将 hashCode 从大端模式转换成小端模式。

```
2 .编写对象布局分析的用例代码
具体的测试用例代码如下：
packagecom. crazymakercircle. innerlock;
//省略 import
publicclassInnerLockTest
{
@org. junit. Test
publicvoidshowNoLockObject () throwsInterruptedException
{
//输出 JVM 的信息
Print.fo (VM.current (). details ());
//创建一个对象
ObjectLockobjectLock=newObjectLock ();
Print.fo ("objectstatus: ");
//输出对象的布局信息
objectLock.printSelf ();
}
//省略其他用例
}
运行以上用例，输出的结果如下：
[InnerLockTest. showNoLockObject]：objectstatus:
[ObjectLock. printSelf]：lockhexHash= 252 c 2823
[ObjectLock. printSelf]：lockbinaryHash= 00100101001011000010100000100011
[ObjectLock. printSelf]：lock=com. crazymakercircle. innerlock. ObjectLockobject
internals:
```

```
第 2 章 Java 内置锁的核心原理 | 129
```
OFFSET SIZE TYPEDESCRIPTION VALUE
0 4 (objectheader) 01252 c 28 ( 00000001001001010010110000101000 )
( 673981697 )
4 4 (objectheader) 23000000 ( 00100011000000000000000000000000 )( 35 )
8 4 (objectheader) a 40001 f 8 ( 10100100000000000000000111111000 )
(- 134152028 )
12 4 java. lang. IntegerObjectLock. amount 0
Instancesize: 16 bytes
Spacelosses: 0 bytesinternal+ 0 bytesexternal= 0 bytestotal
3 ．JOL 对象布局输出结果解读
从运行结果可以看出，当前 JVM 的运行环境为 64 位虚拟机。运行结果中输出了 ObjectLock 的对
象布局，所输出的 ObjectLock 对象为 16 字节，其中对象头（ObjectHeader）占 12 字节，剩下的 4 字节
由 amount 属性（字段）占用。由于 16 字节为 8 字节的倍数，因此没有对齐填充字节（JVM 规定对象
头部分必须是 8 字节的倍数，否则需要对齐填充）。
不同的基础数据类型所占用的字节数，具体如表 2 - 4 所示。
表 2 - 4 Java 基础数据类型所占用的字节数
基础数据类型 boolean byte short char int long float double
所占用的字节数 1 1 2 2 4 8 4 8
接下来分析一下输出结果中的对象哈希码。如果 Java 代码没有重写 Object.hashCode () 方法，那
么默认通过 Native 方式调用 os:: random () 方法产生哈希码，Java 代码也可以调用
System.identityHashCode (obj) 为对象产生哈希码。
对象一旦生成了哈希码，JVM 会将其记录在对象头的 MarkWord 中。当然，只有调用未重写的
Object.hashCode () 方法，或者调用 System.IdentityHashCode (obj) 方法时，其值才被记录到 MarkWord
中。如果调用的是重写的 hashCode () 方法，也不会记录到 MarkWord 中。
从以上用例的结果可以看出，对象的哈希码为“ 252 c 2823 ”，对象布局中的 MarkWord 所包含
的哈希码也为“ 252 c 2823 ”，二者是一致的。由于 Java 内存中的哈希码采用的是大端模式，而 JOL
输出的对象布局中的哈希码采用的是小端模式，因此示例代码在输出哈希码之前先转成小端模式。
对象一旦生成了哈希码，它就无法进入偏向锁状态。也就是说，只要一个对象已经计算过哈
希码，它就无法进入偏向锁状态；当一个对象当前正处于偏向锁状态，并且需要计算其哈希码的话，
它的偏向锁会被撤销，并且锁会膨胀为重量级锁。
通过查看以上的输出结果，可以发现没有加锁的对象的状态是 01 （无锁状态），因为是小端
模式，对象的锁状态处于对象布局的最前面的字节中。

###### 2. 4. 4 大小端问题

有关字节序列的存放格式目前有两大阵营：第一大阵营是 PowerPC 系列 CPU，采用大端模式存
放数据；第二大阵营是 X 86 系列 CPU，采用小端模式存放数据。那么究竟什么是大端模式，什么又
是小端模式呢？

1 ）大端模式是指数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址
中。大端存放模式有点儿类似于把数据当作字符串顺序处理：地址由小向大增加，而数据从高位往
低位放。


130 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

2 ）小端模式是指数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址
中，这种存储模式将地址的高低和数据位权有效地结合起来，高地址部分权值高，低地址部分权值
低，此模式和日常数字计算在方向上是一致的。

举一个例子，如果我们将十六进制数 0 X 1234 abcd 写入以 0 x 0000 开始的内存地址中，两种模式
的结果如表 2 - 5 所示。

表 2 - 5 十六进制数 0 X 1234 abcd 使用两种模式存放的结果
Address 大端模式小端模式
0 x 0000 0 x 12 0 xcd
0 x 0001 0 x 34 0 xab
0 x 0002 0 xab 0 x 34
0 x 0003 0 xcd 0 x 12
如果表 2 - 5 还不够直观，可以通过示意图来展示十六进制数 0 X 1234 abcd 使用两种模式存放的结
果。使用大端模式存放十六进制数 0 X 1234 abcd 的效果如图 2 - 6 所示。
使用小端模式存放十六进制数 0 X 1234 abcd 的效果如图 2 - 7 所示。

图 2 - 6 十六进制数 0 X 1234 abcd 使用大端模式图 2 - 7 十六进制数 0 X 1234 abcd 使用小端模式
存放的效果存放的效果
大端模式将高位存放在低地址，小端模式将高位存放在高地址。采用大端模式进行数据存放
符合人类的正常思维，而采用小端模式进行数据存放利于计算机处理。小端模式的优点大致如下：

1 ）使用小端模式在数据类型转换时（尤其是指针转换）不需要考虑地址问题。内存的低地址
处存放低字节，所以在强制转换数据时不需要调整字节的内容（比如：把 int 的 4 字节强制转换成 short
的 2 字节时，就直接把 int 数据存储的前两个字节给 short 就行，因为前两个字节刚好就是最低的两个
字节，符合转换逻辑）。
2 ）小端模式将地址的高低和数据位权有效地结合起来，高地址部分权值高，低地址部分权值
低，处理逻辑和我们的逻辑方法一致。CPU 做数值运算时从内存中按顺序依次从低位到高位取数据
进行运算，直到最后刷新最高位的符号位，这样的运算方式会更高效。

所以小端模式是处理器的主流字节存放模式。
由于所有网络协议也都是采用大端模式来传输数据的，因此有时也会把大端模式称之为“网
络字节序”。当两台采用不同字节存放模式的主机通信时，在发送数据之前，都必须经过字节次序
转换，转成“网络字节序”（大端模式）后再进行传输。
注意，一般操作系统都是小端模式，而通信协议是大端模式。JVM 所采用字节存放模式，并
不是小端模式，而是大端模式。


```
第 2 章 Java 内置锁的核心原理 | 131
```
###### 2. 4. 5 无锁、偏向锁、轻量级锁和重量级锁

在 JDK 1. 6 版本之前，所有的 Java 内置锁都是重量级锁。重量级锁会造成 CPU 在用户态和核心
态之间频繁切换，所以代价高、效率低。JDK 1. 6 版本为了减少获得锁和释放锁所带来的性能消耗，
引入了“偏向锁”和“轻量级锁”实现。所以，在 JDK 1. 6 版本里内置锁一共有 4 种状态：无锁状态、
偏向锁状态、轻量级锁状态和重量级锁状态，这些状态随着竞争情况逐渐升级。内置锁可以升级但
不能降级，意味着偏向锁升级成轻量级锁后不能降级成偏向锁。这种能升级却不能降级的策略，其
目的是为了提高获得锁和释放锁的效率。

1 .无锁状态
Java 对象刚创建时还没有任何线程来竞争，说明该对象处于无锁状态（无线程竞争它）这偏向
锁标识位是 0 、锁状态 01 。无锁状态下对象的 MarkWord 如图 2 - 8 所示。

图 2 - 8 无锁状态下对象的 MarkWord
2 .偏向锁状态
偏向锁是指一段同步代码一直被同一个线程所访问，那么该线程会自动获取锁，降低获取锁
的代价。如果内置锁处于偏向状态，当有一个线程来竞争锁时，先用偏向锁，表示内置锁偏爱这个
线程，这个线程要执行该锁关联的同步代码时，不需要再做任何检查和切换。偏向锁在竞争不激烈
的情况下效率非常高。
偏向锁状态的 MarkWord 会记录内置锁自己偏爱的线程 ID，内置锁会将该线程当作自己的熟人。
偏向锁状态下对象的 MarkWord 具体如图 2 - 9 所示。

图 2 - 9 偏向锁状态下对象的 MarkWord
3 .轻量级锁状态
当有两个线程开始竞争这个锁对象时，情况发生变化了，不再是偏向（独占）锁了，锁会升
级为轻量级锁，两个线程公平竞争，哪个线程先占有锁对象，锁对象的 MarkWord 就指向哪个线程
的栈帧中的锁记录。轻量级锁状态下对象的 MarkWord 如图 2 - 10 所示。
当锁处于偏向锁又被另一个线程所企图抢占时，偏向锁就会升级为轻量级锁。企图抢占的线
程会通过自旋的形式尝试获取锁，不会阻塞抢锁线程，以便提高性能。


132 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

图 2 - 10 轻量级锁状态下对象的 MarkWord
自旋原理非常简单，如果持有锁的线程能在很短时间内释放锁资源，那么那些等待竞争锁的
线程就不需要做内核态和用户态之间的切换进入阻塞挂起状态，它们只需要等一等（自旋），等持
有锁的线程释放锁后即可立即获取锁，这样就避免用户线程和内核切换的消耗。
但是，线程自旋是需要消耗 CPU 的，如果一直获取不到锁，那线程也不能一直占用 CPU 自旋
做无用功，所以需要设定一个自旋等待的最大时间。JVM 对于自旋周期的选择，JDK 1. 6 之后引入
了适应性自旋锁，适应性自旋锁意味着自旋的时间不是固定的，而是由前一次在同一个锁上的自旋
时间以及锁的拥有者的状态来决定的。线程如果自旋成功了，下次自旋的次数就会更多，如果自旋
失败了，自旋的次数就会减少。
如果持有锁的线程执行的时间超过自旋等待的最大时间仍没有释放锁，就会导致其他争用锁
的线程在最大等待时间内还是获取不到锁，自旋不会一直持续下去，这时争用线程会停止自旋进入
阻塞状态，该锁膨胀为重量级锁。

4 .重量级锁状态
重量级锁会让其他申请的线程之间进入阻塞，性能降低。重量级锁也就叫同步锁，这个锁对
象 MarkWord 再次发生变化，会指向一个监视器对象，该监视器对象用集合的形式来登记和管理排
队的线程。重量级锁状态下对象的 MarkWord 具体如图 2 - 11 所示。

```
图 2 - 11 重量级锁状态下对象的 MarkWord
```
#### 2. 5 偏向锁的原理与实战

偏向锁主要解决无竞争下的锁性能问题，所谓的偏向就是偏心，即锁会偏向于当前已经占有
锁的线程。

###### 2. 5. 1 偏向锁的核心原理

在实际场景中，如果一个同步块（或方法）没有多个线程竞争，而且总是由同一个线程多次
重入获取锁，如果每次还有阻塞线程，唤醒 CPU 从用户态转核心态，那么对于 CPU 是一种资源的浪
费，为了解决这类问题，就引入了偏向锁的概念。


```
第 2 章 Java 内置锁的核心原理 | 133
```
偏向锁的核心原理是：如果不存在线程竞争的一个线程获得了锁，那么锁就进入偏向状态，
此时 MarkWord 的结构变为偏向锁结构，锁对象的锁标志位（lock）被改为 01 ，偏向标志位
（biased_lock）被改为 1 ，然后线程的 ID 记录在锁对象的 MarkWord 中（使用 CAS 操作完成）。以后
该线程获取锁的时候判断一下线程 ID 和标志位，就可以直接进入同步块，连 CAS 操作都不需要，这
样就省去了大量有关锁申请的操作，从而也就提升了程序的性能。
偏向锁的核心思想是，如果一个线程获得了锁，那么锁就进入偏向模式，此时 MarkWord 的结
构也变为偏向锁结构。当这个线程再次请求锁时，无需再作任何同步操作，即获取锁的过程，这样
就省去了大量有关锁申请的操作，从而也就提升了程序的性能。经过研究发现，在大多数情况下，
锁不仅不存在多线程竞争，而且总是由同一线程多次获得锁，因此，在大多数情况下偏向锁是能提
升性能的。

```
从 JDK 1. 6 开始，虽然 JVM 默认开启偏向锁，但是默认延时 4 秒开启。也就是说，
程序刚启动创建的对象是不会开启偏向锁的， 4 秒后创建的对象才会开启偏向锁的。
```
偏向锁的主要作用是消除无竞争情况下的系统底层的同步操作，进一步提升程序性能，所以
在没有锁竞争的场合，偏向锁有很好的优化效果。但是，一旦有第二个线程需要竞争锁，那么偏向
模式立即结束，进入轻量级锁的状态。
假如在大部分情况同步块是没有竞争的，那么可以通过偏向来提高性能。即在无竞争时，之
前获得锁的线程再次获得锁时会判断偏向锁的线程 ID 是否指向自己，如果是，那么该线程将不用
再次获得锁，直接就可以进入同步块；如果未指向当前线程，当前线程会采用 CAS 操作将 MarkWord
中线程 ID 设置为当前线程 ID，如果 CAS 操作成功，那么获取偏向锁成功，去执行同步代码块，如
果 CAS 操作失败，那么表示有竞争，抢锁线程被挂起，撤销占锁线程的偏向锁，然后将偏向锁膨胀
为轻量级锁。
偏向锁的缺点：如果锁对象时常被多条线程竞争，偏向锁就是多余的，并且其撤销的过程会
带来一些性能开销。

###### 2. 5. 2 偏向锁的演示案例

```
这里使用前面定义的 ObjectLock 进行偏向锁的演示，并使用 JOL 工具输出对象的结构布局。
1 .偏向锁演示案例的代码
偏向锁演示案例的代码如下：
packagecom. crazymakercircle. innerlock;
//省略 import
publicclassInnerLockTest
{
//偏向锁的案例演示
@org. junit. Test
publicvoidshowBiasedLock () throwsInterruptedException
{
Print.tcfo (VM.current (). details ());
//JVM 延迟偏向锁
sleepMilliSeconds ( 5000 );
ObjectLockcounter=newObjectLock ();
```

134 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

Print.tcfo ("抢占锁前, lock 的状态: ");
lock.printObjectStruct ();
sleepMilliSeconds ( 5000 );
CountDownLatchlatch=newCountDownLatch ( 1 );
Runnablerunnable=()->
{
for (inti= 0 ;i<MAX_TURN; i++)
{
synchronized (lock)
{
lock.increase ();
if (i==MAX_TURN/ 2 )
{
Print.tcfo ("占有锁, lock 的状态: ");
lock.printObjectStruct ();
}
}
//每一次循环等待 10 毫秒
sleepMilliSeconds ( 10 );
}
latch.countDown ();
};
newThread (runnable,"biased-demo-thread"). start ();
//等待加锁线程执行完成
latch.await ();
sleepMilliSeconds ( 5000 );
Print.tcfo ("释放锁后, lock 的状态: ");
lock.printObjectStruct ();
}
//省略不相关代码
}
2 .偏向锁演示案例运行过程说明
运行以上案例，其数据的结果比较长，而且比较复杂，所以接下来对其运行结果进行分段说
明。运行演示案例之后，在看到第一行输出结果之前，程序要等待 5 秒，其对应的代码为：
//JVM 延迟偏向锁
sleepMilliSeconds ( 5000 );
ObjectLocklock=newObjectLock ();
Print.tcfo ("抢占锁前, lock 的状态: ");
lock.printObjectStruct ();
为什么要等待 5 秒呢？因为 JVM 在启动的时候会延迟启用偏向锁机制。JVM 默认就把偏向锁延
迟了 4000 毫秒，这就解释了为什么演示案例要等待 5 秒才能看到对象锁的偏向状态。
为什么偏向锁会延迟？因为 JVM 启动时会进行一系列的复杂活动，比如装载配置、系统类初
始化等。在这个过程中会使用大量 synchronized 关键字对对象加锁，且大多数锁都存在多线程竞争，
并不是偏向锁。为了减少初始化时间，JVM 默认延时加载偏向锁。
当然，可以关闭偏向锁延迟开启，直接通过修改 JVM 的启动选项来禁止偏向锁延迟，其具体
的启动选项如下：

- XX:+UseBiasedLocking-XX:BiasedLockingStartupDelay= 0
具体使用的方式为：
java-XX:+UseBiasedLocking-XX:BiasedLockingStartupDelay= 0 mainclass
程序启动之后，首先等待 5 秒，演示程序会首先输出 ObjectLock 的对象结构，具体如下：


```
第 2 章 Java 内置锁的核心原理 | 135
```
[main|InnerLockTest. showBiasedLock]： #Running 64 - bitHotSpotVM.
#Usingcompressedoopwith 3 - bitshift.
#Usingcompressedklasswith 3 - bitshift.
#Objectsare 8 bytesaligned.
#Fieldsizesbytype : 4 , 1 , 1 , 2 , 2 , 4 , 4 , 8 , 8 [bytes]
#Arrayelementsizes : 4 , 1 , 1 , 2 , 2 , 4 , 4 , 8 , 8 [bytes]
[main|InnerLockTest. showBiasedLock]：抢占锁前, lock 的状态:
[ObjectLock. printObjectStruct]：lock=com. crazymakercircle. innerlock. ObjectLock
objectinternals:
OFFSET SIZE TYPEDESCRIPTION VALUE
0 4 (objectheader) 05000000 ( 00000101000000000000000000000000 )( 5 )
4 4 (objectheader) 00000000 ( 00000000000000000000000000000000 )( 0 )
8 4 (objectheader) a 40001 f 8 ( 10100100000000000000000111111000 )
(- 134152028 )
12 4 java. lang. IntegerObjectLock. amount 0
通过 ObjectLock 的对象结构可以发现：biased_lock（偏向锁）状态已经启用，值为 1 ；lock（锁
状态）的值为 01 。lock 和 biased_lock 组合在一起为 101 ，表明当前的 ObjectLock 实例处于偏向锁状态。
ObjectLock 实例的对象头中内容“a 40001 f 8 ”为其 ClassPointer（类对象指针），这里的长度
为 32 位，是由于开启了指针压缩所导致。从输出的结果也能看出，对 oop（普通对象）、klass（类
对象）指针都进行了压缩，具体如下：
[main|InnerLockTest. showBiasedLock]： #Running 64 - bitHotSpotVM.
#Usingcompressedoopwith 3 - bitshift.
#Usingcompressedklasswith 3 - bitshift.
在以上输出中，类对象的名称使用了 klass 而不是 class，主要是为了避开使用 class
（作为关键字在定义类时使用）导致的误解。

在输出 ObjectLock 实例的结构之后，程序会再等待 5 秒，然后启动一个线程占用偏向锁，此时
的第二轮输出如下：
[biased-demo-thread|InnerLockTest. lambda$showBiasedLock$ 0 ]：占有锁, lock 的状态:
[ObjectLock. printObjectStruct]：lock=com. crazymakercircle. innerlock. ObjectLock
objectinternals:
OFFSET SIZE TYPEDESCRIPTION VALUE
0 4 (objectheader) 05802 b 20 ( 00000101100000000010101100100000 )
( 539721733 )
4 4 (objectheader) 00000000 ( 00000000000000000000000000000000 )( 0 )
8 4 (objectheader) a 40001 f 8 ( 10100100000000000000000111111000 )
(- 134152028 )
12 4 java. lang. IntegerObjectLock. amount 501
Instancesize: 16 bytes
Spacelosses: 0 bytesinternal+ 0 bytesexternal= 0 bytestotal
此处输出可以看到 ObjectLock 实例的 MarkWord 中已经记录了其偏向的线程 ID，不过由于此线
程 ID 不是 Java 中的 Thread 实例的 ID，因此没有办法直接在 Java 程序中比对。偏向锁的线程 ID（ 54 位）
和时间戳（epoch）合计为 56 位，其具体内容为“ 802 b 2000000000 ”。
偏向锁的加锁过程为：新线程只需要判断内置锁对象的 MarkWord 中的线程 ID 是不是自己的 ID，
如果是就直接使用这个锁，而不用作 CAS 交换；如果不是，比如在第一次获得此锁时内置锁的线程
ID 为空，就使用 CAS 交换，新线程将自己的线程 ID 交换到内置锁的 MarkWord 中，如果交换成功，
就加锁成功。
在演示案例的循环抢锁中，每执行一轮抢占，JVM 内部都会比较内置锁的偏向线程 ID 与当前
线程 ID，如果匹配，就表明当前线程已经获得了偏向锁，当前线程可以快速进入临界区。所以，


136 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

偏向锁的效率是非常高的。总之，偏向锁是针对一个线程而言的，线程获得锁之后就不会再有解锁
等操作了，这样可以省略很多开销。
在偏向锁释放之后，ObjectLock 实例的对象结构依然如下：
[main|InnerLockTest. showBiasedLock]：释放锁后, lock 的状态:
[ObjectLock. printObjectStruct]：lock=com. crazymakercircle. innerlock. ObjectLock
objectinternals:
OFFSET SIZE TYPEDESCRIPTION VALUE
0 4 (objectheader) 05802 b 20 ( 00000101100000000010101100100000 )
( 539721733 )
4 4 (objectheader) 00000000 ( 00000000000000000000000000000000 )( 0 )
8 4 (objectheader) a 40001 f 8 ( 10100100000000000000000111111000 )
(- 134152028 )
12 4 java. lang. IntegerObjectLock. amount 1000
Instancesize: 16 bytes
以上结果说明：虽然抢锁的线程已经结束，但是 ObjectLock 实例的对象结构仍然记录了其之前
的偏向线程 ID，其锁状态还是偏向锁状态 101 。

###### 2. 5. 3 偏向锁的膨胀和撤销

假如有多个线程来竞争偏向锁，此对象锁已经有所偏向，其他的线程发现偏向锁并不是偏向
自己，就说明存在了竞争，尝试撤销偏向锁（很可能引入安全点），然后膨胀到轻量级锁。

1 .偏向锁的撤销
撤销偏向锁的条件：
1 ）多个线程竞争偏向锁。
2 ）调用偏向锁对象 obj. 的 obj.hashCode () 方法或者 System.identityHashCode () 方法计算对象的 H
哈希码之后，偏向锁将被撤销。

为什么计算对象的哈希码时会撤销对象的偏向锁呢？因为偏向锁没有存储 MarkWord 备份信
息的地方。换句话说，因为对于一个对象其哈希码只会生成一次并保存在 MarkWord 中，偏向锁对
象的 MarkWord 已经保存了线程 ID，没有地方再保存哈希码时，所以只能撤销偏向锁，将 MarkWord
用于存放对象的哈希码。

```
轻量级锁会在帧栈的 LockRecord（锁记录）中记录哈希码，重量级锁会在监视
器中记录哈希码，起到了对哈希码备份的作用。而偏向锁没有地方备份哈希码，所以只能撤
销偏向锁。调用哈希码计算将会使对象再也无法偏向，因为在 MarkWord 中已经放置了哈希
码，偏向锁没有办法放置 ThreadID 了。调用哈希码计算后，当锁对象可偏向时，MarkWord
将变成未锁定状态，并只能升级成轻量级锁；当对象正处于偏向锁时，调用哈希码将使偏向
锁撤销后强制升级成重量锁。
```
偏向锁撤销的开销花费还是挺大的，其大概的过程如下：
1 ）JVM 需要等待一个全局安全点（globalsafepoint），当 JVM 到达全局安全点后，所有的用
户线程都是暂停的，当然，此时持有偏向锁的用户线程也被暂停了。


```
第 2 章 Java 内置锁的核心原理 | 137
```
2 ）遍历线程的栈帧，检查是否存在锁记录。如果存在锁记录，就需要清空锁记录，使其变成
无锁状态，并修复锁记录指向的 MarkWord，清除其线程 ID。
3 ）将当前锁升级（或碰撞）成轻量级锁。少数场景直接升级为重量级锁。
4 ）唤醒当前线程。
所以，如果某些临界区存在两个及两个以上的线程竞争，那么偏向锁反而会降低性能。在这
种情况下，可以在启动 JVM 时就把偏向锁的默认功能关闭。

2 .偏向锁的膨胀
如果偏向锁被占据，一旦有第二个线程争抢这个对象，因为偏向锁不会主动释放，所以第二
个线程可以看到内置锁偏向状态，这时表明在这个对象锁上已经存在竞争了。JVM 检查原来持有该
对象锁的占有线程是否依然存活，如果挂了，就可以将对象变为无锁状态，然后进行重新偏向，偏
向为抢锁线程。
如果 JVM 检查到原来的线程依然存活，就表明原来的线程还在使用偏执锁，发生锁竞争，撤
销原来的偏向锁，将偏向锁膨胀（INFLATING）为轻量级锁。

3 .偏向锁的好处
经验表明，其实大部分情况下进入一个同步代码块的线程都会是同一个线程。这也是为什么
JDK 会引入偏向锁出现的原因。所以，总体来说，使用偏向锁带来的好处还是大于偏向锁撤销和膨
胀的所带来的代价。

###### 2. 5. 4 全局安全点原理和偏向锁撤销的性能问题

JVM 包含了一些虚拟机后台线程（包含 VMThread、GC 线程、系统接收外部请求的线程等）以
及用户定义线程（含线程池中的线程），它们分工协作非常巧妙地构建出了 JVM 的系统生态。
这里要介绍的是 VMThread，在所有的虚拟机后台线程中，VMThread 线程的角色是一个超级
线程，可以理解为 JVM 里面的线程母体或者所有线程的大总管。根据 Hotspot 源码 vmThread. hpp 里面
的注释，VMThread 是一个单例的对象（最原始的线程），所有其他的线程都由这个超级线程产生
或触发。
VMThread 本身就是一个线程，负责执行一个自旋的 VMThread:: loop () 函数（定义在
VMThread. cpp 中），该 loop 函数从 VMOperationQueue 操作列队中按照优先级取出当前需要执行的
操作对象（vm_operation），并且调用 VM_Operation->evaluate 方法去执行该操作类型本身的业务逻
辑。而 VMOperationQueue 操作列队，本身是 VMThread 的结构体的一个成员，所有的需要 VMThread
线程执行的操作（vm_operation）都会被保存到这个列队中。从一定的程度上说，操作队列
VMOperationQueue 有点类似于 MPSC（多生产者单消费者）模式的队列。
VMThread 线程负责完成一些基础性的 VM 工作，比如，VMThread 线程可以协调其它线程达到
全局安全点。
什么是全局安全点？总体来说，JVM 的全局安全点是指当线程运行到这类位置时，堆对象状
态是确定一致的，JVM 可以安全地进行一些全局性的操作，如 GC、偏向锁解除等。在到达全局安
全点后，JVM 中的所有工作的用户线程都会被挂起，只有垃圾收集的 native 线程会持续不断地跑。
也就是说，全局安全点会触发 JVM 的 STW（StopTheWorld）停顿。所有的用户线程都会被暂停，


138 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

没有任何响应，有点像卡死的感觉，才称为 STW 停顿。
什么场景需要全局安全点呢？比如，大家非常熟悉的垃圾回收器，不论是 CMS 还是 G 1 都需要
全局安全点。只有到了全局安全点后，JVM 才能保障 GC 线程对堆中对象具有独占式的访问权限，
才能保证 GC 线程对 JVM 堆中的存活对象不出现多标或者漏标问题。所以，垃圾回收过程中需要全
局安全点。
所有的垃圾收集器的都存在 STW 停顿，Serial、Parallel、CMS 收集器均存在不同程度的 STW，
即使是 G 1 收集器也不例外。正是由于 GC 操作需要全局安全点，这就导致 STW 停顿，但是 GC 操作
并不是导致全局安全点从而发生 STW 停顿的唯一场景。
那么，有哪些场景需要让 JVM 进入到全局安全点呢？主要的场景如下：
 垃圾回收。
 偏向锁解除（Biasedlockrevocation）。
 由于代码优化所引起的指令重排。
 类重新定义（Classredefinition），如 hotswap 热部署、AOP 的代码植入。
 Dump 一个或者全部线程（threadDump）。
 Dump 堆（heapDump）。
JVM 如何进入到全局安全点？或者说，JVM 进入全局安全点需要哪些工作呢？大概有以下 3 点：
1 ）JVM 设置一个 globalsafepoint 标志位，各用户线程主动去检查这个标志位，发现全局安全
点标志位为 true 时，就将自己挂起。
2 ）各用户线程都有自己的安全点，当用户线程到达安全点后，都会去检查全局安全点标志位，
如果发现标志位为 true，就安全地将自己挂起。
3 ）JVM 中所有的用户线程都到达安全点之后，此时所有的用户线程都已经挂起，JVM 处于 STW
停顿状态，JVM 也达到一个全局安全点。

```
可以简单地把用户线程的安全点理解为局部安全点，而把 JVM 中所有的用户线
程都到达局部安全点之后，JVM 所处的状态称为全局安全点。
```
现在的问题是：用户线程的安全点又是什么呢？
Java 是一个典型的两段式编程语言：Java 编译器将项目源码编译为字节码（ByteCode），再由
JVM 运行字节码。JVM 主要有两种运行字节码的方式：

1 ）解释执行方式：由解释器去解释执行所有字节码。
2 ）JIT 方式（Justintime，即时编译）：也就是在运行时，JVM 即时地将 ByteCode 转化为 CPU
可以识别的机器码指令。JIT 方式的核心目的在于提高 Java 程序的性能，改变“Java 解释执行比 C/C++
慢很多”这一尴尬情况。

对于 JIT 方式，JVM 会寻找时机（或者说在特定位置）在插入安全点代码，比如，在方法返回
后、调用结束后、跳出循环后等。安全点代码的大致逻辑：主动检查 JVM 设置全局安全点标志位，
如果标志为 true，那么当前线程中断挂起，如果标志位没有被设置，那么继续执行。
出于性能考虑，JIT 方式插入的安全点的位置不能太多，太多会影响性能。但是，本着“不能


```
第 2 章 Java 内置锁的核心原理 | 139
```
让应用线程跑太久一直不进入安全点”的原则，被插入安全点的位置也不能太少，如果太少，就会
让线程一直无法进入安全点。在插入的安全点太少的情况下，如果部分线程一直无法进入安全点，
那么等待 JVM 全局安全点的线程（如 GC 线程）会一直等待，并且其他的已经进入安全点线程也会
被挂起等待，大家都在等待全局安全点的到来，结果 JVM 就相当于被冻结了。所以，JVM 会寻找一
种最优的安全点代码插入策略来实现功能和性能的平衡。
对于解释执行方式，JVM 会设置一个 2 字节的 dispatchtables，JVM 会把全局安全点的请求放置
在 dispatchtables 中。解释器执行时经常去检查这个 dispatchtables，当有全局安全点请求时，就会让
当前线程去进行安全点检查。安全点代码的逻辑和 JIT 场景大致相同：主动检查 JVM 设置全局安全
点标志位，如果标志为 true，那么当前线程中断挂起，如果标志位没有被设置，那么继续执行。
总之，在 HotSpot 虚拟机中，每个用户线程在安全点上都会检测一个全局安全点标志位来决定
自己是否暂停执行。

 对于 JIT 编译后的代码，JIT 会在代码特定的位置（通常在方法的返回处和跳出循环后）插
入安全点检查代码。
 对于解释执行的代码，JVM 会设置一个 2 字节的 dispatchtables 放置全局安全点的请求。解
释器执行时会经常去检查这个 dispatchtables，当有全局安全点请求时，就会让线程去进行
安全点检查。
通过上面的分析，大家应该都清楚地知道，偏向锁的撤销操作需要依赖 JVM 的全局安全点，从而
会带来 STW 停顿。如果偏向锁撤销操作发生频繁，会招来频繁的 STW，从而导致严重的性能问题。
所以，对于高并发应用来说，一般建议关闭偏向锁。具体的方式：可以在启动命令中加上以
下 JVM 参数：

- XX:-UseBiasedLocking
关闭偏向锁之后，Java 内置锁默认会进入轻量级锁状态。

#### 2. 6 轻量级锁的原理与实战

引入轻量级锁的主要目的是在多线程竞争不激烈的情况下，通过 CAS 机制竞争锁减少重量级
锁产生的性能损耗。重量级锁使用了操作系统底层的互斥锁（MutexLock），会导致线程在用户态
和核心态之间频繁切换，从而带来较大的性能损耗。

###### 2. 6. 1 轻量级锁的核心原理

轻量锁存在的目的是尽可能不用动用操作系统层面的互斥锁，因为其性能会比较差。线程的
阻塞和唤醒需要 CPU 从用户态转为核心态，频繁地阻塞和唤醒对 CPU 来说是一件负担很重的工作。
同时我们可以发现，很多对象锁的锁定状态只会持续很短的一段时间，例如整数的自加操作，在很
短的时间内阻塞并唤醒线程显然不值得，为此引入了轻量级锁。轻量级锁是一种自旋锁，因为 JVM
本身就是一个应用，所以希望在应用层面上通过自旋解决线程同步问题。
轻量级锁的执行过程：在抢锁线程进入临界区之前，如果内置锁（临界区的同步对象）没有
被锁定，JVM 首先将在抢锁线程的栈帧中建立一个锁记录（LockRecord），用于存储对象目前 Mark


140 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

Word 的拷贝，这时的线程堆栈与内置锁对象头大致如图 2 - 12 所示。

图 2 - 12 抢锁线程进入临界区之前的线程堆栈与内置锁对象头示意图
抢锁线程首先处理好栈帧中的轻量级锁的锁记录，然后就是最为核心的一步 CAS 自旋。抢锁
线程通过 CAS 自旋操作，尝试将内置锁对象头的 MarkWord 的 ptr_to_lock_record（锁记录指针）更
新为抢锁线程栈帧中锁记录的地址，如果这个更新执行成功了，这个线程就拥有了这个对象锁。然
后 JVM 将 MardWord 中的 lock 标记位改为 00 （轻量级锁标志），即表示该对象处于轻量级锁状态。
MarkWord 值被 CAS 更新之后，包含锁对象信息（如哈希表等）的旧值会被返回，这时需要抢
锁线程找一个地方将旧的 MarkWord 值暂存起来。所以，抢锁线程在通过 CAS 自旋更新完 MarkWord
之后，还会做两个善后工作：

1 ）将含有锁对象信息（如哈希表等）的旧 MardWord 值保存在抢锁线程 LockRecord 的 Displaced
MarkWord（可以理解为放错地方的 MarkWord）字段中，这一步起到备份的作用，以便锁释放之
后，将旧的 MarkWord 值恢复到锁对象头部。
2 ）抢锁线程将栈帧中的锁记录的 owner 指针指向锁对象。
在轻量级锁抢占成功之后，LockRecord 和对象头的状态具体如图 2 - 13 所示。

```
图 2 - 13 抢锁成功之后的线程堆栈与内置锁对象头示意图
锁记录是线程私有的，每个线程有自己的一份锁记录，在创建完锁记录后，会将内置锁对象
```
```
funcA () 的栈帧
```
```
funcA () 的栈帧
```

```
第 2 章 Java 内置锁的核心原理 | 141
```
的 MarkWord 拷贝到锁记录的 DisplacedMarkWord 字段。这是为什么呢？因为内置锁对象的 Mark
Word 的结构会有所变化，MarkWord 将会出现一个指向锁记录的指针，而不再存着无锁状态下的锁
对象哈希码等信息，所以必须将这些信息暂存起来，供后面在锁释放时使用。

###### 2. 6. 2 轻量级锁的案例演示

```
这里使用前面定义的 ObjectLock 进行轻量级锁的演示，并且使用 JOL 工具输出对象的结构布局。
1 .轻量级锁的演示案例
轻量级锁演示案例的代码如下：
packagecom. crazymakercircle. innerlock;
//省略 import
publicclassInnerLockTest
{
//偏向锁的案例演示
@org. junit. Test
publicvoidshowLightweightLock () throwsInterruptedException
{
Print.tcfo (VM.current (). details ());
//JVM 延迟偏向锁
sleepMilliSeconds ( 5000 );
ObjectLocklock=newObjectLock ();
Print.tcfo ("抢占锁前, lock 的状态: ");
lock.printObjectStruct ();
sleepMilliSeconds ( 5000 );
CountDownLatchlatch=newCountDownLatch ( 2 );
Runnablerunnable=()->
{
for (inti= 0 ;i<MAX_TURN; i++)
{
synchronized (lock)
{
lock.increase ();
if (i== 1 )
{
Print.tcfo ("第一个线程占有锁, lock 的状态: ");
lock.printObjectStruct ();
}
}
}
//循环完毕
latch.countDown ();
//线程虽然释放锁，但是一直存在死循环
for (intj= 0 ;; j++)
{
//每一次循环等待 1 毫秒
sleepMilliSeconds ( 1 );
}
};
newThread (runnable). start ();
sleepMilliSeconds ( 1000 );//等待 1 秒
RunnablelightweightRunnable=()->
```

142 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

{
for (inti= 0 ;i<MAX_TURN; i++)
{
synchronized (lock)
{
lock.increase ();
if (i==MAX_TURN/ 2 )
{
Print.tcfo ("第二个线程占有锁, lock 的状态: ");
lock.printObjectStruct ();
}
//每一次循环等待 1 毫秒
sleepMilliSeconds ( 1 );
}
}
//循环完毕
latch.countDown ();
};
newThread (lightweightRunnable). start ();
//等待加锁线程执行完成
latch.await ();
sleepMilliSeconds ( 2000 ); //等待 2 秒
Print.tcfo ("释放锁后, lock 的状态: ");
lock.printObjectStruct ();
} //省略不相关代码
}
2 .演示案例运行结果说明
运行以上案例，其数据的结果比较长，而且比较复杂，所以接下来对其运行结果进行分段说明。
程序启动运行 5 秒之后，ObjectLock 实例的锁状态为偏向锁，具体如下：
[main|InnerLockTest. showLightweightLock]：抢占锁前, lock 的状态:
[ObjectLock. printObjectStruct]：lock=com. crazymakercircle. innerlock. ObjectLock
objectinternals:
OFFSET SIZE TYPEDESCRIPTION VALUE
0 4 (objectheader) 05000000 ( 00000101000000000000000000000000 )( 5 )
4 4 (objectheader) 00000000 ( 00000000000000000000000000000000 )( 0 )
8 4 (objectheader) a 40001 f 8 ( 10100100000000000000000111111000 )
(- 134152028 )
12 4 java. lang. IntegerObjectLock. amount 0
Instancesize: 16 bytes
Spacelosses: 0 bytesinternal+ 0 bytesexternal= 0 bytestotal
现在执行第一个抢锁线程，在抢占完成之后，ObjectLock 实例的锁状态还是为偏向锁，只不过
是 ObjectLock 实例的 MarkWord 记录了第一个抢占线程的 ID。这一步的输出与上一个小节相同，这
里不再赘述。
接着开始第二个抢锁线程，在第二个线程抢锁成功之后，ObjectLock 实例的锁状态为轻量级锁，
具体如下：
[Thread- 1 |InnerLockTest. lambda$showLightweightLock$ 2 ]：第二个线程占有锁, lock 的状态:
[ObjectLock. printObjectStruct]：lock=com. crazymakercircle. innerlock. ObjectLock
objectinternals:
OFFSET SIZE TYPEDESCRIPTION VALUE
0 4 (objectheader) 88 efd 921 ( 100010 **00** 111011111101100100100001 )
( 567930760 )
4 4 (objectheader) 00000000 ( 00000000000000000000000000000000 )( 0 )


```
第 2 章 Java 内置锁的核心原理 | 143
```
8 4 (objectheader) a 40001 f 8 ( 10100100000000000000000111111000 )
(- 134152028 )
12 4 java. lang. IntegerObjectLock. amount 1501
Instancesize: 16 bytes
Spacelosses: 0 bytesinternal+ 0 bytesexternal= 0 bytestotal
ObjectLock 实例 MardWord 的 lock 标记位改为 00 （轻量级锁标志），其 ptr_to_lock_record（锁记
录指针）更新为抢锁线程栈帧中 LockRecord 的地址，此时的锁为轻量级锁。
轻量级锁被释放之后，ObjectLock 实例变成无锁状态，其 lock 标记位改为 01 （无锁标志），具
体的输出结果如下：
[ObjectLock. printObjectStruct]：lock=com. crazymakercircle. innerlock. ObjectLock
objectinternals:
OFFSET SIZE TYPEDESCRIPTION VALUE
0 4 (objectheader) 01000000 ( 00000001000000000000000000000000 )( 1 )
4 4 (objectheader) 00000000 ( 00000000000000000000000000000000 )( 0 )
8 4 (objectheader) a 40001 f 8 ( 10100100000000000000000111111000 )
(- 134152028 )
12 4 java. lang. IntegerObjectLock. amount 2000
Instancesize: 16 bytes

###### 2. 6. 3 轻量级锁的分类

轻量级锁主要有两种：普通自旋锁和自适应自旋锁。
1 .普通自旋锁
所谓普通自旋锁，就是指当有线程来竞争锁时，抢锁线程会在原地循环等待，而不是被阻塞，
直到那个占有锁的线程释放锁之后，这个抢锁线程才可以获得锁。

```
锁在原地循环等待的时候是会消耗 CPU 的，就相当于在执行一个什么也不干的
空循环。所以轻量级锁适用于那些临界区代码耗时很短的场景，这样线程在原地等待很短的
时间就能够获得锁了。
```
默认情况下，自旋的次数为 10 次，用户可以通过-XX: PreBlockSpin 选项来进行更改。
2 .自适应自旋锁
所谓自适应自旋锁，就是等待线程空循环的自旋次数并非是固定的，而是会动态地根据实际
情况来改变自旋等待的次数，自旋次数由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决
定。自适应自旋锁的大概原理是：

1 ）如果抢锁线程在同一个锁对象上之前成功获得过锁，那么 JVM 就会认为这次自旋也很有可
能再次成功，因此允许自旋等待持续相对更长的时间。
2 ）如果对于某个锁，抢锁线程在很少成功获得过，那么 JVM 将可能减少自旋时间甚至省略自
旋过程，以避免浪费处理器资源。

自适应自旋解决的是“锁竞争时间不确定”的问题。自适应自旋假定不同线程持有同一个锁
对象的时间基本相当，竞争程度趋于稳定。总的思想是：根据上一次自旋的时间与结果调整下一次
自旋的时间。


144 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
JDK 1. 6 的轻量级锁使用的是普通自旋锁，且需要使用-XX:+UseSpinning 选项手
工开启。JDK 1. 7 后，轻量级锁使用自适应自旋锁，JVM 启动时自动开启，且自旋时间由 JVM
自动控制。
```
轻量级锁也被称为非阻塞同步、乐观锁，因为这个过程并没有把线程阻塞挂起，而是让线程
空循环等待。

###### 2. 6. 4 轻量级锁的膨胀

轻量级锁的问题在哪里呢？虽然大部分临界区代码的执行时间都是很短的，但是也会存在执
行得很慢的临界区代码。临界区代码执行耗时较长，在其执行期间其他线程都在原地自旋等待，会
空消耗 CPU。因此，如果竞争这个同步锁的线程很多，就会有多个线程在原地等待继续空循环消耗
CPU（空自旋），这会带来很大的性能损耗。
轻量级锁本意是为了减少多线程进入操作系统底层的互斥锁（MutexLock）的概率，并不是
要替代操作系统互斥锁。所以，在争用激烈的场景下，轻量级锁会膨胀为基于操作系统内核互斥锁
实现的重量级锁。

#### 2. 7 重量级锁的原理与实战

在 JVM 中，每个对象都关联一个监视器，这里的对象包含了 Object 实例和 Class 实例。监视器是
一个同步工具，相当于一个许可证，拿到许可证的线程即可以进入临界区进行操作，没有拿到则需
要阻塞等待。重量级锁通过监视器的方式保障了任何时间只允许一个线程通过受到监视器保护的临
界区代码。

###### 2. 7. 1 重量级锁的核心原理

JVM 中每个对象都会有一个监视器，监视器和对象一起创建、销毁。监视器相当于一个用来
监视这些线程进入的特殊房间，其义务是保证（同一时间）只有一个线程可以访问被保护的临界区
代码块。
本质上，监视器是一种同步工具，也可以说是一种同步机制，主要特点是：
1 ）同步。监视器所保护的临界区代码是互斥地执行的。一个监视器是一个运行许可，任一个
线程进入临界区代码都需要获得这个许可，离开时把许可归还。
2 ）协作。监视器提供 Signal 机制，允许正持有许可的线程暂时放弃许可进入阻塞等待状态，
等待其他线程发送 Signal 去唤醒；其他拥有许可的线程可以发送 Signal，唤醒正在阻塞等待的线程，
让它可以重新获得许可并启动执行。

在 Hotspot 虚拟机中，监视器是由 C++类 ObjectMonitor 实现的，ObjectMonitor 类定义在
ObjectMonitor. hpp 文件中，其构造器代码大致如下：
//Monitor 结构体
ObjectMonitor:: ObjectMonitor (){
_header =NULL;


```
第 2 章 Java 内置锁的核心原理 | 145
```
_count = 0 ;
**_** waiters = 0 ,
//线程的重入次数
_recursions = 0 ;
_object =NULL;
//标识拥有该 monitor 的线程
**_** owner =NULL;
//等待线程组成的双向循环链表
**_** WaitSet =NULL;
_WaitSetLock = 0 ;
_Responsible =NULL;
_succ =NULL;
//多线程竞争锁进入时的单向链表
cxq =NULL;
FreeNext =NULL;
//_owner 从该双向循环链表中唤醒线程节点
**_** EntryList =NULL;
_SpinFreq = 0 ;
_SpinClock = 0 ;
OwnerIsThread= 0 ;
}
ObjectMonitor 的 Owner（_owner）、WaitSet（_WaitSet）、Cxq（_cxq）、EntryList（_EntryList）
这几个属性比较关键。ObjectMonitor 的 WaitSet、Cxq、EntryList 这三个队列存放抢夺重量级锁的线
程，而 ObjectMonitor 的 Owner 所指向的线程即为获得锁的线程。
WaitSet、Cxq、EntryList 三个队列的说明如下：
1 ）Cxq：竞争队列（ContentionQueue），所有请求锁的线程首先被放在这个竞争队列中。
2 ）EntryList：Cxq 中那些有资格成为候选资源的线程被移动到 EntryList 中。
3 ）WaitSet：某个拥有 ObjectMonitor 的线程在调用 Object.wait () 方法之后将被阻塞，然后该线
程将被放置在 WaitSet 链表中。

```
ObjectMonitor 的内部抢锁过程如图 2 - 14 所示。
```
图 2 - 14 ObjectMonitor 的内部抢锁过程
1 .Cxq
Cxq 并不是一个真正的队列，只是一个虚拟队列，原因在于 Cxq 是由 Node 及其 next 指针逻辑构
成，并不存在一个队列的数据结构。每次新加入 Node 会在 Cxq 的队头进行，通过 CAS 改变第一个节


146 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

点的指针为新增节点，同时设置新增节点的 next 指向后续节点；从 Cxq 取得元素时，会从队尾获取。
显然，Cxq 结构是一个无锁结构。
因为只有 Owner 线程才能从队尾取元素，即线程出列操作无争用，当然也就避免了 CAS 的 ABA
问题。

```
有关无锁结构以及 ABA 问题的具体知识可参见下一章的内容。
```
在线程进入 Cxq 前，抢锁线程会先尝试通过 CAS 自旋获取锁，如果获取不到，就进入 Cxq 队列，
这明显对于已经进入 Cxq 队列的线程是不公平的。所以，synchronized 同步块所使用的重量级锁是不
公平锁。

2 .EntryList
EntryList 与 Cxq 在逻辑上都属于等待队列。Cxq 会被线程并发访问，为了降低对 Cxq 队尾的争用，
而建立 EntryList。在 Owner 线程释放锁时，JVM 会从 Cxq 中迁移线程到 EntryList，并会指定 EntryList
中的某个线程（一般为 Head）为 OnDeckThread（ReadyThread）。EntryList 中的线程作为候选竞争
线程而存在。

3 .OnDeckThread 与 OwnerThread
JVM 不直接把锁传递给 OwnerThread，而是把锁竞争的权利交给 OnDeckThread，OnDeck 需要
重新竞争锁。这样虽然牺牲了一些公平性，但是能极大地提升系统的吞吐量，在 JVM 中，也把这种
选择行为称之为“竞争切换”。
OnDeckThread 获取到锁资源后会变为 OwnerThread。无法获得锁的 OnDeckThread 则会依然留
在 EntryList 中，考虑到公平性，OnDeckThread 在 EntryList 中的位置不发生变化（依然在队头）。
在 OnDeckThread 成为 Owner 的过程中，还有一个不公平的事情，就是后来的新抢锁线程可能
直接通过 CAS 自旋成为 Owner 而抢到锁。

4 .WaitSet
如果 Owner 线程被 Object.wait () 方法阻塞，就转移到 WaitSet 队列中，直到某个时刻通过
Object.notify () 或者 Object.notifyAll () 唤醒，在线程会重新进入 EntryList 中。

###### 2. 7. 2 重量级锁的开销

处于 ContentionList、EntryList、WaitSet 中的线程都处于
阻塞状态，线程的阻塞或者唤醒都需要操作系统来帮忙，
Linux 内核下采用 pthread_mutex_lock 系统调用实现，进程需
要从用户态切换到内核态。
Linux 系统的体系架构分为用户态（或者用户空间）和
内核态（或者内核空间），具体如图 2 - 15 所示。
Linux 系统的内核是一组特殊的软件程序，负责控制计
算机的硬件资源，例如协调 CPU 资源、分配内存资源，并且
提供稳定的环境供应用程序运行。应用程序的活动空间为用户空间，应用程序的执行必须依托于内

```
图 2 - 15 Linux 进程的用户态与内核态
```

```
第 2 章 Java 内置锁的核心原理 | 147
```
核提供的资源，包括 CPU 资源、存储资源、I/O 资源等。
用户态与内核态有各自专用的内存空间、专用的寄存器等，进程从用户态切换至内核态需要
传递给许多变量、参数给内核，内核也需要保护好用户态在切换时的一些寄存器值、变量等，以便
内核态调用结束后切换回用户态继续工作。
用户态的进程能够访问的资源受到了极大的控制，而运行在内核态的进程可以“为所欲为”。
一个进程可以运行在用户态，也可以运行在内核态，那么它们之间肯定存在用户态和内核态切换的
过程。进程从用户态到内核态切换主要包括以下三种方式：

1 ）硬件中断。硬件中断也称为外设中断，当外设完成用户请求时，会向 CPU 发送中断信号。
2 ）系统调用。其实系统调用本身就是中断，只不过是软件中断，与硬件中断不同。
3 ）异常。如果当前进程运行在用户态，这时发生了异常事件（例如缺页异常），就会触发
切换。

用户态是应用程序运行的空间，为了能访问到内核管理的资源（例如 CPU、内存、I/O），可
以通过内核态所提供的访问接口实现，这些接口就叫系统调用。pthread_mutex_lock 系统调用是内
核态为用户态进程提供的 Linux 内核态下互斥锁的访问机制，所以使用 pthread_mutex_lock 系统调用
时，进程需要从用户态切换到内核态，而这种切换是需要消耗很多时间的，有可能比用户执行代码
的时间还要长。
由于 JVM 轻量级锁使用 CAS 进行自旋抢锁，这些 CAS 操作都处于用户态下，进程不存在用户
态和内核态之间的运行切换，因此 JVM 轻量级锁开销较小。而 JVM 重量级锁使用了 Linux 内核态下
的互斥锁（Mutex），这是重量级锁开销很大的原因。

###### 2. 7. 3 重量级锁的演示案例

```
这里使用前面定义的 ObjectLock 进行重量级锁的演示，并且使用 JOL 工具输出对象的结构布局。
1 .重量级锁的演示案例
重量级锁演示案例的代码如下：
packagecom. crazymakercircle. innerlock;
//省略 import
publicclassInnerLockTest
{
@org. junit. Test
publicvoidshowHeavyweightLock () throwsInterruptedException
{
Print.tcfo (VM.current (). details ());
//JVM 延迟偏向锁
sleepMilliSeconds ( 5000 );
ObjectLockcounter=newObjectLock ();
Print.tcfo ("抢占锁前, lock 的状态: ");
lock.printObjectStruct ();
sleepMilliSeconds ( 5000 );
CountDownLatchlatch=newCountDownLatch ( 3 );
Runnablerunnable=()->
{
for (inti= 0 ;i<MAX_TURN; i++)
```

148 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

{
synchronized (lock)
{
lock.increase ();
if (i== 0 )
{
Print.tcfo ("第一个线程占有锁, lock 的状态: ");
lock.printObjectStruct ();
}
}
}
//循环完毕
latch.countDown ();
//线程虽然释放锁，但是一直存在
for (intj= 0 ;; j++)
{
//每一次循环等待 1 毫秒
sleepMilliSeconds ( 1 );
}
};
newThread (runnable). start ();
sleepMilliSeconds ( 1000 ); //等待 1 秒
RunnablelightweightRunnable=()->
{
for (inti= 0 ;i<MAX_TURN; i++)
{
synchronized (lock)
{
lock.increase ();
if (i== 0 )
{
Print.tcfo ("占有锁, lock 的状态: ");
lock.printObjectStruct ();
}
//每一次循环等待 1 毫秒
sleepMilliSeconds ( 1 );
}
}
//循环完毕
latch.countDown ();
};
//启动两个线程，开始激烈地抢锁
newThread (lightweightRunnable,"抢锁线程 1 "). start ();
sleepMilliSeconds ( 100 ); //等待 100 毫秒
newThread (lightweightRunnable,"抢锁线程 2 "). start ();
//等待加锁线程执行完成
latch.await ();
sleepMilliSeconds ( 2000 ); //等待 2 秒
Print.tcfo ("释放锁后, lock 的状态: ");
lock.printObjectStruct ();
}
2 .重量级锁演示案例运行结果说明
运行以上案例，其数据的结果比较长，而且比较复杂，所以接下来对其运行结果进行分段说
明。在程序启动运行 5 秒之后，ObjectLock 的锁状态为偏向锁，在程序运行的第二个阶段有一个线
程占有锁，此时的 ObjectLock 实例的锁状态仍然为偏向锁，具体如下：


```
第 2 章 Java 内置锁的核心原理 | 149
```
[Thread- 0 |InnerLockTest. lambda$showHeavyweightLock$ 3 ]：第一个线程占有锁, lock 的状态:
[ObjectLock. printObjectStruct]：lock=ObjectLockobjectinternals:
OFFSET SIZE TYPEDESCRIPTION VALUE
0 4 (objectheader) 05 c 07 c 1 f ( 00000101110000000111110000011111 )
( 528269317 )
4 4 (objectheader) 00000000 ( 00000000000000000000000000000000 )( 0 )
8 4 (objectheader) a 40001 f 8 ( 10100100000000000000000111111000 )
(- 134152028 )
12 4 java. lang. IntegerObjectLock. amount 1
Instancesize: 16 bytes
Spacelosses: 0 bytesinternal+ 0 bytesexternal= 0 bytestotal
在程序运行的第三个阶段开启了两个线程去抢占锁，第一个抢锁线程的输出如下：
[抢锁线程 1 |InnerLockTest. lambda$showHeavyweightLock$ 4 ]：占有锁, counter 的状态:
[ObjectLock. printObjectStruct]：lock=ObjectLockobjectinternals:
OFFSET SIZE TYPEDESCRIPTION VALUE
0 4 (objectheader) b 8 f 18 d 21 ( 10111000111100011000110100100001 )
( 562950584 )
4 4 (objectheader) 00000000 ( 00000000000000000000000000000000 )( 0 )
8 4 (objectheader) a 40001 f 8 ( 10100100000000000000000111111000 )
(- 134152028 )
12 4 java. lang. IntegerObjectLock. amount 1001
Instancesize: 16 bytes
Spacelosses: 0 bytesinternal+ 0 bytesexternal= 0 bytestotal
通过以上输出可以看出，此时 ObjectLock 实例的锁状态已经膨胀为轻量级锁，其 lock 标记为 00 。
第二个抢锁线程比第一个抢锁线程晚启动 100 毫秒，其输出如下：
[抢锁线程 2 |InnerLockTest. lambda$showHeavyweightLock$ 4 ]：占有锁, counter 的状态:
[ObjectLock. printObjectStruct]：lock=ObjectLockobjectinternals:
OFFSET SIZE TYPEDESCRIPTION VALUE
0 4 (objectheader) ca 524320 ( 11001010010100100100001100100000 )
( 541283018 )
4 4 (objectheader) 00000000 ( 00000000000000000000000000000000 )( 0 )
8 4 (objectheader) a 40001 f 8 ( 10100100000000000000000111111000 )
(- 134152028 )
12 4 java. lang. IntegerObjectLock. amount 1064
Instancesize: 16 bytes
Spacelosses: 0 bytesinternal+ 0 bytesexternal= 0 bytestotal
通过以上输出可以看出，此时 ObjectLock 实例的锁状态已经从轻量级锁膨胀为重量级锁，其
lock 标记为 10 ，说明此时存在激烈的锁争用。

#### 2. 8 偏向锁、轻量级锁与重量级锁的对比

总结一下 synchronized 的执行过程，大致如下：
1 ）线程抢锁时，JVM 首先检测内置锁对象 MarkWord 中 biased_lock（偏向锁标识）是否设置
成 1 ，lock（锁标志位）是否为 01 ，如果都满足，确认内置锁对象为可偏向状态。
2 ）在内置锁对象确认为可偏向状态之后，JVM 检查 MarkWord 中线程 ID 是否为抢锁线程 ID，
如果是，就表示抢锁线程处于偏向锁状态，抢锁线程快速获得锁，开始执行临界区代码。
3 ）如果 MarkWord 中线程 ID 并未指向抢锁线程，就通过 CAS 操作竞争锁。如果竞争成功，就
将 MarkWord 中线程 ID 设置为抢锁线程，偏向标志位设置为 1 ，锁标志位设置为 01 ，然后执行临界


150 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

区代码，此时内置锁对象处于偏向锁状态。
4 ）如果 CAS 操作竞争失败，就说明发生了竞争，撤销偏向锁，进而升级为轻量级锁。
5 ）JVM 使用 CAS 将锁对象的 MarkWord 替换为抢锁线程的锁记录指针，如果成功，抢锁线程
就获得锁。如果替换失败，就表示其他线程竞争锁，JVM 尝试使用 CAS 自旋替换抢锁线程的锁记录
指针，如果自旋成功（抢锁成功），那么锁对象依然处于轻量级锁状态。
6 ）如果 JVM 的 CAS 替换锁记录指针自旋失败，轻量级锁膨胀为重量级锁，后面等待锁的线程
也要进入阻塞状态。

总体来说，偏向锁是在没有发生锁争用的情况下使用；一旦有了第二个线程的争用锁，偏向
锁就会升级为轻量级锁；如果锁争用很激烈，轻量级锁的 CAS 自旋到达阈值后，轻量级锁就会升级
为重量级锁。三种内置锁的对比如表 2 - 6 所示。

```
表 2 - 6 三种内置锁的对比
锁优点缺点适用场景
```
```
偏向锁
```
```
加锁和解锁不需要额外的消耗，和执
行非同步方法比仅存在纳秒级的差
距
```
```
如果线程间存在锁竞争，会带
来额外的锁撤销的消耗
```
```
适用于只有一个线程
访问临界区场景
```
```
轻量级锁竞的争响的应线速程度不会阻塞，提高了程序抢自不旋到等锁待竞，争会的消线耗程 CP 使 U 用 CAS 锁量占高用时间很短，吞吐
```
```
重量级锁线 CP 程 U 竞争不使用自旋，不会消耗线程阻塞，响应时间缓慢锁量占低用时间较长, 吞吐
```
#### 2. 9 线程间通信

线程是操作系统调度的最小单位，有自己的栈空间，可以按照既定的代码逐步执行，但是如
果每个线程间都孤立地运行，就会造资源浪费。
所以在现实中，如果需要多个线程按照指定的规则共同完成一件任务，那么这些线程之间就
需要互相协调，这个过程被称为线程的通信。

###### 2. 9. 1 线程间通信定义

线程的通信可以被定义为：当多个线程共同操作共享的资源时，线程间通过某种方式互相告
知自己的状态，以避免无效的资源争夺。
线程间线程通信的方式可以有很多种：等待－通知、共享内存、管道流。每种方式有不同的
方法来实现，这里首先介绍的是等待－通知的通信方式。
“等待－通知”通信方式是 Java 中使用普遍的线程间通信方式，其经典的案例就是“生产者－
消费者”模式。

2. 9. (^2) 低效的线程轮询
首先回到前面生产者－消费者安全版本的数据缓冲区类 SafeDataBuffer。其存在一个隐蔽、但


```
第 2 章 Java 内置锁的核心原理 | 151
```
是又很耗性能的问题：消费者每一轮消费，不管数据区是否为空，都需要进行数据区的询问和判断。
其轮询代码如下：
public synchronized IGoods get () throwsException{
IGoodsgoods=null;
if (amount<= 0 ){
Print.tcfo ("队列已经空了！");
//数据区为空，直接返回
returnnull;
}
...
}
当数据区空时（amount<= 0 ），消费者无法取出数据，但是仍然做一个无用的数据区询问工
作，白白耗费了 CPU 的时间片。
对于生产者来说，也存在类似的无效轮询问题。当数据区满时，生产者无法加入数据，这时
候生产者执行 add (Telement) 方法也白白耗费了 CPU 的时间片。其中的轮询代码具体如下：
publicsynchronizedvoidadd (Telement) throwsException
{
if (amount.get ()>MAX_AMOUNT)
{
Print.tcfo ("队列已经满了！");
return;
}
...
}
如何在生产者或者消费者空闲时节约 CPU 时间片，免去巨大的 CPU 资源浪费呢？一个非常有
效的办法是：使用“等待－通知”方式进行生产者与消费者之间的线程通信。
具体来说，在数据区满（amount.get ()>MAX_AMOUNT）时，可以让生产者等待，等到下次
数据区中可以加入数据时，给生产者发通知，让生产者唤醒。
同样，在数据区空（amount<= 0 ）时，可以让消费者等待，等到下次数据区中可以取出数据
时，消费者才能被唤醒。
那么，由谁去唤醒等待状态的生产者呢？可以在消费者取出一个数据后，由消费者去唤醒等
待的生产者。
同样，由谁去唤醒等待状态的消费者呢？可以在生产者加入一个数据后，由生产者去唤醒等
待的消费者。
Java 语言中“等待－通知”方式的线程间的通信使用对象的 wait ()、notify () 两类方法来实现。
每个 Java 对象都有 wait ()、notify () 两类实例方法，并且 wait ()、notify () 方法和对象的监视器是紧密相
关的。

```
wait ()、notify () 两类方法在数量上不止两个。wait ()、notify () 两类方法不属于 Thread
类，而是属于 Java 对象实例（Object 实例或者 Class 实例）。
```

152 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

###### 2. 9. 3 wait 方法、notify 方法的原理

Java 对象中的 wait ()、notify () 两类方法就如同信号开关，用来进行等待方和通知方之间的交互。
1 .对象的 wait () 方法
对象的 wait () 方法的主要作用是让当前线程阻塞并等待被唤醒。wait () 方法与对象监视器紧密相
关，使用 wait () 方法时也一定需要放在同步块中。wait () 方法的调用方法如下：
synchronized (locko)
{
//同步保护的代码块
locko.wait ()；
...
}
Object 类中的 wait 方法有三个版本：
（ 1 ）voidwait ()
这是一个基础版本，当前线程调用了同步对象 locko 的 wait 实例方法后，将导致当前的线程等
待，当前线程进入 locko 的监视器 WaitSet，等待被其他线程唤醒。

（ 2 ）voidwait (longtimeout)
这是一个限时等待版本，导致当前的线程等待，等待被其他线程唤醒，或者指定的时间 timeout
用完，线程不再等待。

（ 3 ）voidwait (longtimeout, intnanos)
这是一个高精度限时等待版本，其主要作用是更精确地控制等待时间。参数 nanos 是一个附加
的纳秒级别等待时间，从而实现更加高精度的等待时间控制。

```
1 秒= 1000 毫秒= 1000000 微秒= 1000000000 纳秒。
```
2 .wait 方法的核心原理
对象的 wait 方法的核心原理大致如下：
1 ）当线程调用了 locko（某个同步锁对象）的 wait () 方法后，JVM 会将当前线程加入 locko 监视
器的 WaitSet（等待集），等待被其他线程唤醒。
2 ）当前线程会释放 locko 对象监视器的 Owner 权利，让其他线程可以抢夺 locko 对象的监视器。
3 ）让当前线程等待，其状态变成 WAITING。
在线程调用了同步对象 locko 的 wait () 方法之后，同步对象 locko 的监视器内部状态大致如图 2 - 16
所示。

3 .对象的 notify () 方法
对象的 notify () 方法的主要作用是唤醒在等待的线程。notify () 方法与对象监视器紧密相关，使
用 notify () 方法时也需要放在同步块中。notify () 方法的调用方法如下：


```
第 2 章 Java 内置锁的核心原理 | 153
```
图 2 - 16 同步对象 locko 的 wait () 方法被调用之后其监视器的内部状态
synchronized (locko)
{
//同步保护的代码块
locko.notify ()；
...
}
notify () 方法有两个版本：
版本一：voidnotify ()
notify () 方法的主要作用如下：locko.notify () 调用后，唤醒 locko 监视器等待集中的第一个等待线
程；被唤醒的线程进入 EntryList，其状态从 WAITING 等待状态变成 BLOCKED。

版本二：voidnotifyAll ()
locko.notifyAll () 被调用后，唤醒 locko 监视器等待集中的全部等待线程；所有被唤醒的线程进
入 EntryList，线程状态从 WAITING 等待状态变成 BLOCKED。

4 .notify () 方法的核心原理
对象的 notify () 或者 notifyAll () 方法的核心原理大致如下：
1 ）当线程调用了 locko（某个同步锁对象）的 notify () 方法后，JVM 会唤醒 locko 监视器 WaitSet
中的第一个等待线程。
2 ）当线程调用了 locko 的 notifyAll () 方法后，JVM 会唤醒 locko 监视器 WaitSet 中的所有等待线程。
3 ）等待线程被唤醒后，会从监视器的 WaitSet 移动到 EntryList，线程具备了排队抢夺监视器
Owner 权利的资格，其状态从 WAITING 变成 BLOCKED。
4 ）EntryList 中的线程抢夺到监视器 Owner 权利之后，线程的状态从 BLOCKED 变成 Runnable，
具备重新执行的资格。

在线程调用了同步对象 locko 的 wait () 或者 notifyAll () 方法之后，同步对象 locko 的监视器内部状
态大致如图 2 - 17 所示。


154 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
图 2 - 17 同步对象 locko 的 wait () 或者 notifyAll () 方法被调之后监视器的内部状态
```
###### 2. 9. 4 “等待－通知”通信模式演示案例

Java 的“等待－通知”机制是指：一个线程 A 调用了同步对象的 wait () 方法进入等待状态，而
另一线程 B 调用了同步对象的 notify () 或者 notifyAll () 方法通知等待线程，当线程 A 收到通知后，重新
进入就绪状态，准备开始执行。
线程间的通信需要借助同步对象（Object）的监视器来完成，Object 对象的 wait ()、notify () 方法
就如开关信号，用于完成等待方和通知方之间的通信。
下面的演示案例定义了一个独立的同步对象 locko，然后借助其 wait ()、notify () 方法完成了两个
线程 WaitThread、NotifyThread 之间的通信，具体代码如下：
packagecom. crazymakercircle. mutithread. basic. use;
//省略 import
publicclassWaitNotifyDemo
{
staticObjectlocko=newObject ();
//等待线程的异步目标任务
staticclassWaitTargetimplementsRunnable
{
publicvoidrun ()
{
//加锁
synchronized (locko)
{
try
{
//启动等待
Print.tco ("启动等待");
//等待被通知，同时释放 locko 监视器的 Owner 权限
locko.wait ();
//收到通知后，线程会进入 locko 监视器的 EntryList
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}
//获取到监视器的 Owner 权利
Print.tco ("收到通知，当前线程继续执行");


```
第 2 章 Java 内置锁的核心原理 | 155
```
}
}
}
//通知线程的异步目标任务
staticclassNotifyTargetimplementsRunnable
{
publicvoidrun ()
{
//加锁
synchronized (locko)
{
//从屏幕读取输入，目的是阻塞通知线程，方便使用 jstack 查看线程状态
Print.consoleInput ();
//获取 lock 锁，然后进行发送
//此时不会立即释放 locko 的 Monitor 的 Owner，需要执行完毕
locko.notifyAll ();
Print.tco ("发出通知了，但是线程还没有立马释放锁");
}
}
}
publicstaticvoidmain (String[]args) throwsInterruptedException
{
//创建等待线程
ThreadwaitThread=newThread (newWaitTarget (),"WaitThread");
//启动等待线程
waitThread.start ();
sleepSeconds ( 1 );
//创建通知线程
ThreadnotifyThread=newThread (newNotifyTarget (),"NotifyThread");
//启动通知线程
notifyThread.start ();
}
}
在案例程序执行过程中，WaitThread 首先调用 locko.wait () 等待被通知并且进入阻塞状态，释放
locko 的 Owner 权利，然后 NotifyThread 可以获取 locko 的 Owner 权利，进入临界区执行。NotifyThread
的临界区代码首先从屏幕读取用于输入，目的是阻塞 NotifyThread 线程，方便使用 jstack 查看线程状态。
运行以上程序，在屏幕中输入任意内容之前，结合使用 jps 与 jstack 两个指令查看线程的状态，
具体如下：
c:/user/username>jps
11828 NailgunRunner
25192 WaitNotifyDemo
26712 Jps
c:/user/username> jstack 25192
...
"WaitThread"# 14 prio= 5 os_prio= 0 tid= 0 x 000000001 f 742800 nid= 0 x 5 b 40 inObject.wait ()
[ 0 x 00000000203 fe 000 ]
java.lang.Thread.State: WAITING (onobjectmonitor)
atjava.lang.Object.wait (NativeMethod)

- waitingon< 0 x 000000076 b 89 f 028 >(ajava. lang. Object)
atjava.lang.Object.wait (Object. java: 502 )
at... WaitNotifyDemo$WaitTarget.run (WaitNotifyDemo. java: 26 )
- locked< 0 x 000000076 b 89 f 028 >(ajava. lang. Object)
atjava.lang.Thread.run (Thread. java: 745 )
...
"NotifyThread"# 17 prio= 5 os_prio= 0 tid= 0 x 000000001 f 87 f 800 nid= 0 x 5088 runnable
[ 0 x 00000000205 fe 000 ]
java. lang. Thread. State:RUNNABLE
atjava.io.FileInputStream.readBytes (NativeMethod)


156 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
atjava.io.FileInputStream.read (FileInputStream. java: 255 )
```
- locked< 0 x 000000076 b 89 f 028 >(ajava. lang. Object)
    ...
       atjava.lang.Thread.run (Thread. java: 745 )
此时通过 jps 指令查看到 WaitNotifyDemo 进程的 Id 为 25192 ，然后使用 jstack 25192 指令看
WaitThread、NotifyThread 两个线程的状态：WaitThread 的状态为 WAITING，NotifyThread 的状态为
RUNNABLE。
为什么 WaitThread 的状态为 WAITING 呢？此时 WaitThread 处于 locko 的 Monitor 的 WaitSet（等待
集）中，等待被唤醒。
在屏幕中输入任意内容之前，以上代码继续执行，其结果大致如下：
[WaitThread]：flag 为 false，不满足条件，启动等待
PleaseEntersth:
go
[NotifyThread]：设置 flag 为 true，发出通知了，但是线程还没有立马释放锁
[WaitThread]：条件满足，当前线程从 wait 状态返回继续执行了
通过实例的演示目前已经知道：WaitThread 线程调用 locko. wait 后会一直处于 WAITING 状态，
不会在占用 CPU 的时间片，也不会占用同步对象 locko 的监视器，直到等待其他线程使用 locko. notify
方法发出通知。

###### 2. 9. 5 生产者－消费者之间的线程间通信

为了避免空轮询导致 CPU 时间片浪费，提高生产者－消费者实现版本的性能，接下来演示使
用“等待－通知”的方式在生产者与消费者之间进行线程间通信。

使用“等待－通知”机制通信的生产者－消费者实现版本
此实现版本大致需要定义以下三个同步对象：
1 ）LOCK_OBJECT：用于临界区同步，临界区资源为数据缓冲区的 dataList 变量和 amount
变量。
2 ）NOT_FULL：用于数据缓冲区的未满条件等待和通知。生产者在添加元素前，需要判断数
据区是否已满，如果是，生产者进入 NOT_FULL 的同步区去等待被通知，只要消费者消耗一个元
素，数据区就是未满的，进入 NOT_FULL 的同步区发送通知。
3 ）NOT_EMPTY：用于数据缓冲区的非空条件等待和通知。消费者在消耗元素前需要判断数
据区是否已空，如果是，消费者进入 NOT_EMPTY 的同步区等待被通知，只要生产者添加一个元素，
数据区就是非空的，生产者会进入 NOT_EMPTY 的同步区发送通知。

```
使用“等待－通知”机制通信的生产者―消费者实现版本，其代码大致如下：
packagecom. crazymakercircle. producerandcomsumer. store;
//省略 import
publicclassCommunicatePetStore
{
publicstaticfinalintMAX_AMOUNT= 10 ;//数据缓冲区最大长度
//数据缓冲区，类定义
staticclassDataBuffer<T>
{
//保存数据
```

```
第 2 章 Java 内置锁的核心原理 | 157
```
privateList<T>dataList=newLinkedList<>();
//数据缓冲区长度
privateIntegeramount= 0 ;
privatefinalObjectLOCK_OBJECT=newObject ();
privatefinalObjectNOT_FULL=newObject ();
privatefinalObjectNOT_EMPTY=newObject ();
//向数据区增加一个元素
publicvoidadd (Telement) throwsException
{
while (amount>MAX_AMOUNT)
{
synchronized (NOT_FULL)
{
Print.tcfo ("队列已经满了！");
//等待未满通知
NOT_FULL.wait ();
}
}
synchronized (LOCK_OBJECT)
{
dataList.add (element);
amount++;
}
synchronized (NOT_EMPTY)
{
//发送未空通知
NOT_EMPTY.notify ();
}
}
/**
*从数据区取出一个商品
*/
publicTfetch () throwsException
{
while (amount<= 0 )
{
synchronized (NOT_EMPTY)
{
Print.tcfo ("队列已经空了！");
//等待未空通知
NOT_EMPTY.wait ();
}
}
Telement=null;
synchronized (LOCK_OBJECT)
{
element=dataList.remove ( 0 );
amount--;
}
synchronized (NOT_FULL)
{
//发送未满通知
NOT_FULL.notify ();
}
returnelement;
}
}
publicstaticvoidmain (String[]args) throwsInterruptedException


158 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
{
Print.cfo ("当前进程的 ID 是"+JvmUtil.getProcessID ());
System.setErr (System. out);
//共享数据区，实例对象
DataBuffer<IGoods>dataBuffer=newDataBuffer<>();
//生产者执行的动作
Callable<IGoods>produceAction=()->
{
//首先生成一个随机的商品
IGoodsgoods=Goods.produceOne ();
//将商品加上共享数据区
dataBuffer.add (goods);
returngoods;
};
//消费者执行的动作
Callable<IGoods>consumerAction=()->
{
//从 PetStore 获取商品
IGoodsgoods=null;
goods=dataBuffer.fetch ();
returngoods;
};
//同时并发执行的线程数
finalintTHREAD_TOTAL= 20 ;
//线程池，用于多线程模拟测试
ExecutorServicethreadPool=Executors.newFixedThreadPool (THREAD_TOTAL);
//假定共 11 条线程，其中有 10 个消费者，但是只有 1 个生产者
finalintCONSUMER_TOTAL= 11 ;
finalintPRODUCE_TOTAL= 1 ;
for (inti= 0 ;i<PRODUCE_TOTAL; i++)
{
//生产者线程每生产一个商品，间隔 50 毫秒
threadPool.submit (newProducer (produceAction, 50 ));
}
for (inti= 0 ;i<CONSUMER_TOTAL; i++)
{
//消费者线程每消费一个商品，间隔 100 毫秒
threadPool.submit (newConsumer (consumerAction, 100 ));
}
}
}
```
###### 2. 9. 6 需要在 synchronized 同步块的内部使用 wait 和 notify

在调用同步对象的 wait () 和 notify () 系列方法时，“当前线程”必须拥有该对象的同步锁，也就
是说，wait () 和 notify () 系列方法需要在同步块中使用，否则 JVM 会抛出类似如下的异常：
java. lang. IllegalMonitorStateException
atjava.lang.Object.notify (NativeMethod)
at......$DataBuffer.add (CommunicatePetStore. java: 58 )
at...... lambda$main$ 0 (CommunicatePetStore. java: 103 )
at......actor.ProducerTask.run (ProducerTask. java: 54 )
at...... Executors$RunnableAdapter.call (Executors. java: 511 )
at...... FutureTask. run$$$capture (FutureTask. java: 266 )
atjava.util.concurrent.FutureTask.run (FutureTask. java)
at......runWorker (ThreadPoolExecutor. java: 1142 )
at......$Worker.run (ThreadPoolExecutor. java: 617 )
atjava.lang.Thread.run (Thread. java: 745 )


```
第 2 章 Java 内置锁的核心原理 | 159
```
为什么 wait () 和 notify () 不在 synchronized 同步块使用会抛出异常呢？这需要从 wait () 和 notify () 原
理说起。

wait () 方法的原理：首先 JVM 会释放当前线程的对象锁监视器的 Owner 资格；其次 JVM 会把当
前线程移入监视器的 WaitSet 队列，而这些操作都和对象锁监视器是相关的。
所以，wait () 方法必须在 synchronized 同步块的内部使用。在当前线程执行 wait () 方法前，必须
通过 synchronized () 方法成为对象锁的监视器的 Owner。
notify () 方法的原理：JVM 从对象锁的监视器的 WaitSet 队列移动一个线程到其 EntryList 队列，
这些操作都与对象锁的监视器有关。

所以，notify () 方法也必须在 synchronized 同步块的内部使用。在执行 notify () 方法前，当前线程
也必须通过 synchronized () 方法成为对象锁的监视器的 Owner。
下面介绍“等待－通知”模式的线程间通信要点。
调用 wait () 和 notify () 系列方法进行线程通信的要点如下：
1 ）调用某个同步对象 locko 的 wait () 和 notify () 类型方法前，必须要取得这个锁对象的监视锁，
所以，wait () 和 notify () 类型方法必须放在 synchronized (locko) 同步块中，如果没有获得监视锁，JVM
就会报 IllegalMonitorStateException 异常。
2 ）使用 wait () 方法时使用 while 进行条件判断：如果是在某种条件下进行等待，对条件的判断
不能使用 if 语句做一次性判断，而是使用 while 循环进行反复判断。只有这样才能在线程被唤醒后继
续检查 wait 的条件，并在条件没有满足的情况下继续等待。

```
下面的代码使用 while 循环进行条件判断是正确的：
publicTfetch () throwsException
{
while (amount<= 0 )
{
synchronized (NOT_EMPTY)
{
Print.tcfo ("队列已经空了！");
//等待未空通知
NOT_EMPTY.wait ();
}
}
//省略其他
}
下面的代码使用 if 进行条件判断是不正确的：
publicTfetch () throwsException
{
if (amount<= 0 )
{
synchronized (NOT_EMPTY)
{
Print.tcfo ("队列已经空了！");
//等待未空通知
NOT_EMPTY.wait ();
}
}
//省略其他
}
```

# 第 3 章

## CAS 原理与 JUC 原子类

由于 JVM 的 synchronized 重量级锁涉及操作系统（如 Linux）内核态下的互斥锁的使用，其线程
阻塞和唤醒都涉及进程在用户态和到内核态的频繁切换，导致重量级锁开销大、性能低。而 JVM
的 synchronized 轻量级锁使用 CAS（CompareAndSwap，比较并交换）进行自旋抢锁，CAS 是 CPU
指令级的原子操作并处于用户态下，所以 JVM 轻量级锁开销较小。
本章首先为大家着重介绍一下 CAS 原理和弊端，然后介绍一下基于 CAS 实现的 JUC 原子类。

#### 3. 1 什么是 CAS

JDK 5 所增加的 JUC（java. util. concurrent）并发包对操作系统的底层 CAS 原子操作进行了封装，
为上层 Java 程序提供了 CAS 操作的 API。

###### 3. 1. 1 Unsafe 类中的 CAS 方法

Unsafe 是位于 sun. misc 包下的一个类，主要提供一些用于执行低级别、不安全的底层操作，如
直接访问系统内存资源、自主管理内存资源等，Unsafe 大量的方法都是原生（native）方法，基于
C++语言实现，这些方法在提升 Java 运行效率、增强 Java 语言底层资源操作能力方面起到了很大的
作用。
Unsafe 类的全限定名为 sun. misc. Unsafe，从名字中我们可以看出这个类对普通程序员来说是
“危险”的，一般的应用开发都不会涉及此类，Java 官方也不建议直接在应用程序中使用。

```
为什么此类取名为 Unsafe 呢？由于使用 Unsafe 类可以像 C 语言一样使用指针操
作内存空间，这无疑增加了指针相关问题、内存泄漏问题的出现概率。总之，在程序中过度
使用 Unsafe 类会使得程序出错的概率变大，使得安全的语言 Java 变得不再“安全”，因此对
Unsafe 的使用一定要慎重。
```
```
操作系统层面的 CAS 是一条 CPU 的原子指令（cmpxchg 指令），正是由于该指令具备了原子性，
```

```
第 3 章 CAS 原理与 JUC 原子类 | 161
```
因此使用 CAS 操作数据时不会造成数据不一致的问题，Unsafe 提供的 CAS 方法直接通过 native 方式
（封装 C++代码）调用了底层的 CPU 指令 cmpxchg。
完成 Java 应用层的 CAS 操作主要涉及的 Unsafe 方法调用，具体如下：
1 ）获取 Unsafe 实例。
2 ）调用 Unsafe 提供的 CAS 方法，这些方法主要封装了底层 CPU 的 CAS 原子操作。
3 ）调用 Unsafe 提供的字段偏移量方法，这些方法用于获取对象中的字段（属性）偏移量，此
偏移量值需要作为参数提供给 CAS 操作。

1 .获取 Unsafe 实例
Unsafe 类是一个 final 修饰的不允许继承的最终类，而且其构造函数是 private 类型的方法，具体
的源码如下：
publicfinalclassUnsafe{
privatestaticfinalUnsafetheUnsafe;
publicstaticfinalintINVALID_FIELD_OFFSET=- 1 ;
privatestaticnativevoidregisterNatives ();
//构造函数是 private 的，不允许外部实例化
privateUnsafe (){
}
...
}
因此，我们无法在外部对 Unsafe 进行实例化，那么怎么获取 Unsafe 的实例呢？可以通过反射的
方式自定义的获取 Unsafe 实例的辅助方法，代码如下：
packagecom. crazymakercircle. util;
//省略 import
publicclassJvmUtil
{
//自定义的获取 Unsafe 实例的辅助方法
publicstaticUnsafegetUnsafe ()
{
try
{
FieldtheUnsafe=Unsafe.class.getDeclaredField ("theUnsafe");
theUnsafe.setAccessible (true);
return (Unsafe) theUnsafe.get (null);
}catch (Exceptione)
{
thrownewAssertionError (e);
}
}
//省略不相关代码
}
2 .调用 Unsafe 提供的 CAS 方法
Unsafe 提供的 CAS 方法主要如下：
/**
* 定义在 Unsafe 类中的三个“比较并交换”原子方法
*@paramo 需要操作的字段所处的对象
*@paramoffset 需要操作的字段的偏移量（相对的，相对于对象头）
*@paramexpected 期望值（旧的值）


162 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

*@paramupdate 更新值（新的值）
*@return true 更新成功 |false 更新失败
*/
publicfinalnativebooleancompareAndSwapObject (Objecto, longoffset, Objectexpected,
Objectupdate);
publicfinalnativebooleancompareAndSwapInt (Objecto, longoffset, intexpected,
intupdate);
publicfinalnativebooleancompareAndSwapLong (Objecto, longoffset, longexpected,
longupdate);
Unsafe 提供的 CAS 方法包含 4 个操作数——字段所处的对象、字段内存位置、预期原值及新值。
在执行 Unsafe 的 CAS 方法时，这些方法首先将内存位置的值与预期值（旧的值）比较，如果相匹配，
那么处理器会自动将该内存位置的值更新为新值，并返回 true；如果不匹配，处理器不做任何操作，
并返回 false。
Unsafe 的 CAS 操作会将第一个参数（对象的指针、地址）与第二个参数（字段偏移量）组合在
一起，计算出最终的内存操作地址。

3 .调用 Unsafe 提供的偏移量相关
Unsafe 提供的获取字段（属性）偏移量的相关操作主要如下：
/**
* 定义在 Unsafe 类中的几个获取字段偏移量的方法
*@paramo 需要操作字段的反射
*@return 字段的偏移量
*/
publicnativelongstaticFieldOffset (Fieldfield);
publicnativelongobjectFieldOffset (Fieldfield);
staticFieldOffset 方法用于获取静态属性 Field 在 Class 对象中的偏移量，在 CAS 操作静态属性时会
用到这个偏移量。objectFieldOffset () 方法用于获取非静态 Field（非静态属性）在 Object 实例中的偏
移量，在 CAS 操作对象的非静态属性时会用到这个偏移量。
一个获取非静态 Field（非静态属性）在 Object 实例中的偏移量的示例代码如下：
static
{
try
{
//获取反射的 Field 对象
OptimisticLockingPlus.class.getDeclaredField ("value");
//取得内存偏移
valueOffset=unsafe.objectFieldOffset ();
}catch (Exceptionex)
{
thrownewError (ex);
}
}

###### 3. 1. 2 使用 CAS 进行无锁编程

CAS 是一种无锁算法，该算法关键依赖两个值——期望值（就值）和新值，底层 CPU 利用原
子操作判断内存原值与期望值是否相等，如果相等就给内存地址赋新值，否则不做任何操作。


```
第 3 章 CAS 原理与 JUC 原子类 | 163
```
使用 CAS 进行无锁编程的步骤大致如下：
1 ）获得字段的期望值（oldValue）。
2 ）计算出需要替换的新值（newValue）。
3 ）通过 CAS 将新值（newValue）放在字段的内存地址上，如果 CAS 失败就重复第 1 ）步到第 2 ）
步，直到 CAS 成功，这种重复俗称 CAS 自旋。

使用 CAS 进行无锁编程的伪代码如下：
do
{
获得字段的期望值（oldValue）；
计算出需要替换的新值（newValue）；
}while (! CAS (内存地址，oldValue，newValue))
下面用一个简单的例子对以上伪代码进行举例说明。
假如某个内存地址（某对象的属性）的值为 100 ，现在有两个线程（线程 A 和线程 B）使用 CAS
无锁编程对该内存地址进行更新，线程 A 欲将其值更新为 200 ，线程 B 欲将其值更新为 300 ，具体如
图 3 - 1 所示。

图 3 - 1 两个线程 A、B 需要对同一个内存地址进行更新
线程是并发执行的，谁都有可能先执行。但是 CAS 是原子操作，对同一个内存地址的 CAS 操
作在同一时刻只能执行一个。因此，在这个例子中，要么线程 A 先执行，要么线程 B 先执行。假设
线程 A 的 CAS（ 100 , 200 ）执行在前，由于内存地址的旧值 100 与该 CAS 的期望值 100 相等，所以线
程 A 会操作成功，内存地址的值被更新为 200 。
线程 A 执行 CAS（ 100 , 200 ）成功之后，内存地址的值如图 3 - 2 所示。

图^3 -^2 线程 A 执行 CAS（^100 ,^200 ）成功之后内存地址的值
接下来执行线程 B 的 CAS（ 100 , 300 ）操作，此时内存地址的值为 200 ，不等于 CAS 的期望值 100 ，
线程 B 操作失败。线程 B 只能自旋，开始新的循环，这一轮循环首先获取到内存地址的值 200 ，然后进
行 CAS（ 200 , 300 ）操作，这一次内存地址的值与 CAS 的预期值（oldValue）相等，线程 B 操作成功。
当 CAS 内存地址的值与预期值比较时，如果相等，就证明内存地址的值没有被修改，可以替


164 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

换成新值，然后继续往下运行；如果不相等，就说明内存地址的值已经被修改，放弃替换操作，然
后重新自旋。当并发修改的线程少，冲突出现的机会少时，自旋的次数也会很少，CAS 性能会很高；
当并发修改的线程多，冲突出现的机会多时，自旋的次数也会很多，CAS 性能会大大降低。所以，
提升 CAS 无锁编程效率的关键在于减少冲突的机会。

###### 3. 1. 3 使用无锁编程实现轻量级安全自增

在第 1 章开头讲到第二个面试故事中，临行时笔者给候选人 Y 君建议回去做一个线程安全的自增
小实验：使用 10 个线程，对一个共享的变量，每个线程自增 100 万次，看看最终的结果是不是 1000 万。
在第 2 章学习 synchronized 关键字时提供了一个线程安全的自增实现版本。由于在争用激烈的场
景下，synchronized 内置锁会膨胀为重量级锁，因此第 2 章的实现版本实际上是一个低性能的实现版本。
这里使用 CAS 无锁编程算法实现一个轻量级的安全自增实现版本：总计 10 个线程并行运行，
每条线程通过 CAS 自旋对一个共享数据进行自增运算，并且每个线程需要成功自增运算 1000 次。
基于 CAS 无锁编程的安全自增实现版本的具体代码如下：
packagecom. crazymakercircle. cas;
//省略 import
publicclassTestCompareAndSwap
{
//基于 CAS 无锁实现的安全自增
staticclassOptimisticLockingPlus
{
//并发数量
privatestaticfinalintTHREAD_COUNT= 10 ;
//内部值，使用 volatile 保证线程可见性
private volatileintvalue;//值
//不安全类
privatestaticfinalUnsafeunsafe=getUnsafe ();;
//value 的内存偏移（相对与对象头部的偏移，不是绝对偏移）
privatestaticfinallongvalueOffset;
//统计失败的次数
privatestaticfinalAtomicLongfailure=newAtomicLong ( 0 );
static
{
try
{
//取得 value 属性的内存偏移
valueOffset=unsafe.objectFieldOffset (
OptimisticLockingPlus.class.getDeclaredField ("value"));
Print.tco ("valueOffset:="+valueOffset);
}catch (Exceptionex)
{
thrownewError (ex);
}
}
//通过 CAS 原子操作，进行“比较并交换”
publicfinalbooleanunSafeCompareAndSet (intoldValue, intnewValue)
{
//原子操作：使用 unsafe 的“比较并交换”方法进行 value 属性的交换
returnunsafe.compareAndSwapInt (this, valueOffset, oldValue, newValue);


```
第 3 章 CAS 原理与 JUC 原子类 | 165
```
}
//使用无锁编程实现安全的自增方法
publicvoidselfPlus ()
{
intoldValue=value;
//通过 CAS 原子操作，如果操作失败就自旋，直到操作成功
do
{
//获取旧值
oldValue=value;
//统计无效的自旋次数
if (i++> 1 )
{
//记录失败的次数
failure.incrementAndGet ();
}
}while (! unSafeCompareAndSet (oldValue, oldValue+ 1 ));
}
//测试用例入口方法
publicstaticvoidmain (String[]args) throwsInterruptedException
{
finalOptimisticLockingPluscas=newOptimisticLockingPlus ();
//倒数闩，需要倒数 THREAD_COUNT 次
CountDownLatchlatch=newCountDownLatch (THREAD_COUNT);
for (inti= 0 ;i<THREAD_COUNT; i++)
{
//提交 10 个任务
ThreadUtil.getMixedTargetThreadPool (). submit (()->
{
//每个任务累加 1000 次
for (intj= 0 ;j< 1000 ;j++)
{
cas.selfPlus ();
}
latch.countDown (); //执行完一个任务，倒数闩减少一次
});
}
latch.await (); //主线程等待倒数闩倒数完毕
Print.tco ("累加之和："+cas. value);
Print.tco ("失败次数："+cas.failure.get ());
}
}
}
运行以上的示例程序，输出的结果如下：
[main]：valueOffset:= 12
[main]：累加之和： 10000
[main]：失败次数： 707
从上面的输出结果可以看出，使用 Unsafe.objectFieldOffset (...) 方法所获取到的 value 属性的偏移
量为 12 。为什么 value 属性的偏移量值为 12 呢？接下来为大家进行一下详细地分析。

###### 3. 1. 4 字段偏移量的计算

```
使用 Unsafe.objectFieldOffset (...) 方法获取到的 Object 字段（也叫 Object 成员属性）的偏移量值，
```

166 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

是字段相对于 Object 头部的偏移量，是一个相对的内存地址值，不是绝对的内存地址值。
首先回顾一下 3. 1. 3 节用到的 OptimisticLockingPlus 类，该类所包含的字段如下：
//模拟 CAS 算法
staticclassOptimisticLockingPlus
{ //静态常量：线程数
privatestaticfinalintTHREAD_COUNT= 10 ;
//成员属性：包装的值
volatileprivateintvalue;
//静态常量：JDK 不安全类的实例
privatestaticfinalUnsafeunsafe=JvmUtil.getUnsafe ();
//静态常量：value 成员的相对偏移（相对于对象头）
privatestaticfinallongvalueOffset;
//静态常量：CAS 的失败次数
privatestaticfinalAtomicLongfailure=newAtomicLong ( 0 );
//省略其他不相干代码
}
虽然 OptimisticLockingPlus 类有 5 个字段，但是其中有 4 个是静态字段，属于类的成员而不是对
象的成员，真正属于对象的字段只有其中的 value 字段。所以，一个 OptimisticLockingPlus 类对象的
大致结构如图 3 - 3 所示。

图 3 - 3 一个 OptimisticLockingPlus 类的对象结构
通过图 3 - 3 可以看出，在 64 位的 JVM 堆区中一个 OptimisticLockingPlus 对象的 ObjectHeader（头
部）占用了 12 字节，其中 MarkWord 占用了 8 字节（ 64 位），压缩过的 KlassPointer 占用了 4 字节。
接在 ObjectHeader 之后的就是成员属性 value 的内存区域，所以 value 属性相对于 ObjectHeader 的偏移
量为 12 。
另外，也可以通过 JOL 工具查看 OptimisticLockingPlus 成员属性 value 的内存相对偏移，具体代
码如下：


```
第 3 章 CAS 原理与 JUC 原子类 | 167
```
packagecom. crazymakercircle. cas;
//省略 import
publicclassTestCompareAndSwap
{
@Test
publicvoidprintObjectStruct ()
{
//创建一个对象
OptimisticLockingPlusobject=newOptimisticLockingPlus ();
//给成员赋值
object. value= 100 ;
//通过 JOL 工具输出内存布局
Stringprintable=ClassLayout.parseInstance (object). toPrintable ();
Print.fo ("object="+printable);
}
//省略不相关代码
}
运行程序，输出的几个如下：
[TestCompareAndSwap. printObjectStruct]：objectinternals:
OFFSET SIZE TYPEDESCRIPTION VALUE
0 4 (objectheader) 01000000 ( 00000001000000000000000000000000 )( 1 )
4 4 (objectheader) 00000000 ( 00000000000000000000000000000000 )( 0 )
8 4 (objectheader) 500801 f 8 ( 01010000000010000000000111111000 )
(- 134150064 )
12 4 intOptimisticLockingPlus. value 100
Instancesize: 16 bytes
Spacelosses: 0 bytesinternal+ 0 bytesexternal= 0 bytestotal
从以上 JOL 输出的结果可以看出，一个 TestCompareAndSwap 对象的 ObjectHeader 占用了 12 字节，
而 value 属性的内存位置紧挨在 ObjectHeader 之后，所以 value 属性的相对偏移量值为 12 。

#### 3. 2 JUC 原子类

在多线程并发执行时，诸如“++”或“--”类的运算不具备原子性，不是线程安全的操作。通
常情况下，大家会使用 synchronized 将这些线程不安全的操作变成同步操作，但是这样会降低并发
程序的性能。所以，JDK 为这些类型不安全的操作提供了一些原子类，与 synchronized 同步机制相
比，JDK 原子类基于 CAS 轻量级原子操作实现，使得程序运行效率变得更高。

###### 3. 2. 1 JUC 中的 Atomic 原子操作包

Atomic 操作翻译成中文是指一个不可中断的操作，
即使在多个线程一起执行 Atomic 类型操作的时候，一个
操作一旦开始，就不会被其他线程中断。所谓 Atomic 类，
指的是具有原子操作特征的类。

JUC 并发包中原子类的位置
JUC 并发包中原子类都存放在 java. util. concurrent.
atomic 类路径下，具体如图 3 - 4 所示。
图^3 -^4 JUC 中的 Atomic 原子操作包中的类


168 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

根据操作的目标数据类型，可以将 JUC 包中的原子类分为 4 类：基本原子类、数组原子类、原
子引用类和字段更新原子类。

（ 1 ）基本原子类
基本原子类的功能是通过原子方式更新 Java 基础类型变量的值。基本原子类主要包括以下三个：
 AtomicInteger：整型原子类。
 AtomicLong：长整型原子类。
 AtomicBoolean：布尔型原子类。
（ 2 ）数组原子类
数组原子类的功能是通过原子方式更新数组中的某个元素的值。数组原子类主要包括了以下
三个：

 AtomicIntegerArray：整型数组原子类。
 AtomicLongArray：长整型数组原子类。
 AtomicReferenceArray：引用类型数组原子类。
（ 3 ）引用原子类
引用原子类主要包括以下三个：
 AtomicReference：引用类型原子类。
 AtomicMarkableReference：带有更新标记位的原子引用类型。
 AtomicStampedReference：带有更新版本号的原子引用类型。
AtomicMarkableReference 类将 boolean 标记与引用关联起来，可以解决使用 AtomicBoolean 进行
原子方式的更新时可能出现的 ABA 问题。
AtomicStampedReference 类将整数值与引用关联起来，可以解决使用 AtomicInteger 进行原子方
式的更新时可能出现的 ABA 问题。

（ 4 ）字段更新原子类
字段更新原子类主要包括以下三个：
 AtomicIntegerFieldUpdater：原子更新整型字段的更新器。
 AtomicLongFieldUpdater：原子更新长整型字段的更新器。
 AtomicReferenceFieldUpdater：原子更新引用类型里的字段。
首先介绍基础原子类。由于 AtomicInteger、AtomicLong、AtomicBoolean 三个基础原子类所提
供的方法几乎相同，因此这里以 AtomicInteger 为例来介绍。

###### 3. 2. 2 基础原子类 AtomicInteger

```
基础原子类 AtomicInteger 常用的方法主要如下：
publicfinalintget () //获取当前的值
publicfinalintgetAndSet (intnewValue) //获取当前的值，然后设置新的值
publicfinalintgetAndIncrement () //获取当前的值，然后自增
```

```
第 3 章 CAS 原理与 JUC 原子类 | 169
```
publicfinalintgetAndDecrement () //获取当前的值，然后自减
publicfinalintgetAndAdd (intdelta) //获取当前的值，并加上预期的值
booleancompareAndSet (intexpect, intupdate) //通过 CAS 方式设置整数值
下面是一个基础原子类 AtomicInteger 的使用示例，具体代码如下：
packagecom. crazymakercircle. cas;
//省略 import
publicclassAtomicTest
{
@Test
public voidatomicIntegerTest ()
{
inttempvalue= 0 ;
//定义一个整数原子类实例，赋值到变量 i
AtomicIntegeri=newAtomicInteger ( 0 );
//取值，然后设置一个新值
tempvalue=i.getAndSet ( 3 );
//输出 tempvalue: 0 ; i: 3
Print.fo ("tempvalue: "+tempvalue+"; i: "+i.get ());
//取值，然后自增
tempvalue=i.getAndIncrement ();
//输出 tempvalue: 3 ; i: 4
Print.fo ("tempvalue: "+tempvalue+"; i: "+i.get ());
//取值，然后增加 5
tempvalue=i.getAndAdd ( 5 );
//输出 tempvalue: 4 ; i: 9
Print.fo ("tempvalue: "+tempvalue+"; i: "+i.get ());
//CAS 交换
booleanflag=i.compareAndSet ( 9 , 100 );
//输出 flag: true; i: 100
Print.fo ("flag: "+flag+"; i: "+i.get ());
}
}
一个基础原子类的综合示例
在多线程环境下，如果涉及基本数据类型的并发操作，不建议采用 synchronized 重量级锁进行
线程同步，而是建议优先使用基础原子类保障并发操作的线程安全性。
接下来通过一个使用原子类进行安全自增的综合示例展示一下基础原子类的使用，具体代码
如下：
packagecom. crazymakercircle. cas;
//省略 import
publicclassAtomicTest
{
@Test
publicstaticvoidmain (String[]args) throwsInterruptedException
{
CountDownLatchlatch=newCountDownLatch (THREAD_COUNT);
//定义一个整数原子类实例，赋值到变量 i
AtomicIntegeratomicInteger=newAtomicInteger ( 0 );
for (inti= 0 ;i<THREAD_COUNT; i++)
{
//创建 10 个线程，模拟多线程环境
ThreadUtil.getMixedTargetThreadPool (). submit (()->
{


170 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

for (intj= 0 ;j< 1000 ;j++)
{
atomicInteger.getAndIncrement ();
}
latch.countDown ();
});
}
latch.await ();
Print.tco ("累加之和："+atomicInteger.get ());
}
//省略不相关代码
}
运行以上程序，结果如下：
[main]：累加之和： 10000
运行以上演示示例，通过结果可以看出： 10 个线程每个线程累加 1000 次结果为 10000 ，该结果
与预期结果相同。所以，对基础原子类实例的并发操作是线程安全的。

###### 3. 2. 3 数组原子类 AtomicIntegerArray

```
使用原子的方式更新数组中的某个元素：
 AtomicIntegerArray：整型数组原子类。
 AtomicLongArray：长整型数组原子类。
 AtomicReferenceArray：引用类型数组原子类。
上面三个类提供的方法几乎相同，所以我们这里以 AtomicIntegerArray 为例来介绍。
AtomicIntegerArray 类常用方法如下：
//获取 index=i 位置元素的值
publicfinalintget (inti)
//返回 index=i 位置的当前的值，并将其设置为新值：newValue
publicfinalintgetAndSet (inti, intnewValue)
//获取 index=i 位置元素的值，并让该位置的元素自增
publicfinalintgetAndIncrement (inti)
//获取 index=i 位置元素的值，并让该位置的元素自减
publicfinalintgetAndDecrement (inti)
//获取 index=i 位置元素的值，并加上预期的值
publicfinalintgetAndAdd (intdelta)
//如果输入的数值等于预期值，就以原子方式将位置 i 的元素值设置为输入值（update）
booleancompareAndSet (intexpect, intupdate)
//最终将位置 i 的元素设置为 newValue
//lazySet 方法可能导致其他线程在之后的一小段时间内还是可以读到旧的值
publicfinalvoidlazySet (inti, intnewValue)
下面是一个数组原子类 AtomicIntegerArray 的使用示例，具体代码如下：
packagecom. crazymakercircle. cas;
//省略 import
publicclassAtomicTest
```

```
第 3 章 CAS 原理与 JUC 原子类 | 171
```
```
{
@Test
public voidtestAtomicIntegerArray (){
inttempvalue= 0 ;
//原始的数组
int[]array={ 1 , 2 , 3 , 4 , 5 , 6 };
//包装为原子数组
AtomicIntegerArrayi=newAtomicIntegerArray (array);
//获取第 0 个元素，然后设置为 2
tempvalue=i.getAndSet ( 0 , 2 );
//输出 tempvalue: 1 ; i:[ 2 , 2 , 3 , 4 , 5 , 6 ]
Print.fo ("tempvalue: "+tempvalue+"; i: "+i);
//获取第 0 个元素，然后自增
tempvalue=i.getAndIncrement ( 0 );
//输出 tempvalue: 2 ; i:[ 3 , 2 , 3 , 4 , 5 , 6 ]
Print.fo ("tempvalue: "+tempvalue+"; i: "+i);
//获取第 0 个元素，然后增加一个 delta 5
tempvalue=i.getAndAdd ( 0 , 5 );
//输出 tempvalue: 3 ; i:[ 8 , 2 , 3 , 4 , 5 , 6 ]
Print.fo ("tempvalue: "+tempvalue+"; i: "+i);
}
}
运行以上程序，结果如下：
[AtomicTest]：tempvalue: 1 ; i:[ 2 , 2 , 3 , 4 , 5 , 6 ]
[AtomicTest]：tempvalue: 2 ; i:[ 3 , 2 , 3 , 4 , 5 , 6 ]
[AtomicTest]：tempvalue: 3 ; i:[ 8 , 2 , 3 , 4 , 5 , 6 ]
```
###### 3. 2. 4 AtomicInteger 线程安全原理

基础原子类（以 AtomicInteger 为例）主要通过 CAS 自旋+volatile 相结合的方案实现，既保障了
变量操作的线程安全性，又避免了 synchronized 重量级锁的高开销，使得 Java 程序的执行效率大为
提升。

```
CAS 用于保障变量操作的原子性，volatile 关键字用于保障变量的可见性，二者
常常结合使用。至于什么是变量的线程可见性，具体请参见第 4 章。
```
下面以 AtomicInteger 源码为例分析一下原子类的 CAS 自旋 +volatile 相结合的实现方案。
AtomicInteger 源码的具体代码如下：
publicclassAtomicIntegerextendsNumberimplementsjava. io. Serializable{
//Unsafe 类实例
privatestaticfinalUnsafeunsafe=Unsafe.getUnsafe ();
//内部 value 值，使用 volatile 保证线程可见性
privatevolatileintvalue;
//value 属性值的地址偏移量
privatestaticfinallongvalueOffset;
static{
try{
//计算 value 属性值的地址偏移量
valueOffset=unsafe.objectFieldOffset (


172 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
AtomicInteger.class.getDeclaredField ("value"));
}catch (Exceptionex){thrownewError (ex);}
}
//初始化
publicAtomicInteger (intinitialValue){
value=initialValue;
}
//获取当前 value 值
publicfinalintget (){
returnvalue;
}
//方法：返回旧值并赋新值
publicfinalintgetAndSet (intnewValue){
for (;;){ //自旋
intcurrent=get (); //获取旧值
//以 CAS 方式赋值，直到成功返回
if (compareAndSet (current, newValue)) returncurrent;
}
}
//方法：封装底层的 CAS 操作，对比 expect (期望值) 与 value，若不同则返回 false
//若 expect 与 value 相同，则将新值赋给 value，并返回 true
publicfinalbooleancompareAndSet (intexpect, intupdate){
returnunsafe.compareAndSwapInt (this, valueOffset, expect, update);
}
//方法：安全自增 i++
publicfinalintgetAndIncrement (){
for (;;){ //自旋
intcurrent=get ();
intnext=current+ 1 ;
if (compareAndSet (current, next))
returncurrent;
}
}
//方法：自定义增量数
publicfinalintgetAndAdd (intdelta){
for (;;){ //自旋
intcurrent=get ();
intnext=current+delta;
if (compareAndSet (current, next))
returncurrent;
}
}
//方法：类似++I，返回自增后的值
publicfinalintincrementAndGet (){
for (;;){ //自旋
intcurrent=get ();
intnext=current+ 1 ;
if (compareAndSet (current, next))
returnnext;
}
}
//方法：返回加上 delta 后的值
publicfinalintaddAndGet (intdelta){
for (;;){ //自旋
intcurrent=get ();
```

```
第 3 章 CAS 原理与 JUC 原子类 | 173
```
intnext=current+delta;
if (compareAndSet (current, next))
returnnext;
}
}
//省略其他源码
}
AtomicInteger 源码中的主要方法都是通过 CAS 自旋实现的。CAS 自旋的主要操作为：
如果一次 CAS 操作失败，获取最新的 value 值后，再次进行 CAS 操作，直到成功。
另外，AtomicInteger 所包装的内部 value 成员是一个使用关键字 volatile 修饰的内部成员。关键
字 volatile 的原理比较复杂，简单地说，该关键字可以保证任何线程在任何时刻总能拿到该变量的最
新值，其目的在于保障变量值的线程可见性。

#### 3. 3 对象操作的原子性

基础的原子类型只能保证一个变量的原子操作，当需要对多个变量进行操作时，CAS 无法保
证原子性操作，这时可以用 AtomicReference（原子引用类型）保证对象引用的原子性。
简单来说，如果需要同时保障对多个变量操作的原子性，就可以把多个变量放在一个对象中
进行操作。
与对象操作的原子性有关的原子类型，除了引用类型原子类之外，还包括属性更新原子类。

###### 3. 3. 1 引用类型原子类

引用类型原子类包括以下：
 AtomicReference：基础的引用原子类。
 AtomicStampedReference：带印戳的引用原子类。
 AtomicMarkableReference：带修改标志的引用原子类。
上面三个类提供的方法几乎相同，所以这里以 AtomicReference 为例子来介绍。
下面为大家介绍一个简单的 AtomicReference 类的使用示例，首先定义一个普通的 POJO 对象，
代码如下：
packagecom. crazymakercircle. im. common. bean;
//省略 import
publicclassUserimplementsSerializable
{
Stringuid; //用户 ID
StringnickName; //昵称
public volatile intage; //年龄
publicUser (Stringuid, StringnickName)
{
this. uid=uid;
this. nickName=nickName;
}
@Override
publicStringtoString ()


174 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

{
return"User{"+
"uid='"+getUid ()+'\''+
", nickName='"+getNickName ()+'\''+
", platform="+getPlatform ()+
'}';
}
接下来介绍如何使用 AtomicReference 对 User 的引用进行原子性修改，代码如下：
packagecom. crazymakercircle. cas;
//省略 import
publicclassAtomicTest
{
@Test
publicvoidtestAtomicReference ()
{
//包装的原子对象
AtomicReference<User>userRef=newAtomicReference<User>();
//待包装的 User 对象
Useruser=newUser (" 1 ","张三");
//为原子对象设置值
userRef.set (user);
Print.tco ("userRefis: "+ userRef.get ());
//要使用 CAS 替换的 User 对象
UserupdateUser=newUser (" 2 ","李四");
//使用 CAS 替换
booleansuccess=userRef.compareAndSet (user, updateUser);
Print.tco ("casresultis: "+success);
Print.tco ("aftercas, userRefis: "+ userRef.get ());
}
//省略其他代码
}
运行以上示例，输出结果如下：
[main]：userRefis: User{uid=' 1 ', nickName='张三'}
[main]：casresultis:true
[main]：aftercas, userRefis: User{uid=' 2 ', nickName='李四'}
以上代码首先创建了一个 User 对象，然后把 User 对象包装到一个 AtomicReference 类型的引用
userRef 中，如果要修改 userRef 的包装值，就需要调用 compareAndSet () 方法才能完成。该方法就是
通过 CAS 操作 userRef，从而保证操作的原子性。

```
使用原子引用类型 AtomicReference 包装了 User 对象之后，只能保障 User 引用的
原子操作，对被包装的 User 对象的字段值修改时不能保证原子性，这点要切记。
```
###### 3. 3. 2 属性更新原子类

如果需要保障对象某个字段（或者属性）更新操作的原子性，需要用到属性更新原子类。属
性更新原子类有以下三个：

```
 AtomicIntegerFieldUpdater：保障整型字段的更新操作的原子性。
 AtomicLongFieldUpdater：保障长整型字段的更新操作的原子性。
 AtomicReferenceFieldUpdater：保障引用字段的更新操作的原子性。
```

```
第 3 章 CAS 原理与 JUC 原子类 | 175
```
由于上面三个类提供的方法几乎相同，所以我们这里以 AtomicIntegerFieldUpdater 为例来介绍。
使用属性更新原子类保障属性安全更新的流程大致需要两步：
 第一步，更新的对象属性必须使用 publicvolatile 修饰符。
 第二步，因为对象的属性修改类型原子类都是抽象类，所以每次使用都必须使用静态方法
newUpdater () 创建一个更新器，并且需要设置想要更新的类和属性。
下面为大家介绍一个简单的 AtomicIntegerFieldUpdater 类的使用示例，原子性更新 User 对象的
age 属性，代码如下：
@Test
publicvoidtestAtomicIntegerFieldUpdater ()
{
//使用静态方法 newUpdater () 创建一个更新器 updater
AtomicIntegerFieldUpdater<User>updater=
AtomicIntegerFieldUpdater.newUpdater (User. class,"age");
Useruser=newUser (" 1 ","张三");
//使用属性更新器的 getAndIncrement、getAndAdd 增加 user 的 age 值
Print.tco (updater.getAndIncrement (user)); // 1
Print.tco (updater.getAndAdd (user, 100 )); // 101
//使用属性更新器的 get 获取 user 的 age 值
Print.tco (updater.get (user)); // 101
}
运行以上代码，结果如下：
[main]： 0
[main]： 1
[main]： 101

#### 3. 4 ABA 问题

由于 CAS 原子操作性能高，因此其在 JUC 包中被广泛应用，只不过如果使用得不合理，CAS
原子操作会存在 ABA 问题。

###### 3. 4. 1 了解 ABA 问题

什么是 ABA 问题？举一个例子来说明。比如一个线程 A 从内存位置 M 中取出 V 1 ，另一个线程 B
也取出 V 1 。现在假设线程 B 进行了一些操作之后将 M 位置的数据 V 1 变成了 V 2 ，然后又在一些操作
之后将 V 2 变成 V 1 。之后，线程 A 进行 CAS 操作，但是线程 A 发现 M 位置的数据仍然是 V 1 ，最后线程
A 操作成功。尽管线程 A 的 CAS 操作成功，但是不代表这个过程是没有问题的，线程 A 操作的数据 V 1
可能已经不是之前的 V 1 ，而是被线程 B 替换过的 V 1 ，这就是 ABA 问题。
如果上面的例子令人迷糊，下面介绍一个更加翔实的、易懂的例子。
现有一个 LIFO（后进先出）堆栈，该堆栈使用单向链表实现，元素的插入和删除都发生在单
向链表的头部。这里假设该堆栈初始的结构如图 3 - 5 所示。


176 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

图 3 - 5 一个假设的堆栈（基于单向链表实现）的初始结构
假设线程 A 和线程 B 是两个在堆栈上进行并发操作的线程，其中线程 A 计划从 head 位置通过
CAS 进行元素 E 2 的弹出操作。
在线程 A 刚好启动 CAS 的执行，但是没有开始之前，线程 B 抢在前面从 head 位置中弹出元素 E 2 、
E 1 ，并压入了一个新元素 E 3 ，再压入了 E 2 ，线程 B 完成操作之后，栈帧的 head 位置的数据仍然是 E 2 。
这时切换到线程 A 执行，通过 CAS 操作发现 head 位置仍然是 E 2 ，线程 A 操作成功，元素 E 2 的弹
出操作，堆栈的 head 位置变成 E 1 。尽管线程 A 的 CAS 操作成功，但存在一个大的问题。具体问题是
什么呢？接下来一步一步进行分析。
以上线程 A 和线程 B 在堆栈上的弹出和压入操作的示意图如图 3 - 6 所示。

图 3 - 6 线程 A 和线程 B 在堆栈上的弹出和压入操作
线程 A 和线程 B 在堆栈上的弹出和压入操作具体步骤如下：
1 ）已知的栈顶为 E 2 ，这时线程 A 已经知道 E 2 .next 为 E 1 ，然后希望用 CAS（E 2 ,E 1 ）将栈顶 E 2
替换为 E 1 ，从而将 E 2 从堆栈弹出，操作完成后，堆栈里边的元素如图 3 - 7 所示。

图 3 - 7 线程 A 使用 CAS（E 2 ,E 1 ）将 E 2 弹出后的预期效果
2 ）但是在线程 A 开始执行 CAS（E 2 ，E 1 ）前，CPU 的时间片被线程 B 抢夺。线程 B 从 head 位置
中弹出元素 E 2 、E 1 ，然后压入了元素 E 3 、E 2 ，最终线程 B 又将 head 位置的数据变成 E 2 。线程 B 操作
完成后，堆栈里边的元素如图 3 - 8 所示。


```
第 3 章 CAS 原理与 JUC 原子类 | 177
```
图 3 - 8 线程 B 完成一系列执行后的堆栈结果
3 ）接下来，线程 A 重新获得 CPU 时间片，开始执行 CAS（E 2 ,E 1 ）操作。CAS 检测发现栈顶仍
为 E 2 ，所以 CAS（E 2 ,E 1 ）操作能成功，将栈顶变为 E 1 。由于 E 1 .next 为 NULL，此时的堆栈只有 1
个元素，堆栈里边的元素如图 3 - 9 所示。

图 3 - 9 线程 A 执行 CAS（E 2 ,E 1 ）后的堆栈结果
在线程 A 执行完成后，线程 B 之前压入的 E 3 元素处于游离状态，不再存在于堆栈中，平白无故
被丢掉了，这就是 ABA 问题引发的不正常状态。

###### 3. 4. 2 ABA 问题解决方案

很多乐观锁的实现版本都是使用版本号（Version）方式来解决 ABA 问题。乐观锁每次在执行
数据的修改操作时都会带上一个版本号，版本号和数据的版本号一致就可以执行修改操作并对版本
号执行加 1 操作，否则执行失败。因为每次操作的版本号都会随之增加，所以不会出现 ABA 问题，
因为版本号只会增加不会减少。

###### 3. 4. 3 使用 AtomicStampedReference 解决 ABA 问题

参考乐观锁的版本号，JDK 提供了一个类似 AtomicStampedReference 类来解决 ABA 问题。
AtomicStampReference 在 CAS 的基础上增加了一个 Stamp（印戳或标记），使用这个印戳可以用来
觉察数据是否发生变化，给数据带上了一种实效性的检验。
AtomicStampReference 的 compareAndSet () 方法首先检查当前的对象引用值是否等于预期引用，
并且当前印戳标志是否等于预期标志，如果全部相等，就以原子方式将引用值和印戳标志的值更新
为给定的更新值。
AtomicStampReference 的构造器有两个参数，具体如下：
//构造器，V 表示要引用的原始数据，initialStamp 表示最初的版本印戳（版本号）
AtomicStampedReference (VinitialRef, intinitialStamp)
AtomicStampReference 的常用的几个方法如下：
//获取被封装的数据
publicVgetRerference ();
//获取被封装的数据的版本印戳
publicintgetStamp ();
AtomicStampedReference 的 CAS 操作的定义如下：
publicbooleancompareAndSet (V expectedReference, //预期引用值
V newReference, //更新后的引用值
int expectedStamp, //预期印戳标志值
int newStamp) //更新后的印戳标志值


178 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

compareAndSet 方法的第一个参数是原 CAS 中的原参数，第二个参数是要替换后的新参数，第
三个参数是原来 CAS 数据旧的版本号，第四个参数表示替换后的版本号。
进行 CAS 操作时，若当前引用值等于预期引用值，并且当前印戳值等于预期印戳值，则以原
子方式将引用值和印戳值更新为给定的更新值。
下面是一个简单的 AtomicStampedReference 使用示例，通过两个线程分别带上印戳更新同一个
atomicStampedRef 实例的值，第一个线程会更新成功，而第二个线程更新失败，具体代码如下：
packagecom. crazymakercircle. cas;
//省略 import
publicclassAtomicTest
{
@Test
publicvoidtestAtomicStampedReference ()
{
CountDownLatchlatch=newCountDownLatch ( 2 );
AtomicStampedReference<Integer>atomicStampedRef=
newAtomicStampedReference<Integer>( 1 , 0 );
ThreadUtil.getMixedTargetThreadPool (). submit (newRunnable ()
{
@Override
publicvoidrun ()
{
booleansuccess=false;
intstamp=atomicStampedRef.getStamp ();
Print.tco ("beforesleep 500 :value="
+atomicStampedRef.getReference ()
+"stamp="+atomicStampedRef.getStamp ());
//等待 500 毫秒
sleepMilliSeconds ( 500 );
success=atomicStampedRef.compareAndSet ( 1 , 10 ,stamp, stamp+ 1 );
Print.tco ("aftersleep 500 cas 1 :success="+success
+"value="+atomicStampedRef.getReference ()
+"stamp="+atomicStampedRef.getStamp ());
//增加印戳值，然后更新，如果印戳被其他线程改了，则会更新失败
stamp++;
success=atomicStampedRef.compareAndSet ( 10 , 1 ,stamp, stamp+ 1 );
Print.tco ("after sleep 500 cas 2 :success="+success
+"value="+atomicStampedRef.getReference ()
+"stamp="+atomicStampedRef.getStamp ());
latch.countDown ();
}
});
ThreadUtil.getMixedTargetThreadPool (). submit (newRunnable ()
{
@Override
publicvoidrun ()
{
booleansuccess=false;
intstamp=atomicStampedRef.getStamp ();
//stamp= 0
Print.tco ("beforesleep 1000 :value="
+atomicStampedRef.getReference ()
+"stamp="+atomicStampedRef.getStamp ());
//等待 1000 毫秒
sleepMilliSeconds ( 1000 );


```
第 3 章 CAS 原理与 JUC 原子类 | 179
```
```
Print.tco ("aftersleep 1000 :stamp="+atomicStampedRef.getStamp ());
//stamp= 1 ，这个值实际已经被修改了
success=atomicStampedRef.compareAndSet ( 1 , 20 ,stamp, stamp++);
Print.tco ("aftercas 31000 :success="+success
+"value="+atomicStampedRef.getReference ()
+"stamp="+atomicStampedRef.getStamp ());
latch.countDown ();
}
});
latch.await ();
}
...
}
运行以上示例，输出结果如下：
[apppool- 1 - mixed- 2 ]：beforesleep 1000 :value= 1 stamp= 0
[apppool- 1 - mixed- 1 ]：beforesleep 500 :value= 1 stamp= 0
[apppool- 1 - mixed- 1 ]：aftersleep 500 cas 1 :success=truevalue= 10 stamp= 1
[apppool- 1 - mixed- 1 ]：after sleep 500 cas 2 :success=truevalue= 1 stamp= 2
[apppool- 1 - mixed- 2 ]：aftersleep 1000 :stamp= 2
[apppool- 1 - mixed- 2 ]：aftercas 31000 :success=falsevalue= 1 stamp= 2
```
###### 3. 4. 4 使用 AtomicMarkableReference 解决 ABA 问题

AtomicMarkableReference 是 AtomicStampedReference 的简化版，不关心修改过几次，仅仅关心
是否修改过。因此，其标记属性 mark 是 boolean 类型，而不是数字类型，标记属性 mark 仅记录值是
否修改过。
AtomicMarkableReference 适用于只要知道对象是否被修改过的场景，而不适用于对象被反复
修改的场景。
下面是一个简单的 AtomicMarkableReference 使用示例，通过两个线程分别更新同一个
atomicRef 的值，第一个线程会更新成功，而第二个线程更新失败，具体代码如下：
packagecom. crazymakercircle. cas;
//省略 import
publicclassAtomicTest
{
@Test
publicvoidtestAtomicMarkableReference () throwsInterruptedException
{
CountDownLatchlatch=newCountDownLatch ( 2 );
AtomicMarkableReference<Integer>atomicRef=
newAtomicMarkableReference<Integer>( 1 ,false);
ThreadUtil.getMixedTargetThreadPool (). submit (newRunnable ()
{
@Override
publicvoidrun ()
{
booleansuccess=false;
intvalue=atomicRef.getReference ();
booleanmark=getMark (atomicRef);
Print.tco ("beforesleep 500 :value="+value+"mark="+mark);
//等待 500 毫秒
sleepMilliSeconds ( 500 );
success=atomicRef.compareAndSet ( 1 , 10 ,mark,! mark);


180 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
Print.tco ("aftersleep 500 cas 1 :success="+success
+"value="+atomicRef.getReference ()
+"mark="+getMark (atomicRef));
latch.countDown ();
}
});
ThreadUtil.getMixedTargetThreadPool (). submit (newRunnable ()
{
@Override
publicvoidrun ()
{
booleansuccess=false;
intvalue=atomicRef.getReference ();
booleanmark=getMark (atomicRef);
Print.tco ("beforesleep 1000 :value="
+atomicRef.getReference ()
+"mark="+mark);
//等待 1000 毫秒
sleepMilliSeconds ( 1000 );
Print.tco ("aftersleep 1000 :mark="+getMark (atomicRef));
success=atomicRef.compareAndSet ( 1 , 20 ,mark,! mark);
Print.tco ("aftercas 31000 :success="+success
+"value="+atomicRef.getReference ()
+"mark="+getMark (atomicRef));
latch.countDown ();
}
});
latch.await ();
}
//取得修改标志值
privatebooleangetMark (AtomicMarkableReference<Integer>atomicRef)
{
boolean[]markHolder={false};
intvalue=atomicRef.get (markHolder);
returnmarkHolder[ 0 ];
}
//省略其他
}
运行以上示例，输出结果如下：
[apppool- 1 - mixed- 1 ]：beforesleep 500 :value= 1 mark=false
[apppool- 1 - mixed- 2 ]：beforesleep 1000 :value= 1 mark=false
[apppool- 1 - mixed- 1 ]：aftersleep 500 cas 1 :success= true value= 10 mark=true
[apppool- 1 - mixed- 2 ]：aftersleep 1000 :mark=true
[apppool- 1 - mixed- 2 ]：aftercas 31000 :success= false value= 10 mark=true
```
#### 3. 5 提升高并发场景下 CAS 操作的性能

在争用激烈的场景下，会导致大量的 CAS 空自旋。比如，在大量的线程同时并发修改一个
AtomicInteger 时，可能有很多线程会不停地自旋，甚至有的线程会进入一个无限重复的循环中。
大量的 CAS 空自旋会浪费大量的 CPU 资源，大大降低了程序的性能。

```
除了存在 CAS 空自旋之外，在 SMP 架构的 CPU 平台上，大量的 CAS 操作还可能
```

```
第 3 章 CAS 原理与 JUC 原子类 | 181
```
```
导致“总线风暴”，具体可参见第 5 章的内容。
```
```
在高并发场景下如何提升 CAS 操作性能呢？可以使用 LongAdder 替代 AtomicInteger。
```
###### 3. 5. 1 以空间换时间：LongAdder

Java 8 提供一个新的类 LongAdder，以空间换时间的方式提升高并发场景下 CAS 操作性能。
LongAdder 核心思想就是热点分离，与 ConcurrentHashMap 的设计思想类似：将 value 值分离成
一个数组，当多线程访问时，通过 Hash 算法将线程映射到数组的一个元素进行操作；而获取最终
的 value 结果时，则将数组的元素求和。
最终，通过 LongAdder 将内部操作对象从单个 value 值“演变”成一系列的数组元素，从而减小
了内部竞争的粒度。LongAdder 的演变如图 3 - 10 所示。

图 3 - 10 LongAdder 的操作对象由单个 value 值“演变”成了数组
下面是一个 LongAdder 和 AtomicLong 的对比实验，使用 10 个线程每个线程累加 1000 次，具体代
码如下：
packagecom. crazymakercircle. cas;
//省略 import
publicclassLongAdderVSAtomicLongTest
{
//每条线程的执行轮数
finalintTURNS= 100000000 ;
//对比测试用例一：使用 AtomicLong 完成 10 个线程累加 1000 次
@org. junit. Test
publicvoidtestAtomicLong ()
{
//并发任务数
finalintTASK_AMOUNT= 10 ;
//线程池，获取 CPU 密集型任务线程池
ExecutorServicepool=ThreadUtil.getCpuIntenseTargetThreadPool ();
//定义一个原子对象
AtomicLongatomicLong=newAtomicLong ( 0 );
//线程同步倒数闩
CountDownLatchcountDownLatch=newCountDownLatch (TASK_AMOUNT);
longstart=System.currentTimeMillis ();


182 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
for (inti= 0 ;i<TASK_AMOUNT; i++)
{
pool.submit (()->
{
try
{
for (intj= 0 ;j<TURNS; j++)
{
atomicLong.incrementAndGet ();
}
//Print.tcfo ("本线程累加完成");
}catch (Exceptione)
{
e.printStackTrace ();
}
//倒数闩，倒数一次
countDownLatch.countDown ();
});
}
try
{
//等待倒数闩完成所有的倒数操作
countDownLatch.await ();
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}
floattime=(System.currentTimeMillis ()-start)/ 1000 F;
//输出统计结果
Print.tcfo ("运行的时长为："+time);
Print.tcfo ("累加结果为："+atomicLong.get ());
}
//对比测试用例二：使用 LongAdder 完成 10 个线程累加 1000 次
@org. junit. Test
publicvoidtestLongAdder ()
{
//并发任务数
finalintTASK_AMOUNT= 10 ;
//线程池，获取 CPU 密集型任务线程池
ExecutorServicepool=ThreadUtil.getCpuIntenseTargetThreadPool ();
//定义一个 LongAdder 对象
LongAdderlongAdder=newLongAdder ();
//线程同步倒数闩
CountDownLatchcountDownLatch=newCountDownLatch (TASK_AMOUNT);
longstart=System.currentTimeMillis ();
for (inti= 0 ;i<TASK_AMOUNT; i++)
{
pool.submit (()->
{
try
{
for (intj= 0 ;j<TURNS; j++)
{
longAdder.add ( 1 );
}
}catch (Exceptione)
{
e.printStackTrace ();
```

```
第 3 章 CAS 原理与 JUC 原子类 | 183
```
}
//倒数闩，倒数一次
countDownLatch.countDown ();
});
}
try
{
//等待倒数闩完成所有的倒数操作
countDownLatch.await ();
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}
floattime=(System.currentTimeMillis ()-start)/ 1000 F;
//输出统计结果
Print.tcfo ("运行的时长为："+time);
Print.tcfo ("累加结果为："+longAdder.longValue ());
}
}
运行以上 testLongAdder () 测试用例，执行结果如下：
[main|LongAdderVSAtomicLongTest. testLongAdder]：运行的时长为： 2. 346
[main|LongAdderVSAtomicLongTest. testLongAdder]：累加结果为： 1000000000
为了进行速度的对比，可以多次运行以上的用例，每一次运行可以修改 TASK_AMOUNT（次
数常量）的值。测试 5 次，TASK_AMOUNT 值从 1000 到 1000000000 ，对比出来的速度倍数值如
表 3 - 1 所示。

表 3 - 1 LongAdder 和 AtomicLong 的对比实验
类型 1000 * 10 100000 * 10 10000000 * 10 100000000 * 10 1000000000 * 10
testAtomicLong 0. 083 0. 11 0. 375 17. 852 198. 434
testLongAdder 0. 126 0. 105 0. 362 2. 346 22. 867
倍数 65. 87 % 104. 76 % 103. 59 % 760. 95 % 867. 77 %
通过对比实验可以看到：当只有 10 个线程总计累加 10000 次的时候，AtomicLong 的性能更好。
随着累加次数的增加，CAS 操作的次数急剧增多，AtomicLong 的性能急剧下降。从对比实验的结
果可以看出，在 CAS 争用最为激烈的场景下，LongAdder 的性能是 AtomicLong 性能的 8 倍。

###### 3. 5. 2 LongAdder 的原理

AtomicLong 使用内部变量 value 保存着实际的 long 值，所有的操作都是针对该 value 变量进行。
也就是说，在高并发环境下，value 变量其实是一个热点，也就是 N 个线程竞争一个热点。重试线程
越多，就意味着 CAS 的失败概率越高，从而进入恶性 CAS 空自旋状态。
LongAdder 的基本思路就是分散热点，将 value 值分散到一个数组中，不同线程会命中到数组的
不同槽（元素）中，各个线程只对自己槽中的那个值进行 CAS 操作。这样热点就被分散了，冲突的
概率就小很多。
使用 LongAdder，即使线程数再多也不担心，各个线程会分配到多个元素上去更新，增加元素
个数就可以降低 value 的“热度”，AtomicLong 中的恶性 CAS 空自旋就解决了。


184 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

如果要获得完整的 LongAdder 存储的值，只要将各个槽中的变量值累加，返回最终的累加之后
的值即可。
LongAdder 的实现思路与 ConcurrentHashMap 中分段锁基本原理非常相似，本质上都是不同的
线程在不同的单元上进行操作，这样减少了线程竞争，提高了并发效率。
LongAdder 的设计体现了空间换时间的思想，不过在实际高并发场景下，数组元素所消耗的空
间可以忽略不计。

```
1 .LongAdder 实例的内部结构
一个 LongAdder 实例的内部结构，具体如图 3 - 11 所示。
```
图 3 - 11 一个 LongAdder 实例的内部结构
LongAdder 的内部成员包含一个 base 值和一个 cells 数组。在最初无竞争时，只操作 base 的值；
当线程执行 CAS 失败后，才初始 cells 数组，并为线程分配所对应的元素。
LongAdder 中没有类似于 AtomicLong 中的 getAndIncrement () 或者 incrementAndGet () 这样的原子
操作，所以只能通过 increment () 方法和 longValue () 方法的组合来实现更新和获取的操作。

2 .基类 Striped 64 内部三个重要的成员
LongAdder 继承于 Striped 64 类，base 值和 cells 数组都在 Striped 64 类定义。基类 Striped 64 内部三
个重要的成员如下：
/**
*成员一：存放 Cell 的哈希表，大小为 2 的幂
*/
transientvolatileCell[]cells;
/**
*成员二：基础值
* 1 .在没有竞争时会更新这个值
* 2 .在 cells 初始化时，cells 不可用，也会尝试将通过 cas 操作值累加到 base
*/
transientvolatilelongbase;
/**
*自旋锁，通过 CAS 操作加锁，为 0 表示 cells 数组没有处于创建、扩容阶段
*为 1 用于表示正在创建或者扩展 Cell 数组，不能进行新 Cell 元素的设置操作
*/


```
第 3 章 CAS 原理与 JUC 原子类 | 185
```
transientvolatileintcellsBusy;
Striped 64 内部包含一个 base 和一个 Cell[]类型的 cells 数组，cells 数组又叫哈希表。在没有竞争的
情况下，要累加的数通过 CAS 累加到 base 上；如果有竞争的话，会将要累加的数累加到 Cells 数组中
的某个 cell 元素里面。所以 Striped 64 的整体值 value 为 base+∑[ 0 ~n]cells。
Striped 64 的整体值 value 的获取函数如下：
publiclonglongValue (){
//longValue () 方法调用了 sum (), 累加所有 cell 的值
returnsum ();
}
/**
*将多个 cell 数组中的值加起来的和就类似于 AtomicLong 中的 value
*/
publiclongsum (){
Cell[]as=cells;
Cella;
longsum=base;
if (as!=null){
//累加所有 cell 的值
for (inti= 0 ;i<as. length;++i){
if ((a=as[i])!=null)
sum+=a.value;
}
}
returnsum;
}
Striped 64 的设计核心思路就是通过内部的分散计算来避免竞争，以空间换时间。LongAdder 的
base 类似于 AtomicInteger 里面的 value，在没有竞争的情况下，cells 数组为 null，这时只使用 base 做累
加；而一旦发生竞争，cells 数组就上场了。
cells 数组第一次初始化长度为 2 ，以后每次扩容都是变为原来的两倍，直到 cells 数组的长度大
于等于当前服务器 CPU 的核数。为什么呢？同一时刻，能持有 CPU 时间片而去并发操作同一个内存
地址的最大线程数最多也就是 CPU 的核数。
当存在线程争用时，每个线程被映射到 cells[threadLocalRandomProbe&cells. length]位置的 Cell
元素，该线程对 value 所做的累加操作就执行在对应的 Cell 元素的值上，最终相当于将线程绑定到了
cells 中的某个 cell 对象上。

```
3 .LongAdder 类的 add () 方法
作为示例，这里分析一下 LongAdder 类的 add () 方法，具体的源码如下：
/**
*自增 1
*/
publicvoidincrement (){
add ( 1 L);
}
/**
*自减 1
*/
publicvoiddecrement (){
add (- 1 L);
}
```

186 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

publicvoidadd (longx){
Cell[]as; longb, v; intm; Cella;
if ((as=cells)!=null|| //CASE 1
!casBase (b=base, b+x)){ //CASE 2
if (as==null||(m=as. length- 1 )< 0 || //CASE 3
(a=as[getProbe ()&m])==null|| //CASE 4
!(uncontended=a.cas (v=a.value, v+x))) //CASE 5
longAccumulate (x, null, uncontended);
}
}
首先介绍一下代码中的外层 if 块的两个条件语句 CASE 1 、CASE 2 ：
 条件语句 CASE 1 ：cells 数组不为 null，说明存在争用；在不存在争用的时候，cells 数组一
定为 null，一旦对 base 的 cas 操作失败，才会初始化 cells 数组。
 条件语句 CASE 2 ：如果 cells 数组为 null，表示之前不存在争用，并且此次 casBase 执行成功，
则表示基于 base 成员累加成功，add 方法直接返回；如果 casBase 方法执行失败，说明产生了
第一次争用冲突，需要对 cells 数组初始化，此时即将进入内层 if 块。
casBase 方法很简单，就是通过 UNSAFE 类的 CAS 设置成员变量 base 的值为 base+x（要累加的值），
casBase 方法的代码如下：
/**
*使用 CAS 来更新 base 值
*/
finalbooleancasBase (longcmp, longval){
returnUNSAFE.compareAndSwapLong (this, BASE, cmp, val);
}
如果 add (longx) 方法的 CASE 1 、CASE 2 两种条件满足一个，就继续执行内层 if 语句块，通过
Cell 元素进行累加，而不是通过 base 属性进行累加。
接下来介绍 add (longx) 方法的内层 if 语句块的三个条件语句 CASE 3 、CASE 4 、CASE 5 ：
 条件语句 CASE 3 ：as==null||(m=as. length- 1 )< 0 代表 cells 没有初始化。
 条件语句 CASE 4 ：指当前线程的哈希值在 cells 数组映射位置的 Cell 对象为空，意思是还没
有其他线程在同一个位置做过累加操作。
 条件语句 CASE 5 ：指当前线程的哈希值在 cells 数组映射位置的 Cell 对象不为空，然后在该
Cell 对象上进行 CAS 操作，设置其值为 v+x（x 为该 Cell 需要累加的值），但是 CAS 操作失败，
表示存在争用。
如果以上三个条件语句 CASE 3 、CASE 4 、CASE 5 有一个为真，就进入 longAccumulate 方法。
4 .LongAdder 类中的 longAccumulate () 方法
longAccumulate () 是 Striped 64 中重要的方法，实现不同的线程更新各自 Cell 中的值，其实现逻辑
类似于分段锁，具体的代码如下：
finalvoidlongAccumulate (longx, LongBinaryOperatorfn, booleanwasUncontended){
inth;//这个太重要，是线程对应的 **hash** 值
if ((h=getProbe ())== 0 ){
ThreadLocalRandom.current ();//forceinitialization
h=getProbe ();
wasUncontended=true;


```
第 3 章 CAS 原理与 JUC 原子类 | 187
```
}
//扩容意向，collide=true 可以扩容，collide=false 不可扩容
booleancollide=false;
//自旋，一直到操作成功
for (;;){
//as 表示 cells 引用
//a 表示当前线程命中的 cell
//n 表示 cells 数组长度
//v 表示期望值
Cell[]as; Cella; intn; longv;
//CASE 1 : 表示 cells 已经初始化了，当前线程应该将数据写入到对应的 cell 中
//这个大的 if 分支有三个小分支
if ((as=cells)!=null&&(n=as. length)> 0 ){
//CASE 1. 1 : true 表示下标位置的 cell 为 null，需要创建 newCell
if ((a=as[(n- 1 )&h])==null){
if (cellsBusy== 0 ){ //cells 数组没有处于创建、扩容阶段
Cellr=newCell (x); //Optimisticallycreate，写入 x
if (cellsBusy== 0 &&casCellsBusy ()){
booleancreated=false;
try{ //Recheckunderlock
Cell[]rs; intm, j;
if ((rs=cells)!=null&&
(m=rs. length)> 0 &&
rs[j=(m- 1 )&h]==null){
rs[j]=r;//这个是找到的空位置，把新 cell 放进去
created=true;
}
}finally{
cellsBusy= 0 ;
}
if (created)
break;
continue; //Slotisnownon-empty
}
}
collide=false;
}
//CASE 1. 2 ：当前线程竞争修改失败，wasUncontended 为 false
elseif (! wasUncontended) //CASalreadyknowntofail
wasUncontended=true; //Continueafterrehash
//CASE 1. 3 ：当前线程 rehash 过哈希值， **CAS** 更新 **Cell** ，如果更新成功就，退出循环
elseif (a.cas (v=a.value, ((fn==null)? v+x: fn.applyAsLong (v, x))))
break;
//CASE 1. 4 : 调整扩容意向，然后进入下一轮循环
elseif (n>=NCPU||cells!=as)
collide=false; //达到最大值，或者 as 值过期
//CASE 1. 5 : 设置扩容意向为 true，但是不一定真的发生扩容
if (! collide)
collide=true;
//CASE 1. 6 : 真正扩容的逻辑
elseif (cellsBusy== 0 &&casCellsBusy ()){
try{
if (cells==as){ //Expandtableunlessstale
Cell[]rs=newCell[n<< 1 ];
for (inti= 0 ;i<n;++i)


188 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
rs[i]=as[i];
cells=rs;
}
}finally{
cellsBusy= 0 ; //释放锁
}
collide=false;
continue; //Retrywithexpandedtable
}
h=advanceProbe (h); //重置（rehash）当前线程哈希值
}
//CASE 2 ：cells 还未初始化（as 为 null），并且 cellsBusy 加锁成功
elseif (cellsBusy== 0 &&cells==as&&casCellsBusy ()){
booleaninit=false;
try{ //Initializetable
if (cells==as){
Cell[]rs=newCell[ 2 ];//初始化数组
rs[h& 1 ]=newCell (x);//初始化元素，并且把值放进去
cells=rs;
init=true;
}
}finally{
cellsBusy= 0 ;
}
if (init)
break; // x 已经加上去了，并且完成初始化，退出循环
}
//CASE 3 ：当前线程 cellsBusy 加锁失败，表示其他线程正在初始化 cells
//所以当前线程将值累加到 base，注意 add (...) 方法调用此方法时 fn 为 null
elseif (casBase (v=base, ((fn==null)? v+x:
fn.applyAsLong (v, x))))
break; //在 base 操作成功时跳出自旋
}
}
longAccumulate 的自旋过程中，有三个大的 if 分支：
 CASE 1 ：表示 cells 已经初始化了，当前线程应该将数据写入到对应的 Cell 中。这里的细分
场景很多，情况复杂，稍后分开介绍。
 CASE 2 ：cells 还未初始化（as 为 null），本分支计划初始化 cells，在此之前开始执行 cellsBusy
加锁，并且要求 cellsBusy 加锁成功。如果一切顺利，这里进行初始化并设置值后退出。
 CASE 3 ：如果 cellsBusy 加锁失败，表示其他线程正在初始化 cells，所以当前线程将值累加
到 base 上。如果加成功则退出循环，否则持续循环。
CASE 1 表示当前线程应该将数据写入到对应的 cell 中，又分为以下几种细分情况：
 CASE 1. 1 ：表示当前线程对应的下标位置的 Cell 为 null，需要创建新 Cell。
 CASE 1. 2 ：wasUncontended 是 add (...) 方法传递进来的参数如果为 false，就表示 cells 已经被
初始化，并且线程对应位置的 Cell 元素也已经被初始化，但是当前线程对 Cell 元素的竞争修
改失败。如果 add 方法中条件语句 CASE 5 通过 CAS 设置 cells[m%cells. length]位置的 Cell 对象
的 value 值设置为 v+x 失败了，说明已经发生竞争，就将 wasUncontended 设置为 false。如果
wasUncontended 为 false，就需要重新计算 prob 的值，自旋操作进入下一轮循环。
 CASE 1. 3 ：无论执行 CASE 1 分支的哪个子条件，都会在末尾执行 h=advanceProb () 语句去
```

```
第 3 章 CAS 原理与 JUC 原子类 | 189
```
```
rehash 出一个新哈希值，然后会命中新的 cell，如果新命中的 Cell 不为空，在此分支进行 CAS
更新，将 Cell 的值更新为a.value+x，如果更新成功就跳出自旋操作；否则还得继续自旋。
 CASE 1. 4 ：调整 cells 数组的扩容意向，然后进入下一轮循环。如果 n>=NCPU 条件成立，
表示 cells 数组大小已经大于等于 CPU 核算，扩容意向改为 false，表示不扩容了；如果该条
件不成立，说明 cells 数组还可以扩容，尽管如此，如果 cells!=as 为 true，表示其他线程已经
扩容过了，也会将扩容意向改为 false，表示当前循环不扩容了。当前线程调到 CASE 1 分支
的末尾执行 rehash 操作重新计算 prob 的值，然后进入下一轮循环。
 CASE 1. 5 ：如果! collide=true 满足，就表示扩容意向不满足，设置扩容意向为 true，但是不
一定真的发生扩容；然后进入 CASE 1 分支末尾重新计算 prob 的值，接着进入下一轮循环。
 CASE 1. 6 ：执行真正扩容的逻辑。其条件一 cellsBusy== 0 为 true 表示当前 cellsBusy 的值为 0
（无锁状态），当前线程可以去竞争这把锁；其条件二 casCellsBusy () 表示当前线程获取锁
成功，CAS 操作 cellsBusy 改为 0 成功，可以执行扩容逻辑。
```
```
通过 longAccumulate 方法的实现逻辑可以看出，DougLea 的编程功力是如此的
深刻。
```
5 .LongAdder 类的 casCellsBusy () 方法
casCellsBusy 方法的代码很简单，就是将 cellsBusy 成员的值改为 1 ，表示目前的 cells 数组在初始
化或扩容中，具体的代码如下：
finalbooleancasCellsBusy (){
returnUNSAFE.compareAndSwapInt (this, CELLSBUSY, 0 , 1 );
}
casCellsBusy () 方法相当于锁的功能：当线程需要 cells 数组初始化或扩容时，需要调用
casCellsBusy () 方法，通过 CAS 方式将 cellsBusy 成员的值改为 1 ，如果修改失败，表示其他的线程正
在进行数组初始化或扩容的操作。只有 CAS 操作成功，cellsBusy 成员的值被改为 1 ，当前线程才能
执行 cells 数组初始化或扩容的操作。在 cells 数组初始化或扩容的操作执行完成之后，cellsBusy 成员
的值被改为 0 ，这时不需要进行 CAS 修改，直接修改即可，因为不存在争用。
当 cellsBusy 成员值为 1 时，表示 cells 数组正被某个线程执行初始化或扩容操作，其他线程不能
进行以下操作：

1 ）对 cells 数组执行初始化。
2 ）对 cells 数组执行扩容。
3 ）如果 cells 数组中某个元素为 null，就为该元素创建新的 Cell 对象。因为数组的结构正在修改，
所以其他线程不能创建新的 Cell 对象。

#### 3. 6 CAS 在 JDK 中的广泛应用

```
CAS 的优势主要有两点：
1 ）属于无锁编程，线程不存在阻塞和唤醒这些重量级的操作。
```

190 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
2 ）进程不存在用户态和内核态之间的运行切换，进程不需要承担频繁切换的开销。
下面主要总结一下 CAS 操作的弊端和规避措施。
```
###### 3. 6. 1 CAS 操作的弊端和规避措施

1 .CAS 操作的弊端
CAS 操作的弊端主要有以下 4 点。
（ 1 ）ABA 问题
使用 CAS 操作内存数据时，当数据发生过变化也能更新成功，如操作序列 A==>B==>A 时，最
后一个 CAS 的预期数据 A 实际已经发生过更改，但也能更新成功，这就产生了 ABA 问题。
ABA 问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候将版
本号加 1 ，那么操作序列 A==>B==>A 的就会变成 A 1 ==>B 2 ==>A 3 ，如果将 A 1 当作 A 3 的预期数据，
就会操作失败。
JDK 提供了两个类 AtomicStampedReference 和 AtomicMarkableReference 来解决 ABA 问题。比较
常用的是 AtomicStampedReference 类，该类的 compareAndSet 方法的作用是首先检查当前引用是否等
于预期引用，以及当前印戳是否等于预期印戳，如果全部相等，就以原子方式将引用和印戳的值一
同设置为新的值。

（ 2 ）只能保证一个共享变量之间的原子性操作
当对一个共享变量执行操作时，我们可以使用循环 CAS 的方式来保证原子操作，但是对多个
共享变量操作时，CAS 无法保证操作的原子性。
一个比较简单的规避方法为：把多个共享变量合并成一个共享变量来操作。
JDK 提供了 AtomicReference 类来保证引用对象之间的原子性，可以把多个变量放在一个
AtomicReference 实例后再进行 CAS 操作。比如有两个共享变量 i＝ 1 、j= 2 ，可以将二者合并成一个
对象，然后用 CAS 来操作该合并对象的 AtomicReference 引用。

（ 3 ）无效 CAS 会带来开销问题
自旋 CAS 如果长时间不成功（不成功就一直循环执行，直到成功为止），就会给 CPU 带来非
常大的执行开销。

（ 4 ）在部分 CPU 平台上存在“总线风暴”问题
CAS 操作和 volatile 一样也需要 CPU 进行通过 MESI 协议各个内核的“Cache 一致性”，会通过
CPU 的 BUS（总线）发送大量 MESI 协议相关的消息，产生“Cache 一致性流量”。因为总线被设计
为固定的“通信能力”，如果 Cache 一致性流量过大，总线将成为瓶颈，这就是所谓的“总线风暴”。

2 .提升 CAS 性能
提升 CAS 性能有效方式之一是以空间换时间，分散竞争热点。较为常见的方案为：
1 ）分散操作热点，使用 LongAdder 替代基础原子类 AtomicLong，LongAdder 将单个 CAS 热点
（value 值）分散到一个 cells 数组中。
2 ）使用队列削峰，将发生 CAS 争用的线程加入一个队列中排队，降低 CAS 争用的激烈程度。


```
第 3 章 CAS 原理与 JUC 原子类 | 191
```
JUC 中非常重要的基础类 AQS（抽象队列同步器）就是这么做的。

```
提升 CAS 性能有效方式之二是使用线程本地变量，从根本上避免竞争。
```
###### 3. 6. 2 CAS 操作在 JDK 中的应用

CAS 在 java. util. concurrent. atomic 包中的原子类、JavaAQS 及其显式锁、CurrentHashMap 等重要
并发容器类的实现都有非常广泛的应用。
在 java. util. concurrent. atomic 包的原子类（如 AtomicXXX 中）都使用了 CAS 保障对数字成员进行
操作的原子性。
java. util. concurrent 的大多数类（包括显式锁、并发容器）都是基于 AQS 和 AtomicXXX 实现的，
其中 AQS 通过 CAS 保障其内部双向队列队头、队尾操作的原子性。



# 第 4 章

## 可见性与有序性原理

原子性、可见性和有序性是并发编程所面临的三大问题。Java 通过 CAS 操作已解决了并发编程
中的原子性问题，本章为大家介绍 Java 如何解决剩余的另外两个问题——可见性和有序性。

#### 4. 1 CPU 物理缓存结构

由于 CPU 的运算速度比主存（物理内存）的存取速度快很多，为了提高处理速度，现代 CPU
不直接和主存进行通信，而是在 CPU 和主存之间设计了多层的高速 Cache（高速缓存），越靠近 CPU
的缓存越快，容量也越小。
CPU 物理缓存结构，具体如图 4 - 1 所示。

```
图 4 - 1 CPU 物理缓存结构
```

236 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

图中的 CPU 缓存分为三个级别 L 1 、L 2 、L 3 ，越靠近 CPU 内核（含寄存器）的缓存速度越快、
容量越小，反之则速度越慢、容量越大。
按照数据读取顺序和与 CPU 结合的紧密程度，CPU 高速缓存有 L 1 和 L 2 高速缓存（即一级高速
缓存和二级高速缓存），部分高端 CPU 还具有 L 3 高速缓存（即三级高速缓存）。每一级高速缓存
中所储存的数据都是下一级高速缓存的一部分，越靠近 CPU 的高速缓存越快，容量也越小。所以
L 1 高速缓存容量很小，但存取速度很快，并且紧挨着在使用它的 CPU 内核。L 2 容量大一些，存取
速度也慢一些，并且仍然只能被一个单核 CPU 使用。L 3 在现代多核 CPU 中更普遍，容量更大、存取
速度更慢一些，能被同一个 CPU 芯片板上的所有 CPU 内核共享。最后，系统还拥有一块主存（即主
内存），由系统中的所有 CPU 共享。拥有 L 3 高速缓存的 CPU，存取数据时的命中率能够达到 95 %，
只有不到 5 %的数据需要从主存中存取。
图 4 - 1 中的 L 1 高速缓存和 L 2 高速缓存都只能被一个 CPU 单核使用，L 3 高速缓存可以被同一个插
槽上的 CPU 内核共享，主存由全部插槽上的所有 CPU 核共享。
CPU 读取数据时，先从 L 1 高速缓存中读取，如果没有命中，再到 L 2 、L 3 高速缓存中读取，假
如这些高速缓存都没有命中，它就会到主存中读取所需要的数据。
高速缓存大大缩小了高速 CPU 与低速主存之间的差距。以三层高速缓存架构为例：
 L 1 高速缓存最接近 CPU，容量最小（如 32 KB、 64 KB 等）、存取速度最高，每个内核上都
有一个 L 1 高速缓存。
 L 2 高速缓存容量更大（如 256 KB）、速度更低，在一般情况下，每个内核上都有一个独立
的 L 2 高速缓存。
 L 3 高速缓存最接近主存，容量最大（如 12 MB），速度最低，由在同一个 CPU 芯片板上的
不同内核共享。
知名 Java 专家 Martin 和 Mike 在 QConPresentation 演讲中给出了一些高速缓存未命中情况下的时
间消耗参考数据，如表 4 - 1 所示。

表 4 - 1 高速缓存未命中的时间消耗参考数据
从 CPU 到大约需要的 CPU 周期大约需要的时间/纳秒
主存约 60 ~ 80
QPI 总线传输（套接字之间，图中未画出来） 约 20
L 3 高速缓存约 40 ~ 45 约 15
L 2 高速缓存约 10 约 3
L 1 高速缓存约 3 ~ 4 约 1
寄存器 1
CPU 通过高速缓存进行数据读取有以下优势：
1 ）写缓冲区可以保证指令流水线持续运行，可以避免由于处理器停顿下来等待向主存写入数
据而产生的延迟。
2 ）通过以批处理的方式刷新写缓冲区，以及合并写缓冲区中对同一主存地址的多次写，减少
对内存总线的占用。


```
第 5 章 JUC 显式锁的原理与实战 | 237
```
#### 4. 2 并发编程的三大问题

由于需要尽可能释放 CPU 的能力，CPU 上不断增加内核和缓存。内核也是越加越多，从之前
的单核演变成 8 核、 32 核甚至更多。缓存也不止 1 层，可能是 2 层、 3 层甚至更多。随着 CPU 内核和缓
存的增加，导致了并发编程的可见性和有序性问题。
本节简单介绍一下并发编程的三大问题：原子性问题、可见性问题和有序性问题。

###### 4. 2. 1 原子性问题

所谓原子操作，就是“不可中断的一个或一系列操作”，是指不会被线程调度机制打断的操
作。这种操作一旦开始，就一直运行到结束，中间不会有任何线程的切换。
下面来看一小段程序：
classCounterSample
{
intsum= 0 ;
publicvoidincrease (){
sum++; //①
}
}
很多读者认为，sum++是单一操作，所以是原子性的。本书前面我们用实验证明了 sum++不是
原子操作。接下来，我们使用 javap 命令解析出以上代码的汇编指令信息，从汇编指令的角度来看
看++操作的细分操作。

```
javap 是 JDK 提供的一个命令行工具，javap 能对给定的 class 文件提供的字节代码
进行反编译。通过它可以对照源代码和字节码，从而了解很多编译器内部的工作，对更深入
地理解如何提高程序执行的效率等问题有极大的帮助。命令选项-c 表示对代码进行反汇编。
```
```
使用 javap 命令解析出 CounterSample 的汇编代码，具体的命令如下：
F:\...\target\classes\...\visiable>javap-c.\CounterSample. class
Compiledfrom"CounterSample. java"
classcom. crazymakercircle. visiable. CounterSample{
intsum;
com.crazymakercircle.visiable.CounterSample ();
Code:
0 : aload_ 0
1 :invokespecial# 1 //Methodjava/lang/Object."<init>": () V
4 : aload_ 0
5 : iconst_ 0
6 : putfield # 2 //Fieldsum:I
9 :return
publicvoidincrease ();
Code:
0 : aload_ 0
1 :dup
2 : getfield # 2 //Fieldsum: I ①
```

238 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

5 : iconst_ 1 ②
6 : iadd ③
7 : putfield # 2 //Fieldsum: I ④
10 :return
}
解释一下上面的 4 个关键性的汇编指令：
①获取当前 sum 变量的值，并且放入栈顶。
②将常量 1 放入栈顶。
③将当前栈顶中两个值（sum 的值和 1 ）相加，并把结果放入栈顶。
④把栈顶的结果再赋值给 sum 变量。
通过以上 4 个关键性的汇编指令可以看出，在汇编代码的层面，++操作实质上是 4 个操作。这 4
个操作之间是可以发生线程切换的，或者说是可以被其他线程打断的。所以，++操作不是原子操
作，在并行场景会发生原子性问题。

###### 4. 2. 2 可见性问题

一个线程对共享变量的修改，另一个线程能够立刻可见，我们称为该共享变量具备内存可见性。
谈到内存可见性，要先引出 JMM（JavaMemoryModel，Java 内存模型）的概念。JMM 规定，
将所有的变量都存放在公共主内存中，当线程使用变量时会把主存中的变量复制到自己的工作空间
（或者叫作私有内存）中，线程对变量的读写操作，是自己工作内存中的变量副本。
如果两个线程同时操作一个共享变量，就可能发生可见性问题。举一个例子：
1 ）主内存中有变量 sum，初始值为 0 。
2 ）线程 A 计划将 sum 加 1 ，先将 sum= 0 复制到自己的私有内存中，然后更新 sum 的值，线程 A 操
作完成之后其私有内存中 sum 值为 1 ，然而线程 A 将更新后的 sum 值回刷到主存的时间是不固定的。
3 ）在线程 A 没有回刷 sum 到主存前，刚好线程 B 同样从主存中读取 sum，此时值为 0 ，和线程 A
一样的操作，最后期盼的 sum= 2 目标没有达成，最终的 sum= 1 。

线程 B 没有将 sum 变成 2 的原因是：线程 A 的修改还在其工作内存中，对线程 B 不可见，因为线
程 A 的修改还没有刷入主存。这就发生了典型的内存可见性问题。
线程 A 和线程 B 并发操作 sum 发生内存可见性问题的过程如图 4 - 2 所示。
要想解决多线程的内存可见性问题，所有线程都必须将共享变量刷新到主内存，一种简单的
方案是：使用 Java 提供的关键字 volatile 修饰共享变量。

```
为什么 Java 局部变量、方法参数不存在内存可见性问题？在 Java 中，所有的局部
变量、方法定义参数不会在线程之间共享，所以也就不会有内存可见性的问题。所有的 Object
实例、Class 实例和数组元素都存储在 JVM 堆内存中，堆内存在线程之间共享，所以存在可见
性问题。
```

```
第 5 章 JUC 显式锁的原理与实战 | 239
```
```
图 4 - 2 线程 A 和线程 B 并发操作 sum 发生内存可见性问题
```
###### 4. 2. 3 有序性问题

所谓的程序的有序性，是指程序执行的顺序按照代码的先后顺序执行。如果程序执行的顺序
与代码的先后顺序不同，并导致了错误的结果，即发生了有序性问题。
举一个简单的例子，看下面这段代码：
packagecom. crazymakercircle. visiable;
//省略 import
publicclassInstructionReorder{
privatevolatilestaticintx= 0 ,y= 0 ;
private staticinta= 0 ,b= 0 ;
publicstaticvoidmain (String[]args) throwsInterruptedException{
inti= 0 ;
for (;;){
i++;
x= 0 ;
y= 0 ;
a= 0 ;
b= 0 ;
Threadone=newThread (newRunnable (){
publicvoidrun (){
a= 1 ; //①
x=b; //②
}
});
Threadother=newThread (newRunnable (){
publicvoidrun (){
b= 1 ; //③
y=a; //④
}
});
one.start ();
other.start ();
one.join ();
other.join ();
Stringresult="第"+i+"次 ("+x+","+y+"）";

```
Java 线程 A Java 线程 B
```
```
主存
```

240 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

if (x== 0 &&y== 0 ){
System.err.println (result);
}
}
}
}
以上程序的代码很简单，两个线程交替给 a、b、x、y 赋值。
由于并发执行的无序性，赋值之后的 x、y 的值可能为 ( 1 , 0 )、( 0 , 1 ) 或 ( 1 , 1 )。为什么呢？因为线程
one 可以在线程 two 开始之前就执行完了，也可能线程 two 在线程 one 开始之前就执行完了，甚至有可
能二者的指令是同时或交替执行的。
当最终 x、y 的值为 ( 0 , 1 )、( 1 , 0 ) 时，线程 one 和线程 two 的执行顺序如图 4 - 3 所示。

图 4 - 3 线程 one 和线程 two 的两种正常的执行顺序
然而，执行以上代码，出乎意料的事情发生了：这段代码的执行结果也可能是 ( 0 , 0 )。以上代
码特意将结果 ( 0 , 0 ) 进行过滤和输出，部分结果如下：
第 195412 次 ( 0 , 0 ）
第 252445 次 ( 0 , 0 ）
第 279149 次 ( 0 , 0 ）
第 351772 次 ( 0 , 0 ）
第 400364 次 ( 0 , 0 ）
对于以上程序来说，( 0 , 0 ) 结果是错误的，意味着已经发生了并发的有序性问题。为什么会出
现 ( 0 , 0 ) 的结果呢？可能在程序的执行过程中发生了指令重排序（Reordering）。
下面解释一下什么是指令重排序。一般来说，CPU 为了提高程序运行效率，可能会对输入代
码进行优化，它不保证程序中各个语句的执行先后顺序同代码中的顺序一致，但是它会保证程序最
终执行结果和代码顺序执行的结果是一致的。
重排序也是单核时代非常优秀的优化手段，有足够多的措施保证其在单核下的正确性。在多
核时代，如果工作线程之间不共享数据或仅共享不可变数据，重排序也是性能优化的利器。然而，
如果工作线程之间共享了可变数据，由于两种重排序的结果都不是固定的，因此会导致工作线程似
乎表现出了随机行为。


```
第 5 章 JUC 显式锁的原理与实战 | 241
```
因为得到 ( 0 , 0 ) 结果的语句执行过程，对于线程 one 来说，可能 a= 1 和 x=b 这两个语句的赋值操作
的顺序被颠倒了，对于线程 two 来说，可能 b= 1 和 y=a 这两个语句的赋值操作的顺序被颠倒了，从而
出现了 (x, y) 值为 ( 0 , 0 ) 的错误结果。线程 one 和线程 two 发生错误结果时的执行顺序如图 4 - 4 所示的右
边部分结果 4 所示。

图 4 - 4 线程 one 和线程 two 的剩余两种执行顺序（含错误顺序）
从上面的说明可知，指令重排序并不会影响单个线程的执行，但是会影响到线程并发执行的
正确性。

```
事实上，输出了乱序的结果，并不代表一定发生了指令重排序，内存可见性问
题也会导致这样的输出。但是，指令重排序也是导致乱序的原因之一。
```
总之，要想并发程序正确地执行，必须要保证原子性、可见性以及有序性。只要有一个没有
得到保证，就有可能会导致程序运行不正确。

#### 4. 3 硬件层的 MESI 协议原理

为了缓解内存与 CPU 的速度差问题，现代计算机会在 CPU 上增加缓存，每个 CPU 内核都只有自
己的 L 1 和 L 2 高速缓存，CPU 芯片上的 CPU 内核之间共享一个 L 3 高速缓存。
每个 CPU 的处理过程为：先将计算需要用到的数据缓存在 CPU 高速缓存中，在 CPU 进行计算时，
直接从高速缓存中读取数据并且在计算完成之后写入高速缓存。在整个运算过程完成后，再把高速
缓存中的数据同步到主存。
由于每个线程可能会运行在不同的 CPU 内核中，因此每个线程拥有自己的高速缓存。同一份
数据可能会被缓存到多个 CPU 内核中，在不同 CPU 内核中运行的线程看到同一个变量的缓存值就会
不一样，就会存在内存的可见性问题。


242 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

硬件层的 MESI 协议，是用于解决内存的可见性问题的一种手段，接下来为大家介绍 MESI 协议
原理和具体内容。

###### 4. 3. 1 总线锁和缓存锁

为了解决内存的可见性问题，CPU 主要提供了两种解决办法：总线锁和缓存锁。
1 .总线锁
操作系统提供了总线锁定的机制。前端总线（也叫 CPU 总线）是所有 CPU 与芯片组连接的主
干道，负责 CPU 与外界所有部件的通信，包括高速缓存、内存、北桥，其控制总线向各个部件发送
控制信号、通过地址总线发送地址信号指定其要访问的部件、通过数据总线双向传输。
在 CPU 内核 1 要执行 i++操作的时候，将在总线上发出一个 LOCK #信号锁定缓存 （具体来说是
变量所在的缓存行），这样其他 CPU 内核就不能操作缓存了，从而阻塞了其他 CPU 内核，使该 CPU
内核 1 可以独享此共享内存。
每当 CPU 去访问 L 3 中的数据时，都会通过线程总线来进行读取。总线锁的意思是在线程总线
中加入一把锁，例如，当不同的 CPU 内核访问同一个缓存行时，只允许一个 CPU 内核进行读取，如
图 4 - 5 所示，a、b 存储于 L 3 高速缓存中，当 CPU 内核 1 对 a 进行访问时，会在总线上发送一个 LOCK#
信号，CPU 内核 2 想对 b 进行查询，但是总线被锁住，得等 CPU 内核 1 访问完，CPU 内核 2 才能访问 b。

图 4 - 5 通过线程总线进行数据的读取
在多 CPU 的系统中，当其中一个 CPU 要对共享主存进行操作时，在总线上发出一个 LOCK #信
号，这个信号使得其他处理器无法通过总线来访问共享内存中的数据，总线锁定把 CPU 和内存之间
的通信锁住了，这使得锁定期间，其他 CPU 不能操作其他主存地址的数据，总线锁定的开销比较大，
这种机制显然是不合适的。
总线锁的缺陷是：某一个 CPU 访问主存时，总线锁把 CPU 和主存的通信给锁住了，其他 CPU
不能操作其他内存地址的数据，使得效率低下，开销较大。

```
Core
1
```
```
Core
2
```

```
第 5 章 JUC 显式锁的原理与实战 | 243
```
总线锁的粒度太大了，最好的方法就是控制锁的保护粒度，只需要保证对于被多个 CPU 缓存
的同一份数据一致即可。为了解决更高性能的解决缓存一致性问题，CPU 减少了锁的保护粒度，引
入了缓存锁（如缓存一致性机制），后来的 CPU 都提供了缓存一致性机制，Intel 486 之后的 CPU 就
提供了这种优化。

2 .缓存锁
相比总线锁，缓存锁降低了锁的粒度。为了达到数据访问的一致，需要各个 CPU 在访问缓存
时遵循一些协议，在存取数据时根据协议来操作，常见的协议有 MSI、MESI、MOSI 等。最常见的
就是 MESI 协议。
就整体而言，缓存一致性机制就是当某 CPU 对高速缓存中的数据进行操作之后，通知其他 CPU
放弃存储在它们内部的缓存数据，或者从主内存中重新读取，用 MESI 描述的原理如图 4 - 6 所示。

图 4 - 6 MESI 描述的原理
为了提高处理速度，CPU 不直接和主存进行通信，而是先将系统主存的数据读到内部高速缓
存（L 1 、L 2 或其他）后再进行操作，但操作完不知道何时会写到内存。如果对声明了 volatile 的变
量进行写操作，JVM 就会向处理器发送一条 Lock 前缀的指令，将这个变量所在缓存行的数据写回
到系统主存。
但是，即使写回到系统主存，如果其他 CPU 高速缓存的值还是旧的，再执行计算操作也会有
问题。所以，在多 CPU 的系统中，为了保证各个 CPU 的高速缓存数据的一致性，会实现缓存一致性
协议，每个 CPU 通过嗅探在总线上传播的数据来检查自己高速缓存中的值是否过期，当 CPU 发现自
己缓存行对应的内存地址被修改时，就会将当前 CPU 的缓存行设置成无效状态，当 CPU 对这个数据
进行修改操作时，会重新从系统主存中把数据读到 CPU 的高速缓存中。
因为高速缓存的内容是部分主存内容的副本，所以应该与主存内容保持一致。而 CPU 对高速
缓存副本如何与主存内容保持一致有几种写入方式供选择，主要的写入方式有以下两种：

```
Core
1
```
```
Core
2
```
```
Core
3
```

244 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

1 ）Write-Through（直写）模式：在数据更新时，同时写入到低一级的高速缓存和主存。此模
式的优点是操作简单，因为所有的数据都会更新到主存，所以其他 CPU 读取主存时都是最新值。此
模式的缺点是数据写入速度较慢，因为数据修改之后需要同时写入低一级的高速缓存和主存。
2 ）Write-Back（回写）模式：数据的更新并不会立即反映到主存，而是只写入高速缓存。只
在数据被替换出高速缓存或者变成共享（S）状态时，如果发现数据有变动，才会将最新的数据更
新到主存。

Write-Back 模式的优点是数据写入速度快，因为发生数据变动时不需要写入主存，所以这种模
式占用总线少，大多数 CPU 的高速缓存采用这种模式。此模式的缺点为：实现一致性协议比较复杂，
因为最新值可能存放在私有高速缓存中，而不是存放在共享的高速缓存或主存中。
主要的缓存一致性协议有 MSI 协议和 MESI 协议等。

###### 4. 3. 2 MSI 协议

多核 CPU 都有自己的专有高速缓存（一般为 L 1 、L 2 ），以及同一个 CPU 芯片板上不同 CPU 内
核之间共享的高速缓存（一般为 L 3 ）。不同 CPU 内核的高速缓存中难免会加载同样的数据，那么
如何保证数据的一致性呢？这就需要用到缓存一致性协议。
缓存一致性协议的基础版本为 MSI 协议，也叫作写入失效协议。如果同时有多个 CPU 要写入，
总线会进行串行化，同一时刻只会有一个 CPU 获得访问权。比如 CPUc 1 、c 2 对变量 m 进行读写，采
用缓存回写模式，总线操作如表 4 - 2 所示。

```
表 4 - 2 CPU 与总线操作
```
```
CPU 操作总线操作 c 1 缓存内容 c 2 缓存内容
主存 m 所在
地址的内容
0
c 1 读取 m 高速缓存没有 m，从主存中读取 0 0
c 2 读取 m 高速缓存没有 m，从主存中读取 0 0 0
c 1 写入 1 到 m 通失效知 c^2 ，使其高速缓存中的 m 值 1 0
```
```
c 2 读取 m 的值
```
```
高速缓存没有 m，从 c 1 的高速缓
存中读取（采用回写模式，并且更
新到主存中）
```
```
1 1 1
```
表 4 - 2 中 c 2 第二次读取 m 时，c 1 会将 m 的最新值返回给 c 2 ，并且更新主存中 m 的值，c 1 和 c 2 的 m
值会变成共享状态。

###### 4. 3. 3 MESI 协议及 RFO 请求

目前主流缓存一致性协议为 MESI 写入失效协议，而 MESI 是 MES 协议的扩展。在 MESI 协议中，
每个缓存行（Cacheline）有 4 种状态，即 M、E、S 和 I（全名是 Modified、Exclusive、Share、Invalid），
可用 2 位表示。

```
缓存行是高速缓存操作的基本单位，在 Intel 的 CPU 上一般是 64 字节。
```

```
第 5 章 JUC 显式锁的原理与实战 | 245
```
MESI 协议是以缓存行的 4 种状态的首字母缩写来命名的。该协议要求在每个缓存行上维护两
个状态位，使得每个数据单位可能处于 M、E、S 和 I 这 4 种状态之一。

（ 1 ）M：被修改（Modified）
该缓存行的数据只在本 CPU 的私有高速缓存中进行了缓存，而其他 CPU 中没有，是被修改过
的脏数据（Dirty)，即与主存中的数据不一致，且没有更新到主存中。该缓存行中的数据需要在未
来的某个时间点（也就是其他 CPU 读取主存中这些被修改的数据之前）写回到主存。当被写回主存
之后，该缓存行的状态会变成独享（Exclusive）状态。
简单来说：处于 Modified 状态的缓存行数据，只有在本 CPU 中有缓存，且其数据与主存中的数
据不一致，数据被修改过。

（ 2 ）E：独享的（Exclusive）
该缓存行的数据只在本 CPU 的私有高速缓存中进行了缓存，而其他 CPU 中没有，缓存行的数
据是未被修改过的（Clean），并且与主存中的数据一致。该状态下的缓存行在任何时刻被其他 CPU
读取之后，其状态变成共享状态。在本 CPU 修改了缓存行中的数据后，该缓存行的状态可以变成
Modified 状态。
简单来说，处于 Exclusive 状态的缓存行数据只在本 CPU 中有缓存，且其数据与主存中一致，
没有被修改过。

（ 3 ）S：共享的（Shared）
该缓存行的数据可能在本 CPU 以及其他 CPU 的私有高速缓存中进行了缓存，并且各 CPU 私有高
速缓存中的数据与主存数据一致，当有一个 CPU 修改该缓存行时，其他 CPU 中该缓存行将被作废，
变成无效状态。
简单来说，处于 Shared 状态的缓存行的数据在多个 CPU 中都有缓存，且与主存一致。
（ 4 ）I：无效的（Invalid）
该缓存行是无效的，可能有其他 CPU 修改了该缓存行。
任意一个 CPU 内核的私有缓存行与其他 CPU 内核的私有缓存行的相容关系如表 4 - 3 所示。
表 4 - 3 缓存行的相容关系
M E S I
M ✕ ✕ ✕ √
E ✕ ✕ ✕ √
S ✕ ✕ √ √
I √ √ √ √
这里介绍一个状态变化的简单例子。假设有一个变量 a= 1 已经加载到 CPU 的 Core 1 、Core 2 、
Core 3 的私有高速缓存中，准确地说，应该是包括变量 a 的缓存行被加载到高速缓存中，此时各内
核中该缓存行的状态为 S，具体如图 4 - 7 所示。
如果 Core 1 将变量 a 的值改为 2 ，那么在 Core 1 的高速缓存中，该缓存行的状态将变为 M，在核
Core 2 、Core 3 的高速缓存中，该缓存行状态将变为 I，具体如图 4 - 8 所示。


246 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
图 4 - 7 Core 1 、Core 2 、Core 3 的私有缓存加载了包含 a 的缓存行
```
图 4 - 8 Core 1 中 a 的值修改后缓存行的状态变化
接下来，分阶段说明一下这 4 种状态是如何转换的：
1 ）初始阶段：开始时，缓存行没有加载任何数据，所以它处于“I 状态”。
2 ）本地写（LocalWrite）阶段：如果 CPU 内核写数据到处于“I 状态”的缓存行，缓存行的状
态变成“M 状态”。

```
Core
1 Co 2 re
```
```
Core
3
```
```
Core
1 Co 2 re
```
```
Core
3
```

```
第 5 章 JUC 显式锁的原理与实战 | 247
```
3 ）本地读（LocalRead）阶段：如果本地 CPU 读取处于“I 状态”的缓存行，很明显此缓存没
有数据给它。此时分两种情况：①其他处理器的缓存中也没有此行数据，那么从主存加载数据到
此缓存行后，再将它设成“E 状态”，表示只有“我”有此行数据，其他 CPU 都没有；②其他 CPU
的缓存有此行数据，就将此缓存行的状态设为“S 状态”（注意：处于“M 状态”的缓存行，再由
本地 CPU 写入/读出，状态是不会改变的）。
4 ）远程读（RemoteRead）阶段：假设我们有两个 CPUc 1 和 c 2 ，如果 c 2 需要读 c 1 的缓存行内
容，c 1 需要把它的缓存行内容通过主存控制器（MemoryController）发送给 c 2 ，c 2 接到后将相应的
缓存行状态设为“S 状态”。在设置之前，主存要从总线上得到这份数据并保存。
5 ）远程写（RemoteWrite）阶段：其实确切地说不是远程写，而是 c 2 得到 c 1 的数据后，不是
为了读，而是为了写。也算是本地写，只是 c 1 也拥有这份数据的拷贝，应该怎么办呢？c 2 将发出一
个 RFO（RequestForOwner）请求，说明它需要拥有这行数据的权限，其他 CPU 的相应缓存行设为
“I 状态”，除了它之外，谁也不能动这行数据。这保证了数据的安全，但处理 RFO 请求以及设置
“I 状态”的过程将给写操作带来很大的性能消耗。

```
有关 MESI 协议中缓存行的状态转换的形象说明如图 4 - 9 所示。
```
```
图^4 -^9 MESI 缓存行的状态转换关系
有关 MESI 协议中缓存行的状态转换的详细说明如表 4 - 4 所示。
```
```
不存在高速缓存备份时
```
```
当其他内核存在高速缓存备份时
```
```
缩写说明
LR：LocalRead（本地读）
LW：LocalWrite（本地写）
RR：RemoteRead（远程读）
RW：RemoteWrite（远程写）
```

248 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
表 4 - 4 MESI 缓存行的状态转换触发条件和转换行为详细说明
当前状态事件行为下一个状态
```
```
I（Invalid）
```
```
LocalRead
```
```
如果其他高速缓存没有这份数据，本高速缓存就从该主存
中取数据，缓存行（CacheLine）状态变成 E
```
```
E/S
```
```
如果其他高速缓存有这份数据，且状态为 M，那么将数据
更新到主存，本高速缓存再从主存中读取数据，两个高速
缓存的缓存行状态都变成 S
如果其他高速缓存有这份数据，且状态为 S 或者 E，则本
高速缓存从主存中读取数据，这些高速缓存的缓存行状态
都变成 S
```
```
LocalWrite
```
```
从主存中读取数据，在高速缓存中修改，状态变成 M；如
果其他高速缓存有这份数据，且状态为 M，那么要先将数
据更新到主存 M
如果其他高速缓存有这份数据，那么其他高速缓存的缓存
行状态变成 1
RemoteRead 既然是 invalid，别的内核操作与它无关 I
RemoteWrite 既然是 invalid，别的内核操作与它无关 I
```
```
E（Exclusive）
```
```
LocalRead 从高速缓存中读取数据，状态不变 E
LocalWrite 修改高速缓存的数据，状态为 M M
RemoteRead 数据和其他 CPU 内核共用，状态变成了 S S
RemoteWrite 数据被修改，本缓存行不能再使用，状态变成 I I
```
```
S（Shared）
```
```
LocalRead 从高速缓存中读取数据，状态不变 S
LocalWrite 修存改行高状速态缓变存成中 I 的数据，状态变成 M，其他内核共享的缓 M
RemoteRead 状态不变 S
RemoteWrite 数据被修改，本缓存行不能再使用，状态变成 I I
```
```
M（Modified）
```
```
LocalRead 从高速缓存中读取数据，状态不变 M
LocalWrite 修改高速缓存中的数据，状态不变 M
RemoteRead 此到缓最新存的行数的据数，据状被态写变到成主存 S 中，使其他 CPU 内核能使用 S
```
```
RemoteWrite
```
```
此缓存行的数据被写到主存中，使其他 CPU 内核能使用
到最新的数据，由于其他内核会修改此行数据，因此状态
变成 I
```
```
I
```
在 MESI 协议中，每个 CPU 内核的缓存控制器不仅知道自己的读写操作，而且也监听其他 CPU
内核缓存控制器的读写操作。各缓存通过状态转换机制（状态机）来实现数据的一致性。

MESI 协议带来的性能问题：
各个 CPU 的缓存行（CacheLine）的状态是通过发送通知消息来进行同步的，比如 RFO（Request
ForOwner）请求就是一种非常典型的通知消息。RFO 请求可以理解为失效请求（InvalidateRequest），
用于通知其他内核将其缓存中的数据置为 Invalid（失效）。比如内核 1 要对一个 Shared 状态的缓存
行中共享变量进行写入，需要发送一个失效消息给到其他缓存了该数据的内核 n。此处的关键在于，
不同内核直接的通信方式在原始 MESI 协议中是同步的，发起者需要等到接收方的回执（Ack），
才能执行写入缓存的操作；如果发起者内核 1 没有拿到 Ack，内核 1 在这段时间内都会处于阻塞状态。


```
第 5 章 JUC 显式锁的原理与实战 | 249
```
同步通信往往存在性能问题。MESI 协议在多个 CPU 内核之间同步通信需要消耗的时间，将导
致内核在此期间无事可做，甚至一旦某个内核发生阻塞，将会导致其他内核也处于阻塞状态，从而
带来性能极大消耗。

###### 4. 3. 4 StoreBuffer 和 InvalidateQueue

既然同步通信存在性能问题，那么按照数据一致性的基础原理，可以改为异步通信。
高速缓存数据一致性和分布式中间件的不同节点之间的数据一致性，在原理上也是类似的。
无论 RocketMQ 主从同步、MySQL 主从同步或 Redis 主从同步都存在类似的问题：同步通信数据强一
致，但性能低；异步通信性能高，但数据弱一致。总之，不同组件的数据一致性问题和原理基本都
是相通的。
如何在 MESI 协议中引入异步通信机制呢？这里需要 CPU 的支持，CPU 内部需要引入两个组件：
存储缓存（StoreBuffer）和失效队列（InvalidateQueue）。StoreBuffer 是缓存写入方用到的组件，
InvalidateQueue 是缓存失效方用到的组件，如图 4 - 10 所示。

图^4 -^10 StoreBuffer 和 InvalidateQueue
1 .什么是 StoreBuffer
StoreBuffer 是缓存写入方在写入 Shared 状态的缓存行（CacheLine）时用到的组件，这个新增
组件位于内核和缓存之间，用于临时存放没有收到失效 Ack（确认）的写入结果。
没有 StoreBuffer 之前，当一个处理器内核作为写入方，需要处理将计算结果写入 Shared 状态的
缓存行时，需要通知其他内核将该缓存置为 Invalid（无效），收到回执后才能执行本地缓存行写


250 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

入；引入 StoreBuffer 后，本地内核将不再需要等待其他内核的响应结果，只需要把修改的数据临时
写入到 StoreBuffer，然后给其他 CPU 内核发送失效请求；接下来本地内核即可去执行其他指令。当
收到其他内核的失效 Ack（响应结果）后，本地内核再把 StoreBuffer 中的数据写入本地缓存行，并
把缓存行状态修改为 Modified。
StoreBuffer 的核心功能是：使得计算结果的缓存行写入一分为二，并且从同步变成了异步。
StoreBuffer 写入的步骤：第一步写入 StoreBuffer，第二步写入缓存行。第一步和第二步之间有一个
异步等待的工作，当前的内核在等待得到其他内核的 Ack 消息后，再将数据写入缓存。这里与旧的
MESI 协议有一个显著不同，之前 MESI 协议是一步到位模式：缓存写入方内核阻塞等待其他缓存失
效方内核的失效 Ack 后直接写入缓存行。

2 .什么是 InvalidateQueue
InvalidateQueue 是缓存失效方在处理失效消息时用到的新组件，这个新增组件是一个队列，用
于临时存放接收到的失效请求（InvalidateRequest），一旦失效请求进入队列之后，缓存失效方立
即进行 Ack 回复，而不是在执行完成缓存失效操作才进行回复。
InvalidateQueue 的核心功能是：使得失效 Ack 的回复从同步变成了异步。没有 InvalidateQueue
之前，旧的缓存失效方（失效请求的接收方）只有在完成了缓存行修改后，才会回复 InvalidateAck；
有了 InvalidateQueue 之后，内存一旦收到失效请求就会将其放入 InvalidateQueue，然后快速返回
InvalidateAck（确认）消息。
总之，StoreBuffer 是属于缓存写入方（修改数据方）的异步优化措施，而 InvalidateQueue 可以
理解为缓存失效方（失效请求的接收方）的异步优化措施。

```
注意，StoreBuffer 和 InvalidateQueue 属于 MESI 协议的性能优化措施，通过两个
异步组件提升缓存写入方和缓存失效方的性能。但不是所有的 CPU 都支持 StoreBuffer 和
InvalidateQueue，比如 X 86 CPU 就没有 InvalidateQueue 组件。
```
###### 4. 3. 5 volatile 的原理

前面介绍过，为了解决 CPU 访问主存时读写性能的短板，在 CPU 中增加了高速缓存，但这带
来了可见性问题。而 Java 的 volatile 关键字可以保证共享变量的主存可见性，也就是将共享变量的改
动值立即刷新回主存。在正常情况下，系统操作并不会校验共享变量的缓存一致性，只有当共享变
量被 volatile 关键字修饰了，该变量所在的缓存行才被要求进行缓存一致性的校验。
接下来，这里从 volatile 关键字的汇编代码出发分析一下 volatile 关键字的底层原理。一段使用
被 volatile 修饰的共享变量的示例代码如下：
packagecom. crazymakercircle. visiable;
publicclassVolatileVar
{
//使用 volatile 保障内存可见性
volatileintvar= 0 ;
publicvoidsetVar (intvar)
{
System.out.println ("setVar="+var);
this. var=var;
}


```
第 5 章 JUC 显式锁的原理与实战 | 251
```
```
publicstaticvoidmain (String[]args)
{
VolatileVarvar=newVolatileVar ();
var.setVar ( 100 );
}
}
1 .输出汇编代码的操作命令
使用下面的命令将 VolatileVar 的汇编代码输出到 volatile. log 文件，具体的命令如下：
F:\..\..\target\classes>java-server-Xcomp-XX:-Inline
```
- XX:+UnlockDiagnosticVMOptions
- XX:+PrintAssembly
com/crazymakercircle/visiable/VolatileVar>volatile. log
对命令中的选项介绍如下：
1 ）-Xcomp：表示永远以编译模式运行（禁止解释器模式）。
2 ）-XX:-Inline：禁止内联优化。
3 ）-server：设置虚拟机使用何种运行模式，“-server”选择 server 模式 JVM，在 Windows 上默
认的 JVM 类型为 client 模式。client 模式启动比较快，但运行时性能和内存管理效率不如 server 模式，
通常用于客户端应用程序。相反，server 模式启动比 client 模式慢，但可获得更高的运行性能。如果
要使用 server 模式，就需要在启动虚拟机时添加-server 参数，以获得更高性能。对服务器端应用，
推荐采用 server 模式，尤其是多个 CPU 的系统。在 Linux 下，Solaris 上默认采用 server 模式。
4 ）>volatile. log：使用重定向符号“>”将命令行中输出的内容存储到 volatile. log 文件中。
2 .输出汇编代码过程中可能出现的错误
运行过程中可能出现的错误之一：找不到或无法加载主类。
如果出现“找不到或无法加载主类”的错误，可能是类路径设置的问题。运行 Java 程序涉及的
环境变量有三个：JAVA_HOME、CLASSPATH 和 Path。示例如下：
JAVA_HOME: C:\ProgramFiles\Java\jdk 1. 8. 0 _ 51
CLASSPATH: .;%JAVA_HOME%\lib\dt. jar;.%JAVA_HOME%\lib\tools. jar;
Path: %JAVA_HOME%\bin;%JAVA_HOME%\jre\bin;
运行过程中可能出现的错误之二：无法加载 hsdis-amd 64 .dll。
该错误的具体信息为：“无法加载 hsdis-amd 64 .dll；库不可加载；PrintAssembly 已禁用”。输
出汇编指令时，在 Windows 平台上需要依赖 hsdis-amd 64 .dll 库，该库可以从 FMCL 下载 ZIP 文件
hsdis- 1. 1. 1 - win 32 - amd 64 .zip，里边有一个 hsdis-amd 64 .dll。
获取 hsdis-amd 64 .dll 文件之后，将其复制到相应的 JRE 目录中即可。JRE 目录为 JAVA_HOME
环境变量下的 JRE 目录。
根据 java 命令是 server 模式还是 client 模式，将反汇编依赖库 hsdis-amd 64 .dll 放在 JRE 对应的
jre/bin/server 目录或 jre/bin/client 目录下。

```
hsdis- 1. 1. 1 - win 32 - amd 64 .zip 可以直接在“疯狂创客圈”共享网盘下载，其地址请
查阅社群的博客。
```

252 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

3 .分析 volatile 关键字对应的汇编指令
运行程序后，volatile. log 会有 VolatileVar 类的汇编指令。volatile. log 可能很长，可以根据共享变
量的名称进行检索，这里的共享变量为 var，所以可以检索到以下两行代码：
0 x 0000000003931 be 6 : mov %r 8 d, 0 xc (%rdx)
0 x 0000000003931 bea:lockaddl$ 0 x 0 ,(%rsp) ;*putfieldvar
;-.. VolatileVar::setVar@ 27 (line 17 )
0 x 000000000305016 f: add $ 0 x 50 ,%rsp
0 x 0000000003050173 : pop %rbp
由于共享变量 var 加了 volatile 关键字，因此在汇编指令中，操作 var 之前多出一个 lock 前缀指令
lockaddl，该 lock 前缀指令有三个功能：

（ 1 ）将当前 CPU 缓存行的数据立即写回系统主存
在对 volatile 修饰的共享变量进行写操作时，其汇编指令前用 lock 前缀修饰。lock 前缀指令使得
在执行指令期间，CPU 可以独占共享内存（即主存）。对共享内存的独占，老的 CPU（如 Intel 486 ）
通过总线锁方式实现。由于总线锁开销比较大，因此新版 CPU（如 IA- 32 、Intel 64 ）通过缓存锁实
现对共享内存的独占性访问，缓存锁（缓存一致性协议）会阻止两个 CPU 同时修改共享内存的数据。

（ 2 ）lock 前缀指令会引起在其他 CPU 中缓存了该内存地址的数据无效
写回操作时要经过总线传播数据，而每个 CPU 通过嗅探在总线上传播的数据来检查自己缓存
的值是否过期，当每个 CPU 发现自己缓存行对应的内存地址被修改时，就会将当前 CPU 的缓存行设
置为无效状态，当 CPU 要对这个值进行修改时，会强制重新从系统内存中把数据读到 CPU 缓存。

（ 3 ）lock 前缀指令禁止指令重排
lock 前缀指令的最后一个作用是作为内存屏障（MemoryBarrier）使用，可以禁止指令重排序，
从而避免多线程环境下程序出现乱序执行的现象。

```
不同 CPU 产品对 MESI 协议的实现方案不同，具体的汇编指令也不一定相同。
MESI 协议仅仅是一种基于过期机制的高速缓存一致性保障协议，作为 Java 工程师，只需要大
概了解即可，不需要深入了解该协议，更不需要了解各个 CPU 产品中对应的硬件指令。
```
总体来说，通过汇编指令可以看出，volatile 关键字的底层原理是非常复杂的，涉及 MESI 协议、
内存屏障等硬件层面的知识和技术。接下来，为大家介绍内存屏障的原理和具体内容。

#### 4. 4 有序性与内存屏障

有序性是与可见性完全不同的概念，虽然二者都是 CPU 不断迭代升级的产物。由于 CPU 的技
术不断发展，为了重复释放硬件的高性能，编译器、CPU 会优化待执行的指令序列，包括调整某些
指令的执行顺序。优化的结果，指令执行顺序会与代码顺序略有不同，可能会导致代码执行出现有
序性问题。
内存屏障又称内存栅栏（MemoryFences），是一系列的 CPU 指令，它的作用主要是保证特定操作
的执行顺序，保障并发执行的有序性。在编译器和 CPU 都进行指令的重排优化时，可以通过在指令间
插入一个内存屏障指令，告诉编译器和 CPU，禁止在内存屏障指令的前（或后）执行指令重排序。


```
第 5 章 JUC 显式锁的原理与实战 | 253
```
###### 4. 4. 1 重排序

为了提高性能，编译器和 CPU 常常会对指令进行重排序。重排序主要分为两类：编译器重排
序和 CPU 重排序，具体如图 4 - 11 所示。

图 4 - 11 Java 源码变成最终的指令序列所经历的重排序
1 .编译器重排序
编译器重排序指的是在代码编译的阶段进行指令重排，不改变程序执行结果的情况下，为了
提升效率，编译器对指令进行乱序（Out-of-Order）的编译。
例如，在代码中，A 操作需要获取其他资源而进入等待的状态，而 A 操作后面的代码跟其没有
数据依赖关系，如果编译器一直等待 A 操作完成再往下执行的话，效率要慢得多，所以可以先编译
后面的代码，这样的乱序可以提升编译速度。
编译器为什么要重排序（Re-Order）呢？它的目的为：与其等待阻塞指令（如等待缓存刷入）
完成，不如先去执行其他指令。与 CPU 乱序执行相比，编译器重排序能够完成更大范围、效果更好
的乱序优化。

2 .CPU 重排序
流水线（Pipeline）和乱序执行（Out-of-OrderExecution）是现代 CPU 基本都具有的特性。机器
指令在流水线中经历取指、译码、执行、访存、写回等操作。为了 CPU 的执行效率，流水线都是并
行处理的，在不影响语义的情况下，处理器次序（ProcessOrdering，机器指令在 CPU 实际执行时的
顺序）和程序次序（ProgramOrdering，程序代码的逻辑执行顺序）是允许不一致的，只要满足
As-if-Serial 规则即可。显然，这里的不影响语义依旧只能保证指令间的显式因果关系，无法保证隐
式因果关系，即无法保证语义上不相关但是在程序逻辑上相关的操作序列按序执行。

```
所谓“乱序”，实际上也遵循着一定规则：只要两个指令之间不存在“数据依
赖”，就可以对这两个指令乱序。
```
CPU 重排序包括两类：指令级重排序和内存系统重排序。
1 ）指令级重排序。在不影响程序执行结果的情况下，CPU 内核采用了 ILP（Instruction-Level
Parallelism，指令级并行运算）技术来将多条指令重叠执行，主要是为了提升效率。如果指令之间
不存在数据依赖性，处理器可以改变语句的对应机器指令的执行顺序，叫作指令级重排序。
2 ）内存系统重排序：对于现代的 CPU 来说，在 CPU 内核和主存之间都具备一个高速缓存，高

```
CPU
```

254 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

速缓存的作用主要为减少 CPU 内核和主内存的交互（CPU 内核的处理速度要快得多），在 CPU 内核
进行读操作时，先从缓存读取，如果缓存没有的话从主存读取；同样，对于写操作都是先写在缓存
中，最后一次性写入主存。无论 CPU 读还是写，都会优先考虑高速缓存，主要为了减少跟主存交互时
CPU 内核的短暂卡顿，从而提升性能。但是，内存系统重排序可能会导致一个问题——数据不一致。

内存重排序和指令级重排序不同，内存系统重排序为伪重排序，也就是说只是看起来像在乱
序执行而已。

###### 4. 4. 2 As-if-Serial 规则

在单核 CPU 的场景下，当指令被重排序之后，如何保障运行的正确性呢？其实很简单，编译
器和 CPU 都需要遵守 As-if-Serial 规则。
As-if-Serial 规则的具体内容为：不管如何重排序，都必须保证代码在单线程下运行正确。
为了遵守 As-if-Serial 规则，编译器和 CPU 不会对存在数据依赖关系的操作进行重排序，因为这
种重排序会改变执行结果。但是，如果指令之间不存在数据依赖关系，这些指令可能被编译器和
CPU 重排序。
下面是一段非常简单的示例代码：
publicclassReorderDemo{
publicstaticvoidmain (String[]args){
inta= 1 ； //①
intb= 2 ； //②
intc=a+b;//③
}
}
示例代码中，③和①之间存在数据依赖关系，同时③和②之间也存在数据依赖关系。因此在
最终执行的指令序列中，③不能被重排序到①和②的前面，因为③排到①和②的前面，程序的结果
将会被改变。但①和②之间没有数据依赖关系，编译器和 CPU 可以重排序①和②之间的执行顺序。
为了保证 As-if-Serial 规则，Java 异常处理机制也会为指令重排序做一些特殊处理。下面是一段
非常简单的 Java 异常处理示例代码：
publicclassReorderDemo 2 {
publicstaticvoidmain (String[]args){
intx, y;
x= 1 ;
try{
x= 2 ; //①
y= 0 / 0 ; //②
}catch (Exceptione){ //③
}finally{
System.out.println ("x="+x);
}
}
}
在上面的代码中，语句①（x= 2 ）和语句②（y= 0 / 0 ）之间没有数据依赖关系，语句②可能
会被重排序在①之前执行。重排之后，语句①尚未执行，语句②已经抛出异常，因而重排后会导致
语句①得不到执行，最终 x 得到错误结果 1 。
所以，为了保证最终不输出 x= 1 的错误结果，JIT 在重排序时会在 catch 语句中插入错误补偿代


```
第 5 章 JUC 显式锁的原理与实战 | 255
```
码，补偿执行语句②，将 x 赋值为 2 ，将程序恢复到发生异常时应有的状态。这种做法的确将异常捕
捉的和处理的底层逻辑变得非常复杂，但是 JIT 的优化原则是，尽力保障正确的运行的逻辑，哪怕
以 catch 块的逻辑变得复杂为代价。

```
JIT 是 JustInTime 的缩写，也就是“即时编译器”。JVM 读入“. class”文件的字
节码后，默认情况下是解释执行的。但是对于运行频率很高（如大于 5000 次）的字节码，JVM
采用了 JIT 技术，将直接编译为机器指令，以提高性能。
```
虽然编译器和 CPU 遵守了 As-if-Serial 规则，无论如何，也只能在单 CPU 执行的情况下能保证结
果正确。在多核 CPU 并发执行的场景下，由于 CPU 的一个内核无法清晰分辨其他内核上指令序列中
的数据依赖关系，因此就可能出现乱序执行, 从而导致程序运行结果错误。
所以，As-if-Serial 规则只能保障单内核指令重排序之后的执行结果正确，不能保障多内核以及
跨 CPU 指令重排序之后的执行结果正确。

###### 4. 4. 3 硬件层面的内存屏障

多核情况下，所有的 CPU 操作都会涉及缓存一致性协议（MESI 协议）校验，该协议用于保障
内存可见性。但是，缓存一致性协议仅仅保障内存弱可见（高速缓存失效），没有保障共享变量的
强可见，而且缓存一致性协议更不能禁止 CPU 重排序，也就是不能确保跨 CPU 指令的有序执行。
如何保障跨 CPU 指令重排序之后的程序结果正确呢？需要用到内存屏障。
1 .硬件层的内存屏障定义
内存屏障又称内存栅栏，是让一个 CPU 高速缓存的内存状态对其他 CPU 内核可见的一项技术，
也是一项保障跨 CPU 内核有序执行指令的技术。
硬件层常用的内存屏障分为三种：写屏障（StoreBarrier）、读屏障（LoadBarrier）、全屏障
（FullBarrier）。

（ 1 ）写屏障
在指令后插入写屏障指令能将寄存器、高速缓存中的最新数据更新到主存，让其他线程可见。
并且写屏障会告诉 CPU 和编译器，在写屏障之前的写指令必须先于写屏障执行，不能进行指令重排。
写屏障对应 X 86 处理器上的 sfence 指令，sfence 指令会保证处于其之前所有写操作都在该指令执
行之前被完成，并把高速缓冲区的数据都刷新到主存中，使得当前 CPU 对共享变量的更改对所有
CPU 可见。
总之，在指令之后插入写屏障指令，有两个作用：
1 ）能让寄存器、高速缓存中的最新数据写回到主内存。
2 ）在写屏障之前的写指令必须先于屏障执行，不能进行指令重排。
（ 2 ）读屏障
读屏障将高速缓存中相应的数据失效。在指令前插入读屏障，可以让高速缓存中的数据失效，
强制重新从主存加载数据。并且读屏障会告诉 CPU 和编译器，后于这个屏障的读指令必须后执行，
不能对后面的读操作进行指令重排。


256 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

读屏障对应着 X 86 处理器上的 lfence 指令，将强制所有在该指令之后的读操作都在 lfence 指令执
行之后被执行，并且强制本地高速缓冲区的值全部失效，以便从主存中重新读取共享变量的值。
总之，在指令前插入读屏障指令，有两个作用：
1 ）让高速缓存中的数据失效，重新从主存加载数据。
2 ）后于读屏障的读指令必须后执行，不能对后面的读操作进行指令重排。
读屏障既使得当前 CPU 内核对共享变量的更改对所有 CPU 内核可见，也阻止了一些可能导致
读取无效数据的指令重排。

（ 3 ）全屏障
全屏障是一种全能型的屏障，具备读屏障和写屏障的能力。FullBarrier 又称为 StoreLoadBarriers，
对应 X 86 处理器上的 mfence 指令。
在 X 86 处理器平台上 mfence 指令综合了 sfence 指令与 lfence 指令的作用。X 86 处理器强制所有在
mfence 之前的 store/load 指令都在 mfence 执行之前被执行；所有在 mfence 之后的 store/load 指令都在该
mfence 执行之后被执行。简单来说，X 86 处理器禁止对 mfence 指令前后的 store/load 指令进行重排序。
X 86 处理器上的 lock 前缀指令也具有内存全屏障的功能。lock 前缀后面可以跟 ADD、ADC、AND、
BTC、BTR、BTS、CMPXCHG、CMPXCH 8 B、DEC、INC、NEG、NOT、OR、SBB、SUB、XOR、
XADD、XCHG 等指令。

2 .硬件层的内存屏障的作用
（ 1 ）阻止屏障两侧的指令重排序
编译器和 CPU 可能为了使性能得到优化而对指令重排序，但是插入一个硬件层的内存屏障相
当于告诉 CPU 和编译器先于这个屏障的指令必须先执行，后于这个屏障的指令必须后执行。

（ 2 ）强制让新数据写回主存，并且让高速缓存的数据失效
硬件层的内存屏障强制把高速缓存中的最新数据等写回主内存，让高速缓存中相应的脏数据
失效。一旦完成写入，任何访问这个变量的线程将会得到最新的值。

```
3 .内存屏障的使用示例
下面是一段可能乱序执行的代码：
publicclassReorderDemo 3 {
privateint x= 0 ;
privateBoolean flag=false;
publicvoidupdate (){
x= 8 ; //①
flag=true; //②
}
publicvoidshow (){
if (flag){ //③
//x 是多少？
System.out.println (x);
}
}
}
ReorderDemo 3 并发运行之后，控制台所输出的 x 值可能是 0 或 8 。为什么 x 可能会输出 0 呢？主
```

```
第 5 章 JUC 显式锁的原理与实战 | 257
```
要原因是：update () 和 show () 方法可能在两个 CPU 内核并发执行，语句①和语句②如果发生了重排
序，那么 show () 方法输出的 x 就可能为 0 。如果输出的 x 结果是 0 ，显然不是程序的正常结果。
如何确保 ReorderDemo 3 的并发运行结果正确呢？可以通过内存屏障进行保障。Java 语言没有
办法直接使用硬件层的内存屏障，只能使用含有 JMM 内存屏障语义的 Java 关键字，这类关键字的典
型为 volatile。使用 volatile 关键字对实例中的 x 进行修饰，修改后的 ReorderDemo 3 代码，具体如下：
publicclassReorderDemo 3 {
privatevolatileint x= 0 ; //使用 volatile 关键字对 x 进行修饰
privateBoolean flag=false;
publicvoidupdate (){
x= 8 ; //①
//volatile 要求编译器在这里插入 StoreBarrier 写屏障
flag=true; //②
}
publicvoidshow (){
if (flag){ //③
//x 是多少？
System.out.println (x);
}
}
}
修改后的 ReorderDemo 3 代码使用 volatile 关键字对成员变量 x 进行修饰，volatile 含有 JMM 全屏障
的语义，要求 JVM 编译器在语句①的后面插入全屏障指令。该全屏障确保 x 的最新值对所有的后序
操作是可见的（含跨 CPU 场景），并且禁止编译器和 CPU 对语句①和语句②进行重排序。
前面介绍 volatile 关键字的原理时，volatile 在 X 86 处理器上被 JVM 编译之后，其汇编代码中会被
插入了一条 lock 前缀指令（LockADD），从而实现全屏障目的。
由于不同的物理 CPU 硬件所提供的内存屏障指令的差异非常大，因此 JMM 定义了自己一套相
对独立的内存屏障指令，用于屏蔽不同硬件的差异性。很多的 Java 关键字（如 volatile）在语义中包
含了 JMM 内存屏障指令，在不同的硬件平台上，这些 JMM 内存屏障逻辑指令会要求 JVM 来为不同
的平台生成相应的硬件层的内存屏障指令。
接下来，为大家介绍 JMM 的原理和具体内容。

#### 4. 5 JMM 详解

JMM（JavaMemoryModel，即 Java 内存模型）并不像 JVM 内存结构一样是真实存在的运行实
体，更多体现为一种规范和规则。

###### 4. 5. 1 什么是 Java 内存模型

JMM 最初由 JSR- 133 （JavaMemoryModelandThreadSpecification）文档描述，JMM 定义了一组规
则或规范，该规范定义了一个线程对共享变量的写入时，如何确保对另一个线程是可见的。实际上，
JMM 提供了合理的禁用缓存以及禁止重排序的方法，所以其核心的价值在于解决可见性和有序性。
JMM 的另一大价值在于能屏蔽各种硬件和操作系统的访问差异，保证 Java 程序在各种平台下
对内存的访问最终都是一致的。


258 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

Java 内存模型规定所有的变量都是存储在主存中，JMM 的主存类似于物理内存，但有区别，
还能包含部分共享缓存。每个 Java 线程都有自己的工作内存（类似于 CPU 高速缓存，但也有区别）。
Java 内存模型定义的两个概念：
1 ）主存：主要存储的是 Java 实例对象，所有线程创建的实例对象都存放在主存中，无论该实
例对象是成员变量还是方法中的本地变量（也称局部变量），当然也包括了共享的类信息、常量、
静态变量。由于是共享数据区域，因此多个线程对同一个变量进行访问可能会发现线程安全问题。
2 ）工作内存：主要存储当前方法的所有本地变量信息（工作内存中存储着主存中的变量副本），
每个线程只能访问自己的工作内存，即线程中的本地变量对其他线程是不可见的，即使两个线程执
行的是同一段代码，它们也会各自在自己的工作内存中创建属于当前线程的本地变量，当然也包括
了字节码行号指示器、相关 Native 方法的信息。注意，由于工作内存是每个线程的私有数据，线程
间无法相互访问工作内存，因此存储在工作内存的数据不存在线程安全问题。

```
Java 内存模型的规定如下：
1 ）所有变量存储在主存中。
2 ）每个线程都有自己的工作内存，且对变量的操作都是在工作内存中进行的。
3 ）不同线程之间无法直接访问彼此工作内存中的变量，要想访问只能通过主存来传递。
在 JMM 中，Java 线程、工作内存、主存之间的关系大致如图 4 - 12 所示。
```
图 4 - 12 JMM 中 Java 线程、工作内存、主内存之间的关系
JMM 将所有的变量都存放在公共主存中，当线程使用变量时，会把公共主存中的变量复制到
自己的工作内存（或者叫作私有内存）中，线程对变量的读写操作是自己的工作内存中的变量副本。
因此，JMM 模型也需要解决代码重排序和缓存可见性问题。JMM 提供了一套自己的方案去禁用缓
存以及禁止重排序来解决这些可见性和有序性问题。JMM 提供的方案包括大家都很熟悉的 volatile、
synchronized、final 等。JMM 定义了一些内存操作的抽象指令集，然后将这些抽象指令包含到 Java 的 volatile、
synchronized 等关键字的语义中，并要求 JVM 在实现这些关键字时必须具备其包含的 JMM 抽象指令的
能力。


```
第 5 章 JUC 显式锁的原理与实战 | 259
```
###### 4. 5. 2 JMM 与 JMM 物理内存的区别

JMM（Java 内存模型）看上去和 JVM（Java 内存结构）差不多，很多人会误以为两者是一回事，
这也就导致面试过程中经常答非所问。
JMM 属于语言级别的内存模型，它确保了在不同的编译器和不同的 CPU 平台上为 Java 程序员
提供一致的内存可见性来保证指令并发执行的有序性。
以 Java 为例，一个 i++方法编译成字节码后，在 JVM 中是分成了以下三个步骤运行的：
1 ）从主存中复制 i 的值并复制到 CPU 的工作内存中。
2 ）CPU 读取工作内存中的值，然后执行 i++操作，完成后刷新到工作内存。
3 ）将工作内存中的值更新到主存。
当多个线程同时访问该共享变量 i 时，每个线程都会将变量 i 复制到工作内存中进行修改，如果
线程 A 读取变量 i 的值时，线程 B 正在修改 i 的值，问题就来了：线程 B 对变量 i 的修改对线程 A 而言就
是不可见的。
这就是多线程并发访问共享变量所造成的结果不一致问题，该问题属于 JMM 需要解决的问题。
JMM 属于概念和规范维度的模型，是一个参考性质的模型。JMM 模型定义了一个指令集、一
个虚拟计算机架构和一个执行模型。具体的 JVM 实现需要遵循 JMM 的模型进行实现，它能够运行
根据 JMM 模型指令集编写的代码，就像真机可以运行机器代码一样。
虽然 JVM 也是一个概念和规范维度的模型，但是大家常常将 JVM 理解为实体的、实现维度的
虚拟机，通常情况下一般指 HotSpotVM。

```
HotSpotVM 是 JVM 模型的一个开源实现，最初由 Sun 开发，现在由 Oracle 拥有。JVM
规范还有其他实现，例如 JRockit、IBMJ 9 等。如果没有特殊说明，本书的 JVM 特指 HotSpotJVM。
```
Java 代码是要运行在虚拟机上的，而虚拟机在执行 Java 程序的过程中会把所管理的内存划分为
若干个不同的数据区域，这些区域都有各自的用途。其中，有些区域随着虚拟机进程的启动而存在，
而有些区域依赖用户线程的启动和结束而建立和销毁。在《Java 虚拟机规范（JavaSE 8 ）》中描述
了 JVM 运行时内存区域结构，如图 4 - 13 所示。

```
图 4 - 13 JVM 运行时内存区域结构
```

260 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

Java 虚拟机规范定义了 JVM 内存结构，JVM 内存结构中各个区域有各自的功能。由于 JVM 的功
能不是本书的重点，因此就不在这里详细介绍了。
这里简单介绍几个需要特别注意的 JVM 知识点：
1 ）JVM 模型定义了 Java 虚拟机规范，但是不同的 JVM 虚拟机实现会各不相同，一般会遵守
规范。
2 ）JVM 模型定义中定义的方法区只是一种概念上的区域，并说明了其应该具有什么功能。但
是并没有规定这个区域到底应该处于何处。所以，对于不同的 JVM 实现来说，是有一定的自由度的。
不同版本的方法区所处位置不同，方法区并不是绝对意义上的物理区域。在某些版本的 JVM 实现中，
方法区其实是在堆中实现的。
3 ）运行时常量池用于存放编译期生成的各种字面量和符号应用。但是，Java 语言并不要求常
量只有在编译期才能产生。比如在运行期，String. intern 也会把新的常量放入池中。
4 ）除了以上介绍的 JVM 运行时内存外，还有一块内存区域可供使用，那就是直接内存。Java
虚拟机规范并没有定义这块内存区域，所以它并不由 JVM 管理，是利用本地方法库直接在堆外申请
的内存区域。
5 ）堆和栈的数据划分也不是绝对的，如 HotSpot 的 JIT 会针对对象分配做相应的优化。
下面介绍 JMM 与硬件内存架构的关系。
通过对硬件缓存架构、Java 内存模型以及 Java 多线程的原理的了解，大家应该已经意识到，多
线程的执行最终都会映射到 CPU 上执行，但是 Java 内存模型和硬件内存架构并不完全一致。
JMM 与硬件内存架构是什么样的关系呢？
对于硬件内存来说只有寄存器、缓存内存、主存的概念，并没有工作内存（线程私有数据区
域）和主存（堆内存）之分，也就是说 Java 内存模型对内存的划分对硬件内存并没有任何影响，因
为 JMM 只是一种抽象的概念，是一组规则，并不实际存在，无论是 JMM 工作内存的数据还是主存
的数据，对于计算机硬件来说都会存储在计算机主存中，当然也有可能存储到 CPU 高速缓存或者寄
存器中，因此总体上来说，Java 内存模型和计算机硬件内存架构是相互交叉的关系，是一种抽象概
念划分与真实物理硬件的交叉。
JMM 与硬件内存架构的对应关系如图 4 - 14 所示。

```
图 4 - 14 JMM 与硬件内存架构的对应关系
```

```
第 5 章 JUC 显式锁的原理与实战 | 261
```
###### 4. 5. 3 JMM 的 8 个操作

Java 内存模型规定所有的变量都是存储在主存中（类似于前面说的主存或者物理内存），每个
线程都有自己的工作内存（类似于 CPU 中的高速缓存）。工作内存保存了线程使用到的变量副本，
线程对变量的所有操作（读取、赋值等）必须在该线程的工作内存中进行。
JMM 定义了一套自己的主存与工作内存之间的交互协议，即一个变量如何从主存拷贝到工作
内存，又如何从工作内存写入到主存，该协议包含 8 个操作，并且要求 JVM 具体实现必须保证其中
每一种操作都是原子的、不可再分的。
JMM 主存与工作内存之间的交互协议的 8 个操作如表 4 - 5 所示。
表 4 - 5 JMM 内存模型的 8 个操作
操作作用对象说明
Read（读取） 主存作便用随于后主的存 Lo 变 ad 量操。作 Re 使 ad 用操作把一个变量的值从主存传输到工作内存中，以

```
Load（载入） 工作内存作入用工于作工内作存内的存变量的变副量本。中 L。o 变 ad 量操副作本将可 R 以 ea 简 d 操单作理从解主为存 C 中 PU 得的到高的速变缓量存值，载
```
```
Use（使用） 工作内存
```
```
作用于工作内存的变量。Use 操作将工作内存中的一个变量的值传递给执
行引擎。每当 JVM 遇到一个需要使用变量值的字节码指令时，执行 Use
操作
Assign（赋值） 工作内存作每用当于 JV 工 M 作遇内到存一的个变给量变。执量行赋引值擎的通字过节码 As 指 sig 令 n 时操，作执给行工作 As 内 sig 存 n 的操变作量赋值。
```
```
Store（存储） 工作内存作存用中于，工以作便内随存后的的变 W 量 rit。eS 操 to 作 re 使操用作将工作内存中的一个变量的值传递到主
```
```
Write（写入） 主存作入用主于存主的存变的量变中量。Write 操作将 Store 操作从工作内存中得到的变量值放
Lock（锁定） 主存作用于主存的变量，将一个变量标识为某个线程独占状态
Unlock（解锁） 主存作才用可于以主被存其的他变线量程，锁将定一个处于锁定状态的变量释放出来，释放后的变量
```
如果要把一个变量从主存复制到工作内存，就要按顺序执行 Read 和 Load 操作；如果要把变量
从工作内存同步回主存，就要按顺序执行 Store 和 Write 操作。

```
JMM 要求 Read 和 Load、Store 和 Write 必须按顺序执行，但不要求连续执行。也就
是说，Read 和 Load 之间、Store 和 Write 之间可插入其他指令。
```
JMM 主存与工作内存之间交互协议的 8 个操作之间的关系如图 4 - 15 所示。
Java 内存模型还规定了执行上述 8 个基本操作时必须满足如下规则：
1 ）不允许 read 和 load、store 和 write 操作之一单独出现，以上两个操作必须按顺序执行，但没
有保证必须连续执行，也就是说，read 与 load 之间、store 与 write 之间是可插入其他指令的。不允许
read 和 load、store 和 write 操作之一单独出现，意味着有 read 就有 load，不能读取了变量值而不予加载
到工作内存中；有 store 就有 write，也不能存储了变量值而不写到主存中。
2 ）不允许一个线程丢弃它的最近的 assign 操作，也就是说当线程使用 assign 操作对私有内存的
变量副本进行变更时，它必须使用 write 操作将其同步到主存中。


262 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

图 4 - 15 JMM 的 8 个操作之间的关系
3 ）不允许一个线程无原因地（没有发生过任何 assign 操作）把数据从线程的工作内存同步回
主存中。
4 ）一个新的变量只能从主存中“诞生”，不允许在工作内存中直接使用一个未被初始化（load
或 assign）的变量，换句话说，就是对一个变量实施 use 和 store 操作之前，必须先执行过了 assign 和
load 操作。
5 ）一个变量在同一个时刻只允许一条线程对其执行 lock 操作，但 lock 操作可以被同一个条线
程重复执行多次，多次执行 lock 后，只有执行相同次数的 unlock 操作，变量才会被解锁。
6 ）如果对一个变量执行 lock 操作，将会清空工作内存中此变量的值，在执行引擎使用这个变
量前，需要重新执行 load 或 assign 操作初始化变量的值。
7 ）如果一个变量实现没有被 lock 操作锁定，就不允许对它执行 unlock 操作，也不允许 unlock
一个被其他线程锁定的变量。
8 ）对一个变量执行 unlock 操作之前，必须先把此变量同步回主存（执行 store 和 write 操作）。
以上 JMM 的 8 大操作规范定义相当严谨，也极为烦琐，JVM 实现起来也非常复杂。Java 设计团
队大概也意识到了这个问题，新的 JMM 版本不断地对这些操作进行简化，比如将 8 个操作简化为
Read、Write、Lock 和 Unlock 四个操作。虽然进行了简化，但是 JMM 的基础设计并未改变。

```
JMM 的规范细节是 JVM 开发人员需要掌握的内容，对于普通的 Java 应用工程师、
应用架构师来说，只需要了解其基本的原理即可。
```
###### 4. 5. 4 JMM 如何解决有序性问题

JMM 如何解决顺序一致性问题？JMM 提供了自己的内存屏障指令，要求 JVM 编译器实现这些
指令，禁止特定类型的编译器和处理器重排序（不是所有的编译器重排序都要禁止）。


```
第 5 章 JUC 显式锁的原理与实战 | 263
```
1 .JMM 内存屏障
由于不同 CPU 硬件实现内存屏障的方式不同，JMM 屏蔽了这种底层 CPU 硬件平台的差异，定义
了不对应任何 CPU 的 JMM 逻辑层内存屏障，由 JVM 在不同的硬件平台生成对应的内存屏障机器码。
JMM 内存屏障主要有 Load 和 Store 两类，具体如下：
（ 1 ）LoadBarrier（读屏障）
在读指令前插入读屏障，可以让高速缓存中的数据失效，重新从主存加载数据。
（ 2 ）StoreBarrier（写屏障）
在写指令之后插入写屏障，能让高速缓存的最新数据写回主存。
在实际使用时，会对以上 JMM 的 LoadBarrier 和 StoreBarrier 两类屏障进行组合，组合成
LoadLoad（LL）、StoreStore（SS）、LoadStore（LS）、StoreLoad（SL）四个屏障，用于禁止特
定类型的处理器重排序。

（ 1 ）LoadLoad（LL）屏障
在执行预加载（或支持乱序处理）的指令序列中，通常需要显式声明 LoadLoad 屏障，因为这
些 Load 指令可能会依赖其他 CPU 执行的 Load 指令的结果。
一段使用 LoadLoad（LL）屏障的伪代码示例如下：
Load 1 ;LoadLoad; Load 2 ;
该示例的含义为：在 Load 2 要读取的数据被访问前，使用 LoadLoad 屏障保证 Load 1 要读取的数
据被读取完毕。
LoadLoad 屏障的 3 项工作：① 告诉编译器和 CPU 禁止对当前 LoadLoad 指令前的读操作进行指
令重排，确保这些读操作保持在当前 LoadLoad 指令的前面；②让高速缓存中的数据失效，重新从
主存加载数据；③告诉编译器和 CPU 禁止对当前 LoadLoad 指令后的读操作进行指令重排，确保这
些读操作保持在当前 LoadLoad 指令的后面。

（ 2 ）StoreStore（SS）屏障
通常情况下，如果 CPU 不能保证从高速缓冲向主存（或其他 CPU）按顺序刷新数据，那么它
需要使用 StoreStore 屏障。
使用 StoreStore（SS）屏障的伪代码示例如下：
Store 1 ;StoreStore; Store 2 ;
该示例的含义为：在 Store 2 及后续写入操作执行前，使 StoreStore 屏障保证 Store 1 的写入结果对
其他 CPU 可见。
StoreStore 屏障的 3 项工作：①告诉编译器和处理器禁止对当前 StoreStore 指令前的写操作进行
指令重排，确保这些写操作保持在当前 StoreStore 指令的前面；②让高速缓存的最新数据写回到主
存中；③告诉编译器和 CPU 禁止对当前 StoreStore 指令后的写操作进行指令重排，确保这些写操作
保持在当前 StoreStore 指令的后面。

（ 3 ）LoadStore（LS）屏障
该屏障用于在数据写入操作执行前，确保完成数据的读取。使用 LoadStore（LS）屏障的伪代
码示例如下：


264 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

Load 1 ;LoadStore; Store 2 ;
该示例的含义为：在 Store 2 及后续写入操作执行前，使 LoadStore 屏障保证 Load 1 要读取的数据
被读取完毕。
LoadStore 屏障的 3 项工作：①告诉编译器和 CPU 禁止对当前 LoadStore 指令前的读操作进行指
令重排，确保这些读操作保持在当前 LoadStore 指令的前面；②让高速缓存中的数据失效，重新从
主存加载数据；③告诉编译器和 CPU 禁止对当前 LoadStore 指令后的写操作进行指令重排，确保这
些写操作保持在当前 LoadStore 指令的后面。

（ 4 ）StoreLoad（SL）屏障
该屏障用于在数据读取操作执行前，确保完成数据的写入。使用 LoadStore（LS）屏障的伪代
码示例如下：
Store 1 ;StoreLoad; Load 2 ;
该示例的含义为：在 Load 2 及后续所有读取操作执行前，使 StoreLoad 屏障保证 Store 1 的写入对
所有 CPU 可见。
StoreLoad 屏障的 4 项工作：①告诉编译器和 CPU 禁止对当前 StoreLoad 指令前的写操作进行指
令重排，确保这些写操作保持在当前 StoreLoad 指令的前面；②让高速缓存的 Store 1 最新数据写回
到主存；③重新从主存加载数据；④告诉编译器和 CPU 禁止对当前 StoreLoad 指令后的读操作进
行指令重排，确保这些读操作保持在当前 StoreLoad 指令的后面。

2 .JMM 四个内存屏障的性能开销
StoreStore、LoadLoad 两个屏障性能高。在这两个屏障的上下文中，缓存和主存只需一种类型
的交互即可完成，JMM 只需要保障同类型交互的先后顺序即可。在 StoreStore 的上下文中，缓存和
主存只需要写入操作不需要读写操作；在 LoadLoad 的上下文中，缓存和主存只需要读取操作不需
要写入操作；内存屏障仅仅是保障同类型操作之间的次序，Cache 数据一致性的维护工作量相对较
小，所以 StoreStore、LoadLoad 屏障性能是比较高的。
LoadStore 的性能相对较低。这里涉及两类操作：读和写。此屏障要求数据加载执行在前，数
据写入执行在后，此屏障只是要求被加载数据的可见性，没有要求被后面 Store 操作写入数据的可
见性，所以这个屏障也没有高速缓存数据一致性的维护工作量。另外，此屏障限制了 Store 不能重
排到 Load 之前。综合起来，LoadStore 实际上没有高速缓存数据一致性的维护工作量，性能还是比
较高的。
StoreLoad 的性能最低，原因是需要维护高速缓存数据的一致性，需要的工作量最大。
如何维护高速缓存的数据一致性呢？在含有 StoreBuffer 组件的 CPU 平台上，数据一致性维护
工作非常繁重复杂。
首先，使用 StoreLoad 的缓存写入方不仅需要将存储缓存（StoreBuffer）刷入缓存行（CacheLine），
还要刷入到内存。如果不将存储缓存刷入主存，其他高速缓存可能读取到本地存储缓存/缓存行中
的旧数据，这就实际上把 Load 操作重排到 Store 操作的前面。
其次，在将存储缓存中的数据刷入主存之外，缓存写入方还要确保失效方的 InvalidateQueue
请求生效，从而保障失效方的缓存行变成 Invalid 状态。如果失效方的 InvalidateQueue 请求没有处理，
则失效方也有可能读到缓存行中的旧数据，这就实际上又把 Load 操作重排到 Store 操作的前面。


```
第 5 章 JUC 显式锁的原理与实战 | 265
```
正是由于 StoreLoad 需要维护高速缓存和主存中的数据一致性，因此相对其他三个屏障来说，
StoreLoad 的性能很低。
对应到物理硬件平台上，JMM 的 StoreLoad 屏障最终会编译成硬件层面的全屏障。而全屏障不
仅仅要让寄存器、高速缓存中的最新数据写回到主存（写屏障的功效），还要让高速缓存中的数据
失效、重新从主存加载数据（读屏障的功效）。另外，还全方位地禁止了对屏障指令前后的 store/load
指令进行重排序。所以，从具体实现角度来说，StoreLoad 屏障也是性能最低、开销最大的。
尽管 StoreLoad 屏障的开销是四种屏障中最大的，但是此屏障是一个“全能型”的屏障，兼具
其他 3 个屏障的效果，现代的多核 CPU 大多支持该屏障。

3 .主要 CPU 对 JMM 四个内存屏障的支持
不过这四个内存屏障只是 Java 为了跨平台而设计出来的，实际上根据 CPU 的不同，对应 CPU 平
台上的 JVM 可以优化一些内存屏障。
目前的主要 CPU 对 JMM 四个内存屏障支持具体如表 4 - 6 所示。
表 4 - 6 CPU 所支持的 JMM 内存屏障
CPU LoadStore LoadLoad StoreStore StoreLoad
Sparc-TSO
（SUN 和 TI 合作开发的 RISC 芯片） _no-op no-op no-op_ membar
X 86 _no-op no-op no-op_ mfence 或 cpuid 或 locked
IA 64 （英特尔安腾架构） st. relorld. acq ld. acq st. rel mf
ARM
（英国 Acorn 公司的 RISC 芯片） Dmb dmb dmb-st dmb
PPC（IBM 的 PowerPC 芯片） Lwsync hwsync lwsync hwsync
Alpha（DEC 公司的芯片） Mb mb wmb mb
PA-RISC
（惠普公司的 RISC 芯片） _no-op no-op no-op no-op_

#### 4. 6 Happens-Before 规则

JMM 的内存屏障指令对 Java 工程师是透明的，是 JMM 对 JVM 实现的一种规范和要求。那么，
作为 Java 工程师，如何确保自己设计和开发的 Java 代码不存在内存可见性问题或者有序性问题？
JMM 定义了一套自己的规则：Happens-Before（先行发生）规则，并且确保只要两个 Java 语句
之间必须存在 Happens-Before 关系，JMM 尽量确保这两个 Java 语句之间的内存可见性和指令有序性。

###### 4. 6. 1 Happens-Before 规则介绍

Happens-Before 规则的主要内容包括以下几个方面：
（ 1 ）程序顺序执行规则（as-if-serial 规则）
在同一个线程中，有依赖关系的操作按照先后顺序，前一个操作必须先行发生于后面一个操
作。换句话说，单个线程中的代码顺序不管怎么重排序，对于结果来说是不变的。


266 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

（ 2 ）volatile 变量规则
对 volatile（修饰的）变量的写操作必须先行发生于对 volatile 变量的读操作。
（ 3 ）传递性规则
如果 A 操作先行发生于 B 操作，而 B 操作又先行发生于 C 操作，那么 A 操作先行发生于 C 操作。
（ 4 ）监视锁规则（MonitorLockRule）
对一个监视锁的解锁操作先行发生于后续对这个监视锁的加锁操作。
（ 5 ）start 规则
对线程的 start 操作先行发生于这个线程内部的其他任何操作。具体来说，如果线程 A 执行
B.start () 启动线程 B，那么线程 A 的B.start () 操作先行发生于线程 B 中的任意操作。

（ 6 ）join 规则
如果线程 A 执行了B.join () 操作并成功返回，那么线程 B 中的任意操作先行发生于线程 A 所执行
的 ThreadB.join () 操作。

###### 4. 6. 2 规则 1 ：顺序性规则

顺序性规则的具体内容：一个线程内，按照代码顺序书写在前面的操作先行发生于书写在后
面的操作。
一段程序的执行，在单个线程中看起来是有序的。程序次序规则看起来是按顺序执行的，因
为虚拟机可能会对程序指令进行重排序。虽然进行了重排序，但是最终执行的结果是与程序顺序执
行的结果是一致的。它只会对不存在数据依赖行的指令进行重排序。
该规则就是前面介绍的 As-if-Serial 规则，仅仅用来保证程序在单线程执行结果的正确性，但是
无法保证程序在多线程执行结果的正确性。

###### 4. 6. 3 规则 2 ：volatile 规则

volatile 规则的具体内容：对一个 volatile 变量的写先行发生于任意后续对这个 volatile 变量的读。
基于 volatile 变量 Happens-Before 规则，罗列一下 volatile 操作与前后指令之间可否重排序的清单，
具体如表 4 - 7 所示。

表 4 - 7 volatile 操作与前后指令之间的可否重排序的清单
第二个操作
第一个操作
普通读/写 volatile 读 volatile 写
普通读/写 － － NO
volatile 读 NO NO NO
volatile 写 － NO NO
从表 4 - 7 最后一列可以看出：如果第二个操作为 volatile 写，不管第一个操作是什么都不能重排
序。这就确保了 volatile 写之前的操作不会被重排序到自己之后。
从表 4 - 7 的倒数第二行可以看出：如果第一个操作为 volatile 读，不管第二个操作是什么都不能
重排序。这确保了 volatile 读之后的操作不会被重排序到自己的前面。


```
第 5 章 JUC 显式锁的原理与实战 | 267
```
classVolatileReorderDemo
{
intx= 10 ;
intdoubleValue= 0 ;
booleanflag=false;
publicvoidupdate ()
{
doubleValue= 100 ; //①
flag=true; //②
}
publicvoiddoubleX ()
{
if (flag) //③
{
doubleValue=x+x;
}
}
}
假设线程 A 执行 update () 方法，线程 B 执行 doubleX () 方法，因为代码①和②没有数据依赖关系，
所以①和②可能被重排序，它们在重排后的次序为：
flag=true; //②
doubleValue = 100 ; //①
线程 A 执行重排之后代码，在完成语句②（flag=true）但没开始语句①（doubleValue= 100 ）
时，假设线程 B 开始执行 doubleX () 方法，将两个 doubleValue（此时值仍然为 10 ）累加，得到的
doubleValue 为 20 。具体的执行流程如图 4 - 16 所示。

图 4 - 16 重排后的代码执行流程示意图
为了获取正确的结果，必须阻止代码重排，为以上代码的 flag 成员属性增加 volatile 修饰，修改
后的代码如下：
classVolatileReorderDemo 2
{
intx= 10 ;


268 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

intdoubleValue= 0 ;
volatile booleanflag=false;
publicvoidupdate ()
{
value= 100 ; //①
flag=true; //②
}
publicvoiddoubleX ()
{
if (flag) //③
{
doubleValue=x+x; //④
}
}
}
从前面的规则已经知道：如果第二个操作为 volatile 写，无论第一个操作是什么都不能重排序。
拿上面的代码来说，由于代码②为写入 flag（volatile 变量）操作，因此代码①不会被重排序到代码
②的后面。
从前面的规则已经知道：如果第一个操作为 volatile 读，无论第二个操作是什么都不能重排序。
拿上面的代码来说，代码③为读取 flag（volatile 变量），代码④不会被重排序到代码③之前。

###### 4. 6. 4 规则 3 ：传递性规则

传递性规则的具体内容：如果 A 操作先行发生于 B 操作，且 B 操作先行发生于 C 操作，那么 A 操
作先行发生于 C 操作。
上一个小节的例子 VolatileReorderDemo 2 中也存在一个传递性规则，具体如图 4 - 17 所示。
从图 4 - 17 可以看出：value= 100 先行发生于 flag=true，这是规则 1 ；写变量 flag=true 先行发生于 if
（flag）读变量，这是规则 2 ；所以，根据规则 3 （传递性规则），value= 100 先行发生于读变量 if（flag）。

图 4 - 17 例子 VolatileReorderDemo 2 中的传递性规则
根据传递性规则，在 VolatileReorderDemo 2 执行过程中，如果线程 B 读到了 flag 是 true，那么
value= 100 对线程 B 就一定可见了。


```
第 5 章 JUC 显式锁的原理与实战 | 269
```
###### 4. 6. 5 规则 4 ：监视锁规则

监视锁规则的具体内容：对一个锁的 unlock 操作先行发生于后面对同一个锁的 lock 操作，即无
论在单线程还是多线程中，同一个锁如果处于被锁定状态，那么必须先对锁进行释放操作，后面才
能继续执行 lock 操作。
classVolatileReorderDemo 2
{
intx= 10 ;
intdoubleValue= 0 ;
booleanflag=false;
public synchronizedvoidupdate ()
{
value= 100 ; //①
flag=true; //②
}
public synchronizedvoiddoubleX ()
{
if (flag) //③
{
doubleValue=x+x; //④
}
}
}
先获取锁的线程，对 x 赋值之后释放锁，另一个再获取锁，一定能看到对 x 赋值的改动，就是
这么简单，请读者用如图 4 - 18 所示的命令查看上面的程序，看同步块和同步方法被转换成汇编指令
有什么不同。

图 4 - 18 使用命令查看程序
监视锁规则不会对临界区内的代码进行约束，临界区内的代码可以重排序（但 JMM 不允许临
界区内的代码“逸出”到临界区之外，那样会破坏监视器的语义）。JMM 会在退出临界区和进入
临界区这两个关键时间点做一些特殊处理，虽然线程 A 在临界区内进行了重排序，但由于监视器互
斥执行的特性，这里的线程 B 根本无法“观察”到线程 A 在临界区内的重排序。这种重排序既提高
了执行效率，又没有改变程序的执行结果。


270 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

###### 4. 6. 6 规则 5 ：start () 规则

start () 规则的具体内容：如果线程 A 执行 ThreadB.start () 操作启动线程 B，那么线程 A 的
ThreadB.start () 操作先行发生于线程 B 中的任意操作。反过来说，如果主线程 A 启动子线程 B 后，线
程 B 能看到线程 A 在启动操作前的任何操作。
packagecom. crazymakercircle. visiable;
importcom. crazymakercircle. util. Print;
publicclassStartExample
{
privateintx= 0 ;
privateinty= 1 ;
privatebooleanflag=false;
publicstaticvoidmain (String[]args) throwsInterruptedException
{
ThreadthreadB=newThread (startExample:: writer,"线程 B");
//启动线程 B 前，线程 A 进行了多个内存操作
Print.tcfo ("开始赋值操作");
startExample. x= 10 ;
startExample. y= 20 ;
startExample. flag=true;
threadB.start ();//启动线程 B
Print.tcfo ("线程结束");
}
publicvoidwriter ()
{
Print.tcfo ("x: "+x);
Print.tcfo ("y: "+y);
Print.tcfo ("flag: "+flag);
}
}
运行程序，结果如下：
[线程 A|StartExample. main]：开始赋值操作
[线程 A|StartExample. main]：线程结束
[线程 B|StartExample. writer]：x: 10
[线程 B|StartExample. writer]：y: 20
[线程 B|StartExample. writer]：flag:true
通过结果可以看出：线程 B 看到了线程 A 调用 threadB.start () 之前的所有赋值结果。

###### 4. 6. 7 规则 6 ：join () 规则

join () 规则的具体内容：如果线程 A 执行 threadB.join () 操作并成功返回，那么线程 B 中的任意操
作先行发生于线程 A 的 ThreadB.join () 操作。join () 规则和 start 规则刚好相反，线程 A 等待子线程 B 完成
后，当前线程 B 的赋值操作，线程 A 都能够看到。
packagecom. crazymakercircle. visiable;
importcom. crazymakercircle. util. Print;
publicclassJoinExample
{
privateintx= 0 ;
privateinty= 1 ;
privatebooleanflag=false;


```
第 5 章 JUC 显式锁的原理与实战 | 271
```
```
publicstaticvoidmain (String[]args) throwsInterruptedException
{
Thread.currentThread (). setName ("线程 A");
JoinExamplejoinExample=newJoinExample ();
ThreadthreadB=newThread (joinExample:: writer,"线程 B");
threadB.start ();
threadB.join ();//线程 Ajoin 线程 B
Print.tcfo ("x: "+joinExample. x);
Print.tcfo ("y: "+joinExample. y);
Print.tcfo ("flag: "+joinExample. flag);
Print.tcfo ("本线程结束");
}
publicvoidwriter ()
{
Print.tcfo ("开始赋值操作");
this. x= 100 ;
this. y= 200 ;
this. flag=true;
}
}
运行程序，结果如下：
[线程 B|JoinExample. writer]：开始赋值操作
[线程 A|JoinExample. main]：x: 100
[线程 A|JoinExample. main]：y: 200
[线程 A|JoinExample. main]：flag:true
[线程 A|JoinExample. main]：本线程结束
通过结果可以看出：线程 A 在调用了 threadB.join () 之后，看到了线程 B 所有的赋值结果。
```
#### 4. 7 volatile 语义中的内存屏障

在 Java 代码中，volatile 关键字的主要有两层语义：
 不同线程对 volatile 变量的值具有内存可见性，即一个线程修改了某个 volatile 变量的值，该
值对其他线程立即可见。
 禁止进行指令重排序。
总之，volatile 关键字除了保障内存可见性外，还能确保执行的有序性。volatile 语义中的有序
性是通过内存屏障指令来确保的。为了实现 volatile 关键字语义的有序性，JVM 编译器在生成字节码
时，会在指令序列中插入内存屏障来禁止特定类型的 CPU 重排序。
JMM 建议 JVM 采取保守策略对重排序进行严格禁止，下面是基于保守策略的 volatile 操作的内
存屏障插入策略：

```
 在每个 volatile 写操作的前面插入一个 StoreStore 屏障。
 在每个 volatile 写操作的后面插入一个 StoreLoad 屏障。
 在每个 volatile 读操作的后面插入一个 LoadLoad 屏障。
 在每个 volatile 读操作的后面插入一个 LoadStore 屏障。
```

272 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

###### 4. 7. 1 volatile 写操作的内存屏障

volatile 写操作的内存屏障插入策略为：在每个 volatile 写操作前插入 StoreStore（SS）屏障，在
写操作后面插入 StoreLoad 屏障，具体如图 4 - 19 所示。

图 4 - 19 volatile 写操作的内存屏障插入策略
StoreStore 屏障可以保证：①前面的写入不会重排的后面；②前面的写指令完成之后，高速
缓存数据刷入主存；③后面的写操作不会重排到前面。所以，在 volatile 写之前，其前面的所有普
通写操作已经对任意 CPU 可见了，并且 volatile 写操作不会被重排到屏障前面。
StoreLoad 屏障可以保证：①前面的写入不会重排的后面；②前面的写指令完成之后，高速
缓存数据刷入主存；③让高速缓存中的数据失效，重新从主存加载数据，保障各内核的高速缓存
数据的一致性；④后面的读操作不会重排到前面。所以，在 volatile 写完成之后，缓存中的已经刷
新成最新数据，后面所有 CPU 的读操作都可见了。

###### 4. 7. 2 volatile 读操作的内存屏障

volatile 读操作的内存屏障插入策略为：在每个 volatile 读操作后插入 LoadLoad（LL）屏障和
LoadStore 屏障，禁止后面的普通读、普通写和前面的 volatile 读操作发生重排序，具体如图 4 - 20 所示。

```
图 4 - 20 volatile 读操作的内存屏障插入策略
```

```
第 5 章 JUC 显式锁的原理与实战 | 273
```
LoadLoad 屏障可以保证：
1 ）前面的读操作不会被排到后面。
2 ）让高速缓存中的数据失效，重新从主存加载数据。
3 ）后面读操作不会被排到前面。
在 volatile 读之后，高速缓存中的数据是重新从主存加载的，并且是最新数据；另外，volatile
读操作不会被重排到屏障后面，后面的读操作也不会排到前面。
LoadStore 屏障可以保证：
1 ）前面的读操作不会被排到后面。
2 ）让高速缓存中的数据失效，重新从主存加载数据。
3 ）后面写操作不会被排到前面。
在 volatile 读之后，高速缓存中的数据是重新从主存加载的，并且是最新数据；另外，volatile
读操作不会被重排到屏障后面，后面的写（load）操作也不会排到前面。

关于 volatile 如何保证内存可见性的原理，一直以来都是面试的重点，也是面试
的难点。很多社群的读者反馈：JMM 对 volatile 读、volatile 写所使用的四个屏障总是记不住。
其实，这里的逻辑很简单。
对于 volatile 读来说，本身的指令是 load，如果需要保证可见性，只要后面的普通读、普通写，
不重排到前面就可以了。所以，在其后面加上 LoadLoad、LoadStore 屏障，这两个屏障指令
的第一个单词 Load，可以代表 volatile 读本身，两个屏障指令的后面的两个单词 Load、Store，
分别表示屏障后面的普通读、写操作。经过这样简单的理解是非常好记的。
同样，对于 volatile 写来说，本身的指令是 store，保证其可见性，需要其前面的普通写、后面
的普通读，不可以和自己重排。所以，在其前面加上 StoreStore、后面加上 StoreLoad 屏障，
第一个指令第二单词、第二个指令第一个单词都代表 volatile 写的本身；然而，第一个指令的
第一单词，所代表的是前面的写操作，第二个指令的第二个单词，所代表的是后面的读操作。
所以，经过这样简单的理解是非常好记的。
以上 JMM 建议的对 volatile 写和 volatile 读的内存屏障插入策略，是针对任意 CPU 平台的，所以
非常保守。
由于不同的 CPU 有不同“松紧度”的 CPU 内存模型，只要不改变 volatile 读写操作的内存语义，
不同 JVM 编译器可以根据具体情况省略不必要的 JMM 屏障。以 X 86 CPU 为例，该平台的 JVM 实现
仅仅在 volatile 写操作后面插入一个 StoreLoad 屏障，其他的 JMM 屏障都会被省略。由于 StoreLoad 屏
障的开销大，因此在 X 86 CPU 中，volatile 写操作比 volatile 读操作的开销会大很多。

###### 4. 7. 3 对 volatile 变量的写入进行性能优化

由于对一个 volatile 变量的每一次读写，JVM 都会插入一系列的内存屏障，这就意味着对一个
volatile 变量每一次的写入操作，性能是比较低的。
由于保障 volatile 可见性的内存屏障性能开销比较大，尤其 StoreLoad 屏障更是如此，为了维护
内核缓存的强一致性，此屏障可畏不惜代价。


274 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

如果不是每一次对 volatile 变量的读写都需要保障其内存可见性，或者说，仅仅是某次特定的
volatile 读写需要保障可见性，那么，有什么措施可以对 volatile 进行性能优化吗？
答案是：有两个策略。
1 ）对于普通变量，使用 Unsafe.putXXXVolatile () 或者 Unsafe.getXXXVolatile ()，保障单次操作
的内存可见性，或者有序性。
2 ）对于 volatile 修饰的变量，如果写入时不需要保障立即可见，或者说不需要保障不同内核高
速缓存之间的强一致，则能以 Unsafe.putOrderXXX () 方法写入，保障写入操作的有序性即可。这种
做法是很多著名中间件（比如 Netty、JCTools 等）常用的提升性能的方案。

```
JCTools（JavaConcurrencyTools）是一个开源工具包，在 ApacheLicense 2. 0 下
发布，并在 Netty、Rxjava 等诸多框架中被广泛使用。JCTools 提供了一系列非阻塞并发数据
结构（标准 Java 中缺失的），当存在线程争抢时，非阻塞并发数据结构比阻塞并发数据结构
能提供更好的性能。
```
通过 Unsafe.putXXXVolatile () 或者 Unsafe.getXXXVolatile () 方法，可以基于普通变量的内存地址
进行其值的读写，并且实现 volatile 语义。XXX 代表基础的数据类型如 Object、int、long 等。
下面以两个 Unsafe.putXXXVolatile () 类型的方法作为例子：
/**
*保存一个引用到一个 Java 成员变量，实现 volatile 语义
*/
publicnativevoidputObjectVolatile (Objecto, longoffset, Objectx);
/**volatile 版本 of{@link #putInt (Object, long, int)} */
publicnativevoidputIntVolatile (Objecto, longoffset, intx);
Unsafe.putXXXVolatile () 等效于在写入的前后，插入 StoreStore 屏障、StoreLoad 屏障。
下面以两个 Unsafe.getXXXVolatile () 类型的方法作为例子：
/**
*获取一个 Java 成员变量，实现 volatile 语义
*/
publicnativeObjectgetObjectVolatile (Objecto, longoffset);
/**volatile 版本 of{@link #getInt (Object, long)} */
publicnativevoidgetIntVolatile (Objecto, longoffset);
Unsafe.getXXXVolatile () 等效于在读取的后面，插入两个屏障：LoadStore 屏障和 LoadLoad 屏障，
防止后面的写入、读取操作进行指令重排。
Unsafe.putXXXVolatile () 或者 Unsafe.getXXXVolatile () 等效于给相应的成员变量加上 volatile 关
键字，通过 API 的方式手动让编译后的代码插入内存屏障，实现 volatile 语义以保证内存可见性和防
止指令重排。
Unsafe.putXXXVolatile () 或者 Unsafe.getXXXVolatile () 的优势在于，其粒度更小，只对需要的地
方进行内存可见性保证和防止指令重排，而不是像 volatile 关键字一样，所有的读写都自动插入内存
屏障。
第二种 volatile 性能提升的方式：对于 volatile 修饰的变量，如果写入时不需要保障可见性或者
可以延迟可见，此时可以通过 Unsafe.putOrderXXX () 方法进行写入，保障写入操作的有序性即可。


```
第 5 章 JUC 显式锁的原理与实战 | 275
```
比如 Netty、JCTools 等著名中间组件的源码中就大量的使用 Unsafe. putOrderXXX 方法。
下面以两个 Unsafe.putOrderXXX () 类型的方法作为例子：
/**
*延迟保存一个引用到一个 Java 成员变量，不保障立即可见，只针对于 volatile 成员有效
*/
publicnativevoidputOrderedObject (Objecto, longoffset, Objectx);
/**延迟/有序版本 of{@link #putIntVolatile (Object, long, int)} */
publicnativevoid putOrderedInt (Objecto, longoffset, intx);
Unsafe.putOrderXXX () 类型的方法等效于在写入的前面插入 StoreStore 屏障，由于不保障可见，
因此去掉 Unsafe.putXXXVolatile () 插入在写入操作后面的 StoreLoad 屏障。正是因为去掉 StoreLoad 屏
障，所以此方法是对 volatile 变量写入操作的一次显著性能提升。
StoreStore 屏障只保证禁止重排序，不保证内存可见性，从而实现一次轻量级的写入，在特定
场景能优化性能，保障了最终一致性。
当然，性能提升是有代价的，虽然 Unsafe.putOrderXXX () 类型的方法性能高，但是写入的结果
并不会立即被其他线程看到。

#### 4. 8 volatile 不具备原子性

volatile 能保证数据的可见性，但 volatile 不能完全保证数据的原子性，对于 volatile 类型的变量
进行复合操作（如++）其仍存在线程不安全的问题。

###### 4. 8. 1 volatile 变量的自增实例

下面的例子使用 10 个线程，每个线程进行 1000 次自增操作（复合操作），看看最终的结果是
否正确，具体的代码如下：
packagecom. crazymakercircle. visiable;
//省略 import
publicclassVolatileDemo
{
privatevolatilelongvalue;
@org. junit. Test
publicvoidtestAtomicLong ()
{
//并发任务数
finalintTASK_AMOUNT= 10 ;
//线程池，获取 CPU 密集型任务线程池
ExecutorServicepool=ThreadUtil.getCpuIntenseTargetThreadPool ();
//每个线程的执行轮数
finalintTURNS= 10000 ;
//线程同步倒数闩
CountDownLatchcountDownLatch=newCountDownLatch (TASK_AMOUNT);
longstart=System.currentTimeMillis ();
for (inti= 0 ;i<TASK_AMOUNT; i++)
{
pool.submit (()->
{


276 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
try
{
for (intj= 0 ;j<TURNS; j++)
{
value++;
}
}catch (Exceptione)
{
e.printStackTrace ();
}
//倒数闩，倒数一次
countDownLatch.countDown ();
});
}
//省略，等待倒数闩完成所有的倒数操作
floattime=(System.currentTimeMillis ()-start)/ 1000 F;
//输出统计结果
Print.tcfo ("运行的时长为："+time);
Print.tcfo ("累加结果为："+value);
Print.tcfo ("与预期相差："+(TURNS*TASK_AMOUNT-value));
}
}
运行以上程序，执行的结果如下：
[main|VolatileDemo. testAtomicLong]：运行的时长为： 0. 089
[main|VolatileDemo. testAtomicLong]：累加结果为： 45897
[main|VolatileDemo. testAtomicLong]：与预期相差： 54103
通过实验可以看出：volatile 变量的复合操作不具备原子性。
```
###### 4. 8. 2 volatile 变量的复合操作不具备原子性的原理

```
首先，回顾一下 JMM 对变量进行读取和写入的操作流程，具体如图 4 - 21 所示。
```
图 4 - 21 JMM 对变量进行读取和写入的操作流程
对于非 volatile 修饰的普通变量而言，在读取变量时，JMM 要求保持 read、load 有相对顺序即可。
例如，若从主存读取 i、j 两个变量，可能的操作是 readi=>readj=>loadj=>loadi，并不要求 read、load
操作是连续的。


```
第 5 章 JUC 显式锁的原理与实战 | 277
```
对于关键字 volatile 修饰的内存可见变量而言，具有两个重要的语义：
1 ）使用 volatile 修饰的变量在变量值发生改变时，会立刻同步到主存，并使其他线程的变量副
本失效。
2 ）禁止指令重排序：用 volatile 修饰的变量在硬件层面上会通过在指令前后加入内存屏障来实
现，编译器级别是通过下面的规则实现的。

为了实现这些 volatile 内存语义，JMM 对于 volatile 变量会有特殊的约束：
1 ）使用 volatile 修饰的变量其 read、load、use 都是连续出现的，所以每次使用变量时都要从主
存读取最新的变量值，替换私有内存的变量副本值（如果不同的话）。
2 ）其对同一变量的 assign、store、write 操作都是连续出现的，所以每次对变量的改变都会立
即同步到主存中。

稍加思考就可以理解，虽然 volatile 修饰的变量可以强制刷新内存，但是其并不具备原子性。
虽然其要求对变量的（read、load、use）、（assign、store、write）必须是连续出现，但是在不同
CPU 内核上并发执行的线程还是有可能出现读取脏数据的时候。
以前面的 VolatileDemo 为例，假设有两个线程 A、B 分别运行在 Core 1 、Core 2 上，并假设此时
的 value 为 0 ，线程 A、B 也都把 value 值读取到自己的工作内存中。
现在线程 A 将 value 变成 1 之后，完成了 assign、store 的操作，假设在执行 write 指令之前，线程 A
的 CPU 时间片用完，线程 A 被空闲，但是线程 A 的 write 操作没有到达主存。由于线程 A 的 store 指令
触发了写的信号，线程 B 缓存过期，重新从主存读取到 value 值，但是线程 A 的写入没有最终完成，
线程 B 读到的 value 值还是 0 。线程 B 执行完成所有的操作之后，将 value 变成 1 写入主存。线程 A 的时
间片重新拿到，重新执行 store 操作，将过期了的 1 写入主存。
线程 A、线程 B 并发操作 value 时可能发生脏数据写入的具体流程，大致如图 4 - 22 所示。

图 4 - 22 线程 A、线程 B 并发操作 value 时可能发生脏数据写入的流程
对于复合操作，volatile 变量无法保障其原子性，如果要保证复合操作的原子性，需要使用锁。
并且，在高并发场景下，volatile 变量一定需要使用 Java 的显式锁结合使用。


278 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

# 第 5 章

## JUC 显式锁的原理与实战

与 Java 内置锁不同，JUC 显式锁提供了一种非常灵活的、使用纯 Java 语言基本的锁，这种锁的
使用非常灵活，可以进行无条件的、可轮询的、定时的、可中断的锁获取和释放操作。由于 JUC 锁
的加锁和解锁的方法都是通过 JavaAPI 显式进行的，所以也叫显式锁。

#### 5. 1 显式锁

使用 Java 内置锁时，不需要通过 Java 代码显式地对同步对象的监视器进行抢占和释放，这些工
作由 JVM 底层完成，而且任何一个 Java 对象都能作为一个内置锁使用，所以，Java 的对象锁使用起
来非常方便。但是，Java 内置锁的功能相对单一，不具备一些比较高级的锁功能，比如：

1 ）限时抢锁：在抢锁时设置超时时长，如果超时还未获得锁就放弃，不至于无限等下去。
2 ）可中断抢锁：在抢锁时，外部线程给抢锁线程发出一个中断信号，就能唤起等待锁的线程，
并终止抢占过程。
3 ）多个等待队列：为锁维持多个等待队列，以便提高锁的效率。比如在生产者－消费者模式
实现中，生产者和消费者共用一把锁，该锁上维持两个等待队列，即一个生产者队列和一个消费者
队列。

除了以上功能问题之外，Java 对象锁还存在性能问题。在竞争稍微激烈的情况下，Java 对象锁
会膨胀为重量级锁（基于操作系统的 MutexLock 实现），而重量级锁的线程阻塞和唤醒操作需要进
程在内核态和用户态之间来回切换，导致其性能非常低。所以，迫切需要提供一种新的锁来提升争
用激烈场景下锁的性能。
Java 显式锁就是为了解决这些 Java 对象锁的功能问题、性能问题而生的。JDK 5 版本引入了 Lock
接口，Lock 是 Java 代码级别的锁。为了与 Java 对象锁相区分，Lock 接口被称为显式锁接口，其对象
实例则被称为显式锁对象。


```
第 5 章 JUC 显式锁的原理与实战 | 279
```
###### 5. 1. 1 显式锁 Lock 接口

JDK 5 版本引入了 java. util. concurrent 并发包，简称为 JUC 包，里面提供了各种高并发工具类，
通过此 JUC 工具包可以在 Java 代码中实现功能非常强大的多线程并发操作。所以，Java 显式锁也被
称为 JUC 显式锁。

```
JUC 出自并发大师 DougLea 之手，DougLea 对 Java 并发性能的提升做出了巨大的
贡献。除了实现 JUC 包外，DougLea 还提供了高并发 IO 模式——Reactor 模式多个版本的参考
实现。Reactor 模式是 Java 高并发服务端编程的一个至关重要的模式，有关其原理和详细知识，
请参考本书的上一卷《Java 高并发核心编程卷 1 （加强版）：NIO、Netty、Redis、ZooKeeper》。
```
Lock 接口位于 java. util. concurrent. locks 包中，是 JUC 显式锁的一个抽象，Lock 接口的主要抽象
方法，如表 5 - 1 所示。

```
表 5 - 1 Lock 接口的主要抽象方法
方法描述
voidlock () 抢锁。成功则向下运行，若失败则阻塞抢锁线程
voidlockInterruptibly ()
throwsInterruptedException 可中断抢锁，当前线程在抢锁的过程中可以响应中断信号
booleantryLock () 尝试抢锁，线程为非阻塞模式，在调用
tryLock 方法后立即返
回。若抢锁成功则返回 true，若抢锁失败则返回 false
booleantryLock (longtime, TimeUnitunit)
throwsInterruptedException
```
```
限时抢锁，到达超时时间返回 false。并且此限时抢锁方法也可
以响应中断信号
voidunlock (); 释放锁
ConditionnewCondition (); 获式取的与线显程式间锁通绑信定的 Condition 对象，用于“等待－通知”方
```
JUC 包中提供了一系列的显式锁实现类（如 ReentrantLock），当然也允许应用程序提供自定义
的锁实现类。
与 synchronized 关键字不同，显式锁不再作为 Java 内置特性来实现，而是作为 Java 语言可编程
特性来实现。这就为多种不同功能的锁实现留下了空间，各种锁实现可能有不同的调度算法、性能
特性或者锁定语义。
从 Lock 提供的接口方法可以看出，显式锁至少比 Java 内置锁多了以下优势：
（ 1 ）可中断获取锁
使用 synchronized 关键字获取锁的时候，如果线程没有获取到被阻塞，阻塞期间该线程是不响
应中断信号（interrupt）的；而使用 Lock.lockInterruptibly () 方法获取锁时，如果线程被中断，线程
将抛出中断异常。

（ 2 ）可非阻塞获取锁
使用 synchronized 关键字获取锁时，如果没有成功获取，线程只有被阻塞；而使用 Lock.tryLock ()
方法获取锁时，如果没有获取成功，线程也不会被阻塞，而是直接返回 false。


280 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

（ 3 ）可限时抢锁
使用 Lock.tryLock (longtime, TimeUnitunit) 方法，显式锁可以设置限定抢占锁的超时时间。而
在使用 synchronized 关键字获取锁时，如果不能抢到锁，线程只能无限制阻塞。

除了以上能通过 Lock 接口直接观察出来的三点优势之外，显式锁还有不少其他的优势，稍后
在介绍显式锁的种类繁多的实现类时，大家就能感觉到。

###### 5. 1. 2 可重入锁 ReentrantLock

ReentrantLock 是 JUC 包提供的显式锁的一个基础实现类，ReentrantLock 类实现了 Lock 接口，它
拥有与 synchronized 相同的并发性和内存语义，但是拥有了限时抢占、可中断抢占等一些高级锁特
性。此外，ReentrantLock 基于内置的抽象队列同步器（AbstractQueuedSynchronized，AQS）实现，
在争用激烈场景下，能表现出表内置锁更佳的性能。

```
抽象队列同步器是 JUC 包同步机制的基础设施，更是 JUC 锁框架的基础，会在第
6 章进行重点和专题介绍。
```
ReentrantLock 是一个可重入的独占（或互斥）锁，其中两个修饰词的含义为：
1 ）可重入的含义：表示该锁能够支持一个线程对资源的重复加锁，也就是说，一个线程可以
多次进入同一个锁所同步的临界区代码块。比如，同一线程在外层函数获得锁后，在内层函数能再
次获取该锁，甚至多次抢占到同一把锁。
下面是一段对可重入锁进行两次抢占和释放的伪代码，具体如下：
lock.lock (); //第一次获取锁
lock.lock (); //第二次获取锁，重新进入
try{
//临界区代码块
}finally{
lock.unlock (); //释放锁
lock.unlock (); //第二次释放锁
}
2 ）独占的含义：在同一时刻只能有一个线程获取到锁，而其他获取锁的线程只能等待，只有
拥有锁的线程释放了锁后，其他的线程才能够获取锁。
一个使用 ReentrantLock 进行同步累加的演示案例如下：
packagecom. crazymakercircle. demo. lock;
//省略 import
publicclassLockTest
{
@org. junit. Test
publicvoidtestReentrantLock ()
{
//每个线程的执行轮数
finalintTURNS= 1000 ;
//线程数
finalintTHREADS= 10 ;
//线程池，用于多线程模拟测试
ExecutorServicepool=Executors.newFixedThreadPool (THREADS);
//创建一个可重入、独占锁对象


```
第 5 章 JUC 显式锁的原理与实战 | 281
```
Locklock=newReentrantLock ();
//倒数闩
CountDownLatchcountDownLatch=newCountDownLatch (THREADS);
longstart=System.currentTimeMillis ();
// 10 个线程并发执行
for (inti= 0 ;i<THREADS; i++)
{
pool.submit (()->
{
try
{
//累加 1000 次
for (intj= 0 ;j<TURNS; j++)
{
//传入锁，执行一次累加
IncrementData.lockAndFastIncrease (lock);
}
Print.tco ("本线程累加完成");
}catch (Exceptione)
{
e.printStackTrace ();
}
//线程执行完成，倒数闩减少一次
countDownLatch.countDown ();
});
}
try
{
//等待倒数闩归零，所有线程结束
countDownLatch.await ();
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}
floattime=(System.currentTimeMillis ()-start)/ 1000 F;
//输出统计结果
Print.tcfo ("运行的时长为："+time);
Print.tcfo ("累加结果为："+IncrementData. sum);
}
//省略其他代码
}
分离变与不变是软件设计的一个基本原则。
本章后续会演示多种锁（包括乐观锁、悲观锁、公平锁、可中断锁、自旋锁等）的使用，在
这些使用案例中，变化的部分为锁的创建代码，而不变的部分为锁的使用代码。因为 JUC 中的显式锁
都实现了 Lock 接口，所以对于不同锁对象的使用代码是模板化的、套路化的。我们可以将演示案例
中创建锁的代码（变化的部分）和使用锁的代码（不变的部分）进行分离。
出于“分离变与不变的”的设计原则，这里将临界区使用锁的代码进行了抽取和封装，形成
一个可以复用的独立类——IncrementData 累加类，具体代码如下：
packagecom. crazymakercircle. demo. lock;
//省略 import
//封装锁的使用代码
publicclassIncrementData
{
publicstaticintsum= 0 ;
publicstaticvoidlockAndFastIncrease (Locklock)
{


282 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

lock.lock ();//step 1 ：抢占锁
try
{
//step 2 ：执行临界区代码
sum++;
}finally
{
lock.unlock ();//step 3 ：释放锁
}
}
//省略其他代码
}
运行以上使用 ReentrantLock 进行累加同步的演示案例，其结果如下：
[pool- 1 - thread- 2 ]：本线程累加完成
[pool- 1 - thread- 9 ]：本线程累加完成
[pool- 1 - thread- 3 ]：本线程累加完成
[pool- 1 - thread- 5 ]：本线程累加完成
[pool- 1 - thread- 1 ]：本线程累加完成
[pool- 1 - thread- 4 ]：本线程累加完成
[pool- 1 - thread- 6 ]：本线程累加完成
[pool- 1 - thread- 10 ]：本线程累加完成
[pool- 1 - thread- 8 ]：本线程累加完成
[pool- 1 - thread- 7 ]：本线程累加完成
[main|LockTest. testReentrantLock]：运行的时长为： 0. 126
[main|LockTest. testReentrantLock]：累加结果为： 10000
除了具体可重入、独占特性之外，ReentrantLock 还支持公平锁和非公平锁两种模式。有关公
平锁与非公平锁的内容，稍后为大家展开介绍。

###### 5. 1. 3 使用显式锁的模板代码

上一小节讲到，因为 JUC 中的显式锁都实现了 Lock 接口，所以不同类型的显式锁对象的使用方
法都是模板化的、套路化的，本小节专门介绍一下使用显式锁的模板代码。

1 .使用 lock () 方法抢锁的模板代码
通常情况下，大家会使用 lock () 方法进行阻塞式的锁抢占，其模板代码如下：
//创建所对象，SomeLock 为 Lock 的某个实现类，如 ReentrantLock
Locklock=newSomeLock ();
lock.lock (); //step 1 ：抢占锁
try{
//step 2 ：抢锁成功，执行临界区代码
}finally{
lock.unlock (); //step 3 ：释放锁
}
以上抢锁模板代码有以下几个需要注意的要点：
1 ）释放锁操作 lock.unlock () 必须在 try-catch 结构的 finally 块中执行，否则，如果临界区代码抛
出异常，锁就有可能永远得不到释放。
2 ）抢占锁操作 lock.lock () 必须在 try 语句块之外，而不是放在 try 块之内。为什么呢？原因之一
是 lock () 方法没有声明抛出异常，所以可以不包含到 try 块中；原因之二是 lock () 方法并不是一定能够
抢占锁成功，如果没有抢占成功，当然也就不需要释放锁，而且在没有占有锁的情况下去释放锁，
可能会导致运行时异常。


```
第 5 章 JUC 显式锁的原理与实战 | 283
```
3 ）在抢占锁操作 lock.lock () 和 try 语句之间不要插入任何代码，避免抛出异常而无法执行释放
锁操作 lock.unlock ()，导致锁无法被释放。

一段错误的抢锁代码大致如下：
Locklock=newSomeLock ();
try{
lock.lock (); //注意：抢锁操作在 try 语句块之内
//抢锁成功，执行临界区代码
}finally{
lock.unlock ();
}
以上代码的抢锁操作在 try 语句块之内，如果抢锁操作没有成功，也就是如果当前线程没有获
取到锁，在 finally 语句块调用 unlock () 方法时就会抛出异常。

2 .调用 tryLock () 方法非阻塞抢锁的模板代码
lock () 是阻塞式抢占，在没有抢到锁的情况下，当前线程会阻塞。如果不希望线程阻塞，可以
使用 tryLock () 方法抢占锁。tryLock () 是非阻塞抢占，在没有抢到锁的情况下，当前线程会立即返回，
不会被阻塞。
调用 tryLock () 方法非阻塞抢占锁，大致的模板代码如下：
//创建所对象，SomeLock 为 Lock 的某个实现类，如 ReentrantLock
Locklock=newSomeLock ();
if (lock.tryLock ()){ //step 1 ：尝试抢占锁
try{
//step 2 ：抢锁成功，执行临界区代码
}finally{
lock.unlock (); //step 3 ：释放锁
}
}
else
{
//step 4 ：抢锁失败，执行后备动作
}
使用 tryLock () 方法时，线程拿不到锁就立即返回，这种处理方式在实际开发中使用不多，但是
其重载版本 tryLock (longtime, TimeUnitunit) 方法在限时阻塞抢锁的场景中非常有用。

3 .调用 tryLock (longtime, TimeUnitunit) 方法抢锁的模板代码
tryLock (longtime, TimeUnitunit) 方法用于限时抢锁，该方法在抢锁时会进行一段时间的阻塞等
待，其 time 参数代表最大的阻塞时长，其 unit 参数为时长的单位（如秒）。
调用 tryLock (longtime, TimeUnitunit) 方法限时抢锁，其大致的代码模板如下：
//创建所对象，SomeLock 为 Lock 的某个实现类，如 ReentrantLock
Locklock=newSomeLock ();
//抢锁时阻塞一段时间，如 1 秒
if (lock.tryLock ( 1 ,TimeUnit. SECONDS)){ //step 1 ：限时阻塞抢占
try{
//step 2 ：抢锁成功，执行临界区代码
}finally{
lock.unlock (); //step 3 ：释放锁


284 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

}
}
else
{
//限时抢锁失败，执行后备动作
}
对 lock ()、tryLock ()、tryLock (longtime, TimeUnitunit) 这三个方法的总结如下：
1 ）lock () 方法用于阻塞抢锁，抢不到锁时线程会一直阻塞。
2 ）tryLock () 方法用于尝试抢锁，该方法有返回值，如果成功则返回 true，如果失败（即锁已
被其他线程获取）则返回 false。此方法无论如何都会立即返回，在抢不到锁时，线程不会像使用 lock ()
方法那样一直被阻塞。
3 ）tryLock (longtime, TimeUnitunit) 方法和 tryLock () 方法是类似的，只不过这个方法在抢不到
锁时会阻塞一段时间。如果在阻塞期间获取到锁立即返回 true，超时则返回 false。

###### 5. 1. 4 基于显式锁进行“等待－通知”方式的线程间通信

在前面介绍 Java 的线程间通信机制时，基于 Java 内置锁实现一种简单的“等待－通知”方式的
线程间通信：通过 Object 对象的 wait、notify 两类方法作为开关信号，用来完成通知方线程和等待方
线程之间的通信。
“等待－通知”方式的线程间通信机制，具体来说是指一个线程 A 调用了同步对象的 wait () 方
法进入等待状态，而另一个线程 B 调用了同步对象的 notify () 或者 notifyAll () 方法去唤醒等待线程；
当线程 A 收到线程 B 的唤醒通知后，就可以重新开始执行。
需要特别注意的是：在通信过程中，线程需要拥有同步对象的监视器，在执行 Object 对象的
wait ()、notify () 方法之前，线程必须先通过抢占到内置锁而成为其监视器的 Owner。
与 Object 对象的 wait ()、notify () 两类方法类似，基于 Lock 显式锁 JUC 也为大家提供了一个用于
线程间进行“等待－通知”方式通信的接口——java. util. concurrent. locks. Condition。

```
1 .Condition 接口的主要方法
Condition 接口的主要方法如下：
publicinterfaceCondition
{
//方法 1 ：等待。此方法在功能上与 Object.wait () 语义等效
//使当前线程加入 await () 等待队列中，并释放当前锁
//当其他线程调用 signal () 时，等待队列中的某个线程会被唤醒，重新去抢锁
voidawait () throwsInterruptedException;
//方法 2 ：通知。此方法在功能上与 Object.notify () 语义等效
//唤醒一个在 await () 等待队列中的线程
voidsignal ();
//方法 3 ：通知全部。唤醒 await () 等待队列中所有的线程
//此方法与 object.notifyAll () 语义上等效
voidsignalAll ();
//方法 4 ：限时等待。此方法与 await () 语义等效
//不同点在于，在指定时间 time 等待超时后，如果没有被唤醒，线程将中止等待
//线程等待超时返回 false，其他情况返回 true
booleanawait (longtime, TimeUnitunit) throwsInterruptedException;
}
```

```
第 5 章 JUC 显式锁的原理与实战 | 285
```
以上是 Condition 接口的常用方法，await（系列）方法对应于 Object.wait () 方法，signal () 方法对
应于 Object.notify () 方法，signalAll () 方法对应于 Object.notifyAll () 方法。

```
为了避免与 Object 中的 wait/notify/notifyAll () 方法在使用时发生混淆，JUC 对
Condition 接口的方法改变了名称，同样的 wait ()/notify ()/notifyAll () 方法，在 Condition 接口中
名称被改为 await ()/signal ()/signalAll () 方法。
```
Condition 的“等待－通知”方法和 Object 的“等待－通知”方法的语义等效关系为：
 Condition 类的 await () 方法和 Object 类的 wait () 方法等效。
 Condition 类的 signal () 方法和 Object 类的 notify () 方法等效。
 Condition 类的 signalAll () 方法和 Object 类的 notifyAll () 方法等效。
Condition 对象的 signal（通知）方法和同一个对象的 await（等待）方法是一一配对使用的，也就
是说，一个 Condition 对象的 signal（或 signalAll）方法不能去唤醒其他 Condition 对象上的 await 线程。
Condition 对象是基于显式锁的，所以不能独立创建一个 Condition 对象，而是需要借助于显式
锁实例去获取其绑定的 Condition 对象。不过，每一个 Lock 显式锁实例可以有任意数量的 Condition
对象。具体来说，可以通过 lock.newCondition () 方法去获取一个与当前显式锁绑定的 Condition 实例，
然后通过该 Condition 实例即可进行“等待－通知”方式的线程间通信。

```
2 .显式锁 Condition 演示案例
下面是一个简单的通过 Condition 完成线程间“等待－通知”方式通信的演示实例：
packagecom. crazymakercircle. demo. lock;
//省略 import
publicclassReentrantCommunicationTest
{
//创建一个显式锁
staticLocklock=newReentrantLock ();
//获取一个显式锁绑定的 Condition 对象
staticprivateConditioncondition=lock.newCondition ();
//等待线程的异步目标任务
staticclassWaitTargetimplementsRunnable
{
publicvoidrun ()
{
lock.lock (); //①抢锁
try
{
Print.tcfo ("我是等待方");
condition.await (); //②开始等待，并且释放锁
Print.tco ("收到通知，等待方继续执行");
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}finally
{
lock.unlock (); //释放锁
}
}
}
```

286 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

//通知线程的异步目标任务
staticclassNotifyTargetimplementsRunnable
{
publicvoidrun ()
{
lock.lock (); //③抢锁
try
{
Print.tcfo ("我是通知方");
condition.signal (); //④发送通知
Print.tco ("发出通知了，但是线程还没有立马释放锁");
}finally
{
lock.unlock (); //⑤释放锁之后，等待线程才能获得所
}
}
}
publicstaticvoidmain (String[]args) throwsInterruptedException
{
//创建等待线程
ThreadwaitThread=newThread (newWaitTarget (),"WaitThread");
//启动等待线程
waitThread.start ();
sleepSeconds ( 1 );//稍等一下
//创建通知线程
ThreadnotifyThread=newThread (newNotifyTarget (),"NotifyThread");
//启动通知线程
notifyThread.start ();
}
}
执行以上代码，大致结果如下：
[WaitThread|ReentrantCommunicationTest$WaitTarget. run]：我是等待方
[NotifyThread|ReentrantCommunicationTest$NotifyTarget. run]：我是通知方
[NotifyThread]：发出通知了，但是线程还没有立马释放锁
[WaitThread]：收到通知，等待方继续执行
以上演示案例中，使用 ReentrantLock（重入锁）作为显式锁的实现类，然后通过该显式锁去
获取一个 Condition 实例。
在调用 await () 方法前，等待线程必须获得显式锁（如语句①），await () 方法会让当前线程加入
到 Condition 对象等待队列中。在语句②调用 await () 方法后，线程会释放当前占用的显式锁，以便通
知线程能够抢到锁。通知线程能够抢到锁之后，才能进行入临界区发送通知。
不过，在调用 signal () 方法前，通知线程也必须获得相应显式锁（如语句③）。在语句④调用
signal () 方法后，JUC 会从 Condition 对象等待队列中唤醒一个线程。当等待线程被唤醒后，将会重新
尝试获得与 Condition 对象绑定的显式锁，一旦抢占成功将继续执行。
所以，通知线程在调用 signal () 方法后，一定要记得释放当前占用的显式锁（如语句⑤），只
有这样，被唤醒的等待线程才能有获得锁的机会，才能继续执行。
由于 Lock 有公平锁和非公平锁之分，而 Condition 是与 Lock 绑定的，所以就有与 Lock 一样的公
平特性：如果是公平锁，等待线程为按照 FIFO（先进先出）顺序从 Condition 对象的等待队列中唤
醒；如果是非公平锁，那么后续的唤醒次序就不保证 FIFO 顺序了。


```
第 5 章 JUC 显式锁的原理与实战 | 287
```
```
作为练习，建议大家基于 Condition 的“等待－通知”通信机制实现一个更高性
能的生产者―消费者程序。由于其核心的实现逻辑，与第 2 章基于 Java 内置锁的“等待－通
知”通信机制所实现的生产者－消费者程序相同，因此这里不再赘述。不过，笔者为大家提
供一份参考实现代码，请参见本书随书源码中的参考实现类——ReentrantLockPetStore。
```
###### 5. 1. 5 LockSupport

LockSupport 是 JUC 提供的一线程阻塞与唤醒的工具类，该工具类可以让线程在任意位置阻塞
和唤醒，其所有的方法都是静态方法。

1 .LockSupport 的常用方法
LockSupport 的常用方法大致如下：
//无限期阻塞当前线程
publicstaticvoidpark ();
//唤醒某个被阻塞的线程
publicstaticvoidunpark (Threadthread);
//阻塞当前线程，有超时时间的限制
publicstaticvoidparkNanos (longnanos);
//阻塞当前线程，直到某个时间
publicstaticvoidparkUntil (longdeadline);
//无限期阻塞当前线程，带 blocker 对象，用于给诊断工具确定线程受阻塞的原因
publicstaticvoidpark (Objectblocker);
//限时阻塞当前线程，带 blocker 对象
publicstaticvoidparkNanos (Objectblocker, longnanos);
//获取被阻塞线程的 blocker 对象，用于分析阻塞的原因
publicstaticObjectgetBlocker (Threadt);
LockSupport 的方法主要有两类：park 和 unpark。park 英文意思为停车，如果把 Thread 看成一辆
车的话，park () 方法就是让车停下，其作用是将调用 park () 的当前线程阻塞；而 unpark () 方法就是让
车启动，然后跑起来，其作用是将指定线程 Thread 唤醒。

```
2 .LockSupport 的演示实例
下面是一个简单的通过 LockSupport 阻塞和唤醒线程的演示实例：
packagecom. crazymakercircle. demo. lock;
//省略 import
publicclassLockSupportDemo
{
publicstaticclassChangeObjectThreadextendsThread
{
publicChangeObjectThread (Stringname)
{
super (name);
}
@Override
publicvoidrun ()
{
```

288 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

Print.tco ("即将进入无限时阻塞");
//阻塞当前线程
LockSupport.park ();
if (Thread.currentThread (). isInterrupted ())
{
Print.tco ("被中断了，但仍然会继续执行");
}else
{
Print.tco ("被重新唤醒了");
}
}
}
//LockSupport 测试用例
@org. junit. Test
publicvoidtestLockSupport ()
{
ChangeObjectThreadt 1 =newChangeObjectThread ("线程一");
ChangeObjectThreadt 2 =newChangeObjectThread ("线程二");
//启动线程一
t 1 .start ();
sleepSeconds ( 1 );
//启动线程二
t 2 .start ();
sleepSeconds ( 1 );
//中断线程一
t 1 .interrupt ();
//唤醒线程二
LockSupport.unpark (t 2 );
}
}
执行以上代码，大致结果如下：
[线程一]：即将进入无限时阻塞
[线程二]：即将进入无限时阻塞
[线程二]：被重新唤醒了
[线程一]：被中断了，但任然会继续执行
3 .LockSupport.park () 和 Thread.sleep () 的区别
从功能上说，LockSupport.park () 与 Thread.sleep () 方法类似，都是让线程阻塞，二者的区别如下：
1 ）Thread.sleep () 没法从外部唤醒，只能自己醒过来；而被 LockSupport.park () 方法阻塞的线程
可以通过调用 LockSupport.unpark () 方法去唤醒。
2 ）Thread.sleep () 方法声明了 InterruptedException 中断异常，这是一个受检异常，调用者需要捕
获这个异常或者再抛出；而使用 LockSupport.park () 方法时不需要捕获中断异常。
3 ）被 LockSupport.park () 方法、Thread.sleep () 方法所阻塞的线程有一个特点，当被阻塞线程的
Thread.interrupt () 方法调用时，被阻塞线程都会响应线程的中断信号，唤醒线程的执行。不同的是，
二者对中断信号的响应方式不同：LockSupport.park () 方法不会抛出 InterruptedException 异常，仅仅
设置了线程的中断标志；而 Thread.sleep () 方法还会抛出 InterruptedException 异常。
4 ）与 Thread.sleep () 相比，调用 LockSupport.park () 能更精准、更加灵活地阻塞、唤醒指定线程。
5 ）Thread.sleep () 本身就是一个原生（native）方法；LockSupport.park () 并不是一个原生方法，
只是调用了一个 Unsafe 类的原生方法（名字也叫 park）去实现。


```
第 5 章 JUC 显式锁的原理与实战 | 289
```
6 ）LockSupport.park () 方法还允许设置一个 Blocker 对象，主要用来供监视工具或诊断工具确定
线程受阻塞的原因。

```
通过 Thread.sleep () 方法进入阻塞的线程不会释放持有的锁，因此在持有锁的时候
调用该方法需要谨慎。那么通过 LockSupport.park () 方法进入阻塞的线程，会不会释放所持有
的锁呢？当然也不会。
```
4 .LockSupport.park () 与 Object.wait () 的区别
从功能上说，LockSupport.park () 与 Object.wait () 方法也类似，都是让线程阻塞，二者的区别
如下：

1 ）Object.wait () 方法需要在 synchronized 块中执行，而 LockSupport.park () 可以在任意地方执行。
2 ）当被阻塞线程中断时，Object.wait () 方法抛出了中断异常，调用者需要捕获或者再抛出；当
被阻塞线程中断时，LockSupport.park () 不会抛出异常，调用时不需要处理中断异常。

下面的演示代码演示在 LockSupport.park () 执行之前，通过执行 LockSupport.unPark () 去唤醒一
个线程，具体如下：
packagecom. crazymakercircle. demo. lock;
//省略 import
publicclassLockSupportDemo
{
@org. junit. Test
publicvoidtestLockSupport 2 ()
{
Threadt 1 =newThread (()->
{
try
{
Thread.sleep ( 1000 ); //使 sleep 阻塞当前线程，时长为 1 秒
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}
Print.tco ("即将进入无限时阻塞");
//使用 LockSupport.park () 阻塞当前线程
LockSupport.park ();
Print.tco ("被重新唤醒了");
},"演示线程");//通过匿名对象创建一个线程
t 1 .start ();
//唤醒一次没有使用 LockSupport.park () 阻塞的线程
LockSupport.unpark (t 1 );
//再唤醒一次没有使用 LockSupport.park () 阻塞的线程
LockSupport.unpark (t 1 );
sleepSeconds ( 2 );
//中断线程一
//第三唤醒使用 LockSupport.park () 阻塞的线程
LockSupport.unpark (t 1 );
}
//省略其他
}


290 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

执行以上代码，大致结果如下：
[演示线程]：即将进入无限时阻塞
[演示线程]：被重新唤醒了
通过结果可以看出，前两次 LockSupport.unpark (t 1 ) 唤醒操作没有发生任何作用，因为线程 t 1 还
没有被 LockSupport.park () 阻塞。只有在被 LockSupport.park () 阻塞之后，LockSupport.unpark (t 1 ) 唤醒
操作才能将线程 t 1 唤醒。

###### 5. 1. 6 显式锁的分类

显式锁有很多种，从不同的角度来看，显式锁大概有以下几种分类：可重入锁与不可重入锁、
悲观锁和乐观锁、公平锁和非公平锁、共享锁和独占锁、可中断锁和不可中断锁。

1 .可重入锁与不可重入锁
从同一个线程是否可以重复占有同一个锁对象的角度来分，显式锁可以分为可重入锁与不可
重入锁。
可重入锁也被称为递归锁，指的是一个线程可以多次抢占同一个锁。例如，线程 A 在进入外层
函数抢占了一个 Lock 显式锁之后，当线程 A 继续进入内层函数时，如果遇到有抢占同一个 Lock 显式
锁的代码，线程 A 依然可以抢到该 Lock 显式锁。
不可重入锁与可重入锁相反，指的是一个线程只能抢占一次同一个锁。例如，线程 A 在进入外
层函数抢占了一个 Lock 显式锁之后，当线程 A 继续进入内层函数时，如果遇到有抢占同一个 Lock
显式锁的代码，线程 A 不可以抢到该 Lock 显式锁。除非线程 A 提前释放了该 Lock 显式锁，才能第二
次抢占该锁。
JUC 的 ReentrantLock 类是可重入锁的一个标准实现类。
2 .悲观锁和乐观锁
从线程进入临界区前是否锁住同步资源的角度来分，显式锁可以分为悲观锁和乐观锁。
悲观锁就是悲观思想，每次去入临界区操作数据的时候都认为别的线程会修改，所以线程每
次在读写数据时都会上锁，锁住同步资源，这样其他线程需要读写这个数据时就会阻塞，一直等到
拿到锁。总体来说，悲观锁适用于写多读少的场景，遇到高并发写的可能性高。
Java 的 Synchronized 重量级锁是一种悲观锁。
乐观锁是一种乐观思想，每次去拿数据的时候都认为别的线程不会修改，所以不会上锁，但
是在更新的时候会判断一下在此期间别人有没有去更新这个数据，采取在写时先读出当前版本号，
然后加锁操作（比较跟上一次的版本号，如果一样就更新），如果失败就要重复读-比较-写的操作。
总体来说，乐观锁适用于读多写少的场景，遇到高并发写的可能性低。
Java 中的乐观锁基本都是通过 CAS 自旋操作实现的。CAS 是一种更新原子操作，比较当前值跟
传入值是否一样，是则更新，不是则失败。在争用激烈的场景下，CAS 自旋会出现大量的空自旋，
会导致乐观锁性能大大降低。
Java 的 Synchronized 轻量级锁是一种乐观锁。另外，JUC 中基于抽象队列同步器（AQS）实现
的显式锁（如 ReentrantLock）都是乐观锁。


```
第 5 章 JUC 显式锁的原理与实战 | 291
```
既然在争用激烈的场景下乐观锁的性能非常低，那么为什么 JUC 的显式锁都是乐
观锁呢？根本的原因是，JUC 的显式锁都是基于 AQS 实现的，而 AQS 通过对队列的使用很大
程度上减少了锁的争用，极大地减少了空的 CAS 自旋。所以，即使在争用激烈场景下，基于
AQS 的 JUC 乐观锁也能表现出比悲观锁更佳的性能。
3 .公平锁和非公平锁
公平锁是指不同的线程抢占锁的机会是公平的、平等的，从抢占时间上来说，先对锁进行抢
占的线程一定被先满足，抢锁成功的次序体现为 FIFO（先进先出）顺序。简单来说，公平锁就是
保障了各个线程获取锁都是按照顺序来的，先到的线程先获取锁。
使用公平锁，比如线程 A、B、C、D 依次去获取锁，线程 A 首先获取到了锁，然后它处理完成
释放锁之后，会唤醒下一个线程 B 去获取锁。后续不断重复前面的过程，线程 C、D 依次获取锁。
非公平锁是指不同的线程抢占锁的机会是非公平的、不平等的，从抢占时间上来说，先对锁
进行抢占的线程不一定被先满足，抢锁成功的次序不会体现为 FIFO（先进先出）顺序。
使用公平锁，比如线程 A、B、C、D 依次去获取锁, 假如此时持有锁的是线程 A，然后线程 B、
C、D 尝试获取锁，就会进入一个等待队列。当线程 A 释放掉锁之后，会唤醒下一个线程 B 去获取锁。
在唤醒线程 B 的这个过程中，如果有别的线程 E 尝试去请求锁，那么线程 E 是可以先获取到的，这就
是插队。为什么线程 E 可以插队呢？因为 CPU 唤醒线程 B 需要进行线程的上下文切换，这个操作需
要一定的时间，线程 E 可能与线程 A、B 不在同一个 CPU 内核上执行，而是在其他的内核上执行，所
以不需要进行线程的上下文切换。在线程 A 释放锁和线程 B 被唤醒的这段时间，锁是空闲的，其他内
核上的线程 E 此时就能趁机获取非公平锁，这样做的目的主要是利用锁的空档期，提高其利用效率。
默认情况下，ReentrantLock 实例是非公平锁，但是，如果在实例构造时传入了参数 true，所得
到的锁就是公平锁。另外，ReentrantLock 的 tryLock () 方法是一个特例，一旦有线程释放了锁，正在
tryLock 的线程就能优先取到锁，即使已经有其他线程在等待队列中。

4 .可中断锁和不可中断锁
什么是可中断锁？如果某一线程 A 正占有锁在执行临界区代码，另一线程 B 正在阻塞式抢占锁，
可能由于等待时间过长，线程 B 不想等待了，想先处理其他事情，我们可以让它中断自己的阻塞等
待，这种就是可中断锁。
什么是不可中断锁？一旦这个锁被其他线程占有，如果自己还想抢占，自己只能选择等待或
者阻塞，直到别的线程释放这个锁，如果别的线程永远不释放锁，那么自己只能永远等下去，并且
没有办法终止等待或阻塞。
简单来说，在抢锁过程中能通过某些方法去终止抢占过程，这就是可中断锁，否则就是不可
中断锁。
Java 的 synchronized 内置锁就是一个不可中断锁，而 JUC 的显式锁（如 ReentrantLock）是一个可
中断锁。

5 .独占锁和共享锁
独占锁指的是每次只有一个线程能持有的锁。独占锁是一种悲观保守的加锁策略，它不必要
地限制了读/读竞争，如果某个只读线程获取锁，那么其他的读线程都只能等待，这种情况下就限


292 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

制了读操作的并发性，因为读操作并不会影响数据的一致性。
JUC 的 ReentrantLock 类是一个标准的独占锁实现类。
共享锁允许多个线程同时获取锁，容许线程并发进入临界区。与独占锁不同，共享锁是一种
乐观锁，它放宽了加锁策略，并不限制读/读竞争，允许多个执行读操作的线程同时访问共享资源。
JUC 的 ReentrantReadWriteLock（读写锁）类是一个共享锁实现类。使用该读写锁时，读操作
可以有很多线程一起读，但是写操作只能有一个线程去写，而且在写入的时候，别的线程也不能进
行读的操作。
用 ReentrantLock 锁替代 ReentrantReadWriteLock 锁虽然可以保证线程安全，但是也会浪费一部
分资源，因为多个读操作并没有线程安全问题，所以在读的地方使用读锁，在写的地方使用写锁，
可以提高程序执行效率。

#### 5. 2 悲观锁和乐观锁

Java 的 synchronized 是悲观锁，悲观锁可以确保无论哪个线程持有锁，都能独占式访问临界区。
虽然悲观锁的逻辑非常简单，但是存在不少问题。

###### 5. 2. 1 悲观锁存在的问题

悲观锁总是假设会发生最坏的情况，每次线程去读取数据时，也会上锁。这样其他线程在读
取数据时就会被阻塞，直到它拿到锁。传统的关系型数据库用到了很多悲观锁，比如行锁、表锁、
读锁、写锁等。
悲观锁机制存在以下问题：
1 ）在多线程竞争下，加锁、释放锁会导致比较多的上下文切换和调度延时，引起性能问题。
2 ）一个线程持有锁后，会导致其他所有抢占此锁的线程挂起。
3 ）如果一个优先级高的线程等待一个优先级低的线程释放锁，就会导致线程的优先级倒置，
从而引发性能风险。

解决以上悲观锁的这些问题的有效方式是使用乐观锁去替代悲观锁。乐观锁其实是一种思想。
在使用乐观锁时，每次线程去读取数据时都认为其他线程不会修改，所以不会上锁，仅仅在更新时
会判断一下其他线程有没有去更新这个数据。数据库操作中的带版本号数据更新、JUC 包的原子类
都使用了乐观锁的方式提高性能。

###### 5. 2. 2 通过 CAS 实现乐观锁

乐观锁的操作主要就是两个步骤：
1 ）第一步：冲突检测。
2 ）第二步：数据更新。
乐观锁的一种比较典型的就是 CAS 原子操作，JUC 强大的高并发性能是建立在 CAS 原子之上的。
CAS 操作中包含三个操作数：需要操作的内存位置（V）、进行比较的预期原值（A）和拟写入的


```
第 5 章 JUC 显式锁的原理与实战 | 293
```
新值（B）。如果内存位置 V 的值与预期原值 A 相匹配，那么处理器会自动将该位置值更新为新值 B；
否则 CPU 不做任何操作。
CAS 操作可以非常清晰地分为两个步骤：
1 ）检测位置 V 的值是否为 A。
2 ）如果是，将位置 V 更新为 B 值；否则不要更改该位置。
CAS 的两个操作步骤其实与乐观锁操作的两个步骤是一致的，都是在冲突检测后进行数据更新。

```
乐观锁是一种思想，而 CAS 是这种思想的一种实现。
```
实际上，如果需要完成数据的最终更新，仅仅进行一次 CAS 操作是不够的，一般情况下，需
要进行自旋操作，即不断地循环重试 CAS 操作直到成功，这也叫 CAS 自旋。
通过 CAS 自旋，在不使用锁的情况下实现多线程之间的变量同步，也就是说，在没有线程被阻
塞的情况下实现变量的同步，这叫作“非阻塞同步”（Non-BlockingSynchronization），或者说“无
锁同步”。使用基于 CAS 自旋的乐观锁进行同步控制，属于无锁编程（LockFree）的一种实践。
接下来为大家介绍如何基于 CAS 自旋实现一个简单的自旋锁。

###### 5. 2. 3 不可重入的自旋锁

自旋锁（SpinLock）的基本含义为：当一个线程在获取锁的时候，如果锁已经被其他线程获
取，调用者就一直在那里循环检查该锁是否已经被释放，一直到获取到锁才会退出循环。
CAS 自旋锁的实现原理为：抢锁线程不断进行 CAS 自旋操作去更新锁的 owner（拥有者），如
果更新成功，表明已经抢锁成功，退出抢锁方法。如果锁已经被其他线程获取（也就是 owner 为其
他线程），调用者就一直在那里循环进行 owner 的 CAS 更新操作，一直到成功才会退出循环。
作为演示，这里先实现一个简单版本的自旋锁——不可重入的自旋锁，具体的代码如下：
packagecom. crazymakercircle. demo. lock. custom;
//省略 import
publicclassSpinLock implementsLock
{
/**当前锁的拥有者
*使用 Thread 作为同步状态
*/
privateAtomicReference<Thread>owner=newAtomicReference<>();
/**
*抢占锁
*/
@Override
publicvoidlock ()
{
Threadt=Thread.currentThread ();
//自旋
while (! owner.compareAndSet (null, t))
{
//DOnothing
Thread.yield ();//让出当前剩余的 CPU 时间片
}
}
/**


294 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

*释放锁
*/
@Override
publicvoidunlock ()
{
Threadt=Thread.currentThread ();
//只有拥有者才能释放锁
if (t==owner.get ())
{
//设置拥有者为空，这里不需要 compareAndSet 操作
//因为已经通过 owner 做过线程检查
owner.set (null);
}
}
//省略其他代码
}
仔细分析以上就可以看出，SpinLock 是不支持重入的，即当一个线程第一次已经获取到了该
锁，在锁没有被释放之前，如果又一次重新获取该锁，第二次将不能成功获取到。

###### 5. 2. 4 可重入的自旋锁

为了实现可重入锁，这里引入一个计数器，用来记录一个线程获取锁的次数。一个简单的可
重入的自旋锁的代码大致如下：
packagecom. crazymakercircle. demo. lock. custom;
//省略 import
publicclassReentrantSpinLockimplementsLock
{
/**当前锁的拥有者
*使用拥有者 Thread 作为同步状态，而不是使用一个简单的整数作为同步状态
*/
privateAtomicReference<Thread>owner=newAtomicReference<>();
/**
*记录一个线程重复获取锁的次数
*此变量为同一个线程在操作，没有必要加上 volatile 保障可见性和有序性
*/
privateintcount= 0 ;
/**
*抢占锁
*/
@Override
publicvoidlock ()
{
Threadt=Thread.currentThread ();
//如果是重入，增加重入次数后返回
if (t==owner.get ())
{
++count;
return;
}
//自旋
while (owner.compareAndSet (null, t))
{
//DOnothing
Thread.yield ();//让出当前剩余的 CPU 时间片
}
}


```
第 5 章 JUC 显式锁的原理与实战 | 295
```
```
/**
*释放锁
*/
@Override
publicvoidunlock ()
{
Threadt=Thread.currentThread ();
//只有拥有者才能释放锁
if (t==owner.get ())
{
if (count> 0 )
{
//如果重入的次数大于 0 ，减少重入次数后返回
```
- -count;
}else
{
//设置拥有者为空
//这里不需要 compareAndSet，因为已经通过 owner 做过线程检查
owner.set (null);
}
}
}
//省略其他代码
}
自旋锁的特点：线程获取锁的时候，如果锁被其他线程持有，当前线程将循环等待，直到获
取到锁。线程抢锁期间状态不会改变，一直是运行状态（RUNNABLE），在操作系统层面线程处
于用户态。
自旋锁的问题：在争用激烈的场景下，如果某个线程持有锁的时间太长，就会导致其他空自
旋的线程耗尽 CPU 资源。另外，如果大量的线程进行空自旋，还可能导致硬件层面的“总线风暴”。

###### 5. 2. 5 CAS 可能导致“总线风暴”

这里通过从 CPU（以 IntelX 86 为例）平台下的汇编代码入手，为大家分析一下 CAS 的实现原理。
下面是 sun. misc. Unsafe 类的 compareAndSwapInt () 方法的源代码：
publicfinalclassUnsafe{
//Unsafe 中的 CAS 操作
publicfinalnativebooleancompareAndSwapInt (
Objecto, //操作对象
longoffset, //字段偏移
intexpected, //预期值
intx); //待更新的值
//省略不相关代码
}
sun. misc. Unsafe 类的 compareAndSwapInt () 方法是一个 Native 方法调用，该本地方法在 JDK 中依
次调用的 C++代码为：
#defineLOCK_IF_MP (mp)__asmcmpmp, 0 \
__asmjeL 0 \
__asm_emit 0 xF 0 \
__asmL 0 :
inlinejintAtomic:: cmpxchg (jint exchange_value, volatilejint* dest,
jint compare_value){
//alternativeforInterlockedCompareExchange


296 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

intmp=os:: is_MP ();
__asm{
movedx, dest
movecx, exchange_value
moveax, compare_value
LOCK_IF_MP (mp)
cmpxchgdwordptr[edx], ecx
}
}
以上程序会根据当前 CPU 的类型是否为多核 CPU 来决定是否为 cmpxchg 指令添加 lock 前缀。如
果程序是在多核 CPU 上运行，就为 cmpxchg 指令加上 lock 前缀（lockcmpxchg）。反之，如果程序是
在单核 CPU 上运行，就省略 lock 前缀，因为单核 CPU 不需要 lock 前缀提供的内存屏障效果。
接下来，以 SMP 架构的 CPU 为例分析一下 CAS 可能导致“总线风暴”。

```
目前的 CPU 架构大体可以分为三类：对称多处理器结构（Symmetric
Multi-Processor，SMP）、非一致存储访问结构（Non-UniformMemoryAccess，NUMA）和
海量并行处理结构（MassiveParallelProcessing，MPP）。常见的 PC、手机、老式服务器都
是 SMP 架构，其架构简单，但拓展性能非常差。
```
第 4 章在介绍 volatile 关键字原理时讲到，lock 前缀指令有以下三个作用：
1 ）将当前 CPU 缓存行的数据立即写回系统内存。
2 ）lock 前缀指令会引起在其他 CPU 中缓存了该内存地址的数据无效。
3 ）lock 前缀指令禁止指令重排。
由于在 IntelX 86 平台下 CAS 的汇编指令 lockcmpxchg 也是一个 lock 前缀指令，因此 CAS 操作和
volatile 一样，也需要 CPU 进行内部通信从而保障变量的缓存一致性。
在 SMP 架构的 CPU 平台上，所有的 Core（内核）会共享一条总线（BUS），靠此总线连接主存。
每个内核都有自己的高速缓存，各内核相对于 BUS 对称分布。因此，这种结构称为“对称多处理器”。
一个 8 核的 SMP 架构 CPU 大致如图 5 - 1 所示。

图 5 - 1 一个 SMP 架构的 8 核 CPU
假设 Core 1 和 Core 2 可同时把某个变量加载到自己高速缓存中，当 Core 1 在自己的高速缓存中
修改这个位置的值时，会通过总线使 Core 2 中 L 1 高速缓存对应的值“失效”，而 Core 2 一旦发现自
己缓存中的值失效，就会通过总线从内存中读取最新的值，当 Core 2 和 Core 1 中的值再次一致时，
CPU 保障了变量的“缓存一致性”。


```
第 5 章 JUC 显式锁的原理与实战 | 297
```
前面讲到，CPU 会通过 MESI 协议保障变量的缓存一致性。为了保障“缓存一致性”，不同的
内核需要通过总线来回通信，因而产生的流量一般称为“缓存一致性流量”。因为总线被设计为固
定的“通信能力”，如果缓存一致性流量过大，总线将成为瓶颈，这就是所谓的“总线风暴”。

```
总线风暴当然与 CPU 的架构和设计有关，并不是所有的 CPU 都会产生总线风暴。
```
由于使用 lock 前缀指令的 Java 操作（包括 CAS、volatile）恰恰会产生缓存一致性流量，当有很
多线程都同时执行 lock 前缀指令操作时，在 SMP 架构的 CPU 平台上必然会导致总线风暴。
前面讲到，在争用激烈场景下，Java 轻量级锁会快速膨胀为重量级锁，其本质上一是为了减少
CAS 空自旋，二是为了避免同一时间大量 CAS 操作所导致的总线风暴。
那么，JUC 基于 CAS 实现的轻量级锁如何避免总线风暴呢？答案是：使用队列对抢锁线性进行
排队，最大程度上减少了 CAS 操作数量。

###### 5. 2. 6 CLH 自旋锁

CLH 锁其实就是一种是基于队列（具体为单向链表）排队的自旋锁，由于是 Craig、Landin 和
Hagersten 三人一起发明的，因此被命名为 CLH 锁，也叫 CLH 队列锁。
简单的 CLH 锁可以基于单向链表实现，申请加锁的线程首先会通过 CAS 操作在单向链表的尾
部增加一个节点，之后该线程只需要在其前驱节点上进行普通自旋，等待前驱节点释放锁即可。由
于 CLH 锁只有在节点入队时进行一下 CAS 的操作，在节点在加入队列之后，抢锁线程不需要进行
CAS 自旋，只需普通自旋即可。因此，在争用激烈的场景下，CLH 锁能大大减少的 CAS 操作的数量，
以避免 CPU 的总线风暴。

```
JUC 中显式锁基于 AQS 抽象队列同步器，而 AQS 是 CLH 锁的一个变种，为了方便
大家理解 AQS 原理（此为 Java 工程师的必备知识），这里详细介绍一下 CLH 锁的实现和核心
原理。
1 .实现 CLH 锁的一个学习版本
首先为大家提供一个 CLH 锁的简单实现版本，代码如下：
packagecom. crazymakercircle. demo. lock. custom;
//省略 import
publicclassCLHLockimplementsLock
{
/**
*当前节点的线程本地变量
*/
privatestaticThreadLocal<Node>curNodeLocal=newThreadLocal ();
/**
*CLHLock 队列的尾部指针，使用 AtomicReference，方便进行 CAS 操作
*/
privateAtomicReference<Node>tail=newAtomicReference<>(null);
publicCLHLock ()
{
//设置尾部节点
tail.getAndSet (Node. EMPTY);
}
```

298 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
//加锁操作：将节点添加到等待队列的尾部
@Override
publicvoidlock ()
{
NodecurNode=newNode (true, null);
NodepreNode=tail.get ();
//CAS 自旋：将当前节点插入到队列的尾部
while (! tail.compareAndSet (preNode, curNode))
{
preNode=tail.get ();
}
//设置前驱节点
curNode.setPrevNode (preNode);
//自旋，监听前驱节点的 locked 变量，直到其值为 false
//若前继节点的 locked 状态为 true，则表示前一个线程还在抢占或者占有锁
while (curNode.getPrevNode (). isLocked ())
{
//让出 CPU 时间片，提高性能
Thread.yield ();
}
//能执行到这里，说明当前线程获取到了锁
//Print.tcfo ("获取到了锁！！！");
//将当前节点缓存在线程本地变量中，释放锁会用到
curNodeLocal.set (curNode);
}
//释放锁
@Override
publicvoidunlock ()
{
NodecurNode=curNodeLocal.get ();
curNode.setLocked (false);
curNode.setPrevNode (null);//helpforGC
curNodeLocal.set (null);//方便下一次抢锁
}
//虚拟等待队列的节点
@Data
staticclassNode
{
publicNode (booleanlocked, NodeprevNode)
{
this. locked=locked;
this. prevNode=prevNode;
}
//true：当前线程正在抢占锁或者已经占有锁
//false：当前线程已经释放锁，下一个线程可以占有锁了
volatilebooleanlocked;
//前一个节点，需要监听其 locked 字段
NodeprevNode;
//空节点
publicstaticfinalNodeEMPTY=newNode (false, null);
}
//省略其他代码
}
2 .CLHLock 锁的测试用例
下面实现一个 CLHLock 的测试用例：基于前面抽取出来的公共 IncrementData 累加类，编写一
```

```
第 5 章 JUC 显式锁的原理与实战 | 299
```
个 10 个线程各种累加 100000 次的累加程序，并使用 CLHLock 作为累加的同步锁。测试用例的代码
具体如下：
packagecom. crazymakercircle. demo. lock;
//省略 import
publicclassLockTest
{
@org. junit. Test
publicvoidtestCLHLockCapability ()
{
//速度对比
//ReentrantLock 1000000 次 0. 154 秒
//CLHLock 1000000 次 2. 798 秒
//每个线程的执行轮数
finalintTURNS= 100000 ;
//线程数
finalintTHREADS= 10 ;
//线程池，用于多线程模拟测试
ExecutorServicepool=Executors.newFixedThreadPool (THREADS);
Locklock=newCLHLock ();
//Locklock=newReentrantLock ();
//倒数闩
CountDownLatchcountDownLatch=newCountDownLatch (THREADS);
longstart=System.currentTimeMillis ();
for (inti= 0 ;i<THREADS; i++)
{
pool.submit (()->
{
for (intj= 0 ;j<TURNS; j++)
{
IncrementData.lockAndFastIncrease (lock);
}
Print.tcfo ("本线程累加完成");
//倒数闩减少 1 次
countDownLatch.countDown ();
});
}
try
{
//等待倒数闩归 0 ，所有线程结束
countDownLatch.await ();
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}
floattime=(System.currentTimeMillis ()-start)/ 1000 F;
//输出统计结果
Print.tcfo ("运行的时长为："+time);
Print.tcfo ("累加结果为："+IncrementData. sum);
}
//省略其他代码
}
运行以上使用 CLHLock 进行累加同步的测试用例 testCLHLockCapability，其结果如下：
[pool- 1 - thread- 5 |LockTest. lambda$testCLHLockCapability$ 8 ]：本线程累加完成
[pool- 1 - thread- 7 |LockTest. lambda$testCLHLockCapability$ 8 ]：本线程累加完成
[pool- 1 - thread- 6 |LockTest. lambda$testCLHLockCapability$ 8 ]：本线程累加完成


300 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

[pool- 1 - thread- 10 |LockTest. lambda$testCLHLockCapability$ 8 ]：本线程累加完成
[pool- 1 - thread- 2 |LockTest. lambda$testCLHLockCapability$ 8 ]：本线程累加完成
[pool- 1 - thread- 9 |LockTest. lambda$testCLHLockCapability$ 8 ]：本线程累加完成
[pool- 1 - thread- 4 |LockTest. lambda$testCLHLockCapability$ 8 ]：本线程累加完成
[pool- 1 - thread- 8 |LockTest. lambda$testCLHLockCapability$ 8 ]：本线程累加完成
[pool- 1 - thread- 3 |LockTest. lambda$testCLHLockCapability$ 8 ]：本线程累加完成
[pool- 1 - thread- 1 |LockTest. lambda$testCLHLockCapability$ 8 ]：本线程累加完成
[main|LockTest. testCLHLockCapability]：运行的时长为： 2. 798
[main|LockTest. testCLHLockCapability]：累加结果为： 1000000
通过以上结果可以看出 CLHLock 进行累加同步， 10 个线程累加 100000 次之后结果为 1000000 。
实际上，该累加结果是正确的，这也说明以上 CLHLock 实现版本没有功能问题。
但是，由于仅仅是一个学习版本，以上 CLHLock 实现版本存在严重的性能问题。经过对比，
其性能足足比 JUC 的 ReentrantLock 锁差 20 倍左右。尽管如此，以上 CLHLock 实现版本用于学习
CLHLock 的原理还是非常有价值的。

3 .CLH 锁的原理分析
简单回顾一下 CLH 的算法：抢锁线程在队列尾部加入一个节点，然后仅在前驱节点上做普通
自旋，它不断轮询前一个节点状态，如果发现前一个节点释放锁，当前节点抢锁成功。
CLH 的算法有以下几个要点：
1 ）初始状态队列尾部属性（tail）指向一个 EMPTY 节点。
/**
*CLHLock 队列的尾部指针，使用 AtomicReference，方便进行 CAS 操作
*/
privateAtomicReference<Node>tail=newAtomicReference<>(null);
publicCLHLock ()
{
//设置队尾节点
tail.getAndSet (Node. EMPTY);
}
tail 属性使用 AtomicReference 类型是为了使得多个线程并发操作 tail 时不会发生线程安全问题。
2 ）Thread 在抢锁时会创建一个新的节点 Node 加入等待队列尾部：tail 指向新的节点 Node，同
时新的节点 Node 的 preNode 属性指向 tail 之前指向的节点，并且以上操作通过 CAS 自旋完成，以确保
操作成功。
NodecurNode=newNode (true, null);
NodepreNode=tail.get ();
//CAS 自旋：将当前节点插入到队列的尾部
while (! tail.compareAndSet (preNode, curNode))
{
preNode=tail.get ();
}
//设置前驱节点
curNode.setPrevNode (preNode);
3 ）Thread 加入抢锁队列之后，会在前驱节点上自旋：循环判断前驱节点的 locked 属性是否为
false，如果为 false 就表示前驱节点释放了锁，当前线程抢占到锁。
//普通自旋，监听前驱节点的 locked 变量，直到其值为 false
//若前驱节点的 locked 状态为 true，则表示前一线程还在抢占或者占有锁
while (curNode.getPrevNode (). isLocked ())


```
第 5 章 JUC 显式锁的原理与实战 | 301
```
{
//让出 CPU 时间片，提高性能
Thread.yield ();
}
//能执行到这里，说明当前线程获取到了锁
//将当前节点缓存在线程本地变量中，释放锁会用到
curNodeLocal.set (curNode);
4 ）Thread 抢到锁之后，其 locked 属性一直为 true，一直到临界区代码执行完，然后使用 unlock
方法释放锁，释放之后其 locked 属性才为 false。释放锁的代码如下：
publicvoidunlock ()
{
NodecurNode=curNodeLocal.get ();
curNode.setPrevNode (null);//helpforGC
curNodeLocal.set (null);//以便下一次抢锁
curNode.setLocked (false);
}
释放锁操作为：线程从本地变量 curNodeLocal 中获取当前节点 curNode，将其状态设置为 false，
以便的其后驱节点能获得锁。
线程在设置取当前节点 curNode 的 locked 状态设置为 false 之前，为了 GC 能回收前驱节点，需要
将 curNode 前驱节点引用设置为空。另外，为了使得线程下一次抢锁不会出错，需要将线程本地变
量 curNodeLocal 中的节点引用设置为空。

4 .举例说明：CLH 锁的抢占过程
假如有这么一个场景：有三个并发线程同时抢占 CLHLock 锁，三个线程的实际执行顺序为
ThreadA<--ThreadB<--ThreadC。

第一步：线程 A 开始执行了 lock 操作，创建一个节点 nodeA，设置其 locked 状态为 true，然后设
置其前驱为 CLHLock. tail（此时为 EMPTY），并将 CLHLock. tail 设置为 nodeA，之后线程 A 开始在其
前驱节点上做普通自旋，具体如图 5 - 2 所示。

图 5 - 2 线程 A 的节点加入 CLHLock 等待队列并开始自旋
第二步：线程 B 开始执行了 lock 操作，创建一个节点 nodeB，设置其 locked 状态为 true，然后设
置其前驱为 CLHLock. tail（此时为 nodeA），并将 CLHLock. tail 设置为 nodeB，之后线程 B 开始在其
前驱节点上进行普通自旋，具体如图 5 - 3 所示。


302 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

图 5 - 3 线程 B 的节点加入 CLHLock 等待队列并开始自旋
第三步：线程 C 开始执行了 lock 操作，创建一个节点 nodeC，设置其 locked 状态为 true，然后设
置其前驱为 CLHLock. tail（此时为 nodeB），并将 CLHLock. tail 设置为 nodeC，之后线程 C 开始在其
前驱节点上做普通自旋，具体如图 5 - 4 所示。

图 5 - 4 线程 C 的节点加入 CLHLock 等待队列并开始自旋
通过以上过程可以看出：
1 ）CLHLock 的尾指针 tail 总是指向最后一个线程的节点。
2 ）CLHLock 队列中的抢锁线程一直进行普通自旋，循环判断前一线程的 locked 状态，如果是
true，那么说明前一线程处于自旋等待状态或正在执行临界区代码，所以自己需要自旋等待。

5 .举例说明：CLH 锁的释放过程
前面举例说明了 CLH 锁的加锁过程，那么，CLH 锁的释放锁的过程又是怎样的呢？接着上面
的例子，这里举例说明一下 CLH 锁的解锁过程。

第一步：线程 A 执行完临界区代码后开始 unlock（释放）操作，设置其 nodeA 的前驱引用为 null，
锁状态 locked 为 false，具体如图 5 - 5 所示。
第二步：线程 B 执行抢到锁并且完成临界区代码的执行后，开始 unlock（释放）操作，设置其
nodeB 的前驱引用为 null，锁状态 locked 为 false，具体如图 5 - 6 所示。
线程 B 释放锁之后，nodeA 对象已经没有任何的强引用，可以被 GC 回收了。
第三步：线程 C 执行抢到锁并且完成临界区代码的执行后，开始 unlock（释放）操作，设置其
nodeC 的前驱引用为 null，锁状态 locked 为 false，具体如图 5 - 7 所示。


```
第 5 章 JUC 显式锁的原理与实战 | 303
```
```
图 5 - 5 线程 A 释放锁之后的 CLHLock 等待队列示意图
```
```
图^5 -^6 线程 B 释放锁之后的 CLHLock 等待队列示意图
```
```
图 5 - 7 线程 C 释放锁之后的 CLHLock 等待队列示意图
```
```
本节的 CLHLock 锁实现仅仅是为了演示 CLHLock 原理而编写的一个学习版本，
在功能和性能上都还有很多待优化的地方，欢迎大家下载随书源码去进行进一步代码优化，
也欢迎大家来“疯狂创客圈”社群一起交流 CLHLock 的优化方案和心得。
```
6 .CLH 锁优缺点
CLH 锁是一种队列锁，其优点是空间复杂度低。如果有 N 个线程、L 个锁，每个线程每次只获
取一个锁，那么需要的存储空间是 O（L+N）：N 个线程有 N 个 Node，L 个锁有 L 个 Tail。
CLH 队列锁的一个显著缺点是它在 NUMA 架构的 CPU 平台上性能很差。CLH 队列锁在 NUMA
架构的 CPU 平台上，每个 CPU 内核有自己的内存，如果前驱节点在不同的 CPU 内核上，其内存位置


304 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

比较远，在自旋判断前驱节点的 locked 属性时，其性能将大打折扣。不论如何，CLH 锁在 SMP 架构
的 CPU 平台上不存在这个问题，性能还是挺高的。
一种提升在 NUMA 架构下 CLH 队列锁的性能的方案是使用 MCS 队列锁。MCS 队列锁与 CLH 队
列锁的原理大致相同，限于本书的篇幅原因，具体的实现在这里不做展开介绍。

```
有关 MCS 队列锁的原理和具体实现，请关注“疯狂创客圈”的社群博客。
```
#### 5. 3 公平锁与非公平锁

synchronized 内置锁是一种非公平锁，默认情况下 ReentrantLock 锁也是非公平锁。接下来，为
大家展开介绍一下非公平锁与公平锁。

###### 5. 3. 1 非公平锁实战

什么是非公平锁呢？非公平锁是指多个线程获取锁的顺序并不一定是其申请锁的顺序，有可
能后申请的线程比先申请的线程优先获取锁，抢锁成功的次序不一定体现为 FIFO（先进先出）顺
序。非公平锁的优点在于吞吐量比公平锁大，其缺点是有可能会导致线程优先级反转或者线程饥饿
现象。
使用 ReentrantLock 锁作为非公平锁的实战用例，具体的代码如下：
packagecom. crazymakercircle. basic. demo. lock;
//省略 import
publicclassLockTest
{
/**
*非公平锁测试用例
*/
@org. junit. Test
publicvoidtestNotFairLock () throwsInterruptedException
{
//创建可重入锁，默认的非公平锁
Locklock=newReentrantLock (false);
//创建 Runnable 可执行实例
Runnabler=()->IncrementData.lockAndIncrease (lock);
//创建 4 个线程
Thread[]tArray=newThread[ 4 ];
for (inti= 0 ;i< 4 ;i++)
{
tArray[i]=newThread (r,"线程"+i);
}
//启动 4 个线程
for (inti= 0 ;i< 4 ;i++)
{
tArray[i]. start ();
}
Thread.sleep (Integer. MAX_VALUE);
}
//省略其他代码
}


```
第 5 章 JUC 显式锁的原理与实战 | 305
```
出于“分离变与不变的”设计原则，将临界区使用锁的代码进行了抽取和封装，形成一个可
以复用的独立类——IncrementData 累加类，具体的代码如下：
packagecom. crazymakercircle. demo. lock;
//省略 import
//封装锁的使用代码
publicclassIncrementData
{
publicstaticvoidlockAndIncrease (Locklock)
{
Print.synTco ("--开始抢占锁");
lock.lock ();
try
{
Print.synTco ("^-^抢到了锁");
sum++;
}catch (Exceptione)
{
e.printStackTrace ();
}finally
{
lock.unlock ();
}
}
//省略其他代码
}
运行以上非公平锁测试用例，具体的输出如下：
[线程 0 ]：--开始抢占锁
[线程 2 ]：--开始抢占锁
[线程 3 ]：--开始抢占锁
[线程 1 ]：--开始抢占锁
[线程 0 ]：^-^抢到了锁
[线程 3 ]：^-^抢到了锁
[线程 2 ]：^-^抢到了锁
[线程 1 ]：^-^抢到了锁
从输出的结果可以看出，各个线程的抢锁次序为：线程 0 →线程 2 →线程 3 →线程 1 ，但是抢到
锁的次序为：线程 0 →线程 3 →线程 2 →线程 1 。所以说，非公平锁是不公平的。

###### 5. 3. 2 公平锁实战

什么是公平锁呢？公平锁是指多个线程按照申请锁的顺序来获取锁，抢锁成功的次序体现为
FIFO（先进先出）顺序。虽然 ReentrantLock 锁默认是非公平锁，但可以通过构造器指定该锁为公
平锁，具体的代码如下：
//可重入、公平锁对象
Locklock=newReentrantLock (true);
下面是一个简单的公平锁实战案例。此实战案例并没有使用 ReentrantLock 锁，而是使用前面
自定义的 CLHLock 锁进行演示，具体的代码如下：
packagecom. crazymakercircle. basic. demo. lock;
//省略 import
publicclassLockTest
{


306 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

/**
*公平锁测试用例
*/
@org. junit. Test
publicvoidtestFairLock () throwsInterruptedException
{
//创建为公平锁的类型
Locklock=newCLHLock ();
//创建 Runnable 可执行实例
Runnabler=()->IncrementData.lockAndIncrease (lock);
//创建 4 个线程
Thread[]tArray=newThread[ 4 ];
for (inti= 0 ;i< 4 ;i++)
{
tArray[i]=newThread (r,"线程"+i);
}
//启动 4 个线程
for (inti= 0 ;i< 4 ;i++)
{
tArray[i]. start ();
}
Thread.sleep (Integer. MAX_VALUE);
}
//省略其他代码
}
运行以上公平锁测试用例，具体的输出如下：
[线程 3 ]：--开始抢占锁
[线程 0 ]：--开始抢占锁
[线程 1 ]：--开始抢占锁
[线程 2 ]：--开始抢占锁
[线程 3 ]：^-^抢到了锁
[线程 0 ]：^-^抢到了锁
[线程 1 ]：^-^抢到了锁
[线程 2 ]：^-^抢到了锁
从输出的结果可以看出，各个线程的抢锁次序为：线程 3 →线程 0 →线程 1 →线程 2 ，但是抢到
锁的次序为：线程 3 →线程 0 →线程 1 →线程 2 。所以说，公平锁是公平的。

#### 5. 4 可中断锁与不可中断锁

可中断锁是指抢占过程是可以被中断的锁，JUC 的显式锁（如 ReentrantLock）是一个可中断锁。
不可中断锁是指抢占过程是不可以被中断的锁，如 Java 的 synchronized 内置锁就是一个不可中断锁。

###### 5. 4. 1 锁的可中断抢占

在 JUC 的显式锁 Lock 接口中，有以下两个方法可以用于可中断抢占：
（ 1 ）lockInterruptibly ()
可中断抢占锁，抢占过程中会处理 Thread.interrupt () 中断信号，如果线程被中断，则会终止抢
占并抛出 InterruptedException 异常。


```
第 5 章 JUC 显式锁的原理与实战 | 307
```
（ 2 ）tryLock (longtimeout, TimeUnitunit)
阻塞式“限时抢占”（在 timeout 时间内）锁抢占过程中会处理 Thread.interrupt () 中断信号，如
果线程被中断，就会终止抢占并抛出 InterruptedException 异常。
下面是使用 lockInterruptibly () 方法进行可中断抢锁的一个简单案例，具体的代码如下：
packagecom. crazymakercircle. demo. lock;
//省略 import
publicclassIncrementData
{
publicstaticintsum= 0 ;
//演示方法：可中断抢锁
publicstaticvoidlockInterruptiblyAndIncrease (Locklock)
{
Print.synTco ("开始抢占锁");
try
{
lock.lockInterruptibly ();
}catch (InterruptedExceptione)
{
Print.synTco ("抢占被中断，抢锁失败");
//e.printStackTrace ();
return;
}
try
{
Print.synTco ("抢到了锁，同步执行 1 秒");
sleepMilliSeconds ( 1000 );
sum++;
if (Thread.currentThread (). isInterrupted ())
{
Print.synTco ("同步执行被中断");
}
}catch (Exceptione)
{
e.printStackTrace ();
}finally
{
lock.unlock ();
}
}
//省略其他代码
}
如果抢占过程收到由 Thread.interrupt () 方法发出的线程中断信号，lockInterruptibly () 方法会抛出
InterruptedException。
以上代码的测试用例具体如下：
packagecom. crazymakercircle. basic. demo. lock;
//省略 import
publicclassLockTest
{
//测试用例：抢锁过程可中断
@org. junit. Test
publicvoidtestInterruptLock () throwsInterruptedException
{
//创建可重入锁，默认的非公平锁
Locklock=newReentrantLock ();


308 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
//创建 Runnable 可执行任务实例
Runnabler=()->IncrementData.lockInterruptiblyAndIncrease (lock);
Threadt 1 =newThread (r,"thread- 1 "); //创建第 1 个线程
Threadt 2 =newThread (r,"thread- 2 "); //创建第 2 个线程
t 1 .start (); //启动第 1 个线程
t 2 .start (); //启动第 2 个线程
sleepMilliSeconds ( 100 );
Print.synTco ("等待 100 毫秒，中断两个线程");
t 1 .interrupt (); //启动第 2 个线程
t 2 .interrupt (); //启动第 2 个线程
Thread.sleep (Integer. MAX_VALUE);
}
//省略其他代码
}
运行以上用例，其结果如下：
[thread- 1 ]：开始抢占锁
[thread- 1 ]：抢到了锁，同步执行 1 秒
[thread- 2 ]：开始抢占锁
[main]：等待 100 毫秒，中断两个线程
[thread- 1 ]：同步执行被中断
[thread- 2 ]：抢占被中断，抢锁失败
```
###### 5. 4. 2 死锁的监测与中断

死锁是指两个或以上线程因抢占锁而造成的互相等待的现象。多个线程通过 AB-BA 模式抢占
两个锁是造成多线程死锁的比较普遍的原因。AB-BA 模式的死锁具体表现为：线程 X 先后按照先后
次序去抢占锁 A 与锁 B，线程 Y 先后按照先后次序去抢占锁 B 与锁 A；当线程 X 抢到锁 A 去抢占锁 B 时，
发现已经被其他线程拿走，然而线程 Y 拿到锁 B 后去抢占 A 锁时，发现已经被其他线程拿走；于是
线程 X 等待其他线程释放锁 B，线程 Y 等待其他线程释放锁 A，两个线程互相等待从而造成死锁。
JDK 8 中包含的 ThreadMXBean 接口提供了多种监视线程的方法，其中包括了两个死锁监测的
方法，具体如下：

（ 1 ）findDeadlockedThreads
用于检测由于抢占 JUC 显式锁、Java 内置锁所引起死锁的线程。
（ 2 ）findMonitorDeadlockedThreads
仅仅用于检测由于抢占 Java 内置锁所引起死锁的线程。
ThreadMXBean 的实例可以通过 JVM 管理工厂 ManagementFactory 去获取，具体的获取代码如下：
//获取 ThreadMXBean 的实例
publicstaticThreadMXBeanmbean=ManagementFactory.getThreadMXBean ();
JVM 管理工厂 ManagementFactory 类提供静态方法，返回各种获取 JVM 信息的 Bean 实例。我们
通过这些 Bean 实例能获取大量的 JVM 运行时信息，比如 JVM 堆的使用情况、GC 情况、线程信息等。
我们通过 JVM 运行时信息可以了解正在运行的 JVM 的情况，以便可以做出相应的参数调整。


```
第 5 章 JUC 显式锁的原理与实战 | 309
```
```
ManagementFactory 位于 JDK 的核心包 java. lang. management 中，该包提供了一系
列的管理接口，用于监视和管理 JVM 以及运行 JVM 的底层操作系统，它同时允许从本地和远
程对正在运行的 JVM 进行监视和管理。
```
如果是可中断抢占锁（如使用 lockInterruptibly () 方法等），就可以在监测到死锁发生之后，使
用 Thread.interrupt () 去中断死锁线程，不让死锁线程一直等下去。
在这里举一个死锁监测与中断的案例。首先定义一段需要抢占两把锁才能进入的临界区代码，
具体如下：
packagecom. crazymakercircle. demo. lock;
//省略 import
publicclassTwoLockDemo
{
//演示代码：使用两把锁，通过可以中断的方式抢锁
publicstaticvoiduseTowlockInterruptiblyLock (Locklock 1 ,Locklock 2 ){
Stringlock 1 Name=
lock 1 .toString (). replace ("java. util. concurrent. locks.","");
Stringlock 2 Name=
lock 2 .toString (). replace ("java. util. concurrent. locks.","");
Print.synTco ("开始抢第一把锁, 为："+lock 1 Name);
try
{
lock 1 .lockInterruptibly ();
}catch (InterruptedExceptione)
{
Print.synTco ("被中断，抢第一把锁失败, 为："+lock 1 Name);
//e.printStackTrace ();
return;
}
try
{
Print.synTco ("抢到了第一把锁, 为："+lock 1 Name);
Print.synTco ("开始抢第二把锁, 为："+lock 2 Name);
try
{
lock 2 .lockInterruptibly ();
}catch (InterruptedExceptione)
{
Print.synTco ("被中断，抢第二把锁失败, 为："+lock 2 Name);
//e.printStackTrace ();
return;
}
try
{
Print.synTco ("抢到了第二把锁："+lock 2 Name);
Print.synTco ("dosomething");
//等待 1000 毫秒
sleepMilliSeconds ( 1000 );
}catch (Exceptione)
{
e.printStackTrace ();
}finally
{
lock 2 .unlock ();
Print.synTco ("释放了第二把锁, 为："+lock 2 Name);


310 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

}
}catch (Exceptione)
{
e.printStackTrace ();
}finally
{
lock 1 .unlock ();
Print.synTco ("释放了第一把锁, 为："+lock 1 Name);
}
}
以上代码很简单，线程在抢占两把锁 lock 1 和 lock 2 成功之后进入临界区进行累加运算，但是两
把锁 lock 1 和 lock 2 是通过参数传入的。如果两个线程抢锁，一个线程传入参数的次序分别为 lockA、
lockB，而一个线程传入参数的次序分别为 lockB、lockA，就会发生 AB-BA 模式的死锁。
以上代码的测试用例如下：
packagecom. crazymakercircle. basic. demo. lock;
//省略 import
publicclassLockTest
{
//获取 ThreadMXBean
publicstaticThreadMXBeanmbean=ManagementFactory.getThreadMXBean ();
//测试用例：抢占两把锁，造成死锁，然后进行死锁监测和部分中断
@org. junit. Test
publicvoidtestDeadLock () throwsInterruptedException
{
//创建可重入锁，默认的非公平锁
Locklock 1 =newReentrantLock ();
Locklock 2 =newReentrantLock ();
//Runnable 异步执行目标实例 1 : 先抢占 lock 1 ，再抢占 lock 2
Runnabler 1 =()->
TwoLockDemo.useTowlockInterruptiblyLock (lock 1 ,lock 2 );
//Runnable 异步执行目标实例 2 : 先抢占 lock 2 ，再抢占 lock 1
Runnabler 2 =()->
TwoLockDemo.useTowlockInterruptiblyLock (lock 2 ,lock 1 );
Threadt 1 =newThread (r 1 ,"thread- 1 "); //创建第 1 个线程
Threadt 2 =newThread (r 2 ,"thread- 2 "); //创建第 2 个线程
t 1 .start ();//启动第 1 个线程
t 2 .start ();//启动第 2 个线程
//等待一段时间再执行死锁检测
Thread.sleep ( 2000 );
Print.tcfo ("等待 2 秒，开始死锁监测和处理");
//获取到所有死锁线程的 id
long[]deadlockedThreads=mbean.findDeadlockedThreads ();
if (deadlockedThreads. length> 0 )
{
Print.tcfo ("发生了死锁，输出死锁线程的信息");
//遍历数组获取所有的死锁线程 id
for (longpid:deadlockedThreads)
{
//此方法用于获取不带有堆栈跟踪信息的线程数据
//ThreadInfothreadInfo=mbean.getThreadInfo (pid);
//此方法用于获取带有堆栈跟踪信息的线程数据
ThreadInfothreadInfo=mbean.getThreadInfo (
pid, Integer. MAX_VALUE);


```
第 5 章 JUC 显式锁的原理与实战 | 311
```
Print.tcfo (threadInfo);
}
Print.tcfo ("中断一个死锁线程，这里是线程："+t 1 .getName ());
t 1 .interrupt (); //中断一个死锁线程
}
}
//省略其他代码
}
以上代码定义了两个锁 lock 1 和 lock 2 ，然后使用两个线程 thread 和 thread 1 构造死锁场景。正常
情况下，这两个线程相互等待对方锁获取的锁，从而进入死锁。但是在通过 ThreadMXBean 检测到
死锁后，此时第一个死锁线程被中断，而另一个线程就可以获取到需要的锁了。

#### 5. 5 独占锁与共享锁

在访问共享资源之前对进行加锁操作，在访问完成之后进行解锁操作。按照是否“允许在同
一时刻被多个线程持有”来区分，锁可以分为独占锁与共享锁。

###### 5. 5. 1 独占锁

独占锁也叫排他锁、互斥锁、独享锁，是指锁在同一时刻只能被一个线程锁所持有。一个线
程加锁后，任何其他试图再次加锁的线程会被阻塞，直到持有锁线程解锁。通俗来说，就是共享资
源某一时刻只能有一个线程访问，其余线程阻塞等待。
如果是公平地独占锁，在持有锁线程解锁时，如果有一个以上的线程在阻塞等待，那么最先
抢锁的线程被唤醒变为就绪状态去执行加锁操作，其他的线程仍然阻塞等待。
Java 中 Synchronized 内置锁和 ReentrantLock 显式锁都是独占锁。

###### 5. 5. 2 共享锁 Semaphore

共享锁就是在同一时刻允许多个线程持有的锁。当然，获得共享锁的线程只能读取临界区数
据，不能修改临界区的数据。
JUC 中的共享锁包括 Semaphore（信号量）、ReadLock（读写锁）中的读锁、CountDownLatch
倒数闩。
Semaphore 可以用来控制在同一时刻访问共享资源的线程数量，通过协调各个线程以保证共享
资源的合理使用。Semaphore 维护了一组虚拟许可，其数量可以通过构造器的参数指定。线程在访
问共享资源前必须使用 Semaphore 的 acquire () 方法获得许可，如果许可数量为 0 ，该线程就一直阻塞。
线程访问完成资源后，必须使用 Semaphore 的 release () 方法释放许可。更形象的说法是：Semaphore
是一个是许可管理器。

```
1 .Semaphore 的主要方法
JUC 包中 Semaphore 类的主要方法大致如下：
（ 1 ）Semaphore (permits)
构造一个 Semaphore 实例，初始化其管理的许可数量为 permits 参数值。
```

312 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

（ 2 ）Semaphore (permits, fair)
构造一个 Semaphore 实例，初始化其管理的许可数量为 permits 参数值，并且可以设置是否以公
平模式（fair 参数是否为 true）进行许可的发放。

```
Semaphore 和 ReentrantLock 类似。Semaphore 发放许可时有两种模式：公平模式
和非公平模式，默认情况下使用非公平模式。
```
（ 3 ）availablePermits ()
获取 Semaphore 对象可用的许可数量。
（ 4 ）acquire ()
当前线程尝试获取 Semaphore 对象的一个许可。此过程是阻塞的，线程会一直等待 Semaphore
发放一个许可，直到发生以下任意一件事：

 当前线程获取了一个可用的许可。
 当前线程被中断，就会抛出 InterruptedException 异常，并停止等待，继续往下执行。
（ 5 ）acquire (permits)
当前线程尝试以阻塞方式获取 permits 个许可。此过程是阻塞的，线程会一直等待 Semaphore 发
放 permits 个许可。如果没有足够的许可而当前线程被中断，就会抛出 InterruptedException 异常并终
止阻塞。

（ 6 ）acquireUninterruptibly ()
当前线程尝试以阻塞方式获取一个许可，阻塞的过程不可中断，直到成功获取一个许可。
（ 7 ）acquireUninterruptibly (permits)
当前线程尝试以阻塞方式获取 permits 个许可，阻塞的过程不可中断，直到成功获取 permits 个
许可。

（ 8 ）tryAcquire ()
当前线程尝试去获取一个许可。此过程是非阻塞的，它只是进行一次尝试，会立即返回。如
果当前线程成功获取了一个许可，就返回 true。如果当前线程没有获得到许可，就返回 false。

（ 9 ）tryAcquire (permits)
当前线程尝试去获取 permits 个许可。此过程是非阻塞的，它只是进行一次尝试，会立即返回。
如果当前线程成功获取了 permits 个许可，就返回 true。如果当前线程没有获得到 permits 个许可，就
返回 false。

```
（ 10 ）tryAcquire (timeout, TimeUnit)
限时获取一个许可。此过程是阻塞的，它会一直等待许可，直到发生以下任意一件事：
 当前线程获取了一个许可，则会停止等待，继续执行，并返回 true。
 当前线程等待 timeout 后超时，则会停止等待，继续执行，并返回 false。
 当前线程在 timeout 时间内被中断，则会抛出 InterruptedException 异常，并停止等待，继续
执行。
```

```
第 5 章 JUC 显式锁的原理与实战 | 313
```
（ 11 ）tryAcquire (permits, timeout, TimeUnit)
与 tryAcquire (timeout, TimeUnit) 方法在逻辑上基本相同，不同之处在于：在获取许可的数量上
不同，此方法用于获取 permits 个许可。

（ 12 ）release ()
当前线程释放一个可用的许可。
（ 13 ）release (permits)
当前线程释放 permits 个可用的许可。
（ 14 ）drainPermits ()
当前线程获得剩余的所有可用许可。
（ 15 ）hasQueuedThreads ()
判断当前 Semaphore 对象上是否存在正在等待许可的线程。
（ 16 ）getQueueLength ()
获取当前 Semaphore 对象上正在等待许可的线程数量。
2 .共享锁使用示例
假设有 10 个人在银行办理业务，只有两个工作窗口，使用 Semaphore 模拟银行排队，大致的代
码如下：
packagecom. crazymakercircle. demo. lock;
//省略 import
publicclassSemaphoreTest
{
@org. junit. Test
publicvoidtestShareLock () throwsInterruptedException
{
//排队总人数（请求总数）
finalintUSER_TOTAL= 10 ;
//可同时受理业务的窗口数量（同时并发执行的线程数）
finalintPERMIT_TOTAL= 2 ;
//线程池，用于多线程模拟测试
finalCountDownLatchcountDownLatch=newCountDownLatch (USER_TOTAL);
//创建信号量，含有两个许可
finalSemaphoresemaphore=newSemaphore (PERMIT_TOTAL);
AtomicIntegerindex=newAtomicInteger ( 0 );
//创建 Runnable 可执行实例
Runnabler=()->
{
try
{
//阻塞开始获取许可
semaphore.acquire ( 1 );
//获取了一个许可
Print.tco (DateUtil.getNowTime ()
+", 受理处理中..., 服务号: "+index.incrementAndGet ());
//模拟业务操作：处理排队业务
Thread.sleep ( 1000 );
//释放一个信号
semaphore.release ( 1 );


314 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
}catch (Exceptione)
{
e.printStackTrace ();
}
countDownLatch.countDown ();
};
//创建 10 个线程
Thread[]tArray=newThread[USER_TOTAL];
for (inti= 0 ;i<USER_TOTAL; i++)
{
tArray[i]=newThread (r,"线程"+i);
}
//启动 10 个线程
for (inti= 0 ;i<USER_TOTAL; i++)
{
tArray[i]. start ();
}
countDownLatch.await ();
}
}
运行程序，结果如下：
[线程 0 ]： 21 : 58 : 20 ,受理处理中..., 服务号: 2
[线程 4 ]： 21 : 58 : 20 ,受理处理中..., 服务号: 1
[线程 3 ]： 21 : 58 : 21 ,受理处理中..., 服务号: 3
[线程 2 ]： 21 : 58 : 21 ,受理处理中..., 服务号: 4
[线程 1 ]： 21 : 58 : 22 ,受理处理中..., 服务号: 6
[线程 9 ]： 21 : 58 : 22 ,受理处理中..., 服务号: 5
[线程 7 ]： 21 : 58 : 23 ,受理处理中..., 服务号: 7
[线程 6 ]： 21 : 58 : 23 ,受理处理中..., 服务号: 8
[线程 8 ]： 21 : 58 : 24 ,受理处理中..., 服务号: 9
[线程 5 ]： 21 : 58 : 24 ,受理处理中..., 服务号: 10
通过结果可以看出，每一秒中只有 2 个线程进入临界区。
```
###### 5. 5. 3 共享锁 CountDownLatch

CountDownLatch 是一个常用的共享锁，其功能相当于一个多线程环境下的倒数门闩。
CountDownLatch 可以指定一个计数值，在并发环境下由线程进行减 1 操作，当计数值变为 0 之后，
被 await 方法阻塞的线程将会唤醒。通过 CountDownLatch 可以实现线程间的计数同步。
下面是一个非常经典的 CountDownLatch 使用示例：司机（Driver）在开车之前，需要 100 个乘
客并发进行不重复的报数，报数到 100 之后说明人已经到齐，随后司机可以开车出发，具体的代码
如下：
packagecom. crazymakercircle. visiable;
//省略 import
classDriver
{
privatestaticfinalintN= 100 ;//乘客数
publicstaticvoidmain (String[]args) throwsInterruptedException
{ //step 1 ：创建倒数闩，设置倒数的总数
CountDownLatchdoneSignal=newCountDownLatch (N);
//取得 CPU 密集型线程池
Executore=ThreadUtil.getCpuIntenseTargetThreadPool ();


```
第 5 章 JUC 显式锁的原理与实战 | 315
```
for (inti= 1 ;i<=N;++i)//启动报数任务
e.execute (newPerson (doneSignal, i));
doneSignal.await ();//step 2 ：等待报数完成, 倒数闩计数值为 0
Print.tcfo ("人到齐，开车"); }
staticclassPersonimplementsRunnable
{
privatefinalCountDownLatchdoneSignal;
privatefinalinti;
Person (CountDownLatchdoneSignal, inti)
{
this. doneSignal=doneSignal;
this. i=i;
}
publicvoidrun ()
{
try
{
//报数
Print.tcfo ("第"+i+"个人已到");
doneSignal.countDown (); //step 3 ：倒数闩减少 1
}catch (Exceptionex)
{
}
}
}
}
运行结果如下：
[apppool- 1 - cpu- 6 |Driver$Person. run]：第 6 个人已到
[apppool- 1 - cpu- 1 |Driver$Person. run]：第 1 个人已到
... 为节省篇幅，省略大部分输出
[apppool- 1 - cpu- 2 |Driver$Person. run]：第 96 个人已到
[apppool- 1 - cpu- 3 |Driver$Person. run]：第 97 个人已到
[apppool- 1 - cpu- 6 |Driver$Person. run]：第 99 个人已到
[apppool- 1 - cpu- 1 |Driver$Person. run]：第 100 个人已到
[apppool- 1 - cpu- 8 |Driver$Person. run]：第 98 个人已到
[main|Driver. main]：人到齐，开车
结合上述示例的运行结果，梳理一下 CountDownLatch 的使用步骤：
1 ）创建倒数闩，初始化 CountDownLatch 时设置倒数的总次数，比如为 100 。
2 ）等待线程调用倒数闩的 await () 方法阻塞自己，等待倒数闩的计数器数值为 0 （即倒数线程全
部执行结束）。
3 ）倒数线程执行完，调用 CountDownLatch.countDown () 方法将计数器数值减 1 。
由于 CountDownLatch 的方法在定义和使用上都非常简单，这里不做过多赘述。

```
Semaphore、countDownLatch 二者都是基于共享锁实现的，用于在线程之间进行
操作同步的工具类。JUC 的同步工具类一共有 3 个：Semaphore、countDownLatch 和 CyclicBarrier。
有关 CyclicBarrier 的具体使用与核心原理，请参见疯狂创客圈社群的博客：
https://www.cnblogs.com/crazymakercircle/p/ 13906379 .html，这里不再赘述。
```

316 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

#### 5. 6 读写锁

在介绍完共享锁和独占锁之后，接下来介绍建立在二者基础上的一种组合锁：读写锁。
读写锁的内部包含了两把锁：一把是为读（操作）锁，是一种共享锁；另一把写（操作）锁，
是一种独占锁。在没有写锁的时候，读锁可以被多个线程同时持有。写锁是排他性的：如果写锁被
一个线程持有，其他的线程不能再持有写锁，抢占写锁会阻塞；进一步来说，如果写锁被一个线程
持有，其他的线程不能再持有读锁，抢占读锁也会阻塞。
读写锁的读写操作之间的互斥原则具体如下：
 读操作、读操作能共存，是相容的。
 读操作、写操作不能共存，是互斥的。
 写操作、写操作不能共存，是互斥的。
与单一的互斥锁相比，组合起来的读写锁允许对于共享数据进行更大程度的并发操作。虽然每次
只能有一个写线程，但是同时可以有多个线程并发地读数据。读写锁适用于读多写少的并发情况。
JUC 包中的读写锁接口为 ReadWriteLock，主要有两个方法，具体如下：
publicinterfaceReadWriteLock{
/**
*返回读锁
*/
LockreadLock ();
/**
*返回写锁
*/
LockwriteLock ();
}
通过 ReadWriteLock 接口能获取其内部的两把锁：一把 ReadLock，负责读操作；另一把是
WriteLock，负责写操作。JUC 中 ReadWriteLock 接口实现类为 ReentrantReadWriteLock。

5. 6. (^1) 读写锁 ReentrantReadWriteLock
通过 ReentrantReadWriteLock 类能获取其读锁和写锁，其读锁是可以多线程共享的共享锁，而
其写锁是排他锁，在被占时候不允许其他线程再抢占操作。然而其读锁和写锁之间是有关系的：同
一时刻不允许读锁和写锁同时被抢占，二者之间是互斥的。
接着进行代码，读锁是共享锁，写锁是排他锁：
packagecom. crazymakercircle. demo. lock;
//省略 import
publicclassReadWriteLockTest
{
//创建一个 Map，代表共享数据
finalstaticMap<String,String>MAP=newHashMap<String,String>();
//创建一个读写锁
finalstaticReentrantReadWriteLockLOCK=newReentrantReadWriteLock ();
//获取读锁
finalstaticLockREAD_LOCK=LOCK.readLock ();


```
第 5 章 JUC 显式锁的原理与实战 | 317
```
//获取写锁
finalstaticLockWRITE_LOCK=LOCK.writeLock ();
//对共享数据的写操作
publicstaticObjectput (Stringkey, Stringvalue)
{
WRITE_LOCK.lock (); //抢写锁
try
{
Print.tco (DateUtil.getNowTime ()+"抢占了 WRITE_LOCK，开始执行 write 操作");
Thread.sleep ( 1000 );
Stringput=MAP.put (key, value); //写入共享数据
returnput;
}catch (Exceptione)
{
e.printStackTrace ();
}finally
{
WRITE_LOCK.unlock (); //释放写锁
}
returnnull;
}
//对共享数据的读操作
publicstaticObjectget (Stringkey)
{
READ_LOCK.lock (); //抢占读锁
try
{
Print.tco (DateUtil.getNowTime ()+"抢占了 READ_LOCK，开始执行 read 操作");
Thread.sleep ( 1000 );
Stringvalue=MAP.get (key); //读取共享数据
returnvalue;
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}finally
{
READ_LOCK.unlock (); //释放读锁
}
returnnull;
}
//入口方法
publicstaticvoidmain (String[]args)
{
//创建 Runnable 异步可执行目标实例
RunnablewriteTarget=()->put ("key","value");
RunnablereadTarget=()->get ("key");
//创建 4 个读线程
for (inti= 0 ;i< 4 ;i++)
{
newThread (readTarget,"读线程"+i). start ();
}
//创建 2 个写线程，并启动
for (inti= 0 ;i< 2 ;i++)
{
newThread (writeTarget,"写线程"+i). start ();
}
}
}


318 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
运行程序，结果如下：
[读线程 2 ]： 09 : 33 : 20 抢占了 READ_LOCK，开始执行 read 操作
[读线程 1 ]： 09 : 33 : 20 抢占了 READ_LOCK，开始执行 read 操作
[读线程 0 ]： 09 : 33 : 20 抢占了 READ_LOCK，开始执行 read 操作
[写线程 1 ]： 09 : 33 : 21 抢占了 WRITE_LOCK，开始执行 write 操作
[读线程 3 ]： 09 : 33 : 22 抢占了 READ_LOCK，开始执行 read 操作
[写线程 0 ]： 09 : 33 : 23 抢占了 WRITE_LOCK，开始执行 write 操作
从输出结果可以看出：
1 ）读线程 0 、读线程 1 、读线程 2 同时获取了读锁，说明可以同时进行共享数据的读操作。
2 ）写线程 1 、写线程 0 只能依次获取写锁，说明共享数据的写操作不能同时进行。
3 ）读线程 3 必须等待写线程 1 释放写锁后才能获取到读锁，说明读写操作是互斥的。
```
###### 5. 6. 2 锁的升级与降级

锁升级是指读锁升级为写锁，锁降级指的是写锁降级为读锁。在 ReentrantReadWriteLock 读写
锁中，只支持写锁降级为读锁，而不支持读锁升级为写锁。具体的演示代码如下：
packagecom. crazymakercircle. demo. lock;
//省略 import
publicclassReadWriteLockTest 2
{
//创建一个 Map，代表共享数据
finalstaticMap<String,String>MAP=newHashMap<String,String>();
//创建一个读写锁
finalstaticReentrantReadWriteLockLOCK=newReentrantReadWriteLock ();
//获取读锁
finalstaticLockREAD_LOCK=LOCK.readLock ();
//获取写锁
finalstaticLockWRITE_LOCK=LOCK.writeLock ();
//对共享数据的写操作
publicstaticObjectput (Stringkey, Stringvalue)
{
WRITE_LOCK.lock ();
try
{
Print.tco (DateUtil.getNowTime ()
+"抢占了 WRITE_LOCK，开始执行 write 操作");
Thread.sleep ( 1000 );
Stringput=MAP.put (key, value);
Print.tco ("尝试降级写锁为读锁");
//写锁降级为读锁（成功）
READ_LOCK.lock ();
Print.tco ("写锁降级为读锁成功");
returnput;
}catch (Exceptione)
{
e.printStackTrace ();
}finally
{
READ_LOCK.unlock ();
WRITE_LOCK.unlock ();
}
returnnull;
}


```
第 5 章 JUC 显式锁的原理与实战 | 319
```
//对共享数据的读操作
publicstaticObjectget (Stringkey)
{
READ_LOCK.lock ();
try
{
Print.tco (DateUtil.getNowTime ()
+"抢占了 READ_LOCK，开始执行 read 操作");
Thread.sleep ( 1000 );
Stringvalue=MAP.get (key);
Print.tco ("尝试升级读锁为写锁");
//读锁升级为写锁 (失败)
WRITE_LOCK.lock ();
Print.tco ("读锁升级为写锁成功");
returnvalue;
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}finally
{
WRITE_LOCK.unlock ();
READ_LOCK.unlock ();
}
returnnull;
}
publicstaticvoidmain (String[]args)
{
//创建 Runnable 可执行实例
RunnablewriteTarget=()->put ("key","value");
RunnablereadTarget=()->get ("key");
//创建 1 条写线程，并启动
newThread (writeTarget,"写线程"). start ();
//创建 1 条读线程
newThread (readTarget,"读线程"). start ();
}
}
运行控制台输出：
[写线程]： 09 : 51 : 42 抢占了 WRITE_LOCK，开始执行 write 操作
[写线程]：写线程尝试降级写锁为读锁
[写线程]：写线程写锁降级为读锁成功
[读线程]： 09 : 51 : 43 抢占了 READ_LOCK，开始执行 read 操作
[读线程]：读线程尝试升级读锁为写锁
通过结果可以看出：ReentrantReadWriteLock 不支持读锁的升级，主要是避免死锁，例如两个
线程 A 和 B 都占了读锁并且都需要升级成写锁，A 升级要求 B 释放读锁，B 升级要求 A 释放读锁，二
者就会由于互相等待形成死锁。
总结起来，与 ReentrantLock 相比，ReentrantReadWriteLock 更适合于读多写少的场景，可以提
高并发读的效率；而 ReentrantLock 更适合于读写比例相差不大或写比读多的场景。

###### 5. 6. 3 StampedLock

StampedLock（印戳锁）是对 ReentrantReadWriteLock 读写锁的一种改进，主要的改进为：在没
有写只有读的场景下，StampedLock 支持不用加读锁而是直接进行读操作，最大程度提升读的效率，
只有在发生过写操作之后，再加读锁才能进行读操作。


320 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

StampedLock 的三种模式如下：
1 ）悲观读锁：与 ReadWriteLock 的读锁类似，多个线程可以同时获取悲观读锁，悲观读锁是
一个共享锁。
2 ）乐观读：相当于直接操作数据，不加任何锁，连读锁都不要。
3 ）写锁：与 ReadWriteLock 的写锁类似，写锁和悲观读锁是互斥的；虽然写锁与乐观读不会
互斥，但是在数据被更新之后，之前通过乐观读所获得的数据已经变成了脏数据。

1 .StampedLock 与 ReentrantReadWriteLock 对比
StampedLock 与 ReentrantReadWriteLock 语义类似，不同的是，StampedLock 并没有实现
ReadWriteLock 接口，而是定义了自己的锁操作 API，主要如下：

```
（ 1 ）悲观读锁的获取与释放
//获取普通读锁（悲观读锁），返回 long 类型的印戳值
publiclongreadLock ()
//释放普通读锁（悲观读锁），以取锁时的印戳值作为参数
publicvoidunlockRead (longstamp)
（ 2 ）写锁的获取与释放
//获取写锁，返回 long 类型的印戳值
publiclongwriteLock ()
//释放写锁，以获取写锁时的印戳值作为参数
publicvoidunlockWrite (longstamp)
（ 3 ）乐观读的印戳获取与有效性判断
//获取乐观读，返回 long 类型的印戳值，返回 0 表示当前锁处于写锁模式，不能乐观读
publiclongtryOptimisticRead ()
//判断乐观读的印戳值是否有效，以 tryOptimisticRead 返回的印戳值作为参数
publiclongtryOptimisticRead ()
2 .StampedLock 的演示案例
一个简单的 StampedLock 的使用案例代码如下：
packagecom. crazymakercircle. demo. lock;
//省略 import
publicclassStampedLockTest
{
//创建一个 Map，代表共享数据
finalstaticMap<String,String>MAP=newHashMap<String,String>();
//创建一个印戳锁
finalstaticStampedLockSTAMPED_LOCK=newStampedLock ();
//对共享数据的写操作
publicstaticObjectput (Stringkey, Stringvalue)
{
longstamp=STAMPED_LOCK.writeLock (); //尝试获取写锁的印戳
try
{
Print.tco (getNowTime ()+"抢占了 WRITE_LOCK，开始执行 write 操作");
Thread.sleep ( 1000 );
Stringput=MAP.put (key, value);
```

```
第 5 章 JUC 显式锁的原理与实战 | 321
```
returnput;
}catch (Exceptione)
{
e.printStackTrace ();
}finally
{
Print.tco (getNowTime ()+"释放了 WRITE_LOCK");
STAMPED_LOCK.unlockWrite (stamp);//释放写锁
}
returnnull;
}
//对共享数据的悲观读操作
publicstaticObjectpessimisticRead (Stringkey)
{
Print.tco (getNowTime ()+"LOCK 进入过写模式，只能悲观读");
//进入了写锁模式，只能获取悲观读锁
longstamp=STAMPED_LOCK.readLock (); //尝试获取读锁的印戳
try
{
//成功获取到读锁，并重新获取最新的变量值
Print.tco (getNowTime ()+"抢占了 READ_LOCK");
Stringvalue=MAP.get (key);
returnvalue;
}finally
{
Print.tco (getNowTime ()+"释放了 READ_LOCK");
STAMPED_LOCK.unlockRead (stamp);//释放读锁
}
}
//对共享数据的乐观读操作
publicstaticObjectoptimisticRead (Stringkey)
{
Stringvalue=null;
//尝试进行乐观读
longstamp=STAMPED_LOCK.tryOptimisticRead ();
if ( 0 !=stamp)
{
Print.tco (getNowTime ()+"乐观读的印戳值，获取成功");
sleepSeconds ( 1 );//模拟耗费时间 1 秒
value=MAP.get (key);
}else // 0 ==stamp 表示当前为写锁模式
{
Print.tco (getNowTime ()+"乐观读的印戳值，获取失败");
//LOCK 已经进入写模式，使用悲观读方法
returnpessimisticRead (key);
}
//乐观读操作已经间隔了一段时间，期间可能发生写入
//所以，需要验证乐观读的印戳值是否有效，即判断 LOCK 是否进入过写模式
if (! STAMPED_LOCK.validate (stamp))
{
//乐观读的印戳值无效，表明写锁被占用过
Print.tco (getNowTime ()+"乐观读的印戳值，已经过期");
//写锁已经被抢占，进入了写锁模式，只能通过悲观读锁，再一次读取最新值
returnpessimisticRead (key);
}else
{
//乐观读的印戳值有效，表明写锁没有被占用过
//不用加悲观读锁而直接读，减少了读锁的开销


322 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
Print.tco (getNowTime ()+"乐观读的印戳值，没有过期");
returnvalue;
}
}
publicstaticvoidmain (String[]args) throwsInterruptedException
{
//创建 Runnable 可执行实例
RunnablewriteTarget=()->put ("key","value");
RunnablereadTarget=()->optimisticRead ("key");
//创建 1 个写线程，并启动
newThread (writeTarget,"写线程"). start ();
//创建 1 个读线程
newThread (readTarget,"读线程"). start ();
}
}
运行以上程序，结果如下：
[写线程]： 12 : 55 : 45 抢占了 WRITE_LOCK，开始执行 write 操作
[读线程]： 12 : 55 : 45 获取乐观读的印戳值，获取失败
[读线程]： 12 : 55 : 45 LOCK 进入过写模式，只能悲观读
[写线程]： 12 : 55 : 46 释放了 WRITE_LOCK
[读线程]： 12 : 55 : 46 抢占了 READ_LOCK
[读线程]： 12 : 55 : 46 释放了 READ_LOCK
```

# 第 6 章

## AQS 抽象同步器核心原理

前面介绍的在争用激烈的场景下，使用基于 CAS 自旋实现的轻量级锁有两个大的问题：
1 ）CAS 恶性空自旋会浪费大量的 CPU 资源。
2 ）在 SMP 架构的 CPU 上会导致“总线风暴”。
解决 CAS 恶性空自旋的有效方式之一是以空间换时间，较为常见的方案有两种：分散操作热
点、使用队列削峰。JUC 并发包使用的是队列削峰的方案解决 CAS 的性能问题，并提供了一个基于
双向队列的削峰基类——抽象基础类 AbstractQueuedSynchronizer（抽象同步器类，简称为 AQS）。

#### 6. 1 锁与队列的关系

无论是单体服务应用内部的锁，还是分布式环境下多体服务应用所使用的分布式锁，为了减
少由于无效争夺导致的资源浪费和性能恶化，一般都基于队列进行排队与削峰。

1 .CLH 锁的内部队列
在第 5 章介绍的 CLH 自旋锁使用的 CLH（Craig, Landin, andHagerstenLockQueue）是一个单向
队列，也是一个 FIFO 队列。在独占锁中，竞争资源在一个时间点只能被一个线程锁访问；队列的
队首节点（队列的头部）表示占有锁的节点，新加入的抢锁线程则需要等待，会插入到队列的尾部。
CLH 锁的内部结构如图 6 - 1 所示。
2 .分布式锁的内部队列
在分布式锁的实现中，比较常见的也是基于队列的方式进行不同节点中“等锁线程”的统一
调度和管理。以基于 ZooKeeper 的分布式锁为例，其等待队列的结构大致如图 6 - 2 所示。


324 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
图 6 - 1 CLH 锁的内部结构
```
```
图 6 - 2 ZooKeeper 分布式锁的等待队列的结构
```
```
ZooKeeper 分布式锁的原理和实战知识，请参阅另一本书《Java 高并发核心编程
卷 1 （加强版）：NIO、Netty、Redis、ZooKeeper》。
```
3 .AQS 的内部队列
AQS 是 JUC 提供的一个用于构建锁和同步容器的基础类。JUC 包内的许多类都是基于 AQS 构建，
例如 ReentrantLock、Semaphore、CountDownLatch、ReentrantReadWriteLock、FutureTask 等。AQS
解决了在实现同步容器时设计的大量细节问题。
AQS 是 CLH 队列的一个变种，主要原理和 CLH 队列差不多，这也是前面对 CLH 队列进行长篇
大论介绍的原因。AQS 队列内部维护的是一个 FIFO 的双向链表，这种结构的特点是每个数据结构
都有两个指针，分别指向直接的前驱节点和直接的后驱节点。所以双向链表可以从任意一个节点开
始很方便地访问前驱节点和后驱节点。每个节点其实是由线程封装的，当线程争抢锁失败后会封装
成 Node 加入到 AQS 队列中去；当获取锁的线程释放锁以后，会从队列中唤醒一个阻塞的节点（线
程）。AQS 的内部结构如图 6 - 3 所示。

```
图 6 - 3 AQS 锁的内部结构
```

```
第 6 章 AQS 抽象同步器核心原理 | 325
```
#### 6. 2 AQS 的核心成员

AQS 出于“分离变与不变”的原则，基于模板模式实现。AQS 为锁获取、锁释放的排队和出
队过程提供了一系列的模板方法。由于 JUC 的显式锁种类丰富，因此 AQS 将不同锁的具体操作抽取
为钩子方法，供各种锁的子类（或者其内部类）去实现。

###### 6. 2. 1 状态标志位

AQS 中维持了一个单一的 volatile 修饰的状态信息 state，AQS 使用 int 类型的 state 标示锁的状态，
可以理解为锁的同步状态。
//同步状态，使用 volatile 保证线程可见
privatevolatileintstate;
state 因为使用 volatile 保证了操作的可见性，所以任何线程通过 getState () 获得状态都是可以得到
最新值。AQS 提供了 getState ()、setState () 来获取和设置同步状态，具体的代码如下：
//获取同步的状态
protectedfinalintgetState (){
returnstate;
}
//设置同步的状态
protectedfinalvoidsetState (intnewState){
state=newState;
}
//通过 CAS 设置同步的状态
protectedfinalbooleancompareAndSetState (intexpect, intupdate){
returnunsafe.compareAndSwapInt (this, stateOffset, expect, update);
}
由于 setState () 无法保证原子性，因此 AQS 给我们提供了 compareAndSetState () 方法利用底层
UnSafe 的 CAS 机制来实现原子性。compareAndSetState () 方法实际上调用的是 unsafe 成员的
compareAndSwapInt () 方法。
以 ReentrantLock 为例，state 初始化为 0 ，表示未锁定状态。A 线程执行该锁的 lock () 操作时，会
调用 tryAcquire () 独占该锁并将 state 加 1 。此后，其他线程再 tryAcquire () 时就会失败，直到 A 线程
unlock () 到 state= 0 （即释放锁）为止，其他线程才有机会获取该锁。当然，释放锁之前，A 线程自己
是可以重复获取此锁的（state 会累加），这就是可重入的概念。但要注意，获取多少次就要释放多
么次，这样才能保证 state 是能回到零态。
AbstractQueuedSynchronizer 继承了 AbstractOwnableSynchronizer，这个基类只有一个变量叫
exclusiveOwnerThread，表示当前占用该锁的线程，并且提供了相应的 get () 和 set () 方法，具体的代码
如下：
publicabstractclassAbstractOwnableSynchronizer
implementsjava. io. Serializable{
//表示当前占用该锁的线程
privatetransientThreadexclusiveOwnerThread;


326 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
//省略 get () 和 set () 方法
}
```
###### 6. 2. 2 队列节点类

AQS 是一个虚拟队列，不存在队列实例，仅存在节点之间的前后关系。节点类型通过内部类
Node 定义，其核心的成员如下：
staticfinalclassNode{
/**节点等待状态值 1 ：取消状态*/
staticfinalintCANCELLED= 1 ;
/**节点等待状态值- 1 ：标识后继线程处于等待状态*/
staticfinalintSIGNAL =- 1 ;
/**节点等待状态值- 2 ：标识当前线程正在进行条件等待*/
staticfinalintCONDITION=- 2 ;
/**节点等待状态值- 3 ：标识下一次共享锁的 acquireShared 操作需要无条件传播*/
staticfinalintPROPAGATE=- 3 ;
//节点状态：值为 SIGNAL、CANCELLED、CONDITION、PROPAGATE、 0
//普通的同步节点的初始值为 0 ，条件等待节点的初始值为 CONDITION（- 2 ）
volatileintwaitStatus;
//节点所对应的线程，为抢锁线程或者条件等待线程
volatileThreadthread;
//前驱节点，当前节点会在前驱节点上自旋，循环检查前驱节点的 waitStatus 状态
volatileNodeprev;
//后驱节点
volatileNodenext;
//如果当前 Node 不是普通节点而是条件等待节点，则节点处于某个条件的等待队列上
//此属性指向下一个条件等待节点，即其条件队列上的后驱节点
NodenextWaiter;
...
}
1 .waitStatus 属性
每个节点与等待线程关联，每个节点维护一个状态 waitStatus，waitStatus 的各种值以常量的形
式进行定义。waitStatus 的各常量值具体如下：

（ 1 ）staticfinalintCANCELLED= 1
waitStatus 值为 1 时表示该线程节点已释放（超时、中断），已取消的节点不会再阻塞。表示线
程因为中断或者等待超时，需要从等待队列中取消等待。
由于该节点线程等待超时或者被中断，需要从同步队列中取消等待，因此该线程被置 1 。节点
进入了取消状态，该类型节点不会参与竞争，且会一直保持取消状态。

（ 2 ）staticfinalintSIGNAL=‒ 1
waitStatus 为 SIGNAL（‒ 1 ）时表示其后驱节点处于等待状态，当前节点对应的线程如果释放了
同步状态或者被取消，将会通知后驱节点，使后驱节点的线程得以运行。

（ 3 ）staticfinalintCONDITION=‒ 2
waitStatus 为‒ 2 时，表示该线程在条件队列中阻塞（Condition 有使用），表示节点在等待队列
中（这里指的是等待在某个锁的 CONDITION 上，关于 CONDITION 的原理后面会讲到），当持有


```
第 6 章 AQS 抽象同步器核心原理 | 327
```
锁的线程调用了 CONDITION 的 signal () 方法之后，节点会从该 CONDITION 的等待队列转移到该锁
的同步队列上，去竞争锁（注意：这里的同步队列就是我们说的 AQS 维护的 FIFO 队列，等待队列
则是每个 CONDITION 关联的队列）。
节点处于等待队列中，节点线程等待在 CONDITION 上，当其他线程对 CONDITION 调用了
signal () 方法后，该节点从等待队列中转移到同步队列中，加入到对同步状态的获取中。

（ 4 ）staticfinalintPROPAGATE=‒ 3
waitStatus 为‒ 3 时，表示下一个线程获取共享锁后，自己的共享状态会被无条件地传播下去，
因为共享锁可能出现同时有 N 个锁可以用，这时直接让后面的 N 个节点都来工作。这种状态在
CountDownLatch 中使用到了。
为什么当一个节点的线程获取共享锁后，要唤醒后继共享节点？共享锁是可以多个线程共有
的，当一个节点的线程获取共享锁后，必然要通知后继共享节点的线程也可以获取锁了，这样就不会
让其他等待的线程等很久，这种向后通知（传播）的目的也是尽快通知其他等待的线程尽快获取锁。

（ 5 ）waitStatus 为 0
waitStatus 为 0 时，表示当前节点处于初始状态。
Node 节点的 waitStatus 状态为以上 5 种状态的一种。
2 .thread 成员
Node 的 thread 成员用来存放进入 AQS 队列中的线程引用；Node 的 nextWaiter 成员用来指向自己
的后继等待节点，此成员只有线程处于条件等待队列中的时候使用。

3 .抢占类型常量标识
Node 节点还定义了两个抢占类型常量标识：SHARED 和 EXCLUSIVE，具体的代码如下：
staticfinalclassNode{
//标识节点在抢占共享锁
staticfinalNodeSHARED=newNode ();
//标识节点在抢占独占锁
staticfinalNodeEXCLUSIVE=null;
...
}
SHARED 表示线程是因为获取共享资源时阻塞而被添加到队列中的；EXCLUSIVE 表示线程因
为获取独占资源时阻塞而被添加到队列中的。

###### 6. 2. 3 FIFO 双向同步队列

AQS 的内部队列是 CLH 队列的变种，每当线程通过 AQS 获取锁失败时，线程将被封装成一个 Node
节点，通过 CAS 原子操作插入队列尾部。当有线程释放锁时，AQS 会尝试让队首的后驱节点占用锁。
AQS 是一个通过内置的 FIFO 双向队列来完成线程的排队工作，内部通过节点 head 和 tail 记录队
首和队尾元素，元素的节点类型为 Node 类型，具体的代码如下：
/*首节点的引用*/
privatetransientvolatileNodehead;
/*尾节点的引用*/
privatetransientvolatileNodetail;


328 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

AQS 的队首节点和队尾节点都是懒加载的。懒加载的意思是在需要的时候才真正创建。只有在线
程竞争失败的情况下，有新线程加入同步队列时，AQS 才创建一个 head 节点。head 节点只能被 setHead ()
方法修改，并且节点的 waitStatus 不能为 CANCELLED。队尾节点只在有新线程阻塞时才被创建。
一个包含 5 个节点的 AQS 同步队列的基本结构如图 6 - 4 所示。

```
图 6 - 4 一个包含 5 个节点的 AQS 同步队列
```
###### 6. 2. 4 JUC 显式锁与 AQS 的关系

AQS 是 java. util. concurrent 包的一个同步器，它实现了锁的基本抽象功能，支持独占锁与共享锁
两种方式。该类使用模板模式来实现的，成为构建锁和同步器的框架，使用该类可以简单且高效地
构造出应用广泛的同步器（或者等待队列）。
java. util. concurrent. locks 包中的显式锁如 ReentrantLock、ReentrantReadWriteLock，线程同步工具
如 Semaphore，异步回调工具如 FutureTask 等，内部都使用了 AQS 作为等待队列。通过开发工具进行
AQS 的子类导航会发现大量的 AQS 子类以内部类的形式使用，具体如图 6 - 5 所示。

```
图 6 - 5 大量的 AQS 子类以内部类的形式使用
同样，我们也能继承 AQS 类去实现自己需求的同步器（或锁）。
```
###### 6. 2. 5 ReentrantLock 与 AQS 的组合关系

```
这里以 ReentrantLock 为例给大家介绍一下 JUC 显式锁与 AQS 的组合关系。
```

```
第 6 章 AQS 抽象同步器核心原理 | 329
```
1 .ReentrantLock 与 AQS 的组合关系
ReentrantLock 是一个可重入的互斥锁，又称为“可重入独占锁”。ReentrantLock 锁在同一个时间
点只能被一个线程锁持有，而可重入的意思是，ReentrantLock 锁可以被单个线程多次获取。
经过观察，ReentrantLock 把所有 Lock 接口的操作都委派到一个 Sync 类上，该类继承了
AbstractQueuedSynchronizer：
staticabstractclassSyncextendsAbstractQueuedSynchronizer {...}
ReentrantLock 为了支持公平锁和非公平锁两种模式，为 Sync 又定义了两个子类，具体如下：
finalstaticclassNonfairSyncextendsSync{...}
finalstaticclassFairSyncextendsSync {...}
NonfairSync 为非公平（或者不公平）同步器，FairSync 为公平同步器。ReentrantLock 提供了两
个构造器，具体如下：
publicReentrantLock (){ //默认的构造器
sync=newNonfairSync (); //内部使用非公平同步器
}
publicReentrantLock (booleanfair){ //true 为公平锁，否则为非公平锁
sync=fair?newFairSync (): newNonfairSync ();
}
ReentrantLock 的默认构造器（无参数构造器）被初始化为一个 NonfairSync 对象，即使用非公
平同步器，所以，默认情况下 ReentrantLock 为非公平锁。带参数的构造器可以根据 fair 参数的值具
体指定 ReentrantLock 的内部同步器使用 FairSync 还是 NonfairSync。
由 ReentrantLock 的 lock () 和 unlock () 的源码可以看到，它们只是分别调用了 sync 对象的 lock () 和
release () 方法。
publicvoidlock (){ //抢占显式锁
sync.lock ();
}
publicvoidunlock (){ //释放显式锁
sync.release ( 1 );
}
通过以上的委托代码可以看出，ReentrantLock 的显式锁操作是委托（或委派）给一个 Sync 内
部类的实例完成的。而 Sync 内部类只是 AQS 的一个子类，所以本质上 ReentrantLock 的显式锁操作是
委托（或委派）给 AQS 完成的。一个 ReentrantLock 对象的内部一定有一个 AQS 类型的组合实例，二
者之间是组合关系。
ReentrantLock 的内部结构，具体如图 6 - 6 所示。
2 .显式锁与 AQS 之间是组合关系
组合和聚合比较类似，二者都表示整体和部分之间的关系。
聚合关系的特点是：整体由部分构成，但是整体和部分之间并不是强依赖的关系，而是弱依
赖的关系，也就是说，即使整体不存在了，部分仍然存在。例如一个部门由多个员工组成，如果部
门撤销了，人员不会消失，人员依然存在。


330 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

图 6 - 6 ReentrantLock 的内部结构
组合关系的特点是：整体由部分构成，但是整体和部分之间是强依赖的关系，如果整体不存
在了，部分也随之消失。例如一个公司由多个部门组成，如果公司不存在了，部门也将不存在。
可以说，组合关系是一种强依赖的、特殊的聚合关系。
在 UML 图中，聚合关系用一条带空心菱形箭头的直线表示，组合关系用一条带实心菱形箭头
直线表示。聚合与组合在 UML 图上的区别如图 6 - 7 所示。

图 6 - 7 聚合与组合在 UML 图上的区别
由于显式锁与 AQS 之间是一种强依赖的聚合关系，如果显式锁的实例销毁，其聚合的 AQS 子
类实例也被销毁，因此显式锁与 AQS 之间是组合关系。

#### 6. 3 AQS 中的模板模式

AQS 同步器是基于模板模式设计的，并且是模板模式经典的一个运用，下面简单地给大家介
绍一下模板方法模式，模板模式是很容易理解的设计模式之一。如果需要自定义同步器，一般的方
法是继承 AQS，并重写指定方法（钩子方法），按照自己定义的规则对 state（锁的状态信息）进行


```
第 6 章 AQS 抽象同步器核心原理 | 331
```
获取与释放；将 AQS 组合在自定义同步组件的实现中，自定义同步器去调用 AQS 的模板方法，而这
些模板方法会调用重写的钩子方法。
作为铺垫，首先为大家介绍一下模板模式。

```
为什么要先介绍模板模式呢？可能很多同学都阅读过 AQS 的源码，但是不一定
能看懂，其原因在于没真正掌握模板模式，并按照其实现方式去阅读代码。
```
资深程序员都知道，Java 程序不是按照顺序执行的逻辑来组织的。Java 代码中所用到的设计模
式在一定程度上已经演变成了代码的组织方式。越是高水平的 Java 代码，抽象的层次越高，到处都
是高度抽象和面向接口的调用，大量用到继承、多态、设计模式。
在阅读别人的源代码时，如果不了解代码所使用的设计模式，往往会晕头转向，不知身在何
处，很难读懂别人的代码，对代码跟踪和阅读都很成问题。反过来，如果先掌握到代码的设计模式，
再去阅读代码，其过程就会变得很轻松，代码也不会那么难懂了。当然，在编写代码时，如果不了
解和熟练地掌握设计模式，也很难写出高水平的 Java 代码。
所以，在介绍 AQS 的核心原理之前，先为大家介绍一下在 AQS 的设计和实现中所用到的重要
模式——模板模式。

###### 6. 3. 1 模板模式

模板模式是类的行为模式。准备一个抽象类，将部分逻辑以具体方法的形式实现，然后声明
一些抽象方法来迫使子类实现剩余的逻辑。不同的子类提供不同的方式实现这些抽象方法，从而对
剩余的逻辑有不同的实现。模板模式的关键在于：父类提供框架性的公共逻辑，子类提供个性化的
定制逻辑。

1 .模板模式的定义
在模板模式中，由抽象类定义模板方法和钩子方法，模板方法定义一套业务算法框架，算法
框架中的某些步骤由钩子方法负责完成。具体的子类可以按需要重写钩子方法。模板方法的调用将
通过抽象类的实例来完成。
模板模式所包含的角色有抽象类和具体类，二者之间的关系如图 6 - 8 所示。

```
图 6 - 8 模板模式的抽象类和具体类以及二者之间的关系
```

332 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

2 .模板方法和钩子方法
模板方法（TemplateMethod）也常常被称为骨架方法，主要定义了整个方法需要实现的业务操作
的算法框架。其中，调用不同方法的顺序因人而异，而且这个方法也可以做成一个抽象方法，要求子
类自行定义逻辑流程。
钩子方法（HookMethod）是被模板方法的算法框架所调用的，而由子类提供具体的实现方法。
在抽象父类中，钩子方法常被定为一个空方法或者抽象方法，需要由子类去实现。钩子方法的存在
可以让子类提供算法框架中的某个细分操作，从而让子类实现算法中可选的、需要变动的部分。

```
模板模式在 Java 开发中用得很多，在很多基础中间件（比如 SpringMVC、Spring
Boot）中被频繁用到，建议大家重点掌握。
```
###### 6. 3. 2 一个模板模式的参考实现

模板设计模式很好理解，顾名思义，定义好一个模式，使用者在模板实现之上能够创造出基
于模板的产品，如图 6 - 9 所示。

```
图 6 - 9 一个模板模式的参考实现
1 .模板模式的参考实现代码
模板模式的参考实现代码如下：
packagecom. crazymakercircle. demo. lock;
importcom. crazymakercircle. util. Print;
publicclassTemplateDemo
{
staticabstractclassAbstractAction
{
/**
*模板方法：算法骨架
*/
publicvoidtempMethod ()
{
Print.cfo ("模板方法的算法骨架被执行");
beforeAction (); //执行前的公共操作
action (); //调用钩子方法
afterAction (); //执行后的公共操作
}
```

```
第 6 章 AQS 抽象同步器核心原理 | 333
```
/**
*执行前
*/
protectedvoidbeforeAction ()
{
Print.cfo ("准备执行钩子方法");
}
/**
*钩子方法：这里定义为一个抽象方法
*/
publicabstractvoidaction ();
/**
*执行后
*/
privatevoidafterAction ()
{
Print.cfo ("钩子方法执行完成");
}
}
//子类 A：提供了钩子方法实现
staticclassActionAextendsAbstractAction
{
/**
*钩子方法的实现
*/
@Override
publicvoidaction ()
{
Print.cfo ("钩子方法的实现 ActionA.action () 被执行");
}
}
//子类 B：提供了钩子方法实现
staticclassActionBextendsAbstractAction
{
/**
*钩子方法的实现
*/
@Override
publicvoidaction ()
{
Print.cfo ("钩子方法的实现 ActionB.action () 被执行");
}
}
publicstaticvoidmain (String[]args)
{
AbstractActionaction=null;
//创建一个 ActionA 实例
action=newActionA ();
//执行基类的模板方法
action.tempMethod ();
//创建一个 ActionB 实例
action=newActionB ();
//执行基类的模板方法
action.tempMethod ();
}
}

运行程序，结果如下：
[TemplateDemo$AbstractAction. tempMethod]：模板方法的算法骨架被执行


334 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

[TemplateDemo$AbstractAction. beforeAction]：准备执行钩子方法
[TemplateDemo$ActionA. action]：钩子方法的实现 ActionA.action () 被执行
[TemplateDemo$AbstractAction. afterAction]：钩子方法执行完成
[TemplateDemo$AbstractAction. tempMethod]：模板方法的算法骨架被执行
[TemplateDemo$AbstractAction. beforeAction]：准备执行钩子方法
[TemplateDemo$ActionB. action]：钩子方法的实现 ActionB.action () 被执行
[TemplateDemo$AbstractAction. afterAction]：钩子方法执行完成
2 .模板模式的优点
分离变与不变是软件设计的一个基本原则。模板模式将不变的部分封装在基类的骨架方法中，
而将变化的部分通过钩子方法进行封装，交给子类去提供具体的实现，在一定程度上优美地阐述了
“分离变与不变”这一软件设计原则。
模板模式的优点如下：
 通过算法骨架最大程度地进行了代码复用，减少重复代码。
 模板模式提取了公共部分代码，便于统一维护。
 钩子方法是由子类实现的，因此子类可以通过拓展增加复杂的功能，符合开放封闭原则。

```
开放封闭原则是面向对象设计的五大原则之一，其核心思想是：对扩展开放，
对修改关闭。面向对象设计的五大原则：单一职责原则、依赖倒置原则、接口隔离原则、里
氏替换原则和开放封闭原则。
```
###### 6. 3. 3 AQS 的模板流程

AQS 定义了两种资源共享方式：
 Exclusive（独享锁）：只有一个线程能占有锁资源，如 ReentrantLock。独享锁又可分为公
平锁和非公平锁。
 Share（共享锁）：多个线程可同时占有锁资源，如 Semaphore、CountDownLatch、CyclicBarrier、
ReadWriteLock 的 Read 锁。
AQS 为不同的资源共享方式提供了不同的模板流程，包括共享锁、独享锁模板流程。这些模
板流程完成了具体线程进出等待队列的基础（如获取资源失败入队/唤醒出队等）、通用逻辑。基
于基础、通用逻辑，AQS 提供一种实现阻塞锁和依赖 FIFO 等待队列的同步器的框架，AQS 模板为
ReentrantLock、CountDownLatch、Semaphore 提供了优秀的解决方案。
自定义的同步器只需要实现共享资源 state 的获取与释放方式即可，这些逻辑都编写在钩子方法
中。无论是共享锁还是独享锁，AQS 在执行模板流程时会回调自定义的钩子方法。

###### 6. 3. 4 AQS 中的钩子方法

```
自定义同步器时，AQS 中需要重写的钩子方法大致如下：
 tryAcquire (int)：独占锁钩子，尝试获取资源。若成功则返回 true，若失败则返回 false。
 tryRelease (int)：独占锁钩子，尝试释放资源。若成功则返回 true，若失败则返回 false。
 tryAcquireShared (int)：共享锁钩子，尝试获取资源，负数表示失败； 0 表示成功，但没有剩
余可用资源；正数表示成功，且有剩余资源。
```

```
第 6 章 AQS 抽象同步器核心原理 | 335
```
 tryReleaseShared (int)：共享锁钩子，尝试释放资源。若成功则返回 true，若失败则返回 false。
 isHeldExclusively ()：独占锁钩子，判断该线程是否正在独占资源。只有用到 condition 条件
队列时才需要去实现它。
以上钩子方法的默认实现会抛出 UnsupportedOperationException 异常。除了这些钩子方法外，
AQS 类中的其他方法都是 final 类型的方法，所以无法被其他类继承，只有这几个方法可以被其他类
继承。
对钩子方法的具体介绍如下。
1 .tryAcquire 独占式获取锁
顾名思义，就是尝试获取锁，AQS 在这里没有对 tryAcquire () 进行功能的实现，只有一个抛出
异常的语句，我们需要自己对其进行实现，可以对其重写实现公平锁、不公平锁、可重入锁、不可
重入锁。
protectedbooleantryAcquire (intarg){
thrownewUnsupportedOperationException ();
}
2 .tryRelease 独占式释放锁
tryRelease 尝试释放独占锁，需要子类来实现。
protectedbooleantryRelease (longarg){
thrownewUnsupportedOperationException ();
}
3 .tryAcquireShared 共享式获取
tryAcquireShared 尝试进行共享锁的获得，需要子类来实现。
protectedlongtryAcquireShared (longarg){
thrownewUnsupportedOperationException ();
}
4 .tryReleaseShared 共享式释放
tryReleaseShared 尝试进行共享锁的释放，需要子类来实现。
protectedbooleantryReleaseShared (longarg){
thrownewUnsupportedOperationException ();
}
5 .查询是否处于独占模式
isHeldExclusively 的功能是查询线程是否正在独占资源。在独占锁的条件队列中用到。
protectedbooleanisHeldExclusively (){
thrownewUnsupportedOperationException ();
}

#### 6. 4 通过 AQS 实现一把简单的独占锁

```
由于 ReentrantLock 的实现比较复杂，为了降低学习难度，本节首先模拟 ReentrantLock 的源码，
```

336 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

基于 AQS 实现一把非常简单的独占锁。在基于该独占锁学习完 AQS 的原理之后，再回头介绍
ReentrantLock 的实现原理。

###### 6. 4. 1 简单的独占锁的 UML 类图

```
基于 AQS 实现一把非常简单的独占锁的类为 SimpleMockLock，它的 UML 类图如图 6 - 10 所示。
```
```
图 6 - 10 为 SimpleMockLock 的 UML 类图
```
###### 6. 4. 2 简单的独占锁的实现

```
SimpleMockLock 是一个基于 AQS 的、简单的非公平独占锁实现，代码如下：
packagecom. crazymakercircle. demo. lock. custom;
//省略 import
publicclassSimpleMockLockimplementsLock
{
//同步器实例
privatefinalSyncsync=newSync ();
//自定义的内部类：同步器
//直接使用 AbstractQueuedSynchronizer. state 值表示锁的状态
//AbstractQueuedSynchronizer. state= 1 表示锁没有被占用
//AbstractQueuedSynchronizer. state= 0 表示锁已经被占用
privatestaticclassSyncextendsAbstractQueuedSynchronizer
{
//钩子方法
protectedbooleantryAcquire (intarg)
{
//CAS 更新状态值为 1
if (compareAndSetState ( 0 , 1 ))
{
setExclusiveOwnerThread (Thread.currentThread ());
returntrue;
}
returnfalse;
}
//钩子方法
```

```
第 6 章 AQS 抽象同步器核心原理 | 337
```
protectedbooleantryRelease (intarg)
{
//如果当前线程不是占用锁的线程
if (Thread.currentThread ()!=getExclusiveOwnerThread ())
{
//抛出非法状态的异常
thrownewIllegalMonitorStateException ();
}
//如果锁的状态为没有占用
if (getState ()== 0 )
{
//抛出非法状态的异常
thrownewIllegalMonitorStateException ();
}
//接下来不需要使用 CAS 操作，因为下面的操作不存在并发场景
setExclusiveOwnerThread (null);
//设置状态
setState ( 0 );
returntrue;
}
}
//显式锁的抢占方法
@Override
publicvoidlock ()
{
//委托给同步器的 acquire () 抢占方法
sync.acquire ( 1 );
}
//显式锁的释放方法
@Override
publicvoidunlock ()
{
//委托给同步器的 release () 释放方法
sync.release ( 1 );
}
//省略其他未实现的方法
}
}
和 ReentrantLock 相比，SimpleMockLock 的代码非常简单，这也是为了大家不被 ReentrantLock
的复杂代码锁困扰，能去更好地聚焦于 AQS 原理的学习。
SimpleMockLock 仅仅实现了 Lock 接口的以下两种方法：
1 ）lock () 方法：完成显式锁的抢占。
2 ）unlock () 方法：完成显式锁的释放。
SimpleMockLock 的锁抢占和锁释放是委托给 Sync 实例的 acquire () 方法和 release () 方法完成的。
SimpleMockLock 的内部类 Sync 继承了 AQS 类，实际上 acquire ()、release () 是 AQS 的两个模板方
法。在抢占锁时，AQS 的模板方法 acquire () 会调用 tryAcquire (intarg) 钩子方法；在释放锁时，AQS
的模板方法 release () 会调用 tryRelease (intarg) 钩子方法。
内部类 Sync 继承 AQS 类时提供了以下两个钩子方法的实现：
1 ）protectedbooleantryAcquire (intarg)：抢占锁的钩子实现。此方法将锁的状态设置为 1 ，表
示互斥锁已经被占用，并保存当前线程。


338 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

2 ）protectedbooleantryRelease (intarg)：释放锁的钩子实现。此方法将锁的状态设置为 0 ，表示
互斥锁已经被释放。

###### 6. 4. 3 SimpleMockLock 测试用例

接下来实现一个用于 SimpleMockLock 的测试用例。基于前面抽取出来的公共 IncrementData 累
加类编写一个让 10 个线程各累加 1000 次的程序，并使用 SimpleMockLock 作为累加的同步锁。自定
义独占锁 SimpleMockLock 的测试代码大致如下：
packagecom. crazymakercircle. demo. lock;
//省略 import
publicclassLockTest
{
@org. junit. Test
publicvoidtestMockLock ()
{
//每个线程的执行轮数
finalintTURNS= 1000 ;
//线程数
finalintTHREADS= 10 ;
//线程池，用于多线程模拟测试
ExecutorServicepool=Executors.newFixedThreadPool (THREADS);
//自定义的独占锁
Locklock=newSimpleMockLock ();
//倒数闩
CountDownLatchcountDownLatch=newCountDownLatch (THREADS);
longstart=System.currentTimeMillis ();
// 10 个线程并发执行
for (inti= 0 ;i<THREADS; i++)
{
pool.submit (()->
{
try
{
//累加 1000 次
for (intj= 0 ;j<TURNS; j++)
{
//传入锁，执行一次累加
IncrementData.lockAndFastIncrease (lock);
}
Print.tco ("本线程累加完成");
}catch (Exceptione)
{
e.printStackTrace ();
}
//线程执行完成，倒数闩减少一次
countDownLatch.countDown ();
});
}
//省略等待并发执行完成、结果输出的代码
}
}
运行程序，结果如下：


```
第 6 章 AQS 抽象同步器核心原理 | 339
```
```
[pool- 1 - thread- 5 ]：本线程累加完成
[pool- 1 - thread- 3 ]：本线程累加完成
[pool- 1 - thread- 4 ]：本线程累加完成
[pool- 1 - thread- 2 ]：本线程累加完成
[pool- 1 - thread- 1 ]：本线程累加完成
[pool- 1 - thread- 7 ]：本线程累加完成
[pool- 1 - thread- 6 ]：本线程累加完成
[pool- 1 - thread- 9 ]：本线程累加完成
[pool- 1 - thread- 8 ]：本线程累加完成
[pool- 1 - thread- 10 ]：本线程累加完成
[main|LockTest. testMockLock]：运行的时长为： 0. 103
[main|LockTest. testMockLock]：累加结果为： 10000
```
#### 6. 5 AQS 锁抢占的原理

AbstractQueuedSynchronizer 的实现非常精巧，令人叹为观止，不入细节难以完全领会其精髓。
下面基于 SimpleMockLock 公平独占锁的抢占过程详细说明 AQS 锁抢占的原理。

###### 6. 5. 1 显式锁抢占的总体流程

```
这里先介绍一下 SimpleMockLock 锁抢占的总体流程，具体如图 6 - 11 所示。
```
```
图 6 - 11 SimpleMockLock 抢锁流程
SimpleMockLock 的 lock () 源码如下：
packagecom. crazymakercircle. demo. lock. custom;
//省略 import
publicclassSimpleMockLockimplementsLock
{
//抢锁：将节点添加到等待队列的尾部
@Override
publicvoidlock ()
{
//开启同步器的抢锁流程，将节点添加到等待队列的尾部
```

340 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
sync.acquire ( 1 );
}
//省略其他
}
流程的第一步，显式锁的 lock () 方法会去调用同步器基类 AQS 的模板方法 acquire（arg）。
```
###### 6. 5. 2 AQS 模板方法：acquire (arg)

acquire 是 AQS 封装好的获取资源的公共入口，它是 AQS 提供的利用独占方式获取资源的方法，
源码实现如下：
publicfinalvoidacquire (intarg){
if (! tryAcquire (arg)&&
acquireQueued (addWaiter (Node. EXCLUSIVE), arg))
selfInterrupt ();
}
通过源码可以发现，acquire (arg) 至少执行一次 tryAcquire (arg) 钩子方法。tryAcquire (arg) 方法默
认是抛出一个异常，具体的获取独占资源 state 的逻辑需要钩子方法去实现。
在模板方法 acquire 中，若调用 tryAcquire (arg) 尝试成功，则 acquire () 将直接返回，表示已经抢到
锁；若不成功，则将线程加入等待队列。
模板方法 acquire () 的代码非常简洁，但是背后的逻辑却非常复杂，可见 DougLea 深刻的编程功力。

###### 6. 5. 3 钩子实现：tryAcquire (arg)

SimpleMockLock 的钩子实现如下：
privatestaticclassSyncextendsAbstractQueuedSynchronizer
{
//钩子方法
protectedbooleantryAcquire (intarg)
{
//CAS 更新状态值为 1
if (compareAndSetState ( 0 , 1 ))
{
setExclusiveOwnerThread (Thread.currentThread ());
returntrue;
}
returnfalse;
}
SimpleMockLock 的 tryAcquire () 的流程是：CAS 操作 state 字段，将其值从 0 改为 1 ，若成功，则
表示锁未被占用，可成功占用，并且返回 true；若失败，则获取锁失败，返回 false。
SimpleMockLock 的实现非常简单，是不可以重入的，仅仅为了学习 AQS 而编写。如果是可以
重入的锁，在重复抢锁时会累计 state 字段值，表示重入锁的次数，具体可参考 ReentrantLock 源码。

###### 6. 5. 4 直接入队：addWaiter

在 acquire 模板方法中，如果钩子方法 tryAcquire 尝试获取同步状态失败，则构造同步节点（独
占式节点模式为 Node. EXCLUSIVE），通过 addWaiter (Nodenode, intargs) 方法将该节点加入到同步
队列的队尾。


```
第 6 章 AQS 抽象同步器核心原理 | 341
```
privateNodeaddWaiter (Nodemode){
//创建新节点
Nodenode=newNode (Thread.currentThread (), mode);
//加入队列尾部，将目前的队列 tail 作为自己的前驱节点 pred
Nodepred=tail;
//队列不为空的时候
if (pred!=null){
node. prev=pred;
//先尝试通过 AQS 方式修改尾节点为最新的节点
//如果修改成功，将节点加入到队列的尾部
if (compareAndSetTail (pred, node)){
pred. next=node;
returnnode;
}
}
//第一次尝试添加尾部失败，意味着有并发抢锁发生，需要进行自旋
enq (node);
returnnode;
}
在 addWaiter () 方法中，首先需要构造一个 Node 对象，具体的代码如下：
Nodenode=newNode (Thread.currentThread (), mode);
构造 Node 对象所用到的两个参数如下：
（ 1 ）当前线程
构造 Node 对象时，将通过 Thread.currentThread () 获取到当前线程作为第一个参数，该线程会被
赋值给 Node 对象的 thread 成员属性，相当于将线程与 Node 节点进行绑定。在后续轮到此 Node 节点去
占用锁时，就需要其 thread 属性获得需要唤醒的线程。

（ 2 ）Node 共享类型
mode 是一个表示 Node 类型的参数，用于标识新节点是独占地还是共享地去抢占锁。mode 虽然
为 Node 类型，但是仅仅起到类型标识的作用。mode 可能的值有两个，以常量的形式定义在 Node 类
中，具体的代码如下：
staticfinalclassNode{
/**常量标识：标识当前的队列节点类型为共享型抢占*/
staticfinalNodeSHARED=newNode ();
/**常量标识：标识当前的队列节点类型为独占型抢占*/
staticfinalNodeEXCLUSIVE=null;
//省略其他代码
}
如果抢占独占锁，那么 mode 值为 EXCLUSIVE；如果抢占共享锁，那么 mode 值为 SHARED。

###### 6. 5. 5 自旋入队：enq

addWaiter () 第一次尝试在尾部添加节点失败，意味着有并发抢锁发生，需要进行自旋。enq ()
方法通过 CAS 自旋将节点的添加到队列尾部。
/**
*这里进行了循环，如果此时存在 tail，就执行添加队尾的操作
*如果依然不存在，就把当前线程作为 head 节点
*插入节点后，调用 acquireQueued () 进行阻塞


342 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
*/
privateNodeenq (finalNodenode){
for (;;){
Nodet=tail;
if (t==null){
//队列为空，初始化队尾节点和队首节点为新节点
if (compareAndSetHead (newNode ()))
tail=head;
}else{
//队列不为空，将新节点插入队列尾部
node. prev=t;
if (compareAndSetTail (t, node)){
t.next=node;
returnt;
}
}
}
}
/**
*CAS 操作 head 指针，仅仅被 enq () 调用
*/
privatefinalbooleancompareAndSetHead (Nodeupdate){
returnunsafe.compareAndSwapObject (this, headOffset, null, update);
}
/**
*CAS 操作 tail 指针，仅仅被 enq () 调用
*/
privatefinalbooleancompareAndSetTail (Nodeexpect, Nodeupdate){
returnunsafe.compareAndSwapObject (this, tailOffset, expect, update);
}
```
###### 6. 5. 6 自旋抢占：acquireQueued ()

在节点入队之后，启动自旋抢锁的流程。acquireQueued () 方法的主要逻辑：当前 Node 节点线
程在死循环中不断获取同步状态，并且不断在前驱节点上自旋，只有当前驱节点是队首节点才能尝
试获取锁，原因是：

1 ）队首节点是成功获取同步状态（锁）的节点，而队首节点的线程释放了同步状态以后，将
会唤醒其后驱节点，后驱节点的线程被唤醒后要检查自己的前驱节点是否为队首节点。
2 ）维护同步队列的 FIFO 原则，节点进入同步队列之后，就进入了一个自旋的过程，每个节点
都在不断地执行 for 死循环。
finalbooleanacquireQueued (finalNodenode, intarg){
booleanfailed=true;
try{
booleaninterrupted=false;
//自旋检查当前节点的前驱节点是否为队首节点，才能获取锁
for (;;){
//获取节点的前驱节点
finalNodep=node.predecessor ();
//节点中的线程循环的检查自己的前驱节点是否为 head 节点
//只有前驱节点是 head 时，进一步调用子类的 tryAcquire（...）实现
if (p==head&&tryAcquire (arg)){
//tryAcquire 成功后，将当前节点设置为队首节点，移除之前的队首节点
setHead (node);
p.next=null;//helpGC


```
第 6 章 AQS 抽象同步器核心原理 | 343
```
failed=false;
returninterrupted;
}
//检查前一个节点的状态，预判当前获取锁失败的线程是否要挂起
//如果需要挂起
//调用 parkAndCheckInterrupt 方法挂起当前线程，直到被唤醒
if (shouldParkAfterFailedAcquire (p, node)&&
parkAndCheckInterrupt ())
interrupted=true;//若两个操作都是 true，则为 true
}
}finally{
//如果等待过程中没有成功获取资源（如 timeout，或者可中断的情况下被中断了）
//那么取消节点在队列中的等待
if (failed)
//取消请求，将当前节点从队列中移除
cancelAcquire (node);
}
}
为了不浪费资源，acquireQueued () 自旋过程中会阻塞线程，等待前驱节点唤醒后才启动循环。如
果成功就返回，否则执行 shouldParkAfterFailedAcquire ()、parkAndCheckInterrupt () 来达到阻塞效果。
调用 acquireQueued () 方法的线程一定是 node 所绑定的线程（由它的 thread 属性所引用），该线
程也是最开始调用 lock () 方法抢锁的那个线程，在 acquireQueued () 的死循环中，该线程可能重复进
行阻塞和被唤醒。
AQS 队列上每一个节点所绑定的线程在抢锁过程中都会自旋，即执行 acquireQueued () 方法的死
循环，也就是说，AQS 队列上每个节点的线程都不断自旋，具体如图 6 - 12 所示。

图 6 - 12 AQS 队列的节点自旋
如果队首节点获取了锁，那么该节点绑定的线程会终止 acquireQueued () 自旋，线程会去执行临
界区代码。此时，其余的节点处于自旋状态，处于自旋状态的线程当然也不会执行无效的空循环而
导致 CPU 资源浪费，而是被挂起（Park）进入阻塞状态。AQS 队列的节点自旋不像 CLH 节点那样在
空自旋而耗费资源。

###### 6. 5. 7 挂起预判：shouldParkAfterFailedAcquire

acquireQueued () 自旋在阻塞自己的线程之前会进行挂起预判。shouldParkAfterFailedAcquire ()
方法的主要功能是：找到当前节点的有效前驱节点（是指有效节点不是 CANCELLED 类型的节点），


344 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

并且将有效前驱节点的状态设置为 SIGNAL，之后返回 true 代表当前线程可以马上被阻塞了。具体
可以分为三种情况：

1 ）如果前驱节点的状态为‒ 1 （SIGNAL），说明前驱的等待标志已设好，返回 true 表示设置
完毕。
2 ）如果前驱节点的状态为 1 （CANCELLED），说明前驱节点本身不再等待了，需要跨越这
些节点，然后找到一个有效节点，再把当前节点和这个有效节点的唤醒关系建立好：调整前驱节点
的 next 指针为自己。
3 ）如果是其他情况：‒ 3 （PROPAGATE、共享锁等待）、‒ 2 （CONDITION、条件等待）、 0
（初始状态），那么通过 CAS 尝试设置前驱节点为 SIGNAL，表示只要前驱释放锁，当前节点就可
以抢占锁了。

其源码如下：
privatestaticbooleanshouldParkAfterFailedAcquire (
Nodepred, Nodenode){
intws=pred. waitStatus; //获得前驱节点的状态
if (ws==Node. SIGNAL) //如果前驱节点状态为 SIGNAL（值为- 1 ）就直接返回
returntrue;
if (ws> 0 ){ //前驱节点以及取消 CANCELLED（ 1 ）
do{
//不断地循环，找到有效前驱节点，即非 CANCELLED（值为 1 ）类型节点
//将 pred 记录前驱的前驱
pred=pred. prev;
//调整当前节点的 prev 指针，保持为前驱的前驱
node. prev=pred;
}while (pred. waitStatus> 0 );
//调整前驱节点的 next 指针
pred. next=node;
}else{
//如果前驱状态不是 CANCELLED，也不是 SIGNAL，就设置为 SIGNAL
compareAndSetWaitStatus (pred, ws, Node. SIGNAL);
//设置前驱状态之后，此方法返回值还是为 false，表示线程不可用，被阻塞
}
returnfalse;
}
在独占锁的场景中，此方法 shouldParkAfterFailedAcquire () 是在 acquireQueued () 方法的死循环中
被调用的，由于此方法返回 false 时 acquireQueued () 不会阻塞当前线程，只有此方法返回 true 时当前
线程才阻塞。因此在一般情况下，此方法至少需执行两次，当前线程才会被阻塞。
在第一次进入此方法时，首先会进入后一个 if 判断的 else 分支，通过 CAS 设置 pred 前驱的
waitStatus 为 SIGNAL，然后返回 false。
此方法返回 false 之后，获取独占锁的 acquireQueued () 方法会继续进行 for 循环去抢锁：
1 ）假设 node 的前驱节点是队首节点，tryAcquire () 抢锁成功，则获取到锁。
2 ）假设 node 的前驱节点仍然不是队首节点，或 tryAcquire () 抢锁失败，仍会再次调用此方法。
第二次进入此方法时，由于上一次进入时已经将 pred. waitStatus 设置为－ 1 （SIGNAL）了，因
此这次会进入第一个判断条件，直接返回 true，表示应该调用 parkAndCheckInterrupt 阻塞当前线程
了，等待前一个节点执行完成之后唤醒。


```
第 6 章 AQS 抽象同步器核心原理 | 345
```
1 .waitStatus 等于‒ 3
什么时候遇到前驱节点状态 waitStatus 等于‒ 3 （PROPAGATE）的场景呢？PROPAGATE 只能
在使用共享锁的时候出现，并且只可能设置在 head 上。所以，对于非队尾节点，如果它的状态为 0
或 PROPAGATE，那么它肯定是 head。当等待队列中有多个节点时，如果 head 的状态为 0 或
PROPAGATE，说明 head 处于一种中间状态，且此时有线程刚才释放锁了。而对于抢锁线程来说，
如果检测到这种状态，说明再次执行 acquire () 是极有可能获得锁的。

2 .waitStatus 大于 0
什么时候会遇到前驱节点的状态 waitStatus 大于 0 的场景呢？当 pred 前驱节点的抢锁请求被取
消后期状态为 CANCELLED（值为 1 ）时，当前节点（如果被唤醒）就会循环移除所有被取消的前
驱节点，直到找到未被取消的前驱。在移除所有被取消的前驱节点后，此方法将返回 false，再一次
去执行 acquireQueued () 的自旋抢占。

3 .waitStatus 等于 0
什么时候遇到前驱节点状态 waitStatus 等于 0 （初始状态）的场景呢？分为两种情况：
1 ）node 节点刚成为新队尾，但还没有将旧队尾的状态设置为 SIGNAL。
2 ）node 节点的前驱节点为 head。
前驱节点为 waitStatus 等于 0 的情况是最常见的。比如现在 AQS 的等待队列中有很多节点正在等
待，当前线程刚执行完毕 addWaiter（节点刚成为新队尾），然后开始执行获取锁的死循环（独占
锁对应的是 acquireQueued () 里的死循环，共享锁对应的是 doAcquireShared () 里的死循环），此时节
点的前驱（也就是旧队尾的状态）肯定还是 0 （也就是默认初始化的值），然后死循环执行两次，
第一次执行 shouldParkAfterFailedAcquire () 自然会检测到前驱状态为 0 ，然后将 0 设置为 SIGNAL；第
二次执行 shouldParkAfterFailedAcquire ()，由于前驱节点为 SIGNAL，当前线程直接返回 true，去执
行自我阻塞。

###### 6. 5. 8 线程挂起：parkAndCheckInterrupt ()

parkAndCheckInterrupt () 主要任务是暂停当前线程，具体如下：
privatefinalbooleanparkAndCheckInterrupt (){
LockSupport.park (this); //调用 park () 使线程进入 waiting 状态
returnThread.interrupted (); //如果被唤醒，查看自己是否已经被中断
}
AbstractQueuedSynchronizer 会把所有的等待线程构成一个阻塞等待队列，当一个线程执行完
lock.unlock () 时，会激活其后驱节点，通过调用 LockSupport.unpark (postThread) 完成后继线程的唤醒。

#### 6. 6 AQS 两个关键点：节点的入队和出队

由于 AQS 的实现非常精妙，因此理解 AQS 的原理还是比较困难的。理解 AQS 的原理一个比较
重要的关键点在于掌握节点的入队和出队。


346 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

###### 6. 6. 1 节点的自旋入队

节点在第一次入队失败后，就会开始自旋入队，分为以下两种情况：
1 ）如果 AQS 的队列非空，新节点通过 CAS 插入队列尾部，并且是通过 CAS 方式插入，插入之
后 AQS 的 tail 将指向新的尾节点。
2 ）如果 AQS 的队列为空，新节点入队时，AQS 通过 CAS 方法将新节点设置为队首节点，并且
将 tail 指针指向新节点。然后自旋，进入 CAS 插入操作，直到插入成功，自旋才结束。

```
节点的入队的代码在 enq () 方法中，因为 enq () 非常重要，所以将其代码重复如下：
privateNodeenq (finalNodenode){
for (;;){//自旋入队
Nodet=tail;
if (t==null){
//队列为空，初始化队尾节点和队首节点为新节点
if (compareAndSetHead (newNode ()))
tail=head;
}else{
//如果队列不为空，将新节点插入队列尾部
node. prev=t;
if (compareAndSetTail (t, node)){
t.next=node;
returnt;
}
}
}
}
```
```
队列初始化创建了一个空的队首节点，这个空的队首节点没有对应的线程，只
占用一个位置，等到后面的节点抢到锁，这个节点就被移除。
```
###### 6. 6. 2 节点的出队

节点出队的算法在 acquireQueued () 方法中，这是一个非常重要的模板方法。acquireQueued () 方
法通过不断在前驱节点上自旋（for 死循环），如果前驱节点是队首节点并且当前线程使用钩子方
法 tryAcquire (arg) 获得了锁，则移除队首节点，将当前节点设置为队首节点。
finalbooleanacquireQueued (finalNodenode, intarg){
booleanfailed=true;
try{
booleaninterrupted=false;
//在前驱节点上自旋
for (;;){
//获取节点的前驱节点
finalNodep=node.predecessor ();
//（ 1 ）前驱节点是队首节点
//（ 2 ）通过子类的 tryAcquire () 钩子实现抢占成功
if (p==head&&tryAcquire (arg)){
//将当前节点设置为队首节点，之前的队首节点出队
setHead (node);
p.next=null;//helpGC
failed=false;
returninterrupted;


```
第 6 章 AQS 抽象同步器核心原理 | 347
```
}
//省略 park（无限期阻塞）线程的代码
}
}finally{
//省略其他
}
}
节点加入到队列尾部后，如果其前驱节点就不是队首节点，通常情况下，该新节点所绑定的
线程会被无限期阻塞，而不会去执行无效循环，从而导致 CPU 资源的浪费。
问题来了：被无限期阻塞的抢锁线程，是什么时候被唤醒的呢？
对于公平锁而言，队首节点就是占用锁的节点，在释放锁时，将会唤醒其后驱节点所绑定的
线程。后驱节点的线程被唤醒后会重新执行以上 acquireQueued () 的自旋（for 死循环）抢锁逻辑，检
查自己的前驱节点是否为队首节点，如果是，在抢锁成功之后会移除旧的队首节点。
AQS 释放锁时是如何唤醒后继线程的呢？AQS 释放锁的核心代码如下：
publicfinalbooleanrelease (longarg){
if (tryRelease (arg)){ //释放锁的钩子实现
Nodeh=head;//队列的队首节点
if (h!=null&&h.waitStatus!= 0 )
unparkSuccessor (h); //唤醒后驱线程
returntrue;
}
returnfalse;
}
unparkSuccessor 的核心代码如下：
privatevoidunparkSuccessor (Nodenode){
//省略不相关代码
Nodes=node. next;//后驱节点
//省略不相关代码
if (s!=null)
LockSupport.unpark (s.thread); //唤醒后驱的线程
}
通过以上分析可以看出：无效节点的出队操作是在唤醒后驱节点的线程之后，其后驱节点的
线程在抢锁过程中完成的。

#### 6. 7 AQS 锁释放的原理

```
下面基于 SimpleMockLock 公平独占锁的释放过程详细说明 AQS 锁释放的原理。
```
###### 6. 7. 1 SimpleMockLock 独占锁的释放流程

```
SimpleMockLock 独占锁的释放流程如图 6 - 13 所示。
```

348 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
图 6 - 13 SimpleMockLock 独占锁的释放流程
```
###### 6. 7. 2 AQS 模板方法：release ()

SimpleMockLock 的 unlock () 方法被调用时，会调用 AQS 的 release (...) 的模板方法。AQS 的
release (...) 的模板方法代码如下：
publicfinalbooleanrelease (longarg){
if (tryRelease (arg)){
Nodeh=head;
if (h!=null&&h.waitStatus!= 0 )
unparkSuccessor (h);
returntrue;
}
returnfalse;
}
这段代码逻辑比较简单，如果同步状态的钩子方法执行成功（tryRelease 返回 true），就会执行
if 块中的代码，当 head 指向的队首节点不为 null，并且该节点的状态值不为 0 时才会执行
unparkSuccessor () 方法。
钩子方法 tryRelease () 方法尝试释放当前线程持有的资源，由子类提供具体的实现。

6. 7. (^3) 钩子实现：tryRelease ()
tryRelease () 方法是需要子类提供实现的一个钩子方法，需要子类根据具体业务去实现。
SimpleMockLock 的钩子实现如下：
//钩子方法
protectedbooleantryRelease (intarg)
{
//如果当前线程不是占用锁的线程
if (Thread.currentThread ()!=getExclusiveOwnerThread ())
{
//抛出非法状态的异常
thrownewIllegalMonitorStateException ();
}
//如果锁的状态为没有占用
if (getState ()== 0 )
SimpleMockLock 独占锁的释放流程
unlock ()


```
第 6 章 AQS 抽象同步器核心原理 | 349
```
```
{
//抛出非法状态的异常
thrownewIllegalMonitorStateException ();
}
//接下来不需要使用 CAS 操作，因为下面的操作不存在并发场景
setExclusiveOwnerThread (null);
//设置状态
setState ( 0 );
returntrue;
}
}
核心逻辑是设置同步状态 state 的值为 0 ，方便后驱节点执行抢占。
```
###### 6. 7. 4 唤醒后驱：unparkSuccessor ()

release () 钩子执行了 tryRelease () 钩子成功之后，使用 unparkSuccessor () 唤醒后驱节点，具体的代
码如下：
privatevoidunparkSuccessor (Nodenode){
intws=node. waitStatus;//获得节点状态，释放锁的节点，也就是队首节点
//CANCELLED（ 1 ）、SIGNAL（- 1 ）、CONDITION（- 2 ）、PROPAGATE（- 3 ）
//如果队首节点状态小于 0 ，则将其置为 0 ，表示初始状态
if (ws< 0 )
compareAndSetWaitStatus (node, ws, 0 );
Nodes=node. next;//找到后面的一个节点
if (s==null||s.waitStatus> 0 ){
//如果新节点已经被取消 CANCELLED（ 1 ）
s=null;
//从队列尾部开始，往前去找最前面的一个 waitStatus 小于 0 的节点
for (Nodet=tail; t!=null&&t!=node; t=t.prev)
if (t.waitStatus<= 0 ) s=t;
}
//唤醒后驱节点对应的线程
if (s!=null)
LockSupport.unpark (s.thread);
}
unparkSuccessor () 唤醒后驱节点的线程后，后驱节点的线程重新执行方法 acquireQueued () 中的
自旋抢占逻辑。

```
当 AQS 队首节点释放锁之后，队首节点的状态变成初始状态，此节点理论上需
要从队列中移除，但是此时该无效节点并没有立即被移除，unparkSuccessor () 方法并没有立
即从队列中删除该无效节点，仅仅唤醒了后驱节点的线程，重启了后驱节点的自旋抢锁。
```
#### 6. 8 ReentrantLock 的抢锁流程

下面结合 AbstractQueuedSynchronizer () 的模板方法详细说明 ReentrantLock 的实现过程。
ReentrantLock 有两种模式：

```
 公平锁：按照线程在队列中的排队顺序，先到者先拿到锁。
```

350 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

 非公平锁：当线程要获取锁时，无视队列顺序直接去抢锁，谁抢到就是谁的。
ReentrantLock 在同一个时间点只能被一个线程获取，ReentrantLock 是通过一个 FIFO 的等待队
列（AQS 队列）来管理获取该锁所有线程的。ReentrantLock 是继承自 Lock 接口实现的独占式可重入
锁，并且 ReentrantLock 组合一个 AQS 内部实例完成同步操作。

###### 6. 8. 1 ReentrantLock 非公平锁的抢占流程

```
ReentrantLock 非公平锁的抢占的总体流程如图 6 - 14 所示。
```
```
图 6 - 14 ReentrantLock 非公平锁的抢占流程
```
6. 8. (^2) 非公平锁的同步器子类
ReentrantLock 为非公平锁实现了一个内部的同步器——NonfairSync，其显式锁获取方法 lock ()
的源码如下：
staticfinalclassNonfairSyncextendsSync{
//非公平锁抢占
finalvoidlock (){
if (compareAndSetState ( 0 , 1 ))
setExclusiveOwnerThread (Thread.currentThread ());
else
acquire ( 1 );
}
//省略其他
}
首先用一个 CAS 操作，判断 state 是否是 0 （表示当前锁未被占用），如果是 0 就把它置为 1 ，并
且设置当前线程为该锁的独占线程，表示获取锁成功。当多个线程同时尝试占用同一个锁时，CAS
操作只能保证一个线程操作成功，剩下的只能乖乖去排队。
ReentrantLock“非公平”性即体现在这里：如果占用锁的线程刚释放锁，state 置为 0 ，而排队
等待锁的线程还未唤醒，新来的线程就直接抢占了该锁，那么就“插队”了。举一个例子：当前有


```
第 6 章 AQS 抽象同步器核心原理 | 351
```
三个线程 A、B、C 去竞争锁，假设线程 A、B 在排队，但是后来的 C 直接进行 CAS 操作成功了，拿
到了锁开开心心地返回了，那么线程 A、B 只能乖乖看着。

###### 6. 8. 3 非公平抢占的钩子方法：tryAcquire (arg)

如果非公平抢占没有成功，非公平锁的 lock 会执行模板方法 acquire ()，首先会调用到钩子方法
tryAcquire (arg)。非公平抢占的钩子方法实现如下：
staticfinalclassNonfairSyncextendsSync{
//非公平锁抢占的钩子方法
protectedfinalbooleantryAcquire (intacquires){
returnnonfairTryAcquire (acquires);
}
//省略其他
}
abstractstaticclassSyncextendsAbstractQueuedSynchronizer{
finalbooleannonfairTryAcquire (intacquires){
finalThreadcurrent=Thread.currentThread ();
//先直接获得锁的状态
intc=getState ();
if (c== 0 ){
//如果任务队列首节点的线程完了，它会将锁的 state 设置为 0
//当前抢锁线程的下一步就是直接进行抢占，不管不顾
//发现 state 是空的，就直接拿来加锁使用，根本不考虑后面后驱者的存在
if (compareAndSetState ( 0 ,acquires)){
// 1 .利用 CAS 自旋方式判断当前 state 确实为 0 ，然后设置成 acquire（ 1 ）
//这是原子性的操作，可以保证线程安全
setExclusiveOwnerThread (current);
//设置当前执行的线程，直接返回 true
returntrue;
}
}
elseif (current==getExclusiveOwnerThread ()){
// 2 .当前的线程和执行中的线程是同一个，也就意味着可重入操作
intnextc=c+acquires;
if (nextc< 0 )//overflow
thrownewError ("Maximumlockcountexceeded");
setState (nextc);
//表示当前锁被 1 个线程重复获取了 nextc 次
returntrue;
}
//否则就是返回 false，表示没有尝试成功获取当前锁，进入排队过程
returnfalse;
}
//省略其他
}
非公平同步器 ReentrantLock. NonfairSync 的核心思想就是当前进程尝试获取锁的时候，如果发
现锁的状态位是 0 ，就直接尝试将锁拿过来，然后执行 setExclusiveOwnerThread ()，根本不管同步队
列中的排队节点。

###### 6. 8. 4 ReentrantLock 公平锁的抢占流程

```
ReentrantLock 公平锁的抢占流程如图 6 - 15 所示。
```

352 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
图 6 - 15 ReentrantLock 公平锁的抢占流程
```
###### 6. 8. 5 公平锁的同步器子类

ReentrantLock 为公平锁实现了一个内部的同步器——FairSync，其显式锁获取方法 lock 的源码
如下：
staticfinalclassFairSyncextendsSync{
//公平锁抢占的钩子方法
finalvoidlock (){
acquire ( 1 );
}
//省略其他
}
公平同步器 ReentrantLock. FairSync 的核心思想是通过 AQS 模板方法去进行队列入队操作。

###### 6. 8. 6 公平抢占的钩子方法：tryAcquire (arg)

公平锁的 lock 会执行模板方法 acquire，该方法首先会调用钩子方法 tryAcquire (arg)。公平抢占
的钩子方法实现如下：
staticfinalclassFairSyncextendsSync{
//公平抢占的钩子方法
protectedfinalbooleantryAcquire (intacquires){
finalThreadcurrent=Thread.currentThread ();
intc=getState (); //锁状态
if (c== 0 ){
if (! hasQueuedPredecessors ()&& //有前驱节点就返回，足够讲义气
compareAndSetState ( 0 ,acquires)){
setExclusiveOwnerThread (current);
returntrue;
}
}
elseif (current==getExclusiveOwnerThread ()){


```
第 6 章 AQS 抽象同步器核心原理 | 353
```
intnextc=c+acquires;
if (nextc< 0 )
thrownewError ("Maximumlockcountexceeded");
setState (nextc);
returntrue;
}
returnfalse;
}
}
公平抢占的钩子方法中，首先判断是否有后驱节点，如果有后驱节点，并且当前线程不是锁
的占有线程，钩子方法就返回 false，模板方法会进入排队的执行流程，可见公平锁是真正公平的。

###### 6. 8. 7 是否有后驱节点的判断

FairSync 进行是否有后驱节点的判断代码如下：
publicfinalbooleanhasQueuedPredecessors (){
Nodet=tail;
Nodeh=head;
Nodes;
returnh!=t&&
((s=h.next)==null||s.thread!=Thread.currentThread ());
}
hasQueuedPredecessors 的执行场景大致如下：
1 ）当 h!=t 不成立的时候，说明 h 队首节点、t 尾节点要么是同一个节点，要么都是 null，此时
hasQueuedPredecessors () 返回 false，表示没有后驱节点。
2 ）当 h!=t 成立的时候，进一步检查 head. next 是否为 null，如果为 null，就返回 true。什么情况下
h!=t 同时h.next==null 呢？有其他线程第一次正在入队时可能会出现。其他线程执行 AQS 的 enq () 方法，
compareAndSetHead (node) 完成，还没执行 tail=head 语句时，此时 t=null、head=newNode ()、
head. next=null。
3 ）如果 h!=t 成立，head. next!=null，判断 head. next 是不是当前线程，如果是就返回 false，否则
返回 true。

head 节点是获取到锁的节点，但是任意时刻 head 节点可能占用着锁，也可能释放了锁，如果释
放了锁，那么此时 state= 0 ，未被阻塞的 head. next 节点对应的线程在任意时刻都是在自旋地尝试获取锁。

#### 6. 9 AQS 条件队列

Condition 是 JUC 用来替代传统的 Object 的 wait ()/notify () 线程间通信与协作机制的新组件，相比
使用 Object 的 wait ()/notify ()，使用 Condition 的 await ()/signal () 这种方式实现线程间协作更加高效。

###### 6. 9. 1 Condition 基本原理

Condition 与 Object 的 wait ()/notify () 作用是相似的，都是使得一个线程等待某个条件（Condition），
只有当该条件具备 signal () 或者 signalAll () 方法被调用时等待线程才会被唤醒，从而重新争夺锁。不


354 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

同的是，Object 的 wait ()/notify () 由 JVM 底层实现，而 Condition 接口与实现类完全使用 Java 代码实现。
当需要进行线程间的通信时，建议结合使用 ReentrantLock 与 Condition，通过 Condition 的 await () 和
signal () 方法进行线程间的阻塞与唤醒。
ConditionObject 类是实现条件队列的关键，每个 ConditionObject 对象都维护一个单独的条件等
待对列。每个 ConditionObject 对应一个条件队列，它记录该队列的队首节点和尾节点。
publicclassConditionObjectimplementsCondition, java. io. Serializable{
//记录该队列的队首节点
privatetransientNodefirstWaiter;
//记录该队列的尾节点
privatetransientNodelastWaiter;
}
一个 Condition 对象是一个单条件的等待队列，具体如图 6 - 16 所示。

图^6 -^16 一个 Condition 单条件的等待队列
在一个显式锁上，我们可以创建多个等待任务队列，这点和内置锁不同，Java 内置锁上只有唯
一的一个等待队列。比如，我们可以使用 newCondition () 创建两个等待队列，具体如下：
privateLocklock=newReentrantLock ();
//创建第一个等待队列
privateConditionfirstCond=lock.newCondition ();
//创建第二个等待队列
privateConditionsecondCond=lock.newCondition ();
Condition 条件队列与 AQS 同步队列的关系如图 6 - 17 所示。

```
图 6 - 17 Condition 条件队列与 AQS 同步队列的关系
```

```
第 6 章 AQS 抽象同步器核心原理 | 355
```
```
Condition 条件队列是单向的，而 AQS 同步队列是双向的，AQS 节点会有前驱指
针。一个 AQS 实例可以有多个条件队列，是聚合关系；但是一个 AQS 实例只有一个同步队列，
是逻辑上的组合关系。
```
###### 6. 9. 2 await () 等待方法原理

当线程调用 await () 方法时，说明当前线程的节点为当前 AQS 队列的队首节点，正好处于占有锁
的状态，await () 方法需要把该线程从 AQS 队列挪到 Condition 等待队列里，如图 6 - 18 所示。

图 6 - 18 await () 方法的主要执行过程
在 await () 方法中将当前线程挪动到 Condition 等待队列后，还会唤醒 AQS 同步队列中 head 节点的
下一个节点。await () 方法的核心代码如下：
publicfinalvoidawait () throwsInterruptedException{
if (Thread.interrupted ())
thrownewInterruptedException ();
Nodenode=addConditionWaiter (); //step 1
intsavedState=fullyRelease (node); //step 2
intinterruptMode= 0 ;
while (! isOnSyncQueue (node)){ //step 3
LockSupport.park (this);
if ((interruptMode=checkInterruptWhileWaiting (node))!= 0 )
break;
}
if (acquireQueued (node, savedState) //step 4
&&interruptMode!=THROW_IE)
interruptMode=REINTERRUPT;
if (node. nextWaiter!=null) //step 5
unlinkCancelledWaiters ();
if (interruptMode!= 0 )
reportInterruptAfterWait (interruptMode);
}
await () 方法的整体流程如下：
1 ）执行 await () 时，会新创建一个节点并放入到 Condition 队列尾部。
2 ）然后释放锁，并唤醒 AQS 同步队列中的队首节点的后一个节点。
3 ）然后执行 while 循环，将该节点的线程阻塞，直到该节点离开等待队列，重新回到同步队列
成为同步节点后，线程才退出 while 循环。


356 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

4 ）退出循环后，开始调用 acquireQueued () 不断尝试拿锁。
5 ）拿到锁后，会清空 Condition 队列中被取消的节点。
创建一个新节点并放入 Condition 队列尾部的工作由 addConditionWaiter () 方法完成，该方法具体
如下：
privateNodeaddConditionWaiter (){
Nodet=lastWaiter;
//如果尾节点取消，重新定位尾节点
if (t!=null&&t.waitStatus!=Node. CONDITION){
unlinkCancelledWaiters ();
t=lastWaiter;
}
//创建一个新 Node，作为等待节点
Nodenode=newNode (Thread.currentThread (), Node. CONDITION);
//将新 Node 加入等待队列
if (t==null)
firstWaiter=node;
else
t.nextWaiter=node;
lastWaiter=node;
returnnode;
}

###### 6. 9. 3 signal () 唤醒方法原理

线程在某个 ConditionObject 对象上调用 signal () 方法后，等待队列中的 firstWaiter 会被加入到同
步队列中，等待节点被唤醒，流程如图 6 - 19 所示。

```
图 6 - 19 signal () 方法的主要执行过程
signal () 方法的源码如下：
//唤醒
publicfinalvoidsignal (){
//如果当前线程不是持有该锁的线程，就抛出异常
if (! isHeldExclusively ())
thrownewIllegalMonitorStateException ();
Nodefirst=firstWaiter;
if (first!=null)
doSignal (first); //唤醒队首节点
}
```

```
第 6 章 AQS 抽象同步器核心原理 | 357
```
//执行唤醒
privatevoiddoSignal (Nodefirst){
do{
//出队的代码写得很巧妙，要看仔细
//first 出队，firstWaiter 头部指向下一个节点，自己的 nextWaiter
if ((firstWaiter=first. nextWaiter)==null)
lastWaiter=null;//如果第二节点为空，则尾部也为空
//将原来头部 first 的后继置空，helpforGC
first. nextWaiter=null;
}while (! transferForSignal (first)&&(first=firstWaiter)!=null);
}
//将被唤醒的节点转移到同步队列
finalbooleantransferForSignal (Nodenode){
if (! compareAndSetWaitStatus (node, Node. CONDITION, 0 ))
returnfalse;
Nodep=enq (node); //step 1
intws=p.waitStatus;
if (ws> 0 ||! compareAndSetWaitStatus (p, ws, Node. SIGNAL))
LockSupport.unpark (node. thread); //step 2 ：唤醒线程
returntrue;
}
signal () 方法的整体流程如下：
1 ）通过 enq () 方法自旋（该方法已经介绍过），将条件队列中的队首节点放入到 AQS 同步队列
尾部，并获取它在 AQS 队列中的前驱节点。
2 ）如果前驱节点的状态是取消状态，或者设置前驱节点为 Signal 状态失败，就唤醒当前节点
的线程；否则节点在同步队列的尾部，参与排队。
3 ）同步队列中的线程被唤醒后，表示重新获取了显式锁，然后继续执行 condition.await () 语句
后面的临界区代码。

###### 6. 9. 4 节点入队的时机

```
在介绍完 AQS 之后总结一下，节点入队 AQS 的时机。
```
```
加入此小节的原因是，有读者在社群中交流，他碰到了一个面试题：“AQS 中
进入队列的 4 个时机”。所以，梳理一下节点进入 AQS 的时机，这里暂时梳理了两个时机和
三种细分场景。
```
时机一：在模板方法 acquire () 中，如果调用 tryAcquire (arg) 尝试成功，acquire () 将直接返回，表
示已经抢到锁；如果不成功，则开始将线程加入等待队列。
这里分为三种场景：
1 ）模板方法 acquire (arg) 通过 addWaiter (Nodenode, intargs) 方法，尝试将该节点加入到同步队
列的队尾，在存在竞争的场景时一般会成功。当然，如果加入失败，或者同步队列为空，就开始调
用 enq (finalNodenode) 自旋入队。
2 ）enq () 方法通过 CAS 自旋将新节点插入队列尾部。具体来说，如果 AQS 的队列非空，新节点
入队的插入位置在队列的尾部，并且是通过 CAS 方式插入的，插入之后 AQS 的 tail 将指向新节点，
新节点作为尾节点。


358 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

3 ）enq () 方法初始化 AQS 队列再执行 CAS 自旋。如果 AQS 的队列为空，新节点入队时首先进行
队列初始化，AQS 通过 CAS 方法创建队首节点，并且将 tail 指针指向队首节点。然后自旋，进入 CAS
自旋插入操作，直到插入成功，自旋才结束。

时机二：Condition 等待队列上的节点被 signal () 唤醒，会通过 enq (finalNodenode) 自旋入队，插
入 AQS 的尾部。

#### 6. 10 AQS 的实际应用

```
首先介绍一下 JUC 的总体架构，如图 6 - 20 所示。
```
图 6 - 20 JUC 的总体架构
AQS 建立在 CAS 原子操作和 volatile 可见性变量的基础之上，为上层的显式锁、同步工具类、
阻塞队列、线程池、并发容器、Future 异步工具提供线程之间同步的基础设施。所以，AQS 在 JUC
框架中的使用是非常广泛的。

```
显式锁
```

# 第 7 章

## JUC 容器类

Java 的基础容器主要有 List、Set、Queue、Map 四个大类，但是大家熟知的基础容器类 ArrayList、
LinkedList、HashMap 都是非线程安全的，在多个线程场景中使用这些基础容器会出现线程安全问
题。为了解决线程安全问题，Java 使用内置锁提供了一套线程安全的同步容器类。虽然同步容器类
的解决了线程安全问题，不过性能却不高。正因为如此，JUC 提供了一套高并发容器类。本章首先
为大家介绍同步容器的问题，然后全面地介绍 JUC 高并发容器类。

#### 7. 1 线程安全的同步容器类

Java 同步容器类是通过 synchronized（内置锁）来实现同步的容器，比如 Vector、HashTable 以
及 SynchronizedList 等容器。线程安全的同步容器类主要有：Vector、Stack、HashTable 等。另外，
Java 还提供一组包装方法，将一个普通的基础容器包装成一个线程安全的同步容器。例如通过
Collections. synchronized 包装方法能将一个普通的 SortedSet 容器包装成一个线程安全的 SortedSet 同
步容器。

1 .通过 synchronizedSortedSet 静态方法包装出一个同步容器
下面的例子使用 java.util.Collections.synchronizedSortedSet () 静态方法包装出一个线程安全的同
步容器：
packagecom. crazymakercircle. syncontainer;
//省略 import
publicclassCollectionsDemo
{
publicstaticvoidmain (String[]args) throwsInterruptedException
{
//创建一下基础的有序集合
SortedSet<String>elementSet=newTreeSet<String>();
//增加元素
elementSet.add ("element 1 ");
elementSet.add ("element 2 ");


360 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

//将 elementSet 包装成一个同步容器
SortedSetsorset=Collections.synchronizedSortedSet (elementSet);
//输出容器中的元素
System.out.println ("SortedSetis: "+sorset);
CountDownLatchlatch=new CountDownLatch ( 5 );
for (inti= 0 ;i< 5 ;i++)
{
intfinalI=i;
ThreadUtil.getCpuIntenseTargetThreadPool ()
.submit (()->{
//向同步容器中增加一个元素
sorset.add ("element"+( 3 +finalI));
Print.tco ("addelement"+( 3 +finalI));
latch.countDown ();
});
}
latch.await ();
//输出容器中的元素
System.out.println ("SortedSet is: "+sorset);
}
}
运行程序，输出的结果如下：
SortedSetis:[element 1 ,element 2 ]
[apppool- 1 - cpu- 3 ]：addelement 5
[apppool- 1 - cpu- 1 ]：addelement 3
[apppool- 1 - cpu- 2 ]：addelement 4
[apppool- 1 - cpu- 4 ]：addelement 6
[apppool- 1 - cpu- 5 ]：addelement 7
SortedSetis:[element 1 ,element 2 ,element 3 ,element 4 ,element 5 ,element 6 ,element 7 ]
2 .java. util. Collections 所提供的同步包装方法
除了提供了对 SortedSet 进行同步包装的方法之外，java. util. Collections 还提供了一系列的对其
他的基础容器进行同步包装的方法，如 synchronizedList () 方法将基础 List 包装成线程安全的列表容
器，synchronizedMap () 方法将基础 Map 容器包装成线程安全的容器，synchronizedCollection () 方法将
基础 Collection 容器包装成线程安全的 Collection 容器。
java. util. Collections 所提供的同步包装方法大致如图 7 - 1 所示。
与同步包装方法相对应，java. util. Collections 还提供了一系列的同步包装类，这些包装内都是
其内部类。这些同步包装类的实现逻辑很简单：实现了容器的操作接口，在操作接口上使用
synchronized 进行线程同步，然后在 synchronized 的临界区将实际的操作委托给被包装的基础容器。

3 .同步容器面临的问题
可以通过查看 Vector、HashTable、java. util. Collections 同步包装内部类的源码，发现这些同步
容器的实现线程安全的方式是：在需要同步访问的方法上加上关键字 synchronized。
第 2 章介绍过，synchronized 在线程没有发生争用的场景下处于偏向锁的状态，其性能是非常高的。
但是，一旦发生了线程争用，synchronized 会由偏向锁膨胀成重量级锁，在抢占和释放时发生 CPU 内核
态与用户态切换，所以削弱了并发性，降低了吞吐量，而且会严重影响性能。


```
第 7 章 JUC 容器类 | 361
```
```
图 7 - 1 java. util. Collections 所提供的同步包装方法
因此，为了解决同步容器的性能问题，有了 JUC 高并发容器。
```
#### 7. 2 JUC 高并发容器

JUC 基于非阻塞算法（LockFree、无锁编程）提供了一组高并发容器，包括高并发的 List、Set、
Queue、Map 容器。

1 .什么是高并发容器
JUC 高并发容器是基于非阻塞算法（或者无锁编程算法）实现的容器类，无锁编程算法主要通
过 CAS（CompareAndSwap）+Volatile 组合实现，通过 CAS 保障操作的原子性，通过 volatile 保障变
量的内存可见性。无锁编程算法的主要优点如下：

1 ）开销较小：不需要在内核态和用户态之间切换进程。
2 ）读写不互斥：只有写操作需要使用基于 CAS 机制的乐观锁，读读操作之间可以不用互斥。
JUC 包中提供了 List、Set、Queue、Map 各种类型的高并发容器，如 ConcurrentHashMap、
ConcurrentSkipListMap、ConcurrentSkipListSet、CopyOnWriteArrayList 和 CopyOnWriteArraySet。在
性能上，ConcurrentHashMap 通常优于同步的 HashMap，ConcurrentSkipListMap 通常优于同步的 TreeMap。
当读取和遍历操作远远大于列表的更新操作时，CopyOnWriteArrayList 优于同步的 ArrayList。

2 .List
JUC 包中高并发 List 主要有 CopyOnWriteArrayList，对应的基础容器为 ArrayList。
CopyOnWriteArrayList 相当于线程安全的 ArrayList，它实现了 List 接口。在读多写少的场景中，
其性能远远高于 ArrayList 的同步包装容器。

```
3 .Set
JUC 包中 Set 主要有 CopyOnWriteArraySet、ConcurrentSkipListSet。
```

362 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

 CopyOnWriteArraySet 继承于 AbstractSet 类，对应的基础容器为 HashSet。其内部组合了一个
CopyOnWriteArrayList 对象，它是核心操作是基于 CopyOnWriteArrayList 实现的。
 ConcurrentSkipListSet 是线程安全的有序集合，对应的基础容器为 TreeSet。它继承于
AbstractSet，并实现了 NavigableSet 接口。ConcurrentSkipListSet 是通过 ConcurrentSkipListMap
实现的。
4 .Map
JUC 包中 Map 主要有 ConcurrentHashMap 和 ConcurrentSkipListMap。
 ConcurrentHashMap 对应的基础容器为 HashMap。JDK 6 中的 ConcurrentHashMap 采用一种更
加细粒度的“分段锁”加锁机制，JDK 8 中采用 CAS 无锁算法。
 ConcurrentSkipListMap 对应的基础容器为 TreeMap。其内部的 SkipList（跳表）结构是一种
可以代替平衡树的数据结构，默认是按照 Key 值升序的。
5 .Queue
JUC 包中 Queue 的实现类包括三类：单向队列、双向队列和阻塞队列。
 ConcurrentLinkedQueue 是一个基于列表实现的单向队列，按照 FIFO（先进先出）原则对元
素进行排序。新元素从队列尾部插入，而获取队列元素则需要从队列头部获取。
 ConcurrentLinkedDeque 是基于链表的双向队列，但是该队列不允许 null 元素。作为双端队
列，ConcurrentLinkedDeque 可以当作“栈”来使用，并且高效地支持并发环境。
除了提供普通的单向、双向队列，JUC 拓展了队列，增加了可阻塞的插入和获取等操作，提供
了一组阻塞队列，具体如下：

```
 ArrayBlockingQueue：基于数组实现的可阻塞的 FIFO 队列。
 LinkedBlockingQueue：基于链表实现的可阻塞的 FIFO 队列。
 PriorityBlockingQueue：按优先级排序的队列。
 DelayQueue：按照元素的 Delay 时间进行排序的队列。
 SynchronousQueue：无缓冲等待队列。
接下来，为大家介绍 CopyOnWriteArrayList 的使用和原理。
```
#### 7. 3 CopyOnWriteArrayList

在很多应用场景中，读操作可能会远远大于写操作。由于读操作根本不会修改原有的数据，
因此如果每次读取都进行加锁操作其实是一种资源浪费。我们应该允许多个线程同时访问 List 的内
部数据，毕竟读操作是线程安全的。
写时复制（CopyOnWrite，COW）思想是计算机程序设计领域中的一种优化策略。其核心思
想是，如果有多个访问器（Accessor）访问一个资源（如内存或者是磁盘上的数据存储）时，它们
会共同获取相同的指针指向相同的资源，只要有一个修改器（Mutator）需要修改该资源，系统会
复制一份专用副本（PrivateCopy）给该修改器，而其他访问器所见到的最初资源仍然保持不变，


```
第 7 章 JUC 容器类 | 363
```
修改的过程对其他的访问器都是透明的（Transparently）。COW 主要的优点是如果没有修改器去修
改资源，就不会创建副本，因此多个访问器可以共享同一份资源。

###### 7. 3. 1 CopyOnWriteArrayList 的使用

前面讲到，Collections 可以将基础容器包装为线程安全的同步容器，但是这些同步容器包装类
在进行元素迭代时并不能进行元素添加操作。下面是一个简单的例子：
packagecom. crazymakercircle. lockfree;
//省略 import
publicclassCopyOnWriteArrayListTest
{
//并发操作的执行目标
publicstaticclassCocurrentTargetimplementsRunnable
{
//并发操作的目标队列
List<String>targetList=null;
publicCocurrentTarget (List<String>targetList)
{
this. targetList=targetList;
}
@Override
publicvoidrun ()
{
Iterator<String>iterator=targetList.iterator ();
//迭代操作
while (iterator.hasNext ())
{
//在迭代操作时，进行列表的修改
StringthreadName=currentThread (). getName ();
Print.tco ("开始往同步队列加入线程名称："+threadName);
targetList.add (threadName);
}
}
}
//测试同步队列：在迭代操作时，进行列表的修改
@Test
publicvoidtestSynchronizedList ()
{
List<String>notSafeList=asList ("a","b","c");
List<String>synList=Collections.synchronizedList (notSafeList);
//创建一个执行目标
CocurrentTargetsynchronizedListListDemo=newCocurrentTarget (synList);
// 10 个线程并发
for (inti= 0 ;i< 10 ;i++)
{
newThread (synchronizedListListDemo,"线程"+i). start ();
}
//主线程等待
sleepSeconds ( 1000 );
}
}
执行用例，抛出以下异常：
java. lang. UnsupportedOperationException
atjava.util.AbstractList.add (AbstractList. java: 148 )


364 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

atjava.util.AbstractList.add (AbstractList. java: 108 )
atjava. util. Collections$SynchronizedCollection.add (Collections. java: 2035 )
atcom. crazymakercircle. lockfree. CopyOnWriteArrayListTest$CocurrentTarget.
run (CopyOnWriteArrayListTest. java: 38 )
atjava.lang.Thread.run (Thread. java: 745 )
那么，该如何解决此问题呢？可使用 CopyOnWriteArrayList 替代 Collections. synchronizedList 同
步包装实例，具体的代码如下：
packagecom. crazymakercircle. lockfree;
//省略 import
publicclassCopyOnWriteArrayListTest
{
//测试 CopyOnWriteArrayList
@Test
publicvoidtestcopyOnWriteArrayList ()
{
List<String>notSafeList=asList ("a","b","c");
//创建一个 CopyOnWriteArrayList 队列
List<String>copyOnWriteArrayList=newCopyOnWriteArrayList ();
copyOnWriteArrayList.addAll (notSafeList);
//并发执行目标
CocurrentTargetcopyOnWriteArrayListDemo=
newCocurrentTarget (copyOnWriteArrayList);
for (inti= 0 ;i< 10 ;i++)
{
newThread (copyOnWriteArrayListDemo,"线程"+i). start ();
}
//主线程等待
sleepSeconds ( 1000 );
}
}
运行以上用例，发现 UnsupportedOperationException 异常没有了。也就是说，使用
CopyOnWriteArrayList 容器，可以在进行元素迭代的同时进行元素添加操作。那么
CopyOnWriteArrayList 是如何做到的呢？下面为大家介绍一下 CopyOnWriteArrayList 的原理。

###### 7. 3. 2 CopyOnWriteArrayList 原理

CopyOnWrite（写时复制）就是在修改器对一块内存进行修改时，不直接在原有内存块上进行
写操作，而是将内存复制一份，在新的内存中进行写操作，写完之后，再将原来的指针（或者引用）
指向新的内存，原来的内存被回收。CopyOnWriteArrayList 是写时复制思想的一种典型实现：其含
有一个指向操作内存的内部指针 array，而可变操作（add、set 等）是在 array 数组的副本上进行的。
当元素需要被修改或者增加时，并不直接在 array 指向的原有数组上操作，而是首先对 array 进行一
次复制，将修改的内容写入复制的副本中。写完之后，再将内部指针 array 指向新的副本，这样就
可以确保修改操作不会影响访问器的读取操作了。CopyOnWriteArrayList 的原理如图 7 - 2 所示。
从名字可以看出：CopyOnWriteArrayList 是一个满足 CopyOnWrite 思想并使用 Array 数组存储数
据的线程安全 List。CopyOnWriteArrayList 的核心成员如下：
publicclassCopyOnWriteArrayList<E>
implementsList<E>, RandomAccess, Cloneable, java. io. Serializable{
privatestaticfinallongserialVersionUID= 8673264195747942595 L;


```
第 7 章 JUC 容器类 | 365
```
```
/**对所有的修改器方法进行保护，访问器方法并不需要保护*/
finaltransientReentrantLocklock=newReentrantLock ();
/**内部对象数组，通过 getArray/setArray 方法访问*/
privatetransientvolatileObject[]array;
/**
*获取内部对象数组
*/
finalObject[]getArray (){
returnarray;
}
/**
*设置内部对象数组
*/
finalvoidsetArray (Object[]a){
array=a;
}
//省略其他代码
}
```
```
图 7 - 2 CopyOnWriteArrayList 的原理
```
###### 7. 3. 3 CopyOnWriteArrayList 读取操作

访问器的读取操作没有任何同步控制和锁操作，理由就是内部数组 array 不会发生修改，只会
被另外一个 array 替换，因此可以保证数据安全。
/**操作内存的引用*/
privatetransientvolatileObject[]array;
publicEget (intindex){
returnget (getArray (), index);
}
//获取元素
@SuppressWarnings ("unchecked")
privateEget (Object[]a, intindex){
return (E) a[index];
}
//返回操作内存

```
写完切换成副本
通过 volatile 保障内存可见
```

366 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
finalObject[]getArray (){
returnarray;
}
```
###### 7. 3. 4 CopyOnWriteArrayList 写入操作

CopyOnWriteArrayList 的写入操作 add () 方法在执行时加了独占锁以确保只能有一个线程进行
写入操作，避免多线程写的时候会复制出多个副本。
publicbooleanadd (Ee){
finalReentrantLocklock=this. lock;
lock.lock (); //加锁
try{
Object[]elements=getArray ();
intlen=elements. length;
//复制新数组
Object[]newElements=Arrays.copyOf (elements, len+ 1 );
newElements[len]=e;
setArray (newElements);
returntrue;
}finally{
lock.unlock (); //释放锁
}
}
从 add () 操作可以看出，在每次进行添加操作时，CopyOnWriteArrayList 底层都是重新复制了一
份数组，再往新的数组中添加新元素，待添加完了，再将新的 array 引用指向新的数组。当 add () 操
作完成后，array 的引用就已经指向另一个存储空间了。
既然每次添加元素的时候都会重新复制一份新的数组，那就带来了一个问题，就是增加了内
存的开销，如果容器的写操作比较频繁，那么其开销就比较大。所以，在实际应用的时候，
CopyOnWriteArrayList 并不适合进行添加操作。但是在并发场景下，迭代操作比较频繁，
CopyOnWriteArrayList 就是一个不错的选择。

###### 7. 3. 5 CopyOnWriteArrayList 的迭代器实现

CopyOnWriteArray 有自己的迭代器，该迭代器不会检查修改状态，也无需检查状态。为什么
呢？因为被迭代的 array 数组是可以说是只读的，不会有其他线程能够修改它。
staticfinalclassCOWIterator<E>implementsListIterator<E>{
/**对象数组的快照（snapshot）*/
privatefinalObject[]snapshot;
/**Indexofelementtobereturnedbysubsequentcalltonext. */
privateintcursor;
privateCOWIterator (Object[]elements, intinitialCursor){
cursor=initialCursor;
snapshot=elements;
}
publicbooleanhasNext (){
returncursor<snapshot. length;
}
//下一个元素
publicEnext (){


```
第 7 章 JUC 容器类 | 367
```
if (! hasNext ())
thrownewNoSuchElementException ();
return (E) snapshot[cursor++];
}
}
迭代器的快照成员会在构造迭代器的时候使用 CopyOnWriteArrayList 的 array 成员去初始化，具
体的代码如下：
//获取迭代器
publicIterator<E>iterator (){
returnnewCOWIterator<E>(getArray (), 0 );
}
//返回操作内存
finalObject[]getArray (){
returnarray;
}
1 .CopyOnWriteArrayList 的优点
CopyOnWriteArrayList 有一个显著的优点，那就是读取、遍历操作不需要同步，速度会非常快。
所以，CopyOnWriteArrayList 适用于读操作多、写操作相对较少的场景（读多写少），比如可以在
进行“黑名单”拦截时使用 CopyOnWriteArrayList。

2 .CopyOnWriteArrayList 和 ReentrantReadWriteLock 的比较
CopyOnWriteArrayList 和 ReentrantReadWriteLock 读写锁的思想非常类似，即读读共享、写写互
斥、读写互斥、写读互斥。但是前者相比后者更进一步：为了将读取的性能发挥到极致，
CopyOnWriteArrayList 读取是完全不用加锁的，而且写入也不会阻塞读取操作，只有写入和写入之间
需要进行同步等待，于是读操作的性能得到大幅度提升。

#### 7. 4 BlockingQueue

在多线程环境中，通过 BlockingQueue（阻塞队列）可以很容易地实现多线程之间数据共享和通
信，比如在经典的“生产者－消费者”模型中，通过 BlockingQueue 可以完成一个高性能的实现版本。

###### 7. 4. 1 BlockingQueue 的特点

阻塞队列与普通队列（ArrayDeque 等）之间的最大不同点在于阻塞队列提供了阻塞式的添加
和删除方法。

（ 1 ）阻塞添加
所谓的阻塞添加是指当阻塞队列元素已满时，队列会阻塞添加元素的线程，直队列元素不满
时，才重新唤醒线程执行元素添加操作。

（ 2 ）阻塞删除
阻塞删除是指在队列元素为空时，删除队列元素的线程将被阻塞，直到队列不为空时，才重
新唤醒删除线程再执行删除操作。


368 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

###### 7. 4. 2 阻塞队列的常用方法

```
先来看看阻塞队列接口提供的主要方法：
publicinterfaceBlockingQueue<E>extendsQueue<E>{
//将指定的元素添加到此队列的尾部（如果立即可行且不会超过该队列的容量）
//在成功时返回 true，如果此队列已满，就抛出 IllegalStateException
booleanadd (Ee);
//非阻塞式添加：将指定的元素添加到此队列的尾部（如果立即可行且不会超过该队列的容量）
//如果该队列已满，就直接返回
booleanoffer (Ee)
//限时阻塞式添加：将指定的元素添加到此队列的尾部
//如果该队列已满，那么在到达指定的等待时间截止之前，添加线程会阻塞，等待可用的空间，该方法可中断
booleanoffer (Ee, longtimeout, TimeUnitunit) throwsInterruptedException;
//阻塞式添加：将指定的元素添加此队列的尾部，如果该队列已满，就一直等待（阻塞）
voidput (Ee) throwsInterruptedException;
//阻塞式删除：获取并移除此队列的队首元素，如果没有元素就等待（阻塞）
//直到有元素，将唤醒等待线程执行该操作
Etake () throwsInterruptedException;
//非阻塞式删除：获取并移除此队列的队首元素，如果没有元素就直接返回 null (空)
Epoll () throwsInterruptedException;
//限时阻塞式删除：获取并移除此队列的队首元素，在指定的等待时间前一直等待获取元素，超过时间，方法
将结束
Epoll (longtimeout, TimeUnitunit) throwsInterruptedException;
//获取但不移除此队列的队首元素，没有则抛出异常 NoSuchElementException
Eelement ();
//获取但不移除此队列的队首元素，如果此队列为空，就返回 null
Epeek ();
//从此队列中移除指定元素，返回删除是否成功
booleanremove (Objecto);
}
这里把上述操作进行分类：
1 .添加类方法
1 ）add (Ee)：添加成功则返回 true，失败就抛出 IllegalStateException 异常。
2 ）offer (Ee)：成功则返回 true，如果此队列已满就返回 false。
3 ）put (Ee)：将元素添加此队列的尾部，如果该队列已满，就一直阻塞。
2 .删除类方法
1 ）poll ()：获取并移除此队列的队首元素，若队列为空，则返回 null。
2 ）take ()：获取并移除此队列的队首元素，若没有元素，则一直阻塞。
3 ）remove (Objecto)：移除指定元素，成功则返回 true，失败则返回 false。
3 .获取元素类方法
1 ）element ()：获取但不移除此队列的队首元素，没有元素则抛出异常。
2 ）peek ()：获取但不移除此队列的队首元素；若队列为空，则返回 null。
```

```
第 7 章 JUC 容器类 | 369
```
阻塞队列对元素的增删查操作主要就是上述的三类方法，这里对这三类方法的特征进行总结，
具体如表 7 - 1 所示。

表 7 - 1 阻塞队列三类方法的特征
抛出异常特殊值阻塞限时阻塞
添加 add (e) offer (e) put (e) offer (e, time, unit)
删除 remove () poll () take () poll (time, unit)
获取元素 element () peek () 不可用不可用
对表 7 - 1 中的 4 个特征说明如下：
（ 1 ）抛出异常
如果尝试的操作无法立即执行，就抛出一个异常。
（ 2 ）特殊值
如果尝试的操作无法立即执行，返回一个特定的值（通常是 true/false）。
（ 3 ）阻塞
如果尝试的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行。
（ 4 ）限时阻塞
如果尝试的操作无法立即执行，该方法调用将会发生阻塞，直到能够执行，但等待时间不会
超过设置的上限值。

###### 7. 4. 3 常见的 BlockingQueue

在了解 BlockingQueue 主要方法后，下面介绍 BlockingQueue 家族大致有哪些成员。BlockingQueue
的实现类有 ArrayBlockingQueue、DelayQueue、LinkedBlockingDeque、LinkedBlockingQueue、
PriorityBlockingQueue、SynchronousQueue 等，具体如图 7 - 3 所示。

图 7 - 3 BlockingQueue 的主要实现类
不同的 BlockingQueue 子类之间的区别主要体现在元素存储结构和元素操作上，对这些子类的
大致介绍如下：

1 .ArrayBlockingQueue
ArrayBlockingQueue 是一个常用的阻塞队列，是基于数组实现的，其内部使用一个定长数组存
储元素。除了一个定长数组外，ArrayBlockingQueue 内部还保存着两个整型变量，分别标识队列的
头部和尾部在数组中的位置。


370 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

ArrayBlockingQueue 的添加和删除操作都是共用同一个锁对象，由此意味着添加和删除无法并
行运行，这一点不同于 LinkedBlockingQueue。ArrayBlockingQueue 完全可以将添加和删除的锁分离，
从而添加和删除操作完全并行。DougLea 之所以没有这样去做，是因为 ArrayBlockingQueue 的数据
写入和获取操作已经足够轻巧。
为什么 ArrayBlockingQueue 比 LinkedBlockingQueue 更加常用？前者在添加或删除元素时不会产
生或销毁任何额外的 Node（节点）实例，而后者会生成一个额外的 Node 实例。在长时间、高并发处
理大批量数据的场景中，LinkedBlockingQueue 产生的额外 Node 实例会加大系统的 GC 压力。

2 .LinkedBlockingQueue
LinkedBlockingQueue 是基于链表的阻塞队列，其内部也维持着一个数据缓冲队列（该队列由
一个链表构成）。LinkedBlockingQueue 对于添加和删除元素分别采用了独立的锁来控制数据同步，
这也意味着在高并发的情况下生产者和消费者可以并行地操作队列中的数据，以此来提高整个队列
的并发性能。
需要注意的是，在新建一个 LinkedBlockingQueue 对象时，若没有指定其容量大小，则
LinkedBlockingQueue 会默认一个类似无限大小的容量（Integer. MAX_VALUE），这样的话，如果
生产者的速度一旦大于消费者的速度，也许还没有等到队列满阻塞产生，系统内存就有可能已被消
耗殆尽了。

```
ArrayBlockingQueue 和 LinkedBlockingQueue 两个队列都比较常用。两个队列的
API 基本相同，实现的原理上也类似。所以，本书为了节约篇幅，仅对 ArrayBlockingQueue
进行介绍，有关 LinkedBlockingQueue 的原理可参见疯狂创客圈的社群博客：
《LinkedBlockingQueue-秒懂》，地址为https://www.cnblogs.com/crazymakercircle/p/ 13934458 .html。
```
3 .DelayQueue
DelayQueue 中的元素只有当其指定的延迟时间到了，才能从队列中获取到该元素。DelayQueue
是一个没有大小限制的队列，因此往队列中添加数据的操作（生产者）永远不会被阻塞，而只有获
取数据的操作（消费者）才会被阻塞。
DelayQueue 使用场景较少，但是相当巧妙，常见的例子比如使用一个 DelayQueue 来管理一个
超时未响应的连接队列。

4 .PriorityBlockingQueue
基于优先级的阻塞队列和 DelayQueue 类似，PriorityBlockingQueue 并不会阻塞数据生产者，而只会
在没有可消费的数据时，阻塞数据的消费者。在使用的时候要特别注意，生产者生产数据的速度绝对
不能快于消费者消费数据的速度，否则时间一长，会最终耗尽所有的可用堆内存空间。

5 .SynchronousQueue
一种无缓冲的等待队列类似于无中介的直接交易，有点像原始社会中的生产者和消费者，生
产者拿着商品去集市销售给商品的最终消费者，而消费者必须亲自去集市找到所要商品的直接生产
者，如果一方没有找到合适的目标，那么大家都在集市等待。相对于有缓冲的阻塞队列（如
LinkedBlockingQueue）来说，SynchronousQueue 少了中间缓冲区（如仓库）的环节。如果有仓库，


```
第 7 章 JUC 容器类 | 371
```
生产者直接把商品批发给仓库，不需要关心仓库最终会将这些商品发给哪些消费者，由于仓库可以
中转部分商品，总体来说有仓库进行生产和消费的吞吐量高一些。反过来说，又因为仓库的引入，
使得商品从生产者到消费者中间增加了额外的交易环节，单个商品的及时响应性能可能会降低，所
以对单个消息的响应要求高的场景可以使用 SynchronousQueue。
声明一个 SynchronousQueue 有两种不同的方式：公平模式和非公平模式。公平模式的
SynchronousQueue 会采用公平锁，并配合一个 FIFO 队列来阻塞多余的生产者和消费者，从而体系整
体的公平策略。非公平模式（默认情况）的 SynchronousQueue 采用非公平锁，同时配合一个 LIFO
堆栈（TransferStack 内部实例）来管理多余的生产者和消费者。对于后一种模式，如果生产者和消
费者的处理速度有差距，则很容易出现线程饥渴的情况，即可能出现某些生产者或者消费者的数据
永远都得不到处理。
了解完阻塞队列的基本方法、主要类型之后，下面我们将分析阻塞队列中最为重要的实现类
ArrayBlockingQueue 的简单使用和实现原理。

###### 7. 4. 4 ArrayBlockingQueue 的基本使用

下面通过 ArrayBlockingQueue 队列实现一个生产者－消费者的案例，通过该案例简单了解其使
用的方式和方法。具体的代码在前面的生产者和消费者实现基础上进行迭代——Consumer（消费
者）和 Producer（生产者）通过 ArrayBlockingQueue 队列获取和添加元素。其中，消费者调用了 take ()
方法获取元素，当队列没有元素就阻塞；生产者调用 put () 方法添加元素，当队列满时就阻塞。通过
这种方式便实现生产者－消费者模式，比直接使用等待唤醒机制或者 Condition 条件队列更加简单。
基于 ArrayBlockingQueue 的生产者和消费者实现版本具体的 UML 类图如图 7 - 4 所示。

图 7 - 4 基于 ArrayBlockingQueue 的生产者和消费者 UML 类图
出于“分离变与不变”的原则，此版本的 Producer（生产者）、Consumer（消费者）的逻辑不
用变化，直接复用前面版本的代码即可。与前面版本不同的是，此版本 DataBuffer（共享数据区）
需要变化，使用一个 ArrayBlockingQueue 用于缓存数据，具体的代码如下：
packagecom. crazymakercircle. producerandcomsumer. store;
//省略 import
publicclassArrayBlockingQueuePetStore
{
publicstaticfinalintMAX_AMOUNT= 10 ;//数据区长度
//共享数据区，类定义


372 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
staticclassDataBuffer<T>
{
//使用阻塞队列保存数据
privateArrayBlockingQueue<T>dataList=newArrayBlockingQueue<>(MAX_AMOUNT);
//向数据区增加一个元素，委托给阻塞队列
publicvoidadd (Telement) throwsException
{
dataList.put (element); //直接委托
}
/**
*从数据区取出一个商品，委托给阻塞队列
*/
publicTfetch () throwsException
{
returndataList.take (); //直接委托
}
}
publicstaticvoidmain (String[]args) throwsInterruptedException
{
Print.cfo ("当前进程的 ID 是"+JvmUtil.getProcessID ());
System.setErr (System. out);
//共享数据区，实例对象
DataBuffer<IGoods>dataBuffer=newDataBuffer<>();
//生产者执行的操作
Callable<IGoods>produceAction=()->
{
//首先生成一个随机的商品
IGoodsgoods=Goods.produceOne ();
//将商品加上共享数据区
dataBuffer.add (goods);
returngoods;
};
//消费者执行的操作
Callable<IGoods>consumerAction=()->
{
//从 PetStore 获取商品
IGoodsgoods=null;
goods=dataBuffer.fetch ();
returngoods;
};
//同时并发执行的线程数
finalintTHREAD_TOTAL= 20 ;
//线程池，用于多线程模拟测试
ExecutorServicethreadPool=
Executors.newFixedThreadPool (THREAD_TOTAL);
//假定共 11 个线程，其中有 10 个消费者，但是只有 1 个生产者
finalintCONSUMER_TOTAL= 11 ;
finalintPRODUCE_TOTAL= 1 ;
for (inti= 0 ;i<PRODUCE_TOTAL; i++)
{
//生产者线程每生产一个商品，间隔 50 毫秒
threadPool.submit (newProducer (produceAction, 50 ));
}
for (inti= 0 ;i<CONSUMER_TOTAL; i++)
{
//消费者线程每消费一个商品，间隔 100 毫秒
```

```
第 7 章 JUC 容器类 | 373
```
```
threadPool.submit (newConsumer (consumerAction, 100 ));
}
}
}
运行程序，部分结果如下：
[pool- 1 - thread- 2 |Consumer. run]：第 11 轮消费：商品{ID= 1 ,名称=宠物- 1 ,价格= 8332. 0 }
[pool- 1 - thread- 1 |Producer. run]：第 0 轮生产：商品{ID= 1 ,名称=宠物- 1 ,价格= 8332. 0 }
[pool- 1 - thread- 1 |Producer. run]：第 1 轮生产：商品{ID= 2 ,名称=宠物粮食- 1 ,价格= 82. 0 }
[pool- 1 - thread- 3 |Consumer. run]：第 11 轮消费：商品{ID= 2 ,名称=宠物粮食- 1 ,价格= 82. 0 }
[pool- 1 - thread- 1 |Producer. run]：第 2 轮生产：商品{ID= 3 ,名称=宠物衣服- 1 ,价格= 92. 0 }
[pool- 1 - thread- 4 |Consumer. run]：第 12 轮消费：商品{ID= 3 ,名称=宠物衣服- 1 ,价格= 92. 0 }
[pool- 1 - thread- 1 |Producer. run]：第 3 轮生产：商品{ID= 4 ,名称=宠物- 2 ,价格= 3234. 0 }
[pool- 1 - thread- 5 |Consumer. run]：第 13 轮消费：商品{ID= 4 ,名称=宠物- 2 ,价格= 3234. 0 }
```
###### 7. 4. 5 ArrayBlockingQueue 构造器和成员

接下来，开始介绍 ArrayBlockingQueue 构造器和成员。ArrayBlockingQueue 中的元素访问存在
公平访问与非公平访问的两种方式，所以 ArrayBlockingQueue 可以分别作为公平队列和非公平队列
使用：

1 ）对于公平队列，被阻塞的线程可以按照阻塞的先后顺序访问队列，即先阻塞的线程先访问
队列。
2 ）对于非公平队列，当队列可用时，阻塞的线程将进入争夺访问资源的竞争中，也就是说谁
先抢到谁就执行，没有固定的先后顺序。

1 .ArrayBlockingQueue 构造方法
创建公平与非公平阻塞队列的代码如下：
//默认非公平阻塞队列
ArrayBlockingQueuequeue=newArrayBlockingQueue (capacity);
//公平阻塞队列
ArrayBlockingQueuequeue 1 =newArrayBlockingQueue (capacity, true);
ArrayBlockingQueue 的两个构造器的源码如下：
//只带一个 capacity 参数的构造器
publicArrayBlockingQueue (intcapacity){
this (capacity, false);
}
//带两个参数的构造器
publicArrayBlockingQueue (intcapacity, booleanfair){
if (capacity<= 0 )
thrownewIllegalArgumentException ();
this. items=newObject[capacity];
lock=newReentrantLock (fair); //根据 fair 参数构造公平锁/获取非公平锁
notEmpty=lock.newCondition (); //有元素加入，队列为非空
notFull= lock.newCondition (); //有元素被取出，队列为未满
}
ArrayBlockingQueue 内部的阻塞队列是通过重入锁 ReentrantLock 和 Condition 条件队列实现的，
接下来看看其内部的成员变量。


374 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

2 .ArrayBlockingQueue 内部的成员变量
ArrayBlockingQueue 是一个基于数组（Array）实现的有界阻塞队列，内部成员变量如下：
publicclassArrayBlockingQueue<E>extendsAbstractQueue<E>
implementsBlockingQueue<E>, java. io. Serializable{
/**存储数据的数组*/
finalObject[]items;
/**获取、删除元素的索引，主要用于 take、poll、peek、remove 方法*/
inttakeIndex;
/**添加元素的索引，主要用于 put、offer、add 方法*/
intputIndex;
/**队列元素的个数*/
intcount;
/**控制并发访问的显式锁*/
finalReentrantLocklock;
/**notEmpty 条件对象，用于通知 take 线程（消费队列），可执行删除操作*/
privatefinalConditionnotEmpty;
/**notFull 条件对象，用于通知 put 线程（生产队列），可执行添加操作*/
privatefinalConditionnotFull;
/**
迭代器
*/
transientItrsitrs=null;
}
ArrayBlockingQueue 内部是通过数组对象 items 来存储所有的数据的，通过 ReentrantLock 类型的
成员 lock 控制添加线程与删除线程的并发访问。ArrayBlockingQueue 使用等待条件对象 notEmpty 成
员来存放或唤醒被阻塞的消费（take）线程，当数组对象 items 有元素时，告诉 take 线程可以执行删
除操作。同理，ArrayBlockingQueue 使用等待条件对象 notFull 成员来存放或唤醒被阻塞的生产（put）
线程，当队列未满时，告诉 put 线程可以执行添加元素的操作。
ArrayBlockingQueue 的 takeIndex 成员为消费（或删除元素）的索引，标识的是下一个方法（take、
poll、peek、remove）被调用时获取数组元素的位置。putIndex 成员为生产（或添加元素）的索引，
代表下一种方法（put、offer、add）被调用时元素添加到数组中的位置。takeIndex 和 putIndex 成员
的图示如图 7 - 5 所示。

```
图 7 - 5 ArrayBlockingQueue 的 takeIndex 和 putIndex 成员
```

```
第 7 章 JUC 容器类 | 375
```
###### 7. 4. 6 非阻塞式添加元素：add ()、offer () 方法的原理

首先来看非阻塞式添加元素。在队列满而不能添加元素时，非阻塞式添加元素的方法会立即
返回，所以其执行线程不会被阻塞。非阻塞式添加元素的方法有 add () 方法和 offer () 方法。

1 .add () 方法的实现
publicbooleanadd (Ee){
if (offer (e))
returntrue;
else
thrownewIllegalStateException ("Queuefull");
}
从源码可以看出，add () 方法间接调用了 offer () 方法，如果 offer () 方法添加失败，那么 add () 将抛
出 IllegalStateException 异常，如果 offer () 方法添加成功，那么 add () 返回 true。

2 .offer () 方法的实现
offer () 方法根据数组是否满了，分两种场景的进行操作：
1 ）如果数组满了，就直接释放锁，然后返回 false。
2 ）如果数组没满，就将元素入队（加入数组），然后返回 true。
//offer 方法
publicbooleanoffer (Ee){
checkNotNull (e); //检查元素是否为 null
finalReentrantLocklock=this. lock;
lock.lock (); //加锁
try{
if (count==items. length) //判断数组是否已满
returnfalse;
else{
enqueue (e); //添加元素到队列
returntrue;
}
}finally{
lock.unlock ();
}
}
add () 方法和 offer () 方法的实现比较简单，需要特别注意的是 offer () 调用了 enqueue (Ex) 元素入队
方法。

```
3 .enqueue () 方法的实现
//入队操作
privatevoidenqueue (Ex){
//获取当前数组
finalObject[]items=this. items;
//通过 putIndex 索引对数组进行赋值
items[putIndex]=x;
//索引自增，如果已经是最后一个位置，重新设置 putIndex= 0
if (++putIndex==items. length)
putIndex= 0 ;
count++;//队列中元素数量加 1
//唤醒调用 take () 方法的线程，执行元素获取操作
```

376 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

notEmpty.signal ();
}
首先，由于进入 enqueue () 方法意味着数组没满，因此 enqueue () 方法可以通过 putIndex 索引直接
将元素添加到数组 items 中，然后调整 putIndex 索引值。这里大家可能会疑惑：当 putIndex 索引大小
等于数组长度时，为什么需要将 putIndex 重新设置为 0 呢？这是因为获取元素时总是在队列头部
（takeIndex 索引）操作，添加元素从中在队列尾部（putIndex 索引）操作，而 ArrayBlockingQueue
将内部数组作为环形队列使用，所以在更新后的索引值与数组长度相等时需要进行校正，下一个值
就需要从数组的第一个元素（索引值 0 ）开始操作，具体如图 7 - 6 所示。
其次，enqueue () 完成尾部的插入后，将自己的元素个数成员 count+ 1 。最后，enqueue () 通过调
用 notFull.notEmpty () 唤醒一个消费（或删除）线程。

```
图 7 - 6 当索引值等于数组长度 items. length 时需要校正为 0
```
###### 7. 4. 7 阻塞式添加元素：put () 方法的原理

首先来看阻塞式添加元素。在队列满而不能添加元素时，执行添加元素的线程会被阻塞。put ()
方法是一个阻塞的方法，如果队列元素已满，那么当前线程会被加入 notFull 条件对象的等待队列中，
直到队列有空位置才会被唤醒执行添加操作。但如果队列没有满，就直接调用 enqueue (e) 方法将元
素加入到数组队列中。
//put () 方法，阻塞时可中断
publicvoidput (Ee) throwsInterruptedException{
checkNotNull (e);
finalReentrantLocklock=this. lock;
lock.lockInterruptibly ();//该方法可中断
try{
//当队列元素个数与数组长度相等时，无法添加元素
while (count==items. length)
//将当前调用线程挂起，添加到 notFull 条件队列中，等待被唤醒
notFull.await ();
enqueue (e);//如果队列没有满，就直接添加
}finally{
lock.unlock ();
}
}


```
第 7 章 JUC 容器类 | 377
```
总结一下 put () 方法的添加操作流程。
1 ）获取 putLock 锁。
2 ）如果队列已满，就被阻塞，put 线程进入 notFull 的等待队列中排队，等待被唤醒。
3 ）如果队列未满，元素通过 enqueue () 方法入队。
4 ）释放 putLock 锁。
当队列已满时，那么新到来的 put 线程将被添加到 notFull 的条件队列中进行阻塞等待，具体如
图 7 - 7 所示。

图 7 - 7 队列满时 put 线程加入 notFull 等待队列示意图
另外，有移除线程执行移除操作，之前满了的数组现在有空余的位置了，移除成功之后会从
notFull 的条件队列中唤醒一个 put 线程，执行添加元素的操作，如图 7 - 8 所示。

图 7 - 8 队列元素被移除时 notFull 等待队列的头部线程被唤醒
至此，三个添加方法 put ()、offer ()、add () 都分析完毕，其中 offer ()、add () 在正常情况下都是无阻塞
添加的，而 put () 方法是阻塞添加的。阻塞添加的原理是：当队列满时通过条件对象 notFull 来阻塞当前调
用 put () 方法的线程，直到线程又再次被唤醒执行。谁来唤醒呢？这就涉及 dequeue () 元素出队方法。

```
注意，被 put () 阻塞的线程是可以中断的，或者说 put () 操作在阻塞时是可以中
断的。
```

378 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

###### 7. 4. 8 非阻塞式删除元素：poll () 方法的原理

在队列空而不能删除元素时，非阻塞式删除元素的方法会立即返回，所以其执行线程不会被
阻塞。非阻塞式删除元素的方法有 poll () 方法。

1 .poll () 方法的实现
publicEpoll (){
finalReentrantLocklock=this. lock;
lock.lock ();
try{
//判断队列是否为 null，不为 null 执行 dequeue () 方法，否则返回 null
return (count== 0 )? null: dequeue ();
}finally{
lock.unlock ();
}
}
poll () 方法删除获取此队列的队首元素，若队列为空，则立即返回 null。poll () 方法的实现比较
简单，其具体的删除操作委托给了 dequeue (Ex) 元素出队方法。
2 .dequeue () 方法的实现
//删除队列的队首元素并返回
privateEdequeue (){
//拿到当前数组的数据
finalObject[]items=this. items;
@SuppressWarnings ("unchecked")
//获取要删除的对象
Ex=(E) items[takeIndex];
//清空位置：将数组中的 takeIndex 索引位置设置为 null
items[takeIndex]=null;
//takeIndex 索引加 1 并判断是否与数组长度相等，
//如果相等就说明已到尽头，恢复为 0
if (++takeIndex==items. length)
takeIndex= 0 ;
count--;//元素个数减 1
if (itrs!=null)
itrs.elementDequeued ();//同时更新迭代器中的元素数据
//删除了元素说明队列有空位，唤醒 notFull 条件等待队列中的 put 线程，执行添加操作
notFull.signal ();
returnx;
}
以上对 dequeue () 代码的注释很清晰，大致分为三步：
1 ）进入 dequeue () 方法，意味着 takeIndex 位置有元素可以删除，反过来说，如果 takeIndex 位置
没有元素，就不会进入此方法。所以，第一步是拿到 takeIndex 位置的元素。
2 ）将 takeIndex 位置后移（自增），移动到下一个位置，无论一个位置有没有元素都没有关系，
总之移动之后的 takeIndex 新位置会是下一轮删除元素的位置。
3 ）如果 takeIndex 自增之后值为 items. length，说明 takeIndex 的索引已到数组尽头，就将其值校
正为 0 ，表示下一次从队列头部开始删除元素，达到环形队列的效果。
4 ）删除了元素说明队列有空位，唤醒 notFull 条件等待队列中的一个 put 线程，执行添加操作。

###### 7. 4. 9 阻塞式删除元素：take () 方法的原理

```
take () 方法是一个可阻塞、可中断的删除方法，主要做了两件事：
```

```
第 7 章 JUC 容器类 | 379
```
1 ）如果队列没有数据，就将线程加入到 notEmpty 等待队列并阻塞线程，一直到有生产者插入
数据后通过 notEmpty 发出一个消息，notEmpty 将从其等待队列唤醒一个消费（或者删除）节点，同
时启动该消费线程。
2 ）如果队列有数据，通过 dequeue () 执行元素的删除（或消费）操作。
//从队列头部移除元素，队列没有元素就阻塞，可中断
publicEtake () throwsInterruptedException{
finalReentrantLocklock=this. lock;
lock.lockInterruptibly ();//中断
try{
//如果队列没有元素
while (count== 0 )
//执行阻塞操作
notEmpty.await ();
returndequeue ();//如果队列有元素执行删除操作
}finally{
lock.unlock ();
}
}
take () 方法其实很简单，有就删除，没有就阻塞。如果队列没有数据，就将线程加入 notEmpty
条件队列等待，如图 7 - 9 所示。

图 7 - 9 队列空时 take 线程被阻塞
如果有新的 put 线程添加了数据，那么 put 操作将会唤醒一个处于阻塞状态的 take 线程其执行消
费（或删除）操作，如图 7 - 10 所示。

```
图 7 - 10 队列非空时唤醒 notEmpty 等待队列头部线程
```
```
队列非空，notEmpty 等待队列的头部线程被唤醒
```

380 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
注意，被 take () 阻塞的线程是可以中断的，或者说 take 操作在阻塞时是可以中
断的。
```
###### 7. 4. 10 peek () 直接返回当前队列的队首元素

peek () 方法从 takeIndex（队列头部位置）直接就可以获取到最早被添加的元素，所以效率是比
较高的，如果不存在就返回 null。
publicEpeek (){
finalReentrantLocklock=this. lock;
lock.lock ();
try{
//直接返回当前队列的队首元素，但不删除
returnitemAt (takeIndex);//nullwhenqueueisempty
}finally{
lock.unlock ();
}
}
finalEitemAt (inti){
return (E) items[i];
}

#### 7. 5 ConcurrentHashMap

ConcurrentHashMap 是一个常用的高并发容器类，也是一种线程安全的哈希表。Java 7 以及之
前版本中的 ConcurrentHashMap 使用 Segment（分段锁）技术将数据分成一段一段存储，然后给每一
段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访
问，能够实现真正的并发访问。Java 8 对其内部的存储结构进行了优化，使之在性能上有了更进一
步的提升。
ConcurrentHashMap 和同步容器 HashTable 的主要区别在锁的类型和粒度上：HashTable 实现同
步是利用 synchronized 关键字进行锁定的，其实是针对整张哈希表进行锁定的，即每次锁住整张表
让线程独占，虽然解决了线程安全问题，但是造成了巨大的资源浪费。

###### 7. 5. 1 HashMap 和 HashTable 的问题

基础容器 HashMap 是线程不安全的，在多线程环境下，使用 HashMap 进行 put 操作时，可能会
引起死循环，导致 CPU 利用率飙升甚至接近 100 %，所以在高并发情况下是不能使用 HashMap 的。
于是 JDK 提供了一个线程安全的 Map——HashTable，HashTable 虽然线程安全，但效率低下。
HashTable 和 HashMap 的实现原理几乎一样，区别有两点：

1 ）HashTable 不允许 key 和 value 为 null。
2 ）HashTable 使用 synchronized 来保证线程安全，包含 get ()/put () 在内的所有相关需要进行同步
执行的方法都加上了 synchronized 关键字，以锁定这个哈希表。

```
HashTable 线程安全策略的代价非常大，这相当于给整个哈希表加了一把大锁。当一个线程访
```

```
第 7 章 JUC 容器类 | 381
```
问 HashTable 的同步方法时，其他访问 HashTable 同步方法的线程就会进入阻塞或轮询状态。如有一
个线程在使用 put () 方法添加元素，则其他线程不但不能调用 put () 方法添加元素，而且不能调用 get ()
方法来获取元素，相当于将所有的操作串行化。所以，HashTable 的效率非常低下。

###### 7. 5. 2 JDK 1. 7 版本 ConcurrentHashMap 的结构

JDK 1. 7 的 ConcurrentHashMap 的锁机制是基于粒度更小的分段锁，分段锁也是提升多并发程序
性能的重要手段之一，和 LongAdder 一样，属于热点分散型的削峰手段。
分段锁其实是一种锁的设计，并不是具体的一种锁，对于 ConcurrentHashMap 而言，分段锁技
术将 Key 分成一个一个小 Segment 的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其
中一个段数据的时候，其他段的数据也能被其他线程访问，能够实现真正的并发访问。

1 .JDK 1. 7 版本 ConcurrentHashMap 的组合结构
ConcurrentHashMap 的内部结构的层次关系为 ConcurrentHashMap→Segment→HashEntry。这样
设计的好处在于，每次访问的时候只需要将一个 Segment 锁定，而不需要将整个 Map 类型集合都进
行锁定。ConcurrentHashMap 的组合结构如图 7 - 11 所示。

图 7 - 11 ConcurrentHashMap 的组合结构
JDK 1. 7 中的 ConcurrentHashMap 采用了 Segment 分段锁的方式实现。一个 ConcurrentHashMap 中
包含一个 Segment 数组，一个 Segment 中包含一个 HashEntry 数组，每个元素是一个链表结构（一个
哈希表的桶）。

2 .ConcurrentHashMap 实例
一个 ConcurrentHashMap 实例的内部结构如图 7 - 12 所示。
ConcurrentHashMap 的内部结构的组成部分具体如下：
（ 1 ）HashEntry
HashEntry 结构用于存储“Key-Value 对”（即“键-值对”）数据，以及存储了其后驱节点的
指针。


382 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

图 7 - 12 ConcurrentHashMap 的内部结构
（ 2 ）Segment
ConcurrentHashMap 中的一个段称为 Segment，Segment 继承了 ReentrantLock，所以一个段又是
一个 ReentrantLock。Segment 内部拥有一个 HashEntry 数组类型的成员 table，数组中的每个元素又是
一个链表，这个由 HashEntry 链接起来的链表对应于一个哈希表的桶，也就是说，table 的一个元素对
应于哈希表的一个桶。Segment 在 ConcurrentHashMap 中扮演锁的角色，每个 Segment 守护着一个
HashEntry 数组中的元素，当对 HashEntry 数组的数据进行修改时，必须首先获得它对应的 Segment 锁。

（ 3 ）ConcurrentHashMap
ConcurrentHashMap 在默认并发级别时会创建包含 16 个 Segment 对象的数组，每个 Segment 大约
守护整个哈希表中桶总数的 1 / 16 ，其中第 N 个哈希桶由第 Nmod 16 个锁来保护。假设使用合理的哈
希算法使关键字能够均匀地分布，那么大约能使对锁的请求减少到原来的 1 / 16 。默认并发级别的情
况下，ConcurrentHashMap 支持多达 16 个并发的写入线程。

###### 7. 5. 3 JDK 1. 7 版本 ConcurrentHashMap 的核心原理

```
1 .ConcurrentHashMap 类
ConcurrentHashMap 类的核心源码如下：
publicclassConcurrentHashMap<K,V>extendsAbstractMap<K,V>
implementsConcurrentMap<K,V>, Serializable{
/**
*哈希映射表的默认初始容量为 16 ，即初始默认为 16 个桶
*在构造器中没有指定这个参数时，使用本参数
*/
staticfinalintDEFAULT_INITIAL_CAPACITY= 16 ;
/**
*哈希映射表的默认装载因子为 0. 75 ，该值是 table 中包含的 HashEntry 元素的个数与 table 数组长度的比值，
*当 table 中包含的 HashEntry 元素的个数超过了 table 数组的长度与装载因子的乘积时，将触发扩容操作
*如果哈希在构造器中没有指定这个参数时，使用本参数的值
*/
staticfinalfloatDEFAULT_LOAD_FACTOR= 0. 75 f;
//集合最大容量
staticfinalintMAXIMUM_CAPACITY= 1 << 30 ;
//分段锁的最小数量
```

```
第 7 章 JUC 容器类 | 383
```
staticfinalintMIN_SEGMENT_TABLE_CAPACITY= 2 ;
//分段锁的最大数量
staticfinalintMAX_SEGMENTS= 1 << 16 ;

//加锁前的重试次数
staticfinalintRETRIES_BEFORE_LOCK= 2 ;
/**
*哈希表的默认并发级别为 16 ，该值表示当前更新线程的估计数
*在构造器中没有指定这个参数时，使用本参数
*/
staticfinalintDEFAULT_CONCURRENCY_LEVEL= 16 ;
/**
*segments 的掩码值
*key 的哈希码的高位用来选择具体的 segment
*/
finalintsegmentMask;
/**
*偏移量
*/
finalintsegmentShift;
/**
*由 Segment 对象组成的数组
*/
finalSegment<K,V>[]segments;
/**
*创建一个带有指定初始容量、加载因子和并发级别的新的空映射
*/
publicConcurrentHashMap (intinitialCapacity,
floatloadFactor, intconcurrencyLevel){
if (! (loadFactor> 0 )||initialCapacity< 0 ||concurrencyLevel<= 0 )
thrownewIllegalArgumentException ();
if (concurrencyLevel>MAX_SEGMENTS)
concurrencyLevel=MAX_SEGMENTS;
//寻找最佳匹配参数（不小于给定参数的最接近的 2 次幂）
intsshift= 0 ;
intssize= 1 ;
while (ssize<concurrencyLevel){
++sshift;
ssize<<= 1 ;
}
segmentShift= 32 - sshift; //偏移量值
segmentMask=ssize- 1 ; //掩码值
this. segments=Segment.newArray (ssize); //创建数组
if (initialCapacity>MAXIMUM_CAPACITY)
initialCapacity=MAXIMUM_CAPACITY;
intc=initialCapacity/ssize;
if (c*ssize<initialCapacity) ++c;
intcap= 1 ;
while (cap<c) cap<<= 1 ;
//依次遍历每个数组元素
for (inti= 0 ;i<this. segments. length;++i)
//初始化每个数组元素引用的 Segment 对象
this. segments[i]=newSegment<K,V>(cap, loadFactor);
}


384 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

/**
*创建一个带有默认初始容量 ( 16 )、默认加载因子 ( 0. 75 ) 和默认并发级别 ( 16 ) 的
*空哈希映射表
*/
publicConcurrentHashMap (){
//使用三个默认参数调用上面重载的构造器来创建空哈希映射表
this (DEFAULT_INITIAL_CAPACITY, DEFAULT_LOAD_FACTOR, DEFAULT_CONCURRENCY_LEVEL);
}
}
2 .Segment 类
每个 Segment 实例用来守护其内部 table 成员对象，table 是一个由 HashEntry 实例数组，其每个元
素就是哈希映射表的一个桶。Segment 类的代码具体如下：
staticfinalclassSegment<K,V>extendsReentrantLockimplementsSerializable{
/**
*在本 segment 范围内包含的 HashEntry 元素的个数
*该变量被声明为 volatile 型
*/
transientvolatileintcount;
/**
*table 被更新的次数
*/
transientintmodCount;
/**
*当 table 中包含的 HashEntry 元素的个数超过本变量值时，触发 table 的再哈希
*/
transientintthreshold;
/**
*table 是由 HashEntry 实例组成的数组
*如果 HashEntry 实例的哈希值发生碰撞，碰撞的 HashEntry 实例就以链表的形式链接成一个链表
*table 数组的数组成员代表哈希映射表的一个桶
*每个 table 守护整个 ConcurrentHashMap 包含桶总数的一部分
*如果并发级别为 16 ，table 则守护 ConcurrentHashMap 包含的桶总数的 1 / 16
*/
transientvolatileHashEntry<K,V>[]table;
/**
*装载因子
*/
finalfloatloadFactor;
Segment (intinitialCapacity, floatlf){
loadFactor=lf;
setTable (HashEntry.<K,V>newArray (initialCapacity));
}
/**
*设置 table 引用到这个新生成的 HashEntry 数组
*只能在持有锁或构造器中调用本方法
*/
voidsetTable (HashEntry<K,V>[]newTable){
//计算临界阈值为新数组的长度与装载因子的乘积
threshold=(int)(newTable. length*loadFactor);
table=newTable;
}
/**
*根据 key 的哈希值，找到 table 中对应的那个桶（table 数组的某个数组成员）


```
第 7 章 JUC 容器类 | 385
```
*/
HashEntry<K,V>getFirst (inthash){
HashEntry<K,V>[]tab=table;
//把哈希值与 table 数组长度减 1 的值相“与”得到哈希值对应的 table 数组的下标
//然后返回 table 数组中此下标对应的 HashEntry 元素
returntab[hash&(tab. length- 1 )];
}
}
每个 Segment 实例都有一个 count 来表示本该分段包含的 HashEntry“Key-Value 对”总数。具体
来说，count 变量是一个计数器，它表示每个 Segment 实例管理的 table 数组（若干个 HashEntry 组成的
链表）包含的 HashEntry 实例的个数。之所以在每个 Segment 实例中包含一个计数器，而不是在
ConcurrentHashMap 中使用全局的计数器，是为了避免出现“全局热点”而影响并发性。
插入三个节点后 Segment 的结构示意图如图 7 - 13 所示。

图 7 - 13 含有三个 HashEntry 的 Segment 的结构示意图
3 .HashEntry
HashEntry 用来封装哈希映射表中的“Key-Value 对”。在 HashEntry 类中，key、hash 和 next 字
段都被声明为 final 型，value 字段被声明为 volatile 型。
staticfinalclassHashEntry<K,V>{
finalKkey; //声明 key 为 final 型
finalinthash; //声明 hash 值为 final 型
volatileVvalue; //声明 value 为 volatile 型
finalHashEntry<K,V>next; //声明 next 为 final 型
HashEntry (Kkey, inthash, HashEntry<K,V>next, Vvalue){
this. key=key;
this. hash=hash;
this. next=next;
this. value=value;
}
}
在 ConcurrentHashMap 中，哈希时如果产生“碰撞”，将采用“分离链接法”来处理：把“碰
撞”的 HashEntry 对象链接成一个链表，形成一个桶。由于 HashEntry 的 next 字段为 final 型，因此新
节点只能在链表的表头处插入。在一个空桶中依次插入 A、B、C 三个 HashEntry 对象后的结构图如
图 7 - 14 所示。

```
由于只能在表头插入，因此链表中节点的顺序和插入的顺序相反。
```

386 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
图 7 - 14 在空桶插入三个元素之后的效果
```
4 .ConcurrentHashMap 的 get 操作
从结构上我们可以看到 Segment 类似于一个小型的 HashMap，ConcurrentHashMap 就是 HashMap
集合。接下来看一下 get 操作：
//根据 key 获取 value
publicVget (Objectkey){
Segment<K,V>s;
HashEntry<K,V>[]tab;
//使用哈希函数计算哈希码
inth=hash (key);
//根据哈希码计算分段锁的索引
longu=(((h>>>segmentShift)&segmentMask)<<SSHIFT)+SBASE;
//根据索引 u 获取分段锁，然后拿到其 table
if ((s=(Segment<K,V>) UNSAFE.getObjectVolatile (segments, u))!=null &&(tab
=s.table)!=null){
//根据哈希码获取链表队首节点，再对链表进行遍历
for (HashEntry<K,V>e=
(HashEntry<K,V>) UNSAFE.getObjectVolatile (tab,
((long)(((tab. length- 1 )&h))<<TSHIFT)+TBASE);
e!=null; e=e.next){
Kk;
//根据 key 和 hash 找到对应元素后返回 value 值
if ((k=e.key)==key||(e.hash==h&&key.equals (k))){
returne. value;
}
}
}
returnnull;
}
以上 get () 方法通过 UnSafe 的 getObjectVolatile () 方法来读取数组中的元素。为什么要这样做？虽
然 Segment 对象持有的 HashEntry 数组引用是 volatile 类型，但是数组内的元素引用不是 volatile 类型，
因此多线程对数组元素的修改是不安全的，可能会在数组中读取到尚未构造完成的元素对象。get ()
方法通过 UnSafe 的 getObjectVolatile () 方法来保证元素的读取安全，调用 getObjectVolatile () 方法读取
数组元素需要先获得元素在数组中的偏移量，在这里，get () 方法根据哈希码计算出偏移量为 u，然
后通过偏移量 u 来尝试从 segments 数组中读取分段锁。
由于分段锁数组在创建时没进行初始化，可能读出来一个空值，因此需要先进行判断。在确
定分段锁和它内部的哈希表都不为空之后，再通过哈希码读取 HashEntry 数组的元素，根据上面的
源码可以看到，这时获得的是链表的队首节点。之后再从头到尾对链表进行遍历查找，如果找到对
应的值就将其返回，否则就返回 null。以上就是整个查找元素的过程。


```
第 7 章 JUC 容器类 | 387
```
get () 方法之所以不需要加锁的原因比较简单，get () 为只读操作，不会改动 Map 的数据结构，所
以在操作过程中，只需保证涉及读取数据的属性为线程可见即可，也就是使用 volatile 修饰涉及的成
员变量。

5 .ConcurrentHashMap 的 put () 操作
ConcurrentHashMap 中有两个添加“Key-Value 对”的方法，通过 put () 方法添加时，若存在
“Key-Value 对”，则会进行覆盖，通过 putIfAbsent () 方法添加时，若存在“Key-Value 对”，则不进行
覆盖。这两个方法都是调用分段锁的 put () 方法来完成操作的，只是传入的最后一个参数不同而已。
//向集合添加“Key-Value 对”(若存在则替换)
@SuppressWarnings ("unchecked")
publicVput (Kkey, Vvalue){
Segment<K,V>s;
//传入的 value 不能为空
if (value==null) thrownewNullPointerException ();
//使用哈希函数计算哈希码
inthash=hash (key);
//根据哈希码计算分段锁的下标
intj=(hash>>>segmentShift)&segmentMask;
//根据下标尝试获取分段锁
if ((s=(Segment<K,V>) UNSAFE.getObject (
segments, (j<<SSHIFT)+SBASE))==null){
//获得的分段锁为空就去构造一个
s=ensureSegment (j);
}
//调用分段锁的 put () 方法
returns.put (key, hash, value, false);
}
在上面的代码中，我们可以看到首先是根据 key 的哈希码来计算分段锁在数组中的下标，然后
根据下标使用 UnSafe 类 getObject () 方法来读取分段锁。由于在构造 ConcurrentHashMap 时没有对
Segment 数组中的元素初始化，因此可能读到一个空值，这时会先通过 ensureSegment () 方法新建一个
分段锁。获取到分段锁之后再调用它的 put () 方法完成添加操作。下面我们来看看具体是怎样操作的。

```
6 .分段锁的 put () 方法
对 ConcurrentHashMap 容器进行结构性修改的操作时需要加锁，put () 操作加锁的过程如下：
//添加“键-值”对
finalVput (Kkey, inthash, Vvalue, booleanonlyIfAbsent){
//尝试获取锁，若失败则进行自旋
HashEntry<K,V>node=tryLock ()? null: scanAndLockForPut (key, hash, value);
VoldValue;
try{
HashEntry<K,V>[]tab=table;
//计算元素在数组中的下标
intindex=(tab. length- 1 )&hash;
//根据下标获取链表头节点
HashEntry<K,V>first=entryAt (tab, index);
for (HashEntry<K,V>e=first;;){
//遍历链表寻找该元素，若找到则进行替换
```

388 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

if (e!=null){
Kk;
if ((k=e.key)==key||
(e.hash==hash&&key.equals (k))){
oldValue=e.value;
//根据参数决定是否替换旧值
if (! onlyIfAbsent){
e.value=value;
++modCount;
}
break;
}
e=e.next;
}else{
//若没找到则在链表添加一个节点
//将 node 节点插入链表头部
if (node!=null){
node.setNext (first);
}else{
node=newHashEntry<K,V>(hash, key, value, first);
}
//插入节点后将元素总是加 1
intc=count+ 1 ;
//元素超过阈值则进行扩容
if (c>threshold&&tab. length<MAXIMUM_CAPACITY){
rehash (node);
}else{
//否则就将哈希表指定下标替换为 node 节点
setEntryAt (tab, index, node);
}
++modCount;
count=c;
oldValue=null;
break;
}
}
}finally{
unlock ();
}
returnoldValue;
}
为了保证线程安全，分段锁中的 put 操作是需要进行加锁的，所以线程一开始就会获取锁，若
获取成功则继续执行，若获取失败则调用 scanAndLockForPut () 方法进行自旋，在自旋过程中会先去
扫描哈希表查找指定的 key，如果 key 不存在就会新建一个 HashEntry 返回，这样在获取到锁之后就
不必再去新建了，为的是在等待锁的过程中顺便做一些事情，不至于白白浪费时间，可见笔者的良
苦用心。
线程在成功获取到锁之后会根据计算到的下标获取指定下标的元素。此时获取到的是链表的
队首节点，如果队首节点不为空就对链表进行遍历查找，找到之后再根据 onlyIfAbsent 参数的值决
定是否进行替换。
如果遍历时没找到队首节点，就会新建一个 HashEntry 节点作为队首节点。在向链表添加元素


```
第 7 章 JUC 容器类 | 389
```
之后，检查元素总数是否超过阀值，如果超过就调用 rehash 进行扩容，没超过的话就直接将数组对
应下标的元素引用指向新添加的节点。setEntryAt () 方法内部是通过调用 UnSafe 的 putOrderedObject ()
方法来更改数组元素引用的，这样就保证了其他线程在读取时可以读到最新的值。
scanAndLockForPut () 方法的实现也比较简单，循环调用 tryLock ()，多次获取，如果循环次数
retries 次数大于事先设置好的 MAX_SCAN_RETRIES，就执行 lock () 方法，此方法会阻塞等待，一直
到成功拿到 Segment 锁为止。MAX_SCAN_RETRIES 的次数如下：
//循环次数，单核为 1 ，多核为 64
staticfinalintMAX_SCAN_RETRIES=
Runtime.getRuntime (). availableProcessors ()> 1? 64 : 1 ;

###### 7. 5. 4 JDK 1. 8 版本 ConcurrentHashMap 的结构

在 JDK 1. 8 中，ConcurrentHashMap 已经抛弃了 Segment 分段锁机制，存储结构采用数组+链表或
者红黑树的组合方式，利用 CAS+Synchronized 来保证并发更新的安全。

1 .JDK 1. 8 版本 ConcurrentHashMap 的组合结构
虽然 JDK 1. 8 对 ConcurrentHashMap 的内部结构进行了改进，改采用数组+链表或红黑树来实现，
但是从 Segment（分段锁）技术角度来说，其原理是类似的。
JDK 1. 7 的 ConcurrentHashMap 为了进行并发热点的分离，默认情况下将一个 table 分裂成 16 个小
的 table（Segment 表示），从而在 Segment 维度进行比较细粒度的并发控制。实际上，如果并发线程
多，这种粒度还是没有足够细。所以，JDK 1. 8 的 ConcurrentHashMap 将并发控制的粒度进一步细化，
也就是进一步进行并发热点的分离，将并发粒度细化到每一个桶。既然如此，比较粗粒度的 Segment
已经没有存在的必要，每一个桶已经变化成实质意义的 Segment，所以该结构直接被丢弃。
JDK 1. 7 的 ConcurrentHashMap 每一个桶都为链表结构，为了提升节点的访问性能，JDK 1. 8 引
入了红黑树的结构，当桶的节点数超过一定的阈值（默认为 64 ）时，JDK 1. 8 将链表结构自动转换
成红黑树的结构，可以理解为将链式桶转换成树状桶。
ConcurrentHashMap 的内部结构的层次关系为 ConcurrentHashMap→链式桶/树状桶。这样设计的
好处在于，每次访问的时候只需对一个桶进行锁定, 而不需要将整个 Map 集合都进行粗粒度的锁定。

```
JDK 1. 8 的 ConcurrentHashMap 引入了红黑树的原因是：链表查询的时间复杂度为
O (n)，红黑树查询的时间复杂度为 O (log (n))，所以在节点比较多的情况下，使用红黑树可以
大大提升性能。
```
JDK 1. 8 版本 ConcurrentHashMap 的组合结构如图 7 - 15 所示。
链式桶是一个由 NODE 节点组成的链表。树状桶是一棵由 TreeNode 节点组成的红黑树，树的根
节点为 TreeBin 类型。

2 .Node
此结构为 ConcurrentHashMap 的核心内部类，它包装了“Key-Value 对”，所有插入
ConcurrentHashMap 的数据都包装在其中。


390 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

图 7 - 15 ConcurrentHashMap 的组合结构
3 .TreeBin（Node 子类）
当数据链表（链式桶）长度大于 8 时，会转换为 TreeBin（树状桶）。TreeBin 作为根节点，可
以认为是红黑树对象。在 ConcurrentHashMap 的 table“数组”中，存放就是 TreeBin 对象，而不是
TreeNode 对象。

```
4 .TreeNode
树状桶的节点类。
5 .JDK 1. 8 版本 ConcurrentHashMap 内部结构示例
一个 JDK 1. 8 版本 ConcurrentHashMap 实例的内部结构示例如图 7 - 16 所示。
```
```
图 7 - 16 一个 JDK 1. 8 版本 ConcurrentHashMap 实例的内部结构
```
###### 7. 5. 5 JDK 1. 8 版本 ConcurrentHashMap 的核心原理

JDK 1. 8 版本的 ConcurrentHashMap 中通过一个 Node<K,V>[]数组 table 来保存添加到哈希表中的
桶，而在同一个 Bucket 位置是通过链表和红黑树的形式来保存的。但是数组 table 是懒加载的，只有
在第一次添加元素的时候才会初始化。


```
第 7 章 JUC 容器类 | 391
```
1 .JDK 1. 8 版本 ConcurrentHashMap 的主要成员属性
JDK 1. 8 版本 ConcurrentHashMap 的主要成员属性大致如下：
publicclassConcurrentHashMap<K,V>extendsAbstractMap<K,V>
implementsConcurrentMap<K,V>, Serializable{
privatestaticfinalintMAXIMUM_CAPACITY= 1 << 30 ;
privatestaticfinalintDEFAULT_CAPACITY= 16 ;
staticfinalintTREEIFY_THRESHOLD= 8 ;
staticfinalintUNTREEIFY_THRESHOLD= 6 ;
staticfinalintMIN_TREEIFY_CAPACITY= 64 ;
//常量：表示正在转移
staticfinalintMOVED =- 1 ;
//常量：表示已经转换成树
staticfinalintTREEBIN =- 2 ;
//常量：hashfortransientreservations
staticfinalintRESERVED =- 3 ;
//常量：usablebitsofnormalnodehash
staticfinalintHASH_BITS= 0 x 7 fffffff;
//数组，用来保存元素
transientvolatileNode<K,V>[]table;
//转移时用的数组
privatetransientvolatileNode<K,V>[]nextTable;
/**
*用来控制表初始化和扩容的控制属性
*/
privatetransientvolatileintsizeCtl;
//省略其他
}
对以上清单中的重要属性，介绍如下：
（ 1 ）table
table 用于保存添加到哈希表中的桶。
（ 2 ）DEFAULT_CAPACITY
table 的默认长度。默认初期长度为 16 ，在第一次添加元素时，会将 table 初始化成 16 个元素的数组。
（ 3 ）TREEIFY_THRESHOLD
链式桶转成红黑树桶的阈值。在增加“Key-Value 对”时，当链表长度大于该值时，将链表转
换成红黑树。
#ConcurrentHashMap所定义的常量值
staticfinalintTREEIFY_THRESHOLD= 8 ;
（ 4 ）UNTREEIFY_THRESHOLD
红黑树桶还原回链式桶的阈值，也就是红黑树转为链表的阈值，当在容量变动时重新计算存
储位置后，当原有的红黑树内数量小于 6 时，将红黑树转换成链表。

（ 5 ）MIN_TREEIFY_CAPACITY
链式桶转成红黑树桶还有一个要求，table 的容量达到最小树形化容量的阈值，只有在当哈希
表中的 table 容量大于该值时，才允许树将链表转换成红黑树的操作。否则，尽管单个桶内的元素太
多，仍然选择直接扩容，而不是将桶树形化。
为了避免进行扩容、树形化选择的冲突，这个值不能小于 4 *TREEIFY_THRESHOLD。


392 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

#ConcurrentHashMap所定义的常量值
staticfinalintMIN_TREEIFY_CAPACITY= 64 ;
（ 6 ）sizeCtl
sizeCtl 用来控制 table 的初始化和扩容操作的过程，其值大致如下：
 ‒ 1 代表 table 正在初始化，其他线程应该交出 CPU 时间片。
 ‒N 表示有 N‒ 1 个线程正在进行扩容操作，严格来说，当其为负数时，只用到其低 16 位，如
果其低 16 位数值为 M，此时有 M‒ 1 个线程进行扩容。
 大于 0 分两种情况：如果 table 未初始化，sizeCtl 表示 table 需要初始化的大小；如果 table 初始
化完成，sizeCtl 表示 table 的容量，默认是 table 大小的 0. 75 倍。
涉及修改 sizeCtl 的方法有 5 个：
（ 1 ）initTable ()
初始化哈希表时，涉及 sizeCtl 的修改。
（ 2 ）addCount ()
增加容量时，涉及 sizeCtl 的修改。
（ 3 ）tryPresize ()
ConcurrentHashMap 扩容方法之一。
（ 4 ）transfer ()
table 数据转移到 nextTable。扩容操作的核心在于数据的转移，把旧数组中的数据迁移到新的
数组。ConcurrentHashMap 精华的部分是它可以利用多线程进行协同扩容，简单来说，它把 table 数
组当作多个线程之间共享的任务队列，然后通过维护一个指针来划分每个线程锁负责的区间，每个
线程通过区间逆向遍历来实现扩容，一个已经迁移完的 Bucket 会被替换为一个 ForwardingNode 节点，
标记当前 Bucket 已经被其他线程迁移完了。

（ 5 ）helpTransfer ()
ConcurrentHashMap 鬼斧神工，并发添加元素时，如果正在扩容，其他线程会帮助扩容，也就
是多线程扩容。
第一次添加元素时，默认初期长度为 16 ，当往 table 中继续添加元素时，通过哈希值跟数组长
度取余来决定放在数组的哪个 Bucket 位置，如果出现放在同一个位置时，就优先以链表的形式存放，
在同一个位置的个数又达到了 8 个以上，如果数组的长度还小于 64 时，就会扩容数组。如果数组的
长度大于等于 64 ，就会将该节点的链表转换成树。
通过扩容数组的方式来把这些节点给分散开，然后将这些元素复制到扩容后的新数组中，同
一个 Bucket 中的元素通过哈希值的数组长度位来重新确定位置，可能还是放在原来的位置，也可能
放到新的位置。而且，在扩容完成之后，如果之前某个节点是树，但是现在该节点的“Key-Value
对”数又小于等于 6 个，就会将该树转为链表。
什么时候扩容？当前容量超过阈值，也就是链表中元素个数超过默认设置（ 8 个）时，如果数
组 table 的大小还未超过 64 ，此时就进行数组的扩容，如果超过就将链表转化成红黑树。


```
第 7 章 JUC 容器类 | 393
```
```
2 .ConcurrentHashMap 类的内部类
桶的节点以内部类的形式定义，具体如下：
//桶的节点放在 table 中可以作为一个链式的桶
staticclassNode<K,V>implementsMap. Entry<K,V>{
finalinthash;
finalKkey;
volatileVval;
volatileNode<K,V>next;
}
//桶的树状节点
staticfinalclassTreeNode<K,V>extendsNode<K,V>{
TreeNode<K,V>parent; //red-blacktreelinks
TreeNode<K,V>left;
TreeNode<K,V>right;
TreeNode<K,V>prev; //neededtounlinknextupondeletion
booleanred;
}
//放在 table 中可以作为一个链式的桶
staticfinalclassTreeBin<K,V>extendsNode<K,V>{
TreeNode<K,V>root;
volatileTreeNode<K,V>first;
volatileThreadwaiter;
volatileintlockState;
}
```
###### 7. 5. 6 JDK 1. 8 版本 ConcurrentHashMap 的核心源码

```
这里介绍一下 JDK 1. 8 版本的 ConcurrentHashMap 的 put () 和 get () 方法。
1 .JDK 1. 8 版本 ConcurrentHashMap 的 put () 方法
下面来看 JDK 1. 8 版本 ConcurrentHashMap 的 put () 操作，具体的源码如下：
publicVput (Kkey, Vvalue){
returnputVal (key, value, false);
}
finalVputVal (Kkey, Vvalue, booleanonlyIfAbsent){
if (key==null||value==null) thrownewNullPointerException ();
inthash=spread (key.hashCode ());
intbinCount= 0 ;
//自旋：并发情况下，也可以保障安全添加成功
for (Node<K,V>[]tab=table;;){
Node<K,V>f; intn, i, fh;
if (tab==null||(n=tab. length)== 0 )
//第一次添加，先初始化 node 数组
tab=initTable ();
elseif ((f=tabAt (tab, i=(n- 1 )&hash))==null){
//计算出 table[i]无节点，创建节点
//使用 Unsafe. compareAndSwapObject 原子操作 table[i]位置
//如果为 null，就添加新建的 node 节点，跳出循环
//反之，再循环进入执行添加操作
if (casTabAt (tab, i, null, newNode<K,V>(hash, key, value, null)))
break;
}
elseif ((fh=f.hash)==MOVED)
//如果当前处于转移状态，返回新的 tab 内部表，然后进入循环执行添加操作
tab=helpTransfer (tab, f);
```

394 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

else{
//在链表或红黑树中追加节点
VoldVal=null;
//使用 synchronized 对 f 对象加锁
//f=tabAt (tab, i=(n- 1 )&hash)：table[i]的 node 对象 (桶)
//注意：这里没用 ReentrantLock，而是使用 synchronized 进行同步
//在争用不激烈的场景中，synchronized 的性能和 ReentrantLock 不相上下
synchronized (f){
if (tabAt (tab, i)==f){
//在链表上追加节点
if (fh>= 0 ){
binCount= 1 ;
for (Node<K,V>e=f;;++binCount){
Kek;
if (e.hash==hash&&
((ek=e.key)==key||
(ek!=null&&key.equals (ek)))){
oldVal=e.val;
if (! onlyIfAbsent)
e.val=value;
break;
}
Node<K,V>pred=e;
if ((e=e.next)==null){
pred. next=newNode<K,V>(hash, key, value, null);
break;
}
}
}
//在红黑树上追加节点
elseif (finstanceofTreeBin){
Node<K,V>p;
binCount= 2 ;
if ((p=((TreeBin<K,V>) f). putTreeVal (hash, key,
value))!=null){
oldVal=p.val;
if (! onlyIfAbsent)
p.val=value;
}
}
}
}
if (binCount!= 0 ){
//节点数大于临界值，转换成红黑树
if (binCount>=TREEIFY_THRESHOLD)
treeifyBin (tab, i);
if (oldVal!=null)
returnoldVal;
break;
}
}
}
addCount ( 1 L, binCount);
returnnull;
}
从 put () 源码可以看到，JDK 1. 8 版本在使用 CAS 自旋完成桶的设置时，使用 synchronized 内置锁
保证桶内并发操作的线程安全。尽管对同一个 Map 操作的线程争用会非常激烈，但是在同一个桶内


```
第 7 章 JUC 容器类 | 395
```
的线程争用通常不会很激烈，所以使用 CAS 自旋（简单轻量级锁）、synchronized 偏向锁或轻量级
锁不会降低 ConcurrentHashMap 的性能。为什么不用 ReentrantLock 显式锁呢？如果为每一个桶都创
建一个 ReentrantLock 实例，就会带来大量的内存消耗，反过来，使用 CAS 自旋（简单轻量级锁）、
synchronized 偏向锁或轻量级锁，内存消耗的增加会微乎其微。

```
2 .JDK 1. 8 版本 ConcurrentHashMap 的 get () 方法
最后，再来看 ConcurrentHashMap 的 get () 方法：
publicVget (Objectkey){
Node<K,V>[]tab; Node<K,V>e, p; intn, eh; Kek;
inth=spread (key.hashCode ());
if ((tab=table)!=null&&(n=tab. length)> 0 &&
//获取 table[i]的 node 元素
(e=tabAt (tab, (n- 1 )&h))!=null){
if ((eh=e.hash)==h){
if ((ek=e.key)==key||(ek!=null&&key.equals (ek)))
returne. val;
}
elseif (eh< 0 )
return (p=e.find (h, key))!=null?p.val: null;
while ((e=e.next)!=null){
if (e.hash==h&&
((ek=e.key)==key||(ek!=null&&key.equals (ek))))
returne. val;
}
}
returnnull;
}
//确保多线程可见，并且保证获取到的是内存中最新的 table[i]元素值
staticfinal<K,V>Node<K,V>tabAt (Node<K,V>[]tab, inti){
return (Node<K,V>)U.getObjectVolatile (tab, ((long) i<<ASHIFT)+ABASE);
}
get () 方法的源码也没有加锁操作，其大致的操作原理跟 JDK 1. 7 版本一样，这里就不赘述了。
```

# 第 8 章

## 高并发设计模式

在高并发场景下，常见的设计模式可能存在线程安全问题，比如传统的单例模式就是一个典
型。另外，为了充分发挥多核优势，高并发程序常常将大的任务分割成一些规模较小的任务，以便
各个击破、分而治之，这就出现了一些高并发场景下特有的设计模式，比如 ForkJoin 模式等。
本章介绍在高并发场景常用的几种模式：线程安全的单例模式、ForkJoin 模式、生产者－消费
者模式、Master-Worker 模式和 Future 模式。

#### 8. 1 线程安全的单例模式

单例模式是常见的一种设计模式，一般用于全局对象的管理，比如 XML 读写实例、系统配置
实例、任务调度实例、数据库连接池实例等。

###### 8. 1. 1 从饿汉式单例到懒汉式单例

按照单例对象被初始化的时机，单例模式一般分为懒汉式、饿汉式两种。饿汉式单例在类被
加载时就直接被初始化，具体的参考代码如下：
//简单的饿汉单例模式
publicclassSingleton 1
{
privateSingleton 1 (){}//私有构造器
//静态成员
privatestaticfinalSingleton 1 single=newSingleton 1 ();
publicstaticSingleton 1 getInstance (){
returnsingle;
}
}
饿汉单例模式的优点是足够简单、安全。其缺点是：单例对象在类被加载时，实例就直接被
初始化了。很多时候，在类被加载时并不需要进行单例初始化，所以需要对单例的初始化予以延迟，


```
第 8 章高并发设计模式 | 397
```
一直到实例使用的时候初始化。
在使用的时候才对单例进行初始化，这就是懒汉单例模式。懒汉单例模式的参考代码如下：
//简单的懒汉单例模式
publicclassASingleton
{
staticASingletoninstance; //静态成员
//私有构造器
privateASingleton (){}
//获取单例的方法
staticASingletongetInstance ()
{
if (instance==null) //①
{
instance=newASingleton (); //②
}
returninstance;
}
}
以上的懒汉单例模式的实现大家应该都很熟悉，估计也编写过类似的代码。以上的参考实现
在单线程场景中是合理的、安全的。在第一次被调用时，getInstance () 方法会新建出一个 ASingleton
实例，但之后访问时返回的是第一次新建的 ASingleton 实例。
多线程并发访问 getInstance () 方法时，问题就出来了：不同的线程有可能同时进入代码①处的
条件判断，多次执行代码②，从而新建多个 ASingleton 对象。
假设 ThreadA、B 两个线程并发通过 getInstance () 方法去获取 ASingleton 的单例，可能出现一种
执行次序，具体如表 8 - 1 所示。

表 8 - 1 两线程 ThreadA、B 并发执行的情况之一
时间点 ThreadA ThreadB
T 1 检查到 instance 为空，进入 if 程序块
T 2 检查到 instance 为空，进入 if 程序块
T 3 创建新 ASingleton 对象，初始化 instance 实例
T 4 返回对象 ASingleton
T 5
创建新 ASingleton 对象，初始化 instance
实例
T 6 返回对象 ASingleton
通过表 8 - 1 可以看到，instance 被实例化了两次，违背了单例模式的初衷。也就是说，以上的单
例模式实现在并发执行场景存在着单例被多次创建的问题。

###### 8. 1. 2 使用内置锁保护懒汉式单例

如何确保单例只创建一次，可以使用 synchronized 内置锁进行单例获取同步，确保同时只能一
条线程进入临界区执行。
//使用 synchronized 内置锁进行单例获取同步
publicclassBSingleton
{
staticBSingletoninstance; //保持单例的静态成员
privateBSingleton (){} //私有构造方法


398 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

//获取单例的方法
staticsynchronizedBSingletongetInstance ()
{
if (instance==null)
{
instance=newBSingleton ();
}
returninstance;
}
}
getInstance () 方法加 synchronized 关键字之后，可以保证在并发执行时不出错。问题是：每次执
行 getInstance () 方法都要用到同步，在争用激励的场景下，内置锁会升级为重量级锁，开销大、性
能差，所以不推荐高并发线程使用这种方式的单例模式。

###### 8. 1. 3 双重检查锁方式

实际上，单例模式的加锁操作只有单例在第一次创建的时候才需要用到，之后的单例获取操
作都没必要再加锁。所以，可以先判断单例对象是否已经被初始化，如果没有，加锁后再初始化，
这种模式被叫作双重检查锁（DoubleCheckedLocking）单例模式。示例代码如下：
//双重检查的懒汉式单例模式
publicclassESingleton
{
staticESingletoninstance; //保持单例的静态成员
privateESingleton (){} //私有构造器
staticESingletongetInstance ()
{
if (instance==null) //检查①
{
synchronized (ESingleton. class) //加锁
{
if (instance==null) //检查②
{
instance=newESingleton ();
}
}
}
returninstance;
}
}
双重检查锁单例模式主要包括以下三步：
1 ）检查单例对象是否被初始化，如果已被初始化，就立即返回单例对象。这是第一次检查，
对应于示例代码中的检查①，此次检查不需要使用锁进行线程同步来提高获取单例对象的性能。
2 ）如果单例没有被初始化，就试图去进入临界区进行初始化操作，此时才去获取锁。
3 ）进入临界区之后，再一次检查单例对象是否已经被初始化，如果还没被初始化，就初始化
一个实例。这是第二次检查，对应于代码中的检查②，此次检查在临界区内进行。

为什么在临界区内还需要执行一次检查呢？答案是：在多个线程竞争的场景下，可能同时不
止一个线程通过了第一次检查（检查①），此时第一个通过“检查①”的线程将首先进入临界区，


```
第 8 章高并发设计模式 | 399
```
而其他的通过“检查①”的线程将被阻塞，在第一个线程实例化单例对象释放锁之后，其他线程可
能获取到锁进入临界区，实际上单例已经被初始化了，所以哪怕是进入了临界区，其他线程并没有
办法通过“检查②”的条件判断，无法执行重复的初始化。
双重检查不仅避免了单例对象在多线程场景中的反复初始化，而且除了初始化的时候需要现
加锁外，后续的所有调用不需要加锁而直接返回单例，从而提升了获取单例时的性能。

###### 8. 1. 4 使用双重检查锁+volatile

表面上，使用双重检查锁机制的单例模式一切看上去都很完美，其实并不是这样的。那么问
题出现在哪里呢？下面这行代码实际大有玄机：
//初始化单例
instance=newSingleton ();
这行初始化单例代码转换成了汇编指令（具有原子性的指令）后，大致会细分成三个：
1 ）分配一块内存 M。
2 ）在内存 M 上初始化 Singleton 对象。
3 ）M 的地址赋值给 instance 变量。
编译器、CPU 都可能对没有内存屏障、数据依赖关系的操作进行重排序，上述的三个指令优
化后可能就变成了这样：

1 ）分配一块内存 M。
2 ）将 M 的地址赋值给 instance 变量。
3 ）在内存 M 上初始化 Singleton 对象。
指令重排之后，获取单例是可能导致问题的发生，这里假设两个线程以下面的次序执行：
1 ）线程 A 先执行 getInstance () 方法，当执行到分配一块内存并将地址赋值给 M 后，恰好发生了
线程切换。此时，线程 A 还没有来得及将 M 指向的内存初始化。
2 ）线程 B 刚进入 getInstance () 方法，判断 if 语句 instance 是否为空，此时的 instance 不为空，线程
B 直接获取到了未初始化的 instance 变量。

由于线程 B 得到的是一个未完全初始化的对象，因此访问 instance 成员变量的时候可能发生异
常。如何确保线程 B 获取的是一个完全初始化的单例呢？可以通过 volatile 禁止指令重排。双重检查
锁+volatile 相结合的单例模式实现大致的代码如下：
publicclassESingleton
{
//双重检查锁+volatile 相结合的单例模式实现
static volatileESingletoninstance; //保持单例的静态成员具有内存可见性
privateESingleton (){} //私有构造器
staticESingletongetInstance ()
{
if (instance==null) //检查①
{
synchronized (ESingleton. class) //加锁
{


400 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
if (instance==null) //检查②
{
instance=newESingleton ();
}
}
}
returninstance;
}
}
```
###### 8. 1. 5 使用静态内部类实例懒汉单例模式

虽然通过双重检查锁+volatile 相结合方式能实现高性能、线程安全的单例模式，但是该实现的
底层原理比较复杂，写法烦琐。另一种易于理解、编程简单的单例模式的实现为使用静态内部类实
例懒汉单例模式，参考代码如下：
publicclassSingleton{
//静态内部类
privatestaticclassLazyHolder{
//通过 final 保障初始化时的线程安全
privatestaticfinalSingletonINSTANCE=newSingleton ();
}
//私有的构造器
privateSingleton (){}
//获取单例的方法
publicstaticfinalSingletongetInstance (){
//返回内部类的静态、最终成员
returnLazyHolder. INSTANCE;
}
}
使用静态内部类实例懒汉单例模式只有在 getInstance () 被调用时才去加载内部类并且初始化单
例，该方式既解决了线程安全问题, 又解决了写法烦琐问题。本书随书源码中的三个单例线程池
——CPU 密集型线程池、IO 线程池、业务线程池的创建都使用了这种模式。

#### 8. 2 Master-Worker 模式

Master-Worker 模式是一种常见的高并发模式，它的核心思想是任务的调度和执行分离，调度
任务的角色为 Master，执行任务的角色为 Worker，Master 负责接收和、分配任务和合并（Merge）
任务结果，Worker 负责执行任务。Master-Worker 模式是一种归并类型的模式。
举一个例子，在 TCP 服务端的请求处理过程中，大量的客户端连接相当于大量的任务，Master
需要将这些存储在一个任务队列中，然后分发给各个 Worker，每个 Worker 是一个工作线程，负责
完成连接的传输处理。
Master-Worker 模式的整体结构如图 8 - 1 所示。


```
第 8 章高并发设计模式 | 401
```
```
图 8 - 1 Master-Worker 模式的整体结构
```
###### 8. 2. 1 Master-Worker 模式的参考实现

假设一个场景需要执行 N 个任务，将这些任务的结果进行累加求和，如果任务太多，可以采用
Master-Worker 模式实现。Master 持有 workerCount 个 Worker，并且负责接收任务，然后分发给 Worker，
最后在回调函数中对 Worker 的结果进行归并求和。

```
1 .Master 的参考代码
packagecom. crazymakercircle. designmodel. masterworker;
//省略 import
publicclassMaster<TextendsTask,R>
{
//所有 worker 的集合
privateHashMap<String,Worker<T,R>>workers=newHashMap<>();
//任务的集合
privateLinkedBlockingQueue<T>taskQueue=newLinkedBlockingQueue<>();
//任务处理结果集合
protectedMap<String,R>resultMap=newConcurrentHashMap<>();
//Master 的任务调度线程
privateThreadthread=null;
//保持最终的和
privateAtomicLongsum=newAtomicLong ( 0 );
publicMaster (intworkerCount)
{
//每个 worker 对象都需要持有 queue 的引用，用于领任务与提交结果
for (inti= 0 ;i<workerCount; i++)
{
Worker<T,R>worker=newWorker<>();
workers.put ("子节点: "+i, worker);
}
```
```
任务队列
```

402 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

thread=newThread (()->this.execute ());
thread.start ();
}
//提交任务
publicvoidsubmit (Ttask)
{
taskQueue.add (task);
}
//获取 worker 结果处理的回调函数
privatevoidresultCallBack (Objecto)
{
Task<R>task=(Task<R>) o;
StringtaskName="Worker: "+task.getWorkerId ()+"-"+"Task: "+task.getId ();
Rresult=task.getResult ();
resultMap.put (taskName, result);
sum.getAndAdd ((Integer) result); //和的累加
}
//启动所有的子任务
publicvoidexecute ()
{
for (;;)
{
//从任务队列中获取任务，然后 Worker 节点轮询，轮流分配任务
for (Map. Entry<String,Worker<T,R>>entry: workers.entrySet ())
{
Ttask=null;
try
{
task=this.taskQueue.take (); //获取任务
Workerworker=entry.getValue (); //获取节点
worker.submit (task, this::resultCallBack); //分配任务
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}
}
}
}
//获取最终的结果
publicvoidprintResult ()
{
Print.tco ("----------sumis: "+sum.get ());
for (Map. Entry<String,R>entry: resultMap.entrySet ())
{
StringtaskName=entry.getKey ();
Print.fo (taskName+": "+entry.getValue ());
}
}
}
Master 负责接收客户端提交的任务，然后通过阻塞队列对任务进行缓存。Master 所拥有的线程
作为阻塞队列的消费者，不断从阻塞队列获取任务并轮流分给 Worker。

2 .Worker 的参考代码
Worker 接收 Master 分配的任务，同样也通过阻塞队列对局部任务进行缓存。Worker 所拥有的
线程作为局部任务的阻塞队列的消费者，不断从阻塞队列获取任务并且执行，执行完成后回调
Master 传递过来的回调函数。


```
第 8 章高并发设计模式 | 403
```
packagecom. crazymakercircle. designmodel. masterworker;
//省略 import
publicclassWorker<TextendsTask,R>
{
//接收任务的阻塞队列
privateLinkedBlockingQueue<T>taskQueue=newLinkedBlockingQueue<>();
//worker 的编号
staticAtomicIntegerindex=newAtomicInteger ( 1 );
privateintworkerId;
//执行任务的线程
privateThreadthread=null;
publicWorker ()
{
this. workerId=index.getAndIncrement ();
thread=newThread (()->this.run ());
thread.start ();
}
/**
*轮询执行任务
*/
publicvoidrun ()
{
//轮询启动所有的子任务
for (;;)
{
try
{
//从阻塞队列中提取任务
Ttask=this.taskQueue.take ();
task.setWorkerId (workerId);
task.execute ();
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}
}
}
//接收任务到异步队列
publicvoidsubmit (Ttask, Consumer<R>action)
{
task. resultAction=action; //设置任务的回调方法
try{
this.taskQueue.put (task);
}catch (InterruptedExceptione)
{
e.printStackTrace ();
}
}
}
3 .异步任务类
异步任务类在执行子类任务的 doExecute () 方法之后，回调一下 Master 传递过来的回调函数，将
执行完成后的任务进行回填。
packagecom. crazymakercircle. designmodel. masterworker;
//省略 import
@Data


404 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
publicclassTask<R>
{
staticAtomicIntegerindex=newAtomicInteger ( 1 );
//任务的回调函数
publicConsumer<Task<R>>resultAction;
//任务的 id
privateintid;
//workerID
privateintworkerId;
//计算结果
Rresult=null;
publicTask ()
{
this. id=index.getAndIncrement ();
}
publicvoidexecute ()
{
this. result=this.doExecute ();
//执行回调函数
resultAction.accept (this);
}
//由子类实现
protectedRdoExecute ()
{
returnnull;
}
}
4 .测试用例
完整的测试用例如下：
packagecom. crazymakercircle. designmodel. masterworker;
//省略 import
publicclassMasterWorkerTest
{
//简单任务
staticclassSimpleTaskextendsTask<Integer>
{
@Override
protectedIntegerdoExecute ()
{
Print.tcfo ("task"+getId ()+"isdone");
returngetId ();
}
}
publicstaticvoidmain (String[]args)
{
//创建 Master，包含 4 个 Worker，并启动 Master 的执行线程
Master<SimpleTask,Integer>master=newMaster<>( 4 );
//定期向 Master 提交任务
ThreadUtil.scheduleAtFixedRate (()->master.submit (newSimpleTask ()),
2 ,TimeUnit. SECONDS);
//定期从 Master 提取结果
ThreadUtil.scheduleAtFixedRate (()->master.printResult (), 5 ,TimeUnit. SECONDS);
}
}
```

```
第 8 章高并发设计模式 | 405
```
```
执行测试用例，结果如下：
Thread- 0 |MasterWorkerTest$SimpleTask. doExecute]：task 1 isdone
[Thread- 3 |MasterWorkerTest$SimpleTask. doExecute]：task 2 isdone
[apppool- 1 - seq- 1 ]：-----------------------------------
[Master. printResult]：Worker: 1 - Task: 1 : 1
[Master. printResult]：Worker: 4 - Task: 2 : 2
[Thread- 1 |MasterWorkerTest$SimpleTask. doExecute]：task 3 isdone
[Thread- 2 |MasterWorkerTest$SimpleTask. doExecute]：task 4 isdone
[Thread- 0 |MasterWorkerTest$SimpleTask. doExecute]：task 5 isdone
[apppool- 1 - seq- 1 ]：-----------------------------------
[Master. printResult]：Worker: 1 - Task: 5 : 5
[Master. printResult]：Worker: 3 - Task: 4 : 4
[Master. printResult]：Worker: 1 - Task: 1 : 1
[Master. printResult]：Worker: 2 - Task: 3 : 3
[Master. printResult]：Worker: 4 - Task: 2 : 2
[Thread- 3 |MasterWorkerTest$SimpleTask. doExecute]：task 6 isdone
[Thread- 1 |MasterWorkerTest$SimpleTask. doExecute]：task 7 isdone
```
###### 8. 2. 2 Netty 中的 Master-Worker 模式的实现

Master-Worker 模式的核心思想为分而治之，Master 角色负责接收和分配任务，Worker 角色负
责执行任务和结果回填，具体如图 8 - 2 所示。

```
子任务分配
任务提交
```
```
部分结果返回
```
```
最终结果
```
```
Client Master
```
```
Worker
```
```
Worker
```
```
Worker
```
图 8 - 2 Master-Worker 模式的核心思想
实际上，高性能传输模式 Reactor 模式就是 Master-Worker 模式在传输领域的一种应用。基于 Java
的 NIO 技术，Netty 设计了一套优秀的、高性能的 Reactor（反应器）模式的具体实现。在 Netty 中，
EventLoop 反应器内部有一个线程负责 JavaNIO 选择器的事件轮询，然后进行对应的事件分发。事
件分发的目标就是 Netty 的 Handler 处理程序（含用户定义的业务处理程序）。
Netty 服务器程序中需要设置两个 EventLoopGroup 轮询组，一个组负责新连接的监听和接收，
另一个组负责 IO 传输事件的轮询与分发，两个轮询组的具体职责如下：

1 ）负责新连接的监听和接收的 EventLoopGroup 轮询组中的反应器完成查询通道的新连接 IO 事
件查询，这些反应器有点像负责招工的包工头，因此该轮询组可以形象地称为“包工头”（Boss）
轮询组。
2 ）另一个轮询组中的反应器完成查询所有子通道的 IO 事件，并且执行对应的 Handler 处理器完
成 IO 处理，例如数据的输入和输出（有点儿像搬砖），这个轮询组可以形象地称为“工人”（Worker）
轮询组。

```
Netty 中的 Reactor 模式如图 8 - 3 所示。
```

406 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

图 8 - 3 Netty 中的 Reactor 模式示意图
Netty 是基于 Reactor 模式的具体实现，体现了 Master-Worker 模式的思想。Netty 的 EventLoop
（Reactor 角色）可以对应到 Master-Worker 模式的 Worker 角色，而 Netty 的 EventLoopGroup 轮询组可
以对应到 Master-Worker 模式的 Master 角色。

```
Netty 是互联网中间件领域使用广泛、核心的网络通信框架之一。几乎所有 Java
互联网中间件或者大数据中间件的高性能通信与传输均离不开 Netty，掌握 Netty 是一名初、
中级工程师迈向高级工程师重要的技能之一。有关 Netty 的原理和实战知识请参阅笔者的另
一本书《Java 高并发核心编程卷 1 （加强版）：NIO、Netty、Redis、ZooKeeper》。
```
###### 8. 2. 3 Nginx 中的 Master-Worker 模式的实现

鼎鼎大名的 Nginx 服务器是 Master-Worker 模式（更准确地说是 Reactor 模式）在高性能服务器领
域的一种应用。Nginx 是一个高性能的 HTTP 和反向代理 Web 服务器，是由伊戈尔·赛索耶夫为俄罗
斯访问量第二的 Rambler. ru 站点开发的 Web 服务器。Nginx 源代码以类 BSD 许可证的形式发布，它的
第一个公开版本 0. 1. 0 发布于 2004 年 10 月 4 日， 2011 年 6 月 1 日发布了 1. 0. 4 版本。Nginx 因高稳定性、丰
富的功能集、内存消耗少、并发能力强而闻名全球，目前得到非常广泛的使用，比如百度、京东、
新浪、网易、腾讯、淘宝等都是它的用户。
Nginx 在启动后会以 daemon 方式在后台运行，它的后台进程有两类：一类称为 Master 进程（相
当于管理进程），另一类称为 Worker 进程（工作进程）。Nginx 的进程结构图如图 8 - 4 所示。
Nginx 的 Master 进程主要负责调度 Worker 进程，比如加载配置、启动工作进程、接收来自外界
的信号、向各 Worker 进程发送信号、监控 Worker 进程的运行状态等。Master 进程负责创建监听套接
口，交由 Worker 进程进行连接监听。Worker 进程主要用来处理网络事件，当一个 Worker 进程在接
收一条连接通道之后，就开始读取请求、解析请求、处理请求，处理完成产生的数据后，再返回给
客户端，最后断开连接通道。


```
第 8 章高并发设计模式 | 407
```
图 8 - 4 Nginx 的进程结构图
Nginx 的架构也非常直观地体现了 Master-Worker 模式的思想。Nginx 的 Master 进程可以对应到
Master-Worker 模式的 Master 角色，Nginx 的 Worker 进程可以对应到 Master-Worker 模式的 Worker 角色。

```
在实际的高并发 Web 项目中，Nginx 的使用率在 90 %以上。有关 Nginx 的原理和实
战知识请参阅笔者的另一本书《SpringCloud、Nginx 高并发核心编程》。
```
#### 8. 3 ForkJoin 模式

“分而治之”是一种思想，所谓“分而治之”就是把一个复杂的算法问题按一定的“分解”
方法分为规模较小的若干部分，然后逐个解决，分别找出各部分的解，最后把各部分的解再整合成
整个问题的解。“分而治之”思想在软件体系结构设计、模块化设计、基础算法中得到了非常广泛
的应用。许多基础算法都运用了“分治”的思想，比如二分查找、快速排序等。
Master-Worker 模式是“分而治之”思想的一种应用，本节所介绍的 ForkJoin 模式是“分而治之”
思想的另一种应用。与 Master-Worker 模式不同，ForkJoin 模式没有 Master 角色，其所有的角色都是
Worker，ForkJoin 模式中的 Worker 将大的任务分解成小的任务，一直到任务的规模足够小，可以使
用很简单、直接的方式来完成。

###### 8. 3. 1 ForkJoin 模式的原理

ForkJoin 模式先把一个大任务分解成许多个独立的子任务，然后开启多个线程并行去处理这些
子任务。有可能子任务还是很大而需要进一步分解，最终得到足够小的任务。ForkJoin 模式的任务
分解和执行过程大致如图 8 - 5 所示。
ForkJoin 模式借助了现代计算机多核的优势并行去处理数据。通常情况下，ForkJoin 模式将分
解出来的子任务放入双端队列中，然后几个启动线程从双端队列中获取任务并执行。子任务执行的
结果放到一个队列中，各个线程从队列中获取数据, 然后进行局部结果的合并，得到最终结果。

```
Master 进程
```
```
Worker 进程 Worker 进程
```

408 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
图 8 - 5 ForkJoin 模式的任务分解和执行过程
```
###### 8. 3. 2 ForkJoin 框架

JUC 包提供了一套 ForkJoin 框架的实现，具体以 ForkJoinPool 线程池的形式提供，并且该线程池
在 Java 8 的 Lambda 并行流框架中充当着底层框架的角色。JUC 包的 ForkJoin 框架包含如下组件：

1 ）ForkJoinPool：执行任务的线程池，继承了 AbstractExecutorService 类。
2 ）ForkJoinWorkerThread：执行任务的工作线程（ForkJoinPool 线程池中的线程）。每个线程
都维护着一个内部队列，用于存放“内部任务”。该类继承了 Thread 类。
3 ）ForkJoinTask：用于 ForkJoinPool 的任务抽象类，实现了 Future 接口。
4 ）RecursiveTask：带返回结果的递归执行任务，是 ForkJoinTask 的子类，在子任务带返回结
果时使用。
5 ）RecursiveAction：不返回结果的递归执行任务，是 ForkJoinTask 的子类，在子任务不带返回
结果时使用。

因为 ForkJoinTask 比较复杂，并且其抽象方法比较多，故在日常使用时一般不会直接继承
ForkJoinTask 来实现自定义的任务类，而是通过继承 ForkJoinTask 两子类 RecursiveTask 或者
RecursiveAction 之一去实现自定义任务类，自定义任务类需要实现这些子类的 compute () 方法，该方
法的执行流程一般如下：
if 任务足够小
直接返回结果
else
分解成 N 个子任务
依次调用每个子任务的 fork 方法执行子任务
依次调用每个子任务的 join 方法，等待子任务的完成，然后合并执行结果


```
第 8 章高并发设计模式 | 409
```
###### 8. 3. 3 ForkJoin 框架使用实战

假设需要计算 0 ~ 100 的累加求和，可以使用 ForkJoin 框架完成。首先需要设计一个可以递归执
行的异步任务子类。

```
1 .可递归执行的异步任务类 AccumulateTask
packagecom. crazymakercircle. designmodel. forkjoin;
//省略 import
publicclassAccumulateTaskextendsRecursiveTask<Integer>
{
privatestaticfinalintTHRESHOLD= 2 ;
//累加的起始编号
privateintstart;
//累加的结束编号
privateintend;
publicAccumulateTask (intstart, intend)
{
this. start=start;
this. end=end;
}
@Override
protectedIntegercompute ()
{
intsum= 0 ;
//判断任务的规模：若规模小则可以直接计算
booleancanCompute=(end-start)<=THRESHOLD;
//若任务已经足够小，则可以直接计算
if (canCompute)
{
//直接计算并返回结果，Recursive 结束
for (inti=start; i<=end; i++)
{
sum+=i;
}
Print.tcfo ("执行任务，计算"+start+"到"+end+"的和，结果是："+sum);
}else
{
//任务过大，需要切割，Recursive 递归计算
Print.tcfo ("切割任务：将"+start+"到"+end+"的和一分为二");
intmiddle=(start+end)/ 2 ;
//切割成两个子任务
AccumulateTasklTask=newAccumulateTask (start, middle);
AccumulateTaskrTask=newAccumulateTask (middle+ 1 ,end);
//依次调用每个子任务的 fork () 方法执行子任务
lTask.fork ();
rTask.fork ();
//等待子任务完成，依次调用每个子任务的 join () 方法合并执行结果
intleftResult=lTask.join ();
intrightResult=rTask.join ();
//合并子任务执行结果
sum=leftResult+rightResult;
}
returnsum;
}
}
```

410 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

自定义的异步任务子类 AccumulateTask 继承自 RecursiveTask，每一次执行可以携带返回值。在
AccumulateTask 通过 THRESHOLD 常量设置子任务分解的阈值，并在它的 compute () 方法中会进行阈
值判断，判断的逻辑如下：

1 ）若当前的计算规模（这里为求和的数字个数）大于 THRESHOLD，则当前子任务需要进一
步分解，若当前的计算规模没有大于 THRESHOLD，则直接计算（这里为求和）。
2 ）如果子任务可以直接执行，就进行求和操作，并返回结果。如果任务进行了分解，就需要
等待所有的子任务执行完毕，然后对各个分解结果求和。如果一个任务分解为多个子任务（含两个），
就依次调用每个子任务的 fork () 方法执行子任务，然后依次调用每个子任务的 join () 方法合并执行结果。

```
2 .使用 ForkJoinPool 调度 AccumulateTask ()
使用 ForkJoinPool 调度 AccumulateTask () 的示例代码如下：
packagecom. crazymakercircle. designmodel. forkjoin;
//省略 import
publicclassForkJoinTest
{
@org. junit. Test
publicvoidtestAccumulateTask ()
{
ForkJoinPoolforkJoinPool=newForkJoinPool ();
//创建一个累加任务，计算由 1 加到 10
AccumulateTaskcountTask=newAccumulateTask ( 1 , 100 );
Future<Integer>future=forkJoinPool.submit (countTask);
Integersum=future.get ( 1 ,TimeUnit. SECONDS);
Print.tcfo ("最终的计算结果："+sum);
//预期的结果为 5050
Assert.assertTrue (sum== 5050 );
}
执行以上用例，部分结果如下：
[ForkJoinPool- 1 - worker- 1 ]：切割任务：将 1 到 100 的和一分为二
[ForkJoinPool- 1 - worker- 3 ]：切割任务：将 51 到 100 的和一分为二
[ForkJoinPool- 1 - worker- 2 ]：切割任务：将 1 到 50 的和一分为二
[ForkJoinPool- 1 - worker- 1 ]：切割任务：将 1 到 25 的和一分为二
[ForkJoinPool- 1 - worker- 1 ]：切割任务：将 1 到 13 的和一分为二
[ForkJoinPool- 1 - worker- 1 ]：执行任务：计算 1 到 7 的和，结果是： 28
[ForkJoinPool- 1 - worker- 5 ]：切割任务：将 14 到 25 的和一分为二
[ForkJoinPool- 1 - worker- 3 ]：切割任务：将 51 到 75 的和一分为二
...
[ForkJoinPool- 1 - worker- 6 ]：切割任务：将 76 到 88 的和一分为二
[ForkJoinPool- 1 - worker- 2 ]：切割任务：将 89 到 100 的和一分为二
[ForkJoinPool- 1 - worker- 6 ]：执行任务：计算 76 到 82 的和，结果是： 553
[ForkJoinPool- 1 - worker- 2 ]：执行任务：计算 89 到 94 的和，结果是： 549
[ForkJoinPool- 1 - worker- 5 ]：执行任务：计算 83 到 88 的和，结果是： 513
[ForkJoinPool- 1 - worker- 4 ]：执行任务：计算 95 到 100 的和，结果是： 585
[main|ForkJoinTest. testAccumulateTask]：最终的计算结果： 5050
```
###### 8. 3. 4 ForkJoin 框架的核心 API

ForkJoin 框架的核心是 ForkJoinPool 线程池。该线程池使用一个无锁的栈来管理空闲线程，如
果一个工作线程暂时取不到可用的任务，则可能被挂起，而挂起的线程将被压入由 ForkJoinPool 维


```
第 8 章高并发设计模式 | 411
```
护的栈中，待有新任务到来时，再从栈中唤醒这些线程。

1 .ForkJoinPool 的构造器
publicForkJoinPool (intparallelism, //并行度，默认为 CPU 数，最小为 1
ForkJoinWorkerThreadFactoryfactory, //线程创建工厂
UncaughtExceptionHandlerhandler, //异常处理程序
booleanasyncMode) //是否为异步模式
{
this (checkParallelism (parallelism),
checkFactory (factory),
handler,
asyncMode? FIFO_QUEUE: LIFO_QUEUE,
"ForkJoinPool-"+nextPoolId ()+"-worker-");
checkPermission ();
}
对以上构造函数的 4 个参数具体介绍如下：
（ 1 ）parallelism：可并行级别
ForkJoin 框架将依据 parallelism 设定的级别决定框架内并行执行的线程数量。并行的每一个任
务都会有一个线程进行处理，但 parallelism 属性并不是 ForkJoin 框架中最大的线程数量，该属性也和
ThreadPoolExecutor 线程池中的 corePoolSize、maximumPoolSize 属性有区别，因为 ForkJoinPool 的结
构和工作方式与 ThreadPoolExecutor 完全不一样。ForkJoin 框架中可存在的线程数量和 parallelism 参
数值并不是绝对的关联。

（ 2 ）factory：线程创建工厂
当 ForkJoin 框架创建一个新的线程时，同样会用到线程创建工厂。只不过这个线程工厂不再需要实
现 ThreadFactory 接口，而是需要实现 ForkJoinWorkerThreadFactory 接口。后者是一个函数式接口，只需
要实现一个名叫 newThread () 的方法。在 ForkJoin 框架中有一个默认的 ForkJoinWorkerThreadFactory 接口
实现：DefaultForkJoinWorkerThreadFactory。

（ 3 ）handler：异常捕获处理程序
当执行的任务中出现异常，并从任务中被抛出时，就会被 handler 捕获。
（ 4 ）asyncMode：异步模式
asyncMode 参数表示任务是否为异步模式，其默认值为 false。如果 asyncMode 为 true，就表示子
任务的执行遵循 FIFO（先进先出）顺序，并且子任务不能被合并；如果 asyncMode 为 false，表示子
任务的执行遵循 LIFO（后进先出）顺序，并且子任务可以被合并。虽然从字面意思来看 asyncMode
是指异步模式，它并不是指 ForkJoin 框架的调度模式采用是同步模式还是异步模式工作，仅仅指任
务的调度方式。ForkJoin 框架中为每一个独立工作的线程准备了对应的待执行任务队列，这个任务
队列是使用数组进行组合的双向队列。asyncMode 模式的主要意思指的是待执行任务可以使用 FIFO
（先进先出）的工作模式，也可以使用 LIFO（后进先出）的工作模式，工作模式为 FIFO（先进先出）
的任务适用于工作线程只负责运行异步事件，不需要合并结果的异步任务。
ForkJoinPool 无参数的、默认的构造器如下：
staticfinalintMAX_CAP= 0 x 7 fff; //并行度常量 32767
publicForkJoinPool (){
this (Math.min (MAX_CAP,Runtime.getRuntime (). availableProcessors ()),


412 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

defaultForkJoinWorkerThreadFactory, null, false);
}
该构造器的 parallelism 值为 CPU 核数；factory 值为 defaultForkJoinWorkerThreadFactory 默认的线
程工厂；异常捕获处理器 handler 值为 null，表示不进行异常处理；异步模式 asyncMode 值为 false，
使用 LIFO（后进先出）的、可以合并子任务的模式。

2 .ForkJoinPool 的 common 通用池
很多场景可以直接使用 ForkJoinPool 定义的 common 通用池，使用 ForkJoinPool.commonPool () 方
法可以获取该 ForkJoin 线程池，该线程池通过 makeCommonPool () 来构造，具体的代码如下：
privatestaticForkJoinPoolmakeCommonPool (){
intparallelism=- 1 ;
ForkJoinWorkerThreadFactoryfactory=null;
UncaughtExceptionHandlerhandler=null;
try{
//并行度
Stringpp=System.getProperty (
"java. util. concurrent. ForkJoinPool. common. parallelism");
//线程工厂
Stringfp=System.getProperty (
"java. util. concurrent. ForkJoinPool. common. threadFactory");
//异常处理类
Stringhp=System.getProperty (
"java. util. concurrent. ForkJoinPool. common. exceptionHandler");
if (pp!=null) parallelism=Integer.parseInt (pp);
if (fp!=null) factory=((ForkJoinWorkerThreadFactory)
ClassLoader.getSystemClassLoader (). loadClass (fp). newInstance ());
if (hp!=null) handler=((UncaughtExceptionHandler)
ClassLoader.getSystemClassLoader (). loadClass (hp). newInstance ());
}catch (Exceptionignore){
}
if (factory==null){
if (System.getSecurityManager ()==null)
factory=defaultForkJoinWorkerThreadFactory;
else//usesecurity-manageddefault
factory=newInnocuousForkJoinWorkerThreadFactory ();
}
//默认并行度为 cores- 1
if (parallelism< 0 &&
(parallelism=Runtime.getRuntime (). availableProcessors ()- 1 )<= 0 )
parallelism= 1 ;
if (parallelism>MAX_CAP) parallelism=MAX_CAP;
returnnewForkJoinPool (parallelism, factory, handler, LIFO_QUEUE,
"ForkJoinPool. commonPool-worker-");
}
使用 common 池的优点是可以通过指定系统属性的方式定义“并行度、线程工厂和异常处理类”，
并且 common 池使用的是同步模式，也就是说可以支持任务合并。
通过系统属性的方式指定 parallelism 值的示例如下：
System.setProperty ("java. util. concurrent. ForkJoinPool. common. parallelism"," 8 ");
除此之外，还可以通过 Java 指令选项的方式指定 parallelism 值，具体的选项为：


```
第 8 章高并发设计模式 | 413
```
- Djava. util. concurrent. ForkJoinPool. common. parallelism= 8
其他的参数值如异常处理器 handler，都可以通过以上两种方式指定。
3 .向 ForkJoinPool 线程池提交任务的方式
可以向 ForkJoinPool 线程池提交以下两类任务：
（ 1 ）外部任务（External/SubmissionsTask）提交
向 ForkJoinPool 提交外部任务有三种方式：方式一使用 invoke () 方法，该方法提交任务后线程会
等待，等到任务计算完毕并返回结果；方式二使用 execute () 方法提交一个任务来异步执行，无返回
结果；方式三使用 submit () 方法提交一个任务，并且会返回一个 ForkJoinTask 实例，之后的适当时候
可通过 ForkJoinTask 实例获取执行结果。

（ 2 ）子任务（WorkerTask）提交
向 ForkJoinPool 提交子任务的方法相对比较简单，由任务实例的 fork () 方法完成。当任务被分解
之后，内部会调用 ForkJoinPool.WorkQueue.push () 方法直接把任务放到内部队列中等待被执行。

###### 8. 3. 5 工作窃取算法

ForkJoinPool 线程池的任务分为“外部任务”和“内部任务”，两种任务的存放位置不同：
1 ）外部任务存放在 ForkJoinPool 的全局队列中。
2 ）子任务会作为“内部任务”放到内部队列中，ForkJoinPool 池中的每个线程都维护着一个
内部队列，用于存放这些“内部任务”。

由于 ForkJoinPool 线程池通常有多个工作线程，与之相对应的就会有多个任务队列，这就会出
现任务分配不均衡的问题：有的队列任务多，忙得不停；有的队列没有任务一直空闲。那么有没有
一种机制帮忙将任务从繁忙的线程分摊给空闲的线程呢？答案是使用工作窃取算法。
工作窃取核心思想是：工作线程自己的活干完了之后，会去看看别人有没有没干完的活，如
果有就拿过来帮忙干。工作窃取算法的主要逻辑：每个线程拥有一个双端队列（本地队列）用于存
放需要执行的任务，当自己的队列没有任务时，可以从其他线程的任务队列中获得一个任务继续执
行，如图 8 - 6 所示。

图 8 - 6 工作窃取算法的主要逻辑
在实际进行任务窃取操作的时候，操作线程会进行其他线程的任务队列的扫描和任务的出队
尝试，为什么说尝试？因为完全有可能操作失败，主要原因是并行执行肯定涉及线程安全的问题，


414 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

假如在窃取过程中该任务已经开始执行，那么任务的窃取操作就会失败。
如何尽量避免在任务窃取中发生的线程安全问题呢？一种简单的优化办法是：在线程自己的
本地队列采取 LIFO（后进先出）策略，窃取其他任务队列的任务时采用 FIFO（先进先出）策略。
简单来说，获取自己队列的任务时从头开始，窃取其他队列的任务时从尾开始。由于窃取的操作十
分快速，会大量降低这种冲突，也是一种优化方式，如图 8 - 7 所示。

```
图 8 - 7 从尾部开始窃取其他任务队列的任务
```
###### 8. 3. 6 ForkJoin 框架的原理

ForkJoin 框架的核心原理大致如下：
1 ）ForkJoin 框架的线程池 ForkJoinPool 的任务分为“外部任务”和“内部任务”。
2 ）“外部任务”是放在 ForkJoinPool 的全局队列中。
3 ）ForkJoinPool 池中的每个线程都维护着一个任务队列用于存放“内部任务”，线程切割任
务得到的子任务就会作为“内部任务”放到内部队列中。
4 ）当工作线程想要拿到子任务的计算结果时，先判断子任务有没有完成，如果没有完成，再
判断子任务有没有被其他线程“窃取”，如果子任务没有被窃取，就由本线程来完成；一旦子任务
被窃取了，就去执行本线程“内部队列”的其他任务，或者去扫描其他的任务队列并窃取任务。
5 ）当工作线程完成其“内部任务”，处于空闲的状态时，就会扫描其他的任务队列窃取任务，
尽可能不会阻塞等待。

总之，ForkJoin 线程在等待一个任务完成时，要么自己来完成这个任务，要么在其他线程窃取
了这个任务的情况下，去执行其他任务，是不会阻塞等待的，从而避免资源浪费，除非所有任务队
列都为空。
工作窃取算法的优点如下：
1 ）线程是不会因为等待某个子任务的执行或者没有内部任务要执行而被阻塞等待、挂起，而
是会扫描所有的队列窃取任务，直到所有队列都为空时才会被挂起。
2 ）ForkJoin 框架为每个线程为维护着一个内部任务队列以及一个全局的任务队列，而且任务
队列都是双向队列，可从首尾两端来获取任务，极大地减少了竞争的可能性，可提高并行的性能。


```
第 8 章高并发设计模式 | 415
```
ForkJoinPool 适合于需要“分而治之”的场景，特别是分治之后递归调用的函数，例如快速排
序、二分搜索、大整数乘法、矩阵乘法、棋盘覆盖、归并排序、线性时间选择、汉诺塔问题等。
ForkJoinPool 适合调度的任务为 CPU 密集型任务，如果任务存在 I/O 操作、线程同步操作、sleep () 睡
眠等较长时间阻塞的情况，最好配合使用 ManagedBlocker 进行阻塞管理。总的来说，ForkJoinPool
不适合进行 IO 密集型、混合型的任务调度。

#### 8. 4 生产者－消费者模式

生产者－消费者模式是一个经典的多线程设计模式，它为多线程间的协作提供了良好的解决
方案，是高并发编程过程中常用的一种设计模式。
在实际的软件开发过程中，经常会碰到如下场景：某些模块负责产生数据，另一些模块负责
消费数据（此处的模块可以是类、函数、线程、进程等）。产生数据的模块可以形象地称为生产者，
而消费数据的模块可以称为消费者。然而，仅仅抽象出来生产者和消费者还不够，该模式还需要有
一个数据缓冲区作为生产者和消费者之间的中介：生产者把数据放入缓冲区，而消费者从缓冲区取
出数据。生产者－消费者模式的结构如图 8 - 8 所示。

图 8 - 8 生产者－消费者模式的结构
数据缓冲区的作用主要在于能使生产者和消费者解耦。如果没有数据缓冲区，让生产者直接
调用消费者的某个方法，那么生产者对于消费者就会产生依赖（也就是耦合）。将来如果消费者的
代码发生变化，可能会影响到生产者。而如果两者都依赖于某个缓冲区，两者之间不直接依赖，耦
合也就相应降低了。
生产者－消费者模式天生就是用来处理并发问题的。生产者和消费者是两个独立的并发主体，
生产者把制造出来的数据往缓冲区一放，就可以再去生产下一个数据了。生产者基本上不用依赖消
费者的处理速度。尤其是在生产者的速度时快时慢时，生产者－消费者模式的好处就体现出来了。
当数据制造快的时候，消费者来不及处理，未处理的数据可以暂时存在缓冲区中。等生产者的制造
速度慢下来，消费者再慢慢处理掉。
在生产者－消费者模式中，缓冲区是性能的关键，缓冲区可以基于 ArrayList、LinkedList、
BlockingQueue、环形队列等各种不同数据存储组件去设计，所使用的组件不同，生产者－消费者
模式实现的性能当然也就不同。由于本书前面已经编写了多个不同版本的生产者－消费者模式的实
现，这里对该模式的实现不再赘述。


416 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

#### 8. 5 Future 模式

Future 模式是高并发设计与开发过程中常见的设计模式，它的核心思想是异步调用。对于 Future
模式来说，它不是立即返回我们需要的数据，但是它会返回一个契约（或者说异步任务），将来我
们可以凭借这个契约（或异步任务）去获取需要的结果。
在进行传统的 RPC（远程调用）时，同步调用 RPC 是一段耗时的过程。当客户端发出 RPC 请求
后，服务端完成请求处理需要很长的一段时间才会返回，这个过程中客户端一直在等待，直到数据
返回后，再进行其他任务的处理。现有一个 Client 同步对三个 Server 分别进行一次 RPC 调用，具体如
图 8 - 9 所示。

图 8 - 9 一个 Client 同步对三个 Server 分别进行一次 RPC 调用
假设一次远程调用的时间为 500 毫秒，则一个 Client 同步对三个 Server 分别进行一次 RPC 调用的
总时间需要耗费 1500 毫秒。如果要减小这个总时间，可以使用 Future 模式对其进行改造，将同步的
RPC 调用改为异步并发的 RPC 调用，一个 Client 异步并发对三个 Server 分别进行一次 RPC 调用，具体
如图 8 - 10 所示。

```
图 8 - 10 一个 Client 异步并发对三个 Server 分别进行一次 RPC 调用
```

```
第 8 章高并发设计模式 | 417
```
假设一次远程调用的时间为 500 毫秒，则一个 Client 异步并发对三个 Server 分别进行一次 RPC 调
用的总时间只要耗费 500 毫秒。使用 Future 模式异步并发地进行 RPC 调用，客户端在得到一个 RPC
的返回结果前并不急于获取该结果，而是充分利用等待时间去执行其他的耗时操作（如其他 RPC
调用），这就是 Future 模式的核心所在。
Future 模式的核心思想是异步调用，有点类似于异步的 Ajax 请求。当调用某个耗时方法时，可
以不急于立刻获取结果，而是让被调用者立刻返回一个契约（或异步任务），并且将耗时的方法放
到另外的线程中执行，后续凭契约再去获取异步执行的结果。
在具体的实现上，Future 模式和异步回调模式既有区别，又有联系。Java 的 Future 模式实现没
有实现异步回调模式，仍然需要主动去获取耗时任务的结果；而 Java 8 中的 CompletableFuture 组件
实现了异步回调模式。


# 第 9 章

## 异步回调模式

随着业务模块系统越来越多，各个系统的业务架构变得越来越错综复杂，特别是随着这几年
微服务架构的兴起，跨机器、跨服务的接口调用越来越频繁。打个简单的比方：现在的一个业务流
程可能需要调用 N 次第三方接口，获取 N 种上游数据。因此，面临一个大的问题：如何异步去调取
这些接口（做到高效率），然后同步去处理这些接口的返回结果呢？这里涉及线程的异步回调问题，
这也是高并发的一个基础问题。
在 Netty 源码中大量的使用了异步回调技术，并且基于 Java 的异步回调设计了自己的一整套异
步回调接口和实现。
这里从 JavaFuture 异步回调技术入手，然后介绍比较常用的第三方异步回调技术——谷歌的
GuavaFuture 相关技术，最后介绍 Netty 的异步回调技术。
当然，学习高并发编程、掌握异步回调同样很重要。

#### 9. 1 从泡茶的案例说起

在进入异步回调的正式解读之前，先看一个比较好理解的异步生活实例。笔者想到自己中学 8
年级的语文中有一篇华罗庚的课文——《统筹方法》，里边举了一个合理安排工序以便提升效率的
泡茶案例。这里使用阻塞模式和异步回调模式分别实现其中的异步泡茶流程。强调一下：这里直接
略过顺序执行的冒泡工序，那个效率太低了。
为了异步执行整个泡茶流程，分别设计三条线程：泡茶线程（MainThread，主线程）、烧水
线程（HotWarterThread）、清洗线程（WashThread）。泡茶线程的工作是：启动清洗线程、启动烧
水线程，等清洗、烧水的工作完成后，泡茶喝；清洗线程的工作是：洗茶壶、洗茶杯；烧水线程的
工作是：洗好水壶，灌上凉水，放在火上，一直等水烧开。
下面分别使用阻塞模式、回调模式实现泡茶喝的案例。


```
第 9 章异步回调模式 | 419
```
#### 9. 2 join：异步阻塞之闷葫芦

阻塞模式实现泡茶实例首先从基础的多线程 join 合并实验入手。join 操作的原理是阻塞当前的
线程，直到待合并的目标线程的执行完成。

###### 9. 2. 1 线程的合并流程

Java 中线程的合并流程是：假设线程 A 调用线程 B 的 join () 方法去合并 B 线程，那么线程 A 进入阻
塞状态，直到线程 B 执行完成。
在泡茶的例子中，主线程通过分别调用烧水线程和清洗线程的 join () 方法，等待烧水线程和清
洗线程执行完成，然后执行主线程自己的泡茶操作。具体的执行流程如图 9 - 1 所示。

```
图 9 - 1 使用 join () 实现泡茶实例的流程
```
###### 9. 2. 2 调用 join () 实现异步泡茶喝

```
使用 join () 实现泡茶喝是一个异步阻塞版本，具体的代码实现如下：
packagecom. crazymakercircle. coccurent;
...
publicclassJoinDemo{
publicstaticfinalintSLEEP_GAP= 500 ;
publicstaticStringgetCurThreadName (){
returnThread.currentThread (). getName ();
}
staticclassHotWarterThreadextendsThread{
publicHotWarterThread (){
super ("**烧水-Thread");
}
publicvoidrun (){
try{
Logger.info ("洗好水壶");
Logger.info ("灌上凉水");
Logger.info ("放在火上");
//线程睡眠一段时间，代表烧水中
Thread.sleep (SLEEP_GAP);
Logger.info ("水开了");
}catch (InterruptedExceptione){
Logger.info ("发生异常被中断.");
```

420 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

}
Logger.info ("运行结束.");
}
}
staticclassWashThreadextendsThread{
publicWashThread (){
super ("$$清洗-Thread");
}
publicvoidrun (){
try{
Logger.info ("洗茶壶");
Logger.info ("洗茶杯");
Logger.info ("拿茶叶");
//线程睡眠一段时间，代表清洗中
Thread.sleep (SLEEP_GAP);
Logger.info ("洗完了");
}catch (InterruptedExceptione){
Logger.info ("发生异常被中断.");
}
Logger.info ("运行结束.");
}
}
publicstaticvoidmain (Stringargs[]){
ThreadhThread=newHotWarterThread ();
ThreadwThread=newWashThread ();
hThread.start ();
wThread.start ();
//在等待烧水和清洗之时，可以干点其他事情
try{
//合并烧水-线程
hThread.join ();
//合并清洗-线程
wThread.join ();
Thread.currentThread (). setName ("主线程");
Logger.info ("泡茶喝");
}catch (InterruptedExceptione){
Logger.info (getCurThreadName ()+"发生异常被中断.");
}
Logger.info (getCurThreadName ()+"运行结束.");
}
}
程序中有三个线程：主线程 main、烧水线程 hThread 和清洗线程 wThread。main 调用了
hThread.join () 实例方法，合并烧水线程，也调用了 wThread.join () 实例方法，合并清洗线程。
说明一下：hThread、wThread 是线程实例，在例子代码中，hThread 对应的线程名称为“**烧
水-Thread”，wThread 对应的线程名称为“$$清洗-Thread”。

###### 9. 2. 3 join () 方法详解

join () 方法应用场景如下：
A 线程调用 B 线程的 join () 方法，等待 B 线程执行完成；在 B 线程没有完成前，A 线程阻塞。
join () 方法是有三个重载版本：
1 ）voidjoin ()：A 线程等待 B 线程执行结束后，A 线程重启执行。
2 ）voidjoin (longmillis)：A 线程等待 B 线程执行一段时间，最长等待时间为 millis（毫秒）。超
过 millis 后，不论 B 线程是否结束，A 线程重启执行。


```
第 9 章异步回调模式 | 421
```
3 ）voidjoin (longmillis, intnanos)：等待乙方线程执行一段时间，最长等待时间为 millis 加 nanos
（纳秒）。超过该时间后，无论乙方是否结束，甲方线程都重启执行。

强调一下容易混淆的几点：
1 ）join () 是实例方法不是静态方法，需要使用线程对象去调用，如 thread.join ()。
2 ）调用 join () 时，不是 thread 所指向的目标线程阻塞，而是当前线程阻塞。
3 ）只有等到 thread 所指向的线程执行完成或者超时，当前线程才能启动执行。
join () 有一个问题：被合并线程没有返回值。比如，在烧水的实例中，如果烧水线程的执行结
束，main 线程是没有办法知道结果的。同样，清洗线程的执行结果，main 线程（泡茶线程）也是没
有办法知道的。形象地说，join 线程合并就像一个闷葫芦。只能发起合并线程，不能取到执行结果。
如果需要获得异步线程的执行结果，怎么办呢？可以使用 Java 的 FutureTask 系列类。
下面来查看 join () 的实现源码：
publicfinalsynchronizedvoidjoin (longmillis)
throwsInterruptedException{
longbase=System.currentTimeMillis ();
longnow= 0 ;
if (millis< 0 ){
thrownewIllegalArgumentException ("timeoutvalueisnegative");
}
if (millis== 0 ){
while (isAlive ()){
wait ( 0 ); //阻塞当前线程
}
}else{
while (isAlive ()){
longdelay=millis-now;
if (delay<= 0 ){
break;
}
wait (delay); //限时阻塞当前线程
now=System.currentTimeMillis ()-base;
}
}
}
join () 的实现原理是不停地检查 join 线程是否存活，如果 join 线程存活，wait ( 0 ) 就永远等下去，
直至 join 线程终止后，线程的 this.notifyAll () 方法会被调用（该方法是在 JVM 中实现的，JDK 中并不
会看到源码），join () 方法将退出循环，恢复主线程执行。很显然这种循环检查的方式比较低效。
除此之外，调用 join () 缺少很多灵活性，比如实际项目中很少让自己单独创建线程，而是使用
Executor，这进一步减少了 join () 的使用场景，所以 join () 的使用多数停留在 Demo 演示上。

#### 9. 3 FutureTask：异步调用之重武器

为了获取异步线程的返回结果，Java 在 1. 5 版本之后提供了一种新的多线程的创建方式——
FutureTask 方式。FutureTask 方式包含了一系列的 Java 相关的类，处于 java. util. concurrent 包中。使用
FutureTask 方式进行异步调用时，所涉及的重要组件为 FutureTask 类和 Callable 接口。
由于 Runnable 有一个重要的问题，其 run () 方法是没有返回值的，因此 Runnable 不能用在需要有返


422 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

回值的场景。为了解决 Runnable 接口的问题，Java 定义了一个新的和 Runnable 类似的接口——Callable
接口，并且将其中被异步执行的业务处理抽象方法——run () 方法改名为 call ()，但是 call () 方法有返回值。

```
由于第 1 章已经详细介绍了使用 FutureTask 进行异步调用所涉及的几个类和接口：
Callable、Future 和 FutureTask，故这里不再赘述。建议大家翻到前面去温习一下这部分的内容。
```
###### 9. 3. 1 通过 FutureTask 获取异步执行结果的步骤

通过 FutureTask 类和 Callable 接口的联合使用可以创建能获取异步执行结果的线程。具体的步
骤重复介绍如下：

1 ）创建一个 Callable 接口的实现类，并实现其 call () 方法，编写好异步执行的具体逻辑，并且
可以有返回值。
2 ）使用 Callable 实现类的实例构造一个 FutureTask 实例。
3 ）使用 FutureTask 实例作为 Thread 构造器的 target 入参，构造新的 Thread 线程实例。
4 ）调用 Thread 实例的 start () 方法启动新线程，启动新线程的 run () 方法并发执行。其内部的执行
过程为：启动 Thread 实例的 run () 方法并发执行后，会执行 FutureTask 实例的 run () 方法，最终会并发
执行 Callable 实现类的 call () 方法。
5 ）调用 FutureTask 对象的 get () 方法阻塞性地获得并发线程的执行结果。

```
为什么将 FutureTask 称为异步调用之重武器呢？具体结论将在 9. 5. 5 节为大家揭晓。
```
###### 9. 3. 2 使用 FutureTask 实现异步泡茶喝

前面的 join 版本喝茶实例中有一个很大的问题：就是主线程获取不到异步线程的返回值。打个
比方，如果烧水线程出了问题，或者清洗线程出了问题，main 线程（泡茶线程）没有办法知道。哪
怕不具备泡茶条件，main 线程（泡茶线程）也只能继续泡茶喝。
使用 FutureTask 实现异步泡茶喝，main 线程可以获取烧水线程、清洗线程的执行结果，然后根
据结果判断是否具备泡茶条件，如果具备泡茶条件再泡茶。
使用 FutureTask 实现异步泡茶喝的执行流程具体如图 9 - 2 所示。

```
图 9 - 2 使用 FutureTask 实现异步泡茶喝的执行流程
```

```
第 9 章异步回调模式 | 423
```
使用 FutureTask 类和 Callable 接口进行泡茶喝的实战，代码如下：
packagecom. crazymakercircle. coccurent;
...
publicclassJavaFutureDemo{
publicstaticfinalintSLEEP_GAP= 500 ;
publicstaticStringgetCurThreadName (){
returnThread.currentThread (). getName ();
}
staticclassHotWarterJobimplementsCallable<Boolean>//①
{
@Override
publicBooleancall () throwsException//②
{
try{
Logger.info ("洗好水壶");
Logger.info ("灌上凉水");
Logger.info ("放在火上");
//线程睡眠一段时间，代表烧水中
Thread.sleep (SLEEP_GAP);
Logger.info ("水开了");
}catch (InterruptedExceptione){
Logger.info ("发生异常被中断.");
returnfalse;
}
Logger.info ("运行结束.");
returntrue;
}
}
staticclassWashJobimplementsCallable<Boolean>{
@Override
publicBooleancall () throwsException{
try{
Logger.info ("洗茶壶");
Logger.info ("洗茶杯");
Logger.info ("拿茶叶");
//线程睡眠一段时间，代表清洗中
Thread.sleep (SLEEP_GAP);
Logger.info ("洗完了");
}catch (InterruptedExceptione){
Logger.info ("清洗工作发生异常被中断.");
returnfalse;
}
Logger.info ("清洗工作运行结束.");
returntrue;
}
}
publicstaticvoiddrinkTea (booleanwarterOk, booleancupOk){
if (warterOk&&cupOk){
Logger.info ("泡茶喝");
}elseif (! warterOk){
Logger.info ("烧水失败，没有茶喝了");
}elseif (! cupOk){
Logger.info ("杯子洗不了，没有茶喝了");
}
}
publicstaticvoidmain (Stringargs[]){
Thread.currentThread (). setName ("主线程");
Callable<Boolean>hJob=newHotWarterJob ();//③
FutureTask<Boolean>hTask=
newFutureTask<>(hJob);//④


424 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

ThreadhThread=newThread (hTask,"**烧水-Thread");//⑤
Callable<Boolean>wJob=newWashJob ();//③
FutureTask<Boolean>wTask=
newFutureTask<>(wJob);//④
ThreadwThread=newThread (wTask,"$$清洗-Thread");//⑤
hThread.start ();
wThread.start ();
//在等待烧水和清洗时可以干点其他事情
try{
boolean warterOk=hTask.get ();
boolean cupOk=wTask.get ();
drinkTea (warterOk, cupOk);
}catch (InterruptedExceptione){
Logger.info (getCurThreadName ()+"发生异常被中断.");
}catch (ExecutionExceptione){
e.printStackTrace ();
}
Logger.info (getCurThreadName ()+"运行结束.");
}
}
首先，在上面的喝茶实例代码使用了 Callable 接口来替代 Runnable 接口，并且在 call () 方法中返
回了异步线程的执行结果。
staticclassWashJobimplementsCallable<Boolean>
{
@Override
publicBooleancall () throwsException
{
//业务代码，并且有执行结果返回
}
}
其次，从 Callable 异步逻辑到异步线程需要创建一个 FutureTask 实例，并通过 FutureTask 实例创
建新的线程：
Callable<Boolean>hJob=newHotWarterJob ();//异步逻辑
FutureTask<Boolean>hTask=
newFutureTask<Boolean>(hJob);//包装异步逻辑的异步任务实例
ThreadhThread=newThread (hTask,"**烧水-Thread");//异步线程
FutureTask 和 Callable 都是泛型类，泛型参数表示返回结果的类型。所以，在使用时它们两个
实例的泛型参数需要保持一致。
最后，通过 FutureTask 实例取得异步线程的执行结果。一般来说，通过 FutureTask 实例的 get ()
方法可以获取线程的执行结果。
总之，FutureTask 比 join 线程合并操作更加高明，能取得异步线程的结果。但是，也就未必高
明到哪里去。为什么呢？
因为通过 FutureTask 的 get () 方法获取异步结果时，主线程也会被阻塞。这一点 FutureTask 和 join
是一致的，它们都是异步阻塞模式。
异步阻塞的效率往往比较低，被阻塞的主线程不能干任何事情，唯一能干的就是傻傻等待。
原生 JavaAPI 除了阻塞模式的获取结果外，并没有实现非阻塞的异步结果获取方法。如果需要用到
获取异步的结果，得引入一些额外的框架，接下来将会介绍谷歌的 Guava 框架。


```
第 9 章异步回调模式 | 425
```
#### 9. 4 异步回调与异步阻塞调用

在前面的泡茶喝实例中，无论主线程调用 join () 进行闷葫芦式线程同步，还是使用 Future.get ()
去获取异步线程的执行结果，都属于异步阻塞的调用。
异步阻塞属于主动模式的异步调用；异步回调属于被动模式的异步调用。
在前面的异步阻塞版本的泡茶喝的实现中，泡茶线程是调用线程，烧水（或者清洗）线程是
被调用线程，调用线程和被调用线程之间是一种主动关系，而不是被动关系。泡茶线程需要主动获
取烧水（或者清洗）线程的执行结果。
调用 join () 或 Future.get () 进行线程同步时，泡茶线程和烧水（或者清洗）线程之间的主动关系
如图 9 - 3 所示。

图 9 - 3 泡茶线程（调用方）和清洗线程之间的主动关系
主动调用是一种阻塞式调用，“调用方”要等待“被调用方”执行完毕才返回。如果“被调
用方”的执行时间很长，那么“调用方”线程需要阻塞很长一段时间。
如何将主动调用的方向进行反转呢？这就是异步回调。回调是一种被动的调用模式，也就是
说，被调用方在执行完成后，会反向执行“调用方”所设置的钩子方法。
使用回调模式将泡茶线程和烧水（或者清洗）线程之间的“主动”关系进行反转，具体如
图 9 - 4 所示。

图 9 - 4 泡茶线程（调用方）和清洗线程之间的回调关系
实质上，在异步回调模式中负责执行回调方法的具体线程已经不再是调用方的线程（如实例
中的泡茶喝线程），而是变成了异步的被调方的线程（如烧水线程）。
Java 中回调模式的标准实现类为 CompletableFuture，由于该类出现的时间比较晚，因此很多的
著名的中间件如 Guava、Netty 等都提供了自己的异步回调模式 API 供开发者使用。开发者还可以使
用 RxJava 响应式编程组件进行异步回调的开发。


426 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
RxJava 响应式编程组件也是一个非常重要的组件，在 Android 应用开发、Spring
Cloud 基础开发中使用得非常多。有关 RxJava 的具体内容请参阅《SpringCloud、Nginx 高并
发核心编程》一书。
```
```
接下来，为大家介绍 Guava、Netty 等著名组件中的异步回调模式实现。
```
#### 9. 5 Guava 的异步回调模式

Guava 是 Google 提供的 Java 扩展包，它提供了一种异步回调的解决方案。Guava 中与异步回调
相关的源码处于 com. google. common. util. concurrent 包中。包中的很多类都用于对 java. util. concurrent
的能力扩展和能力增强。比如，Guava 的异步任务接口 ListenableFuture 扩展了 Java 的 Future 接口，实
现了异步回调的的能力。

###### 9. 5. 1 详解 FutureCallback

总的来说，Guava 主要增强了 Java 而不是另起炉灶。为了实现异步回调方式获取异步线程的结
果，Guava 做了以下增强：

 引入了一个新的接口 ListenableFuture，继承了 Java 的 Future 接口，使得 Java 的 Future 异步任
务在 Guava 中能被监控和以非阻塞方式获取异步结果。
 引入了一个新的接口 FutureCallback，这是一个独立的新接口。该接口的目的是在异步任务
执行完成后，根据异步结果完成不同的回调处理，并且可以处理异步结果。
FutureCallback 是一个新增的接口，用来填写异步任务执行完后的监听逻辑。FutureCallback 拥
有两个回调方法：

 onSuccess () 方法，在异步任务执行成功后被回调。调用时，异步任务的执行结果作为
onSuccess () 方法的参数被传入。
 onFailure () 方法，在异步任务执行过程中抛出异常时被回调。调用时，异步任务所抛出的
异常作为 onFailure 方法的参数被传入。
FutureCallback 的源码如下：
packagecom. google. common. util. concurrent;
publicinterfaceFutureCallback<V>{
voidonSuccess (@NullableVvar 1 );
voidonFailure (Throwablevar 1 );
}
注意，Guava 的 FutureCallback 与 Java 的 Callable 名字相近，实质不同，存在本质的区别：
1 ）Java 的 Callable 接口代表的是异步执行的逻辑。
2 ）Guava 的 FutureCallback 接口代表的是 Callable 异步逻辑执行完成之后，根据成功或者异常两
种情形所需要执行的善后工作。


```
第 9 章异步回调模式 | 427
```
Guava 是对 JavaFuture 异步回调的增强，使用 Guava 异步回调也需要用到 Java 的 Callable 接口。简
单地说，只有在 Java 的 Callable 任务执行结果出来后，才可能执行 Guava 中的 FutureCallback 结果回调。
Guava 如何实现异步任务 Callable 和结果回调 FutureCallback 之间的监控关系呢？Guava 引入了
一个新接口 ListenableFuture，它继承了 Java 的 Future 接口，增强了被监控的能力。

###### 9. 5. 2 详解 ListenableFuture

Guava 的 ListenableFuture 接口是对 Java 的 Future 接口的扩展，可以理解为异步任务实例，源码如下：
packagecom. google. common. util. concurrent;
importjava. util. concurrent. Executor;
importjava. util. concurrent. Future;
publicinterfaceListenableFuture<V>extendsFuture<V>{
//此方法由 Guava 内部调用
void addListener (Runnable r, Executor e);
}
ListenableFuture 仅仅增加了一个 addListener () 方法。它的作用就是将 9. 5. 1 节的 FutureCallback 善
后回调逻辑封装成一个内部的 Runnable 异步回调任务，在 Callable 异步任务完成后回调
FutureCallback 善后逻辑。
注意，此 addListener () 方法只在 Guava 内部使用，如果对它感兴趣，可以查看 Guava 源码。在实
际编程中，addListener () 不会使用到。
在实际编程中，如何将 FutureCallback 回调逻辑绑定到异步的 ListenableFuture 任务呢？可以使
用 Guava 的 Futures 工具类，它有一个 addCallback () 静态方法，可以将 FutureCallback 的回调实例绑定
到 ListenableFuture 异步任务。下面是一个简单的绑定实例：
Futures.addCallback (listenableFuture, newFutureCallback<Boolean>()
{
publicvoidonSuccess (Booleanr)
{
//listenableFuture 内部的 Callable 成功时回调此方法
}
publicvoidonFailure (Throwablet)
{
//listenableFuture 内部的 Callable 异常时回调此方法
}
});
现在的问题来了，既然 Guava 的 ListenableFuture 接口是对 Java 的 Future 接口的扩展，两者都表示
异步任务，那么 Guava 的异步任务实例从何而来？

###### 9. 5. 3 ListenableFuture 异步任务

如果要获取 Guava 的 ListenableFuture 异步任务实例，主要是通过向线程池（ThreadPool）提交
Callable 任务的方式获取。不过，这里所说的线程池不是 Java 的线程池，而是经过 Guava 自己定制过
的 Guava 线程池。
Guava 线程池是对 Java 线程池的一种装饰。创建 Guava 线程池的方法如下：
//Java 线程池
ExecutorServicejPool= Executors.newFixedThreadPool ( 10 );


428 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

//Guava 线程池
ListeningExecutorServicegPool= MoreExecutors.listeningDecorator (jPool);
首先创建 Java 线程池，然后以其作为 Guava 线程池的参数再构造一个 Guava 线程池。有了 Guava
的线程池之后，就可以通过 submit () 方法来提交任务了，任务提交之后的返回结果就是我们所要的
ListenableFuture 异步任务实例。
简单来说，获取异步任务实例的方式是通过向线程池提交 Callable 业务逻辑来实现，代码如下：
//submit () 方法用来提交任务，返回异步任务实例
ListenableFuture<Boolean>hFuture=gPool.submit (hJob);
//绑定回调实例
Futures.addCallback (listenableFuture, newFutureCallback<Boolean>()
{
//有两种实现回调的方法
});
取到了 ListenableFuture 实例后，通过 Futures.addCallback () 方法将 FutureCallback 回调逻辑的实例
绑定到 ListenableFuture 异步任务实例，实现异步执行完成后的回调。
总结一下，Guava 异步回调的流程如下：
1 ）实现 Java 的 Callable 接口，创建的异步执行逻辑。还有一种情况，如果不需要返回值，异步
执行逻辑也可以实现 Runnable 接口。
2 ）创建 Guava 线程池。
3 ）将 1 ）创建的 Callable/Runnable 异步执行逻辑的实例提交到 Guava 线程池，从而获取
ListenableFuture 异步任务实例。
4 ）创建 FutureCallback 回调实例，通过 Futures. addCallback 将回调实例绑定到 ListenableFuture
异步任务上。

完成以上 4 步，当 Callable/Runnable 异步执行逻辑完成后，就会回调异步回调实例 FutureCallback
实例的回调方法 onSuccess ()/onFailure ()。

###### 9. 5. 4 使用 Guava 实现泡茶喝的实例

前面已经完成了 join 版本、FutureTask 版本的泡茶喝实战。大家对此实例的业务功能应该已经
非常熟悉了，这里不再赘述。
基于 Guava 异步回调模式的泡茶喝程序的执行流程如图 9 - 5 所示。

```
图 9 - 5 使用 Guava 实现的异步回调模式泡茶喝程序的执行流程
```

```
第 9 章异步回调模式 | 429
```
下面是基于 Guava 异步回调的泡茶喝程序演进版本，代码如下：
packagecom. crazymakercircle. coccurent;
//省略 import
publicclassGuavaFutureDemo
{
publicstaticfinalintSLEEP_GAP= 3000 ;
staticclassHotWaterJobimplementsCallable<Boolean>//①
{
@Override
publicBooleancall () throwsException//②
{
try
{
Print.tcfo ("洗好水壶");
Print.tcfo ("烧开水");
//线程睡眠一段时间，代表烧水中
Thread.sleep (SLEEP_GAP);
Print.tcfo ("水开了");
}catch (InterruptedExceptione)
{
Print.tcfo ("发生异常被中断.");
returnfalse;
}
Print.tcfo ("烧水工作，运行结束.");
returntrue;
}
}
staticclassWashJobimplementsCallable<Boolean>
{
@Override
publicBooleancall () throwsException
{
try
{
Print.tcfo ("洗茶杯");
//线程睡眠一段时间，代表清洗中
Thread.sleep (SLEEP_GAP);
Print.tcfo ("洗完了");
}catch (InterruptedExceptione)
{
Print.tcfo ("清洗工作发生异常被中断.");
returnfalse;
}
Print.tcfo ("清洗工作运行结束.");
returntrue;
}
}
//泡茶喝的工作
staticclassDrinkJob
{
booleanwaterOk=false;
booleancupOk=false;
//泡茶喝，回调方法
publicvoiddrinkTea ()


430 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
{
if (waterOk&&cupOk)
{
Print.tcfo ("泡茶喝，茶喝完");
this. waterOk=false;
}
}
}
publicstaticvoidmain (Stringargs[])
{
Thread.currentThread (). setName ("泡茶喝线程");
//新起一个线程，作为泡茶主线程
DrinkJobdrinkJob=newDrinkJob ();
//烧水的业务逻辑
Callable<Boolean>hotJob=newHotWaterJob ();
//清洗的业务逻辑
Callable<Boolean>washJob=newWashJob ();
//创建 Java 线程池
ExecutorServicejPool=
Executors.newFixedThreadPool ( 10 );
//包装 Java 线程池，构造 Guava 线程池
ListeningExecutorServicegPool=
MoreExecutors.listeningDecorator (jPool);
//烧水的回调钩子
FutureCallback<Boolean>hotWaterHook=newFutureCallback<Boolean>()
{
publicvoidonSuccess (Booleanr)
{
if (r)
{
drinkJob. waterOk=true;
//执行回调方法
drinkJob.drinkTea ();
}
}
publicvoidonFailure (Throwablet)
{
Print.tcfo ("烧水失败，没有茶喝了");
}
};
//启动烧水线程
ListenableFuture<Boolean>hotFuture=gPool.submit (hotJob);
//设置烧水任务的回调钩子
Futures.addCallback (hotFuture, hotWaterHook);
//启动清洗线程
ListenableFuture<Boolean>washFuture=gPool.submit (washJob);
//使用匿名实例，作为清洗之后的回调钩子
Futures.addCallback (washFuture, newFutureCallback<Boolean>()
{
publicvoidonSuccess (Booleanr)
{
if (r)
{
drinkJob. cupOk=true;
//执行回调方法
```

```
第 9 章异步回调模式 | 431
```
drinkJob.drinkTea ();
}
}
publicvoidonFailure (Throwablet)
{
Print.tcfo ("杯子洗不了，没有茶喝了");
}
});
Print.tcfo ("干点其他事情...");
sleepSeconds ( 1 );
Print.tcfo ("执行完成");
}
}
运行以上程序，结果如下：
[pool- 1 - thread- 1 |GuavaFutureDemo$HotWaterJob. call]：洗好水壶
[泡茶喝线程|GuavaFutureDemo. main]：干点其他事情...
[pool- 1 - thread- 2 |GuavaFutureDemo$WashJob. call]：洗茶杯
[泡茶喝线程|GuavaFutureDemo. main]：执行完成
[pool- 1 - thread- 1 |GuavaFutureDemo$HotWaterJob. call]：烧开水
[pool- 1 - thread- 2 |GuavaFutureDemo$WashJob. call]：洗完了
[pool- 1 - thread- 2 |GuavaFutureDemo$WashJob. call]：清洗工作运行结束.
[pool- 1 - thread- 1 |GuavaFutureDemo$HotWaterJob. call]：水开了
[pool- 1 - thread- 1 |GuavaFutureDemo$HotWaterJob. call]：烧水工作，运行结束.
[pool- 1 - thread- 2 |GuavaFutureDemo$DrinkJob. drinkTea]：泡茶喝，茶喝完
[pool- 1 - thread- 1 |GuavaFutureDemo$DrinkJob. drinkTea]：泡茶喝，茶喝完
以上结果，烧水线程为 pool- 1 - thread- 1 ，清洗线程为 pool- 1 - thread- 2 ，在二者完成之前，泡茶喝
线程已经执行完了。泡茶喝的工作在异步回调方法 drinkTea () 中执行，执行的线程并不是“泡茶喝”
线程，而是烧水线程和清洗线程。

###### 9. 5. 5 Guava 异步回调和 Java 异步调用的区别

总结一下 Guava 异步回调和 Java 的 FutureTask 异步调用的区别，具体如下：
1 ）FutureTask 是主动调用的模式，“调用线程”主动获得异步结果，在获取异步结果时处于
阻塞状态，并且会一直阻塞，直到拿到异步线程的结果。
2 ）Guava 是异步回调模式，“调用线程”不会主动去获得异步结果，而是准备好回调函数，
并设置好回调钩子；执行回调函数的并不是“调用线程”自身，回调函数的执行者是“被调用线程”，
“调用线程”在执行完自己的业务逻辑后就已经结束了。当回调函数被执行时，“调用线程”已经
结束很久了。

```
9. 3 节为什么将 FutureTask 称为异步调用之重武器呢？这里为大家揭晓答案。主要
有两个原因： 1 ）和异步回调模式相比，使用 FutureTask 获取结果时，调用线程（如泡茶线程）
多少存在阻塞； 2 ）使用 FutureTask 又涉及三四个类或接口的使用，与 join 相比，使用起来烦
琐多了。所以，本书特将其称为异步调用之重武器。
```

432 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

#### 9. 6 Netty 的异步回调模式

Netty 官方文档说明 Netty 的网络操作都是异步的。Netty 源码中大量使用了异步回调处理模式。
在 Netty 的业务开发层面，处于 Netty 应用的 Handler 处理程序中的业务处理代码也都是异步执行的。
所以，了解 Netty 的异步回调，无论是 Netty 应用开始还是源码级开发都是十分重要的。
Netty 和 Guava 一样，实现了自己的异步回调体系：Netty 继承和扩展了 JDKFuture 系列异步回调
的 API，定义了自身的 Future 系列接口和类，实现异步任务的监控、异步执行结果的获取。
总的来说，Netty 对 JavaFuture 异步任务的扩展如下：
继承 Java 的 Future 接口得到一个新的属于 Netty 自己的 Future 异步任务接口；该接口对原有的接口
进行了增强，使得 Netty 异步任务能够非阻塞地处理回调结果。注意，Netty 没有修改 Future 的名称，
只是调整了所在的包名，Netty 的 Future 类的包名和 Java 的 Future 接口的包不同。
引入了一个新接口——GenericFutureListener，用于表示异步执行完成的监听器。这个接口和
Guava 的 FutureCallbak 回调接口不同。Netty 使用了监听器的模式，异步任务执行完成后的回调逻辑
抽象成了 Listener 监听器接口。可以将 Netty 的 GenericFutureListener 监听器接口加入 Netty 异步任务
Future 中，实现对异步任务执行状态的事件监听。
总的来说，在异步非阻塞回调的设计思路上，Netty 和 Guava 是一致的。对应关系为：
1 ）Netty 的 Future 接口可以对应到 Guava 的 ListenableFuture 接口。
2 ）Netty 的 GenericFutureListener 接口可以对应到 Guava 的 FutrueCallback 接口。

###### 9. 6. 1 GenericFutureListener 接口详解

前面提到，和 Guava 的 FutrueCallback 一样，Netty 新增了一个接口，用来封装异步非阻塞回调
的逻辑，那就是 GenericFutureListener 接口。
GenericFutureListener 位于 io. netty. util. concurrent 包中，源码如下：
packageio. netty. util. concurrent;
importjava. util. EventListener;
publicinterfaceGenericFutureListener<FextendsFuture<?>>extendsEventListener{
//监听器的回调方法
voidoperationComplete (Fvar 1 ) throwsException;
}
GenericFutureListener 拥有一个回调方法 operationComplete ()，表示异步任务操作完成。在 Future
异步任务执行完成后将回调此方法。大多数情况下，Netty 的异步回调的代码编写在
GenericFutureListener 接口的实现类中的 operationComplete () 方法中。
说明一下，GenericFutureListener 的父接口 EventListener 是一个空接口，没有任何抽象方法，是
一个仅仅具有标识作用的接口。

###### 9. 6. 2 Netty 的 Future 接口详解

Netty 也对 Java 的 Future 接口进行了扩展，并且名称没有变，还是被称为 Future 接口，实现在
io. netty. util. concurrent 包中。


```
第 9 章异步回调模式 | 433
```
和 Guava 的 ListenableFuture 一样，Netty 的 Future 接口扩展了一系列方法，对执行的过程进行监
控，对异步回调完成事件进行 Listen 监听并且回调。Netty 的 Future 的源码如下：
publicinterfaceFuture<V> extends java. util. concurrent. Future<V>{
booleanisSuccess (); //判断异步执行是否成功
booleanisCancellable (); //判断异步执行是否取消
Throwablecause (); //获取异步任务异常的原因
//增加异步任务执行完成 Listener 监听器
Future<V>addListener (GenericFutureListener<?extendsFuture<?superV>>listener);
//移除异步任务执行完成 Listener 监听器
Future<V>removeListener (GenericFutureListener<?extendsFuture<?superV>>listener);
...
}
Netty 的 Future 接口一般不会直接使用，使用过程中会使用其他的子接口。Netty 有一系列的子
接口，代表不同类型的异步任务，如 ChannelFuture 接口。
ChannelFuture 子接口表示 Channel 通道 I/O 操作的异步任务；如果在 Channel 的异步 I/O 操作完成
后，需要执行回调操作，就需要使用到 ChannelFuture 接口。

###### 9. 6. 3 ChannelFuture 的使用

在 Netty 网络编程中，网络连接通道的输入、输出处理都是异步进行的，都会返回一个
ChannelFuture 接口的实例。通过返回的异步任务实例，可以为其增加异步回调的监听器。在异步任
务真正完成后，回调执行。
Netty 的网络连接的异步回调，实例代码如下：
//connect 是异步的，仅仅是提交异步任务
ChannelFuturefuture=bootstrap.connect (
newInetSocketAddress ("www.manning.com", 80 ));
//connect 的异步任务真正执行完成后，future 回调监听器会执行
future.addListener (newChannelFutureListener () {
@Override
publicvoidoperationComplete (ChannelFuturechannelFuture)
throwsException {
if (channelFuture.isSuccess ()){
System.out.println ("Connectionestablished");
} else {
System.err.println ("Connectionattemptfailed");
channelFuture.cause (). printStackTrace ();
}
}
});
GenericFutureListener 接口在 Netty 中是一个基础类型接口。在网络编程的异步回调中，一般使
用 Netty 中提供的某个子接口，如 ChannelFutureListener 接口。在上面的代码中，使用到的是这个子
接口。

###### 9. 6. 4 Netty 的出站和入站异步回调

```
Netty 的出站和入站操作都是异步的。这里异步回调的方法和前面 Netty 建立的异步回调是一样的。
```

434 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

下面以经典的 NIO 出站操作 write 为例说明 ChannelFuture 的使用。
在 write 操作调用后，Netty 并没有立即完成对 JavaNIO 底层连接的写入操作，底层的写入操作是异
步执行的，代码如下：
//write () 输出方法，返回的是一个异步任务
ChannelFuturefuture=ctx.channel (). write (msg);
//为异步任务加上监听器
future.addListener (
newChannelFutureListener ()
{
@Override
publicvoidoperationComplete (ChannelFuturefuture)
{
//write 操作完成后的回调代码
}
});
在 write 操作完成后立即返回，返回的是一个 ChannelFuture 接口的实例。通过这个实例可以绑
定异步回调监听器，编写异步回调的逻辑。
如果大家运行以上的 EchoServer 案例会发现一个很大的问题：客户端接收到的回写信息和发送
到服务器的信息不是一一对应输出的。看到的比较多的情况是：客户端发出很多次信息后，客户端
才收到一次服务器的回写。
这是什么原因呢？这就是网络通信中的粘包/半包问题。对于这个问题的解决方案，在后面会
做非常详细的解答，这里暂时搁置。粘包/半包问题的出现说明了一个问题：仅仅基于 Java 的 NIO 开
发一套高性能、没有 Bug 的通信服务器程序远远没有大家想象的简单，有一系列的坑、一大堆的基
础问题等着大家解决。
在进行大型的 Java 通信程序的开发时，尽量采用一些实现了成熟、稳定的基础通信的 Java 开源
中间件（如 Netty）。这些中间件已经帮助大家解决了很多的基础问题，如前面出现的粘包/半包
问题。
至此，大家已经学习了 JavaNIO、Reactor 模式、Future 模式，这些都是学习 Netty 应用开发的
基础。

#### 9. 7 异步回调模式小结

随着高并发系统越来越多，异步回调模式愈发重要。在 Netty 源码中大量使用了异步回调技术，
所以在开始介绍 Netty 之前，用整整一章的内容非常详细、由浅入深地为大家介绍了异步回调模式。
本章首先为大家介绍了 Java 的 join 闷葫芦式的异步阻塞，然后介绍了 Java 的 FutureTask 阻塞式地
获取异步任务结果，最后介绍了 Guava 和 Netty 的异步回调方式。
Guava 和 Netty 的异步回调是非阻塞的，而 Java 的 join、FutureTask 都是阻塞的。


# 第 10 章

## CompletableFuture 异步回调

很多语言（如 JavaScript）提供了异步回调，一些 Java 中间件（如 Netty、Guava）也提供了异步
回调 API，为开发者带来更好的异步编程工具。Java 8 提供一个新的、具备异步回调能力的工具类
——CompletableFuture，该类实现了 Future 接口，还具备函数式编程的能力。

#### 10. 1 CompletableFuture 详解

CompletableFuture 是 JDK 1. 8 引入的实现类，该类实现了 Future 和 CompletionStage 两个接口。该
类的实例作为一个异步任务，可以在自己异步执行完成之后触发一些其他的异步任务，从而达到异
步回调的效果。

###### 10. 1. 1 CompletableFuture 的 UML 类关系

```
CompletableFuture 的 UML 类关系图如图 10 - 1 所示。
```
图 10 - 1 CompletableFuture 的 UML 类关系图
对于 Future 接口，大家已经非常熟悉了，接下来介绍一下 CompletionStage 接口。CompletionStage
代表异步计算过程中的某一个阶段，一个阶段完成以后可能会进入另一个阶段。一个阶段可以理解
为一个子任务，每个子任务会包装一个 Java 函数式接口实例，表示该子任务所要执行的操作。


436 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

###### 10. 1. 2 CompletionStage 接口

顾名思义，Stage 是阶段的意思。CompletionStage 代表某个同步或者异步计算的一个阶段，或
者是一系列异步任务中的一个子任务（或者阶段性任务）。
每个 CompletionStage 子任务所包装的可以是一个 Function、Consumer 或者 Runnable 函数式接口
实例。这三个常用的函数式接口的特点如下：

（ 1 ）Function
Function 接口的特点是：有输入、有输出。包装了 Function 实例的 CompletionStage 子任务需要
一个输入参数，并会产生一个输出结果到下一步。

（ 2 ）Runnable
Runnable 接口的特点是：无输入、无输出。包装了 Runnable 实例的 CompletionStage 子任务既不
需要任何输入参数，又不会产生任何输出。

（ 3 ）Consumer
Consumer 接口的特点是：有输入、无输出。包装了 Consumer 实例的 CompletionStage 子任务需
要一个输入参数，但不会产生任何输出。
多个 CompletionStage 构成了一条任务流水线，一个环节执行完成了就可以将结果移交给下一
个环节（子任务）。多个 CompletionStage 子任务之间可以使用链式调用，下面是一个简单的例子：
oneStage.thenApply (x->square (x))
.thenAccept (y->System.out.println (y))
.thenRun (()->System.out.println ())
对以上例子中的 CompletionStage 子任务说明如下：
1 ）oneStage 是一个 CompletionStage 子任务，这是一个前提。
2 ）“x->square (x)”是一个 Function 类型的 Lambda 表达式，被 thenApply 方法包装成了一个
CompletionStage 子任务，该子任务需要接收一个参数 x，然后会输出一个结果——x 的平方值。
3 ）“y->System.out.println (y)”是一个 Consumer 类型的 Lambda 表达式，被 thenAccept () 方法包
装成了一个 CompletionStage 子任务，该子任务需要上一个子任务的输出值，但是此子任务并没有输出。
4 ）“()->System.out.println ()”是一个 Runnable 类型的 Lambda 表达式，被 thenRun () 方法包装成
了一个 CompletionStage 子任务，既不需要上一个子任务的输出值，又不产生结果。

CompletionStage 代表异步计算过程中的某一个阶段，一个阶段完成以后可能会触发另一个阶
段。虽然一个子任务可以触发其他子任务，但是并不能保证后续子任务的执行顺序。

###### 10. 1. 3 使用 runAsync 和 supplyAsync 创建子任务

CompletionStage 子任务的创建是通过 CompletableFuture 完成的。CompletableFuture 类提供了非
常强大的 Future 的扩展功能来帮助我们减少异步编程的复杂性，提供了函数式编程的能力来帮助我
们通过回调的方式处理计算结果，也提供了转换和组合 CompletionStage () 的方法。
CompletableFuture 定义了一组方法用于创建 CompletionStage 子任务（或者阶段性任务），基础
的方法如下：


```
第 4 章可见性与有序性原理 | 437
```
//子任务包装一个 Runnable 实例，并使用 ForkJoinPool.commonPool () 线程池来执行
publicstaticCompletableFuture<Void>runAsync (Runnablerunnable)
//子任务包装一个 Runnable 实例，并调用指定的 executor 线程池来执行
publicstaticCompletableFuture<Void>runAsync (Runnablerunnable, Executorexecutor)
//子任务包装一个 Supplier 实例，并调用 ForkJoinPool.commonPool () 线程池来执行
publicstatic<U>CompletableFuture<U>supplyAsync (Supplier<U>supplier)
//子任务包装一个 Supplier 实例，并调用指定的 executor 线程池来执行
publicstatic<U>CompletableFuture<U>supplyAsync (
Supplier<U>supplier, Executorexecutor)
在使用 CompletableFuture 创建 CompletionStage 子任务时，如果没有指定 Executor 线程池，在默
认情况下 CompletionStage 会使用公共的 ForkJoinPool 线程池。
下面是两个创建 CompletionStage 子任务的简单示例：
packagecom. crazymakercircle. completableFutureDemo;
//省略 import
publicclassCompletableFutureDemo
{
//创建一个无输入值、无返回值的异步子任务
@Test
publicstaticvoidrunAsyncDemo () throwsException
{
CompletableFuture<Void>future=CompletableFuture. **runAsync** (()->
{
sleepSeconds ( 1 );//模拟执行 1 秒
Print.tcfo ("runend...");
});
//等待异步任务执行完成，现时等待 2 秒
future.get ( 2 ,TimeUnit. SECONDS);
}
//创建一个无输入值、有返回值的异步子任务
@Test
publicstaticvoidsupplyAsyncDemo () throwsException
{
CompletableFuture<Long>future=CompletableFuture.supplyAsync (()->
{
longstart=System.currentTimeMillis ();
sleepSeconds ( 1 ); //模拟执行 1 秒
Print.tcfo ("runend...");
returnSystem.currentTimeMillis ()-start;
});
//等待异步任务执行完成，现时等待 2 秒
longtime=future.get ( 2 ,TimeUnit. SECONDS);
Print.tcfo ("异步执行耗时（秒）="+time/ 1000 );
}
//省略其他代码
}

###### 10. 1. 4 设置的子任务回调钩子

可以为 CompletionStage 子任务设置特定的回调钩子，当计算结果完成或者抛出异常的时候，
可以执行这些特定的回调钩子。
设置子任务回调钩子的主要函数如下：


438 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
//设置子任务完成时的回调钩子
publicCompletableFuture<T>whenComplete (
BiConsumer<?superT,?superThrowable>action)
//设置子任务完成时的回调钩子，可能不在同一线程执行
publicCompletableFuture<T>whenCompleteAsync (
BiConsumer<?superT,?superThrowable>action)
//设置的子任务完成时的回调钩子，提交给线程池 executor 执行
publicCompletableFuture<T>whenCompleteAsync (
BiConsumer<?superT,?superThrowable>action,
Executorexecutor)
//设置的异常处理的回调钩子
publicCompletableFuture<T>exceptionally (Function<Throwable,?extendsT>fn)
下面是一个为 CompletionStage 子任务设置完成钩子和异常钩子的简单示例：
packagecom. crazymakercircle. completableFutureDemo;
//省略 import
publicclassCompletableFutureDemo
{
@Test
publicvoidwhenCompleteDemo () throwsException
{
//创建异步任务
CompletableFuture<Void>future=CompletableFuture.runAsync (()->
{
sleepSeconds ( 1 ); //模拟执行 1 秒
Print.tco ("抛出异常！");
thrownewRuntimeException ("发生异常");
});
//设置异步任务执行完成后的回调钩子
future.whenComplete (newBiConsumer<Void,Throwable>()
{
@Override
publicvoidaccept (Voidt, Throwableaction)
{
Print.tco ("执行完成！");
}
});
//设置异步任务发生异常后的回调钩子
future.exceptionally (newFunction<Throwable,Void>()
{
@Override
publicVoidapply (Throwablet)
{
Print.tco ("执行失败！"+t.getMessage ());
returnnull;
}
});
//获取异步任务的结果
future.get ();
}
//省略其他代码
}
运行程序，结果如下：
[ForkJoinPool. commonPool-worker- 1 ]：抛出异常！
[main]：执行完成！
```

```
第 4 章可见性与有序性原理 | 439
```
[ForkJoinPool. commonPool-worker- 1 ]：执行失败！java. lang. RuntimeException: 发生异常
调用 cancel () 方法取消 CompletableFuture 时，任务被视为异常完成，completeExceptionally () 方法
所设置的异常回调钩子也会被执行。
如果没有设置异常回调钩子，发生内部异常时可能会发生两种情况：
1 ）在调用 get () 和 get (long, TimeUnit) 方法启动任务时，如果遇到内部异常，get () 方法就会抛出
ExecutionException（执行异常）。
2 ）在使用 join () 和 getNow (T) 启动任务时（大多数情况下都是如此），如果遇到内部异常，join ()
和 getNow (T) 方法就会抛出 CompletionException。

###### 10. 1. 5 调用 handle () 方法统一处理异常和结果

除了通过 whenComplete、exceptionally 设置完成钩子、异常钩子之外，还可以调用 handle () 方法
统一处理结果和异常。
handle () 方法有三个重载版本，声明如下：
//在执行任务的同一个线程中处理异常和结果
public<U>CompletionStage<U>handle (BiFunction<?superT,Throwable,?extendsU>fn);
//可能不在执行任务的同一个线程中处理异常和结果
public<U>CompletionStage<U>handleAsync (
BiFunction<?superT,Throwable,?extendsU>fn);
//在指定线程池 executor 中处理异常和结果
public<U>CompletionStage<U>handleAsync (
BiFunction<?superT,Throwable,?extendsU>fn,
Executorexecutor);
handle () 方法的示例代码如下：
packagecom. crazymakercircle. completableFutureDemo;
//省略 import
publicclassCompletableFutureDemo
{
@Test
publicvoidhandleDemo () throwsException
{
CompletableFuture<Void>future=CompletableFuture.runAsync (()->
{
sleepSeconds ( 1 ); //模拟执行 1 秒
Print.tco ("抛出异常！");
thrownewRuntimeException ("发生异常");
//Print.tco ("runend...");
});
//统一处理异常和结果
future.handle (newBiFunction<Void,Throwable,Void>()
{
@Override
publicVoidapply (Voidinput, Throwablethrowable)
{
if (throwable==null)
{
Print.tcfo ("没有发生异常！");
}else


440 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
{
Print.tcfo ("sorry, 发生了异常！");
}
returnnull;
}
});
future.get ();
}
//省略其他代码
}
运行程序，结果如下：
[ForkJoinPool. commonPool-worker- 1 ]：抛出异常！
[ForkJoinPool. commonPool-worker- 1 |CompletableFutureDemo$ 3 .apply]：sorry, 发生了异常！
```
###### 10. 1. 6 线程池的使用

默认情况下，通过静态方法 runAsync ()、supplyAsync () 创建的 CompletableFuture 任务会使用公共
的 ForkJoinPool 线程池，默认的线程数是 CPU 的核数。当然，它的线程数可以通过以下 JVM 参数设置：
option:-Djava. util. concurrent. ForkJoinPool. common. parallelism
问题是：如果所有 CompletableFuture 共享一个线程池，那么一旦有任务执行一些很慢的 IO 操作，
就会导致线程池中所有线程都阻塞在 IO 操作上，造成线程饥饿，进而影响整个系统的性能。所以，
强烈建议大家根据不同的业务类型创建不同的线程池，以避免互相干扰。第 1 章为大家介绍了三种
线程池：IO 密集型任务线程池、CPU 密集型任务线程池和混合型任务线程池，大家可以根据不同的
任务类型确定线程池的类型和线程数。
作为演示，这里使用混合型任务线程池执行 CompletableFuture 任务，具体的代码如下：
packagecom. crazymakercircle. completableFutureDemo;
//省略 import
publicclassCompletableFutureDemo
{
@Test
publicvoidthreadPoolDemo () throwsException
{
//混合线程池
ThreadPoolExecutorpool=ThreadUtil.getMixedTargetThreadPool ();
CompletableFuture<Long>future=CompletableFuture.supplyAsync (()->
{
Print.tco ("runbegin...");
longstart=System.currentTimeMillis ();
sleepSeconds ( 1 ); //模拟执行 1 秒
Print.tco ("runend...");
returnSystem.currentTimeMillis ()-start;
}, pool);
//等待异步任务执行完成，限时等待 2 秒
longtime=future.get ( 2 ,TimeUnit. SECONDS);
Print.tco ("异步执行耗时（秒）="+time/ 1000 );
}
//省略其他代码
}


```
第 4 章可见性与有序性原理 | 441
```
```
运行程序，结果如下：
[apppool- 1 - mixed- 1 ]：runbegin...
[apppool- 1 - mixed- 1 ]：runend...
[main]：异步执行耗时（秒）= 1
```
#### 10. 2 异步任务的串行执行

如果两个异步任务需要串行（当一个任务依赖另一个任务）执行，可以通过 CompletionStage
接口的 thenApply ()、thenAccept ()、thenRun () 和 thenCompose () 四个方法来实现。

###### 10. 2. 1 thenApply () 方法

thenApply 方法有三个重载版本，声明如下：
//后一个任务与前一个任务在同一个线程中执行
public<U>CompletableFuture<U>thenApply (Function<?superT,?extendsU>fn)
//后一个任务与前一个任务不在同一个线程中执行
public<U>CompletableFuture<U>thenApplyAsync (Function<?superT,?extendsU>fn)
//后一个任务在指定的 executor 线程池中执行
public<U>CompletableFuture<U>thenApplyAsync (
Function<?superT,?extendsU>fn, Executorexecutor)
thenApply 的三个重载版本有一个共同的参数 fn，该参数表示待串行执行的第二个异步任务，
其类型为 Function。fn 的类型声明涉及两个泛型参数，具体如下：

```
 泛型参数 T：上一个任务所返回结果的类型。
 泛型参数 U：当前任务的返回类型。
作为示例，调用 thenApply 分两步计算 ( 10 + 10 )* 2 ，代码如下：
packagecom. crazymakercircle. completableFutureDemo;
//省略 import
publicclassCompletableFutureDemo
{
@Test
publicvoidthenApplyDemo () throwsException
{
CompletableFuture<Long>future=
CompletableFuture.supplyAsync (newSupplier<Long>()
{
@Override
publicLongget ()
{
longfirstStep= 10 L+ 10 L;
Print.tco ("firstStepoutcomeis"+firstStep);
returnfirstStep;
}
}). thenApplyAsync (newFunction<Long,Long>()
{
@Override
publicLongapply (LongfirstStepOutCome)//传入第一步的结果
{
```

442 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

longsecondStep=firstStepOutCome* 2 ;
Print.tco ("secondStepoutcomeis"+secondStep);
returnsecondStep;
}
});
longresult=future.get ();
Print.tco ("outcomeis"+result);
}
//省略其他代码
}
运行以上代码，结果如下：
[ForkJoinPool. commonPool-worker- 1 ]：firstStepoutcomeis 20
[ForkJoinPool. commonPool-worker- 1 ]：secondStepoutcomeis 40
[main]：outcomeis 40
thenApply 系列函数的回调参数为 fn，它的类型为接口 Function<T,R>，该接口的代码如下：
@FunctionalInterface
publicinterfaceFunction<T,R>{
Rapply (Tt);
}
Function<T,R>接口既能接收参数又支持返回值，所以 thenApply 可以将前一个任务的结果通过
Function 的 Rapply (Tt) 方法传递给第二个任务，并且能输出第二个任务的执行结果。

###### 10. 2. 2 thenRun () 方法

thenRun () 与 thenApply () 方法不同的是，不关心任务的处理结果。只要前一个任务执行完成，
就开始执行后一个串行任务。
thenApply () 方法也有三个重载版本，声明如下：
//后一个任务与前一个任务在同一个线程中执行
publicCompletionStage<Void>thenRun (Runnableaction);
//后一个任务与前一个任务可以不在同一个线程中执行
publicCompletionStage<Void>thenRunAsync (Runnableaction);
//后一个任务在 executor 线程池中执行
publicCompletionStage<Void>thenRunAsync (Runnableaction, Executorexecutor);
从方法的声明可以看出，thenRun () 方法同 thenApply () 方法类似；不同的是前一个任务处理完
成后，thenRun () 并不会把计算的结果传给后一个任务，而且后一个任务也没有结果输出。
thenRun 系列方法中的 action 参数是 Runnable 类型的，所以 thenRun () 既不能接收参数又不支持返
回值。

###### 10. 2. 3 thenAccept () 方法

thenAccept () 方法对 thenRun ()、thenApply () 的特点进行了折中，使用此方法时一个任务可以接
收（或消费）前一个任务的处理结果，但是后一个任务没有结果输出。
thenAccept () 方法有三个重载版本，声明如下：
//后一个任务与前一个任务在同一个线程中执行


```
第 4 章可见性与有序性原理 | 443
```
publicCompletionStage<Void>thenAccept (Consumer<?superT>action);
//后一个任务与前一个任务不在同一个线程中执行
publicCompletionStage<Void>thenAcceptAsync (Consumer<?superT>action);
//后一个任务在指定的 executor 线程池中执行
publicCompletionStage<Void>thenAcceptAsync (
Consumer<?superT>action, Executorexecutor);
thenAccept 系列方法的回调参数为 action，它的类型为 Consumer<?superT>接口，该接口的代
码如下：
@FunctionalInterface
publicinterfaceConsumer<T>{
voidaccept (Tt);
}
Consumer<T>接口的 accept () 可以接收一个参数，但是不支持返回值，所以 thenAccept () 可以将
前一个任务的结果及该阶段性的结果通过 voidaccept (Tt) 方法传递到下一个任务。但是
Consumer<T>接口的 accept () 方法没有返回值，所以 thenAccept () 也不能提供第二个任务的执行结果。

###### 10. 2. 4 thenCompose () 方法

thenCompose () 方法在功能上与 thenApply ()、thenAccept ()、thenRun () 一样，可以对两个任务进
行串行的调度操作，第一个任务操作完成时，将其结果作为参数传递给第二个任务。
thenCompose () 方法有三个重载版本，声明如下：
public<U>CompletableFuture<U>thenCompose (
Function<?superT,?extendsCompletionStage<U>>fn);
public<U>CompletableFuture<U>thenComposeAsync (
Function<?superT,?extendsCompletionStage<U>>fn);
public<U>CompletableFuture<U>thenComposeAsync (
Function<?superT,?extendsCompletionStage<U>>fn,
Executorexecutor);
thenCompose () 方法要求第二个任务的返回值是一个 CompletionStage 异步实例。因此，可以调
用 CompletableFuture.supplyAsync () 方法将第二个任务所要调用的普通异步方法包装成一个
CompletionStage 异步实例。
作为演示，使用 thenCompose 分两步计算 ( 10 + 10 )* 2 ，代码如下：
packagecom. crazymakercircle. completableFutureDemo;
//省略 import
{
@Test
publicvoidthenComposeDemo () throwsException
{
CompletableFuture<Long>future=
CompletableFuture.supplyAsync (newSupplier<Long>()
{
@Override
publicLongget ()
{
longfirstStep= 10 L+ 10 L;
Print.tco ("firstStepoutcomeis"+firstStep);


444 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

returnfirstStep;
}
}). thenCompose (newFunction<Long,CompletionStage<Long>>()
{
@Override
publicCompletionStage<Long>apply (LongfirstStepOutCome)
{
//重点：将第二个任务所要调用的普通异步方法包装成一个 CompletionStage 异步实例
returnCompletableFuture.supplyAsync (newSupplier<Long>()
{
//两个任务所要调用的普通异步方法
@Override
publicLongget ()
{
longsecondStep=firstStepOutCome* 2 ;
Print.tco ("secondStepoutcomeis"+secondStep);
returnsecondStep;
}
});
}
});
longresult=future.get ();
Print.tco ("outcomeis"+result);
}
//省略其他代码
}
这段程序的执行结果与使用 thenApply () 分两步计算 ( 10 + 10 )* 2 的结果是一样的。但是，
thenCompose () 所返回的不是第二个任务所要执行的普通异步方法 Supplier<Long>. get () 的直接计算
结果，而是调用 CompletableFuture.supplyAsync () 方法将普通异步方法 Supplier<Long>. get () 包装成了
一个 CompletionStage 异步实例并返回。

###### 10. 2. 5 4 个任务串行方法的区别

thenApply ()、thenRun ()、thenAccept () 这三个方法的不同之处主要在于其核心参数 fn、action、
consumer 的类型不同，分别为 Function<T,R>、Runnable、Consumer<?superT>类型。
但是，thenCompose () 方法与 thenApply () 方法有本质的不同：
1 ）thenCompose () 的返回值是一个新的 CompletionStage 实例，可以持续用来进行下一轮
CompletionStage 任务的调度。
具体来说，thenCompose () 返回的是包装了普通异步方法的 CompletionStage 任务实例，通过该
实例还可以进行下一轮 CompletionStage 任务的调度和执行，比如可以持续进行 CompletionStage 链式
（或者流式）调用。
2 ）thenApply () 的返回值简单多了，直接就是第二个任务的普通异步方法的执行结果，其返回
类型与第二步执行的普通异步方法的返回类型相同，通过 thenApply () 所返回的值不能进行下一轮
CompletionStage 链式（或者流式）调用。


```
第 4 章可见性与有序性原理 | 445
```
#### 10. 3 异步任务的合并执行

如果某个任务同时依赖另外两个异步任务的执行结果，就需要对另外两个异步任务进行合并。
以泡茶喝为例，“泡茶喝”任务需要对“烧水”任务与“清洗”任务进行合并。
对两个异步任务的合并可以通过 CompletionStage 接口的 thenCombine ()、runAfterBoth ()、
thenAcceptBoth () 三个方法来实现。这三个方法的不同之处主要在于这三类方法的核心参数 fn、action、
consumer 的类型不同，分别为 Function<T,R>、Runnable、Consumer<?superT>类型。

###### 10. 3. 1 thenCombine () 方法

thenCombine () 会在两个 CompletionStage 任务都执行完成后，一块来处理两个任务的执行结果。
//合并第二步任务的 CompletionStage 实例，返回第三步任务的 CompletionStage
public<U,V>CompletionStage<V>thenCombine (
CompletionStage<?extendsU>other,//待合并 CompletionStage 实例
BiFunction<?superT,?superU,?extendsV>fn);//第三步的逻辑
//不一定在同一个线程中执行第三步任务的 CompletionStage 实例
public<U,V>CompletionStage<V>thenCombineAsync (
CompletionStage<?extendsU>other,
BiFunction<?superT,?superU,?extendsV>fn);
//第三步任务的 CompletionStage 实例在指定的 executor 线程池中执行
public<U,V>CompletionStage<V>thenCombineAsync (
CompletionStage<?extendsU>other,
BiFunction<?superT,?superU,?extendsV>fn,
Executorexecutor);
thenCombine () 方法的调用者为第一步的 CompletionStage 实例；该方法的第一个参数为第二步
的 CompletionStage 实例；该方法的返回值为第三步的 CompletionStage 实例。在逻辑上，thenCombine ()
方法的功能是将第一步、第二步的结果合并到第三步上。
thenCombine 系列方法有两个核心参数：
 other 参数：表示待合并的第二步任务的 CompletionStage 实例。
 fn 参数：表示第一个任务和第二个任务执行完成后，第三步的需要执行的逻辑。
fn 参数的类型为 BiFunction<?superT,?superU,?extendsV>，该类型的声明涉及三个泛型参数，
具体如下：

```
 泛型参数 T：表示第一个任务所返回结果的类型。
 泛型参数 U：表示第二个任务所返回结果的类型。
 泛型参数 V：表示第三个任务所返回结果的类型。
BiFunction<?superT,?superU,?extendsV>的源码如下：
@FunctionalInterface
publicinterfaceBiFunction<T,U,R>{
```

446 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

Rapply (Tt, Uu);
}
通过 BiFunction 的 apply () 方法的源码可以看出，BiFunction 的前两个泛型参数 T、U 是输入参数
类型，BiFunction 的后一个泛型参数 V 是输出参数的类型。
作为示例，接下来使用 thenCombine 分三步计算 ( 10 + 10 )*( 10 + 10 )，具体的代码如下：
packagecom. crazymakercircle. completableFutureDemo;
//省略 import
publicclassCompletableFutureDemo
{
@Test
publicvoidthenCombineDemo () throwsException
{
CompletableFuture<Integer>future 1 =
CompletableFuture.supplyAsync (newSupplier<Integer>()
{
@Override
publicIntegerget ()
{
IntegerfirstStep= 10 + 10 ;
Print.tco ("firstStepoutcomeis"+firstStep);
returnfirstStep;
}
});
CompletableFuture<Integer>future 2 =
CompletableFuture.supplyAsync (newSupplier<Integer>()
{
@Override
publicIntegerget ()
{
IntegersecondStep= 10 + 10 ;
Print.tco ("secondStepoutcomeis"+secondStep);
returnsecondStep;
}
});
CompletableFuture<Integer>future 3 =future 1 .thenCombine (future 2 ,
newBiFunction<Integer,Integer,Integer>()
{
@Override
publicIntegerapply (
Integerstep 1 OutCome, Integerstep 2 OutCome)
{
returnstep 1 OutCome*step 2 OutCome;
}
});
Integerresult=future 3 .get ();
Print.tco ("outcomeis"+result);
}
//省略其他代码
}
运行程序，结果如下：
[ForkJoinPool. commonPool-worker- 1 ]：firstStepoutcomeis 20
[ForkJoinPool. commonPool-worker- 2 ]：secondStepoutcomeis 20
[main]：outcomeis 400


```
第 4 章可见性与有序性原理 | 447
```
###### 10. 3. 2 runAfterBoth () 方法

runAfterBoth () 方法跟 thenCombine () 方法不一样的是：runAfterBoth () 方法不关心每一步任务的
输入参数和处理结果。runAfterBoth () 方法也有三个重载版本，声明如下：
//合并第二步任务的 CompletionStage 实例，返回第三步任务的 CompletionStage
publicCompletionStage<Void>runAfterBoth (
CompletionStage<?>other, Runnableaction);
//不一定在同一个线程中执行第三步任务的 CompletionStage 实例
publicCompletionStage<Void>runAfterBothAsync (
CompletionStage<?>other, Runnableaction);
//第三步任务的 CompletionStage 实例在指定的 executor 线程池中执行
publicCompletionStage<Void>runAfterBothAsync (
CompletionStage<?>other, Runnableaction,
Executorexecutor);
runAfterBoth () 方法的调用者为第一步任务的 CompletionStage 实例；runAfterBoth () 方法的第一
个参数为第二步任务的 CompletionStage 实例；runAfterBoth () 方法的返回值为第三步的
CompletionStage 实例。
在逻辑上，第一步任务和第二步任务是并行执行的，thenCombine () 方法的功能是将第一步、
第二步的结果合并到第三步任务上。
与 thenCombine 系列方法的不同，runAfterBoth 系列方法的第二个参数 action 为 Runnable 类型，
表示其第一步任务、第二步任务、第三步任务既没有输入值，也没有输出值。

###### 10. 3. 3 thenAcceptBoth () 方法

thenAcceptBoth () 方法对 runAfterBoth () 方法和 thenCombine () 方法的特点进行了折中，调用该方
法，第三个任务可以接收其合并过来的第一个任务、第二个任务的处理结果，但是第三个任务（合
并任务）却不能返回结果。
thenAcceptBoth () 方法有三个重载版本，声明如下：
//合并第二步任务的 CompletionStage 实例，返回第三步任务的 CompletionStage
public<U>CompletionStage<Void>thenAcceptBoth (
CompletionStage<?extendsU>other,
BiConsumer<?superT,?superU>action);
//功能与上一个方法相同，不一定在同一个线程执行第三步任务
public<U>CompletionStage<Void>thenAcceptBothAsync (
CompletionStage<?extendsU>other,
BiConsumer<?superT,?superU>action);
//功能与上一个方法相同，在指定的 executor 线程池中执行第三步任务
public<U>CompletionStage<Void>thenAcceptBothAsync (
CompletionStage<?extendsU>other,
BiConsumer<?superT,?superU>action,
Executorexecutor);
thenAcceptBoth 系列方法的第二个参数为需要合并的第二步任务的 CompletionStage 实例。第三
个参数为第三个任务的回调函数，该参数名称为 action，其类型为 BiConsumer<?superT,?superU>
接口，该接口的代码如下：


448 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

@FunctionalInterface
publicinterfaceBiConsumer<T,U>{
voidaccept (Tt, Uu);
}
BiConsumer<?superT,?superU>接口的 accept () 方法可以接收两个参数，但是不支持返回值。
所以 thenAcceptBoth () 可以将前面的第一个任务、第二个任务的结果作为阶段性的结果进行合并。
但是 BiConsumer<T,U>的 accept () 方法没有返回值，所以 thenAccept () 不能提供第三个任务的执行结果。

###### 10. 3. 4 allOf () 等待所有的任务结束

CompletionStage 接口的 allOf () 会等待所有的任务结束，以合并所有的任务。thenCombine () 只能
合并两个任务，如果需要合并多个异步任务，可以使用 allOf ()。
一个简单的实例如下：
packagecom. crazymakercircle. completableFutureDemo;
//省略 import
publicclassCompletableFutureDemo
{
@Test
publicvoidallOfDemo () throwsException
{
CompletableFuture<Void>future 1 =
CompletableFuture.runAsync (()->Print.tco ("模拟异步任务 1 "));
CompletableFuture<Void>future 2 =
CompletableFuture.runAsync (()->Print.tco ("模拟异步任务 2 "));
CompletableFuture<Void>future 3 =
CompletableFuture.runAsync (()->Print.tco ("模拟异步任务 3 "));
CompletableFuture<Void>future 4 =
CompletableFuture.runAsync (()->Print.tco ("模拟异步任务 4 "));
CompletableFuture<Void>all=
CompletableFuture.allOf (future 1 ,future 2 ,future 3 ,future 4 );
all.join ();
}
//省略其他代码
}
运行程序，结果如下：
[ForkJoinPool. commonPool-worker- 1 ]：模拟异步任务 1
[ForkJoinPool. commonPool-worker- 4 ]：模拟异步任务 4
[ForkJoinPool. commonPool-worker- 3 ]：模拟异步任务 3
[ForkJoinPool. commonPool-worker- 2 ]：模拟异步任务 2

#### 10. 4 异步任务的选择执行

CompletableFuture 对异步任务的选择执行不是按照某种条件进行选择的，而是按照执行速度进
行选择的：前面两并行任务，谁的结果返回速度快，其结果将作为第三步任务的输入。
对两个异步任务的选择可以通过 CompletionStage 接口的 applyToEither ()、runAfterEither () 和
acceptEither () 三个方法来实现。这三个方法的不同之处在于它的核心参数 fn、action、consumer 的类
型不同，分别为 Function<T,R>、Runnable、Consumer<?superT>类型。


```
第 4 章可见性与有序性原理 | 449
```
###### 10. 4. 1 applyToEither () 方法

两个 CompletionStage 谁返回结果的速度快，applyToEither () 就用这个最快的 CompletionStage 的
结果进行下一步（第三步）的回调操作。
applyToEither () 方法有三个重载版本，声明如下：
//和 other 任务进行速度比较，最快返回的结果用于执行 fn 回调函数
public<U>CompletionStage<U>applyToEither (
CompletionStage<?extendsT>other, Function<?superT,U>fn);
//功能与上一个方法相同，不一定在同一个线程中执行 fn 回调函数
public<U>CompletionStage<U>applyToEitherAsync (
CompletionStage<?extendsT>other, Function<?superT,U>fn);
//功能与上一个方法相同，在指定线程执行 fn 回调函数
public<U>CompletionStage<U>applyToEitherAsync (
CompletionStage<?extendsT>other,
Function<?superT,U>fn, Executorexecutor);
applyToEither 系列方法的回调参数为 fn，其类型为接口 Function<T,R>，该接口的代码如下：
@FunctionalInterface
publicinterfaceFunction<T,R>{
Rapply (Tt);
}
Function<T,R>接口既能接收输入参数也支持返回值。在 applyToEither () 方法中，Function 的输
入参数为前两个 CompletionStage 中返回快的那个结果，Function 的输出值为最终的执行结果。
作为示例，接下来使用 applyToEither 随机选（ 10 + 10 ）和（ 100 + 100 ）的结果，代码如下：
packagecom. crazymakercircle. completableFutureDemo;
//省略 import
{
@Test
publicvoidapplyToEitherDemo () throwsException
{
CompletableFuture<Integer>future 1 =
CompletableFuture.supplyAsync (newSupplier<Integer>()
{
@Override
publicIntegerget ()
{
IntegerfirstStep= 10 + 10 ;
Print.tco ("firstStepoutcomeis"+firstStep);
returnfirstStep;
}
});
CompletableFuture<Integer>future 2 =
CompletableFuture.supplyAsync (newSupplier<Integer>()
{
@Override
publicIntegerget ()
{
IntegersecondStep= 100 + 100 ;
Print.tco ("secondStepoutcomeis"+secondStep);
returnsecondStep;
}
});


450 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

```
//谁返回结果快，其结果将被第三步选择到
CompletableFuture<Integer>future 3 =
future 1 .applyToEither (future 2 ,
newFunction<Integer,Integer>()
{
@Override
publicIntegerapply (IntegereitherOutCome)
{
returneitherOutCome;
}
});
Integerresult=future 3 .get ();
Print.tco ("outcomeis"+result);
}
//省略其他代码
}
运行程序，结果如下：
[ForkJoinPool. commonPool-worker- 1 ]：firstStepoutcomeis 20
[ForkJoinPool. commonPool-worker- 2 ]：secondStepoutcomeis 200
[main]：outcomeis 200
```
```
以上示例中，由于 commonPool-worker- 1 、commonPool-worker- 2 两个线程的调度
具有随机性，因此输出结果有时是 200 ，有时是 20 。
```
###### 10. 4. 2 runAfterEither () 方法

runAfterEither () 方法功能为：前面两个 CompletionStage 实例，任何一个完成了都会执行第三步
回调操作。三个任务的回调函数都是 Runnable 类型的。
runAfterEither () 方法有三个重载版本，声明如下：
//和 other 任务进行速度 PK，只要一个执行完成，就开始执行 fn 回调函数
publicCompletionStage<Void>runAfterEither (
CompletionStage<?>other, Runnableaction);
//功能与上一个函数相同，不一定在同一个线程中执行 fn 回调函数
publicCompletionStage<Void>runAfterEitherAsync (
CompletionStage<?>other, Runnableaction);
//功能与上一个函数相同，在指定线程执行 fn 回调函数
publicCompletionStage<Void>runAfterEitherAsync (
CompletionStage<?>other, Runnableaction,
Executorexecutor);
runAfterEither () 方法的调用者为第一步任务的 CompletionStage 实例；runAfterEither () 方法的第
一个参数为第二步任务的 CompletionStage 实例；runAfterEither () 方法的返回值为第三步任务的
CompletionStage 实例。
调用 runAfterEither () 方法，只要前面两个 CompletionStage 实例中的任何一个执行完成，就开始
执行第三步的 CompletionStage 实例。

###### 10. 4. 3 acceptEither () 方法

```
acceptEither () 方法对 applyToEither () 方法和 runAfterEither () 方法的特点进行了折中，两个
```

```
第 4 章可见性与有序性原理 | 451
```
CompletionStage 谁返回结果的速度快，acceptEither () 就用这个最快的 CompletionStage 的结果作为下
一步（第三步）的输入，但是第三步没有输出。
acceptEither () 方法有三个重载版本，声明如下：
//和 other 任务进行速度 PK，最快返回的结果用于执行 fn 回调函数
publicCompletionStage<Void>acceptEither (
CompletionStage<?extendsT>other,
Consumer<?superT>action);
//功能与上一个方法相同，不一定在同一个线程中执行 fn 回调函数
publicCompletionStage<Void>acceptEitherAsync (
CompletionStage<?extendsT>other,
Consumer<?superT>action);
//功能与上一个方法相同，在指定的 executor 线程池中执行第三步任务
publicCompletionStage<Void>acceptEitherAsync (
CompletionStage<?extendsT>other,
Consumer<?superT>action, Executorexecutor);
acceptEither 系列方法的第二个参数 other 为待进行速度比较的第二步任务的 CompletionStage 实
例。第三个参数为第三个任务的回调函数，该参数名称为 action，其类型为 Consumer<?superT>接
口，该接口的代码如下：
@FunctionalInterface
publicinterfaceConsumer<T>{
voidaccept (Tt);
}
Consumer<T>接口的 accept () 可以接收一个参数，但是不支持返回值，所以 acceptEither () 可以将前
面最快返回的阶段性结果通过 voidaccept (Tt) 方法传递给第三个任务。但是 Consumer<T>接口的
accept () 方法没有返回值，所以 acceptEither () 也不能提供第三个任务的执行结果。

#### 10. 5 CompletableFuture 的综合案例

```
本节基于 CompletableFuture 来实现前面介绍的泡茶喝实例和 RPC 异步调用实例。
```
###### 10. 5. 1 使用 CompletableFuture 实现泡茶喝实例

为了领略 CompletableFuture 异步编程的优势，这里用 CompletableFuture 重新实现前面曾提及的
烧水泡茶程序。首先需要完成分工方案，在下面的程序中，我们分 3 个任务：任务 1 负责洗水壶、烧
开水，任务 2 负责洗茶壶、洗茶杯和拿茶叶，任务 3 负责泡茶。其中任务 3 要等待任务 1 和任务 2 都完
成后才能开始。
基于 CompletableFuture 框架实现的泡茶喝程序，具体的代码如下：
packagecom. crazymakercircle. completableFutureDemo;
//省略 import
publicclassDrinkTea
{
privatestaticfinalintSLEEP_GAP= 3 ;//等待 3 秒
publicstaticvoidmain (String[]args)


452 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

{
//任务 1 ：洗水壶->烧开水
CompletableFuture<Boolean>hotJob=
CompletableFuture.supplyAsync (()->
{
Print.tcfo ("洗好水壶");
Print.tcfo ("烧开水");
//线程睡眠一段时间，代表烧水中
sleepSeconds (SLEEP_GAP);
Print.tcfo ("水开了");
returntrue;
});
//任务 2 ：洗茶壶->洗茶杯->拿茶叶
CompletableFuture<Boolean>washJob=
CompletableFuture.supplyAsync (()->
{
Print.tcfo ("洗茶杯");
//线程睡眠一段时间，代表清洗中
sleepSeconds (SLEEP_GAP);
Print.tcfo ("洗完了");
returntrue;
});
//任务 3 ：任务 1 和任务 2 完成后执行泡茶
CompletableFuture<String>drinkJob=
hotJob.thenCombine (washJob, (hotOk, washOK)->
{
if (hotOk&&washOK)
{
Print.tcfo ("泡茶喝，茶喝完");
return"茶喝完了";
}
return"没有喝到茶";
});
//等待任务 3 执行结果
Print.tco (drinkJob.join ());
}
}
执行程序，结果如下：
[ForkJoinPool. commonPool-worker- 2 |DrinkTea. lambda$main$ 1 ]：洗茶杯
[ForkJoinPool. commonPool-worker- 1 |DrinkTea. lambda$main$ 0 ]：洗好水壶
[ForkJoinPool. commonPool-worker- 1 |DrinkTea. lambda$main$ 0 ]：烧开水
[ForkJoinPool. commonPool-worker- 2 |DrinkTea. lambda$main$ 1 ]：洗完了
[ForkJoinPool. commonPool-worker- 1 |DrinkTea. lambda$main$ 0 ]：水开了
[ForkJoinPool. commonPool-worker- 2 |DrinkTea. lambda$main$ 2 ]：泡茶喝，茶喝完
[main]：茶喝完了
以上结果，烧水线程为 commonPool-worker- 1 ，清洗线程为 commonPool-worker- 2 。通过整体的
执行过程可以发现：

1 ）给任务分配线程的工作由框架自动完成，没有烦琐的手工维护线程的工作，当然也无须手
工维护线程。
2 ）任务之间的依赖关系能够一目了然。以下面的伪代码为例：
job 3 =job 1 .thenCombine (job 2 ,(result 1 ，result 2 )->{回调逻辑})


```
第 4 章可见性与有序性原理 | 453
```
以上伪代码能够清晰地表述“任务 3 要等待任务 1 和任务 2 都完成后才能开始”。所以，使用
CompletableFuture 框架能使得代码更简练、并发逻辑更加清晰。

###### 10. 5. 2 使用 CompletableFuture 进行多个 RPC 调用

```
使用 CompletableFuture 进行多个 RPC 调用，参考的代码如下：
packagecom. crazymakercircle. completableFutureDemo;
//省略 import
publicclassIntegrityDemo
{
/**
*模拟 RPC 调用 1
*/
publicStringrpc 1 ()
{
//睡眠 400 毫秒，模拟执行耗时
sleepMilliSeconds ( 600 );
Print.tcfo ("模拟 RPC 调用：服务器 server 1 ");
return"sth. fromserver 1 ";
}
/**
*模拟 RPC 调用 2
*/
publicStringrpc 2 ()
{
//睡眠 400 毫秒，模拟执行耗时
sleepMilliSeconds ( 600 );
Print.tcfo ("模拟 RPC 调用：服务器 server 2 ");
return"sth. fromserver 2 ";
}
@Test
publicvoidrpcDemo () throwsException
{
CompletableFuture<String>future 1 =CompletableFuture.supplyAsync (()->
{
returnrpc 1 ();
});
CompletableFuture<String>future 2 =
CompletableFuture.supplyAsync (()->rpc 2 ());
CompletableFuture<String>future 3 =
future 1 .thenCombine (future 2 ,
(out 1 ,out 2 )->
{
returnout 1 +"&"+out 2 ;
});
Stringresult=future 3 .get ();
Print.tco ("客户端合并最终的结果："+result);
}
}
运行程序，结果如下：
[ForkJoinPool. commonPool-worker- 2 |IntegrityDemo. rpc 2 ]：模拟 RPC 调用：服务器 server 2
[ForkJoinPool. commonPool-worker- 1 |IntegrityDemo. rpc 1 ]：模拟 RPC 调用：服务器 server 1
[main]：客户端合并最终的结果：sth. fromserver 1 &sth. fromserver 2
```

454 | Java 高并发核心编程卷^2 （加强版）：多线程、锁、JMM、JUC、高并发设计模式

###### 10. 5. 3 使用 RxJava 模拟 RPC 异步回调

除了使用 CompletableFuture 组件外，很多 Android 程序员会使用 RxJava 去实现 RPC 异步回调，
类似的代码如下：
packagecom. crazymakercircle. completableFutureDemo;
//省略 import
publicclassIntegrityDemo
{
//省略重复代码
@Test
publicvoidrxJavaDemo () throwsException
{
Observable<String>observable 1 =Observable.fromCallable (()->
{
returnrpc 1 ();
}). subscribeOn (Schedulers.newThread ());
Observable<String>observable 2 =
Observable.fromCallable (()->rpc 2 ())
.subscribeOn (Schedulers.newThread ());
Observable.merge (observable 1 ,observable 2 )
.observeOn (Schedulers.newThread ())
.toList ()
.subscribe (
(result)->Print.tco ("客户端合并最终的结果："+result));
sleepSeconds (Integer. MAX_VALUE);
}
}
运行程序，结果如下：
[RxNewThreadScheduler- 2 |IntegrityDemo. rpc 2 ]：模拟 RPC 调用：服务器 server 2
[RxNewThreadScheduler- 1 |IntegrityDemo. rpc 1 ]：模拟 RPC 调用：服务器 server 1
[RxNewThreadScheduler- 3 ]：客户端合并最终的结果：[sth. fromserver 1 ,sth. fromserver 2 ]

```
RxJava 在 Android 开发、SpringCloud 基础开发中得到了广泛的应用，唯一的问题
就是上手不容易，但是无论实际开发是否用到 RxJava，其原理和思想都值得大家学习。有关
RxJava 的原理和实战知识请参阅笔者的另一本书《Java 高并发核心编程卷 3 加强版：亿级
用户 WEB 应用架构与实操》。
```


```
疯狂创客圈^
```
## 硬核推荐：尼恩 Java 硬核架构班

### 又名疯狂创客圈社群 VIP

##### 详情：

##### https://www.cnblogs.com/crazymakercircle/p/9904544.html


```
疯狂创客圈^
```
#### 架构班（社群 VIP）的起源：^

最初的视频，主要是给读者加餐。很多的读者，需要一些高质量的实操、理论视频，所以，我就围绕书，和
底层，做了几个实操、理论视频，然后效果还不错，后面就做成迭代模式了。

#### 架构班（社群 VIP）的功能：^

提供高质量实操项目整刀真枪的架构指导、快速提升大家的:
 开发水平
 设计水平
 架构水平
弥补业务中 CRUD 开发短板，帮助大家尽早脱离具备 3 高能力，掌握：
 高性能
 高并发
 高可用
作为一个高质量的架构师成长、人脉社群，把所有的卷王聚焦起来，一起卷：
 卷高并发实操
 卷底层原理
 卷架构理论、架构哲学
 最终成为顶级架构师，实现人生理想，走向人生巅峰


```
疯狂创客圈^
```
#### 架构班（社群 VIP）的目的：^

 高质量的实操，大大提升简历的含金量，吸引力，增强面试的召唤率
 为大家提供九阳真经、葵花宝典，快速提升水平
 进大厂、拿高薪
 一路陪伴，提供助学视频和指导，辅导大家成为架构师
 自学为主，和其他卷王一起，卷高并发实操，卷底层原理、卷大厂面试题，争取狠卷 3 月成高手，狠卷
3 年成为顶级架构师


```
疯狂创客圈^
```
#### N 个超高并发实操项目：简历压轴、个顶个精彩


```
疯狂创客圈^
```
###### 【样章】第 17 章：横扫全网 Rocketmq 视频第 2 部曲: 工业级 rocketmq 高可用（HA）

###### 底层原理和实操

工业级 rocketmq 高可用底层原理，包含：消息消费、同步消息、异步消息、单向消息等不同消息的底层原理
和源码实现；消息队列非常底层的主从复制、高可用、同步刷盘、异步刷盘等底层原理。
工业级 rocketmq 高可用底层原理和搭建实操，包含：高可用集群的搭建。
解决以下难题：
1 、技术难题：RocketMQ 如何最大限度的保证消息不丢失的呢？RocketMQ 消息如何做到高可靠投递？
2 、技术难题：基于消息的分布式事务，核心原理不理解
3 、选型难题： kafka or rocketmq ，该娶谁？
下图链接：https://www.processon.com/view/6178e8ae0e3e7416bde9da19


```
疯狂创客圈^
```
#### 成功案例：^2 年翻^3 倍，^35 岁卷王成功转型为架构师^

详情：http://topcoder.cloud/forum.php?mod=forumdisplay&fid=43&page=1


疯狂创客圈^


疯狂创客圈^


疯狂创客圈^


```
疯狂创客圈^
```
### 简历优化后的成功涨薪案例（VIP 含免费简历优化）


疯狂创客圈^


疯狂创客圈^


疯狂创客圈^


疯狂创客圈^


```
疯狂创客圈^
```
## 修改简历找尼恩（资深简历优化专家）

 如果面试表达不好，尼恩会提供简历优化指导

 如果项目没有亮点，尼恩会提供项目亮点指导

 如果面试表达不好，尼恩会提供面试表达指导

作为 40 岁老架构师，尼恩长期承担技术面试官的角色：

 从业以来，“阅历”无数，对简历有着点石成金、改头换面、脱胎换骨的指导能力。

 尼恩指导过刚刚就业的小白，也指导过 P 8 级的老专家，都指导他们上岸。

如何联系尼恩。尼恩微信，请参考下面的地址：

语雀：https://www.yuque.com/crazymakercircle/gkkw8s/khigna
码云：https://gitee.com/crazymaker/SimpleCrayIM/blob/master/疯狂创客圈总目录.md


