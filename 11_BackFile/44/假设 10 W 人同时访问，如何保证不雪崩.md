```
疯狂创客圈^
```
# 牛逼的职业发展之路

###### 40 岁老架构尼恩用一张图揭秘: Java 工程师的高端职业发展路径，走向食物链顶端的之路

###### 链接：https://www.processon.com/view/link/618a2b62e0b34d73f7eb3cd


```
疯狂创客圈
```
# 史上最全：价值 10 W 的架构师知识图谱

###### 此图梳理于尼恩的多个 3 高生产项目：多个亿级人民币的大型 SAAS 平台和智慧城市项目

###### 链接：https://www.processon.com/view/link/60fb9421637689719d


```
疯狂创客圈
```
# 牛逼的架构师哲学

###### 40 岁老架构师尼恩对自己的 20 年的开发、架构经验总结

###### 链接：https://www.processon.com/view/link/616f801963768961e9d9aec


```
疯狂创客圈
```
# 牛逼的 3 高架构知识宇宙

###### 尼恩 3 高架构知识宇宙，帮助大家穿透 3 高架构，走向技术自由，远离中年危机

###### 链接：https://www.processon.com/view/link/635097d2e0b34d40be778ab


```
疯狂创客圈
```
# 尼恩 Java 高并发三部曲（卷 1 加强版）

###### 老版本：《Java 高并发核心编程卷 1 ：NIO、Netty、Redis、ZooKeeper》（已经过时，不建

###### 议购买）

##### 新版本：《Java 高并发核心编程卷 1 加强版 ：NIO、Netty、Redis、ZooKeeper》

 由浅入深地剖析了高并发 IO 的底层原理。

 图文并茂的介绍了 TCP、HTTP、WebSocket 协议的核心原理。

 细致深入地揭秘了 Reactor 高性能模式。

 全面介绍了 Netty 框架，并完成单体 IM、分布式 IM 的实战设计。

 详尽地介绍了 ZooKeeper、Redis 的使用，以帮助提升高并发、可扩展能力

###### 详情：https://www.cnblogs.com/crazymakercircle/p/16868827.html


```
疯狂创客圈
```
# 尼恩 Java 高并发三部曲（卷 2 加强版）

###### 老版本：《Java 高并发核心编程卷 2 ：多线程、锁、JMM、JUC、高并发设计模式》

###### （已经过时，不建议购买）

##### 新版本：《Java 高并发核心编程卷 2 加强版 ：多线程、锁、JMM、JUC、高并发设计模式》

 由浅入深地剖析了 Java 多线程、线程池的底层原理。

 总结了 IO 密集型、CPU 密集型线程池的线程数预估算法。

 图文并茂的介绍了 Java 内置锁、JUC 显式锁的核心原理。

 细致深入地揭秘了 JMM 内存模型。

 全面介绍了 JUC 框架的设计模式与核心原理，并完成其高核心组件的实战介绍。

 详尽地介绍了高并发设计模式的使用，以帮助提升高并发、可扩展能力

###### 详情参阅：https://www.cnblogs.com/crazymakercircle/p/16868827.html


```
疯狂创客圈
```
# 尼恩 Java 高并发三部曲（卷 3 加强版）

###### 老版本：《SpringCloud Nginx 高并发核心编程》（已经过时，不建议购买）

##### 新版本：《Java 高并发核心编程卷 3 加强版 ：亿级用户 Web 应用架构与实战》

 在当今的面试场景中， 3 高知识是大家面试必备的核心知识，本书基于亿级用户 3 高 Web 应用

```
的架构分析理论，为大家对 3 高架构系统做一个系统化和清晰化的介绍。
```
 从 Java 静态代理、动态代理模式入手，抽丝剥茧地解读了 Spring Cloud 全家桶中 RPC 核心原

```
理和执行过程，这是高级Java工程师面试必备的基础知识。
```
 从 Reactor 反应器模式入手，抽丝剥茧地解读了 Nginx 核心思想和各配置项的底层知识和原理，

```
这是高级Java工程师、架构师面试必备的基础知识。
```
 从观察者模式入手，抽丝剥茧地解读了 RxJava、Hystrix 的核心思想和使用方法，这也是高级

```
Java工程师、架构师面试必备的基础知识。
```
###### 详情：https://www.cnblogs.com/crazymakercircle/p/16868827.html


```
疯狂创客圈
```
# 尼恩 Java 面试宝典

###### 35 个专题（卷王专供+ 史上最全 + 2023 面试必备）

###### 详情：https://www.cnblogs.com/crazymakercircle/p/13917138.html


## 假设 10 W 人同时访问，如何保证不雪崩？

```
如果面试遇到这个问题，很多小伙伴的第一反应：
```
```
怎么可能，我们的系统，总体的用户量，不到 1 万， 怎么可能会有10W人同时访问。
```
```
这个问题，如果遇到了，只能会硬着头皮作答。
如果直接用这个疑问，去反问面试官，那么 ，面试官一定会说这小子 没有遇到过事情。
```
```
为啥呢？
```
```
因为哪怕用户不到 1 万，还是可能会有10W人同时访问。
```
```
这些人包括：
```
```
爬虫
刷子（羊毛党）
```
#### 爬虫对访问量的贡献

```
大家应该听过一句话吧，整个互联网上大概有 50%以上的流量其实是爬虫。
```
```
一个做反爬虫哥们，发现了一个极端案例，
```
```
某个页面 12000 次点击里边，98%的点击率，是爬虫贡献的。
```
```
爬虫和用户的比例是 19 比1.
```
```
那么 1W用户， 可能会对应到19W 爬虫，
那么 1W用户， 有没有 10W的 同时访问的可能呢？
```
```
因为 大量爬虫的存着， 当然有的。
```
#### 刷子用户（羊毛党）对访问量的贡献

```
“羊毛党”战术之一：开启机器人批量注册新账号，招募“新兵”。
```
```
“这是个‘昏招’，批量注册的账号很容易识别。
“羊毛党”战术之二：提前囤积账号，囤积的老账号”。
```
```
但通过注册时间、注册地与下单地比对等方式，很快识别出来。
```
```
某年的“618”电商节活动期间，某电商公司，平均每天拦截“羊毛党”账号 2000 万个。
```
```
那么 1W用户， 可能会对应到多少羊毛党用户呢？
```
```
其中，可能会包含部分 提前囤积账号
另外，在 活动执行的过程中， 还是有 可能 批量注册大量的新账号
```
```
那么 1W用户， 有没有 10W的 同时访问的可能呢？
```
```
只要有利可图，就会有 刷子用户（羊毛党），他们会通过群体人手，或者 自动化工具 ， 制造大量的瞬
间流量 。
```
```
这些自动化工具，在 1s之内， 尝试10W次。
```
page: 1/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
所以，只要是有利可图，如 秒杀等， 那么 1W用户， 有没有 10W的 同时访问的可能呢？
```
```
当然有的。
```
## 假设 10 W 人突然访问，现有架构能否扛住？

```
按照之前尼恩和大家分析的架构理论
一个系统10W人同时访问 ， 也就是：并发量为 10w Qps
```
```
那么 10w Qps ，对应到多少用户量呢?
```
```
是 一个 1 亿的用户量。
```
```
而 ，我们很多同学手上的 系统， 总体的用户量 不到 1 万，
```
```
不到 1 万的用户，对应到多少 的 吞吐量呢？
是 10 。
```
```
没错，如果 总体的用户量 不到 1 万，按照 正常估算， 吞吐量就只有 10 。
```
```
也就是说， 如果我们按照 1 万 做系统架构
```
这种架构，对于 qps 为 10 的小流量来说，可以说是小菜一碟。
page: 2/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
可以说，用牛刀 在 杀鸡。
```
```
那么，如果发生突发情况，
```
```
假设10W人突然访问，我们的架构，如何抵抗？
```
```
大家看看，上面的架构， 能抵抗吗？
```
page: 3/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


#### 接入层和服务层如何抵抗？

```
方式之一： 扩容
```
```
方式之二：限流
```
#### 首先能用到的策略： 扩容

```
大家首先会想到的策略，就是扩容。
```
```
但是，如果流量是突发的， 又不知道什么时候扩， 怎么办呢？
那么就是 自动扩容 。
```
```
自动扩容 虽然比较难，办法总是有的，只要稍微想想，就出来了。
大致有两种自动扩容方式，具体请参见 《java 高并发核心编程 卷 3 》 第 1.5.3 小节。
```
page: 4/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


#### 其次能用到的策略： 限流

```
nginx 限流
SpringCloud gateway 限流
```
```
接入层限流可以进行 nginx 限流
```
```
微服务 SpringCloud gateway 里边，
```
```
还 可以使用 redis lua进行分布式限流， 或者使用 sentinel 进行 限流，
```
```
经过 扩容和限流， 咱们的系统，应该可以扛住 10Wqps， 因为可以把流量限制到 1Wqps，甚至是 1 K
qps。
```
```
谁怪 有那么多刷子流量，或者 爬虫流量呢。
```
```
但是，限流是无奈之举。
```
page: 5/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
或者说，如果10Wqps，都是有效流量， 不能使用限流这 简单粗暴的方式 ， 而是这个 10Wqps 必须进
入到服务层。
```
#### 分布式 Redis 集群如何抵抗？

```
这个 10Wqps 必须进入到服务层。
```
```
怎么办？
服务层 倒是好说，和网关一样， 可以通过扩容解决。
```
```
所以，后面的 流量就进入 redis集群。
```
```
redis 集群一般搭建的是 3 主 3 从：
```
page: 6/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
一般来说，主节点提供服务， 从节点是做冗余的， 并不提供数据的写入服务。
```
```
redis cluster模式官方默认主节点提供读写, 从节点提供slot数据备份以及故障转移。默认情况下，从节
点并不提供数据读写服务。
```
```
单个redis 的吞吐量，一般就是 2W左右。
```
```
那么 10Wqps，访问 redis cluster，分布到 3 个节点， 还是不够。
```
```
如果 10Wqps 访问的是同一个key， 那就问题更大了。
因为 单个redis 的吞吐量，一般就是 2W左右。 怎么可能扛住 5 倍的吞吐量。
```
```
于是就很容易出现 redis cpu 100%， 请求排队， 没有响应，严重的情况 出现 redis 雪崩。
于是乎，改怎么办?
```
```
大概也有两种方案：
```
```
方法一： redis 扩容
方法二： 本地缓存
```
```
方法一 redis 扩容 可以解决 key 的访问量比较 均匀的问题。比如扩容到 10 主 10 从，就可以承担
20Wqps的 流量。
```
```
但是方法一 要求每个key的访问量 必须分布得比较均匀。如果20w qps 的流量，全部来自一个key， 则
方案一 无效。
```
```
方法二 本地缓存 可以解决 单个key 访问量 巨大的问题。这种 占据大量流量的 单个key，叫做
hotkey（热key）。
```
```
所以，接下来，还是得调整系统的架构， 加入本地缓存的 环节。
```
## 解决 10 WQps 突发流量的本地缓存架构

page: 7/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
解决 10WQps 突发流量的本地缓存架构，大致有两种：
```
```
二级缓存架构
三级缓存架构
```
#### 二级缓存架构：

```
java 本地缓存+ redis 分布式缓存，具体如下图：
```
```
先发问一级缓存caffeine ，如果 没有找到，再访问 二级缓存 redis 集群
```
#### 三级缓存架构：

```
nginx本地缓存+ java 本地缓存+ redis 分布式缓存，具体如下图：
```
page: 8/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


#### 本地缓存的优缺点

**1. 快但是量少：访问速度快，但无法进行大数据存储**
本地缓存相对于分布式缓存的好处是，由于数据不需要跨网络传输，故性能更好，

```
但是由于占用了应用进程的内存空间，如 Java 进程的 JVM 内存空间，故不能进行大数据量的数据存
储。
```
**2. 需要解决数据一致性问题：本地缓存、分布式缓存、DB 数据一致性问题**
与此同时，本地缓存只支持被该应用进程访问，一般无法被其他应用进程访问，故在应用进程的集群部
署当中，

```
如果对应的数据库数据，存在数据更新，则需要 同步更新不同部署节点的缓存数据 来包保证数据一致
性，
复杂度较高并且容易出错，如基于 rocketmq 的发布订阅机制来同步更新各个部署节点。
```
```
3.未持久化，容易丢失： 数据随应用进程的重启而丢失
```
```
由于本地缓存的数据是存储在应用进程的内存空间的，所以当应用进程重启时，本地缓存的数据会丢
失。
所以对于需要更改然后持久化的数据，需要注意及时保存，否则可能会造成数据丢失。
```
**4. 需要尽量缓存热点 key，而提升缓存的命中率**
page: 9/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
由于本地缓存太小，从而很容易被淘汰，
```
```
如果还没有来得及访问，本地缓存中的数据，就被淘汰了，那就失去了本地缓存的价值， 当然，本地缓
存的命中率也会很低。
```
#### 如何提升缓存的命中率？

```
方式 1 ： 采用更好的 缓存淘汰策略
比如caffeine中，使用了 w-tinylfu 策略。
```
```
这种策略的 缓存的命中率，比较简单的 lfu、lru 都 高出很多。
有测试表明： caffeine 比 guava 的命中率，不同场景，都会高出10%以上。
```
```
方式 2 ： 尽量识别和缓存 热点数据
简单的说，把热点数据， 加载到本地缓存。
```
## 什么是 HotKey？

```
在某个Key接收到的访问次数、显著高于其它Key时，我们可以将其称之为HotKey，
```
```
从访问量上来说，常见的HotKey如：
```
```
某Redis实例的每秒总访问量为 10000 ，而其中一个Key的每秒访问量达到了 7000 （访问次数显著
高于其它Key）
对一个拥有上千个成员且总大小为1MB的HASH Key每秒发送大量的HGETALL（带宽占用显著高于
其它Key）
对一个拥有数万个成员的ZSET Key每秒发送大量的ZRANGE（CPU时间占用显著高于其它Key）
```
```
从业务上来说， 常见的HotKey如：
```
```
1 、MySQL等数据库会被频繁访问的热数据
```
```
如爆款商品的skuId。
2 、redis的被密集访问的key
```
```
如爆款商品的各维度信息，skuId、shopId等。
```
```
3 、机器人、爬虫、刷子用户
```
```
如用户的userId、uuid、ip等。
```
```
4 、某个接口地址
如/sku/query或者更精细维度的。
```
```
注意，我们的HotKey探测框架只关心key，其实就是一个字符串，
```
page: 10/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


#### HotKey 对服务层和数据层的风险

```
在拥有大量并发用户的系统中，HotKey一直以来都是一个不可避免的问题。
```
```
或许是突然某些商品成了爆款，
```
```
或许是海量用户突然涌入某个店铺，
```
```
或许是秒杀时瞬间大量开启的爬虫用户，
突发大批机器人 以远超正常用户的速度发起极其密集的请求，这些机器人只需要很小的代价，就能
发出百倍于普通用户的请求量，从而大幅挤占正常用户的资源。
```
```
以京东为例的这些头部互联网公司，动辄某个爆品，会瞬间引入每秒上百万甚至数百万的请求，当然流
量多数会在几秒内就消失。
```
```
但就是这短短的几秒的HotKey，就会瞬间造成其所在redis分片集群瘫痪。
```
```
原因也很简单，redis作为一个单线程的结构，所有的请求到来后都会去排队，当请求量远大于自身处理
能力时，后面的请求会陷入等待、超时。
```
```
由于该redis分片完全被这个key的请求给打满，导致该分片上所有其他数据操作都无法继续提供服务，
也就是HotKey不仅仅影响自己，还会影响和它合租的数据。
```
```
这样，redis 缓存没有响应之后，相当于 redis 击穿， 请求直接转向DB
DB的吞吐量，比如会低很多，DB 就会雪崩。
```
##### 总结一下，HotKey 带来的常见问题

```
HotKey占用大量的Redis CPU时间，使其性能变差并影响其它请求；
Redis Cluster中各node流量不均衡造成Redis Cluster的分布式优势无法被Client利用，一个分片
负载很高而其它分片十分空闲从而产生读/写热点问题；
在抢购、秒杀活动中，由于商品对应库存Key的请求量过大，超出Redis处理能力造成超卖；
HotKey的请求压力数量超出Redis的承受能力造成缓存击穿，此时大量强求将直接指向后端存储，
将后端存储打挂并影响到其它业务；
```
##### HotKey 问题的根本：

```
HotKey问题归根到底就是如何找到HotKey，并将HotKey放到本地内存的问题。
只要该key在内存里，我们就能极快地来对它做逻辑，内存访问和redis访问的速度不在一个量级。
```
```
如果该key是在本地内存中，读取一个内存中的值，每秒多少个万次都是很正常的，不存在任何数据层
的瓶颈。
```
```
但问题是事先不知道HotKey在哪里？
那么，问题就来了，如何进行 HotKey的探测？
```
#### HotKey 探测关键指标

```
1 、实时性
```
```
这个很容易理解，key往往是突发性瞬间就热了，根本不给你再慢悠悠手工去配置中心添加HotKey再推
送到jvm的机会。
```
page: 11/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
它大部分时间不可预知，来得也非常迅速，可能某个商家上个活动，瞬间HotKey就出现了。如果短时
间内没能进到内存，就有redis集群被打爆的风险。
```
```
所以HotKey探测框架最重要的就是实时性，最好是某个key刚有热的苗头，在 1 秒内它就已经进到整个
服务集群的内存里了， 1 秒后就不会再去密集访问redis了。
```
```
同理，对于刷子用户也一样，刚开始刷， 1 秒内我就把它给禁掉了。
```
```
2 、准确性
```
```
这个很重要，也容易实现，累加数量，做到不误探，精准探测，保证探测出的HotKey是完全符合用户
自己设定的阈值。
3 、集群一致性
```
```
这个比较重要，尤其是某些带删除key的场景，要能做到删key时整个集群内的该key都会删掉，以避免
数据的错误。
```
```
4 、高性能
```
```
这个是核心之一，高性能带来的就是低成本，做HotKey探测目的就是为了降低数据层的负载，提升应
用层的性能，节省服务器资源。不然，大家直接去整体扩充redis集群规模就好了。
```
```
理论上，在不影响实时性的情况下，要完成实时HotKey探测，所消耗的机器资源越少，那么经济价值
就越大。
```
## 如何实现 HotKey 探测？

##### HotKey 探测方案 1 ： 流计算集群

```
通过 流式计算集群 storm/ flink 集群，进行 topkey
```
page: 12/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
java 应用将访问 记录发送到 消息队列，如 kafka
```
```
storm、flink 集群，进行top N 的计算，把top N 结果存在 redis
```
```
其中的 top N 的key，就是热点 key
```
##### HotKey 探测方案 2 ： 流计算集群

```
有赞透明多级缓存解决方案
```
##### HotKey 探测方案 3 ： 结合开源 hotkey，做热点探测

```
比如：结合京东开源hotkey，做热点探测
```
## HotKey 探测方案 2 ：有赞透明多级缓存解决方案（TMC）

#### 一、TMC 简介

##### 1-1. TMC 是什么

page: 13/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
TMC ，即“透明多级缓存（ Transparent Multilevel Cache ）”，是有赞 PaaS 团队给公司内应用提供的
整体缓存解决方案。
```
```
TMC 在通用“分布式缓存解决方案（如 CodisProxy + Redis ，如有赞自研分布式缓存系统 zanKV ）”基
础上，增加了以下功能：
```
```
应用层热点探测
应用层本地缓存
应用层缓存命中统计
```
```
以帮助应用层解决缓存使用过程中出现的热点访问问题。
```
##### 1-2. 为什么要做 TMC

```
使用有赞服务的电商商家数量和类型很多，商家会不定期做一些“商品秒杀”、“商品推广”活动，导致“营
销活动”、“商品详情”、“交易下单”等链路应用出现 缓存热点访问 的情况：
```
```
活动时间、活动类型、活动商品之类的信息不可预期，导致 缓存热点访问 情况不可提前预知；
缓存热点访问 出现期间，应用层少数 热点访问 key 产生大量缓存访问请求：冲击分布式缓存系
统，大量占据内网带宽，最终影响应用层系统稳定性；
为了应对以上问题，需要一个能够 自动发现热点 并 将热点缓存访问请求前置在应用层本地缓存 的解决
方案，这就是 TMC 产生的原因。
```
##### 1-3. 多级缓存解决方案的痛点

```
基于上述描述，我们总结了下列 多级缓存解决方案 需要解决的需求痛点：
```
```
热点探测：如何快速且准确的发现 热点访问 key ？
数据一致性：前置在应用层的本地缓存，如何保障与分布式缓存系统的数据一致性？
效果验证：如何让应用层查看本地缓存命中率、热点 key 等数据，验证多级缓存效果？
透明接入：整体解决方案如何减少对应用系统的入侵，做到快速平滑接入？
```
```
TMC 聚焦上述痛点，设计并实现了整体解决方案。
```
```
以支持“热点探测”和“本地缓存”，减少热点访问时对下游分布式缓存服务的冲击，避免影响应用服务的
性能及稳定性。
```
#### 二、 TMC 整体架构

page: 14/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
TMC 整体架构如上图，共分为三层：
```
```
存储层：提供基础的kv数据存储能力，针对不同的业务场景选用不同的存储服务（ codis / zankv /
aerospike ）；
代理层：为应用层提供统一的缓存使用入口及通信协议，承担分布式数据水平切分后的路由功能转
发工作；
应用层：提供统一客户端给应用服务使用，内置“热点探测”、“本地缓存”等功能，对业务透明；
```
#### 三、 TMC 本地缓存

##### 3-1. 如何透明

```
TMC 是如何减少对业务应用系统的入侵，做到透明接入的？
```
```
对于公司 Java 应用服务，在缓存客户端使用方式上分为两类：
```
```
基于spring.data.redis包，使用RedisTemplate编写业务代码；
基于youzan.framework.redis包，使用RedisClient编写业务代码；
```
```
不论使用以上那种方式，最终通过JedisPool创建的Jedis对象与缓存服务端代理层做请求交互。
```
page: 15/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
TMC 对原生jedis包的JedisPool和Jedis类做了改造，
```
```
在JedisPool初始化过程中, 集成TMC“热点发现”+“本地缓存”功能Hermes-SDK包的初始化逻辑，
```
```
使Jedis客户端与缓存服务端代理层交互时, 先与Hermes-SDK交互，从而完成 “热点探测”+“本地缓
存”功能的透明接入。
```
```
对于 Java 应用服务，只需使用特定版本的 jedis-jar 包，无需修改代码，即可接入 TMC 使用“热点发
现”+“本地缓存”功能，做到了对应用系统的最小入侵。
```
##### 3-2. 整体结构

```
3-2-1. 模块划分
```
```
TMC 本地缓存整体结构分为如下模块：
Jedis-Client ： Java 应用与缓存服务端交互的直接入口，接口定义与原生 Jedis-Client 无异；
Hermes-SDK ：自研“热点发现+本地缓存”功能的SDK封装， Jedis-Client 通过与它交互来集成相应
能力；
Hermes服务端集群 ：接收 Hermes-SDK 上报的缓存访问数据，进行热点探测，将热点 key 推送
给 Hermes-SDK 做本地缓存；
缓存集群 ：由代理层和存储层组成，为应用客户端提供统一的分布式缓存服务入口；
基础组件 ： etcd 集群、 Apollo 配置中心，为 TMC 提供“集群推送”和“统一配置”能力；
```
```
3-2-2. 基本流程
```
```
1 ） key 值获取
```
```
Java 应用调用 Jedis-Client 接口获取key的缓存值时， Jedis-Client 会询问 Hermes-SDK 该 key
当前是否是 热点key ；
对于 热点key ，直接从 Hermes-SDK 的 热点模块 获取热点 key 在本地缓存的 value 值，不去访
问 缓存集群 ，从而将访问请求前置在应用层；
对于非 热点key ， Hermes-SDK 会通过Callable回调 Jedis-Client 的原生接口，从 缓存集群
拿到 value 值；
```
page: 16/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
对于 Jedis-Client 的每次 key 值访问请求， Hermes-SDK 都会通过其 通信模块 将 key访问事件
异步上报给 Hermes服务端集群 ，以便其根据上报数据进行“热点探测”；
```
```
2 ）key值过期
```
```
Java 应用调用 Jedis-Client 的set() del() expire()接口时会导致对应 key 值失效， Jedis-
Client 会同步调用 Hermes-SDK 的invalid()方法告知其“ key 值失效”事件；
对于 热点key ， Hermes-SDK 的 热点模块 会先将 key 在本地缓存的 value 值失效，以达到本地
数据 强一致 。同时 通信模块 会异步将“ key 值失效”事件通过 etcd集群 推送给 Java 应用集群中其
他 Hermes-SDK 节点；
其他 Hermes-SDK 节点的 通信模块 收到 “ key 值失效”事件后，会调用 热点模块 将 key 在本地缓
存的 value 值失效，以达到集群数据 最终一致 ；
3 ）热点发现
```
```
Hermes服务端集群 不断收集 Hermes-SDK 上报的 key访问事件 ，对不同业务应用集群的缓存访
问数据进行周期性（3s一次）分析计算，以探测业务应用集群中的 热点key 列表；
对于探测到的 热点key 列表， Hermes服务端集群 将其通过 etcd集群 推送给不同业务应用集群的
Hermes-SDK 通信模块，通知其对 热点key 列表进行本地缓存；
```
```
4 ）配置读取
Hermes-SDK 在启动及运行过程中，会从 Apollo配置中心 读取其关心的配置信息（如：启动关
闭配置、黑白名单配置、etcd地址...）；
Hermes服务端集群 在启动及运行过程中，会从 Apollo配置中心 读取其关心的配置信息（如：业
务应用列表、热点阈值配置、 etcd 地址...）；
```
```
3-2-3. 稳定性
```
```
TMC本地缓存稳定性表现在以下方面：
```
```
数据上报异步化： Hermes-SDK 使用rsyslog技术对“ key 访问事件”进行异步化上报，不会阻塞
业务；
通信模块线程隔离： Hermes-SDK 的 通信模块 使用独立线程池+有界队列，保证事件上报&监听
的I/O操作与业务执行线程隔离，即使出现非预期性异常也不会影响基本业务功能；
缓存管控： Hermes-SDK 的 热点模块 对本地缓存大小上限进行了管控，使其占用内存不超过
64MB（LRU），杜绝 JVM 堆内存溢出的可能；
```
##### 3-2-4. 一致性

```
TMC 本地缓存一致性表现在以下方面：
Hermes-SDK 的 热点模块 仅缓存 热点key 数据，绝大多数非热点 key 数据由 缓存集群 存储；
热点key 变更导致 value 失效时， Hermes-SDK 同步失效本地缓存，保证 本地强一致 ；
热点key 变更导致 value 失效时， Hermes-SDK 通过 etcd集群 广播事件，异步失效业务应用集
群中其他节点的本地缓存，保证 集群最终一致 ；
```
#### 四、TMC 热点发现

##### 4-1. 整体流程

```
TMC 热点发现流程分为四步：
```
page: 17/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
数据收集 ：收集 Hermes-SDK 上报的 key 访问事件；
热度滑窗 ：对 App 的每个 Key ，维护一个时间轮，记录基于当前时刻滑窗的访问热度；
热度汇聚 ：对 App 的所有 Key ，以<key,热度>的形式进行 热度排序汇总；
热点探测 ：对 App ，从 热 Key 排序汇总 结果中选出 TopN 的热点 Key ，推送给 Hermes-SDK ；
```
##### 4-2. 数据收集

```
Hermes-SDK 通过本地rsyslog将 key访问事件 以协议格式放入 kafka ， Hermes服务端集群 的每
个节点消费 kafka 消息，实时获取 key访问事件 。
访问事件协议格式如下：
```
```
appName：集群节点所属业务应用
uniqueKey：业务应用 key 访问事件 的 key
sendTime：业务应用 key 访问事件 的发生时间
weight：业务应用 key 访问事件 的访问权值
Hermes服务端集群 节点将收集到的 key访问事件 存储在本地内存中，
```
```
内存数据结构为Map<String, Map<String, LongAdder>>，
```
```
对应业务含义映射为Map< appName , Map< uniqueKey , 热度 >>。
```
##### 4-3. 热度滑窗

```
4-3-1. 时间滑窗
```
```
Hermes服务端集群 节点，对每个App的每个 key ，维护了一个 时间轮 ：
时间轮中共 10 个 时间片 ，每个时间片记录当前 key 对应 3 秒时间周期的总访问次数；
时间轮 10 个时间片的记录累加即表示当前 key 从当前时间向前 30 秒时间窗口内的总访问次数；
```
```
4-3-2. 映射任务
```
```
Hermes服务端集群 节点，对每个 App 每 3 秒 生成一个 映射任务 ，交由节点内 “ 缓存映射线程池 ” 执
行。
```
```
映射任务 内容如下：
```
page: 18/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
对当前 App ，从Map< appName , Map< uniqueKey , 热度 >>中取出 appName 对应的Map
Map< uniqueKey , 热度 >>；
遍历Map< uniqueKey , 热度 >>中的 key ，对每个 key 取出其热度存入其 时间轮 对应的时间片
中；
```
##### 4-4. 热度汇聚

```
完成第二步“热度滑窗”后， 映射任务 继续对当前 App 进行“热度汇聚”工作：
遍历 App 的 key ，将每个 key 的 时间轮 热度进行汇总（即 30 秒时间窗口内总热度）得到探测时
刻 滑窗总热度 ；
将 < key , 滑窗总热度 > 以排序集合的方式存入 Redis 存储服务 中，即 热度汇聚结果 ；
```
##### 4-5. 热点探测

```
在前几步， 每 3 秒 一次的 映射任务 执行，对每个 App 都会产生一份当前时刻的 热度汇聚结果 ；
Hermes服务端集群 中的“热点探测”节点，对每个 App ，只需周期性从其最近一份 热度汇聚结果
中取出达到热度阈值的 TopN 的 key 列表，即可得到本次探测的 热点key列表 ；
```
```
TMC 热点发现整体流程如下图：
```
##### 4-6. 特性总结

```
4-6-1. 实时性
```
**Hermes-SDK** 基于 rsyslog + kafka 实时上报 **key 访问事件** 。
**映射任务** 3 秒一个周期完成“热度滑窗” + “热度汇聚”工作，当有 **热点访问场景** 出现时最长 3 秒即可探测
出对应 **热点 key** 。
page: 19/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
4-6-2. 准确性
```
```
key 的 热度汇聚结果 由“基于时间轮实现的滑动窗口”汇聚得到，相对准确地反应当前及最近正在发生访
问分布。
```
```
4-6-3.扩展性
```
```
Hermes服务端集群 节点无状态，节点数可基于 kafka 的 partition 数量横向扩展。
“热度滑窗” + “热度汇聚” 过程基于 App 数量，在单节点内多线程扩展。
```
#### 五、TMC 实战效果

##### 5-1. 快手商家某次商品营销活动

```
有赞商家通过快手直播平台为某商品搞活动，造成该商品短时间内被集中访问产生访问热点，活动期间
TMC 记录的实际热点访问效果数据如下：
```
```
5-1-1. 某核心应用的缓存请求&命中率曲线图
```
```
上图蓝线为应用集群调用get()方法访问缓存次数
上图绿线为获取缓存操作命中 TMC 本地缓存的次数
```
```
上图为本地缓存命中率曲线图
```
```
可以看出活动期间缓存请求量及本地缓存命中量均有明显增长，本地缓存命中率达到近 80% （即应用
集群中 80% 的缓存查询请求被 TMC 本地缓存拦截）。
```
##### 5-1-2. 热点缓存对应用访问的加速效果

page: 20/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
上图为应用接口QPS曲线
```
```
上图为应用接口RT曲线
可以看出活动期间应用接口的请求量有明显增长，由于 TMC 本地缓存的效果应用接口的 RT 反而出现下
降。
```
##### 5-2. 双十一期间部分应用 TMC 效果展示

```
5-2-1. 商品域核心应用效果
```
page: 21/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
5-2-2. 活动域核心应用效果
```
#### 六、TMC 功能展望

```
在有赞， TMC 目前已为商品中心、物流中心、库存中心、营销活动、用户中心、网关&消息等多个核
心应用模块提供服务，后续应用也在陆续接入中。
TMC 在提供“热点探测” + “本地缓存”的核心能力同时，也为应用服务提供了灵活的配置选择，应用服务
可以结合实际业务情况在“热点阈值”、“热点key探测数量”、“热点黑白名单”维度进行自由配置以达到更
好的使用效果。
```
```
配合三级缓存的使用，需要进行 热key的 探测，有赞平台通过 热key的探测和 支持，
```
```
其中：活动期间，本地缓存命中率达到近 80%的命中率 ， 并且， 响应时间，和平峰时段，没有变
化。
```
## HotKey 探测方案 3 ： 结合开源 hotkey，做热点探测

```
基于开源hotkey进行 热点探测，有很多小伙伴，在生产系统进行了 缓存系统的重构
```
page: 22/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
特性 重构系统前 使用京东hotkey重构系统后
```
```
机器资
源 高配物理机/虚拟机 普通物理机/虚拟机/容器
```
```
管控复
杂 无法控制热点，不易监控 热点数据可以监控统计，可以手动刷新
```
```
资源利
用率
```
```
资源利用率低，无论是否是热点数据都
占用资源
```
```
资源利用率高，大部分热点数据持有资
源
```
```
突发流
量
```
```
无法弹性应对突发流量 弹性应对突发流量
```
```
预发流
量 预设所有数据 只提前预设热点数据
```
```
数据一
致性
```
```
集群内数据不一致情况时常发生，出
现“横跳”现象
```
```
集群内数据一致性高，极少或不发生不
一致性情况
```
```
下面将重构前与重构后做下对照，来说明这套机制的优缺点。
```
```
以上内容的视频介绍，将在 《第 26 章 百万qps 三级缓存 组件实操》 中 详细介绍。
```
## 假设 10 W 人同时访问，如何保证不雪崩？

```
扩容
限流
三级缓存
```
```
三级缓存 强烈推荐进行 热点探测 相结合， 主要的优势是：
通过热点探测，既能提升 本地缓存命中率，
```
```
除此之外，还能识别 刷子用户， 把刷子用户加入 黑名单， 并且利用 bloom 过滤器进行缓存。
从而提升系统的安全性。
```
```
以上内容的视频介绍，将在 《第 26 章 百万qps 三级缓存 组件实操》 中 详细介绍。
```
## 参考文献：

```
https://blog.51cto.com/u_14889520/4870736
```
page: 23/23 of 尼恩 Java 硬核架构班：狠卷 3 高架构，卷透底层技术，走向技术自由！


```
疯狂创客圈^
```
# 硬核推荐：尼恩 Java 硬核架构班

## 又名疯狂创客圈社群 VIP

## 详情：https://www.cnblogs.com/crazymakercircle/p/9904544.html


疯狂创客圈^


```
疯狂创客圈^
```
### 架构班（社群 VIP）的起源：^

最初的视频，主要是给读者加餐。很多的读者，需要一些高质量的实操、理论视频，所以，我就围绕书，和
底层，做了几个实操、理论视频，然后效果还不错，后面就做成迭代模式了。

### 架构班（社群 VIP）的功能：^

提供高质量实操项目整刀真枪的架构指导、快速提升大家的:
 开发水平
 设计水平
 架构水平
弥补业务中 CRUD 开发短板，帮助大家尽早脱离具备 3 高能力，掌握：
 高性能
 高并发
 高可用
作为一个高质量的架构师成长、人脉社群，把所有的卷王聚焦起来，一起卷：
 卷高并发实操
 卷底层原理
 卷架构理论、架构哲学
 最终成为顶级架构师，实现人生理想，走向人生巅峰

### 架构班（社群 VIP）的目的：^

 高质量的实操，大大提升简历的含金量，吸引力，增强面试的召唤率
 为大家提供九阳真经、葵花宝典，快速提升水平
 进大厂、拿高薪
 一路陪伴，提供助学视频和指导，辅导大家成为架构师
 自学为主，和其他卷王一起，卷高并发实操，卷底层原理、卷大厂面试题，争取狠卷 3 月成高手，狠卷
3 年成为顶级架构师


```
疯狂创客圈^
```
### N 个超高并发实操项目：简历压轴、个顶个精彩


```
疯狂创客圈^
```
##### 【样章】第 17 章：横扫全网 Rocketmq 视频第 2 部曲: 工业级 rocketmq 高可用（HA）

##### 底层原理和实操

工业级 rocketmq 高可用底层原理，包含：消息消费、同步消息、异步消息、单向消息等不同消息的底层原理
和源码实现；消息队列非常底层的主从复制、高可用、同步刷盘、异步刷盘等底层原理。
工业级 rocketmq 高可用底层原理和搭建实操，包含：高可用集群的搭建。
解决以下难题：
1 、技术难题：RocketMQ 如何最大限度的保证消息不丢失的呢？RocketMQ 消息如何做到高可靠投递？
2 、技术难题：基于消息的分布式事务，核心原理不理解
3 、选型难题： kafka or rocketmq ，该娶谁？
下图链接：https://www.processon.com/view/6178e8ae0e3e7416bde9da19


```
疯狂创客圈^
```
### 成功案例：^2 年翻^3 倍，^35 岁卷王成功转型为架构师^

###### 详情：http://topcoder.cloud/forum.php?mod=forumdisplay&fid=43&page=1


疯狂创客圈^


疯狂创客圈^


疯狂创客圈^


```
疯狂创客圈^
```
### 简历优化后的成功涨薪案例（VIP 含免费简历优化）


疯狂创客圈^


疯狂创客圈^


疯狂创客圈^


疯狂创客圈^


疯狂创客圈^


```
疯狂创客圈^
```
# 修改简历找尼恩（资深简历优化专家）

######  如果面试表达不好，尼恩会提供简历优化指导

######  如果项目没有亮点，尼恩会提供项目亮点指导

######  如果面试表达不好，尼恩会提供面试表达指导

###### 作为 40 岁老架构师，尼恩长期承担技术面试官的角色：

######  从业以来，“阅历”无数，对简历有着点石成金、改头换面、脱胎换骨的指导能力。

######  尼恩指导过刚刚就业的小白，也指导过 P 8 级的老专家，都指导他们上岸。

###### 如何联系尼恩。尼恩微信，请参考下面的地址：

###### 语雀：https://www.yuque.com/crazymakercircle/gkkw8s/khigna

###### 码云：https://gitee.com/crazymaker/SimpleCrayIM/blob/master/疯狂创客圈总目录.md


